[
  {
    "date": "2026-02-09",
    "title": "GaussianCaR: Gaussian Splatting for Efficient Camera-Radar Fusion",
    "authors": "Santiago Montiel-Marín, Miguel Antunes-García, Fabio Sánchez-García, Angel Llamazares, Holger Caesar, Luis M. Bergasa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08784v1",
    "source": "arXiv",
    "abstract": "Robust and accurate perception of dynamic objects and map elements is crucial for autonomous vehicles performing safe navigation in complex traffic scenarios. While vision-only methods have become the de facto standard due to their technical advances, they can benefit from effective and cost-efficient fusion with radar measurements. In this work, we advance fusion methods by repurposing Gaussian Splatting as an efficient universal view transformer that bridges the view disparity gap, mapping both image pixels and radar points into a common Bird's-Eye View (BEV) representation. Our main contribution is GaussianCaR, an end-to-end network for BEV segmentation that, unlike prior BEV fusion methods, leverages Gaussian Splatting to map raw sensor information into latent features for efficient camera-radar fusion. Our architecture combines multi-scale fusion with a transformer decoder to efficiently extract BEV features. Experimental results demonstrate that our approach achieves performance on par with, or even surpassing, the state of the art on BEV segmentation tasks (57.3%, 82.9%, and 50.1% IoU for vehicles, roads, and lane dividers) on the nuScenes dataset, while maintaining a 3.2x faster inference runtime. Code and project page are available online."
  },
  {
    "date": "2026-02-09",
    "title": "How negative feedback from filamentous actin affects cell shapes and motility",
    "authors": "Jack M. Hughes, Jupiter Algorta, Leah Edelstein-Keshet",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08779v1",
    "source": "arXiv",
    "abstract": "The crawling motility of many eukaryotic cells is driven by filamentous actin (F-actin), and regulated by a network of signaling proteins and lipids (including small GTPases). The tangle of positive and negative feedback loops gives rise to various experimentally observed dynamic patterns (``actin waves''). Here we consider a recent prototypical model for actin waves in which F-actin exerts negative feedback onto a GTPase. Guided by recent numerical PDE bifurcation analysis in Hughes (2025) and Hughes et al (2026), we explore cell shapes and motility associated with polar, oscillatory, and traveling waves solutions of a mass-conserved partial differential equation (PDE) model. We use Morpheus (cellular Potts) simulations to investigate the implications of such regimes of behavior on the shapes and motion of cells, and on transitions between modes of behavior. The model demonstrates various cell states, including resting (spatially uniform GTPase), polar cells (static ``zones'' of GTPase), and traveling waves along the cell edge. In some parameter regimes, such states can coexist, so that cells can transition from one behavior to another in response to noisy stimuli."
  },
  {
    "date": "2026-02-09",
    "title": "Heterogeneous Optically-Detected Spin-Acoustic Resonance in Solid-State Molecular Thin-film",
    "authors": "Kuan-Cheng Chen, Yongqiang Wen, Xiaotian Xu, Max Attwood, Jingdong Xu, Chen Fu, Sami Ramadan, Shang Yu, Sandrine Heutz, Mark Oxborrow",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08772v1",
    "source": "arXiv",
    "abstract": "We report an implementation of spin-acoustic resonance in pentacene thin films integrated on a high-quality-factor (high-Q) surface acoustic wave (SAW) resonator on a lithium niobate substrate. Heterogeneous optically detected spin-acoustic resonance (HODSAR) is an optically detected spin-resonance measurement in which the resonant drive is delivered mechanically by a surface acoustic wave (SAW). By leveraging the photo-excited triplet state of pentacene at room temperature, we demonstrate coherent spin manipulation via acoustic driving under zero externally applied magnetic field. The heterogeneously integrated device, referred to as HODSAR, utilizes spin-phonon coupling to achieve mechanically driven, zero-field spin resonance, opening avenues for room-temperature mechanically addressable spin control and device integration. We show that the high-Q multimode response of the SAW resonator enables spectrally selective acoustic addressing of triplet transitions near 105 MHz. Coherent control is evidenced by Rabi oscillations, with a Rabi frequency that increases linearly with the square root of the applied RF input power over the measured drive range, consistent with driven two-level dynamics under acoustic excitation. These results establish spin-acoustic resonance in a heterogeneously integrated molecular thin-film platform and provide a quantitative basis for benchmarking mechanically mediated spin control."
  },
  {
    "date": "2026-02-09",
    "title": "A single frequency approach to nonequilibrium modeling of the chromosphere",
    "authors": "W. Ruan, D. Przybylski, R. Cameron, S. K. Solanki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08763v1",
    "source": "arXiv",
    "abstract": "The solar chromosphere is a region where radiation plays a critical role in energy transfer and interacts strongly with the plasma. In this layer, strong spectral lines, such as the Lyman lines, contribute significantly to radiative energy exchange. Due to the long ionization/relaxation timescale, departures from LTE become significant in the chromosphere. Accurately modeling this layer therefore requires one to solve the non-LTE radiative transfer for the Lyman transitions. We present an updated version of the MURaM code to enable more accurate simulations of chromospheric hydrogen level populations and temperature evolution. In the previous extension, a non-LTE equation of state, collisional transitions of hydrogen, and radiative transitions of non-Lyman lines were already implemented in the code. Building on this, we have now incorporated radiative transfer for the Lyman lines to compute radiative rate coefficients and the associated radiative losses. These were used to solve the population and temperature evolution equations, rendering the system self-consistent. To reduce computational cost, a single-frequency approximation was applied to each line in the numerical solution of the radiative transfer problem. The extended model shows good agreement with reference solutions from the Lightweaver framework, accurately capturing the radiative processes associated with Lyman lines in the chromosphere. The extension brings the simulated hydrogen level populations in the deep chromosphere closer to detailed radiative balance, while those in the upper chromosphere remain significantly out of balance, consistent with the expected conditions in the real solar atmosphere. The extension enables the MURaM code to accurately capture chromospheric dynamics."
  },
  {
    "date": "2026-02-09",
    "title": "An unusual pair of interstellar HI features and a related white dwarf star inside the HI cavity surrounding the Upper Sco-Cen OB2 Association",
    "authors": "Gerrit L. Verschuur",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08756v1",
    "source": "arXiv",
    "abstract": "Two mysterious unresolved HI structures at velocities of +12 and -6 km/s were discovered in high resolution 21-cm survey data in the direction of a faint white dwarf star. Examination of the HI morphology in this area of sky shows that the star and HI features exists in a large cavity in interstellar HI surrounding the Upper Sco-Cen OB2 Association. The cavity may have been created by an ancient supernova. It is hypothesized that the pair of HI features and filamentary HI structure found in its immediate vicinity may be the remnants of a planetary nebula some 3 x 10^5 years old that have cooled to the point that the gas is neutral and emitting the 21-cm spectral line. This remnant has maintained the morphological characteristics of the original planetary nebula because it expanded into a volume of space relatively devoid of interstellar gas that would otherwise have absorbed any traces of the original nebula."
  },
  {
    "date": "2026-02-09",
    "title": "Belief Offloading in Human-AI Interaction",
    "authors": "Rose E. Guingrich, Dvija Mehta, Umang Bhatt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08754v1",
    "source": "arXiv",
    "abstract": "What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction."
  },
  {
    "date": "2026-02-09",
    "title": "Shifting the Breaking Point of Flow Matching for Multi-Instance Editing",
    "authors": "Carmine Zaccagnino, Fabio Quattrini, Enis Simsar, Marta Tintoré Gazulla, Rita Cucchiara, Alessio Tonioni, Silvia Cascianelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08749v1",
    "source": "arXiv",
    "abstract": "Flow matching models have recently emerged as an efficient alternative to diffusion, especially for text-guided image generation and editing, offering faster inference through continuous-time dynamics. However, existing flow-based editors predominantly support global or single-instruction edits and struggle with multi-instance scenarios, where multiple parts of a reference input must be edited independently without semantic interference. We identify this limitation as a consequence of globally conditioned velocity fields and joint attention mechanisms, which entangle concurrent edits. To address this issue, we introduce Instance-Disentangled Attention, a mechanism that partitions joint attention operations, enforcing binding between instance-specific textual instructions and spatial regions during velocity field estimation. We evaluate our approach on both natural image editing and a newly introduced benchmark of text-dense infographics with region-level editing instructions. Experimental results demonstrate that our approach promotes edit disentanglement and locality while preserving global output coherence, enabling single-pass, instance-level editing."
  },
  {
    "date": "2026-02-09",
    "title": "(Claw, C_3)-free digraphs with unbounded dichromatic number",
    "authors": "Guillaume Aubian, Luis Kuffner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08736v1",
    "source": "arXiv",
    "abstract": "We construct orientations of rook graphs (whose underlying graphs are claw-free) that contain no directed $C_3$ but have unbounded dichromatic number. This disproves a conjecture of Aboulker, Charbit and Naserasr and improves a result of Carbonero, Koerts, Moore and Spirkl."
  },
  {
    "date": "2026-02-09",
    "title": "SynSacc: A Blender-to-V2E Pipeline for Synthetic Neuromorphic Eye-Movement Data and Sim-to-Real Spiking Model Training",
    "authors": "Khadija Iddrisu, Waseem Shariff, Suzanne Little, Noel OConnor",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08726v1",
    "source": "arXiv",
    "abstract": "The study of eye movements, particularly saccades and fixations, are fundamental to understanding the mechanisms of human cognition and perception. Accurate classification of these movements requires sensing technologies capable of capturing rapid dynamics without distortion. Event cameras, also known as Dynamic Vision Sensors (DVS), provide asynchronous recordings of changes in light intensity, thereby eliminating motion blur inherent in conventional frame-based cameras and offering superior temporal resolution and data efficiency. In this study, we introduce a synthetic dataset generated with Blender to simulate saccades and fixations under controlled conditions. Leveraging Spiking Neural Networks (SNNs), we evaluate its robustness by training two architectures and finetuning on real event data. The proposed models achieve up to 0.83 accuracy and maintain consistent performance across varying temporal resolutions, demonstrating stability in eye movement classification. Moreover, the use of SNNs with synthetic event streams yields substantial computational efficiency gains over artificial neural network (ANN) counterparts, underscoring the utility of synthetic data augmentation in advancing event-based vision. All code and datasets associated with this work is available at https: //github.com/Ikhadija-5/SynSacc-Dataset."
  },
  {
    "date": "2026-02-09",
    "title": "FusionEdit: Semantic Fusion and Attention Modulation for Training-Free Image Editing",
    "authors": "Yongwen Lai, Chaoqun Wang, Shaobo Min",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08725v1",
    "source": "arXiv",
    "abstract": "Text-guided image editing aims to modify specific regions according to the target prompt while preserving the identity of the source image. Recent methods exploit explicit binary masks to constrain editing, but hard mask boundaries introduce artifacts and reduce editability. To address these issues, we propose FusionEdit, a training-free image editing framework that achieves precise and controllable edits. First, editing and preserved regions are automatically identified by measuring semantic discrepancies between source and target prompts. To mitigate boundary artifacts, FusionEdit performs distance-aware latent fusion along region boundaries to yield the soft and accurate mask, and employs a total variation loss to enforce smooth transitions, obtaining natural editing results. Second, FusionEdit leverages AdaIN-based modulation within DiT attention layers to perform a statistical attention fusion in the editing region, enhancing editability while preserving global consistency with the source image. Extensive experiments demonstrate that our FusionEdit significantly outperforms state-of-the-art methods. Code is available at \\href{https://github.com/Yvan1001/FusionEdit}{https://github.com/Yvan1001/FusionEdit}."
  },
  {
    "date": "2026-02-09",
    "title": "Discovering hypergeometric series with harmonic numbers via Wilf-Zeilberger seeds",
    "authors": "Kam Cheong Au",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08721v1",
    "source": "arXiv",
    "abstract": "By extracting coefficients from Wilf-Zeilberger pairs with respect to auxiliary parameters, we discover many nontrivial hypergeometric series involving harmonic numbers. In particular, we obtain a rapidly convergent series for the depth-two multiple zeta value $ζ(5,3)$, which appears to be the first result of its kind in the literature. We also experiment with the Hilbert-Poincare series attached with a WZ-seed and conjecture that it admits a remarkably simple form, suggesting the presence of an underlying graded algebra structure behind WZ-seeds."
  },
  {
    "date": "2026-02-09",
    "title": "How far from the edge need a population be to survive? A probability model",
    "authors": "Rinaldo B. Schinazi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08712v1",
    "source": "arXiv",
    "abstract": "Let $N$ be a natural number. We consider a population which lives on $I_N=\\{-N,-N+1,\\dots,N-1,N\\}$. Each individual gives birth at rate $λ$ on each of its neighboring sites and dies at rate 1. No births are allowed from the inside of $I_N$ to the outside or vice-versa. The population on the whole line (i.e. $N=+\\infty$) survives with positive probability if and only if $λ>1/2$. On the other hand for any $1/2< λ\\leq \\sqrt 2/2$ there exists a natural number $N_c$ such that the population survives on $I_N$ for $N\\geq N_c$ but dies out for $N<N_c$. There is no limit on the number of individuals per site so the population could grow at the center where the birth rates are maximum. Our result shows that it does not if the edge is too close."
  },
  {
    "date": "2026-02-09",
    "title": "Intermediate Results on the Complexity of STRIPS$_{1}^{1}$",
    "authors": "Stefan Edelkamp, Jiří Fink, Petr Gregor, Anders Jonsson, Bernhard Nebel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08708v1",
    "source": "arXiv",
    "abstract": "This paper is based on Bylander's results on the computational complexity of propositional STRIPS planning. He showed that when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. While NP-hardness is settled, it is unknown whether propositional STRIPS with operators that only have one precondition and one effect is NP-complete. We shed light on the question whether this small solution hypothesis for STRIPS$^1_1$ is true, calling a SAT solver for small instances, introducing the literal graph, and mapping it to Petri nets."
  },
  {
    "date": "2026-02-09",
    "title": "Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers",
    "authors": "Aditya Gulati, Nuria Oliver",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08707v1",
    "source": "arXiv",
    "abstract": "As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices that leverage cognitive biases to influence user behavior. Based on this observation, we propose reframing chatbots not as companions or assistants, but as highly skilled salespeople whose objectives are determined by the deploying organization. We argue that the coexistence of competing notions of \"trust\" under a shared term obscures important distinctions between psychological trust formation and normative trustworthiness. Addressing this gap requires further research and stronger support mechanisms to help users appropriately calibrate trust in conversational AI systems."
  },
  {
    "date": "2026-02-09",
    "title": "Weak forms offer strong regularisations: how to make physics-informed (quantum) machine learning more robust",
    "authors": "Annie E. Paine, Smit Chaudhary, Antonio A. Gentile",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08703v1",
    "source": "arXiv",
    "abstract": "Physics-informed (PI) methodologies have surged to become a pillar route to solve Differential Equations (DEs), sustained by the growth of machine learning methods in scientific contexts. The main proposition of PI is to minimise variationally a loss function, formally ensuring that a neural surrogate of the solution has the DE locally satisfied. The nature of such formulation encouraged the exploration of equivalent quantum algorithms, where the surrogate solution is expressed by variational quantum architectures. The locality of typical loss functions emphasises the DE to hold at an ensemble of points sampled in the domain, but encounters issues when generalising beyond such points, or when propagating boundary conditions. Issues which affect classical and quantum PI algorithms alike. The quest to fill this gap in robustness and accuracy against mainstream DE solvers has led to a plethora of proposals in various directions. In particular, classical DE solvers have long employed the weak form - an integral based approach aiming at imposing a global condition on the solution - prioritising a good average behaviour instead of ``overfitting'' select points. Here, we propose and explore to combine contributions from both local and global loss functions in PI routines, to exploit the advantages and mitigate the weaknesses of both. We showcase this intuition in a variety of problems focusing on differentiable quantum architectures, and demonstrating in particular how orchestrating such hybrid loss formulation with domain decomposition can offer a strong advantage over local-only strategies."
  },
  {
    "date": "2026-02-09",
    "title": "Low-Light Video Enhancement with An Effective Spatial-Temporal Decomposition Paradigm",
    "authors": "Xiaogang Xu, Kun Zhou, Tao Hu, Jiafei Wu, Ruixing Wang, Hao Peng, Bei Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08699v1",
    "source": "arXiv",
    "abstract": "Low-Light Video Enhancement (LLVE) seeks to restore dynamic or static scenes plagued by severe invisibility and noise. In this paper, we present an innovative video decomposition strategy that incorporates view-independent and view-dependent components to enhance the performance of LLVE. The framework is called View-aware Low-light Video Enhancement (VLLVE). We leverage dynamic cross-frame correspondences for the view-independent term (which primarily captures intrinsic appearance) and impose a scene-level continuity constraint on the view-dependent term (which mainly describes the shading condition) to achieve consistent and satisfactory decomposition results. To further ensure consistent decomposition, we introduce a dual-structure enhancement network featuring a cross-frame interaction mechanism. By supervising different frames simultaneously, this network encourages them to exhibit matching decomposition features. This mechanism can seamlessly integrate with encoder-decoder single-frame networks, incurring minimal additional parameter costs. Building upon VLLVE, we propose a more comprehensive decomposition strategy by introducing an additive residual term, resulting in VLLVE++. This residual term can simulate scene-adaptive degradations, which are difficult to model using a decomposition formulation for common scenes, thereby further enhancing the ability to capture the overall content of videos. In addition, VLLVE++ enables bidirectional learning for both enhancement and degradation-aware correspondence refinement (end-to-end manner), effectively increasing reliable correspondences while filtering out incorrect ones. Notably, VLLVE++ demonstrates strong capability in handling challenging cases, such as real-world scenes and videos with high dynamics. Extensive experiments are conducted on widely recognized LLVE benchmarks."
  },
  {
    "date": "2026-02-09",
    "title": "Reasoning aligns language models to human cognition",
    "authors": "Gonçalo Guiomar, Elia Torre, Pehuen Moure, Victoria Shavina, Mario Giulianelli, Shih-Chii Liu, Valerio Mante",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08693v1",
    "source": "arXiv",
    "abstract": "Do language models make decisions under uncertainty like humans do, and what role does chain-of-thought (CoT) reasoning play in the underlying decision process? We introduce an active probabilistic reasoning task that cleanly separates sampling (actively acquiring evidence) from inference (integrating evidence toward a decision). Benchmarking humans and a broad set of contemporary large language models against near-optimal reference policies reveals a consistent pattern: extended reasoning is the key determinant of strong performance, driving large gains in inference and producing belief trajectories that become strikingly human-like, while yielding only modest improvements in active sampling. To explain these differences, we fit a mechanistic model that captures systematic deviations from optimal behavior via four interpretable latent variables: memory, strategy, choice bias, and occlusion awareness. This model places humans and models in a shared low-dimensional cognitive space, reproduces behavioral signatures across agents, and shows how chain-of-thought shifts language models toward human-like regimes of evidence accumulation and belief-to-choice mapping, tightening alignment in inference while leaving a persistent gap in information acquisition."
  },
  {
    "date": "2026-02-09",
    "title": "Constraints on non-standard neutrino interactions from Borexino extended data-set",
    "authors": "V. Antonelli, D. Basilico, G. Bellini, J. Benziger, R. Biondi, B. Caccianiga, F. Calaprice, A. Caminata, A. Chepurnov, D. D'Angelo, A. Derbin, A. Di Giacinto, V. Di Marcello, X. F. Ding, A. Di Ludovico, L. Di Noto, I. Drachnev, D. Franco, C. Galbiati, C. Ghiano, M. Giammarchi, A. Goretti, M. Gromov, D. Guffanti, Aldo Ianni, Andrea Ianni, A. Jany, V. Kobychev, G. Korga, S. Kumaran, M. Laubenstein, E. Litvinovich, P. Lombardi, I. Lomskaya, L. Ludhova, I. Machulin, J. Martyn, E. Meroni, L. Miramonti, M. Misiaszek, V. Muratova, L. Oberauer, V. Orekhov, F. Ortica, M. Pallavicini, L. Pelicci, O. Penek, L. Pietrofaccia, N. Pilipenko, A. Pocar, G. Raikov, M. T. Ranalli, G. Ranucci, A. Razeto, A. Re, N. Rossi, S. Schoenert, D. Semenov, G. Settanta, M. Skorokhvatov, A. Singhal, O. Smirnov, A. Sotnikov, G. Sun, R. Tartaglia, G. Testera, M. D. C. Torri, E. Unzhakov, A. Vishneva, R. B. Vogelaar, F. von Feilitzsch, M. Wojcik, M. Wurm, S. Zavatarelli, X. Zhou, K. Zuber, G. Zuzel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08685v1",
    "source": "arXiv",
    "abstract": "Neutrino non-standard interactions (NSI) constitute an active research field, as they are closely related to potential new physics associated with dark matter searches and exotic interactions arising from fundamental symmetry violations. The Borexino's unprecedented sensitivity to solar neutrinos, derived from its low background and precision spectral measurements, enables stringent constraints on potential deviations from the standard three-flavor neutrino oscillation paradigm. This work presents an update on the analysis of flavor-diagonal NSI using the full Borexino Phase-III data set, extending the study previously reported in Constraints on flavor-diagonal non-standard neutrino interactions from Borexino Phase-II (JHEP 2020, 38). The updated analysis incorporates the extended temporal and statistical coverage of Phase-III. The results indicate improved sensitivity to the diagonal NSI parameters, with constraints exceeding those obtained in Phase-II. Furthermore, a more general analysis that includes all possible off-diagonal NSI terms is presented for the first time, providing a comprehensive exploration of the NSI parameter space associated with the flavors of the incoming and outgoing neutrinos. This work once again underlines Borexino's critical role in probing new physics scenarios and reinforces its legacy in neutrino research. Detailed comparisons with Phase-II results are discussed, along with implications for theoretical models of NSI."
  },
  {
    "date": "2026-02-09",
    "title": "ALIVE: Animate Your World with Lifelike Audio-Video Generation",
    "authors": "Ying Guo, Qijun Gan, Yifu Zhang, Jinlai Liu, Yifei Hu, Pan Xie, Dongjun Qian, Yu Zhang, Ruiqi Li, Yuqi Zhang, Ruibiao Lu, Xiaofeng Mei, Bo Han, Xiang Yin, Bingyue Peng, Zehuan Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08682v1",
    "source": "arXiv",
    "abstract": "Video generation is rapidly evolving towards unified audio-video generation. In this paper, we present ALIVE, a generation model that adapts a pretrained Text-to-Video (T2V) model to Sora-style audio-video generation and animation. In particular, the model unlocks the Text-to-Video&Audio (T2VA) and Reference-to-Video&Audio (animation) capabilities compared to the T2V foundation models. To support the audio-visual synchronization and reference animation, we augment the popular MMDiT architecture with a joint audio-video branch which includes TA-CrossAttn for temporally-aligned cross-modal fusion and UniTemp-RoPE for precise audio-visual alignment. Meanwhile, a comprehensive data pipeline consisting of audio-video captioning, quality control, etc., is carefully designed to collect high-quality finetuning data. Additionally, we introduce a new benchmark to perform a comprehensive model test and comparison. After continue pretraining and finetuning on million-level high-quality data, ALIVE demonstrates outstanding performance, consistently outperforming open-source models and matching or surpassing state-of-the-art commercial solutions. With detailed recipes and benchmarks, we hope ALIVE helps the community develop audio-video generation models more efficiently. Official page: https://github.com/FoundationVision/Alive."
  },
  {
    "date": "2026-02-09",
    "title": "Branch-Price-and-Cut Accelerated with a Pricing for Integrality Heuristic for the Electrical Vehicle Routing Problem with Time Windows and Charging Time Slots",
    "authors": "Lukas Eveborn, Elina Rönnberg",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08673v1",
    "source": "arXiv",
    "abstract": "Branch-price-and-cut is the state-of-the-art exact method for solving many types of vehicle routing problems, and is particularly effective for vehicle routing problems with time windows. A well-known challenge in branch-price-and-cut is that the generation of columns is guided by information from the linear relaxation of the master problem, with no guarantee that they will be useful from an integer perspective. As a consequence, high-quality primal solutions are often found only after significant cutting and branching or the use of primal heuristics. In this work, based on the ideas of pricing for integrality, we propose a new primal heuristic for vehicle routing problems.The heuristic is designed to generate columns that are more likely to be part of high-quality integer solutions. It begins by constructing a partial integer solution from a given column pool and then iteratively searches for columns that complement this solution. The search is done by modifying the pricing problem with respect to the partial solution, linear program dual information as well as previously generated columns in the heuristic. Computational tests are performed on the electrical vehicle routing problem with time windows extended with charging time slots, a problem that has both scheduling and routing aspects, making it well-suited to evaluate the performance of the proposed heuristic. The results show that the proposed heuristic closes 30% - 40% of the root node gap on average in comparison to a restricted master heuristic."
  },
  {
    "date": "2026-02-09",
    "title": "Lifts of cycles in tropical hypersurfaces and the Gamma conjecture",
    "authors": "Yuto Yamamoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08666v1",
    "source": "arXiv",
    "abstract": "For a complex hypersurface of dimension $d \\geq 1$ in a toric variety, we construct lifts of tropical $(p, q)$-cycles with $p+q=d$ in the associated tropical hypersurface. The tropical cycles we consider are described by Minkowski weights, and their lifts are realized as topological cycles admitting a torus fibration structure over the tropical cycles. The intersection numbers of these lifted cycles are computed in terms of tropical intersection theory. We further derive the asymptotic formulas for the period integrals of the lifts in the tropical limit, which are closely related to the mirror symmetric Gamma conjecture. Throughout the paper, we assume that the tropicalization is dual to a unimodular triangulation of the Newton polytope."
  },
  {
    "date": "2026-02-09",
    "title": "Heterogeneous Distributed Zeroth-Order Nonconvex Optimization with Communication Compression",
    "authors": "Haonan Wang, Xinlei Yi, Yiguang Hong, Minghui Liwang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08659v1",
    "source": "arXiv",
    "abstract": "Distributed zeroth-order optimization is increasingly applied in heterogeneous scenarios where agents possess distinct data distributions and objectives. This heterogeneity poses fundamental challenges for convergence analysis, as existing convergence analyses rely on relatively strong assumptions to ensure theoretical guarantees. Specifically, at least one of the following three assumptions is usually required: (i) data homogeneity across agents, (ii) $\\mathcal{O}(pn)$ function evaluations per iteration with $p$ denoting the dimension and $n$ the number of agents, or (iii) the Polyak--Łojasiewicz (P--L) or strong convexity condition with a known corresponding constant. To overcome these limitations, we propose a Heterogeneous Distributed Zeroth-Order Compressed (HEDZOC) algorithm, which is based on a two-point zeroth-order gradient estimator and a general class of compressors. Without assuming data homogeneity, we develop the analysis covering three settings: general nonconvex functions, functions satisfying the P--L condition without knowing the P--L constant, and those with a known constant. To the best of our knowledge, the proposed HEDZOC algorithm is the first distributed zeroth-order method that establishes convergence without relying on the above three assumptions. Moreover, it achieves linear speedup convergence rate, which is comparable to state-of-the-art results attainable under data homogeneity and exact communication assumptions. Finally, experiments on heterogeneous adversarial example generation validate the theoretical results."
  },
  {
    "date": "2026-02-09",
    "title": "Measures for Assessing Causal Effect Heterogeneity Unexplained by Covariates",
    "authors": "Yuta Kawakami, Jin Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08647v1",
    "source": "arXiv",
    "abstract": "There has been considerable interest in estimating heterogeneous causal effects across individuals or subpopulations. Researchers often assess causal effect heterogeneity based on the subjects' covariates using the conditional average causal effect (CACE). However, substantial heterogeneity may persist even after accounting for the covariates. Existing work on causal effect heterogeneity unexplained by covariates mainly focused on binary treatment and outcome. In this paper, we introduce novel heterogeneity measures, P-CACE and N-CACE, for binary treatment and continuous outcome that represent CACE over the positively and negatively affected subjects, respectively. We also introduce new heterogeneity measures, P-CPICE and N-CPICE, for continuous treatment and continuous outcome by leveraging stochastic interventions, expanding causal questions that researchers can answer. We establish identification and bounding theorems for these new measures. Finally, we show their application to a real-world dataset."
  },
  {
    "date": "2026-02-09",
    "title": "Enhancing Genetic Algorithms with Graph Neural Networks: A Timetabling Case Study",
    "authors": "Laura-Maria Cornei, Mihaela-Elena Breabăn",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08619v1",
    "source": "arXiv",
    "abstract": "This paper investigates the impact of hybridizing a multi-modal Genetic Algorithm with a Graph Neural Network for timetabling optimization. The Graph Neural Network is designed to encapsulate general domain knowledge to improve schedule quality, while the Genetic Algorithm explores different regions of the search space and integrates the deep learning model as an enhancement operator to guide the solution search towards optimality. Initially, both components of the hybrid technique were designed, developed, and optimized independently to solve the tackled task. Multiple experiments were conducted on Staff Rostering, a well-known timetabling problem, to compare the proposed hybridization with the standalone optimized versions of the Genetic Algorithm and Graph Neural Network. The experimental results demonstrate that the proposed hybridization brings statistically significant improvements in both the time efficiency and solution quality metrics, compared to the standalone methods. To the best of our knowledge, this work proposes the first hybridization of a Genetic Algorithm with a Graph Neural Network for solving timetabling problems."
  },
  {
    "date": "2026-02-09",
    "title": "Breaking the Grid: Distance-Guided Reinforcement Learning in Large Discrete and Hybrid Action Spaces",
    "authors": "Heiko Hoppe, Fabian Akkerman, Wouter van Heeswijk, Maximilian Schiffer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08616v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning is increasingly applied to logistics, scheduling, and recommender systems, but standard algorithms struggle with the curse of dimensionality in such large discrete action spaces. Existing algorithms typically rely on restrictive grid-based structures or computationally expensive nearest-neighbor searches, limiting their effectiveness in high-dimensional or irregularly structured domains. We propose Distance-Guided Reinforcement Learning (DGRL), combining Sampled Dynamic Neighborhoods (SDN) and Distance-Based Updates (DBU) to enable efficient RL in spaces with up to 10$^\\text{20}$ actions. Unlike prior methods, SDN leverages a semantic embedding space to perform stochastic volumetric exploration, provably providing full support over a local trust region. Complementing this, DBU transforms policy optimization into a stable regression task, decoupling gradient variance from action space cardinality and guaranteeing monotonic policy improvement. DGRL naturally generalizes to hybrid continuous-discrete action spaces without requiring hierarchical dependencies. We demonstrate performance improvements of up to 66% against state-of-the-art benchmarks across regularly and irregularly structured environments, while simultaneously improving convergence speed and computational complexity."
  },
  {
    "date": "2026-02-09",
    "title": "Inspiration Seeds: Learning Non-Literal Visual Combinations for Generative Exploration",
    "authors": "Kfir Goldberg, Elad Richardson, Yael Vinker",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08615v1",
    "source": "arXiv",
    "abstract": "While generative models have become powerful tools for image synthesis, they are typically optimized for executing carefully crafted textual prompts, offering limited support for the open-ended visual exploration that often precedes idea formation. In contrast, designers frequently draw inspiration from loosely connected visual references, seeking emergent connections that spark new ideas. We propose Inspiration Seeds, a generative framework that shifts image generation from final execution to exploratory ideation. Given two input images, our model produces diverse, visually coherent compositions that reveal latent relationships between inputs, without relying on user-specified text prompts. Our approach is feed-forward, trained on synthetic triplets of decomposed visual aspects derived entirely through visual means: we use CLIP Sparse Autoencoders to extract editing directions in CLIP latent space and isolate concept pairs. By removing the reliance on language and enabling fast, intuitive recombination, our method supports visual ideation at the early and ambiguous stages of creative work."
  },
  {
    "date": "2026-02-09",
    "title": "JOREK simulations of the X-point radiator formation and its movement in ASDEX Upgrade",
    "authors": "Y. C. Liang, A. Cathey, M. Hoelzl, S. Q. Korving, M. Szucs, O. Pan, D. Maris, F. Antlitz, the JOREK Team, the ASDEX Upgrade Team",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08614v1",
    "source": "arXiv",
    "abstract": "Future large-scale magnetic confinement fusion reactors require operational regimes that can avoid extreme heat fluxes onto the plasma-facing components. One promising regime is the X-point radiator (XPR), which relies on a highly radiative, cold and dense plasma volume forming above the X-point, and which can be accessed via impurity seeding. Experimentally, the height of the XPR can be controlled by adjusting the seeding rate and heating power. This contribution presents axisymmetric (2D) simulations of the XPR regime in ASDEX Upgrade using the nonlinear MHD code JOREK extended with a kinetic particle framework for the main species neutrals and nitrogen impurities. With the time-dependent simulations, the progression from attached divertors to a complete detachment with the XPR formation is shown, highlighting the effects of the neutrals and impurities separately. Amidst this progression, the formation and the loss of the high-field-side high-density are observed. After the XPR is well-formed at the height of 6.8 cm, the fuelling and seeding rates are adjusted so that the XPR remains stationary. From the stationary case, the seeding rate is then changed to see how the XPR location reacts. By increasing and decreasing the seeding rate, the XPR responds by moving upwards and downwards, respectively. These simulations show JOREK's capability of simulating time-varying XPR, which will provide a baseline for the transition to 3D simulations, so the MHD activities and their interaction with the XPR can be studied."
  },
  {
    "date": "2026-02-09",
    "title": "Quantum Charging Advantage in Superconducting Solid-State Batteries",
    "authors": "Chang-Kang Hu, Chilong Liu, Jingchao Zhao, Liuzhu Zhong, Yuxuan Zhou, Mingze Liu, Haolan Yuan, Yongchang Lin, Yue Xu, Guantian Hu, Guixu Xie, Zixing Liu, Ruiyang Zhou, Yougui Ri, Wenxuan Zhang, Ruicheng Deng, Andreia Saguia, Xiayu Linpeng, Marcelo S. Sarandy, Song Liu, Alan C. Santos, Dian Tan, Dapeng Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08610v1",
    "source": "arXiv",
    "abstract": "Quantum battery, as a novel energy storage device, offers the potential for unprecedented efficiency and performance beyond the capabilities of classical systems, with broad implications for future quantum technologies. Here, we experimentally \\RefC{demonstrate quantum charging advantage (QCA)} in a scalable solid-state quantum battery. More specifically, we show how double-excitation Hamiltonians for two-level systems promote scalable QCA \\RefB{with standard methods.} We effectively implement the collective evolution of quantum systems with 2 up to 12 battery cells in a superconducting quantum processor, and study the performance of quantum charging compared to its uncorrelated classical counterpart. The model considered is a linear chain of superconducting transmon qubits with only \\textit{nearest-neighbor} and \\textit{pairwise} interactions, which constitute the simplest model of a multi-cell quantum battery. Our results empirically realize substantial QCA without the necessity of adopting long-range and many-body interactions \\RefB{ and showcase the quantum features of the QB charging processes with measurements of non-zero coherent ergotropy, incoherent ergotropy and entanglement,} revealing a promising prospect for further developments of efficient and experimentally feasible protocols for QCA."
  },
  {
    "date": "2026-02-09",
    "title": "Holographic information measures for spin-$3/2$ $Δ$ baryons in AdS/QCD",
    "authors": "H. Almeida, R. da Rocha, P. H. O. Silva, B. Toniato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08605v1",
    "source": "arXiv",
    "abstract": "Spin-$3/2$ $Δ$ baryon resonances are investigated within AdS/QCD, using Rarita-Schwinger fields. The differential configurational entropy (DCE) and differential configurational complexity (DCC) associated with their bulk energy densities are computed. It yields Regge-like trajectories relating configurational information measures to the radial excitation number and the experimental mass spectrum of the $Δ$ baryons. We then extrapolate the spectrum of heavier $Δ$ baryon resonances beyond currently established states in the PDG, also comparing them with states in PDG omitted from the summary table. Our results support a relevant interplay among holographic QCD dynamics, configurational information entropy, and baryon spectroscopy in strongly coupled QCD."
  },
  {
    "date": "2026-02-09",
    "title": "RFSoC-Based Integrated Navigation and Sensing Using NavIC",
    "authors": "Riya Sachdeva, Aakanksha Tewari, Sumit J. Darak, Shobha Sundar Ram, Sanat K. Biswas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08596v1",
    "source": "arXiv",
    "abstract": "Prior art has proposed a secondary application for Global Navigation Satellite System (GNSS) infrastructure for remote sensing of ground-based and maritime targets. Here, a passive radar receiver is deployed to detect uncooperative targets on Earth's surface by capturing ground-reflected satellite signals. This work demonstrates a hardware prototype of an L-band Navigation with Indian Constellation (NavIC) satellite-based remote sensing receiver system mounted on an AMD Zynq radio frequency system-on-chip (RFSoC) platform. Two synchronized receiver channels are introduced for capturing the direct signal (DS) from the satellite and ground-reflected signal (GRS) returns from targets. These signals are processed on the ARM processor and field programmable gate array (FPGA) of the RFSoC to generate delay-Doppler maps of the ground-based targets. The performance is first validated in a loop-back configuration of the RFSoC. Next, the DS and GRS signals are emulated by the output from two ports of the Keysight Arbitrary Waveform Generator (AWG) and interfaced with the RFSoC where the signals are subsequently processed to obtain the delay-Doppler maps. The performance is validated for different signal-to-noise ratios (SNR)."
  },
  {
    "date": "2026-02-09",
    "title": "MOSAIC: Bridging the Sim-to-Real Gap in Generalist Humanoid Motion Tracking and Teleoperation with Rapid Residual Adaptation",
    "authors": "Zhenguo Sun, Bo-Sheng Huang, Yibo Peng, Xukun Li, Jingyu Ma, Yu Sun, Zhe Li, Haojun Jiang, Biao Gao, Zhenshan Bing, Xinlong Wang, Alois Knoll",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08594v1",
    "source": "arXiv",
    "abstract": "Generalist humanoid motion trackers have recently achieved strong simulation metrics by scaling data and training, yet often remain brittle on hardware during sustained teleoperation due to interface- and dynamics-induced errors. We present MOSAIC, an open-source, full-stack system for humanoid motion tracking and whole-body teleoperation across multiple interfaces. MOSAIC first learns a teleoperation-oriented general motion tracker via RL on a multi-source motion bank with adaptive resampling and rewards that emphasize world-frame motion consistency, which is critical for mobile teleoperation. To bridge the sim-to-real interface gap without sacrificing generality, MOSAIC then performs rapid residual adaptation: an interface-specific policy is trained using minimal interface-specific data, and then distilled into the general tracker through an additive residual module, outperforming naive fine-tuning or continual learning. We validate MOSAIC with systematic ablations, out-of-distribution benchmarking, and real-robot experiments demonstrating robust offline motion replay and online long-horizon teleoperation under realistic latency and noise."
  },
  {
    "date": "2026-02-09",
    "title": "Conditional Sequence Modeling for Safe Reinforcement Learning",
    "authors": "Wensong Bai, Chao Zhang, Qihang Xu, Chufan Chen, Chenhao Zhou, Hui Qian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08584v1",
    "source": "arXiv",
    "abstract": "Offline safe reinforcement learning (RL) aims to learn policies from a fixed dataset while maximizing performance under cumulative cost constraints. In practice, deployment requirements often vary across scenarios, necessitating a single policy that can adapt zero-shot to different cost thresholds. However, most existing offline safe RL methods are trained under a pre-specified threshold, yielding policies with limited generalization and deployment flexibility across cost thresholds. Motivated by recent progress in conditional sequence modeling (CSM), which enables flexible goal-conditioned control by specifying target returns, we propose RCDT, a CSM-based method that supports zero-shot deployment across multiple cost thresholds within a single trained policy. RCDT is the first CSM-based offline safe RL algorithm that integrates a Lagrangian-style cost penalty with an auto-adaptive penalty coefficient. To avoid overly conservative behavior and achieve a more favorable return--cost trade-off, a reward--cost-aware trajectory reweighting mechanism and Q-value regularization are further incorporated. Extensive experiments on the DSRL benchmark demonstrate that RCDT consistently improves return--cost trade-offs over representative baselines, advancing the state-of-the-art in offline safe RL."
  },
  {
    "date": "2026-02-09",
    "title": "Modeling Score Approximation Errors in Diffusion Models via Forward SPDEs",
    "authors": "Junsu Seo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08579v1",
    "source": "arXiv",
    "abstract": "This study investigates the dynamics of Score-based Generative Models (SGMs) by treating the score estimation error as a stochastic source driving the Fokker-Planck equation. Departing from particle-centric SDE analyses, we employ an SPDE framework to model the evolution of the probability density field under stochastic drift perturbations. Under a simplified setting, we utilize this framework to interpret the robustness of generative models through the lens of geometric stability and displacement convexity. Furthermore, we introduce a candidate evaluation metric derived from the quadratic variation of the SPDE solution projected onto a radial test function. Preliminary observations suggest that this metric remains effective using only the initial 10% of the sampling trajectory, indicating a potential for computational efficiency."
  },
  {
    "date": "2026-02-09",
    "title": "Time resolution at the quantum limit of two incoherent sources based on frequency resolved two-photon-interference",
    "authors": "Salvatore Muratore, Vincenzo Tamma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08578v1",
    "source": "arXiv",
    "abstract": "The Rayleigh criterion is a widely known limit in the resolution of incoherent sources with classical measurements in the spatial domain. Unsurprisingly the estimation of the time delay between two weak incoherent signals is afflicted by an analogue problem. In this work, we show the emergence of two-photon quantum beats in the frequency domain from the interference at a beam splitter of a photon emitted by a reference source and one from the two incoherent weak signals. We demonstrate, based on this phenomena, that with a relatively low number of measurements of the frequencies of the interfering photons either bunching or antibunching at the beam splitter output one can achieve a precision amounting to half of the quantum limit, independently of both the temporal shape of the photonic wavepacket and the time delay to be estimated. The feasibility of the technique makes it applicable in astronomy, microscopy, remote clocks synchronization and radar ranging"
  },
  {
    "date": "2026-02-09",
    "title": "Multiple convolutions and multilinear fractal Fourier restriction",
    "authors": "Itamar Oliveira, Ana E. de Orellana",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08568v1",
    "source": "arXiv",
    "abstract": "The classical Stein--Tomas theorem extends the theory of linear Fourier restriction estimates from smooth manifolds to fractal measures exhibiting Fourier decay. In the multilinear setting, transversality allows for Fourier extension estimates that go beyond those implied by the linear theory to hold. We establish a multilinear Fourier extension estimate for measures whose convolution belongs to an $L^p$ space, applicable to known results by Shmerkin and Solomyak that exploit `transversality' between self-similar measures. Moreover, we generalise work by Hambrook--Łaba and Chen from the linear setting to obtain Knapp-type examples for multilinear estimates; we obtain two necessary conditions: one in terms of the upper box dimension of the measures' supports, and another one in terms of their Fourier decay and a ball condition. In particular, these conditions give a more restrictive range compared with previously known results whenever the convolution of the measures at play is singular."
  },
  {
    "date": "2026-02-09",
    "title": "ValueFlow: Measuring the Propagation of Value Perturbations in Multi-Agent LLM Systems",
    "authors": "Jinnuo Liu, Chuke Liu, Hua Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08567v1",
    "source": "arXiv",
    "abstract": "Multi-agent large language model (LLM) systems increasingly consist of agents that observe and respond to one another's outputs. While value alignment is typically evaluated for isolated models, how value perturbations propagate through agent interactions remains poorly understood. We present ValueFlow, a perturbation-based evaluation framework for measuring and analyzing value drift in multi-agent systems. ValueFlow introduces a 56-value evaluation dataset derived from the Schwartz Value Survey and quantifies agents' value orientations during interaction using an LLM-as-a-judge protocol. Building on this measurement layer, ValueFlow decomposes value drift into agent-level response behavior and system-level structural effects, operationalized by two metrics: beta-susceptibility, which measures an agent's sensitivity to perturbed peer signals, and system susceptibility (SS), which captures how node-level perturbations affect final system outputs. Experiments across multiple model backbones, prompt personas, value dimensions, and network structures show that susceptibility varies widely across values and is strongly shaped by structural topology."
  },
  {
    "date": "2026-02-09",
    "title": "Homing through Reinforcement Learning",
    "authors": "Riya Singh, Pratikshya Jena, Anish Kumar, Shradha Mishra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08566v1",
    "source": "arXiv",
    "abstract": "Homing and navigation are fundamental behaviors in biological systems that enable agents to reliably reach a target under uncertainty. We present a Reinforcement Learning (RL) framework to model adaptive homing in continuous two-dimensional domain. In this framework, the agent's state is given by its angular deviation from home, actions correspond to alignment or stochastic reorientation, and learning is driven by a radial-distance-based cost that penalizes motion away from the target. For a single self-propelled agent moving with constant speed, we find that the mean homing time $\\langle T_{\\mathrm{home}} \\rangle$ exhibits a non-monotonic dependence on the rotational diffusion strength $D_r$, with an optimal noise level $D_r^{*}$, revealing a subtle interplay between exploration and goal-directed correction. Extending to two agents with soft repulsion, one agent consistently reaches home faster than the other, while in multi-agents system, repulsion ensures separation and the fastest agent becomes progressively faster as group size increases. Finally comparing the mean homing time $\\langle T_{\\mathrm{home}} \\rangle$ of an Active Brownian Particle (ABP) and RL agent over an identical range of $D_r$, we find that RL trajectories are shorter, less noisy, and consistently faster. Our results show that cost-driven learning, stochastic reorientation, and inter-agent interactions enable efficient adaptive navigation, linking individual and collective homing. This reinforcement learning framework captures key biological features such as feedback-based route learning, randomness to escape unfavorable orientations, and mutual coordination."
  },
  {
    "date": "2026-02-09",
    "title": "Semantics and Multi-Query Optimization Algorithms for the Analyze Operator",
    "authors": "Marios Iakovidis, Panos Vassiliadis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08546v1",
    "source": "arXiv",
    "abstract": "In their hunt for highlights, i.e., interesting patterns in the data, data analysts have to issue groups of related queries and manually combine their results. To the extent that the analyst's goals are based on an intention on what to discover (e.g., contrast a query result to peer ones, verify a pattern to a broader range of data in the data space, etc), the integration of intentional query operators in analytical engines can enhance the efficiency of these analytical tasks. In this paper, we introduce, with well-defined semantics, the ANALYZE operator, a novel cube querying intentional operator that provides a 360 view of data. We define the semantics of an ANALYZE query as a tuple of five internal, facilitator cube queries, that (a) report on the specifics of a particular subset of the data space, which is part of the query specification, and to which we refer as the original query, (b) contrast the result with results from peer-subspaces, or sibling queries, and, (c) explore the data space in lower levels of granularity via drill-down queries. We introduce formal query semantics for the operator and we theoretically prove that we can obtain the exact same result by merging the facilitator cube queries into a smaller number of queries. This effectively introduces a multi-query optimization (MQO) strategy for executing an ANALYZE query. We propose three alternative algorithms, (a) a simple execution without optimizations (Min-MQO), (b) a total merging of all the facilitator queries to a single one (Max-MQO), and (c) an intermediate strategy, Mid-MQO, that merges only a subset of the facilitator queries. Our experimentation demonstrates that Mid-MQO achieves consistently strong performance across several contexts, Min-MQO always follows it, and Max-MQO excels for queries where the siblings are sizable and significantly overlap."
  },
  {
    "date": "2026-02-09",
    "title": "Adaptive Markovian Spatiotemporal Transfer Learning in Multivariate Bayesian Modeling",
    "authors": "Luca Presicce, Sudipto Banerjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08544v1",
    "source": "arXiv",
    "abstract": "This manuscript develops computationally efficient online learning for multivariate spatiotemporal models. The method relies on matrix-variate Gaussian distributions, dynamic linear models, and Bayesian predictive stacking to efficiently share information across temporal data shards. The model facilitates effective information propagation over time while seamlessly integrating spatial components within a dynamic framework, building a Markovian dependence structure between datasets at successive time instants. This structure supports flexible, high-dimensional modeling of complex dependence patterns, as commonly found in spatiotemporal phenomena, where computational challenges arise rapidly with increasing dimensions. The proposed approach further manages exact inference through predictive stacking, enhancing accuracy and interoperability. Combining sequential and parallel processing of temporal shards, each unit passes assimilated information forward, then back-smoothed to improve posterior estimates, incorporating all available information. This framework advances the scalability and adaptability of spatiotemporal modeling, making it suitable for dynamic, multivariate, and data-rich environments."
  },
  {
    "date": "2026-02-09",
    "title": "GISA: A Benchmark for General Information-Seeking Assistant",
    "authors": "Yutao Zhu, Xingshuo Zhang, Maosen Zhang, Jiajie Jin, Liancheng Zhang, Xiaoshuai Song, Kangzhi Zhao, Wencong Zeng, Ruiming Tang, Han Li, Ji-Rong Wen, Zhicheng Dou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08543v1",
    "source": "arXiv",
    "abstract": "The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\\% exact match score, with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement."
  },
  {
    "date": "2026-02-09",
    "title": "TIBR4D: Tracing-Guided Iterative Boundary Refinement for Efficient 4D Gaussian Segmentation",
    "authors": "He Wu, Xia Yan, Yanghui Xu, Liegang Xia, Jiazhou Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08540v1",
    "source": "arXiv",
    "abstract": "Object-level segmentation in dynamic 4D Gaussian scenes remains challenging due to complex motion, occlusions, and ambiguous boundaries. In this paper, we present an efficient learning-free 4D Gaussian segmentation framework that lifts video segmentation masks to 4D spaces, whose core is a two-stage iterative boundary refinement, TIBR4D. The first stage is an Iterative Gaussian Instance Tracing (IGIT) at the temporal segment level. It progressively refines Gaussian-to-instance probabilities through iterative tracing, and extracts corresponding Gaussian point clouds that better handle occlusions and preserve completeness of object structures compared to existing one-shot threshold-based methods. The second stage is a frame-wise Gaussian Rendering Range Control (RCC) via suppressing highly uncertain Gaussians near object boundaries while retaining their core contributions for more accurate boundaries. Furthermore, a temporal segmentation merging strategy is proposed for IGIT to balance identity consistency and dynamic awareness. Longer segments enforce stronger multi-frame constraints for stable identities, while shorter segments allow identity changes to be captured promptly. Experiments on HyperNeRF and Neu3D demonstrate that our method produces accurate object Gaussian point clouds with clearer boundaries and higher efficiency compared to SOTA methods."
  },
  {
    "date": "2026-02-09",
    "title": "Trajectory Stitching for Solving Inverse Problems with Flow-Based Models",
    "authors": "Alexander Denker, Moshe Eliasof, Zeljko Kereta, Carola-Bibiane Schönlieb",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08538v1",
    "source": "arXiv",
    "abstract": "Flow-based generative models have emerged as powerful priors for solving inverse problems. One option is to directly optimize the initial latent code (noise), such that the flow output solves the inverse problem. However, this requires backpropagating through the entire generative trajectory, incurring high memory costs and numerical instability. We propose MS-Flow, which represents the trajectory as a sequence of intermediate latent states rather than a single initial code. By enforcing the flow dynamics locally and coupling segments through trajectory-matching penalties, MS-Flow alternates between updating intermediate latent states and enforcing consistency with observed data. This reduces memory consumption while improving reconstruction quality. We demonstrate the effectiveness of MS-Flow over existing methods on image recovery and inverse problems, including inpainting, super-resolution, and computed tomography."
  },
  {
    "date": "2026-02-09",
    "title": "UniPlan: Vision-Language Task Planning for Mobile Manipulation with Unified PDDL Formulation",
    "authors": "Haoming Ye, Yunxiao Xiao, Cewu Lu, Panpan Cai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08537v1",
    "source": "arXiv",
    "abstract": "Integration of VLM reasoning with symbolic planning has proven to be a promising approach to real-world robot task planning. Existing work like UniDomain effectively learns symbolic manipulation domains from real-world demonstrations, described in Planning Domain Definition Language (PDDL), and has successfully applied them to real-world tasks. These domains, however, are restricted to tabletop manipulation. We propose UniPlan, a vision-language task planning system for long-horizon mobile-manipulation in large-scale indoor environments, that unifies scene topology, visuals, and robot capabilities into a holistic PDDL representation. UniPlan programmatically extends learned tabletop domains from UniDomain to support navigation, door traversal, and bimanual coordination. It operates on a visual-topological map, comprising navigation landmarks anchored with scene images. Given a language instruction, UniPlan retrieves task-relevant nodes from the map and uses a VLM to ground the anchored image into task-relevant objects and their PDDL states; next, it reconnects these nodes to a compressed, densely-connected topological map, also represented in PDDL, with connectivity and costs derived from the original map; Finally, a mobile-manipulation plan is generated using off-the-shelf PDDL solvers. Evaluated on human-raised tasks in a large-scale map with real-world imagery, UniPlan significantly outperforms VLM and LLM+PDDL planning in success rate, plan quality, and computational efficiency."
  },
  {
    "date": "2026-02-09",
    "title": "Coupling between CaWO$_4$ phonons and Er$^{3+}$ dopants",
    "authors": "Mikhael T. Sayat, Federico Pisani, Hin Lok Chang, Yaroslav Zhumagulov, Kirrily C. Rule, Tom Fennell, Jakob Nunnendorf, Chee Kwan Gan, Oleg V. Yazyev, Ping Koy Lam, Jian-Rui Soh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08525v1",
    "source": "arXiv",
    "abstract": "We investigate the lattice dynamics of CaWO$_4$, a promising host crystal for erbium-based quantum memories, using inelastic neutron scattering together with density-functional perturbation theory. The measured phonon dispersion along the (100), (001), and (101) reciprocal space direction reveals phonon bands extending up to 130 meV, with a gap between 60 and 80 meV, in good agreement with our calculations. From a symmetry analysis of the phonon eigenmodes, we identify eight Raman-active modes that can couple directly to the Er$^{3+}$ crystal-field operators, including a low-energy $B_g$ mode at 9.1 meV that is expected to play a dominant role in phonon-assisted spin-lattice relaxation. These results provide a microscopic description of the phonon bath in CaWO$_4$ and establish a basis for engineering phononic environments to mitigate the loss of stored quantum states and optimize Er-doped CaWO$_4$ for quantum-memory applications."
  },
  {
    "date": "2026-02-09",
    "title": "Thermal Vacuum Cosmology Explains Hubble Tension",
    "authors": "Robert Alicki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08522v1",
    "source": "arXiv",
    "abstract": "It is argued that the previously proposed modification of the standard (flat) inflationary $ΛCDM$ model in which cosmological constant is replaced by thermal energy of expanding vacum, characterized by the Gibbons-Hawking temperature, explains the origin of notorious ``Hubble tension''."
  },
  {
    "date": "2026-02-09",
    "title": "Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering",
    "authors": "Yunhui Liu, Pengyu Qiu, Yu Xing, Yongchao Liu, Peng Du, Chuntao Hong, Jiajun Zheng, Tao Zheng, Tieke He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08519v1",
    "source": "arXiv",
    "abstract": "Attributed Graph Clustering (AGC) is a fundamental unsupervised task that integrates structural topology and node attributes to uncover latent patterns in graph-structured data. Despite its significance in industrial applications such as fraud detection and user segmentation, a significant chasm persists between academic research and real-world deployment. Current evaluation protocols suffer from the small-scale, high-homophily citation datasets, non-scalable full-batch training paradigms, and a reliance on supervised metrics that fail to reflect performance in label-scarce environments. To bridge these gaps, we present PyAGC, a comprehensive, production-ready benchmark and library designed to stress-test AGC methods across diverse scales and structural properties. We unify existing methodologies into a modular Encode-Cluster-Optimize framework and, for the first time, provide memory-efficient, mini-batch implementations for a wide array of state-of-the-art AGC algorithms. Our benchmark curates 12 diverse datasets, ranging from 2.7K to 111M nodes, specifically incorporating industrial graphs with complex tabular features and low homophily. Furthermore, we advocate for a holistic evaluation protocol that mandates unsupervised structural metrics and efficiency profiling alongside traditional supervised metrics. Battle-tested in high-stakes industrial workflows at Ant Group, this benchmark offers the community a robust, reproducible, and scalable platform to advance AGC research towards realistic deployment. The code and resources are publicly available via GitHub (https://github.com/Cloudy1225/PyAGC), PyPI (https://pypi.org/project/pyagc), and Documentation (https://pyagc.readthedocs.io)."
  },
  {
    "date": "2026-02-09",
    "title": "Compatibility complexes for the conformal-to-Einstein operator",
    "authors": "Igor Khavkine, Josef Šilhan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08510v1",
    "source": "arXiv",
    "abstract": "The conformal-to-Einstein operator is a conformally invariant linear overdetermined differential operator whose non-vanishing solutions correspond to Einstein metrics within a conformal class. We construct compatibility complexes for this operator under natural genericity assumptions on the Weyl curvature in dimension $n\\ge 4$, which implies at most one independent solution. An analogous result for the projective-to-Ricci-flat operator is obtained as well. The construction is based on a method, previously proposed by one of the authors, that leverages existing symmetries and geometric properties of the starting operator. In this case the compatibility complexes consist of, respectively, conformally and projectively invariant operators. We also make some comments on how Bernstein-Gelfand-Gelfand sequences can be interpreted as compatibility complexes in the locally flat case, which may be of general interest."
  },
  {
    "date": "2026-02-09",
    "title": "Viscous Burgers equation driven by point source: a formula for the weak limit",
    "authors": "Smritikana Pal, Manas R. Sahoo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08496v1",
    "source": "arXiv",
    "abstract": "In this article, we obtain the weak limit of the solutions of the viscous Burgers equation driven by a point source term, as the coefficient of viscosity tends to zero. The weak limit is related to the variational problem that consists of three types of functional, which is not usual in the absence of the source term."
  },
  {
    "date": "2026-02-09",
    "title": "The problem with twp linear branches",
    "authors": "Fritz Schweiger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08493v1",
    "source": "arXiv",
    "abstract": "Piecewise fractional linear maps wzth three or more branches have been studied in several papers. For many Moebius maps the shape of the density of their invariant measurs can be written down exactly. However, if just two branches are linear, no explicit form is known. In this paper a partial solution is offered."
  },
  {
    "date": "2026-02-09",
    "title": "An intramembranous ossification model for the in-silico analysis of bone tissue formation in tooth extraction sites",
    "authors": "Jennifer Paola Corredor-Gómez, Andrés Mauricio Rueda-Ramírez, Miguel Alejandro Gamboa-Márquez, Carolina Torres-Rodríguez, Carlos Julio Cortés-Rodríguez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08492v1",
    "source": "arXiv",
    "abstract": "The accurate modeling of biological processes allows to predict the spatio-temporal behavior of living tissues by computer-aided (in-silico) testing, a useful tool for the development of medical strategies, avoiding the expenses and potential ethical implications of in-vivo experimentation. A model for bone healing in mouth would be useful for selecting proper surgical techniques in dental procedures. In this paper, the formulation and implementation of a model for Intramembranous Ossification is presented aiming to describe the complex process of bone tissue formation in tooth extraction sites. The model consists in a mathematical description of the mechanisms in which different types of cells interact, synthesize and degrade extra-cellular matrices under the influence of biochemical factors. Special attention is given to angiogenesis, oxygen-dependent effects and growth factor-induced apoptosis of fibroblasts. Furthermore, considering the depth-dependent vascularization of mandibular bone and its influence on bone healing, a functional description of the cell distribution on the severed periodontal ligament (PDL) is proposed. The developed model was implemented using the finite element method (FEM) and successfully validated by simulating an animal in-vivo experiment on dogs reported in the literature. A good fit between model outcome and experimental data was obtained with a mean absolute error of 3.04%. The mathematical framework presented here may represent an important tool for the design of future in-vitro and in-vivo tests, as well as a precedent for future in-silico studies on osseointegration and mechanobiology."
  },
  {
    "date": "2026-02-09",
    "title": "Empirical Bayes Variable Selection with Lasso Statistics in the AMP Framework",
    "authors": "Lina Hidmi, Asaf Weinstein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08486v1",
    "source": "arXiv",
    "abstract": "The Lasso is one of the most ubiquitous methods for variable selection in high-dimensional linear regression and has been studied extensively under different regimes. In a particular asymptotic setup entailing $n/p\\to \\text{constant}$, an i.i.d.~Gaussian $X$ matrix and linear sparsity, \\citet{su2017false} analyzed the Lasso selection path and presented negative results, showing that maintaining small levels of the false discovery proportion comes at a substantial cost in power. Followup work by \\citet{wang2020bridge} used the same framework to study the tradeoff between type I error and power for thresholded-Lasso selection, which ranks the variables based on the magnitude of the Lasso estimate instead of the order of appearance on the Lasso path, and demonstrated that significant improvements are possible if the regularization parameter is chosen appropriately. We take this line of research a step further, seeking an {\\em optimal} selection procedure in the AMP framework among procedures that order the variables by some univariate function of the Lasso estimate at a fixed value $λ$ of the regularization term. Observing that the model for the Lasso estimates effectively reduces asymptotically to a version of the well-studied two-groups model, we propose an empirical Bayes variable selection procedure based on an estimate of the local false discovery rate. We extend existing results in the AMP framework to obtain exact predictions for the curve describing the asymptotic tradeoff between type I error and power of this procedure. Additionally, we prove that the optimal $λ$ is the minimizer of the asymptotic mean squared error, and accordingly propose to use the empirical Bayes procedure with $λ$ estimated by cross-validation. The theoretical predictions imply that the gains in power can be substantial, and we confirm this by numerical studies under different settings."
  },
  {
    "date": "2026-02-09",
    "title": "CLEAR: A Knowledge-Centric Vessel Trajectory Analysis Platform",
    "authors": "Hengyu Liu, Tianyi Li, Haoyu Wang, Kristian Torp, Yushuai Li, Tiancheng Zhang, Torben Bach Pedersen, Christian S. Jensen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08482v1",
    "source": "arXiv",
    "abstract": "Vessel trajectory data from the Automatic Identification System (AIS) is used widely in maritime analytics. Yet, analysis is difficult for non-expert users due to the incompleteness and complexity of AIS data. We present CLEAR, a knowledge-centric vessel trajectory analysis platform that aims to overcome these barriers. By leveraging the reasoning and generative capabilities of Large Language Models (LLMs), CLEAR transforms raw AIS data into complete, interpretable, and easily explorable vessel trajectories through a Structured Data-derived Knowledge Graph (SD-KG). As part of the demo, participants can configure parameters to automatically download and process AIS data, observe how trajectories are completed and annotated, inspect both raw and imputed segments together with their SD-KG evidence, and interactively explore the SD-KG through a dedicated graph viewer, gaining an intuitive and transparent understanding of vessel movements."
  },
  {
    "date": "2026-02-09",
    "title": "Boltzmann sampling and optimal exact-size sampling for directed acyclic graphs",
    "authors": "Wojciech Gabryelski, Zbigniew Gołȩbiewski, Martin Pépin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08471v1",
    "source": "arXiv",
    "abstract": "We propose two efficient algorithms for generating uniform random directed acyclic graphs, including an asymptotically optimal exact-size sampler that performs $\\frac{n^2}{2} + o(n^2)$ operations and requests to a random generator. This was achieved by extending the Boltzmann model for graphical generating functions and by using various decompositions of directed acyclic graphs. The presented samplers improve upon the state-of-the-art algorithms in terms of theoretical complexity and offer a significant speed-up in practice."
  },
  {
    "date": "2026-02-09",
    "title": "TriC-Motion: Tri-Domain Causal Modeling Grounded Text-to-Motion Generation",
    "authors": "Yiyang Cao, Yunze Deng, Ziyu Lin, Bin Feng, Xinggang Wang, Wenyu Liu, Dandan Zheng, Jingdong Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08462v1",
    "source": "arXiv",
    "abstract": "Text-to-motion generation, a rapidly evolving field in computer vision, aims to produce realistic and text-aligned motion sequences. Current methods primarily focus on spatial-temporal modeling or independent frequency domain analysis, lacking a unified framework for joint optimization across spatial, temporal, and frequency domains. This limitation hinders the model's ability to leverage information from all domains simultaneously, leading to suboptimal generation quality. Additionally, in motion generation frameworks, motion-irrelevant cues caused by noise are often entangled with features that contribute positively to generation, thereby leading to motion distortion. To address these issues, we propose Tri-Domain Causal Text-to-Motion Generation (TriC-Motion), a novel diffusion-based framework integrating spatial-temporal-frequency-domain modeling with causal intervention. TriC-Motion includes three core modeling modules for domain-specific modeling, namely Temporal Motion Encoding, Spatial Topology Modeling, and Hybrid Frequency Analysis. After comprehensive modeling, a Score-guided Tri-domain Fusion module integrates valuable information from the triple domains, simultaneously ensuring temporal consistency, spatial topology, motion trends, and dynamics. Moreover, the Causality-based Counterfactual Motion Disentangler is meticulously designed to expose motion-irrelevant cues to eliminate noise, disentangling the real modeling contributions of each domain for superior generation. Extensive experimental results validate that TriC-Motion achieves superior performance compared to state-of-the-art methods, attaining an outstanding R@1 of 0.612 on the HumanML3D dataset. These results demonstrate its capability to generate high-fidelity, coherent, diverse, and text-aligned motion sequences. Code is available at: https://caoyiyang1105.github.io/TriC-Motion/."
  },
  {
    "date": "2026-02-09",
    "title": "Selberg and Brolin on value distribution of complex dynamics",
    "authors": "Yûsuke Okuyama",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08454v1",
    "source": "arXiv",
    "abstract": "The Brolin-Lyubich-Freire--Lopes--Mañé equidistribution theorem for iterated preimages of a given non-exceptional value and Lyubich's periodic point version of it are foundational in the study of dynamics of rational functions of degree more than one on the complex projective line, and Drasin and the author studied a quantification of the former in a formalism of Nevanlinna theory or more specifically with the aid of Selberg's theorem. In this paper, we point out that the argument in that previous study have already yielded a better quantification of the Brolin-Lyubich-Freire--Lopes--Mañé equidistribution theorem, and also point out that a similar argument also yields a quantification of Lyubich's theorem under an exponentwise version of the so called hypothesis H."
  },
  {
    "date": "2026-02-09",
    "title": "Neutrinoless double beta decays of hyperons in covariant chiral perturbation theory",
    "authors": "Zi-Ying Zhao, Ze-Rui Liang, Feng-Kun Guo, Li-Ping He, De-Liang Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08453v1",
    "source": "arXiv",
    "abstract": "Neutrinoless double beta ($0νββ$) decays of spin-1/2 hyperons are investigated in a covariant baryon chiral perturbation theory framework, extended by a $ΔL=2$ operator proportional to the Majorana neutrino mass, where $L$ denotes the lepton number. Within the light Majorana neutrino exchange mechanism, the decay amplitudes are found to emerge at the one-loop level, representing the long-range contribution. The extended-on-mass-shell scheme is employed to renormalize the one-loop amplitudes and restore consistent chiral power counting. Consequently, the differential decay rates for all accessible hyperon $0νββ$ channels are predicted and the corresponding branching ratios are more than 20 orders of magnitude smaller than the current experimental upper bounds. Interestingly, it is found that the leading contribution to hyperon $0νββ$ decay is actually from short-range counterterm operators, as required by the renormalization argument. Neutrinoless transition form factors are proposed to determine this leading contribution through future lattice QCD simulations."
  },
  {
    "date": "2026-02-09",
    "title": "Ozonation of Dielectric Fosters Self-Healing Efficiency in Metalized-Film Capacitors: Quantum-Chemical Simulation",
    "authors": "Nadezhda A. Andreeva, Cuixia Liu, Vitaly V. Chaban",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08451v1",
    "source": "arXiv",
    "abstract": "Metalized-film capacitors (MFCs) employ polymer organic dielectrics like polypropylene (PP) and polyimide (PI), in which self-healing is seen as a key advantage. However, the performance of self-healing depends on specific chemical mechanisms involved. The formation of semiconductive carbonaceous soot represents a critical failure risk. This study investigates how oxygen atom impregnation through ozonation of the dielectric material tunes the composition and electrical conductivity of breakdown products in the PP and PI systems with aluminum-zinc electrodes. We revealed, at the atomistic level, that oxygen atoms tend to remove a fraction of carbon atoms from the semiconductive soot by oxidizing carbon into carbon monoxide in both polymers. In PP, oxygen fraction linearly increases gas mass fraction, thereby reducing soot fraction. In PI, the gas/soot ratio effect of oxygen content is less drastic, still clearly positive. The PP soot conductivity decreases uniformly as larger fractions of oxygen atoms are added. In turn, the PI conductivity drops to ~1500 S/m quickly. The PI soot exhibits narrower band gaps compared to that of PP. The oxygen fraction non-monotonically tailors band gaps, which generally increase. To summarize, ozonation enhances MFC reliability by increasing gas species fraction and reducing soot conductivity. We hereby provide numerical molecular-level insights to rationalize self-healing performance enhancement through polymer ozonation."
  },
  {
    "date": "2026-02-09",
    "title": "Dynamically entangled oscillating state in a Bose gas with an attractive polaron",
    "authors": "Saptarshi Majumdar, Aleksandra Petković",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08443v1",
    "source": "arXiv",
    "abstract": "We study the out-of-equilibrium dynamics of an attractively interacting impurity suddenly immersed with a nonzero initial velocity into a system of one-dimensional weakly interacting homogeneous bosons. We uncover and characterize different dynamical regimes in the parameter space. Especially interesting is the relaxation of a fast impurity with a mass close to or exceeding the critical one, where the impurity exhibits undamped temporal long-lived velocity oscillations before reaching a stationary state. The underlying mechanism is the transient localization of a boson depletion cloud near the impurity, that oscillates around the boson density peak situated at the impurity position. The lifetime of this entangled oscillating state increases with the absolute value of the impurity-boson coupling. Cold atomic gases provide an ideal playground where this phenomenon can be probed."
  },
  {
    "date": "2026-02-09",
    "title": "SteerVLA: Steering Vision-Language-Action Models in Long-Tail Driving Scenarios",
    "authors": "Tian Gao, Celine Tan, Catherine Glossop, Timothy Gao, Jiankai Sun, Kyle Stachowicz, Shirley Wu, Oier Mees, Dorsa Sadigh, Sergey Levine, Chelsea Finn",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08440v1",
    "source": "arXiv",
    "abstract": "A fundamental challenge in autonomous driving is the integration of high-level, semantic reasoning for long-tail events with low-level, reactive control for robust driving. While large vision-language models (VLMs) trained on web-scale data offer powerful common-sense reasoning, they lack the grounded experience necessary for safe vehicle control. We posit that an effective autonomous agent should leverage the world knowledge of VLMs to guide a steerable driving policy toward robust control in driving scenarios. To this end, we propose SteerVLA, which leverages the reasoning capabilities of VLMs to produce fine-grained language instructions that steer a vision-language-action (VLA) driving policy. Key to our method is this rich language interface between the high-level VLM and low-level VLA, which allows the high-level policy to more effectively ground its reasoning in the control outputs of the low-level policy. To provide fine-grained language supervision aligned with vehicle control, we leverage a VLM to augment existing driving data with detailed language annotations, which we find to be essential for effective reasoning and steerability. We evaluate SteerVLA on a challenging closed-loop benchmark, where it outperforms state-of-the-art methods by 4.77 points in overall driving score and by 8.04 points on a long-tail subset. The project website is available at: https://steervla.github.io/."
  },
  {
    "date": "2026-02-09",
    "title": "Exact Stationary State of a $d$-dimensional Run-and-Tumble Particle in a Harmonic Potential",
    "authors": "Mathis Guéneau, Satya N. Majumdar, Grégory Schehr",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08436v1",
    "source": "arXiv",
    "abstract": "We derive the exact nonequilibrium steady state of a run-and-tumble particle (RTP) in $d$ dimensions confined in an isotropic harmonic trap $V(\\mathbf r)=μr^{2}/2$, with $r=\\|\\mathbf r\\|$. Rotational invariance reduces the problem to the stationary single-coordinate marginal $p_X(x)$, from which the radial distribution $p_R(r)$ and the full joint stationary density follow by explicit integral transforms. We first focus on a generalized trapped RTP in one dimension, where post-tumble velocities are drawn from an arbitrary distribution $W(v)$. Using a Kesten-type recursion, we represent its stationary position in terms of a stick-breaking (or Dirichlet) process, yielding closed-form expressions for its distribution and its moments. Specializing $W(v)$ to the projected velocity law of an isotropic RTP, we reconstruct $p_R(r)$ and the full joint distribution of all the coordinates in $d=1,2,3$. In $d=1$ and $d=2$, the radial law simplifies to a beta distribution, while in $d=3$, we derive closed-form expressions for $p_R(r)$ and the stationary joint distribution $P(x,y,z)$, which differ from a beta distribution. In all cases, we characterize a persistence-controlled shape transition at the turning surface $r=v_0/μ$, where $v_0$ is the self-propulsion speed. We further include thermal noise characterized by a diffusion coefficient $D>0$, showing that the stationary law is a Gaussian convolution of the $D=0$ result, which regularizes turning-point singularities and controls the crossover between persistence- and diffusion-dominated regimes as $D \\to 0$ and $D \\to \\infty$ respectively. All analytical predictions are systematically validated against numerical simulations."
  },
  {
    "date": "2026-02-09",
    "title": "NovaMoon: A Strategic Lunar Reference Station for Positioning, Timing, and Largely Enhanced Science in the Earth-Moon System Serena",
    "authors": "Serena Molli, Agnès Fienga, Pascale Defraigne, Krzysztof Sośnica, Luigi Cacciapuoti, Luca Porcelli, Lotfi Massarweh, Sara Bruni, Riccardo Pozzobon, Albert Roura, Francesco Vespe, Diego Blas, Ozgur Karatekin, Yoann Audet, Floor Melman, Richard Swinden, Javier Ventura-Traveset, Olivier Alibart, Marie-Christine Angonin, Daniel Arnold, Ruth Bamford, Emmanuele Battista, Marco Belloni, J. C. Berton, Orfeu Bertolami, Mathis Bloßfeld, Adrien Bourgoin, Giada Bargiacchi, Salvatore Buoninfante, Nicolò Burzillà, Roberto Campagnola, Paolo Cappuccio, Salvatore Capozziello, Giuseppe Cimò, Clément Courde, Rolf Dach, Mario Siciliani de Cumis, Simone Dell'Agnello, Fabrizio De Marchi, Valentina Galluzzi, Francesco Gini, Philipp Glaeser, Klaus Gwinner, Alex Guinard, Rüdiger Haas, Aurélien Hees, Hauke Hussmann, Luciano Iess, Alexander C. Jenkins, Siddarth K. Joshi, Maria Karbon, Sergei Klioner, Kaisa Laiho, Christophe Le Poncin-Lafitte, Marco Lucente, David Lucchesi, Riccardo March, Lucia McCallum, Jürgen Müller, Weijie Nie, Jillian Oduber, Roberto Peron, Francesco Picciariello, Théo Pichavant, Michael Plumaris, Eleonora Polini, Ana-Catalina Plesa, Dimitrios Psychas, Bernardino Quaranta, Nicolas Rambaux, Marc Rovira-Navarro, Francesco Santoli, Matthias Schartner, Florian Seitz, Ilaria Sesia, Yan Seyffert, Stefano Speretta, Tim Springer, Giuseppe Vallone, Paolo Villoresi, Sebastien Vincent-Bonnieu, Ben Wadsworth, Pierre Waller, Radosław Zajdel, Erik Schoenemann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08432v1",
    "source": "arXiv",
    "abstract": "The renewed interest in lunar exploration and the development of future lunar communication and navigation services highlight the need for a precise, stable, and interoperable geodetic and timing infrastructure on the Moon. NovaMoon, proposed as a scientific and navigation payload for ESA's Argonaut lander, is designed as a lunar-based local differential, geodetic, and timing station supporting both operational needs in the Moon's south polar region and a broad range of scientific investigations. The payload integrates a lunar laser retroreflector, a Very Long Baseline Interferometry transmitter, a receiver for navigation signals compatible with LunaNet standards, high-stability atomic clocks, and direct-to-Earth radio links -- making it the first lunar station to co-locate multiple ranging, tracking, and timing techniques. NovaMoon will enable sub-metre to decimetre positioning, provide local differential corrections for lunar users, and ensure an accurate and stable realisation of position and time. Preliminary simulation studies show that this multi-technique dataset improves the lunar reference frame, orientation and ephemerides, and estimates of interior parameters like tidal response and core properties. NovaMoon will also provide the first long-duration physical realisation of a lunar time reference. Beyond its primary goals, it supports improved cartography, precise surface geolocation, and higher-resolution topography, contributing to safer landings and operations. It also enables new tests of fundamental physics, including constraints on relativity and possible deviations from classical gravity."
  },
  {
    "date": "2026-02-09",
    "title": "USBD: Universal Structural Basis Distillation for Source-Free Graph Domain Adaptation",
    "authors": "Yingxu Wang, Kunyu Zhang, Mengzhu Wang, Siyang Gao, Nan Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08431v1",
    "source": "arXiv",
    "abstract": "SF-GDA is pivotal for privacy-preserving knowledge transfer across graph datasets. Although recent works incorporate structural information, they implicitly condition adaptation on the smoothness priors of sourcetrained GNNs, thereby limiting their generalization to structurally distinct targets. This dependency becomes a critical bottleneck under significant topological shifts, where the source model misinterprets distinct topological patterns unseen in the source domain as noise, rendering pseudo-label-based adaptation unreliable. To overcome this limitation, we propose the Universal Structural Basis Distillation, a framework that shifts the paradigm from adapting a biased model to learning a universal structural basis for SF-GDA. Instead of adapting a biased source model to a specific target, our core idea is to construct a structure-agnostic basis that proactively covers the full spectrum of potential topological patterns. Specifically, USBD employs a bi-level optimization framework to distill the source dataset into a compact structural basis. By enforcing the prototypes to span the full Dirichlet energy spectrum, the learned basis explicitly captures diverse topological motifs, ranging from low-frequency clusters to high-frequency chains, beyond those present in the source. This ensures that the learned basis creates a comprehensive structural covering capable of handling targets with disparate structures. For inference, we introduce a spectral-aware ensemble mechanism that dynamically activates the optimal prototype combination based on the spectral fingerprint of the target graph. Extensive experiments on benchmarks demonstrate that USBD significantly outperforms state-of-the-art methods, particularly in scenarios with severe structural shifts, while achieving superior computational efficiency by decoupling the adaptation cost from the target data scale."
  },
  {
    "date": "2026-02-09",
    "title": "On- and off-chain demand and supply drivers of Bitcoin price",
    "authors": "Pavel Ciaian, d'Artis Kancs, Miroslava Rajcaniova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08429v1",
    "source": "arXiv",
    "abstract": "Around three quarters of Bitcoin transactions take place off-chain. Despite their significance, the vast majority of the empirical literature on cryptocurrencies focuses on on-chain transactions. This paper presents one of the first analysis of both on- and off-chain demand- and supply-side factors. Two hypotheses relating on-chain and off-chain demand and supply drivers to the Bitcoin price are tested in an ARDL model with daily data from 2019 to 2024. Our estimates document the differential contributions of on-chain and off-chain drivers on the Bitcoin price. Off-chain demand pressures have a significant impact on the Bitcoin price in the long-run. In the short-run, both demand and supply drivers significantly affect the Bitcoin price. Regarding transactions on the blockchain, only on-chain demand pressures are statistically significant - both in the long- and short-run. These findings confirm the dual nature of the Bitcoin price dynamics, where also market fundamentals affect the Bitcoin price in addition to speculative drivers. Bitcoin whale trading has less significant impact on price in the long-run, while is more pronounced contemporaneously and one-period lag."
  },
  {
    "date": "2026-02-09",
    "title": "Radial Müntz-Szász Networks: Neural Architectures with Learnable Power Bases for Multidimensional Singularities",
    "authors": "Gnankan Landry Regis N'guessan, Bum Jun Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08419v1",
    "source": "arXiv",
    "abstract": "Radial singular fields, such as $1/r$, $\\log r$, and crack-tip profiles, are difficult to model for coordinate-separable neural architectures. We show that any $C^2$ function that is both radial and additively separable must be quadratic, establishing a fundamental obstruction for coordinate-wise power-law models. Motivated by this result, we introduce Radial Müntz-Szász Networks (RMN), which represent fields as linear combinations of learnable radial powers $r^μ$, including negative exponents, together with a limit-stable log-primitive for exact $\\log r$ behavior. RMN admits closed-form spatial gradients and Laplacians, enabling physics-informed learning on punctured domains. Across ten 2D and 3D benchmarks, RMN achieves 1.5$\\times$--51$\\times$ lower RMSE than MLPs and 10$\\times$--100$\\times$ lower RMSE than SIREN while using 27 parameters, compared with 33,537 for MLPs and 8,577 for SIREN. We extend RMN to angular dependence (RMN-Angular) and to multiple sources with learnable centers (RMN-MC); when optimization converges, source-center recovery errors fall below $10^{-4}$. We also report controlled failures on smooth, strongly non-radial targets to delineate RMN's operating regime."
  },
  {
    "date": "2026-02-09",
    "title": "A Bayesian regression framework for circular models with INLA",
    "authors": "Xiang Ye, Janet Van Niekerk, Haavard Rue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08413v1",
    "source": "arXiv",
    "abstract": "Regression models for circular variables are less developed, since the concept of building a linear predictor from linear combinations of covariates and various random effects, breaks the circular nature of the variable. In this paper, we introduce a new approach to rectify this issue, leading to well-defined regression models for circular responses when the data are concentrated. Our approach extends naturally to joint regression models where we can have several circular and non-circular responses, and allow us to handle a mix of linear covariates, circular covariates and various random effects. Our formulation aligns naturally with the integrated nested Laplace approximation (INLA), which provides fast and accurate Bayesian inference. We illustrate our approach through several simulated and real examples."
  },
  {
    "date": "2026-02-09",
    "title": "Movable Antenna Enabled Reconfigurable Array Topologies for Structured Beam Communications",
    "authors": "Hongyun Jin, Wenchi Cheng, Jingqing Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08409v1",
    "source": "arXiv",
    "abstract": "Spatially structured beams have emerged as a promising technology for enhancing spectrum efficiency (SE) in sixth-generation (6G) networks. However, structured beam schemes based on fixed-position antennas (FPAs) fail to fully exploit the array aperture, thereby limiting their topological reconfigurability and adaptability to diverse communication scenarios. To overcome these limitations, this paper proposes a novel structured beam communication framework exploiting movable antennas (MAs) to achieve reconfigurable array topologies. Specifically, we develop an MA-based geometric modeling framework to construct a variety of practical array topologies, thereby enabling the realization of diverse array configurations utilizing a unified hardware platform. Furthermore, we investigate the joint design of the array topology and the structured beamforming vector to efficiently exploit the array aperture and facilitate the multiplexing of orthogonal spatial modes. Accordingly, we formulate the corresponding beam generation and demodulation schemes and derive the channel gains under varying array topologies. We also propose an alternating optimization algorithm to jointly optimize the array topology configuration, the antenna element positions, and the structured beamforming vector, with the aim of maximizing the system SE. Numerical results demonstrate that the proposed joint design significantly enhances the SE compared to conventional FPA schemes. By synergizing the spatial multiplexing degrees of freedom (DoFs) of structured beams with the mobility DoFs of MAs within 2D planar regions, this work establishes a reconfigurable and practical framework for structured beam-based wireless communications."
  },
  {
    "date": "2026-02-09",
    "title": "Optimizing Spectral Prediction in MXene-Based Metasurfaces Through Multi-Channel Spectral Refinement and Savitzky-Golay Smoothing",
    "authors": "Shujaat Khan, Waleed Iqbal Waseer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08406v1",
    "source": "arXiv",
    "abstract": "The prediction of electromagnetic spectra for MXene-based solar absorbers is a computationally intensive task, traditionally addressed using full-wave solvers. This study introduces an efficient deep learning framework incorporating transfer learning, multi-channel spectral refinement (MCSR), and Savitzky-Golay smoothing to accelerate and enhance spectral prediction accuracy. The proposed architecture leverages a pretrained MobileNetV2 model, fine-tuned to predict 102-point absorption spectra from $64\\times64$ metasurface designs. Additionally, the MCSR module processes the feature map through multi-channel convolutions, enhancing feature extraction, while Savitzky-Golay smoothing mitigates high-frequency noise. Experimental evaluations demonstrate that the proposed model significantly outperforms baseline Convolutional Neural Network (CNN) and deformable CNN models, achieving an average root mean squared error (RMSE) of 0.0245, coefficient of determination \\( R^2 \\) of 0.9578, and peak signal-to-noise ratio (PSNR) of 32.98 dB. The proposed framework presents a scalable and computationally efficient alternative to conventional solvers, positioning it as a viable candidate for rapid spectral prediction in nanophotonic design workflows."
  },
  {
    "date": "2026-02-09",
    "title": "Intelligent support for Human Oversight: Integrating Reinforcement Learning with Gaze Simulation to Personalize Highlighting",
    "authors": "Thorsten Klößner, João Belo, Zekun Wu, Jörg Hoffmann, Anna Maria Feit",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08403v1",
    "source": "arXiv",
    "abstract": "Interfaces for human oversight must effectively support users' situation awareness under time-critical conditions. We explore reinforcement learning (RL)-based UI adaptation to personalize alerting strategies that balance the benefits of highlighting critical events against the cognitive costs of interruptions. To enable learning without real-world deployment, we integrate models of users' gaze behavior to simulate attentional dynamics during monitoring. Using a delivery-drone oversight scenario, we present initial results suggesting that RL-based highlighting can outperform static, rule-based approaches and discuss challenges of intelligent oversight support."
  },
  {
    "date": "2026-02-09",
    "title": "On Protecting Agentic Systems' Intellectual Property via Watermarking",
    "authors": "Liwen Wang, Zongjie Li, Yuchong Xie, Shuai Wang, Dongdong She, Wei Wang, Juergen Rahmel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08401v1",
    "source": "arXiv",
    "abstract": "The evolution of Large Language Models (LLMs) into agentic systems that perform autonomous reasoning and tool use has created significant intellectual property (IP) value. We demonstrate that these systems are highly vulnerable to imitation attacks, where adversaries steal proprietary capabilities by training imitation models on victim outputs. Crucially, existing LLM watermarking techniques fail in this domain because real-world agentic systems often operate as grey boxes, concealing the internal reasoning traces required for verification. This paper presents AGENTWM, the first watermarking framework designed specifically for agentic models. AGENTWM exploits the semantic equivalence of action sequences, injecting watermarks by subtly biasing the distribution of functionally identical tool execution paths. This mechanism allows AGENTWM to embed verifiable signals directly into the visible action trajectory while remaining indistinguishable to users. We develop an automated pipeline to generate robust watermark schemes and a rigorous statistical hypothesis testing procedure for verification. Extensive evaluations across three complex domains demonstrate that AGENTWM achieves high detection accuracy with negligible impact on agent performance. Our results confirm that AGENTWM effectively protects agentic IP against adaptive adversaries, who cannot remove the watermarks without severely degrading the stolen model's utility."
  },
  {
    "date": "2026-02-09",
    "title": "SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains",
    "authors": "Longkun Li, Yuanben Zou, Jinghan Wu, Yuqing Wen, Jing Li, Hangwei Qian, Ivor Tsang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08400v1",
    "source": "arXiv",
    "abstract": "Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without global graph visibility or exhaustive querying. To address this challenge, we introduce \\textbf{SCOUT-RAG} (\\textit{\\underline{S}calable and \\underline{CO}st-efficient \\underline{U}nifying \\underline{T}raversal}), a distributed agentic Graph-RAG framework that performs progressive cross-domain retrieval guided by incremental utility goals. SCOUT-RAG employs four cooperative agents that: (i) estimate domain relevance, (ii) decide when to expand retrieval to additional domains, (iii) adapt traversal depth to avoid unnecessary graph exploration, and (iv) synthesize the high-quality answers. The framework is designed to minimize retrieval regret, defined as missing useful domain information, while controlling latency and API cost. Across multi-domain knowledge settings, SCOUT-RAG achieves performance comparable to centralized baselines, including DRIFT and exhaustive domain traversal, while substantially reducing cross-domain calls, total tokens processed, and latency."
  },
  {
    "date": "2026-02-09",
    "title": "$C^{1,α}$-regularity for Mixed Local and Nonlocal Degenerate Elliptic Equations in the Heisenberg Group",
    "authors": "Junli Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08398v1",
    "source": "arXiv",
    "abstract": "The regularity theory for equations combining both local and nonlocal operators in sub-Riemannian geometries is a huge challenge. In this paper, we investigate the $C^{1,α}$-regularity of weak solutions to mixed local and nonlocal degenerate elliptic equations on the Heisenberg group. We first derive a sophisticated iteration scheme of Morrey-type by leveraging horizontal difference quotient combined with the Nirenberg difference quotient and fractional Sobolev-type inequality on the Heisenberg group. Then, the Hölder continuity of the weak solutions is established by applying the local boundedness, the iteration scheme of Morrey-type, an iterative method and the Morrey inequality. Finally, we use the Hölder continuity in conjunction with Theorem 1.2 from Mukherjee and Zhong[18] to prove the $C^{1,α}$-regularity of weak solutions."
  },
  {
    "date": "2026-02-09",
    "title": "D$^2$-VR: Degradation-Robust and Distilled Video Restoration with Synergistic Optimization Strategy",
    "authors": "Jianfeng Liang, Shaocheng Shen, Botao Xu, Qiang Hu, Xiaoyun Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08395v1",
    "source": "arXiv",
    "abstract": "The integration of diffusion priors with temporal alignment has emerged as a transformative paradigm for video restoration, delivering fantastic perceptual quality, yet the practical deployment of such frameworks is severely constrained by prohibitive inference latency and temporal instability when confronted with complex real-world degradations. To address these limitations, we propose \\textbf{D$^2$-VR}, a single-image diffusion-based video-restoration framework with low-step inference. To obtain precise temporal guidance under severe degradation, we first design a Degradation-Robust Flow Alignment (DRFA) module that leverages confidence-aware attention to filter unreliable motion cues. We then incorporate an adversarial distillation paradigm to compress the diffusion sampling trajectory into a rapid few-step regime. Finally, a synergistic optimization strategy is devised to harmonize perceptual quality with rigorous temporal consistency. Extensive experiments demonstrate that D$^2$-VR achieves state-of-the-art performance while accelerating the sampling process by \\textbf{12$\\times$}"
  },
  {
    "date": "2026-02-09",
    "title": "Altruism and Fair Objective in Mixed-Motive Markov games",
    "authors": "Yao-hua Franck Xu, Tayeb Lemlouma, Arnaud Braud, Jean-Marie Bonnin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08389v1",
    "source": "arXiv",
    "abstract": "Cooperation is fundamental for society's viability, as it enables the emergence of structure within heterogeneous groups that seek collective well-being. However, individuals are inclined to defect in order to benefit from the group's cooperation without contributing the associated costs, thus leading to unfair situations. In game theory, social dilemmas entail this dichotomy between individual interest and collective outcome. The most dominant approach to multi-agent cooperation is the utilitarian welfare which can produce efficient highly inequitable outcomes. This paper proposes a novel framework to foster fairer cooperation by replacing the standard utilitarian objective with Proportional Fairness. We introduce a fair altruistic utility for each agent, defined on the individual log-payoff space and derive the analytical conditions required to ensure cooperation in classic social dilemmas. We then extend this framework to sequential settings by defining a Fair Markov Game and deriving novel fair Actor-Critic algorithms to learn fair policies. Finally, we evaluate our method in various social dilemma environments."
  },
  {
    "date": "2026-02-09",
    "title": "Cross-Modal Bottleneck Fusion For Noise Robust Audio-Visual Speech Recognition",
    "authors": "Seaone Ok, Min Jun Choi, Eungbeom Kim, Seungu Han, Kyogu Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08293v1",
    "source": "arXiv",
    "abstract": "Audio-Visual Speech Recognition (AVSR) leverages both acoustic and visual cues to improve speech recognition under noisy conditions. A central question is how to design a fusion mechanism that allows the model to effectively exploit visual information when the audio signal is degraded, while maintaining strong performance on clean speech. We propose CoBRA (Cross-modal Bottleneck for Robust AVSR), a bottleneck-based fusion framework that introduces a compact set of learnable tokens to mediate cross-modal exchange. By regulating information flow through these tokens, the audio stream can reliably access essential visual cues even under adverse or out-of-domain noise. Despite limited training data, our model surpasses comparable baselines and remains competitive with large-scale systems through noise-adaptive fusion, demonstrating both efficiency and robustness. Ablation studies highlight that the depth of fusion is the most critical factor, underscoring its importance in designing robust AVSR systems."
  },
  {
    "date": "2026-02-09",
    "title": "Probing $α$ clustering in $^{12}\\mathrm{C}$ at CSR energies using the Jet AA Microscopic Transport Model",
    "authors": "Subhash Singha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08288v1",
    "source": "arXiv",
    "abstract": "We investigate the sensitivity of low-energy nuclear collisions to intrinsic nuclear structure by studying the interplay between initial-state geometry and final-state observables in C+C and C+Pb collisions at $\\sqrt{s_{NN}}=2.36$~GeV, relevant for experiments at the Cooling Storage Ring (CSR) facility in Lanzhou and forthcoming experiments at the High Intensity heavy-ion Accelerator Facility (HIAF) in Huizhou. Calculations are performed within the Jet AA Microscopic Transport Model (JAM) using Woods--Saxon and triangular $α$-clustered configurations for the $^{12}C$ nucleus. The initial geometry is characterized in terms of transverse size, compactness, eccentricities, and their event-by-event fluctuations. We find that $α$ clustering leads to a more compact participant configuration than the Woods--Saxon case, while transverse-size and eccentricity fluctuations show only weak sensitivity to clustering. At this beam energy, radial observables remain sensitive to geometric compactness, with the proton mean transverse momentum $\\langle p_T \\rangle$ enhanced for $α$-clustered configurations, whereas pions show little sensitivity. The anisotropic response is examined using flow harmonic coefficients. We find an enhancement of the mean flow magnitudes, $\\langle v_n \\rangle = \\sqrt{\\langle v_n^2\\rangle}$, for $α$-clustered configurations at large $N_{part}$, while the event-by-event fluctuation strength of individual harmonics remains small. Symmetric cumulants of the initial-state eccentricities show sensitivity to clustering, whereas the corresponding correlations among final-state flow harmonics do not exhibit a comparably strong separation. These results indicate that radial observables and correlation-based flow measurements provide complementary probes of $α$ clustering in low-energy nuclear collisions."
  },
  {
    "date": "2026-02-09",
    "title": "ReefFlex: A Generative Design Framework for Soft Robotic Grasping of Organic and Fragile objects",
    "authors": "Josh Pinskier, Sarah Baldwin, Stephen Rodan, David Howard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08285v1",
    "source": "arXiv",
    "abstract": "Climate change, invasive species and human activities are currently damaging the world's coral reefs at unprecedented rates, threatening their vast biodiversity and fisheries, and reducing coastal protection. Solving this vast challenge requires scalable coral regeneration technologies that can breed climate-resilient species and accelerate the natural regrowth processes; actions that are impeded by the absence of safe and robust tools to handle the fragile coral. We investigate ReefFlex, a generative soft finger design methodology that explores a diverse space of soft fingers to produce a set of candidates capable of safely grasping fragile and geometrically heterogeneous coral in a cluttered environment. Our key insight is encoding heterogeneous grasping into a reduced set of motion primitives, creating a simplified, tractable multi-objective optimisation problem. To evaluate the method, we design a soft robot for reef rehabilitation, which grows and manipulates coral in onshore aquaculture facilities for future reef out-planting. We demonstrate ReefFlex increases both grasp success and grasp quality (disturbance resistance, positioning accuracy) and reduces in adverse events encountered during coral manipulation compared to reference designs. ReefFlex, offers a generalisable method to design soft end-effectors for complex handling and paves a pathway towards automation in previously unachievable domains like coral handling for restoration."
  },
  {
    "date": "2026-02-09",
    "title": "Tighnari v2: Mitigating Label Noise and Distribution Shift in Multimodal Plant Distribution Prediction via Mixture of Experts and Weakly Supervised Learning",
    "authors": "Haixu Liu, Yufei Wang, Tianxiang Xu, Chuancheng Shi, Hongsheng Xing",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08282v1",
    "source": "arXiv",
    "abstract": "Large-scale, cross-species plant distribution prediction plays a crucial role in biodiversity conservation, yet modeling efforts in this area still face significant challenges due to the sparsity and bias of observational data. Presence-Absence (PA) data provide accurate and noise-free labels, but are costly to obtain and limited in quantity; Presence-Only (PO) data, by contrast, offer broad spatial coverage and rich spatiotemporal distribution, but suffer from severe label noise in negative samples. To address these real-world constraints, this paper proposes a multimodal fusion framework that fully leverages the strengths of both PA and PO data. We introduce an innovative pseudo-label aggregation strategy for PO data based on the geographic coverage of satellite imagery, enabling geographic alignment between the label space and remote sensing feature space. In terms of model architecture, we adopt Swin Transformer Base as the backbone for satellite imagery, utilize the TabM network for tabular feature extraction, retain the Temporal Swin Transformer for time-series modeling, and employ a stackable serial tri-modal cross-attention mechanism to optimize the fusion of heterogeneous modalities. Furthermore, empirical analysis reveals significant geographic distribution shifts between PA training and test samples, and models trained by directly mixing PO and PA data tend to experience performance degradation due to label noise in PO data. To address this, we draw on the mixture-of-experts paradigm: test samples are partitioned according to their spatial proximity to PA samples, and different models trained on distinct datasets are used for inference and post-processing within each partition. Experiments on the GeoLifeCLEF 2025 dataset demonstrate that our approach achieves superior predictive performance in scenarios with limited PA coverage and pronounced distribution shifts."
  },
  {
    "date": "2026-02-09",
    "title": "Pitot-Aided Attitude and Air Velocity Estimation with Almost Global Asymptotic Stability Guarantees",
    "authors": "Melone Nyoba Tchonkeu, Soulaimane Berkane, Tarek Hamel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08273v1",
    "source": "arXiv",
    "abstract": "This paper investigates the problem of attitude and air velocity estimation for fixed-wing unmanned aerial vehicles (UAVs) using IMU measurements and at least one Pitot tube measurement, with almost global asymptotic stability (AGAS) guarantees. A cascade observer architecture is developed, in which a Riccati/Kalman-type filter estimates the body-fixed frame air velocity and the vehicle's tilt using IMU data as inputs and Pitot measurements as outputs. Under mild excitation conditions, the resulting air velocity and tilt estimation error dynamics are shown to be uniformly observable. The estimated tilt is then combined with magnetometer measurements in a nonlinear observer on SO(3) to recover the full attitude. Rigorous analysis establishes AGAS of the overall cascade structure under the uniform observability (UO) condition. The effectiveness of the proposed approach is demonstrated through validation on real flight data."
  },
  {
    "date": "2026-02-09",
    "title": "Optimal Transmit Beamforming for MIMO ISAC with Unknown Target and User Locations",
    "authors": "Yizhuo Wang, Shuowen Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08255v1",
    "source": "arXiv",
    "abstract": "This paper studies a challenging scenario in a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system where the locations of the sensing target and the communication user are both unknown and random, while only their probability distribution information is known. In this case, how to fully utilize the spatial resources by designing the transmit beamforming such that both sensing and communication can achieve satisfactory performance statistically is a difficult problem, which motivates the study in this paper. Moreover, we aim to reveal if it is desirable to have similar probability distributions for the target and user locations in terms of the ISAC performance. Firstly, based on only probability distribution information, we establish communication and sensing performance metrics via deriving the expected rate or posterior Cramér-Rao bound (PCRB). Then, we formulate the transmit beamforming optimization problem to minimize the PCRB subject to the expected rate constraint, for which the optimal solution is derived. It is unveiled that the rank of the optimal transmit covariance matrix is upper bounded by the summation of MIMO communication channel matrices for all possible user locations. Furthermore, due to the need to cater to multiple target/user locations, we investigate whether dynamically employing different beamforming designs over different time slots improves the performance. It is proven that using a static beamforming strategy is sufficient for achieving the optimal performance. Numerical results validate our analysis, show that ISAC performance improves as the target/user location distributions become similar, and provide useful insights on the BS-user/-target association strategy."
  },
  {
    "date": "2026-02-09",
    "title": "SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities",
    "authors": "Arman Aghaee, Sepehr Asgarian, Jouhyun Jeon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08254v1",
    "source": "arXiv",
    "abstract": "Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System (MAS) framework designed to model obesity patients with comorbid mental disorders, including depression, anxiety, social phobia, and binge eating disorder. SynthAgent integrates clinical and medical evidence from claims data, population surveys, and patient-centered literature to construct personalized virtual patients enriched with personality traits that influence adherence, emotion regulation, and lifestyle behaviors. Through autonomous agent interactions, the system simulates disease progression, treatment response, and life management across diverse psychosocial contexts. Evaluation of more than 100 generated patients demonstrated that GPT-5 and Claude 4.5 Sonnet achieved the highest fidelity as the core engine in the proposed MAS framework, outperforming Gemini 2.5 Pro and DeepSeek-R1. SynthAgent thus provides a scalable and privacy-preserving framework for exploring patient journeys, behavioral dynamics, and decision-making processes in both medical and psychological domains."
  },
  {
    "date": "2026-02-09",
    "title": "Software Testing at the Network Layer: Automated HTTP API Quality Assessment and Security Analysis of Production Web Applications",
    "authors": "Ali Hassaan Mughal, Muhammad Bilal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08242v1",
    "source": "arXiv",
    "abstract": "Modern web applications rely heavily on client-side API calls to fetch data, render content, and communicate with backend services. However, the quality of these network interactions (redundant requests, missing cache headers, oversized payloads, and excessive third-party dependencies) is rarely tested in a systematic way. Moreover, many of these quality deficiencies carry security implications: missing cache headers enable cache poisoning, excessive third-party dependencies expand the supply-chain attack surface, and error responses risk leaking server internals. In this study, we present an automated software testing framework that captures and analyzes the complete HTTP traffic of 18 production websites spanning 11 categories (e-commerce, news, government, developer tools, travel, and more). Using automated browser instrumentation via Playwright, we record 108 HAR (HTTP Archive) files across 3 independent runs per page, then apply 8 heuristic-based anti-pattern detectors to produce a composite quality score (0-100) for each site. Our results reveal a wide quality spectrum: minimalist server-rendered sites achieve perfect scores of 100, while content-heavy commercial sites score as low as 56.8. We identify redundant API calls and missing cache headers as the two most pervasive anti-patterns, each affecting 67% of sites, while third-party overhead exceeds 20% on 72% of sites. One utility site makes 2,684 requests per page load, which is 447x more than the most minimal site. To protect site reputations, all identities are anonymized using category-based pseudonyms. We provide all analysis scripts, anonymized results, and reproducibility instructions as an open artifact. This work establishes an empirical baseline for HTTP API call quality across the modern web and offers a reproducible testing framework that researchers and practitioners can apply to their own applications."
  },
  {
    "date": "2026-02-09",
    "title": "Linearization Explains Fine-Tuning in Large Language Models",
    "authors": "Zahra Rahimi Afzal, Tara Esmaeilbeig, Mojtaba Soltanalian, Mesrob I. Ohannessian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08239v1",
    "source": "arXiv",
    "abstract": "Parameter-Efficient Fine-Tuning (PEFT) is a popular class of techniques that strive to adapt large models in a scalable and resource-efficient manner. Yet, the mechanisms underlying their training performance and generalization remain underexplored. In this paper, we provide several insights into such fine-tuning through the lens of linearization. Fine-tuned models are often implicitly encouraged to remain close to the pretrained model. By making this explicit, using an Euclidean distance inductive bias in parameter space, we show that fine-tuning dynamics become equivalent to learning with the positive-definite neural tangent kernel (NTK). We specifically analyze how close the fully linear and the linearized fine-tuning optimizations are, based on the strength of the regularization. This allows us to be pragmatic about how good a model linearization is when fine-tuning large language models (LLMs). When linearization is a good model, our findings reveal a strong correlation between the eigenvalue spectrum of the NTK and the performance of model adaptation. Motivated by this, we give spectral perturbation bounds on the NTK induced by the choice of layers selected for fine-tuning. We empirically validate our theory on Low Rank Adaptation (LoRA) on LLMs. These insights not only characterize fine-tuning but also have the potential to enhance PEFT techniques, paving the way to better informed and more nimble adaptation in LLMs."
  },
  {
    "date": "2026-02-09",
    "title": "Adaptive Matrix Online Learning through Smoothing with Guarantees for Nonsmooth Nonconvex Optimization",
    "authors": "Ruichen Jiang, Zakaria Mhammedi, Mehryar Mohri, Aryan Mokhtari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08232v1",
    "source": "arXiv",
    "abstract": "We study online linear optimization with matrix variables constrained by the operator norm, a setting where the geometry renders designing data-dependent and efficient adaptive algorithms challenging. The best-known adaptive regret bounds are achieved by Shampoo-like methods, but they require solving a costly quadratic projection subproblem. To address this, we extend the gradient-based prediction scheme to adaptive matrix online learning and cast algorithm design as constructing a family of smoothed potentials for the nuclear norm. We define a notion of admissibility for such smoothings and prove any admissible smoothing yields a regret bound matching the best-known guarantees of one-sided Shampoo. We instantiate this framework with two efficient methods that avoid quadratic projections. The first is an adaptive Follow-the-Perturbed-Leader (FTPL) method using Gaussian stochastic smoothing. The second is Follow-the-Augmented-Matrix-Leader (FAML), which uses a deterministic hyperbolic smoothing in an augmented matrix space. By analyzing the admissibility of these smoothings, we show both methods admit closed-form updates and match one-sided Shampoo's regret up to a constant factor, while significantly reducing computational cost. Lastly, using the online-to-nonconvex conversion, we derive two matrix-based optimizers, Pion (from FTPL) and Leon (from FAML). We prove convergence guarantees for these methods in nonsmooth nonconvex settings, a guarantee that the popular Muon optimizer lacks."
  },
  {
    "date": "2026-02-09",
    "title": "Some Patterns of Research in Mathematics",
    "authors": "Octavio A. Agustín-Aquino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08231v1",
    "source": "arXiv",
    "abstract": "We partially update Grossman's 2005 survey of patterns in mathematical research using a sample of 401 mathematicians from MathSciNet. The mathematical landscape has changed substantially: single-paper authors have reduced from $43$ \\% to $32$ \\%, collaboration has intensified, more mathematicians have greater breadth of research areas, and the giant component of the co-authorship network has grown denser, with median Erdős number dropping from $5$ to $4$. The data reveals the profession as markedly more collaborative, particularly among younger generations, although the tail of high productivity has also grown more extreme."
  },
  {
    "date": "2026-02-09",
    "title": "Comparing Mixture, Box, and Wasserstein Ambiguity Sets in Distributionally Robust Asset Liability Management",
    "authors": "Alireza Ghahtarani, Ahmed Saif, Alireza Ghasemi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08228v1",
    "source": "arXiv",
    "abstract": "Asset Liability Management (ALM) represents a fundamental challenge for financial institutions, particularly pension funds, which must navigate the tension between generating competitive investment returns and ensuring the solvency of long-term obligations. To address the limitations of traditional frameworks under uncertainty, this paper implements Distributionally Robust Optimization (DRO), an emergent paradigm that accounts for a broad spectrum of potential probability distributions. We propose and evaluate three distinct DRO formulations: mixture ambiguity sets with discrete scenarios, box ambiguity sets of discrete distribution functions, and Wasserstein metric ambiguity sets. Utilizing empirical data from the Canada Pension Plan (CPP), we conduct a comparative analysis of these models against traditional stochastic programming approaches. Our results demonstrate that DRO formulations, specifically those utilizing Wasserstein and box ambiguity sets, consistently outperform both mixture-based DRO and stochastic programming in terms of funding ratios and overall fund returns. These findings suggest that incorporating distributional robustness significantly enhances the resilience and performance of pension fund management strategies."
  },
  {
    "date": "2026-02-09",
    "title": "CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts",
    "authors": "Xuhua Ma, Richong Zhang, Zhijie Nie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08221v1",
    "source": "arXiv",
    "abstract": "Retrieval-Augmented Generation (RAG) often struggles with knowledge conflicts, where model-internal parametric knowledge overrides retrieved evidence, leading to unfaithful outputs. Existing approaches are often limited, relying either on superficial decoding adjustments or weight editing that necessitates ground-truth targets. Through layer-wise analysis, we attribute this failure to a parametric suppression phenomenon: specifically, in deep layers, certain FFN layers overwrite context-sensitive representations with memorized priors. To address this, we propose CoRect (Context-Aware Logit Contrast for Hidden State Rectification). By contrasting logits from contextualized and non-contextualized forward passes, CoRect identifies layers that exhibit high parametric bias without requiring ground-truth labels. It then rectifies the hidden states to preserve evidence-grounded information. Across question answering (QA) and summarization benchmarks, CoRect consistently improves faithfulness and reduces hallucinations compared to strong baselines."
  },
  {
    "date": "2026-02-09",
    "title": "Thermodynamic Isomorphism of Transformers: A Lagrangian Approach to Attention Dynamics",
    "authors": "Gunn Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08216v1",
    "source": "arXiv",
    "abstract": "Although the Transformer architecture has revolutionized artificial intelligence, its underlying mechanisms remain largely heuristic and lack a unified physical theory. In this work, we propose a first-principles framework for information dynamics, treating the attention mechanism as a physical system governed by the principle of least action rather than as an algorithmic optimization. By mapping information states to a Riemannian manifold with the Fisher information metric, we derive the intelligence Lagrangian. We show that the softmax function corresponds to the unique thermodynamic equilibrium state that minimizes the Helmholtz free energy of the information gas. In addition, we identify the query-key interaction as an electrodynamic coupling between an external field and an intrinsic dipole moment. This theory establishes the first law of information thermodynamics, unifying inference (mechanical work) and learning (chemical evolution). It also explains emergent phenomena, such as scaling laws and grokking, as phase transitions characterized by the divergence of specific heat. Finally, we discuss how rotational symmetry breaking in the attention manifold generates massless Goldstone bosons, providing a field-theoretic perspective on rotary positional embeddings (RoPE). Our work connects Statistical Physics and Deep Learning, laying the groundwork for a general theory of physics-based intelligence."
  },
  {
    "date": "2026-02-09",
    "title": "LLMs and people both learn to form conventions -- just not with each other",
    "authors": "Cameron R. Jones, Agnese Lombardi, Kyle Mahowald, Benjamin K. Bergen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08208v1",
    "source": "arXiv",
    "abstract": "Humans align to one another in conversation -- adopting shared conventions that ease communication. We test whether LLMs form the same kinds of conventions in a multimodal communication game. Both humans and LLMs display evidence of convention-formation (increasing the accuracy and consistency of their turns while decreasing their length) when communicating in same-type dyads (humans with humans, AI with AI). However, heterogenous human-AI pairs fail -- suggesting differences in communicative tendencies. In Experiment 2, we ask whether LLMs can be induced to behave more like human conversants, by prompting them to produce superficially humanlike behavior. While the length of their messages matches that of human pairs, accuracy and lexical overlap in human-LLM pairs continues to lag behind that of both human-human and AI-AI pairs. These results suggest that conversational alignment requires more than just the ability to mimic previous interactions, but also shared interpretative biases toward the meanings that are conveyed."
  },
  {
    "date": "2026-02-09",
    "title": "Complementary Roles of Distance and Growth Probes in Testing Time-Varying Dark Energy",
    "authors": "Seokcheon Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08207v1",
    "source": "arXiv",
    "abstract": "Distance measurements have long provided the primary observational constraints on the expansion history of the Universe and the properties of dark energy. However, because such observables depend on cumulative line-of-sight integrals over the Hubble rate, their sensitivity to time-dependent features of the dark energy equation of state is intrinsically limited. In this work, we examine this limitation from an information-based perspective using the eigenvalue structure of the Fisher information matrix constructed from distance, expansion rate, and growth observables. We show that distance and expansion-rate data generically produce a strongly hierarchical Fisher spectrum dominated by a single information mode, reflecting an irreducible loss of sensitivity to temporal variations in dark energy. This behavior can be traced directly to the integrated kernel structure of geometric observables. Growth measurements, by contrast, respond through differential dynamics and can introduce additional independent information directions. Using both controlled mock data and survey-like configurations representative of next-generation experiments, we find that the impact of growth information depends not only on its nominal precision but also on the structure of the data covariance. In simplified mock setups, growth measurements can partially activate a second information direction even at moderate precision. In Euclid-like configurations, however, the information remains effectively one-dimensional until growth precision reaches the percent level, below which a second mode emerges rapidly. These results clarify the complementary roles of distance and growth probes and provide a model-independent criterion for assessing the physical content of cosmological constraints on dynamical dark energy."
  },
  {
    "date": "2026-02-09",
    "title": "Geospatial-Reasoning-Driven Vocabulary-Agnostic Remote Sensing Semantic Segmentation",
    "authors": "Chufeng Zhou, Jian Wang, Xinyuan Liu, Xiaokang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08206v1",
    "source": "arXiv",
    "abstract": "Open-vocabulary semantic segmentation has emerged as a promising research direction in remote sensing, enabling the recognition of diverse land-cover types beyond pre-defined category sets. However, existing methods predominantly rely on the passive mapping of visual features and textual embeddings. This ``appearance-based\" paradigm lacks geospatial contextual awareness, leading to severe semantic ambiguity and misclassification when encountering land-cover classes with similar spectral features but distinct semantic attributes. To address this, we propose a Geospatial Reasoning Chain-of-Thought (GR-CoT) framework designed to enhance the scene understanding capabilities of Multimodal Large Language Models (MLLMs), thereby guiding open-vocabulary segmentation models toward precise mapping. The framework comprises two collaborative components: an offline knowledge distillation stream and an online instance reasoning stream. The offline stream establishes fine-grained category interpretation standards to resolve semantic conflicts between similar land-cover types. During online inference, the framework executes a sequential reasoning process involving macro-scenario anchoring, visual feature decoupling, and knowledge-driven decision synthesis. This process generates an image-adaptive vocabulary that guides downstream models to achieve pixel-level alignment with correct geographical semantics. Extensive experiments on the LoveDA and GID5 benchmarks demonstrate the superiority of our approach."
  },
  {
    "date": "2026-02-09",
    "title": "Epitaxial Growth of Anisotropic SnSe on GaAs(001) via Step-Edge Orientation Control",
    "authors": "Pooja D. Reddy, Zahra N. Heussen, Kunal Mukherjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08195v1",
    "source": "arXiv",
    "abstract": "Epitaxial growth of orthorhombic SnSe on cubic substrates is challenging due to lattice-symmetry mismatch and anisotropic bonding. Here we demonstrate that epitaxial films with sharp interfaces can be achieved for layered SnSe grown directly on on-axis and 4 degree miscut GaAs(001) substrates. The substrate miscut strongly influences the growth morphology, evolving from spirals on on-axis GaAs to a terraced structure on miscut GaAs. X-ray diffraction reveals that on-axis GaAs supports SnSe with two in-plane orientation variants, whereas the miscut substrate stabilizes a single orientation and introduces a small out-of-plane tilt. Accordingly, in-plane optical anisotropy is enhanced in the single variant film compared to the double variant, as determined by cross-polar reflectance. High-resolution TEM shows that the SnSe/GaAs interface is atomically abrupt and incoherent, characteristic of quasi-van der Waals epitaxy. We find a pronounced tendency for the zigzag edges of SnSe to align parallel to step edges on both substrates, and we show that step-skipping nucleation and layer growth on the miscut substrate leads to the additional tilt. These results establish direct SnSe/GaAs heteroepitaxy as a route to integrate anisotropic layered semiconductors with cubic platforms, and show that miscut substrates provide additional control over in-plane anisotropy."
  },
  {
    "date": "2026-02-09",
    "title": "Dreaming in Code for Curriculum Learning in Open-Ended Worlds",
    "authors": "Konstantinos Mitsides, Maxence Faldor, Antoine Cully",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08194v1",
    "source": "arXiv",
    "abstract": "Open-ended learning frames intelligence as emerging from continual interaction with an ever-expanding space of environments. While recent advances have utilized foundation models to programmatically generate diverse environments, these approaches often focus on discovering isolated behaviors rather than orchestrating sustained progression. In complex open-ended worlds, the large combinatorial space of possible challenges makes it difficult for agents to discover sequences of experiences that remain consistently learnable. To address this, we propose Dreaming in Code (DiCode), a framework in which foundation models synthesize executable environment code to scaffold learning toward increasing competence. In DiCode, \"dreaming\" takes the form of materializing code-level variations of the world. We instantiate DiCode in Craftax, a challenging open-ended benchmark characterized by rich mechanics and long-horizon progression. Empirically, DiCode enables agents to acquire long-horizon skills, achieving a $16\\%$ improvement in mean return over the strongest baseline and non-zero success on late-game combat tasks where prior methods fail. Our results suggest that code-level environment design provides a practical mechanism for curriculum control, enabling the construction of intermediate environments that bridge competence gaps in open-ended worlds. Project page and source code are available at https://konstantinosmitsides.github.io/dreaming-in-code and https://github.com/konstantinosmitsides/dreaming-in-code."
  },
  {
    "date": "2026-02-09",
    "title": "Nexus: Inferring Join Graphs from Metadata Alone via Iterative Low-Rank Matrix Completion",
    "authors": "Tianji Cong, Yuanyuan Tian, Andreas Mueller, Rathijit Sen, Yeye He, Fotis Psallidas, Shaleen Deep, H. V. Jagadish",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08186v1",
    "source": "arXiv",
    "abstract": "Automatically inferring join relationships is a critical task for effective data discovery, integration, querying and reuse. However, accurately and efficiently identifying these relationships in large and complex schemas can be challenging, especially in enterprise settings where access to data values is constrained. In this paper, we introduce the problem of join graph inference when only metadata is available. We conduct an empirical study on a large number of real-world schemas and observe that join graphs when represented as adjacency matrices exhibit two key properties: high sparsity and low-rank structure. Based on these novel observations, we formulate join graph inference as a low-rank matrix completion problem and propose Nexus, an end-to-end solution using only metadata. To further enhance accuracy, we propose a novel Expectation-Maximization algorithm that alternates between low-rank matrix completion and refining join candidate probabilities by leveraging Large Language Models. Our extensive experiments demonstrate that Nexus outperforms existing methods by a significant margin on four datasets including a real-world production dataset. Additionally, Nexus can operate in a fast mode, providing comparable results with up to 6x speedup, offering a practical and efficient solution for real-world deployments."
  },
  {
    "date": "2026-02-09",
    "title": "Highly Polarized and Long Range Dissipationless Spin Transport Due to Counterflowing Electron and Hole Edge Channels",
    "authors": "Maxen Cosset-Chéneau, Boxuan Yang, Bart J. van Wees",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08386v1",
    "source": "arXiv",
    "abstract": "The presence of edge channels in the quantum Hall regime leads to dissipationless charge transport over long distances. When graphene is interfaced with a magnetic material, the exchange interaction lifts the Landau levels spin degeneracy. This causes the presence of counterflowing edge channels with opposite spin polarization. We show theoretically that the spin-flip scattering between these edge channels enables a dissipationless spin transport with larger than 100% spin polarization of the charge current. It also allows the transport of spin over macroscopically long distances, even in the absence of an applied charge current."
  },
  {
    "date": "2026-02-09",
    "title": "Heavy quark collisional energy loss in a nonextensive quark-gluon plasma",
    "authors": "Bing-feng Jiang, Jun Chen, De-fu Hou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08379v1",
    "source": "arXiv",
    "abstract": "In this study, we derive the longitudinal and transverse gluon self-energies and the corresponding dielectric functions for a nonextensive QGP, based on nonextensive statistical mechanics and a kinetic theory framework. The nonextensive parameter $q$ enters these quantities primarily through the modification of the Debye mass. Utilizing the derived dielectric functions, we then calculate the collisional energy loss for a heavy quark using two established formalisms: the plasma physics-based Thoma-Gyulassy formula and the thermal field theory-originated Kirzhnits-Thoma formula. Our results show that for both formalisms, the collisional energy loss increases with the nonextensive parameter $q$ with this enhancement being more significant at higher incident quark momenta and suppressed for a heavier quark mass. The energy loss predicted from the Kirzhnits-Thoma formula is substantially larger than that from the Thoma-Gyulassy formula, and the nonextensive effect on the energy loss is more pronounced in the former. Furthermore, the mass suppression of the nonextensive effect on the energy loss is weaker in the Kirzhnits-Thoma approach. These calculations demonstrate that nonextensive statistics can significantly alter the energy loss in the QGP."
  },
  {
    "date": "2026-02-09",
    "title": "Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI",
    "authors": "Feiyu Wu, Xu Zheng, Yue Qu, Zhuocheng Wang, Zicheng Feng, Hui Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08373v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering repairs. We introduce the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic architecture that shifts the paradigm from passive safety gatekeeping to active collaboration. Our core contribution is a tutor-apprentice dialogue where a deterministic Logic Tutor, grounded in a formal safety ontology, provides causal and pedagogical feedback to an LLM planner. This enables intelligent plan repairs rather than mere avoidance. We also introduce a scalable knowledge acquisition pipeline that synthesizes safety knowledge bases from real-world documents, correcting blind spots in existing benchmarks. In challenging home safety tasks, VIRF achieves a perfect 0 percent Hazardous Action Rate (HAR) and a 77.3 percent Goal-Condition Rate (GCR), which is the highest among all baselines. It is highly efficient, requiring only 1.1 correction iterations on average. VIRF demonstrates a principled pathway toward building fundamentally trustworthy and verifiably safe embodied agents."
  },
  {
    "date": "2026-02-09",
    "title": "GKM Theory for Manifolds of Isospectral Matrices in Lie Type D",
    "authors": "Evgeny Zhukov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08366v1",
    "source": "arXiv",
    "abstract": "We study the manifold $Q_{Γ, λ}$ of isospectral real skew-symmetric matrices with a prescribed sparsity pattern determined by a graph $Γ$. The compact torus $T^n$ acts naturally on $Q_{Γ,λ}$ by conjugation, and this action can be studied using GKM theory. We prove two results about this manifold and its GKM graph. The first theorem describes how the GKM graph of $Q_{Γ, λ}$ is obtained from the GKM graph of the corresponding manifold $M_{Γ, λ}$ of isospectral Hermitian matrices. The second theorem gives a criterion for equivariant formality of $Q_{Γ, λ}$."
  },
  {
    "date": "2026-02-09",
    "title": "Intimate relationship between spin configuration in the triplet pair and superconductivity in UTe$_2$",
    "authors": "Hiroki Matsumura, Yuki Takahashi, Riku Matsubayashi, Katsuki Kinjo, Shunsaku Kitagawa, Kenji Ishida, Yo Tokunaga, Hironori Sakai, Shinsaku Kambe, Motoi Kimata, Ai Nakamura, Yusei Shimizu, Yoshiya Homma, Dexin Li, Fuminori Honda, Atsushi Miyake, Dai Aoki, Tetsuya Furukawa, Takahiro Sasaki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08358v1",
    "source": "arXiv",
    "abstract": "Spin-triplet superconductivity is an intriguing quantum coherent state with both spin and orbital degrees of freedom, which holds significant potential for future applications in quantum technology. However, how the spin of the triplet pairs responds to an external magnetic field remains poorly understood. This is mainly due to the absence of suitable spin-triplet superconductors. Here, we report results of Knight-shift and ac-susceptibility measurements on UTe$_2$. We demonstrate that the spin susceptibility, which slightly decreases compared to the normal-state value below the superconducting (SC) transition temperature $T_{\\rm c}$, is rapidly restored and nearly recovers to the normal-state values around 5 T, well below the SC upper critical field $H_{c2}$ when the magnetic field is applied along the $c$ axis ($H \\parallel c$). In addition, we found that $H_{\\rm c2}$ of superconductivity becomes larger when the SC spin aligns with the magnetic field. By considering the results on $H \\parallel b$, our results suggest the presence of a close relationship between the spin configuration of the triplet pair and $H_{\\rm c2}$, as well as the anisotropic pinning interaction acting on the triplet pairs. These phenomena, which have never been observed in spin-singlet superconductors, represent characteristic features unique to spin-triplet superconductors. We discuss the similarities between superconductivity in UTe$_2$ and superfluid $^3$He, focusing on their spin-triplet pairing states."
  },
  {
    "date": "2026-02-09",
    "title": "E-VAds: An E-commerce Short Videos Understanding Benchmark for MLLMs",
    "authors": "Xianjie Liu, Yiman Hu, Liang Wu, Ping Hu, Yixiong Zou, Jian Xu, Bo Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08355v1",
    "source": "arXiv",
    "abstract": "E-commerce short videos represent a high-revenue segment of the online video industry characterized by a goal-driven format and dense multi-modal signals. Current models often struggle with these videos because existing benchmarks focus primarily on general-purpose tasks and neglect the reasoning of commercial intent. In this work, we first propose a \\textbf{multi-modal information density assessment framework} to quantify the complexity of this domain. Our evaluation reveals that e-commerce content exhibits substantially higher density across visual, audio, and textual modalities compared to mainstream datasets, establishing a more challenging frontier for video understanding. To address this gap, we introduce \\textbf{E-commerce Video Ads Benchmark (E-VAds)}, which is the first benchmark specifically designed for e-commerce short video understanding. We curated 3,961 high-quality videos from Taobao covering a wide range of product categories and used a multi-agent system to generate 19,785 open-ended Q&A pairs. These questions are organized into two primary dimensions, namely Perception and Cognition and Reasoning, which consist of five distinct tasks. Finally, we develop \\textbf{E-VAds-R1}, an RL-based reasoning model featuring a multi-grained reward design called \\textbf{MG-GRPO}. This strategy provides smooth guidance for early exploration while creating a non-linear incentive for expert-level precision. Experimental results demonstrate that E-VAds-R1 achieves a 109.2% performance gain in commercial intent reasoning with only a few hundred training samples."
  },
  {
    "date": "2026-02-09",
    "title": "To Tango or to Disentangle? Making Ethnography Public in the Digital Age",
    "authors": "Daniel Mwesigwa, Cyan DeVeaux, Palashi Vaghela",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08349v1",
    "source": "arXiv",
    "abstract": "Ethnography attends to relations among people, practices, and the technologies that mediate them. Central to this method is the duality of roles ethnographers navigate as researchers and participants and as outsiders and insiders. However, the rise of digital platforms has introduced new opportunities as well as practical and ethical challenges that reshape these dualities across hybrid media environments spanning both online and offline contexts. Drawing on two case studies of VRChat and WhatsApp, we examine how ethnographers employ diverse tactics to study both enduring and emerging socio-cultural issues of race and caste, particularly those that form what are often called publics. We propose emergent relationality as a key analytic for understanding the mutual shaping of ethnographers, platforms, and publics. In this work, emergent relationality offers registers for analyzing how positionality and hybrid media environments constitute and condition what can be accessed, articulated, and made public."
  },
  {
    "date": "2026-02-09",
    "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration",
    "authors": "Qi Guo, Jianing Wang, Deyang Kong, Xiangyu Xi, Jianfei Zhang, Yi Lu, Jingang Wang, Wei Wang, Shikun Zhang, Wei Ye",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08344v1",
    "source": "arXiv",
    "abstract": "Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage. In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards (RLVR) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE), which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions."
  },
  {
    "date": "2026-02-09",
    "title": "Vec-QMDP: Vectorized POMDP Planning on CPUs for Real-Time Autonomous Driving",
    "authors": "Xuanjin Jin, Yanxin Dong, Bin Sun, Huan Xu, Zhihui Hao, XianPeng Lang, Panpan Cai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08334v1",
    "source": "arXiv",
    "abstract": "Planning under uncertainty for real-world robotics tasks, such as autonomous driving, requires reasoning in enormous high-dimensional belief spaces, rendering the problem computationally intensive. While parallelization offers scalability, existing hybrid CPU-GPU solvers face critical bottlenecks due to host-device synchronization latency and branch divergence on SIMT architectures, limiting their utility for real-time planning and hindering real-robot deployment. We present Vec-QMDP, a CPU-native parallel planner that aligns POMDP search with modern CPUs' SIMD architecture, achieving $227\\times$--$1073\\times$ speedup over state-of-the-art serial planners. Vec-QMDP adopts a Data-Oriented Design (DOD), refactoring scattered, pointer-based data structures into contiguous, cache-efficient memory layouts. We further introduce a hierarchical parallelism scheme: distributing sub-trees across independent CPU cores and SIMD lanes, enabling fully vectorized tree expansion and collision checking. Efficiency is maximized with the help of UCB load balancing across trees and a vectorized STR-tree for coarse-level collision checking. Evaluated on large-scale autonomous driving benchmarks, Vec-QMDP achieves state-of-the-art planning performance with millisecond-level latency, establishing CPUs as a high-performance computing platform for large-scale planning under uncertainty."
  },
  {
    "date": "2026-02-09",
    "title": "PACC: Protocol-Aware Cross-Layer Compression for Compact Network Traffic Representation",
    "authors": "Zhaochen Guo, Tianyufei Zhou, Honghao Wang, Ronghua Li, Shinan Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08331v1",
    "source": "arXiv",
    "abstract": "Network traffic classification is a core primitive for network security and management, yet it is increasingly challenged by pervasive encryption and evolving protocols. A central bottleneck is representation: hand-crafted flow statistics are efficient but often too lossy, raw-bit encodings can be accurate but are costly, and recent pre-trained embeddings provide transfer but frequently flatten the protocol stack and entangle signals across layers. We observe that real traffic contains substantial redundancy both across network layers and within each layer; existing paradigms do not explicitly identify and remove this redundancy, leading to wasted capacity, shortcut learning, and degraded generalization. To address this, we propose PACC, a redundancy-aware, layer-aware representation framework. PACC treats the protocol stack as multi-view inputs and learns compact layer-wise projections that remain faithful to each layer while explicitly factorizing representations into shared (cross-layer) and private (layer-specific) components. We operationalize these goals with a joint objective that preserves layer-specific information via reconstruction, captures shared structure via contrastive mutual-information learning, and maximizes task-relevant information via supervised losses, yielding compact latents suitable for efficient inference. Across datasets covering encrypted application classification, IoT device identification, and intrusion detection, PACC consistently outperforms feature-engineered and raw-bit baselines. On encrypted subsets, it achieves up to a 12.9% accuracy improvement over nPrint. PACC matches or surpasses strong foundation-model baselines. At the same time, it improves end-to-end efficiency by up to 3.16x."
  },
  {
    "date": "2026-02-09",
    "title": "Grokking in Linear Models for Logistic Regression",
    "authors": "Nataraj Das, Atreya Vedantam, Chandrashekar Lakshminarayanan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08302v1",
    "source": "arXiv",
    "abstract": "Grokking, the phenomenon of delayed generalization, is often attributed to the depth and compositional structure of deep neural networks. We study grokking in one of the simplest possible settings: the learning of a linear model with logistic loss for binary classification on data that are linearly (and max margin) separable about the origin. We investigate three testing regimes: (1) test data drawn from the same distribution as the training data, in which case grokking is not observed; (2) test data concentrated around the margin, in which case grokking is observed; and (3) adversarial test data generated via projected gradient descent (PGD) attacks, in which case grokking is also observed. We theoretically show that the implicit bias of gradient descent induces a three-phase learning process-population-dominated, support-vector-dominated unlearning, and support-vector-dominated generalization-during which delayed generalization can arise. Our analysis further relates the emergence of grokking to asymmetries in the data, both in the number of examples per class and in the distribution of support vectors across classes, and yields a characterization of the grokking time. We experimentally validate our theory by planting different distributions of population points and support vectors, and by analyzing accuracy curves and hyperplane dynamics. Overall, our results demonstrate that grokking does not require depth or representation learning, and can emerge even in linear models through the dynamics of the bias term."
  },
  {
    "date": "2026-02-09",
    "title": "\"I Can't Keep Up\": Accessibility Barriers in Video-Based Learning for Individuals with Borderline Intellectual Functioning",
    "authors": "Hyehyun Chu, Seungju Kim, Chen Zhou, Yu-Kai Hung, Saelyne Yang, Hyun W. Ka, Juho Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08300v1",
    "source": "arXiv",
    "abstract": "Video-based learning (VBL) has become a dominant method for learning practical skills, yet accessibility guidelines provide limited guidance for users with cognitive differences. In particular, challenges that individuals with Borderline Intellectual Functioning (BIF) encounter in video-based learning remain largely underexplored, despite VBL's potential to support their learning through features like self-paced viewing and visual demonstration. To address this gap, we conducted a series of studies with BIF individuals and caretakers to comprehensively understand their VBL challenges. Our analysis revealed challenges stemming from misalignment between user cognitive characteristics and video elements (e.g., overwhelmed by pacing and density, difficulty inferring omitted content), and experiential factors intensifying challenges (e.g., low self-efficacy). While participants employed coping strategies such as repetitive viewing to address these challenges, these strategies could not overcome fundamental gaps with video. We further discuss the design implications on both content and UI-level features for BIF and broader groups with cognitive diversities."
  },
  {
    "date": "2026-02-09",
    "title": "Autoregressive Image Generation with Masked Bit Modeling",
    "authors": "Qihang Yu, Qihao Liu, Ju He, Xinyang Zhang, Yang Liu, Liang-Chieh Chen, Xi Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09024v1",
    "source": "arXiv",
    "abstract": "This paper challenges the dominance of continuous pipelines in visual generation. We systematically investigate the performance gap between discrete and continuous methods. Contrary to the belief that discrete tokenizers are intrinsically inferior, we demonstrate that the disparity arises primarily from the total number of bits allocated in the latent space (i.e., the compression ratio). We show that scaling up the codebook size effectively bridges this gap, allowing discrete tokenizers to match or surpass their continuous counterparts. However, existing discrete generation methods struggle to capitalize on this insight, suffering from performance degradation or prohibitive training costs with scaled codebook. To address this, we propose masked Bit AutoRegressive modeling (BAR), a scalable framework that supports arbitrary codebook sizes. By equipping an autoregressive transformer with a masked bit modeling head, BAR predicts discrete tokens through progressively generating their constituent bits. BAR achieves a new state-of-the-art gFID of 0.99 on ImageNet-256, outperforming leading methods across both continuous and discrete paradigms, while significantly reducing sampling costs and converging faster than prior continuous approaches. Project page is available at https://bar-gen.github.io/"
  },
  {
    "date": "2026-02-09",
    "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models",
    "authors": "Zichen Jeff Cui, Omar Rayyan, Haritheja Etukuru, Bowen Tan, Zavier Andrianarivo, Zicheng Teng, Yihang Zhou, Krish Mehta, Nicholas Wojno, Kevin Yuanbo Wu, Manan H Anjaria, Ziyuan Wu, Manrong Mao, Guangxun Zhang, Binit Shah, Yejin Kim, Soumith Chintala, Lerrel Pinto, Nur Muhammad Mahi Shafiullah",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09017v1",
    "source": "arXiv",
    "abstract": "The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/"
  },
  {
    "date": "2026-02-09",
    "title": "Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction",
    "authors": "Hongyi Chen, Tony Dong, Tiancheng Wu, Liquan Wang, Yash Jangir, Yaru Niu, Yufei Ye, Homanga Bharadhwaj, Zackory Erickson, Jeffrey Ichnowski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09013v1",
    "source": "arXiv",
    "abstract": "Multi-finger robotic hand manipulation and grasping are challenging due to the high-dimensional action space and the difficulty of acquiring large-scale training data. Existing approaches largely rely on human teleoperation with wearable devices or specialized sensing equipment to capture hand-object interactions, which limits scalability. In this work, we propose VIDEOMANIP, a device-free framework that learns dexterous manipulation directly from RGB human videos. Leveraging recent advances in computer vision, VIDEOMANIP reconstructs explicit 4D robot-object trajectories from monocular videos by estimating human hand poses, object meshes, and retargets the reconstructed human motions to robotic hands for manipulation learning. To make the reconstructed robot data suitable for dexterous manipulation training, we introduce hand-object contact optimization with interaction-centric grasp modeling, as well as a demonstration synthesis strategy that generates diverse training trajectories from a single video, enabling generalizable policy learning without additional robot demonstrations. In simulation, the learned grasping model achieves a 70.25% success rate across 20 diverse objects using the Inspire Hand. In the real world, manipulation policies trained from RGB videos achieve an average 62.86% success rate across seven tasks using the LEAP Hand, outperforming retargeting-based methods by 15.87%. Project videos are available at videomanip.github.io."
  },
  {
    "date": "2026-02-09",
    "title": "Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense",
    "authors": "Jiacheng Liu, Yaxin Luo, Jiacheng Cui, Xinyi Shang, Xiaohan Zhao, Zhiqiang Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09012v1",
    "source": "arXiv",
    "abstract": "The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like \"Bingo\". In response, we introduce Next-Gen CAPTCHAs, a scalable defense framework designed to secure the next-generation web against the advanced agents. Unlike static datasets, our benchmark is built upon a robust data generation pipeline, allowing for large-scale and easily scalable evaluations, notably, for backend-supported types, our system is capable of generating effectively unbounded CAPTCHA instances. We exploit the persistent human-agent \"Cognitive Gap\" in interactive perception, memory, decision-making, and action. By engineering dynamic tasks that require adaptive intuition rather than granular planning, we re-establish a robust distinction between biological users and artificial agents, offering a scalable and diverse defense mechanism for the agentic era."
  },
  {
    "date": "2026-02-09",
    "title": "Complete discrete Schoenberg-Delsarte theory for homogeneous spaces",
    "authors": "Sujit Sakharam Damase, James Eldred Pascoe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09010v1",
    "source": "arXiv",
    "abstract": "We develop a theory of partially defined complete positivity preservers, extending Schoenberg's classical characterization to functions defined only on discrete subsets or constrained domains. We frame the extension problem through the theory of completely positive maps on operator systems -- we characterize general partially defined completely positive definite functions on general homogeneous spaces. We apply our interpolation to constrained packing problems and Delsarte theory, where one uses positive definite functions on homogeneous spaces to obtain bounds on various packing problems. We prove the specific positive definite function witnesses that a code is sharp for constrained angle codes must be from polynomials."
  },
  {
    "date": "2026-02-09",
    "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
    "authors": "Yudong Wang, Zixuan Fu, Hengyu Zhao, Chen Zhao, Chuyue Zhou, Xinle Lin, Hongya Lyu, Shuaikang Xue, Yi Yi, Yingjiao Wang, Zhi Zheng, Yuzhou Zhang, Jie Zhou, Chaojun Xiao, Xu Han, Zhiyuan Liu, Maosong Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09003v1",
    "source": "arXiv",
    "abstract": "The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community."
  },
  {
    "date": "2026-02-09",
    "title": "Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models",
    "authors": "Yuliang Liu, Yunchong Song, Yixuan Wang, Kewen Ge, Alex Lamb, Qipeng Guo, Kai Chen, Bowen Zhou, Zhouhan Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08984v1",
    "source": "arXiv",
    "abstract": "We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling."
  },
  {
    "date": "2026-02-09",
    "title": "Platform Design, Earnings Transparency and Minimum Wage Policies: Evidence from A Natural Experiment on Lyft",
    "authors": "Rubing Li, Xiao Liu, Arun Sundararajan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08955v1",
    "source": "arXiv",
    "abstract": "We study the impact of a major policy and design change at Lyft that altered both driver earnings and platform transparency, offering insights into how such changes affect stakeholders and platform outcomes. In February 2024, Lyft began a staggered rollout of a new policy that guaranteed drivers a minimum share of rider payments and increased transparency by displaying estimated earnings per ride upfront. This policy was first introduced in major urban markets, creating a natural experiment to evaluate its effects. Using data from over 47 million rides across urban and neighboring suburban markets, we apply dynamic staggered difference-in-differences and geographic border strategies to measure causal effects on driver behavior, rider experience, and platform performance. We find the policy significantly increased driver engagement-particularly among those with lower pre-policy earnings or higher income uncertainty-leading to more hours worked, higher utilization, and greater trip volume. These supply-side changes also generated positive spillovers on rider demand. We disentangle the separate effects of earnings guarantees and transparency and show that while both were beneficial, transparency may have also triggered strategic driver behaviors. In ongoing work, we develop a counterfactual simulation framework linking driver supply and rider intents to ride production, showing how small behavioral shifts could further amplify platform outcomes. We also train a self-supervised model on driver trajectories to detect multihoming, examining whether the observed supply increase reflects net expansion or substitution from other platforms. Together, our findings highlight the potential for platform-led policies to serve as alternatives to regulation and offer design insights for managing platform change."
  },
  {
    "date": "2026-02-09",
    "title": "Equivalent definitions of fusion category arising from separability",
    "authors": "Zhenbang Zuo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08954v1",
    "source": "arXiv",
    "abstract": "For a semisimple multiring category with left duals, we prove that the unit object is simple if and only if the tensor functors by any non-zero algebra are separable (resp. faithful, resp. Maschke, resp. dual Maschke, resp. conservative). This induces a list of equivalent definitions of fusion category. As an application, we describe the connectness of a class of weak Hopf algebras by the separability of tensor functors. We also consider applications to transfer of simplicity between the unit objects, semisimple indecomposable module category and Grothendieck ring."
  },
  {
    "date": "2026-02-09",
    "title": "How Should We Model the Probability of a Language?",
    "authors": "Rasul Dent, Pedro Ortiz Suarez, Thibault Clérice, Benoît Sagot",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08951v1",
    "source": "arXiv",
    "abstract": "Of the over 7,000 languages spoken in the world, commercial language identification (LID) systems only reliably identify a few hundred in written form. Research-grade systems extend this coverage under certain circumstances, but for most languages coverage remains patchy or nonexistent. This position paper argues that this situation is largely self-imposed. In particular, it arises from a persistent framing of LID as decontextualized text classification, which obscures the central role of prior probability estimation and is reinforced by institutional incentives that favor global, fixed-prior models. We argue that improving coverage for tail languages requires rethinking LID as a routing problem and developing principled ways to incorporate environmental cues that make languages locally plausible."
  },
  {
    "date": "2026-02-09",
    "title": "pixelLOG: Logging of Online Gameplay for Cognitive Research",
    "authors": "Zeyu Lu, Dennis L. Barbour",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08941v1",
    "source": "arXiv",
    "abstract": "Traditional cognitive assessments often rely on isolated, output-focused measurements that may fail to capture the complexity of human cognition in naturalistic settings. We present pixelLOG, a high-performance data collection framework for Spigot-based Minecraft servers designed specifically for process-based cognitive research. Unlike existing frameworks tailored only for artificial intelligence agents, pixelLOG also enables human behavioral tracking in multi-player/multi-agent environments. Operating at configurable frequencies up to and exceeding 20 updates per second, the system captures comprehensive behavioral data through a hybrid approach of active state polling and passive event monitoring. By leveraging Spigot's extensible API, pixelLOG facilitates robust session isolation and produces structured JSON outputs integrable with standard analytical pipelines. This framework bridges the gap between decontextualized laboratory assessments and richer, more ecologically valid tasks, enabling high-resolution analysis of cognitive processes as they unfold in complex, virtual environments."
  },
  {
    "date": "2026-02-09",
    "title": "No Word Left Behind: Mitigating Prefix Bias in Open-Vocabulary Keyword Spotting",
    "authors": "Yi Liu, Chuan-Che, Huang, Xiao Quan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08930v1",
    "source": "arXiv",
    "abstract": "Open-vocabulary keyword spotting (OV-KWS) enables personalized device control via arbitrary voice commands. Recently, researchers have explored using audio-text joint embeddings, allowing users to enroll phrases with text, and proposed techniques to disambiguate similar utterances. We find that existing OV-KWS solutions often overly bias the beginning phonemes of an enrollment, causing false triggers when negative enrollment-query-pairs share a prefix (``turn the volume up'' vs. ``turn the volume down''). We trace this to two factors: training data bias and position-biased cross-modal scoring. To address these limitations, we introduce the Partial Overlap Benchmark (POB) with two datasets, POB-Spark and POB-LibriPhrase (POB-LP), containing mismatched audio-text pairs with shared prefixes, and propose Equal-weighting Position Scoring (EPS), a lightweight decision layer. Using EPS alone reduces EER on POB-Spark from 64.4\\% to 29.3\\% and improves POB-LP accuracy from 87.6\\% to 96.8\\%, while maintaining performance on LibriPhrase and Google Speech Commands (GSC). With POB data added in training, our work achieves the best POB benchmark results while incurring the least amount of degradation on prior metrics among baselines. This degradation is most pronounced in GSC, which contains only one-word commands. We surface mitigating this trade-off as future work."
  },
  {
    "date": "2026-02-09",
    "title": "The Reawakening of 4U 1755-338 after 25 Years of Quiescence: Spectro-temporal Analysis Using Multi-instrument X-ray Data",
    "authors": "Geethu Prabhakar, Samir Mandal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08926v1",
    "source": "arXiv",
    "abstract": "The black hole X-ray binary 4U 1755$-$338 underwent an outburst in 2020 after 25 years of quiescence. The comprehensive spectral analysis revealed that the system has a low interstellar neutral hydrogen column density of $0.34\\pm0.01 \\times$10$^{22}$ cm$^{-2}$. The outburst began with a low mass-accretion rate and was characterized as a low-luminosity outburst. The radius of the inner accretion disc remained constant throughout the outburst. Additionally, a growing neutral medium with constant density was detected in the local environment of 4U 1755$-$338.The hardness-intensity diagram (HID) did not follow the standard q-shaped pattern, indicating a non-canonical outburst. Instead, the HID showed a correlated evolution of hardness and source flux, suggesting a thermal disc origin of the flux. A wideband spectral analysis was performed using simultaneous NICER-NuSTAR data in two frameworks, based on kerrbb and bhspec. The results of bhspec (kerrbb) based modeling indicate that 4U 1755$-$338 is a high-inclination system, $67.44_{-3.03}^{+9.75}$ ($75.25_{-4.68}^{+5.59}$) degrees, and harbors a moderately spinning black hole with a spin parameter of $0.78_{-0.14}^{+0.02}$ ($0.50_{-0.43}^{+0.19}$) and a mass of $3.37_{-1.04}^{+0.45} (3.28_{-1.1}^{+1.7})M_{\\odot}$ respectively. The inferred key parameters: black hole mass, spin, and system inclination are consistent across both modeling approaches. No reflection features were detected in the spectra of 4U 1755$-$338. The high spectral index, the blackbody nature ($L\\propto T^4$) of the hardness ratio, the absence of reflection signatures, and the weak variability in the power density spectra indicate that the source remained in the high/soft state throughout the outburst."
  },
  {
    "date": "2026-02-09",
    "title": "Seasonal Variation of Polar Ice: Implications for Ultrahigh Energy Neutrino Detectors",
    "authors": "Alexander Kyriacou, Steven Prohira, Dave Besson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08921v1",
    "source": "arXiv",
    "abstract": "The upper $100 \\, \\mathrm{m}$ to $150 \\, \\mathrm{m}$ of the polar ice sheet, called the firn, has a time-dependent density due to seasonal variations in the surface temperature and snow accumulation. We present RF simulations of an in-ice neutrino-induced radio source that show that these density anomalies create variations in the amplitude and propagation times of radio signals propagating through polar firn at an altitude of ${\\sim}3000 \\, \\mathrm{m}$ above sea level. The received power from signals generated in the ice that refract within the upper ${\\sim} 15 \\, \\mathrm{m}$ firn are subject to a seasonal variation on the order of 10\\%. These variations result in an irreducible background uncertainty on the reconstructed neutrino energy and arrival direction for detectors using ice as a detection medium."
  },
  {
    "date": "2026-02-09",
    "title": "Analysis of Converged 3D Gaussian Splatting Solutions: Density Effects and Prediction Limit",
    "authors": "Zhendong Wang, Cihan Ruan, Jingchuan Xiao, Chuqing Shi, Wei Jiang, Wei Wang, Wenjie Liu, Nam Ling",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08909v1",
    "source": "arXiv",
    "abstract": "We investigate what structure emerges in 3D Gaussian Splatting (3DGS) solutions from standard multi-view optimization. We term these Rendering-Optimal References (RORs) and analyze their statistical properties, revealing stable patterns: mixture-structured scales and bimodal radiance across diverse scenes. To understand what determines these parameters, we apply learnability probes by training predictors to reconstruct RORs from point clouds without rendering supervision. Our analysis uncovers fundamental density-stratification. Dense regions exhibit geometry-correlated parameters amenable to render-free prediction, while sparse regions show systematic failure across architectures. We formalize this through variance decomposition, demonstrating that visibility heterogeneity creates covariance-dominated coupling between geometric and appearance parameters in sparse regions. This reveals the dual character of RORs: geometric primitives where point clouds suffice, and view synthesis primitives where multi-view constraints are essential. We provide density-aware strategies that improve training robustness and discuss architectural implications for systems that adaptively balance feed-forward prediction and rendering-based refinement."
  },
  {
    "date": "2026-02-09",
    "title": "The Scrollar Invariants of Curves Mapping to a Hirzebruch Surface",
    "authors": "Riccardo Redigolo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08902v1",
    "source": "arXiv",
    "abstract": "In this note we analyse the scrollar invariants of $k:1$ covers of $\\mathbb P^1$ that factor through the normalisation of a nodal curve in the $m$-th Hirzebruch surface $\\mathbb F_m$. We then give an existence theorem for nodal curves in $\\mathbb F_m$ having fixed class and singular locus."
  },
  {
    "date": "2026-02-09",
    "title": "A Mathematical Theory of Redox Biology",
    "authors": "James N. Cobley, Michalis G. Nikolaidis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08897v1",
    "source": "arXiv",
    "abstract": "Redox biology underpins signalling, metabolism, immunity, and adaptation, yet lacks a unifying theoretical framework capable of formalising structure, function, and dynamics. Current interpretations rely on descriptive catalogues of molecules and reactions, obscuring how redox behaviour emerges from constrained biochemical organisation. Here, we present a mathematical theory of redox biology that resolves this gap by treating redox systems as finite, compositional, dynamical, and spatially embedded objects. We define a structured redox state space in which admissible molecular transformations form a neutral algebra of possibilities. Biological function emerges when this structure is embedded within a wider molecular network and interpreted through weighted flux distributions. Time-dependent reweighting of these transformations generates redox dynamics, while spatial embedding enforces locality and causality, yielding a distributed redox field. Within this framework, context dependence, nonlinearity, hysteresis, and memory arise naturally from bounded state spaces and irreversible transformations, without requiring ad hoc assumptions. This theory provides a working, predictive interpretative basis for redox biology: it constrains admissible states and trajectories, clarifies the meaning of redox measurements, and links chemical transformation to biological behaviour. Redox biology emerges as a geometric, dynamical process governed by lawful organisation."
  },
  {
    "date": "2026-02-09",
    "title": "Rethinking IPv6 Defense: A Unified Edge-Centric Zero-Trust Data-Plane Architecture",
    "authors": "Walid Aljoby, Mohammed Alzayani, Md. Kamrul Hossain, Khaled A. Harras",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08891v1",
    "source": "arXiv",
    "abstract": "IPv6 dependability is increasingly inseparable from IPv6 security: Neighbor Discovery (ND), Router Advertisements (RA), and ICMPv6 are essential for correct operation yet expose a broad attack surface for spoofing and flooding. Meanwhile, IPv6's massive address space breaks per-IP reputation and makes many defenses either non-scalable or narrowly scoped (e.g., only internal threats, only RA abuse, or only volumetric floods). We propose a zero-trust edge architecture implemented in a single programmable data-plane pipeline that unifies four modules: external spoofing, internal spoofing, external flooding, and internal flooding. A key design choice is to enforce identity plausibility before rate plausibility: stateless per-packet validation filters spoofed traffic early so that time-window statistics for flooding operate on credible identities. We outline a concrete P4 design (prefix Hop-Limit bands, DAD-anchored address-port bindings, and Count-Min Sketch windowed counting) and evaluate it across a systematic 15-scenario suite spanning single-, dual-, and multi-vector compositions. We report results from a BMv2 prototype and validate the same pipeline on a Netronome NFP-4000 SmartNIC, and we discuss limitations and open directions."
  },
  {
    "date": "2026-02-09",
    "title": "DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories",
    "authors": "Adam Trendowicz, Daniel Seifert, Andreas Jedlitschka, Marcus Ciolkowski, Anton Strahilov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08887v1",
    "source": "arXiv",
    "abstract": "Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4o) approach \"DeepQuali\", for assessing and improving requirements quality in agile software development. We applied it to projects in two small companies, where we compared LLM-based quality assessments with expert judgments. Experts also participated in walkthroughs of the solution, provided feedback, and rated their acceptance of the approach. Experts largely agreed with the LLM's quality assessments, especially regarding overall ratings and explanations. However, they did not always agree with the other experts on detailed ratings, suggesting that expertise and experience may influence judgments. Experts recognized the usefulness of the approach but criticized the lack of integration into their workflow. LLMs show potential in supporting software engineers with the quality assessment and improvement of requirements. The explicit use of quality models and explanatory feedback increases acceptance."
  },
  {
    "date": "2026-02-09",
    "title": "AnomSeer: Reinforcing Multimodal LLMs to Reason for Time-Series Anomaly Detection",
    "authors": "Junru Zhang, Lang Feng, Haoran Shi, Xu Guo, Han Yu, Yabo Dong, Duanqing Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08868v1",
    "source": "arXiv",
    "abstract": "Time-series anomaly detection (TSAD) with multimodal large language models (MLLMs) is an emerging area, yet a persistent challenge remains: MLLMs rely on coarse time-series heuristics but struggle with multi-dimensional, detailed reasoning, which is vital for understanding complex time-series data. We present AnomSeer to address this by reinforcing the model to ground its reasoning in precise, structural details of time series, unifying anomaly classification, localization, and explanation. At its core, an expert chain-of-thought trace is generated to provide a verifiable, fine-grained reasoning from classical analyses (e.g., statistical measures, frequency transforms). Building on this, we propose a novel time-series grounded policy optimization (TimerPO) that incorporates two additional components beyond standard reinforcement learning: a time-series grounded advantage based on optimal transport and an orthogonal projection to ensure this auxiliary granular signal does not interfere with the primary detection objective. Across diverse anomaly scenarios, AnomSeer, with Qwen2.5-VL-3B/7B-Instruct, outperforms larger commercial baselines (e.g., GPT-4o) in classification and localization accuracy, particularly on point- and frequency-driven exceptions. Moreover, it produces plausible time-series reasoning traces that support its conclusions."
  },
  {
    "date": "2026-02-09",
    "title": "Global well-posedness for one-dimensional compressible Navier--Stokes system in dynamic combustion with small $BV\\cap L^1$ initial data",
    "authors": "Siran Li, Haitao Wang, Jianing Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08867v1",
    "source": "arXiv",
    "abstract": "We establish the global well-posedness theory of small BV weak solutions to a one-dimensional compressible Navier--Stokes model for reacting gas mixtures in dynamic combustion. The unknowns of the PDE system consist of the specific volume, velocity, temperature, and mass fraction of the reactant. For initial data that are small perturbations around the constant equilibrium state $(1, 0, 1, 0)$ in the $L^1(\\mathbb{R}) \\cap {\\rm BV}(\\mathbb{R})$-norm, we establish the local-in-time existence of weak solutions via an iterative scheme, show the stability and uniqueness of local weak solutions, and prove the global-in-time existence of solutions for initial data with small BV-norm via an analysis of the Green's function of the linearised system. The large-time behaviour of the global BV weak solutions is also characterised. This work is motivated by and extends the recent global well-posedness theory for BV weak solutions to the one-dimensional isentropic Navier--Stokes and Navier--Stokes--Fourier systems developed in [T.-P. Liu, S.-H. Yu, Commun. Pure Appl. Math. 75 (2022), 223--348] and [H. Wang, S.-H. Yu, X. Zhang, Arch. Ration. Mech. Anal. 245 (2022), 375--477]."
  },
  {
    "date": "2026-02-09",
    "title": "Rethinking Graph Generalization through the Lens of Sharpness-Aware Minimization",
    "authors": "Yang Qiu, Yixiong Zou, Jun Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08855v1",
    "source": "arXiv",
    "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success across various graph-based tasks but remain highly sensitive to distribution shifts. In this work, we focus on a prevalent yet under-explored phenomenon in graph generalization, Minimal Shift Flip (MSF),where test samples that slightly deviate from the training distribution are abruptly misclassified. To interpret this phenomenon, we revisit MSF through the lens of Sharpness-Aware Minimization (SAM), which characterizes the local stability and sharpness of the loss landscape while providing a theoretical foundation for modeling generalization error. To quantify loss sharpness, we introduce the concept of Local Robust Radius, measuring the smallest perturbation required to flip a prediction and establishing a theoretical link between local stability and generalization. Building on this perspective, we further observe a continual decrease in the robust radius during training, indicating weakened local stability and an increasingly sharp loss landscape that gives rise to MSF. To jointly solve the MSF phenomenon and the intractability of radius, we develop an energy-based formulation that is theoretically proven to be monotonically correlated with the robust radius, offering a tractable and principled objective for modeling flatness and stability. Building on these insights, we propose an energy-driven generative augmentation framework (E2A) that leverages energy-guided latent perturbations to generate pseudo-OOD samples and enhance model generalization. Extensive experiments across multiple benchmarks demonstrate that E2A consistently improves graph OOD generalization, outperforming state-of-the-art baselines."
  },
  {
    "date": "2026-02-09",
    "title": "Cutting Through the Noise: On-the-fly Outlier Detection for Robust Training of Machine Learning Interatomic Potentials",
    "authors": "Terry C. W. Lam, Niamh O'Neill, Christoph Schran, Lars L. Schaaf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08849v1",
    "source": "arXiv",
    "abstract": "The accuracy of machine learning interatomic potentials suffers from reference data that contains numerical noise. Often originating from unconverged or inconsistent electronic-structure calculations, this noise is challenging to identify. Existing mitigation strategies such as manual filtering or iterative refinement of outliers, require either substantial expert effort or multiple expensive retraining cycles, making them difficult to scale to large datasets. Here, we introduce an on-the-fly outlier detection scheme that automatically down-weights noisy samples, without requiring additional reference calculations. By tracking the loss distribution via an exponential moving average, this unsupervised method identifies outliers throughout a single training run. We show that this approach prevents overfitting and matches the performance of iterative refinement baselines with significantly reduced overhead. The method's effectiveness is demonstrated by recovering accurate physical observables for liquid water from unconverged reference data, including diffusion coefficients. Furthermore, we validate its scalability by training a foundation model for organic chemistry on the SPICE dataset, where it reduces energy errors by a factor of three. This framework provides a simple, automated solution for training robust models on imperfect datasets across dataset sizes."
  },
  {
    "date": "2026-02-09",
    "title": "Deciding the Satisfiability of Combined Qualitative Constraint Networks",
    "authors": "Quentin Cohen-Solal, Alexandre Niveau, Maroua Bouzid",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08848v1",
    "source": "arXiv",
    "abstract": "Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework makes it possible to reason in the context of each of these combinations and extensions, but also to study in a unified way the satisfiability decision and its complexity. In particular, we establish two complementary theorems guaranteeing that the satisfiability decision is polynomial, and we use them to recover the known results of the size-topology combination. We also generalize the main definition of qualitative formalism to include qualitative formalisms excluded from the definitions of the literature, important in the context of combinations."
  },
  {
    "date": "2026-02-09",
    "title": "Unconventional magnetoelectric conductivity and electrochemical response from dipole-like sources of Berry curvature",
    "authors": "Ipsita Mandal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08844v1",
    "source": "arXiv",
    "abstract": "We compute longitudinal magnetoelectric conductivity ($σ_{zz}$) and nonlinear electrochemical response (ECR), applying the semiclassical Boltzmann formalism, for three-dimensional nodal-ring semimetals (vortex nodal-rings and $\\mathcal P \\mathcal T$-symmetric nodal-rings) and three-band Hopf semimetals. While the nodal-curves of the former are taken to lie along the $k_z = 0$-plane, the nodal points of the latter harbour dipoles in their Berry-curvature (BC) profile, with the dipole's axis aligned along the $k_z$-axis. All these systems are topological and are unified on the aspect that their bands possess a vanishing Chern number. The linear response, $σ_{zz}$, is obtained from an exact solution when the systems are subjected to collinear electric and magnetic fields applied along the anisotropy axis, viz. $\\boldsymbol{\\hat z}$. The nonlinear part involves third-rank tensors representing second-order response coefficients, relating the electrical current to the combined effects of the gradient of the chemical potential and an external electric field. We analyse the similarities of the response arising from the vortex nodal-rings and the Hopf semimetals, which can be traced to the dipole-like sources in their BC fields."
  },
  {
    "date": "2026-02-09",
    "title": "Division of labor enables efficient collective decision-making under uncertainty",
    "authors": "Hyunjoong Kim, Zachary Kilpatrick, Kresimir Josic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08840v1",
    "source": "arXiv",
    "abstract": "How do social animals make effective decisions in the absence of a leader? While coordination can improve accuracy, it also delays responses as information propagates through the group. In changing environments, these delays can outweigh the benefits of centralized control, making decentralized strategies advantageous in large groups. This raises a key question: how can groups implement efficient collective decisions without central coordination? We address this question using a model of collective foraging in which individuals choose whether to invest in costly exploration or remain idle, while sharing information and rewards across the group. We show that decentralized collectives can match the performance of centrally controlled groups through a division of labor: a small, heterogeneous subset explores even when expected rewards are negative, while a synchronized majority forages only when expected rewards are positive. Information redundancy causes the optimal scout number to grow sublinearly with group size, so that larger groups need proportionally fewer explorers. The heterogeneity of the group is maximized at intermediate ecological pressures, but optimal groups are homogeneous when costs or environmental contrasts or fluctuations are extreme. Crucially, these group-level policies do not require central coordination, emerging instead from agents following simple threshold-based decision rules. We thus demonstrate a mechanism through which leaderless collectives can make effective decisions under uncertainty and show how ecological pressures can drive changes in the distribution of strategies employed by the group."
  },
  {
    "date": "2026-02-09",
    "title": "Glow with the Flow: AI-Assisted Creation of Ambient Lightscapes for Music Videos",
    "authors": "Frederic Anthony Robinson, Vishnu Raj, David Cooper, Fan Du, David Gunawan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08838v1",
    "source": "arXiv",
    "abstract": "Designed light is an established modality for live performance and music playback. Despite the growing availability of consumer smart lighting, the creation of designed light for music visualization remains limited to professional contexts due to time and skill constraints. To address this, we present an AI-assisted system for generating ambient light sequences for music videos. Informed by professional design heuristics, the system extracts salient features from source video and audio to generate an editable preliminary design of object based ambient light effect. We evaluated the system by comparing its autonomous output against hand-authored designs for three music videos. Findings from responses by 32 participants indicate that the initial output provides a viable baseline for further refinement by human authors. This work demonstrates the utility of AI-assisted workflows in supporting the creation and adoption of designed light beyond professional venues."
  },
  {
    "date": "2026-02-09",
    "title": "AMEM4Rec: Leveraging Cross-User Similarity for Memory Evolution in Agentic LLM Recommenders",
    "authors": "Minh-Duc Nguyen, Hai-Dang Kieu, Dung D. Le",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08837v1",
    "source": "arXiv",
    "abstract": "Agentic systems powered by Large Language Models (LLMs) have shown strong potential in recommender systems but remain hindered by several challenges. Fine-tuning LLMs is parameter-inefficient, and prompt-based agentic reasoning is limited by context length and hallucination risk. Moreover, existing agentic recommendation systems predominantly leverages semantic knowledge while neglecting the collaborative filtering (CF) signals essential for implicit preference modeling. To address these limitations, we propose AMEM4Rec, an agentic LLM-based recommender that learns collaborative signals in an end-to-end manner through cross-user memory evolution. AMEM4Rec stores abstract user behavior patterns from user histories in a global memory pool. Within this pool, memories are linked to similar existing ones and iteratively evolved to reinforce shared cross-user patterns, enabling the system to become aware of CF signals without relying on a pre-trained CF model. Extensive experiments on Amazon and MIND datasets show that AMEM4Rec consistently outperforms state-of-the-art LLM-based recommenders, demonstrating the effectiveness of evolving memory-guided collaborative filtering."
  },
  {
    "date": "2026-02-09",
    "title": "VideoVeritas: AI-Generated Video Detection via Perception Pretext Reinforcement Learning",
    "authors": "Hao Tan, Jun Lan, Senyuan Shi, Zichang Tan, Zijian Yu, Huijia Zhu, Weiqiang Wang, Jun Wan, Zhen Lei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08828v1",
    "source": "arXiv",
    "abstract": "The growing capability of video generation poses escalating security risks, making reliable detection increasingly essential. In this paper, we introduce VideoVeritas, a framework that integrates fine-grained perception and fact-based reasoning. We observe that while current multi-modal large language models (MLLMs) exhibit strong reasoning capacity, their granular perception ability remains limited. To mitigate this, we introduce Joint Preference Alignment and Perception Pretext Reinforcement Learning (PPRL). Specifically, rather than directly optimizing for detection task, we adopt general spatiotemporal grounding and self-supervised object counting in the RL stage, enhancing detection performance with simple perception pretext tasks. To facilitate robust evaluation, we further introduce MintVid, a light yet high-quality dataset containing 3K videos from 9 state-of-the-art generators, along with a real-world collected subset that has factual errors in content. Experimental results demonstrate that existing methods tend to bias towards either superficial reasoning or mechanical analysis, while VideoVeritas achieves more balanced performance across diverse benchmarks."
  },
  {
    "date": "2026-02-09",
    "title": "Josephson tunneling through a Yu-Shiba-Rusinov state: Interplay of $π$-shifts in Josephson current and local superconducting order parameter",
    "authors": "Andreas Theiler, Christian R. Ast, Annica M. Black-Schaffer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08827v1",
    "source": "arXiv",
    "abstract": "An impurity hosting a magnetic moment coupled to a conventional $s$-wave superconductor gives rise to so-called Yu-Shiba-Rusinov (YSR) states with energies inside the superconducting gap. Depending on the coupling between the impurity and the superconductor, the system can have two distinct quantum ground states separated by a quantum phase transition (QPT). We investigate the interplay of two effects observed at the QPT. First, the tunneling supercurrent through the impurity reverses its sign at the QPT, denoted as a $π$-shift in the current-phase relation. Secondly, the local superconducting order parameter at the impurity site is suppressed and becomes negative at the QPT, generally termed a $π$-shift in the local superconducting order parameter. We find that both these effects are governed by the presence of the YSR state, however, they do not significantly depend or influence each other. In particular, we establish that the $π$-shift in the superconducting order parameter does not induce a $π$-shift in the tunneling Josephson current, nor can the Josephson current and its spatial behavior be used to directly probe the impurity-induced changes in the local superconducting order parameter, which occur on a length scale substantially shorter than the superconducting coherence length."
  },
  {
    "date": "2026-02-09",
    "title": "Perfect all-angle asymmetric transmission via normal susceptibilities: exact spatial derivative by local meta-atoms and nonlocal metasurfaces",
    "authors": "Amit Shaham, Ariel Epstein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08823v1",
    "source": "arXiv",
    "abstract": "We present a systematic methodology for realizing accurate asymmetric all-angle transmission in nonlocal metasurfaces. As a representative example, we derive closed-form susceptibility conditions for exact first-order spatial differentiation of unity numerical aperture, clarifying the role of each underlying balance. We provide rigorous and detailed designs of physically meaningful structures that directly feature such susceptibilities: a conceptual local meta-atom and a realistic nonlocal multilayered printed circuit board (PCB). Importantly, the latter leverages an intricate system of nearfield coupling beyond standard homogenization. Validated in simulations, our results provide a general and modular route to high-resolution asymmetric nonlocal metasurfaces for optical analog processing."
  },
  {
    "date": "2026-02-09",
    "title": "Any-to-All MRI Synthesis: A Unified Foundation Model for Nasopharyngeal Carcinoma and Its Downstream Applications",
    "authors": "Yao Pu, Yiming Shi, Zhenxi Zhang, Peixin Yu, Yitao Zhuang, Xiang Wang, Hongzhao Chen, Jing Cai, Ge Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08822v1",
    "source": "arXiv",
    "abstract": "Magnetic resonance imaging (MRI) is essential for nasopharyngeal carcinoma (NPC) radiotherapy (RT), but practical constraints, such as patient discomfort, long scan times, and high costs often lead to incomplete modalities in clinical practice, compromising RT planning accuracy. Traditional MRI synthesis methods are modality-specific, limited in anatomical adaptability, and lack clinical interpretability-failing to meet NPC's RT needs. Here, we developed a unified foundation model integrating contrastive visual representation learning and vision-language alignment (VLA) to enable any-to-all MRI synthesis. The model uses a contrastive encoder for modality-invariant representations and a CLIP-based text-informed decoder for semantically consistent synthesis, supporting any-to-all MRI synthesis via one unified foundation model. Trained on 40,825 images from 13 institutions, it achieves consistently high performance (average SSIM 0.90, PSNR 27) across 26 internal/external validation sites (15,748 images), with superior synthesis fidelity and robustness to noise and domain shifts. Meanwhile, its unified representation enhances downstream RT-relevant tasks (e.g., segmentation). This work advances digital medicine solutions for NPC care by leveraging foundation models to bridge technical synthesis and clinical utility."
  },
  {
    "date": "2026-02-09",
    "title": "Two-Dimensional Kelvin-Helmholtz Instability with Anisotropic Pressure",
    "authors": "Shishir Biswas, Masaru Nakanotani, Dinshaw S. Balsara, Vladimir Florinski, Merav Opher",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08806v1",
    "source": "arXiv",
    "abstract": "The Kelvin-Helmholtz (KH) instability occurs in multiple heliospheric (solar-wind stream interfaces, planetary magnetospheres, cometary tails, heliopause flanks) and interstellar (protoplanetary disks, relativistic jets, neutron star accretion disks) environments. While the KH instability has been well-studied in the magnetohydrodynamic (MHD) limit, only limited studies were performed in the collisionless regime, which is conducive to development of anisotropic pressures. Collisionless plasmas are often described using the Chew Goldberger and Low (CGL) equations which feature an anisotropic pressure tensor. This paper presents a comprehensive analysis of the CGL version of the KH instability using linearised and numerical techniques. We find that the largest growth rates and the greatest incidence of magnetic effects occur in the MHD limit. In the large relaxation time CGL limit, part of the energy goes into the formation of pressure anisotropies, resulting in smaller amounts of energy being available for bending the field lines. Consequently, when we cross-compare CGL and MHD simulations that are otherwise identical, the current densities are largest in the MHD limit, and the largest magnetic islands also form in that limit. Early and late time formation of pressure anisotropies have also been studied. We also find that the strongest trend for forming intermittencies in the flow also occurs in the MHD limit. The paper also discusses possible consequences of our results for turbulence and reconnection in the heliosheath (the layer between the solar wind termination shock and the heliopause)."
  },
  {
    "date": "2026-02-09",
    "title": "Towards resurgence of Joyce structures",
    "authors": "Iván Tulli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08805v1",
    "source": "arXiv",
    "abstract": "Given a Joyce structure, we show that the associated $\\mathbb{C}^*$-family of non-linear connections $\\mathcal{A}^ε$ can be gauged to a standard form $\\mathcal{A}^{ε,\\text{st}}$ by a gauge transformation $\\hat{g}$, formal in $ε$. We show that the corresponding infinitesimal gauge transformation $\\dot{g}=\\log(\\hat{g})$ has a convergent Borel transform, provided $\\dot{g}$ vanishes on the base of the Joyce structure. This establishes the first step in showing that such a $\\dot{g}$ is resurgent. We also use $\\hat{g}$ to produce formal twistor Darboux coordinates for the complex hyperkähler structure associated to the Joyce structure, and show a similar result about convergence of the Borel transform of the formal twistor Darboux coordinates."
  },
  {
    "date": "2026-02-09",
    "title": "Equilibria: Fair Multi-Tenant CXL Memory Tiering At Scale",
    "authors": "Kaiyang Zhao, Neha Gholkar, Hasan Maruf, Abhishek Dhanotia, Johannes Weiner, Gregory Price, Ning Sun, Bhavya Dwivedi, Stuart Clark, Dimitrios Skarlatos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08800v1",
    "source": "arXiv",
    "abstract": "Memory dominates datacenter system cost and power. Memory expansion via Compute Express Link (CXL) is an effective way to provide additional memory at lower cost and power, but its effective use requires software-level tiering for hyperscaler workloads. Existing tiering solutions, including current Linux support, face fundamental limitations in production deployments. First, they lack multi-tenancy support, failing to handle stacked homogeneous or heterogeneous workloads. Second, limited control-plane flexibility leads to fairness violations and performance variability. Finally, insufficient observability prevents operators from diagnosing performance pathologies at scale. We present Equilibria, an OS framework enabling fair, multi-tenant CXL tiering at datacenter scale. Equilibria provides per-container controls for memory fair-share allocation and fine-grained observability of tiered-memory usage and operations. It further enforces flexible, user-specified fairness policies through regulated promotion and demotion, and mitigates noisy-neighbor interference by suppressing thrashing. Evaluated in a large hyperscaler fleet using production workloads and benchmarks, Equilibria helps workloads meet service level objectives (SLOs) while avoiding performance interference. It improves performance over the state-of-the-art Linux solution, TPP, by up to 52% for production workloads and 1.7x for benchmarks. All Equilibria patches have been released to the Linux community."
  },
  {
    "date": "2026-02-09",
    "title": "CryptoGen: Secure Transformer Generation with Encrypted KV-Cache Reuse",
    "authors": "Hedong Zhang, Neusha Javidnia, Shweta Pardeshi, Qian Lou, Farinaz Koushanfar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08798v1",
    "source": "arXiv",
    "abstract": "The widespread deployment of cloud-hosted generative models raises a fundamental challenge: enabling efficient autoregressive generation while preserving the privacy of both user prompts and model parameters in untrusted environments. We address this challenge in a client-server setting where an untrusted server hosts an autoregressive Transformer and the client requires cryptographic protection for both inputs and inference. We present CryptoGen, the first system to enable scalable privacy-preserving neural generation with persistent encrypted key-value (KV) cache reuse. Discriminative-task secure inference systems incur quadratic latency and memory growth when adapted to autoregressive decoding due to the lack of native encrypted KV-cache support. In contrast, CryptoGen achieves near-linear scaling by securely reusing and updating encrypted KV caches throughout generation. CryptoGen integrates homomorphic encryption and secret sharing to support both prefilling and generation. Key techniques include a unified encrypted KV-cache framework, heterogeneous SIMD encodings for different phases, optimized cipher-cipher matrix-matrix and matrix-vector operations, and efficient noise refresh and ciphertext concatenation mechanisms. Evaluation on generative Transformer models trained on WikiText-2, PTB, and LAMBADA shows that for input lengths of 128-512 tokens, CryptoGen achieves 4.4x-7.6x lower per-token latency than state-of-the-art discriminative secure inference systems, while maintaining near-linear latency and memory scaling, with advantages increasing for longer sequences. CryptoGen is released as an open-source library."
  },
  {
    "date": "2026-02-09",
    "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation",
    "authors": "SII-OpenMOSS Team, :, Donghua Yu, Mingshu Chen, Qi Chen, Qi Luo, Qianyi Wu, Qinyuan Cheng, Ruixiao Li, Tianyi Liang, Wenbo Zhang, Wenming Tu, Xiangyu Peng, Yang Gao, Yanru Huo, Ying Zhu, Yinze Luo, Yiyang Zhang, Yuerong Song, Zhe Xu, Zhiyu Zhang, Chenchen Yang, Cheng Chang, Chushu Zhou, Hanfu Chen, Hongnan Ma, Jiaxi Li, Jingqi Tong, Junxi Liu, Ke Chen, Shimin Li, Songlin Wang, Wei Jiang, Zhaoye Fei, Zhiyuan Ning, Chunguo Li, Chenhui Li, Ziwei He, Zengfeng Huang, Xie Chen, Xipeng Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08794v1",
    "source": "arXiv",
    "abstract": "Audio is indispensable for real-world video, yet generation models have largely overlooked audio components. Current approaches to producing audio-visual content often rely on cascaded pipelines, which increase cost, accumulate errors, and degrade overall quality. While systems such as Veo 3 and Sora 2 emphasize the value of simultaneous generation, joint multimodal modeling introduces unique challenges in architecture, data, and training. Moreover, the closed-source nature of existing systems limits progress in the field. In this work, we introduce MOVA (MOSS Video and Audio), an open-source model capable of generating high-quality, synchronized audio-visual content, including realistic lip-synced speech, environment-aware sound effects, and content-aligned music. MOVA employs a Mixture-of-Experts (MoE) architecture, with a total of 32B parameters, of which 18B are active during inference. It supports IT2VA (Image-Text to Video-Audio) generation task. By releasing the model weights and code, we aim to advance research and foster a vibrant community of creators. The released codebase features comprehensive support for efficient inference, LoRA fine-tuning, and prompt enhancement."
  },
  {
    "date": "2026-02-09",
    "title": "Microquasar Remnants as Pevatrons Illuminating the Galactic Cosmic Ray Knee",
    "authors": "Bing Theodore Zhang, Shiqi Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08940v1",
    "source": "arXiv",
    "abstract": "Microquasars are primary candidates for Galactic PeVatrons, yet their collective contribution to the cosmic ray (CR) ``knee\" remains poorly understood. We investigate this contribution by simulating anisotropic diffusive propagation through the Galactic magnetic field (GMF). Our results demonstrate that the GMF establishes a transport regime where magnetic connectivity between sources and the solar neighborhood determines the local flux. Active sources aligned with local GMF lines, such as Cygnus X-1, exhibit significant flux enhancements, while magnetically disconnected sources, such as V616 Mon, are strongly suppressed. By integrating source evolution with anisotropic transport, we show that the observed proton bump at the CR ``knee\" is best reproduced by the cumulative contribution of microquasar remnants, which is often dominated by a few nearby or recent events, rather than the active ones alone. We find that a harder injection spectrum allows CRs from remnants to reproduce the PeV bump after propagation, as low-energy CRs have sufficient time to accumulate while high-energy CRs escape the Galactic plane. Our findings suggest that the integrated history of microquasar remnants, governed by the interplay of source age and magnetic connectivity, is the primary driver populating the observed CR ``knee''."
  },
  {
    "date": "2026-02-09",
    "title": "Non-Hermitian Renormalization Group from a Few-Body Perspective",
    "authors": "Hiroyuki Tajima, Masaya Nakagawa, Haozhao Liang, Masahito Ueda",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08705v1",
    "source": "arXiv",
    "abstract": "Non-Hermiticity plays a fundamental role in open quantum systems and describes a wide variety of effects of interactions with environments, including quantum measurement. However, understanding its consequences in strongly interacting systems is still elusive due to the interplay between non-perturbative strong correlations and non-Hermiticity. While the Wilsonian renormalization group (RG) method has been applied to tackle this problem, its foundation, based on the existence of the partition function, is ill-defined. In this paper, we establish a microscopic foundation of the non-Hermitian RG method from a few-body perspective. We show that the invariance of the scattering amplitude under RG transformations enables us to rigorously derive the non-Hermitian RG equation, giving a physically transparent interpretation of RG flows. We discuss a detailed structure of such RG flows in a non-relativistic two-body system with inelastic two-body loss, and show its relation to a non-Hermitian quantum scale anomaly. Our analysis suggests that non-Hermitian complex potentials often used in high-energy physics can be interpreted as being caused by quantum measurement, where the detection of elastically scattered particles updates the observer's knowledge, resulting in a nonunitary state change of the system. We apply our formalism to nuclear physics, find the emergence of a critical semicircle, and show that several nuclei are located near the critical semicircle in the coherent neutron-nucleus scattering. We also propose that the localized dineutron in two-neutron halo nuclei can be interpreted as the quantum measurement effect on the imaginary potential associated with absorption into the core nucleus. Our result bridges different contexts of non-Hermitian systems in high-energy and atomic, molecular, and optical physics, opening an interdisciplinary playground of non-Hermitian few-body physics."
  },
  {
    "date": "2026-02-09",
    "title": "Learning Credal Ensembles via Distributionally Robust Optimization",
    "authors": "Kaizheng Wang, Ghifari Adam Faza, Fabio Cuzzolin, Siu Lun Chau, David Moens, Hans Hallez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08470v1",
    "source": "arXiv",
    "abstract": "Credal predictors are models that are aware of epistemic uncertainty and produce a convex set of probabilistic predictions. They offer a principled way to quantify predictive epistemic uncertainty (EU) and have been shown to improve model robustness in various settings. However, most state-of-the-art methods mainly define EU as disagreement caused by random training initializations, which mostly reflects sensitivity to optimization randomness rather than uncertainty from deeper sources. To address this, we define EU as disagreement among models trained with varying relaxations of the i.i.d. assumption between training and test data. Based on this idea, we propose CreDRO, which learns an ensemble of plausible models through distributionally robust optimization. As a result, CreDRO captures EU not only from training randomness but also from meaningful disagreement due to potential distribution shifts between training and test data. Empirical results show that CreDRO consistently outperforms existing credal methods on tasks such as out-of-distribution detection across multiple benchmarks and selective classification in medical applications."
  },
  {
    "date": "2026-02-09",
    "title": "Bi-Adapt: Few-shot Bimanual Adaptation for Novel Categories of 3D Objects via Semantic Correspondence",
    "authors": "Jinxian Zhou, Ruihai Wu, Yiwei Liu, Yiwen Hou, Xunzhe Zhou, Checheng Yu, Licheng Zhong, Lin Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08425v1",
    "source": "arXiv",
    "abstract": "Bimanual manipulation is imperative yet challenging for robots to execute complex tasks, requiring coordinated collaboration between two arms. However, existing methods for bimanual manipulation often rely on costly data collection and training, struggling to generalize to unseen objects in novel categories efficiently. In this paper, we present Bi-Adapt, a novel framework designed for efficient generalization for bimanual manipulation via semantic correspondence. Bi-Adapt achieves cross-category affordance mapping by leveraging the strong capability of vision foundation models. Fine-tuning with restricted data on novel categories, Bi-Adapt exhibits notable generalization to out-of-category objects in a zero-shot manner. Extensive experiments conducted in both simulation and real-world environments validate the effectiveness of our approach and demonstrate its high efficiency, achieving a high success rate on different benchmark tasks across novel categories with limited data. Project website: https://biadapt-project.github.io/"
  },
  {
    "date": "2026-02-09",
    "title": "Averaging Dynamics and Wong-Zakai approximations for a Fast-Slow Navier-Stokes System Driven by fractional Brownian Motion",
    "authors": "Eliseo Luongo, Francesco Triggiano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08680v1",
    "source": "arXiv",
    "abstract": "We study a slow-fast system of coupled two- and three-dimensional Navier-Stokes equations in which the fast component is perturbed by an additive fractional Brownian noise with Hurst parameter $H>\\frac{1}{3}$. The system is analyzed using rough path theory, and the limiting behaviour strongly depends on the value of $H$. We prove convergence in law of the slow component to a Navier-Stokes system with an additional Itô-Stokes drift when $H<\\frac{1}{2}$. In contrast, for $H\\in (\\frac{1}{2},1)$, the limit equation features only a transport noise driven by a rough path."
  },
  {
    "date": "2026-02-09",
    "title": "High-resolution numerical simulations of turbulent non-catalytic reverse water gas shift",
    "authors": "Nils Erland L. Haugen, Axel Brandenburg, Ewa Karchniwy, Ole Hauke Heinz Meyer, Åsmund Ervik, Hursanay Fyhn, Ladan Samaei, Bjørn Bringedal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08365v1",
    "source": "arXiv",
    "abstract": "A green transition in aviation requires a drastic upscaling of Sustainable Aviation Fuel (SAF). The power-to-liquid process for the production of CO2-neutral jet fuel via electricity, called e-SAF, directly replaces fossil jet fuel without having to change infrastructure, aeroplanes, or jet-engines. The process combines green hydrogen with industrial exhaust gas, or captured carbon dioxide, in a circular economy concept. A key element of the e-SAF production plant is the reactor where syngas is produced. Traditional reactors use catalytic technology, which faces severe challenges due to the reduced performance over time because of catalyst degradation, clogging, and breakup due to embrittlement. A high-potential alternative is the catalyst-free reverse water-gas-shift (RWGS) reactor concept. The primary aim of this paper is to investigate the fundamental aspects of the catalyst-free RWGS process, such as reaction kinetics and the interactions between turbulence and chemistry. The secondary aim is to identify how a typical combustion subgrid scale models for Large Eddy Simulations (LES) perform when the chemical reactions are endothermic, in contrast to the strong endothermicity associated with classical combustion. It is found that even small traces of O2 in the CO2 stream can significantly increase the production rate of CO. This is attributed to the increased pool of OH. The effect is strongest at atmospheric pressure and less pronounced at higher pressure. By using the temporal jet framework to study turbulence-chemistry interactions, an algebraic equation for the prediction of the CO conversion time in a turbulent flow as a function of Damkohler number and chemical timescale is employed. Finally, it is concluded that the PaSR LES subgrid model designed for combustion reactions perform well also for the endothermic reverse water-gas-shift reaction."
  },
  {
    "date": "2026-02-09",
    "title": "Complex harmonic mean",
    "authors": "Atsushi Nakayasu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08292v1",
    "source": "arXiv",
    "abstract": "We study the harmonic mean of non-zero complex-valued random variables (complex harmonic mean) and establish several geometric estimates and bounds. In contrast to the classical positive-valued case, complex harmonic means may lie outside the convex hull of the range. We prove that if the range is contained in a disk not containing the origin, then the complex harmonic mean is confined to the same disk. This result is based on the behavior of disks under inversion and convexity arguments. Further estimates involving the modulus and the real part are obtained, and the two-point case is analyzed explicitly, revealing a circular structure. Several examples are provided to illustrate the distinctive features of complex harmonic means."
  },
  {
    "date": "2026-02-09",
    "title": "2.5D co-packaged optical I/O chipsets on a SiON/Si interposer for 4 $\\times$ 100G optical interconnection",
    "authors": "Daibao Hou, Yuntian Yao, Xiaotian Cheng, Shuning Ding, Qiyou Wu, Yonghong Hu, Wei Pan, Chao Huang, Huihui Zhu, Yongzhen Huang, Chenhui Li, Chaoyuan Jin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08284v1",
    "source": "arXiv",
    "abstract": "Optical I/O technologies have emerged as a potential industrial solution for high-performance data interconnection in AI/ML computing acceleration. While optical I/Os are deployed at the edge of computational chips by co-packaged optics (CPO), flexible and high-performance integration architectures need to be explored to address system-level challenges. In this work, we present and experimentally demonstrate a SiON/Si-based optical interposer that integrates high-bandwidth and energy-efficient optical I/O chipsets. High-performance photonic and electronic components are co-packaged on the interposer, leading to low-loss, signal-integrity-friendly, and thermally efficient characteristics. The optical interposer incorporates low-loss SiON photonic circuits to realize scalable waveguide routing and wavelength-division multiplexing (WDM) with polarization-insensitive operation and high fabrication tolerance, while supporting flip-chip integration with InP-based active devices, including electro-absorption modulated lasers (EMLs) and photodetectors (PDs). Based on this architecture, a 400-Gb/s single-fiber optical transceiver is implemented and experimentally evaluated. Clear eye diagrams and high receiver sensitivity demonstrate reliable high-speed data transmission, which offers scalable, high-bandwidth optical I/Os in future high-performance computational clusters."
  },
  {
    "date": "2026-02-09",
    "title": "DexFormer: Cross-Embodied Dexterous Manipulation via History-Conditioned Transformer",
    "authors": "Ke Zhang, Lixin Xu, Chengyi Song, Junzhe Xu, Xiaoyi Lin, Zeyu Jiang, Renjing Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08278v1",
    "source": "arXiv",
    "abstract": "Dexterous manipulation remains one of the most challenging problems in robotics, requiring coherent control of high-DoF hands and arms under complex, contact-rich dynamics. A major barrier is embodiment variability: different dexterous hands exhibit distinct kinematics and dynamics, forcing prior methods to train separate policies or rely on shared action spaces with per-embodiment decoder heads. We present DexFormer, an end-to-end, dynamics-aware cross-embodiment policy built on a modified transformer backbone that conditions on historical observations. By using temporal context to infer morphology and dynamics on the fly, DexFormer adapts to diverse hand configurations and produces embodiment-appropriate control actions. Trained over a variety of procedurally generated dexterous-hand assets, DexFormer acquires a generalizable manipulation prior and exhibits strong zero-shot transfer to Leap Hand, Allegro Hand, and Rapid Hand. Our results show that a single policy can generalize across heterogeneous hand embodiments, establishing a scalable foundation for cross-embodiment dexterous manipulation. Project website: https://davidlxu.github.io/DexFormer-web/."
  },
  {
    "date": "2026-02-09",
    "title": "Linguistics and Human Brain: A Perspective of Computational Neuroscience",
    "authors": "Fudong Zhang, Bo Chai, Yujie Wu, Wai Ting Siok, Nizhuan Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08275v1",
    "source": "arXiv",
    "abstract": "Elucidating the language-brain relationship requires bridging the methodological gap between the abstract theoretical frameworks of linguistics and the empirical neural data of neuroscience. Serving as an interdisciplinary cornerstone, computational neuroscience formalizes the hierarchical and dynamic structures of language into testable neural models through modeling, simulation, and data analysis. This enables a computational dialogue between linguistic hypotheses and neural mechanisms. Recent advances in deep learning, particularly large language models (LLMs), have powerfully advanced this pursuit. Their high-dimensional representational spaces provide a novel scale for exploring the neural basis of linguistic processing, while the \"model-brain alignment\" framework offers a methodology to evaluate the biological plausibility of language-related theories."
  },
  {
    "date": "2026-02-09",
    "title": "Language Modeling and Understanding Through Paraphrase Generation and Detection",
    "authors": "Jan Philip Wahle",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08274v1",
    "source": "arXiv",
    "abstract": "Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphrase. Modeling paraphrases is a keystone to meaning in computational language models; being able to construct different variations of texts that convey the same meaning or not shows strong abilities of semantic understanding. If computational language models are to represent meaning, they must understand and control the different aspects that construct the same meaning as opposed to different meanings at a fine granularity. Yet most existing approaches reduce paraphrasing to a binary decision between two texts or to producing a single rewrite of a source, obscuring which linguistic factors are responsible for meaning preservation. In this thesis, I propose that decomposing paraphrases into their constituent linguistic aspects (paraphrase types) offers a more fine-grained and cognitively grounded view of semantic equivalence. I show that even advanced machine learning models struggle with this task. Yet, when explicitly trained on paraphrase types, models achieve stronger performance on related paraphrase tasks and downstream applications. For example, in plagiarism detection, language models trained on paraphrase types surpass human baselines: 89.6% accuracy compared to 78.4% for plagiarism cases from Wikipedia, and 66.5% compared to 55.7% for plagiarism of scientific papers from arXiv. In identifying duplicate questions on Quora, models trained with paraphrase types improve over models trained on binary pairs. Furthermore, I demonstrate that..."
  },
  {
    "date": "2026-02-09",
    "title": "When Do Multi-Agent Systems Outperform? Analysing the Learning Efficiency of Agentic Systems",
    "authors": "Junwei Su, Chuan Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08272v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning (RL) has emerged as a crucial method for training or fine-tuning large language models (LLMs), enabling adaptive, task-specific optimizations through interactive feedback. Multi-Agent Reinforcement Learning (MARL), in particular, offers a promising avenue by decomposing complex tasks into specialized subtasks learned by distinct interacting agents, potentially enhancing the ability and efficiency of LLM systems. However, theoretical insights regarding when and why MARL outperforms Single-Agent RL (SARL) remain limited, creating uncertainty in selecting the appropriate RL framework. In this paper, we address this critical gap by rigorously analyzing the comparative sample efficiency of MARL and SARL within the context of LLM. Leveraging the Probably Approximately Correct (PAC) framework, we formally define SARL and MARL setups for LLMs, derive explicit sample complexity bounds, and systematically characterize how task decomposition and alignment influence learning efficiency. Our results demonstrate that MARL improves sample complexity when tasks naturally decompose into independent subtasks, whereas dependent subtasks diminish MARL's comparative advantage. Additionally, we introduce and analyze the concept of task alignment, quantifying the trade-offs when enforcing independent task decomposition despite potential misalignments. These theoretical insights clarify empirical inconsistencies and provide practical criteria for deploying MARL strategies effectively in complex LLM scenarios."
  },
  {
    "date": "2026-02-09",
    "title": "A few-shot and physically restorable symbolic regression turbulence model based on normalized general effective-viscosity hypothesis",
    "authors": "Ziqi Ji, Penghao Duan, Gang Du",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08270v1",
    "source": "arXiv",
    "abstract": "Turbulence is a complex, irregular flow phenomenon ubiquitous in natural processes and engineering applications. The Reynolds-averaged Navier-Stokes (RANS) method, owing to its low computational cost, has become the primary approach for rapid simulation of engineering turbulence problems. However, the inaccuracy of classical turbulence models constitutes the main drawback of the RANS framework. With the rapid development of data-driven approaches, many data-driven turbulence models have been proposed, yet they still suffer from issues of generalizability and accuracy. In this work, we propose a few-shot, physically restorable, symbolic regression turbulence model based on the normalized general effective-viscosity hypothesis. Few-shot indicates that our model is trained on limited flow configurations spanning only a narrow subset of turbulent flow physics, yet can still outperform the baseline model in substantially different turbulent flows. Physically restorable means our model can nearly revert to the baseline model in regimes satisfying specific physical conditions, using only the symbolic regression training results. The normalized general effective-viscosity hypothesis was proposed in our previous study. Specifically, we first formalize the concept of few-shot data-driven turbulence models. Second, we train our symbolic regression turbulence models using only direct numerical simulation (DNS) data for three-dimensional periodic hill flow slices. Third, we evaluate our models on periodic hill flows, zero pressure gradient flat plate flow, NACA0012 airfoil flows, and NASA Rotor 37 transonic axial compressor flows. One of our symbolic regression turbulence models consistently outperforms the baseline model, and we further demonstrate that this model can nearly revert to baseline behavior in certain flow regimes."
  },
  {
    "date": "2026-02-09",
    "title": "Quantization-aware Photonic Homodyne computing for Accelerated Artificial Intelligence and Scientific Simulation",
    "authors": "Lian Zhou, Kaiwen Xue, Amirhossein Fallah, Lijin Liu, Chun-Ho Lee, Kiwon Kwon, Clayton Cheung, Yuan Li, Yue Yu, Yun-Jhu Lee, Songlin Zhao, Ryan Hamerly, Edo Waks, Dirk Englund, Constantine Sideris, Mengjie Yu, Zaijun Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08269v1",
    "source": "arXiv",
    "abstract": "Modern problems in high-performance computing, ranging from training and inferencing deep learning models in computer vision and language models to simulating complex physical systems with nonlinearly-coupled equations, require exponential growth of computational resources. Photonic analog systems are emerging with solutions of intrinsic parallelism, high bandwidth, and low propagation loss. However, their application has been hindered by the low analog accuracy due to the electro-optic distortion, material nonlinearities, and signal-to-noise ratios. Here we overcome this barrier with a quantization-aware digital-photonic mixed-precision framework across chiplets for accelerated AI processing and physical simulation. Using Lithium Niobate photonics with channel equalization techniques, we demonstrate linear multiplication (9-bit amplitude-phase decoupling) in homodyne optical logics with 6-bit precision at the clock rate of 128 giga-symbol-per-second (128 GS/s), enabling AI processing with 6 ns latency. Codesign hardware-algorithms, including iterative solvers, sparse-dense quantization, and bit-sliced matrix multiplication, explore photonic amplitude and phase coherence for complex-valued, physics-inspired computation. In electromagnetic problems, our approach yields 12-bit solutions for partial differential equations (PDEs) in scattering problems that would conventionally require up to 32-bit and often even 64-bit precision. These results preserve digital-level fidelity while leveraging the high-speed low-energy photonic hardware, establishing a pathway toward general-purpose optical acceleration for generative artificial intelligence, real-time robotics, and accurate simulation for climate challenges and biological discoveries."
  },
  {
    "date": "2026-02-09",
    "title": "Stochastic many-body perturbation theory for high-order calculations",
    "authors": "Xin Zhen, Rongzhe Hu, Junchen Pei, Furong Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08265v1",
    "source": "arXiv",
    "abstract": "High-order perturbative $\\textit{ab initio}$ calculations are challenging due to the rapidly growing configuration space and the difficulty of assessing convergence. In this work, we introduce perturbation theory quantum Monte Carlo (PTQMC), a stochastic approach designed to compute high-order many-body perturbative corrections. By representing the perturbative wave function with random walkers in configuration space, PTQMC avoids the exponential scaling inherent to conventional constructions of high-rank excitation operators. Benchmark calculations for the Richardson pairing model demonstrate that PTQMC accurately reproduces exact many-body perturbation theory (MBPT) coefficients up to 16th order, even in strongly divergent regimes. We further show that combining PTQMC with series resummation techniques yields stable and precise energy estimates in cases where the straightforward perturbative series fails. Finally, we propose the effective number of configurations, $e^{S}$, as a global measure of perturbative wave-function complexity that can be directly extracted within PTQMC. We demonstrate that the saturation behavior of $e^{S}$ provides a more reliable indicator of the validity of perturbative expansions than energy convergence alone."
  },
  {
    "date": "2026-02-09",
    "title": "Constraint-Aware Generative Auto-bidding via Pareto-Prioritized Regret Optimization",
    "authors": "Binglin Wu, Yingyi Zhang, Xianneng Li, Ruyue Deng, Chuan Yue, Weiru Zhang, Xiaoyi Zeng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08261v1",
    "source": "arXiv",
    "abstract": "Auto-bidding systems aim to maximize marketing value while satisfying strict efficiency constraints such as Target Cost-Per-Action (CPA). Although Decision Transformers provide powerful sequence modeling capabilities, applying them to this constrained setting encounters two challenges: 1) standard Return-to-Go conditioning causes state aliasing by neglecting the cost dimension, preventing precise resource pacing; and 2) standard regression forces the policy to mimic average historical behaviors, thereby limiting the capacity to optimize performance toward the constraint boundary. To address these challenges, we propose PRO-Bid, a constraint-aware generative auto-bidding framework based on two synergistic mechanisms: 1) Constraint-Decoupled Pareto Representation (CDPR) decomposes global constraints into recursive cost and value contexts to restore resource perception, while reweighting trajectories based on the Pareto frontier to focus on high-efficiency data; and 2) Counterfactual Regret Optimization (CRO) facilitates active improvement by utilizing a global outcome predictor to identify superior counterfactual actions. By treating these high-utility outcomes as weighted regression targets, the model transcends historical averages to approach the optimal constraint boundary. Extensive experiments on two public benchmarks and online A/B tests demonstrate that PRO-Bid achieves superior constraint satisfaction and value acquisition compared to state-of-the-art baselines."
  },
  {
    "date": "2026-02-09",
    "title": "Towards Optimal Semantic Communications: Reconsidering the Role of Semantic Feature Channels",
    "authors": "Yongjeong Oh, Jihong Park, Jinho Choi, Yo-Seb Jeon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08260v1",
    "source": "arXiv",
    "abstract": "This paper investigates the optimization of transmitting the encoder outputs, termed semantic features (SFs), in semantic communication (SC). We begin by modeling the entire communication process from the encoder output to the decoder input, encompassing the physical channel and all transceiver operations, as the SF channel, thereby establishing an encoder-SF channel-decoder pipeline. In contrast to prior studies that assume a fixed SF channel, we note that the SF channel is configurable, as its characteristics are shaped by various transmission and reception strategies, such as power allocation. Based on this observation, we formulate the SF channel optimization problem under a mutual information constraint between the SFs and their reconstructions, and analytically derive the optimal SF channel under a linear encoder-decoder structure and Gaussian source assumption. Building upon this theoretical foundation, we propose a joint optimization framework for the encoder-decoder and SF channel, applicable to both analog and digital SCs. To realize the optimized SF channel, we also propose a physical-layer calibration strategy that enables real-time power control and adaptation to varying channel conditions. Simulation results demonstrate that the proposed SF channel optimization achieves superior task performance under various communication environments."
  },
  {
    "date": "2026-02-09",
    "title": "Modules of minimal multiplicity over one-dimensional Cohen-Macaulay local rings",
    "authors": "Ela Celikbas, Olgur Celikbas, Naoki Endo, Shinya Kumashiro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08258v1",
    "source": "arXiv",
    "abstract": "We study finitely generated modules of minimal multiplicity, a notion introduced by Puthenpurakal that extends the classical concept of minimal multiplicity from rings to modules. Our main result characterizes when trace ideals or reflexive ideals yield modules of minimal multiplicity over one-dimensional Cohen-Macaulay local rings. As a consequence, we show that a one-dimensional non-Gorenstein reduced local ring with a canonical module has minimal multiplicity if and only if its canonical module has minimal multiplicity as a module. We also construct several examples and compare them with Burch and Ulrich modules, highlighting cases where minimal multiplicity coincides with the Burch or Ulrich property."
  },
  {
    "date": "2026-02-09",
    "title": "Quo vadis biophotonics? Wearing serendipity and slow science as a badge of pride, and embracing biology",
    "authors": "G. E. Schroeder-Turk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08256v1",
    "source": "arXiv",
    "abstract": "This article is a reflection on the themes of the Faraday Discussion meeting on \"Biological and bio-inspired optics\" held from 20 to 22 July 2020. It is a personal perspective on the nature of this field as a broad and interdisciplinary field that has led to a sound understanding of the material properties of biological nanostructured and optical materials. The article describes how the nature of the field and the themes of the conference are reflected in particular in work on the 3D bicontinuous biophotonic nanostructures known as single gyroids and in bicontinuous structures more broadly. Such single gyroid materials are found for example in the butterfly Thecla opisena, where the questions of biophotonic response, of bio-inspired optics, of the relationship between structure and function, and of the relationship between natural and synthetic realisations are closely interlinked. This multitude of facets of research on single gyroid structures reflects the beauty of the broader field of biophotonics, namely as a field that lives through embracing the serendipitous discovery of the biophotonic marvels that nature offers to us as seeds for in-depth analysis and understanding. The meandering nature of its discoveries, and the need to accept the slowness that comes from exploration of intellectually new or foreign territory, mean that the field shares some traits with biological evolution itself. Looking into the future, I consider that a closer engagement with living tissue and with the biological questions of function and formation, rather than with the materials science of biological materials, will help ensure the continuing great success of this field."
  },
  {
    "date": "2026-02-09",
    "title": "Mixing properties of bi-disperse ellipsoid assemblies: Mean-field behaviour in a granular matter experiment",
    "authors": "F. M. Schaller, H. Punzmann, G. E. Schröder-Turk, M. Saadatfar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08250v1",
    "source": "arXiv",
    "abstract": "The structure and spatial statistical properties of amorphous ellipsoid assemblies have profound scientific and industrial significance in many systems, from cell assays to granular materials. This paper uses a fundamental theoretical relationship for mixture distributions to explain the observations of an extensive X-ray computed tomography study of granular ellipsoidal packings. We study a size-bi-disperse mixture of two types of ellipsoids of revolutions that have the same aspect ratio of alpha approximately equal to 0.57 and differ in size, by about 10% in linear dimension, and compare these to mono-disperse systems of ellipsoids with the same aspect ratio. Jammed configurations with a range of packing densities are achieved by employing different tapping protocols. We numerically interrogate the final packing configurations by analyses of the local packing fraction distributions calculated from the Voronoi diagrams. Our main finding is that the bi-disperse ellipsoidal packings studied here can be interpreted as a mixture of two uncorrelated mono-disperse packings, insensitive to the compaction protocol. Our results are consolidated by showing that the local packing fraction shows no correlation beyond their first shell of neighbours in the binary mixtures. We propose a model of uncorrelated binary mixture distribution that describes the observed experimental data with high accuracy. This analysis framework will enable future studies to test whether the observed mean-field behaviour is specific to the particular granular system or the specific parameter values studied here or if it is observed more broadly in other bi-disperse non-spherical particle systems."
  },
  {
    "date": "2026-02-09",
    "title": "Relating visual attention and learning in an online instructional physics module",
    "authors": "Razan Hamed, N. Sanjay Rebello, Jeremy Munsell",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08247v1",
    "source": "arXiv",
    "abstract": "Learning using Computer-Assisted Instruction (CAI) demands a high level of attention given the tendency to be distracted and mind-wander. How does the online STEM instructor know when learners are having attentional problems and the extent to which these problems affect learning? In the present study, the visual attentional and cognitive state of physics graduate students were probed while they went through a multimedia instructional module to refresh their knowledge of Newton's II Law. Data from an eye tracker, webcam, egocentric glasses, screen recording, and mouse and keyboard events were integrated to record learners' attention overt attention to the learning environment (+/-) and thinking about learning content (+/-) to analyze students' attention spans during learning from this module. On average, learners were found to be on-task and on-screen for a vast majority of time, with evidence of mind wandering. The learning module improved the participants efficiency with which they answered the questions correctly on a post-test relative to the pre-test. Further, there is a positive albeit statistically non-significant correlation between the improvement from pre- to post-test efficiency and the time spent on-screen and on-task during the module."
  },
  {
    "date": "2026-02-09",
    "title": "STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction",
    "authors": "Jinhao Li, Yuxuan Cong, Yingqiao Wang, Hao Xia, Shan Huang, Yijia Zhang, Ningyi Xu, Guohao Dai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08245v1",
    "source": "arXiv",
    "abstract": "Diffusion policies have recently emerged as a powerful paradigm for visuomotor control in robotic manipulation due to their ability to model the distribution of action sequences and capture multimodality. However, iterative denoising leads to substantial inference latency, limiting control frequency in real-time closed-loop systems. Existing acceleration methods either reduce sampling steps, bypass diffusion through direct prediction, or reuse past actions, but often struggle to jointly preserve action quality and achieve consistently low latency. In this work, we propose STEP, a lightweight spatiotemporal consistency prediction mechanism to construct high-quality warm-start actions that are both distributionally close to the target action and temporally consistent, without compromising the generative capability of the original diffusion policy. Then, we propose a velocity-aware perturbation injection mechanism that adaptively modulates actuation excitation based on temporal action variation to prevent execution stall especially for real-world tasks. We further provide a theoretical analysis showing that the proposed prediction induces a locally contractive mapping, ensuring convergence of action errors during diffusion refinement. We conduct extensive evaluations on nine simulated benchmarks and two real-world tasks. Notably, STEP with 2 steps can achieve an average 21.6% and 27.5% higher success rate than BRIDGER and DDIM on the RoboMimic benchmark and real-world tasks, respectively. These results demonstrate that STEP consistently advances the Pareto frontier of inference latency and success rate over existing methods."
  },
  {
    "date": "2026-02-09",
    "title": "SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning",
    "authors": "Peng Xia, Jianwen Chen, Hanyang Wang, Jiaqi Liu, Kaide Zeng, Yu Wang, Siwei Han, Yiyang Zhou, Xujiang Zhao, Haifeng Chen, Zeyu Zheng, Cihang Xie, Huaxiu Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08234v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM) agents have shown stunning results in complex tasks, yet they often operate in isolation, failing to learn from past experiences. Existing memory-based methods primarily store raw trajectories, which are often redundant and noise-heavy. This prevents agents from extracting high-level, reusable behavioral patterns that are essential for generalization. In this paper, we propose SkillRL, a framework that bridges the gap between raw experience and policy improvement through automatic skill discovery and recursive evolution. Our approach introduces an experience-based distillation mechanism to build a hierarchical skill library SkillBank, an adaptive retrieval strategy for general and task-specific heuristics, and a recursive evolution mechanism that allows the skill library to co-evolve with the agent's policy during reinforcement learning. These innovations significantly reduce the token footprint while enhancing reasoning utility. Experimental results on ALFWorld, WebShop and seven search-augmented tasks demonstrate that SkillRL achieves state-of-the-art performance, outperforming strong baselines over 15.3% and maintaining robustness as task complexity increases. Code is available at this https://github.com/aiming-lab/SkillRL."
  },
  {
    "date": "2026-02-09",
    "title": "Tutti: Expressive Multi-Singer Synthesis via Structure-Level Timbre Control and Vocal Texture Modeling",
    "authors": "Jiatao Chen, Xing Tang, Xiaoyue Duan, Yutang Feng, Jinchao Zhang, Jie Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08233v1",
    "source": "arXiv",
    "abstract": "While existing Singing Voice Synthesis systems achieve high-fidelity solo performances, they are constrained by global timbre control, failing to address dynamic multi-singer arrangement and vocal texture within a single song. To address this, we propose Tutti, a unified framework designed for structured multi-singer generation. Specifically, we introduce a Structure-Aware Singer Prompt to enable flexible singer scheduling evolving with musical structure, and propose Complementary Texture Learning via Condition-Guided VAE to capture implicit acoustic textures (e.g., spatial reverberation and spectral fusion) that are complementary to explicit controls. Experiments demonstrate that Tutti excels in precise multi-singer scheduling and significantly enhances the acoustic realism of choral generation, offering a novel paradigm for complex multi-singer arrangement. Audio samples are available at https://annoauth123-ctrl.github.io/Tutii_Demo/."
  },
  {
    "date": "2026-02-09",
    "title": "Generating Adversarial Events: A Motion-Aware Point Cloud Framework",
    "authors": "Hongwei Ren, Youxin Jiang, Qifei Gu, Xiangqian Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08230v1",
    "source": "arXiv",
    "abstract": "Event cameras have been widely adopted in safety-critical domains such as autonomous driving, robotics, and human-computer interaction. A pressing challenge arises from the vulnerability of deep neural networks to adversarial examples, which poses a significant threat to the reliability of event-based systems. Nevertheless, research into adversarial attacks on events is scarce. This is primarily due to the non-differentiable nature of mainstream event representations, which hinders the extension of gradient-based attack methods. In this paper, we propose MA-ADV, a novel \\textbf{M}otion-\\textbf{A}ware \\textbf{Adv}ersarial framework. To the best of our knowledge, this is the first work to generate adversarial events by leveraging point cloud representations. MA-ADV accounts for high-frequency noise in events and employs a diffusion-based approach to smooth perturbations, while fully leveraging the spatial and temporal relationships among events. Finally, MA-ADV identifies the minimal-cost perturbation through a combination of sample-wise Adam optimization, iterative refinement, and binary search. Extensive experimental results validate that MA-ADV ensures a 100\\% attack success rate with minimal perturbation cost, and also demonstrate enhanced robustness against defenses, underscoring the critical security challenges facing future event-based perception systems."
  },
  {
    "date": "2026-02-09",
    "title": "Investigating Writing Professionals' Relationships with Generative AI: How Combined Perceptions of Rivalry and Collaboration Shape Work Practices and Outcomes",
    "authors": "Rama Adithya, Varanasi, Nov, Oded, Wiesenfeld, Batia Mishan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08227v1",
    "source": "arXiv",
    "abstract": "This study investigates how professional writers' complex relationship with GenAI shapes their work practices and outcomes. Through a cross-sectional survey with writing professionals (n=403) in diverse roles, we show that collaboration and rivalry orientation are associated with differences in work practices and outcomes. Rivalry is primarily associated with relational crafting and skill maintenance. Collaboration is primarily associated with task crafting, productivity, and satisfaction, at the cost of long-term skill deterioration. Combination of the orientations (high rivalry and high collaboration) reconciles these differences, while boosting the association with the outcomes. Our findings argue for a balanced approach where high levels of rivalry and collaboration are essential to shape work practices and generate outcomes aimed at the long-term success of the job. We present key design implications on how to increase friction (rivalry) and reduce over-reliance (collaboration) to achieve a more balanced relationship with GenAI."
  },
  {
    "date": "2026-02-09",
    "title": "ByteHouse: A Cloud-Native OLAP Engine with Incremental Computation and Multi-Modal Retrieval",
    "authors": "Yuxing Han, Yu Lin, Yifeng Dong, Xuanhe Zhou, Xindong Peng, Xinhui Tian, Zhiyuan You, Yingzhong Guo, Xi Chen, Weiping Qu, Tao Meng, Dayue Gao, Haoyu Wang, Liuxi Wei, Huanchen Zhang, Fan Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08226v1",
    "source": "arXiv",
    "abstract": "With the rapid rise of intelligent data services, modern enterprises increasingly require efficient, multimodal, and cost-effective data analytics infrastructures. However, in ByteDance's production environments, existing systems fall short due to limitations such as I/O-inefficient multimodal storage, inflexible query optimization (e.g., failing to optimize multimodal access patterns), and performance degradation caused by resource disaggregation (e.g., loss of data locality in remote storage). To address these challenges, we introduce ByteHouse (https://bytehouse.cloud), a cloud-native data warehouse designed for real-time multimodal data analytics. The storage layer integrates a unified table engine that provides a two-tier logical abstraction and physically consistent layout, SSD-backed cluster-scale cache (CrossCache) that supports shared caching across compute nodes, and virtual file system (NexusFS) that enable efficient local access on compute nodes. The compute layer supports analytical, batch, and incremental execution modes, with tailored optimizations for hybrid queries (e.g., runtime filtering over tiered vector indexes). The control layer coordinates global metadata and transactions, and features an effective optimizer enhanced by historical execution traces and AI-assisted plan selection. Evaluations on internal and standard workloads show that ByteHouse achieves significant efficiency improvement over existing systems."
  },
  {
    "date": "2026-02-09",
    "title": "Constitutive flow law for hydrogel granular rafts near the brittle-ductile transition",
    "authors": "Yuto Sasaki, Hiroaki Katsuragi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08217v1",
    "source": "arXiv",
    "abstract": "Spatially varying flow laws have been identified in dry granular flow, yet their applicability to unjammed suspensions remains unclear. This study demonstrates that the quasistatic suspension flow combines dry granular rheology with nonlocal effects in the shear band and damped viscous flow in the outer creep region. Through rotary shear experiments on a hydrogel granular raft, we observe that the flow decays from the interface in the quasistatic regime, where the particles remain mobile even below the yield stress. These findings suggest the universal flow law across the transition between jammed/brittle granular behavior and unjammed/ductile viscous flow."
  },
  {
    "date": "2026-02-09",
    "title": "RECUR: Resource Exhaustion Attack via Recursive-Entropy Guided Counterfactual Utilization and Reflection",
    "authors": "Ziwei Wang, Yuanhe Zhang, Jing Chen, Zhenhong Zhou, Ruichao Liang, Ruiying Du, Ju Jia, Cong Wu, Yang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08214v1",
    "source": "arXiv",
    "abstract": "Large Reasoning Models (LRMs) employ reasoning to address complex tasks. Such explicit reasoning requires extended context lengths, resulting in substantially higher resource consumption. Prior work has shown that adversarially crafted inputs can trigger redundant reasoning processes, exposing LRMs to resource-exhaustion vulnerabilities. However, the reasoning process itself, especially its reflective component, has received limited attention, even though it can lead to over-reflection and consume excessive computing power. In this paper, we introduce Recursive Entropy to quantify the risk of resource consumption in reflection, thereby revealing the safety issues inherent in inference itself. Based on Recursive Entropy, we introduce RECUR, a resource exhaustion attack via Recursive Entropy guided Counterfactual Utilization and Reflection. It constructs counterfactual questions to verify the inherent flaws and risks of LRMs. Extensive experiments demonstrate that, under benign inference, recursive entropy exhibits a pronounced decreasing trend. RECUR disrupts this trend, increasing the output length by up to 11x and decreasing throughput by 90%. Our work provides a new perspective on robust reasoning."
  },
  {
    "date": "2026-02-09",
    "title": "DrugR: Optimizing Molecular Drugs through LLM-based Explicit Reasoning",
    "authors": "Haoran Liu, Zheni Zeng, Yukun Yan, Yuxuan Chen, Yunduo Xiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08213v1",
    "source": "arXiv",
    "abstract": "Molecule generation and optimization is a fundamental task in chemical domain. The rapid development of intelligent tools, especially large language models (LLMs) with powerful knowledge reserves and interactive capabilities, has provided new paradigms for it. Nevertheless, the intrinsic challenge for LLMs lies in the complex implicit relationship between molecular structure and pharmacological properties and the lack of corresponding labeled data. To bridge this gap, we propose DrugR, an LLM-based method that introduces explicit, step-by-step pharmacological reasoning into the optimization process. Our approach integrates domain-specific continual pretraining, supervised fine-tuning via reverse data engineering, and self-balanced multi-granular reinforcement learning. This framework enables DrugR to effectively improve key ADMET properties while preserving the original molecule's core efficacy. Experimental results demonstrate that DrugR achieves comprehensive enhancement across multiple properties without compromising structural similarity or target binding affinity. Importantly, its explicit reasoning process provides clear, interpretable rationales for each optimization step, yielding actionable design insights and advancing toward automated, knowledge-driven scientific discovery. Our code and model checkpoints are open-sourced to foster future research."
  },
  {
    "date": "2026-02-09",
    "title": "Improved Conditional Logistic Regression using Information in Concordant Pairs with Software",
    "authors": "Jacob Tennenbaum, Adam Kapelner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08212v1",
    "source": "arXiv",
    "abstract": "We develop an improvement to conditional logistic regression (CLR) in the setting where the parameter of interest is the additive effect of binary treatment effect on log-odds of the positive level in the binary response. Our improvement is simply to use information learned above the nuisance control covariates found in the concordant response pairs' observations (which is usually discarded) to create an informative prior on their coefficients. This prior is then used in the CLR which is run on the discordant pairs. Our power improvements over CLR are most notable in small sample sizes and in nonlinear log-odds-of-positive-response models. Our methods are released in an optimized R package called bclogit."
  },
  {
    "date": "2026-02-09",
    "title": "An Experimental Study on Fine-Grained Bistatic Sensing of UAV Trajectory via Cellular Downlink Signals",
    "authors": "Chenqing Ji, Jiahong Liu, Qionghui Liu, Yifei Sun, Chao Yu, Rui Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08203v1",
    "source": "arXiv",
    "abstract": "In this letter, a dual-bistatic unmanned aerial vehicles (UAVs) tracking system utilizing downlink Long-Term Evolution (LTE) signals is proposed and demonstrated. Particularly, two LTE base stations (BSs) are exploited as illumination sources. Two passive sensing receivers are deployed at different locations to detect the bistatic Doppler frequencies of the target UAV at different directions according to downlink signals transmitted from their corresponding BSs, such that the velocities of the UAV versus time can be estimated. Hence, the trajectories of the target UAV can be reconstructed. Although both the target UAV and the sensing receivers are around 200 meters away from the illuminating BSs, it is demonstrated by experiments that the tracking errors are below 50 centimeters for 90% of the complicated trajectories, when the distances between the UAV and sensing receivers are less than 30 meters. Note this accuracy is significantly better than the ranging resolution of LTE signals, high-accuracy trajectory tracking for UAV might be feasible via multi-angle bistatic Doppler measurements if the receivers are deployed with a sufficient density."
  },
  {
    "date": "2026-02-09",
    "title": "JWST spectral retrieval of cold directly imaged planet WD0806 b and the first measurement of altitude-dependent K$_{zz}$ in exoplanet atmospheres",
    "authors": "Ben W. P. Lew, Thomas Roellig, Natasha E. Batalha, Nicholas F. Wogan, Thomas Greene, Mark S. Marley, Jonathan J. Fortney, Jarron Leisenring, Doug Johnstone, Matthew De Furio, Klaus Hodapp, Charles Beichman, Marcia Rieke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08200v1",
    "source": "arXiv",
    "abstract": "WD0806 b is a rare exoplanet companion orbiting a white dwarf, currently with a projected orbital distance of 2500 au. The Spitzer mid-IR photometry suggests that the temperature is as cold as 350K, making it one of the coldest directly imaged exoplanets. In this paper, we present the Near-infrared Camera (NIRCam) F150W2, F200W, F356W, and F444W broadband photometry and a 3--5\\um Near-Infrared spectroscopy (NIRSpec) G395M spectrum obtained with the James Webb Space Telescope (JWST). We develop a new retrieval framework based on the open-source PICASO software that includes additive and multiplicative systematic parameters. Our retrieval results reveal bounded abundances of H$_2$S, CO$_2$, CO, NH$_3$, H$_2$O, and CH$_4$. We present a new chemical analysis framework that utilizes retrieved abundances to measure altitude-dependent eddy diffusion coefficients (K$_{\\mathrm zz}$) at multiple quenched pressures. We find that the eddy diffusion coefficients decrease from around $10^4$ to $10^2$ $\\rm cm^2/s$ as the atmospheric pressure decreases from from 50 to 20 bars. To our knowledge, this is the first study to report altitude-dependent vertical mixing (or, equivalently, quenched-species-dependent vertical mixing) based on the measured molecular abundances of CO, CH$_4$, and CO$_2$. With the 1--21\\um NIRCam, NIRSpec and the previously published MIRI data, we measure the bolometric luminosity to be log(L/L$_{\\odot}$) = $-6.75\\pm0.01$ and derive the mass to be $8\\pm 1 \\mathrm{M_J}$. The retrieval results suggest that \\target has an elevated C/O ratio of 0.76, or 1.3$\\times$ solar, sub-solar metallicity ([M/H ]= -0.25), and a nearly solar C/S ratio (1.17x solar)."
  },
  {
    "date": "2026-02-09",
    "title": "Fork, Explore, Commit: OS Primitives for Agentic Exploration",
    "authors": "Cong Wang, Yusheng Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08199v1",
    "source": "arXiv",
    "abstract": "AI agents increasingly perform agentic exploration: pursuing multiple solution paths in parallel and committing only the successful one. Because each exploration path may modify files and spawn processes, agents require isolated environments with atomic commit and rollback semantics for both filesystem state and process state. We introduce the branch context, a new OS abstraction that provides: (1) copy-on-write state isolation with independent filesystem views and process groups, (2) a structured lifecycle of fork, explore, and commit/abort, (3) first-commit-wins resolution that automatically invalidates sibling branches, and (4) nestable contexts for hierarchical exploration. We realize branch contexts in Linux through two complementary components. First, BranchFS is a FUSE-based filesystem that gives each branch context an isolated copy-on-write workspace, with O(1) creation, atomic commit to the parent, and automatic sibling invalidation, all without root privileges. BranchFS is open sourced in https://github.com/multikernel/branchfs. Second, branch() is a proposed Linux syscall that spawns processes into branch contexts with reliable termination, kernel-enforced sibling isolation, and first-commit-wins coordination. Preliminary evaluation of BranchFS shows sub-350 us branch creation independent of base filesystem size, and modification-proportional commit overhead (under 1 ms for small changes)."
  },
  {
    "date": "2026-02-09",
    "title": "PEGAsus: 3D Personalization of Geometry and Appearance",
    "authors": "Jingyu Hu, Bin Hu, Ka-Hei Hui, Haipeng Li, Zhengzhe Liu, Daniel Cohen-Or, Chi-Wing Fu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08198v1",
    "source": "arXiv",
    "abstract": "We present PEGAsus, a new framework capable of generating Personalized 3D shapes by learning shape concepts at both Geometry and Appearance levels. First, we formulate 3D shape personalization as extracting reusable, category-agnostic geometric and appearance attributes from reference shapes, and composing these attributes with text to generate novel shapes. Second, we design a progressive optimization strategy to learn shape concepts at both the geometry and appearance levels, decoupling the shape concept learning process. Third, we extend our approach to region-wise concept learning, enabling flexible concept extraction, with context-aware and context-free losses. Extensive experimental results show that PEGAsus is able to effectively extract attributes from a wide range of reference shapes and then flexibly compose these concepts with text to synthesize new shapes. This enables fine-grained control over shape generation and supports the creation of diverse, personalized results, even in challenging cross-category scenarios. Both quantitative and qualitative experiments demonstrate that our approach outperforms existing state-of-the-art solutions."
  },
  {
    "date": "2026-02-09",
    "title": "NeuroScaler: Towards Energy-Optimal Autoscaling for Container-Based Services",
    "authors": "Alisson O. Chaves, Rodrigo Moreira, Larissa F. Rodrigues Moreira, Joao Correia, David Santos, Rui Silva, Tiago Barros, Daniel Corujo, Miguel Rocha, Flavio de Oliveira Silva",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08191v1",
    "source": "arXiv",
    "abstract": "Future networks must meet stringent requirements while operating within tight energy and carbon constraints. Current autoscaling mechanisms remain workload-centric and infrastructure-siloed, and are largely unaware of their environmental impact. We present NeuroScaler, an AI-native, energy-efficient, and carbon-aware orchestrator for green cloud and edge networks. NeuroScaler aggregates multi-tier telemetry, from Power Distribution Units (PDUs) through bare-metal servers to virtualized infrastructure with containers managed by Kubernetes, using distinct energy and computing metrics at each tier. It supports several machine learning pipelines that link load, performance, and power. Within this unified observability layer, a model-predictive control policy optimizes energy use while meeting service-level objectives. In a real testbed with production-grade servers supporting real services, NeuroScaler reduces energy consumption by 34.68% compared to the Horizontal Pod Autoscaler (HPA) while maintaining target latency."
  },
  {
    "date": "2026-02-09",
    "title": "ZipFlow: a Compiler-based Framework to Unleash Compressed Data Movement for Modern GPUs",
    "authors": "Gwangoo Yeo, Zhiyang Shen, Wei Cui, Matteo Interlandi, Rathijit Sen, Bailu Ding, Qi Chen, Minsoo Rhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08190v1",
    "source": "arXiv",
    "abstract": "In GPU-accelerated data analytics, the overhead of data transfer from CPU to GPU becomes a performance bottleneck when the data scales beyond GPU memory capacity due to the limited PCIe bandwidth. Data compression has come to rescue for reducing the amount of data transfer while taking advantage of the powerful GPU computation for decompression. To optimize the end-to-end query performance, however, the workflow of data compression, transfer, and decompression must be holistically designed based on the compression strategies and hardware characteristics to balance the I/O latency and computational overhead. In this work, we present ZipFlow, a compiler-based framework for optimizing compressed data transfer in GPU-accelerated data analytics. ZipFlow classifies compression algorithms into three distinct patterns based on their inherent parallelism. For each pattern, ZipFlow employs generalized scheduling strategies to effectively exploit the computational power of GPUs across diverse architectures. Building on these patterns, ZipFlow delivers flexible, high-performance, and holistic optimization, which substantially advances end-to-end data transfer capabilities. We evaluate the effectiveness of ZipFlow on industry-standard benchmark, TPC-H. Overall, ZipFlow achieves an average improvement of 2.08 times over the state-of-the-art GPU compression library (nvCOMP) and 3.14 times speedup against CPU-based query processing engines (e.g., DuckDB)."
  },
  {
    "date": "2026-02-09",
    "title": "Nansde-net: A neural sde framework for generating time series with memory",
    "authors": "Hiromu Ozai, Kei Nakagawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08182v1",
    "source": "arXiv",
    "abstract": "Modeling time series with long- or short-memory characteristics is a fundamental challenge in many scientific and engineering domains. While fractional Brownian motion has been widely used as a noise source to capture such memory effects, its incompatibility with Itô calculus limits its applicability in neural stochastic differential equation~(SDE) frameworks. In this paper, we propose a novel class of noise, termed Neural Network-kernel ARMA-type noise~(NA-noise), which is an Itô-process-based alternative capable of capturing both long- and short-memory behaviors. The kernel function defining the noise structure is parameterized via neural networks and decomposed into a product form to preserve the Markov property. Based on this noise process, we develop NANSDE-Net, a generative model that extends Neural SDEs by incorporating NA-noise. We prove the theoretical existence and uniqueness of the solution under mild conditions and derive an efficient backpropagation scheme for training. Empirical results on both synthetic and real-world datasets demonstrate that NANSDE-Net matches or outperforms existing models, including fractional SDE-Net, in reproducing long- and short-memory features of the data, while maintaining computational tractability within the Itô calculus framework."
  },
  {
    "date": "2026-02-09",
    "title": "Relations and Derivatives of Multiple Eisenstein Series",
    "authors": "Henrik Bachmann, Hayato Kanno",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08176v1",
    "source": "arXiv",
    "abstract": "In this paper, we study multiple Eisenstein series, which build a natural bridge between the theory of multiple zeta values and modular forms. We prove a large family of relations among these series and propose an explicit conjectural formula for their derivatives. This formula is expressed using the double shuffle structure and the Drop1 operator introduced by Hirose, Maesaka, Seki, and Watanabe. Based on this, we propose a family of linear relations that is conjectured to generate all linear relations among multiple Eisenstein series. Motivated by this conjecture, we introduce a space of formal multiple Eisenstein series and show that it is an $\\mathfrak{sl}_2$-algebra."
  },
  {
    "date": "2026-02-09",
    "title": "Self-Supervised Bootstrapping of Action-Predictive Embodied Reasoning",
    "authors": "Milan Ganai, Katie Luo, Jonas Frey, Clark Barrett, Marco Pavone",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08167v1",
    "source": "arXiv",
    "abstract": "Embodied Chain-of-Thought (CoT) reasoning has significantly enhanced Vision-Language-Action (VLA) models, yet current methods rely on rigid templates to specify reasoning primitives (e.g., objects in the scene, high-level plans, structural affordances). These templates can force policies to process irrelevant information that distracts from critical action-prediction signals. This creates a bottleneck: without successful policies, we cannot verify reasoning quality; without quality reasoning, we cannot build robust policies. We introduce R&B-EnCoRe, which enables models to bootstrap embodied reasoning from internet-scale knowledge through self-supervised refinement. By treating reasoning as a latent variable within importance-weighted variational inference, models can generate and distill a refined reasoning training dataset of embodiment-specific strategies without external rewards, verifiers, or human annotation. We validate R&B-EnCoRe across manipulation (Franka Panda in simulation, WidowX in hardware), legged navigation (bipedal, wheeled, bicycle, quadruped), and autonomous driving embodiments using various VLA architectures with 1B, 4B, 7B, and 30B parameters. Our approach achieves 28% gains in manipulation success, 101% improvement in navigation scores, and 21% reduction in collision-rate metric over models that indiscriminately reason about all available primitives. R&B-EnCoRe enables models to distill reasoning that is predictive of successful control, bypassing manual annotation engineering while grounding internet-scale knowledge in physical execution."
  },
  {
    "date": "2026-02-09",
    "title": "Black Flower Microstates",
    "authors": "Suvankar Dutta, Shruti Menon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08777v1",
    "source": "arXiv",
    "abstract": "We investigate stationary, non-axisymmetric black hole solutions in AdS$_3$ gravity, known as black flower geometries, in the Chern-Simons formulation. Boundary conditions are specified by a collective field theory-inspired Hamiltonian with field-dependent chemical potentials and angularly inhomogeneous boundary data. We construct a tractable class of solutions and analyze their geometric and thermodynamic properties, obtaining an entropy with nontrivial dependence on the angular deformation. Upon quantization of the boundary theory via bosonization, the boundary degrees of freedom are mapped to relativistic free fermions. We explicitly construct and count the microstates associated with a given black flower geometry and find exact agreement with the Bekenstein-Hawking entropy."
  },
  {
    "date": "2026-02-09",
    "title": "Mind the Gap: Learning Implicit Impedance in Visuomotor Policies via Intent-Execution Mismatch",
    "authors": "Cuijie Xu, Shurui Zheng, Zihao Su, Yuanfan Xu, Tinghao Yi, Xudong Zhang, Jian Wang, Yu Wang, Jinchen Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08776v1",
    "source": "arXiv",
    "abstract": "Teleoperation inherently relies on the human operator acting as a closed-loop controller to actively compensate for hardware imperfections, including latency, mechanical friction, and lack of explicit force feedback. Standard Behavior Cloning (BC), by mimicking the robot's executed trajectory, fundamentally ignores this compensatory mechanism. In this work, we propose a Dual-State Conditioning framework that shifts the learning objective to \"Intent Cloning\" (master command). We posit that the Intent-Execution Mismatch, the discrepancy between master command and slave response, is not noise, but a critical signal that physically encodes implicit interaction forces and algorithmically reveals the operator's strategy for overcoming system dynamics. By predicting the master intent, our policy learns to generate a \"virtual equilibrium point\", effectively realizing implicit impedance control. Furthermore, by explicitly conditioning on the history of this mismatch, the model performs implicit system identification, perceiving tracking errors as external forces to close the control loop. To bridge the temporal gap caused by inference latency, we further formulate the policy as a trajectory inpainter to ensure continuous control. We validate our approach on a sensorless, low-cost bi-manual setup. Empirical results across tasks requiring contact-rich manipulation and dynamic tracking reveal a decisive gap: while standard execution-cloning fails due to the inability to overcome contact stiffness and tracking lag, our mismatch-aware approach achieves robust success. This presents a minimalist behavior cloning framework for low-cost hardware, enabling force perception and dynamic compensation without relying on explicit force sensing. Videos are available on the \\href{https://xucj98.github.io/mind-the-gap-page/}{project page}."
  },
  {
    "date": "2026-02-09",
    "title": "VedicTHG: Symbolic Vedic Computation for Low-Resource Talking-Head Generation in Educational Avatars",
    "authors": "Vineet Kumar Rakesh, Ahana Bhattacharjee, Soumya Mazumdar, Tapas Samanta, Hemendra Kumar Pandey, Amitabha Das, Sarbajit Pal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08775v1",
    "source": "arXiv",
    "abstract": "Talking-head avatars are increasingly adopted in educational technology to deliver content with social presence and improved engagement. However, many recent talking-head generation (THG) methods rely on GPU-centric neural rendering, large training sets, or high-capacity diffusion models, which limits deployment in offline or resource-constrained learning environments. A deterministic and CPU-oriented THG framework is described, termed Symbolic Vedic Computation, that converts speech to a time-aligned phoneme stream, maps phonemes to a compact viseme inventory, and produces smooth viseme trajectories through symbolic coarticulation inspired by Vedic sutra Urdhva Tiryakbhyam. A lightweight 2D renderer performs region-of-interest (ROI) warping and mouth compositing with stabilization to support real-time synthesis on commodity CPUs. Experiments report synchronization accuracy, temporal stability, and identity consistency under CPU-only execution, alongside benchmarking against representative CPU-feasible baselines. Results indicate that acceptable lip-sync quality can be achieved while substantially reducing computational load and latency, supporting practical educational avatars on low-end hardware. GitHub: https://vineetkumarrakesh.github.io/vedicthg"
  },
  {
    "date": "2026-02-09",
    "title": "Default Machine Learning Hyperparameters Do Not Provide Informative Initialization for Bayesian Optimization",
    "authors": "Nicolás Villagrán Prieto, Eduardo C. Garrido-Merchán",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08774v1",
    "source": "arXiv",
    "abstract": "Bayesian Optimization (BO) is a standard tool for hyperparameter tuning thanks to its sample efficiency on expensive black-box functions. While most BO pipelines begin with uniform random initialization, default hyperparameter values shipped with popular ML libraries such as scikit-learn encode implicit expert knowledge and could serve as informative starting points that accelerate convergence. This hypothesis, despite its intuitive appeal, has remained largely unexamined. We formalize the idea by initializing BO with points drawn from truncated Gaussian distributions centered at library defaults and compare the resulting trajectories against a uniform-random baseline. We conduct an extensive empirical evaluation spanning three BO back-ends (BoTorch, Optuna, Scikit-Optimize), three model families (Random Forests, Support Vector Machines, Multilayer Perceptrons), and five benchmark datasets covering classification and regression tasks. Performance is assessed through convergence speed and final predictive quality, and statistical significance is determined via one-sided binomial tests. Across all conditions, default-informed initialization yields no statistically significant advantage over purely random sampling, with p-values ranging from 0.141 to 0.908. A sensitivity analysis on the prior variance confirms that, while tighter concentration around the defaults improves early evaluations, this transient benefit vanishes as optimization progresses, leaving final performance unchanged. Our results provide no evidence that default hyperparameters encode useful directional information for optimization. We therefore recommend that practitioners treat hyperparameter tuning as an integral part of model development and favor principled, data-driven search strategies over heuristic reliance on library defaults."
  },
  {
    "date": "2026-02-09",
    "title": "Small Rarefaction, Large Consequences: Limits of Navier Stokes Turbulence Simulations",
    "authors": "Songyan Tian, Lei Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08770v1",
    "source": "arXiv",
    "abstract": "We conduct numerical simulations of rocket plume impingement on a lunar landing surface using two complementary frameworks: the Boltzmann equation, which naturally captures rarefied gas dynamics, and the Navier Stokes (NS) equations, the conventional workhorse for turbulent flow simulations. We show that subtle rarefaction effects, long considered negligible in turbulent regimes, can become locally dominant within shear layers where viscous stresses predicted by the NS constitutive relation undergo sign reversals. This phenomenon, which we term constitutive degeneracy, produces order-one relative errors in predicted surface shear stress and heat flux. Our results demonstrate that turbulence can expose hidden limits of NS equations with broad implications for high-speed aerodynamics and planetary exploration."
  },
  {
    "date": "2026-02-09",
    "title": "Efficient Brain Extraction of MRI Scans with Mild to Moderate Neuropathology",
    "authors": "Hjalti Thrastarson, Lotta M. Ellingsen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08764v1",
    "source": "arXiv",
    "abstract": "Skull stripping magnetic resonance images (MRI) of the human brain is an important process in many image processing techniques, such as automatic segmentation of brain structures. Numerous methods have been developed to perform this task, however, they often fail in the presence of neuropathology and can be inconsistent in defining the boundary of the brain mask. Here, we propose a novel approach to skull strip T1-weighted images in a robust and efficient manner, aiming to consistently segment the outer surface of the brain, including the sulcal cerebrospinal fluid (CSF), while excluding the full extent of the subarachnoid space and meninges. We train a modified version of the U-net on silver-standard ground truth data using a novel loss function based on the signed-distance transform (SDT). We validate our model both qualitatively and quantitatively using held-out data from the training dataset, as well as an independent external dataset. The brain masks used for evaluation partially or fully include the subarachnoid space, which may introduce bias into the comparison; nonetheless, our model demonstrates strong performance on the held-out test data, achieving a consistent mean Dice similarity coefficient (DSC) of 0.964$\\pm$0.006 and an average symmetric surface distance (ASSD) of 1.4mm$\\pm$0.2mm. Performance on the external dataset is comparable, with a DSC of 0.958$\\pm$0.006 and an ASSD of 1.7$\\pm$0.2mm. Our method achieves performance comparable to or better than existing state-of-the-art methods for brain extraction, particularly in its highly consistent preservation of the brain's outer surface. The method is publicly available on GitHub."
  },
  {
    "date": "2026-02-09",
    "title": "Germanium Thermophotovoltaic Devices Achieving 7.3% Efficiency Under High-Temperature Emission by Empirical Calorimetry",
    "authors": "A. M. Medrano, E. Lopez, Pablo Garcia-Linares, J. Villa, M. Gamel, M. Garin, I. Martin, C. Canizo, A. Datas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08761v1",
    "source": "arXiv",
    "abstract": "We report the first empirical efficiency measurement of germanium-based thermophotovoltaic devices under high-temperature, high-irradiance conditions using a high view-factor calorimetric setup. Two TPV cell architectures were fabricated on p-type, highly doped (10^17 cm-3) Ge substrates, differing only in rear contact configuration. A standard device with a gold rear contact achieves a peak efficiency of 7.3 % and a power density of 1.77 W/cm2 at an emitter temperature of 1480 C, while a PERC-type device reaches 6.3 % efficiency and 1.22 W/cm2 at 1426 C. The superior performance of the standard device is attributed to lower series resistance, whereas the PERC design exhibits slightly higher efficiency at lower emitter temperatures (4.0 % vs. 3.8 % at 1150 C) due to enhanced rear-surface reflectivity. A detailed TPV model has been developed and validated across both device architectures. The model identifies out-of-band optical losses as the dominant efficiency-limiting mechanism, primarily caused by strong free-carrier absorption in the highly doped Ge substrate. Using this model, we predict device performance under idealized spectral conditions commonly assumed in prior literature. For a simulated AlN/W spectrally selective emitter, efficiencies as high as 22.3 % at 1800 C are obtained, consistent with previous semi-empirical predictions. In contrast, when previously reported Ge devices are modeled under the realistic graphite emitter spectrum used here, projected efficiencies decrease to as low as 8.1 % at 1480 C. These results show that earlier projections remain valid but idealized and underscore the importance of emitter spectral engineering and substrate optimization. Finally, we present the first direct comparison of Ge and InGaAs TPV devices under identical conditions, demonstrating the superior performance of InGaAs while confirming the cost-driven competitiveness of Ge."
  },
  {
    "date": "2026-02-09",
    "title": "Small Seifert 3-manifolds with non-reduced $\\mathrm{SL}_2(\\mathbb{C})$-character scheme",
    "authors": "Renaud Detcherry",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08760v1",
    "source": "arXiv",
    "abstract": "We complete the work started in previous work of the author and Kalfagianni and Sikora, and give a complete description of the $\\mathrm{SL}_2(\\mathbb{C})$-character scheme $\\mathcal{X}(M)$ of all small Seifert $3$-manifolds $M$. We find that $\\mathcal{X}(M)$ is reduced if and only if $M$ admits no exceptional abelian character, and that exceptional abelian character have multiplicity $2$ in $\\mathcal{X}(M).$"
  },
  {
    "date": "2026-02-09",
    "title": "DyMA-Fuzz: Dynamic Direct Memory Access Abstraction for Re-hosted Monolithic Firmware Fuzzing",
    "authors": "Guy Farrelly, Michael Chesser, Seyit Camtepe, Damith C. Ranasinghe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08750v1",
    "source": "arXiv",
    "abstract": "The rise of smart devices in critical domains--including automotive, medical, industrial--demands robust firmware testing. Fuzzing firmware in re-hosted environments is a promising method for automated testing at scale, but remains difficult due to the tight coupling of code with a microcontroller's peripherals. Existing fuzzing frameworks primarily address input challenges in providing inputs for Memory-Mapped I/O or interrupts, but largely overlook Direct Memory Access (DMA), a key high-throughput interface used that bypasses the CPU. We introduce DyMA-Fuzz to extend recent advances in stream-based fuzz input injection to DMA-driven interfaces in re-hosted environments. It tackles key challenges--vendor-specific descriptors, heterogeneous DMA designs, and varying descriptor locations--using runtime analysis techniques to infer DMA memory access patterns and automatically inject fuzzing data into target buffers, without manual configuration or datasheets. Evaluated on 94 firmware samples and 8 DMA-guarded CVE benchmarks, DyMA-Fuzz reveals vulnerabilities and execution paths missed by state-of-the-art tools and achieves up to 122% higher code coverage. These results highlight DyMA-Fuzz as a practical and effective advancement in automated firmware testing and a scalable solution for fuzzing complex embedded systems."
  },
  {
    "date": "2026-02-09",
    "title": "Tree Pairs for Algebraic Bieri-Strebel Groups",
    "authors": "Lewis Molyneux",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08748v1",
    "source": "arXiv",
    "abstract": "We reintroduce a previously discovered method for constructing tree pair representations for Algebraic Bieri-Strebel groups, as well as demonstrate a class of higher order groups that cannot have a tree pair representation. In doing so, we demonstrate that there is no maximum degree such that for all polynomials of higher degree, the associated Algebraic Bieri Strebel group must have a tree-pair representation."
  },
  {
    "date": "2026-02-09",
    "title": "A Variational Principle for the Topological Pressure of Non-autonomous Iterated Function Systems on Subsets",
    "authors": "Yujun Ju, Lingbing Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08746v1",
    "source": "arXiv",
    "abstract": "Motivated by the notion of topological entropy for free semigroup actions introduced by Biś, we define the Pesin--Pitskel topological pressure for non-autonomous iterated function systems via the Carathéodory--Pesin structure. We show that this Pesin--Pitskel topological pressure coincides with the corresponding weighted topological pressure. Furthermore, we establish a variational principle asserting that, for any nonempty compact subset, the Pesin--Pitskel topological pressure equals the supremum of the associated measure-theoretic pressures over all Borel probability measures supported on that subset."
  },
  {
    "date": "2026-02-09",
    "title": "Preprint: Sheath thickness measurements with the biased plasma impedance probe, Agreement with Child Langmuir scaling",
    "authors": "John Whitlock Brooks, Richeek Dutta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08743v1",
    "source": "arXiv",
    "abstract": "Plasma sheaths play a central role in plasma-surface interactions, yet their thickness remains challenging to measure experimentally. Although classical analytical models such as the Child-Langmuir (CL) sheath model provide clear predictions for sheath thickness, experimental validation has been limited because most diagnostics either rely on indirect, multi-step inference (e.g., Langmuir probes) or require invasive and technically demanding techniques. In this work, we demonstrate that the plasma impedance probe (PIP), when operated with a controlled DC bias, enables relatively direct, model-informed measurements of sheath thickness that are reasonably straightforward to implement experimentally. Across a range of discharge conditions, biased-PIP sheath thickness measurements are found to follow CL scaling closely, requiring a single, consistent empirical correction factor of $α\\approx 0.74$ to reconcile the measured thickness with CL predictions. Concurrent measurements of plasma density and electron damping show that probe biasing does not significantly perturb the bulk plasma density, supporting the validity of the biased-PIP approach. Building on this validation, we leverage the empirically determined $α$ factor to extend the floating (unbiased) PIP analysis to obtain model-dependent estimates of electron temperature and plasma potential without electrical biasing. A side-by-side comparison demonstrates close agreement between floating-PIP results and those obtained from a biased Langmuir probe. Taken together, these results establish the PIP as a complementary diagnostic to the Langmuir probe, expanding the range of accessible plasma measurements while providing experimental support for classical sheath models."
  },
  {
    "date": "2026-02-09",
    "title": "Welfarist Formulations for Diverse Similarity Search",
    "authors": "Siddharth Barman, Nirjhar Das, Shivam Gupta, Kirankumar Shiragur",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08742v1",
    "source": "arXiv",
    "abstract": "Nearest Neighbor Search (NNS) is a fundamental problem in data structures with wide-ranging applications, such as web search, recommendation systems, and, more recently, retrieval-augmented generations (RAG). In such recent applications, in addition to the relevance (similarity) of the returned neighbors, diversity among the neighbors is a central requirement. In this paper, we develop principled welfare-based formulations in NNS for realizing diversity across attributes. Our formulations are based on welfare functions -- from mathematical economics -- that satisfy central diversity (fairness) and relevance (economic efficiency) axioms. With a particular focus on Nash social welfare, we note that our welfare-based formulations provide objective functions that adaptively balance relevance and diversity in a query-dependent manner. Notably, such a balance was not present in the prior constraint-based approach, which forced a fixed level of diversity and optimized for relevance. In addition, our formulation provides a parametric way to control the trade-off between relevance and diversity, providing practitioners with flexibility to tailor search results to task-specific requirements. We develop efficient nearest neighbor algorithms with provable guarantees for the welfare-based objectives. Notably, our algorithm can be applied on top of any standard ANN method (i.e., use standard ANN method as a subroutine) to efficiently find neighbors that approximately maximize our welfare-based objectives. Experimental results demonstrate that our approach is practical and substantially improves diversity while maintaining high relevance of the retrieved neighbors."
  },
  {
    "date": "2026-02-09",
    "title": "Map of Encoders -- Mapping Sentence Encoders using Quantum Relative Entropy",
    "authors": "Gaifan Zhang, Danushka Bollegala",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08740v1",
    "source": "arXiv",
    "abstract": "We propose a method to compare and visualise sentence encoders at scale by creating a map of encoders where each sentence encoder is represented in relation to the other sentence encoders. Specifically, we first represent a sentence encoder using an embedding matrix of a sentence set, where each row corresponds to the embedding of a sentence. Next, we compute the Pairwise Inner Product (PIP) matrix for a sentence encoder using its embedding matrix. Finally, we create a feature vector for each sentence encoder reflecting its Quantum Relative Entropy (QRE) with respect to a unit base encoder. We construct a map of encoders covering 1101 publicly available sentence encoders, providing a new perspective of the landscape of the pre-trained sentence encoders. Our map accurately reflects various relationships between encoders, where encoders with similar attributes are proximally located on the map. Moreover, our encoder feature vectors can be used to accurately infer downstream task performance of the encoders, such as in retrieval and clustering tasks, demonstrating the faithfulness of our map."
  },
  {
    "date": "2026-02-09",
    "title": "Moments of C$β$E field partition function, $\\mathsf{Sine}_β$ correlations and stochastic zeta",
    "authors": "Theodoros Assiotis, Joseph Najnudel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08739v1",
    "source": "arXiv",
    "abstract": "We prove a conjecture of Fyodorov and Keating on the supercritical moments of the partition function of the C$β$E field or equivalently the supercritical moments of moments of the characteristic polynomial of the C$β$E ensemble for general $β>0$ and general real moment exponents. Moreover, we give the first expression for all correlation functions of the $\\mathsf{Sine}_β$ point process for all $β>0$. The main object behind both results is the Hua-Pickrell stochastic zeta function introduced by Li and Valkó."
  },
  {
    "date": "2026-02-09",
    "title": "Cell strain-stiffening drives cell breakout from embedded spheroids",
    "authors": "Shabeeb Ameen, Kyungeun Kim, Ligesh Theeyancheri, Minh Thanh, Mingming Wu, Alison E. Patteson, J. M. Schwarz, Tao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08737v1",
    "source": "arXiv",
    "abstract": "Understanding how cells escape from embedded spheroids requires a mechanical framework linking stress generation within cells, across cells, and between cells and the surrounding extracellular matrix (ECM). We develop such a framework by coupling a 3D vertex model of a spheroid to a fibrous ECM network and deriving a 3D Cauchy stress tensor for deformable polyhedral cells, enabling direct cell-level stress quantification in three dimensions. We analyze maximum shear stress in solid-like and fluid-like spheroids: solid-like spheroids exhibit broader stress distributions and radial stress gradients, while fluid-like spheroids show lower stresses with weak spatial organization. Cell shape anisotropy is not generically aligned with principal stress directions, indicating that morphology alone is an unreliable proxy for mechanical state. We further demonstrate strain stiffening at the single-cell level, where elongation produces nonlinear increases in maximum shear stress, allowing boundary cells in otherwise low-stress, fluid-like spheroids to transiently generate forces sufficient to remodel the matrix. To connect strain-induced stress amplification to invasion modes, we introduce an extended 3D vertex model with explicit, tunable cell-cell adhesion springs. In this minimal mechanical framework, single-cell breakout results from strain stiffening combined with reduced adhesion, whereas multi-cell streaming additionally requires anisotropic adhesion strengthened along the elongation axis and weakened orthogonally. Together, these results identify distinct mechanical pathways coupling cell strain, stress amplification, and adhesion organization to spheroid invasion."
  },
  {
    "date": "2026-02-09",
    "title": "Post-Newtonian accelerations of a Mercury orbiter",
    "authors": "Miriam Falletta, Gabriel Rodríguez-Moris, Sergei A. Klioner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08720v1",
    "source": "arXiv",
    "abstract": "We investigate the relativistic modeling of spacecraft motion in Mercury's post-Newtonian local coordinates. This investigation is motivated by the fact that Mercury's post-Newtonian gravitational field (as well as that of any other planet) admits an expansion in terms of multipole moments, which are most appropriately defined in the local reference system. The equations of motion in the Mercury-centric local frame include relativistic local perturbations, given by the Schwarzschild term, Lense-Thirring precession, and the acceleration due to the quadrupole moment, and relativistic third-body perturbations, which are the gravito-electric and gravito-magnetic accelerations, along with a coupling term between Mercury and other solar system bodies. The relativistic third-body perturbations are usually neglected in all practical applications. In this study, we analyze the magnitude of the post-Newtonian terms of the equations of motion formulated in the Mercury-centric frame, evaluating them along the trajectories of the two BepiColombo spacecrafts. Based on this analysis, we provide a practical approach for constructing a high-accuracy relativistic orbital model suitable for a Mercury orbiter."
  },
  {
    "date": "2026-02-09",
    "title": "Influence of octupole field on quadrupole mass filter performance in the second stability zone",
    "authors": "Anushree Dutta, Pintu Mandal, Nabanita Deb",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08719v1",
    "source": "arXiv",
    "abstract": "Radial asymmetry in a quadrupole mass filter (QMF), introduced by symmetric displacement of a diagonally opposite rod pair, modifies the confinement potential and alters the ion stability characteristics. In this work, the influence of such radial asymmetry on QMF operation in the second stability zone is investigated through simulations. Using an existing potential formulation for a radially asymmetric QMF, the stability diagram in the second stability zone is extracted for the first time, revealing a systematic shift of the stability apex with the asymmetry parameter. Radial asymmetry introduces additional multipole components, notably an octupole term whose magnitude scales with the asymmetry parameter and whose sign depends on the DC polarity applied to the displaced rods. Transmission simulations show that the transmission peak shifts in accordance with the displaced stability apex, while the resolution exhibits a strong dependence on both the asymmetry parameter and the DC polarity. Comparable maximum resolution is obtained for inward and outward displacements under suitable polarity configurations, with outward displacement providing higher transmission efficiency due to an increased effective aperture. These results demonstrate that controlled radial asymmetry provides an effective means to tailor the resolution and transmission characteristics of QMFs operating in the second stability zone."
  },
  {
    "date": "2026-02-09",
    "title": "Technosocial risks of ideal emotion recognition technologies: A defense of the (social) value of emotional expressions",
    "authors": "Alexandra Pregent",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08706v1",
    "source": "arXiv",
    "abstract": "The prospect of AI systems that I call ideal emotion recognition technologies (ERTs) is often defended on the assumption that social life would benefit from increased affective transparency. This paper challenges that assumption by examining the technosocial risks posed by ideal ERTs, understood as multimodal systems capable of reliably inferring inner affective states in real time. Drawing on philosophical accounts of emotional expression and social practice, as well as empirical work in affective science and social psychology, I argue that the appeal of such systems rests on a misunderstanding of the social functions of emotional expression. Emotional expressions function not only as read-outs of inner states, but also as tools for coordinating action, enabling moral repair, sustaining interpersonal trust, and supporting collective norms. These functions depend on a background of partial opacity and epistemic friction. When deployed in socially authoritative or evaluative contexts, ideal ERTs threaten this expressive space by collapsing epistemic friction, displacing relational meaning with technology-mediated affective profiles, and narrowing the space for aspirational and role-sensitive expressions. The result is a drift towards affective determinism and ambient forms of affective auditing, which undermine both social cohesion and individual agency. I argue that, although it is intuitive to think that increasing accuracy would legitimise such systems, in the case of ERTs accuracy does not straightforwardly justify their deployment, and may, in some contexts, provide a reason for regulatory restraint. I conclude by defending a function-first regulatory approach that treats expressive discretion and intentional emotional expression as constitutive of certain social goods, and that accordingly seeks to protect these goods from excessive affective legibility."
  },
  {
    "date": "2026-02-09",
    "title": "Friedkin-Johnsen Social Influence Dynamics on Networks: A Boundary-Value Formulation and Influenceability Measures",
    "authors": "Moses Boudourides",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08704v1",
    "source": "arXiv",
    "abstract": "This article presents a rigorous mathematical analysis of the Friedkin--Johnsen model of social influence on networks. We frame the opinion dynamics as a discrete boundary-value problem on a network, emphasizing the role of stubborn (boundary) and susceptible (interior) agents in shaping opinion evolution. This perspective allows for a precise analysis of how network structure, stubborn agents (boundary), and susceptible agents (interior) collectively determine the evolution of opinions. We derive the transient and steady-state solutions using two distinct but related approaches: a general resolvent-based method applicable to agents with heterogeneous susceptibilities, and a spectral method valid for the special case of homogeneous susceptibility. We further establish quantitative convergence rates to the steady state, derive explicit sensitivity formulas with respect to susceptibility parameters, and prove perturbation bounds under changes in the influence matrix. Moreover, we formally define a set of influenceability measures and prove some of their basic properties. Finally, we provide a Monte Carlo illustration on the Zachary karate club graph, showing how the proposed opinion broadcasting centralities and centralizations behave under random susceptibility profiles and how they relate to classical network centralities."
  },
  {
    "date": "2026-02-09",
    "title": "Homotopy types of finite étale spaces and generalized inflations",
    "authors": "Anton Ayzenberg, Nadya Khoroshavkina",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08694v1",
    "source": "arXiv",
    "abstract": "Inflation of a simplicial complex $K$ is a construction well known in combinatorial topology. It replaces each vertex $i$ of $K$ with a finite number $n_i$ of its copies, and each simplex $\\{i_0,\\ldots,i_k\\}$ with $n_{i_0}n_{i_1}\\cdots n_{i_k}$ many copies so that the collection of vertex-copies is spanned by a simplex in the inflation if and only if their originals were spanned by a simplex in the original complex. The celebrated poset fiber theorem of Björner, Wachs, and Welker describes the homotopy type of such inflation in terms of homotopy types of $K$ and its links. In the current paper, we introduce more general inflations over simplicial posets: we replace each simplex with an arbitrary finite set of copies. The way how these sets patch together is specified by a commutative diagram, or, equivalently, a sheaf on the corresponding finite topology. The generalized inflation can be understood as étale space of such sheaf. We prove that, whenever this inflation sheaf is flabby, the poset fiber theorem still applies. We prove all results similar to those known for vertex inflations. We also cover the previous result of the first author about homotopy types of clique complexes of multigraphs."
  },
  {
    "date": "2026-02-09",
    "title": "Abstract integrodifferential equations and applications",
    "authors": "Bruno de Andrade, Marcos Gabriel de Santana",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08691v1",
    "source": "arXiv",
    "abstract": "In this work, we study the initial value problem associated with an abstract integrodifferential equation in interpolation scales. We prove local-in-time existence, uniqueness, continuation, and a blow-up alternative for regular mild solutions to the problem. Additionally, we apply this theory to the Navier-Stokes equations with hereditary viscosity, taking initial data in the scale of fractional power spaces associated with the Stokes operator. We also explore reaction-diffusion problems with memory, considering the effects of super-linear and gradient-type nonlinearities, and initial data in Lebesgue and Besov spaces, respectively."
  },
  {
    "date": "2026-02-09",
    "title": "SoK: The Pitfalls of Deep Reinforcement Learning for Cybersecurity",
    "authors": "Shae McFadden, Myles Foley, Elizabeth Bates, Ilias Tsingenopoulos, Sanyam Vyas, Vasilios Mavroudis, Chris Hicks, Fabio Pierazzi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08690v1",
    "source": "arXiv",
    "abstract": "Deep Reinforcement Learning (DRL) has achieved remarkable success in domains requiring sequential decision-making, motivating its application to cybersecurity problems. However, transitioning DRL from laboratory simulations to bespoke cyber environments can introduce numerous issues. This is further exacerbated by the often adversarial, non-stationary, and partially-observable nature of most cybersecurity tasks. In this paper, we identify and systematize 11 methodological pitfalls that frequently occur in DRL for cybersecurity (DRL4Sec) literature across the stages of environment modeling, agent training, performance evaluation, and system deployment. By analyzing 66 significant DRL4Sec papers (2018-2025), we quantify the prevalence of each pitfall and find an average of over five pitfalls per paper. We demonstrate the practical impact of these pitfalls using controlled experiments in (i) autonomous cyber defense, (ii) adversarial malware creation, and (iii) web security testing environments. Finally, we provide actionable recommendations for each pitfall to support the development of more rigorous and deployable DRL-based security systems."
  },
  {
    "date": "2026-02-09",
    "title": "Dashed Line Defense: Plug-And-Play Defense Against Adaptive Score-Based Query Attacks",
    "authors": "Yanzhang Fu, Zizheng Guo, Jizhou Luo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08679v1",
    "source": "arXiv",
    "abstract": "Score-based query attacks pose a serious threat to deep learning models by crafting adversarial examples (AEs) using only black-box access to model output scores, iteratively optimizing inputs based on observed loss values. While recent runtime defenses attempt to disrupt this process via output perturbation, most either require access to model parameters or fail when attackers adapt their tactics. In this paper, we first reveal that even the state-of-the-art plug-and-play defense can be bypassed by adaptive attacks, exposing a critical limitation of existing runtime defenses. We then propose Dashed Line Defense (DLD), a plug-and-play post-processing method specifically designed to withstand adaptive query strategies. By introducing ambiguity in how the observed loss reflects the true adversarial strength of candidate examples, DLD prevents attackers from reliably analyzing and adapting their queries, effectively disrupting the AE generation process. We provide theoretical guarantees of DLD's defense capability and validate its effectiveness through experiments on ImageNet, demonstrating that DLD consistently outperforms prior defenses--even under worst-case adaptive attacks--while preserving the model's predicted labels."
  },
  {
    "date": "2026-02-09",
    "title": "Input-Adaptive Spectral Feature Compression by Sequence Modeling for Source Separation",
    "authors": "Kohei Saijo, Yoshiaki Bando",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08671v1",
    "source": "arXiv",
    "abstract": "Time-frequency domain dual-path models have demonstrated strong performance and are widely used in source separation. Because their computational cost grows with the number of frequency bins, these models often use the band-split (BS) module in high-sampling-rate tasks such as music source separation (MSS) and cinematic audio source separation (CASS). The BS encoder compresses frequency information by encoding features for each predefined subband. It achieves effective compression by introducing an inductive bias that places greater emphasis on low-frequency parts. Despite its success, the BS module has two inherent limitations: (i) it is not input-adaptive, preventing the use of input-dependent information, and (ii) the parameter count is large, since each subband requires a dedicated module. To address these issues, we propose Spectral Feature Compression (SFC). SFC compresses the input using a single sequence modeling module, making it both input-adaptive and parameter-efficient. We investigate two variants of SFC, one based on cross-attention and the other on Mamba, and introduce inductive biases inspired by the BS module to make them suitable for frequency information compression. Experiments on MSS and CASS tasks demonstrate that the SFC module consistently outperforms the BS module across different separator sizes and compression ratios. We also provide an analysis showing that SFC adaptively captures frequency patterns from the input."
  },
  {
    "date": "2026-02-09",
    "title": "Reliable one-bit quantization of bandlimited graph data via single-shot noise shaping",
    "authors": "Johannes Maly, Anna Veselovska",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08669v1",
    "source": "arXiv",
    "abstract": "Graph data are ubiquitous in natural sciences and machine learning. In this paper, we consider the problem of quantizing graph structured, bandlimited data to few bits per entry while preserving its information under low-pass filtering. We propose an efficient single-shot noise shaping method that achieves state-of-the-art performance and comes with rigorous error bounds. In contrast to existing methods it allows reliable quantization to arbitrary bit-levels including the extreme case of using a single bit per data coefficient."
  },
  {
    "date": "2026-02-09",
    "title": "Three lectures on tropical algebra",
    "authors": "Jeffrey Giansiracusa, Kevin Kuehn, Stefano Mereta, Eduardo Vital",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08664v1",
    "source": "arXiv",
    "abstract": "This document is a slightly expanded version of a series of talks given by J. Giansiracusa at the workshop `Geometry over semirings' at Universitat Autònoma de Barcelona in July 2025. In the first lecture we introduce tropical polynomials, ideals, congruences, and how the connection with tropical geometry is made via congruences of bend relations. Tropical geometry and matroid theory are telling us that we should focus attention on a narrow slice of the world of tropical algebra, and this leads to the theory of tropical ideals (as developed by Maclagan and Rincón) and an abundance of interesting open questions. In the second lecture we examine the relationship between Berkovich analytification and tropicalization from the perspective of bend relations, giving a refinement of Payne's influential limit theorem. In the third lecture we set aside geometry and focus on tropicalization via bend relations as a construction in commutative and non-commutative algebra. Constructions such as symmetric algebras, exterior algebras, matrix algebras, and Clifford algebras can be tropicalized. In the case of exterior algebras, the resulting tropical notion beautifully completes the picture of the Plücker embedding and gives a new perspective on the tropical Plücker relations. For matrix algebras and Clifford algebras, Morita theory becomes an interesting topic."
  },
  {
    "date": "2026-02-09",
    "title": "WiFlow: A Lightweight WiFi-based Continuous Human Pose Estimation Network with Spatio-Temporal Feature Decoupling",
    "authors": "Yi Dao, Lankai Zhang, Hao Liu, Haiwei Zhang, Wenbo Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08661v1",
    "source": "arXiv",
    "abstract": "Human pose estimation is fundamental to intelligent perception in the Internet of Things (IoT), enabling applications ranging from smart healthcare to human-computer interaction. While WiFi-based methods have gained traction, they often struggle with continuous motion and high computational overhead. This work presents WiFlow, a novel framework for continuous human pose estimation using WiFi signals. Unlike vision-based approaches such as two-dimensional deep residual networks that treat Channel State Information (CSI) as images, WiFlow employs an encoder-decoder architecture. The encoder captures spatio-temporal features of CSI using temporal and asymmetric convolutions, preserving the original sequential structure of signals. It then refines keypoint features of human bodies to be tracked and capture their structural dependencies via axial attention. The decoder subsequently maps the encoded high-dimensional features into keypoint coordinates. Trained on a self-collected dataset of 360,000 synchronized CSI-pose samples from 5 subjects performing continuous sequences of 8 daily activities, WiFlow achieves a Percentage of Correct Keypoints (PCK) of 97.00% at a threshold of 20% (PCK@20) and 99.48% at PCK@50, with a mean per-joint position error of 0.008m. With only 4.82M parameters, WiFlow significantly reduces model complexity and computational cost, establishing a new performance baseline for practical WiFi-based human pose estimation. Our code and datasets are available at https://github.com/DY2434/WiFlow-WiFi-Pose-Estimation-with-Spatio-Temporal-Decoupling.git."
  },
  {
    "date": "2026-02-09",
    "title": "Two-Stage Data Synthesization: A Statistics-Driven Restricted Trade-off between Privacy and Prediction",
    "authors": "Xiaotong Liu, Shao-Bo Lin, Jun Fan, Ding-Xuan Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08657v1",
    "source": "arXiv",
    "abstract": "Synthetic data have gained increasing attention across various domains, with a growing emphasis on their performance in downstream prediction tasks. However, most existing synthesis strategies focus on maintaining statistical information. Although some studies address prediction performance guarantees, their single-stage synthesis designs make it challenging to balance the privacy requirements that necessitate significant perturbations and the prediction performance that is sensitive to such perturbations. We propose a two-stage synthesis strategy. In the first stage, we introduce a synthesis-then-hybrid strategy, which involves a synthesis operation to generate pure synthetic data, followed by a hybrid operation that fuses the synthetic data with the original data. In the second stage, we present a kernel ridge regression (KRR)-based synthesis strategy, where a KRR model is first trained on the original data and then used to generate synthetic outputs based on the synthetic inputs produced in the first stage. By leveraging the theoretical strengths of KRR and the covariant distribution retention achieved in the first stage, our proposed two-stage synthesis strategy enables a statistics-driven restricted privacy--prediction trade-off and guarantee optimal prediction performance. We validate our approach and demonstrate its characteristics of being statistics-driven and restricted in achieving the privacy--prediction trade-off both theoretically and numerically. Additionally, we showcase its generalizability through applications to a marketing problem and five real-world datasets."
  },
  {
    "date": "2026-02-09",
    "title": "Compact linearly uncoupled resonators for efficient spontaneous parametric downconversion via angular phase matching",
    "authors": "Alessia Stefano, Matteo Piccolini, Marco Liscidini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08654v1",
    "source": "arXiv",
    "abstract": "We report an integrated platform for efficient second-order nonlinear interactions based on linearly uncoupled resonators and angular phase matching. The proposed architecture confines phase control to a limited section of the device, maximizing field enhancement and effective nonlinear interaction length while simultaneously reducing the overall footprint. As an example we show the results for an AlGaAs-on-insulator structure demonstrating a photon-pair generation rate of 3.16 GHz/mW in the continuous-wave regime and 5.89 MHz under pulsed pumping. The generated biphoton state exhibits a Schmidt number K=1.02, indicating nearly uncorrelated photon pairs. The compact and reconfigurable nature of this approach, together with its independence from material-specific poling techniques, makes it applicable to a broad class of integrated $χ_2$ nonlinear platforms."
  },
  {
    "date": "2026-02-09",
    "title": "Weighted composition operators on weighted Dirichlet spaces: boundedness, compactness and spectral properties",
    "authors": "Anirban Sen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08651v1",
    "source": "arXiv",
    "abstract": "We establish necessary and sufficient conditions for the boundedness and compactness of weighted composition operators acting on weighted Dirichlet spaces and determine the spectrum of a certain class of such operators. Our results extend earlier work on unweighted composition operators and highlight the close interplay between the operator theoretic behavior of weighted composition operators and the function theoretic properties of their inducing functions. Several examples are provided to illustrate the applicability of the obtained results."
  },
  {
    "date": "2026-02-09",
    "title": "Projected Gradient Ascent for Efficient Reward-Guided Updates with One-Step Generative Models",
    "authors": "Jisung Hwang, Minhyuk Sung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08646v1",
    "source": "arXiv",
    "abstract": "We propose a constrained latent optimization method for reward-guided generation that preserves white Gaussian noise characteristics with negligible overhead. Test-time latent optimization can unlock substantially better reward-guided generations from pretrained generative models, but it is prone to reward hacking that degrades quality and also too slow for practical use. In this work, we make test-time optimization both efficient and reliable by replacing soft regularization with hard white Gaussian noise constraints enforced via projected gradient ascent. Our method applies a closed-form projection after each update to keep the latent vector explicitly noise-like throughout optimization, preventing the drift that leads to unrealistic artifacts. This enforcement adds minimal cost: the projection matches the $O(N \\log N)$ complexity of standard algorithms such as sorting or FFT and does not practically increase wall-clock time. In experiments, our approach reaches a comparable Aesthetic Score using only 30% of the wall-clock time required by the SOTA regularization-based method, while preventing reward hacking."
  },
  {
    "date": "2026-02-09",
    "title": "Fully coupled implicit finite-volume algorithm for viscoelastic interfacial flows",
    "authors": "Ayman Mazloum, Gabriele Gennari, Fabian Denner, Berend van Wachem",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08645v1",
    "source": "arXiv",
    "abstract": "A fully coupled implicit finite-volume algorithm for incompressible viscoelastic interfacial flows is proposed, whereby the viscoelasticity of the flow is described by an upper-convected Maxwell constitutive model, including limited extensibility and shear-thinning behaviour. The governing equations describing the conservation of continuity and momentum, as well as the constitutive model are discretized using standard finite-volume methods and are solved for pressure, velocity and the polymer stress tensor in a single linear system of equations. Treating all terms of the linearized and discretized governing equations implicit in velocity, pressure and/or the components of the polymer stress tensor, a tightly coupled system of equations is obtained. The interface separating the interacting bulk phases and the surface tension acting at the fluid interface are modelled using a state-of-the-art front-tracking method. We demonstrate the capabilities of the proposed numerical framework with four representative test cases, including the deformation of a viscoelastic droplet in shear flow at large Weissenberg numbers of up to Wi=10^4, and the jump discontinuity of the rise velocity of a bubble rising in a viscoelastic liquid as a result of a \"negative wake\". Contrary to previous studies using segregated algorithms, the proposed fully coupled implicit algorithm does not apply or require a log-conformation approach to predict these flows. Overall, the fully implicit coupled front-tracking formulation provides a robust framework to reliable numerical predictions of strongly elastic interfacial flows at large Weissenberg numbers."
  },
  {
    "date": "2026-02-09",
    "title": "Inverse problem for the geometric Navier-Stokes equations",
    "authors": "Yavar Kian, Lauri Oksanen, Ziyao Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08644v1",
    "source": "arXiv",
    "abstract": "We consider the inverse problem of determining a compact Riemannian manifold with boundary from fixed time observations of the solution, restricted to a small subset in space, for the Navier-Stokes system with a local source on the manifold. Our approach is based on a reduction to an inverse problem for an auxiliary hyperbolic Stokes system, via linearization and spectral techniques. We solve the resulting inverse problem by a new generalization of the Boundary Control method."
  },
  {
    "date": "2026-02-09",
    "title": "State policy heterogeneity analyses: considerations and proposals",
    "authors": "Max Rubinstein, Megan S. Schuler, Elizabeth A. Stuart, Bradley D. Stein, Max Griswold, Elizabeth M. Stone, Beth Ann Griffin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08643v1",
    "source": "arXiv",
    "abstract": "State-level policy studies often conduct heterogeneity analyses that quantify how treatment effects vary across state characteristics. These analyses may be used to inform state-specific policy decisions, or to infer how the effect of a policy changes in combination with other state characteristics. However, in state-level settings with varied contexts and policy landscapes, multiple versions of similar policies, and differential policy implementation, the causal quantities targeted by these analyses may not align with the inferential goals. This paper clarifies these issues by distinguishing several causal estimands relevant to heterogeneity analyses in state-policy settings, including state-specific treatment effects (ITE), conditional average treatment effects (CATE), and controlled direct effects (CDE). We argue that the CATE is often the easiest to identify and estimate, but may not be the most policy relevant target of inference. Moreover, the widespread practice of coarsening distinct policies or implementations into a single indicator further complicates the interpretation of these analyses. Motivated by these limitations, we propose bounding ITEs as an alternative inferential goal, yielding ranges for each state's policy effect under explicit assumptions that quantify deviations from the ideal identifying conditions. These bounds target a well-defined and policy-relevant quantity, the effect for specific states. We develop this approach within a difference-in-differences framework and discuss how sensitivity parameters may be informed using pre-treatment data. Through simulations we demonstrate that bounding state-specific effects can more reliably determine the sign of the ITEs than CATE estimates. We then illustrate this method to examine the effect of the Affordable Care Act Medicaid expansion on high-volume buprenorphine prescribing."
  },
  {
    "date": "2026-02-09",
    "title": "Topological beam stirring in a multicore fiber",
    "authors": "Alena Kolesnikova, Mikhail Gervaziev, Nikita Bochkarev, Denis Kharenko, Evgeny Podivilov, Sergey Babin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08635v1",
    "source": "arXiv",
    "abstract": "Multicore fibers (MCF) are perspective media for telecommunications, sensing, imaging and laser technologies. Here, the effect of beam stirring between weakly coupled cores is observed for sub-nanosecond transform-limited pulses of several kW peak power propagating in ~10 m long 7-core fiber, for the first time to our knowledge. In contrast to low-power domain where the output power distribution in the cores is random with large fluctuations sensitive to fiber disturbances, at high power of the input pulse injected in the central core the output power becomes equalized between the cores with fluctuations reduced to <5% being insensitive to disturbances. Similar behavior is observed in cut-back experiments showing that equi-partition is approached at a distance of ~5 m. The performed modeling describes well the experimental results and clarifies mechanisms of the new effect reasoned by a large nonlinear phase shift changing along the pulse and thereby resulting in statistical averaging over the pulse length of multidirectional power transfer processes between cores, thus leading to the robust equilibrium (equi-partitition for hexagonal MCF topology). At the same time, the combined output beam measured in a far field takes a stable bell-shaped profile instead of speckled beam at low powers, similar to the beam self-cleaning effect in multimode fibers."
  },
  {
    "date": "2026-02-09",
    "title": "We Should Separate Memorization from Copyright",
    "authors": "Adi Haviv, Niva Elkin-Koren, Uri Hacohen, Roi Livni, Shay Moran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08632v1",
    "source": "arXiv",
    "abstract": "The widespread use of foundation models has introduced a new risk factor of copyright issue. This issue is leading to an active, lively and on-going debate amongst the data-science community as well as amongst legal scholars. Where claims and results across both sides are often interpreted in different ways and leading to different implications. Our position is that much of the technical literature relies on traditional reconstruction techniques that are not designed for copyright analysis. As a result, memorization and copying have been conflated across both technical and legal communities and in multiple contexts. We argue that memorization, as commonly studied in data science, should not be equated with copying and should not be used as a proxy for copyright infringement. We distinguish technical signals that meaningfully indicate infringement risk from those that instead reflect lawful generalization or high-frequency content. Based on this analysis, we advocate for an output-level, risk-based evaluation process that aligns technical assessments with established copyright standards and provides a more principled foundation for research, auditing, and policy."
  },
  {
    "date": "2026-02-09",
    "title": "Quantum Wasserstein isometries of the $n$-qubit state space: a Wigner-type result",
    "authors": "Gergely Bunth, Eszter Szabó, Dániel Virosztek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08628v1",
    "source": "arXiv",
    "abstract": "We determine the isometry group of the $n$-qubit state space with respect to the quantum Wasserstein distance induced by the so-called symmetric transport cost for all $n \\in \\mathbb{N}.$ It turns out that the isometries are precisely the Wigner symmetries, that is, the unitary or anti-unitary conjugations."
  },
  {
    "date": "2026-02-09",
    "title": "First-principles discovery of stable, anisotropic, semiconducting Sb2X2O (X = S, Se) and Janus Sb2SSeO nanosheets for optoelectronics and photocatalysis",
    "authors": "Masoud Shahrokhi, Bohayra Mortazavi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08622v1",
    "source": "arXiv",
    "abstract": "In this work, we conduct a comprehensive first-principles investigation into the design and discovery of novel antimony oxychalcogenide monolayers Sb2X2O (X = S, Se) and Janus Sb2SSeO, examining their structural stability, elastic, electronic, optoelectronic, and photocatalytic properties. Our analysis confirms their thermodynamic and dynamical stability and reveals low cleavage energies, indicating strong feasibility for mechanical exfoliation. The excellent agreement between our HSE06-predicted bandgap of bulk Sb2S2O and experimental measurements further validates the employed computational framework. EWe also find that their optoelectronic responses can be efficiently tuned via biaxial strain, providing a viable route for device-specific property engineering. Favorable band alignments, strong optical absorption, efficient carrier transport, and relatively high dielectric constants collectively support their candidacy for overall water splitting under neutral conditions.These results establish a solid theoretical foundation for the rational design of Sb-based 2D nanostructures and highlight their potential in next-generation direction-dependent optoelectronic and sustainable energy-conversion applications."
  },
  {
    "date": "2026-02-09",
    "title": "VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling",
    "authors": "Ziyang Cheng, Yuhao Wang, Heyang Liu, Ronghua Wu, Qunshan Gu, Yanfeng Wang, Yu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08607v1",
    "source": "arXiv",
    "abstract": "Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Diffusion Modeling~(MDM) as a non-autoregressive paradigm for speech LLMs and introduce VocalNet-MDM. To adapt MDM for streaming speech interaction, we address two critical challenges: training-inference mismatch and iterative overhead. We propose Hierarchical Block-wise Masking to align training objectives with the progressive masked states encountered during block diffusion decoding, and Iterative Self-Distillation to compress multi-step refinement into fewer steps for low-latency inference. Trained on a limited scale of only 6K hours of speech data, VocalNet-MDM achieves a 3.7$\\times$--10$\\times$ decoding speedup and reduces first-chunk latency by 34\\% compared to AR baselines. It maintains competitive recognition accuracy while achieving state-of-the-art text quality and speech naturalness, demonstrating that MDM is a promising and scalable alternative for low-latency, efficient speech LLMs."
  },
  {
    "date": "2026-02-09",
    "title": "Mimic Intent, Not Just Trajectories",
    "authors": "Renming Huang, Chendong Zeng, Wenjing Tang, Jingtian Cai, Cewu Lu, Panpan Cai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08602v1",
    "source": "arXiv",
    "abstract": "While imitation learning (IL) has achieved impressive success in dexterous manipulation through generative modeling and pretraining, state-of-the-art approaches like Vision-Language-Action (VLA) models still struggle with adaptation to environmental changes and skill transfer. We argue this stems from mimicking raw trajectories without understanding the underlying intent. To address this, we propose explicitly disentangling behavior intent from execution details in end-2-end IL: \\textit{``Mimic Intent, Not just Trajectories'' (MINT)}. We achieve this via \\textit{multi-scale frequency-space tokenization}, which enforces a spectral decomposition of action chunk representation. We learn action tokens with a multi-scale coarse-to-fine structure, and force the coarsest token to capture low-frequency global structure and finer tokens to encode high-frequency details. This yields an abstract \\textit{Intent token} that facilitates planning and transfer, and multi-scale \\textit{Execution tokens} that enable precise adaptation to environmental dynamics. Building on this hierarchy, our policy generates trajectories through \\textit{next-scale autoregression}, performing progressive \\textit{intent-to-execution reasoning}, thus boosting learning efficiency and generalization. Crucially, this disentanglement enables \\textit{one-shot transfer} of skills, by simply injecting the Intent token from a demonstration into the autoregressive generation process. Experiments on several manipulation benchmarks and on a real robot demonstrate state-of-the-art success rates, superior inference efficiency, robust generalization against disturbances, and effective one-shot transfer."
  },
  {
    "date": "2026-02-09",
    "title": "Kissan-Dost: Bridging the Last Mile in Smallholder Precision Agriculture with Conversational IoT",
    "authors": "Muhammad Saad Ali, Daanish U. Khan, Laiba Intizar Ahmad, Umer Irfan, Maryam Mustafa, Naveed Anwar Bhatti, Muhammad Hamad Alizai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08593v1",
    "source": "arXiv",
    "abstract": "We present Kissan-Dost, a multilingual, sensor-grounded conversational system that turns live on-farm measurements and weather into plain-language guidance delivered over WhatsApp text or voice. The system couples commodity soil and climate sensors with retrieval-augmented generation, then enforces grounding, traceability, and proactive alerts through a modular pipeline. In a 90-day, two-site pilot with five participants, we ran three phases (baseline, dashboard only, chatbot only). Dashboard engagement was sporadic and faded, while the chatbot was used nearly daily and informed concrete actions. Controlled tests on 99 sensor-grounded crop queries achieved over 90 percent correctness with subsecond end-to-end latency, alongside high-quality translation outputs. Results show that careful last-mile integration, not novel circuitry, unlocks the latent value of existing Agri-IoT for smallholders."
  },
  {
    "date": "2026-02-09",
    "title": "SDFed: Bridging Local Global Discrepancy via Subspace Refinement and Divergence Control in Federated Prompt Learning",
    "authors": "Yicheng Di, Wei Yuan, Tieke He, Zhanjie Zhang, Ao Ma, Yuan Liu, Hongzhi Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08590v1",
    "source": "arXiv",
    "abstract": "Vision-language pretrained models offer strong transferable representations, yet adapting them in privacy-sensitive multi-party settings is challenging due to the high communication cost of federated optimization and the limited local data on clients. Federated prompt learning mitigates this issue by keeping the VLPM backbone frozen and collaboratively training lightweight prompt parameters. However, existing approaches typically enforce a unified prompt structure and length across clients, which is inadequate under practical client heterogeneity in both data distributions and system resources, and may further introduce conflicts between globally shared and locally optimal knowledge. To address these challenges, we propose \\textbf{SDFed}, a heterogeneous federated prompt learning framework that bridges Local-Global Discrepancy via Subspace Refinement and Divergence Control. SDFed maintains a fixed-length global prompt for efficient aggregation while allowing each client to learn a variable-length local prompt to better match its data characteristics and capacity. To mitigate local-global conflicts and facilitate effective knowledge transfer, SDFed introduces a subspace refinement method for local prompts and an information retention and divergence control strategy that preserves key local information while maintaining appropriate separability between global and local representations. Extensive experiments on several datasets demonstrate that SDFed consistently improves performance and robustness in heterogeneous federated settings."
  },
  {
    "date": "2026-02-09",
    "title": "Magnon confinement and trapping at the nanoscale",
    "authors": "J. Chen, H. Yu, R. Gallardo, P. Landeros, G. Gubbiotti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08587v1",
    "source": "arXiv",
    "abstract": "Magnon confinement and trapping refer to the localization of magnons-quasiparticles that represent collective spin-wave excitations in magnetic materials-within specific regions or structures. This concept is essential in magnonics, a subfield of spintronics that leverages spin waves for processing and transmitting information. Compared to conventional electronics, magnonics offers lower power consumption and faster operation, making it a promising technology for future devices. Magnons can be confined using both static and dynamic methods, often relying on potential wells and barriers to restrict their free propagation and trap them in designated locations. In this review, we will explore the main strategies for magnon confinement and trapping, including: magnetic field inhomogeneities, spin textures (i.e. domain walls, vortices, skyrmions) nanostructured materials (i.e. nanowires, disks, and magnonic crystals), topological states, chiral magnons and flat band formation, induced by dipole-dipole interactions and Dzyaloshinskii-Moriya interaction. Microwave cavities and resonant magnetic fields, as well as spin-torque effects and Bose-Einstein condensation contribute to magnon localization. Furthermore, spin-wave edge and cavity modes have been observed in two-dimensional magnetic materials and twisted moiré superlattices at a specific twist angle. Magnon trapping has broad applications in computing and data processing, particularly in the development of magnonic crystals, waveguides, and memory elements. Additionally, magnon systems are being explored for quantum computing, where confinement can enhance the coupling between magnons and other quasiparticles in hybrid quantum systems. Precision control of magnons could lead to next-generation spintronic devices, offering improved efficiency and scalability."
  },
  {
    "date": "2026-02-09",
    "title": "PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition",
    "authors": "Yiming Yang, Zhuoyuan Li, Fanxiang Zeng, Hao Fu, Yue Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08586v1",
    "source": "arXiv",
    "abstract": "Multi-agent collaboration has emerged as a promising paradigm for enhancing reasoning capabilities of Large Language Models (LLMs). However, existing approaches remain largely heuristic, lacking principled guidance on what drives performance gains and how to systematically optimize multi-agent reasoning. Specifically, it remains unclear why multi-agent collaboration outperforms single-agent reasoning and which design choices contribute most to these gains, making it difficult to build better systems. We address this gap by introducing a unified theoretical framework that decomposes multi-agent reasoning gains into three conceptually independent dimensions: Exploration for diverse solution coverage, Information for high-fidelity feedback, and Aggregation for principled consensus. Through this lens, existing methods can be understood as special cases that optimize only subsets of these dimensions. Building upon this decomposition, a novel framework called PRISM (Propose-Review-Integrate Synthesis for Multi-agent Reasoning) is proposed, which jointly maximizes all three dimensions through role-based diversity, execution-grounded feedback with evidence-based cross-evaluation, and iterative synthesis with closed-loop validation. Extensive experiments across mathematical reasoning, code generation, and function calling benchmarks demonstrate that PRISM achieves state-of-the-art performance with superior compute-efficiency compared to methods optimizing partial dimensions. The theoretical framework provides actionable design principles for future multi-agent reasoning systems."
  },
  {
    "date": "2026-02-09",
    "title": "Uphill transport in competitive drift-diffusion models with volume exclusion",
    "authors": "Francesco Casini, Cristian Giardinà, Jacopo Nicolini, Luca Selmi, Cecilia Vernia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08583v1",
    "source": "arXiv",
    "abstract": "This paper addresses uphill transport (defined as a regime in which particle flow is opposite to the prescriptions of Fick's diffusion) in drift-diffusion particle transport constrained by volume exclusion. Firstly, we show that the stationary hydrodynamic limit of a multispecies, weakly asymmetric exclusion process (SHDL) naturally predicts precisely characterized uphill regimes in the space of external drivings. Then, with specific reference to systems of oppositely charged particles, we identify well-defined model hypotheses and extensions whereby the SHDL converges to the modified Poisson-Nernst-Planck model, thus bridging the gap between exclusion-based particle models and continuum descriptions commonly used in engineering. The merits and limitations of the models in describing the particle fluxes and predicting uphill transport conditions are investigated in detail with respect to the adopted approximations and simplifications. The results demonstrate the persistence of uphill transport phenomena across modeling scales, clarify the conditions under which they occur, and suggest that uphill transport may play a significant role in nanoscale electrolytes, confined ionic and iontronic devices, and membrane-based technologies."
  },
  {
    "date": "2026-02-09",
    "title": "Random Polyhedral Cones: Distributional Results via Gale Duality",
    "authors": "Zakhar Kabluchko",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08581v1",
    "source": "arXiv",
    "abstract": "Let $U_1,\\ldots,U_n$ be independent random vectors uniformly distributed on the unit sphere $\\mathbb S^{d-1}\\subseteq\\mathbb R^d$, where $n\\ge d$, and consider the random polyhedral cone \\[ \\mathcal W_{n,d}:=\\mathop{\\mathrm{pos}} (U_1,\\ldots,U_n) = \\{λ_1 U_1+ \\ldots + λ_n U_n: λ_1\\geq 0, \\ldots, λ_n \\geq 0\\}. \\] We establish several distributional results for $\\mathcal W_{n,d}$ and the associated spherical polytope $\\mathcal W_{n,d}\\cap\\mathbb S^{d-1}$. Our main contributions include: (i) Let $α_d$ denote the solid angle of $\\mathcal W_{d,d}$ and write $m(d,k):=\\mathbb E[α_d^k]$ for its $k$-th moment. We prove the symmetry $m(d,k)=m(k,d)$. As an application, we compute $\\mathop{\\mathrm{Var}}[α_d]=2^{-d}(d+1)^{-1}-4^{-d}$ and derive a closed formula for the third moment. (ii) For $n=d+1,d+2,d+3$ we determine the probability that $\\mathcal W_{n,d}\\cap\\mathbb S^{d-1}$ is a spherical simplex, a spherical analogue of the classical Sylvester problem. In the case $n=d+2$ we also determine the distribution of the number of vertices of $\\mathcal W_{d+2,d}\\cap\\mathbb S^{d-1}$. (iii) Let $f_\\ell(\\mathcal W_{n,d})$ denote the number of $\\ell$-dimensional faces of $\\mathcal W_{n,d}$. We prove a distributional limit theorem for $f_\\ell(\\mathcal W_{n,d})$ in the regime $n=d+k$ and $\\ell=d-q$, where $k,q\\in\\mathbb N$ are fixed and $d\\to\\infty$. The limit law is a weighted sum of independent chi squared variables, with weights given by explicit eigenvalues of a convolution operator on the sphere. A unifying ingredient is an explicit coupling producing i.i.d. uniform vectors $U_1,\\ldots,U_n\\in\\mathbb S^{d-1}$ together with i.i.d. uniform vectors $V_1,\\ldots,V_n\\in\\mathbb S^{n-d-1}$ whose associated oriented matroids are Gale dual."
  },
  {
    "date": "2026-02-09",
    "title": "retinalysis-vascx: An explainable software toolbox for the extraction of retinal vascular biomarkers",
    "authors": "Jose D. Vargas Quiros, Michael J. Beyeler, Sofia Ortin Vela, EyeNED Reading Center, Sven Bergmann, Caroline C. W. Klaver, Bart Liefers",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08580v1",
    "source": "arXiv",
    "abstract": "The automatic extraction of retinal vascular biomarkers from color fundus images (CFI) is essential for large-scale studies of the retinal vasculature. We present VascX, an open-source Python toolbox designed for the automated extraction of biomarkers from artery and vein segmentations. The VascX workflow processes vessel segmentation masks into skeletons to build undirected and directed vessel graphs, which are then used to resolve segments into continuous vessels. This architecture enables the calculation of a comprehensive suite of biomarkers, including vascular density, bifurcation angles, central retinal equivalents (CREs), tortuosity, and temporal angles, alongside image quality metrics. A distinguishing feature of VascX is its region awareness; by utilizing the fovea, optic disc, and CFI boundaries as anatomical landmarks, the tool ensures spatially standardized measurements and identifies when specific biomarkers are not computable. Spatially localized biomarkers are calculated over grids relative to these landmarks, facilitating precise clinical analysis. Released via GitHub and PyPI, VascX provides an explainable and modifiable framework that supports reproducible vascular research through integrated visualizations. By enabling the rapid extraction of established biomarkers and the development of new ones, VascX advances the field of oculomics, offering a robust, computationally efficient solution for scalable deployment in large-scale clinical and epidemiological databases."
  },
  {
    "date": "2026-02-09",
    "title": "An arithmetic method algorithm optimizing k-nearest neighbors compared to regression algorithms and evaluated on real world data sources",
    "authors": "Theodoros Anagnostopoulos, Evanthia Zervoudi, Christos Anagnostopoulos, Apostolos Christopoulos, Bogdan Wierzbinski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08577v1",
    "source": "arXiv",
    "abstract": "Linear regression analysis focuses on predicting a numeric regressand value based on certain regressor values. In this context, k-Nearest Neighbors (k-NN) is a common non-parametric regression algorithm, which achieves efficient performance when compared with other algorithms in literature. In this research effort an optimization of the k-NN algorithm is proposed by exploiting the potentiality of an introduced arithmetic method, which can provide solutions for linear equations involving an arbitrary number of real variables. Specifically, an Arithmetic Method Algorithm (AMA) is adopted to assess the efficiency of the introduced arithmetic method, while an Arithmetic Method Regression (AMR) algorithm is proposed as an optimization of k-NN adopting the potentiality of AMA. Such algorithm is compared with other regression algorithms, according to an introduced optimal inference decision rule, and evaluated on certain real world data sources, which are publicly available. Results are promising since the proposed AMR algorithm has comparable performance with the other algorithms, while in most cases it achieves better performance than the k-NN. The output results indicate that introduced AMR is an optimization of k-NN."
  },
  {
    "date": "2026-02-09",
    "title": "RankGR: Rank-Enhanced Generative Retrieval with Listwise Direct Preference Optimization in Recommendation",
    "authors": "Kairui Fu, Changfa Wu, Kun Yuan, Binbin Cao, Dunxian Huang, Yuliang Yan, Junjun Zheng, Jianning Zhang, Silu Zhou, Jian Wu, Kun Kuang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08575v1",
    "source": "arXiv",
    "abstract": "Generative retrieval (GR) has emerged as a promising paradigm in recommendation systems by autoregressively decoding identifiers of target items. Despite its potential, current approaches typically rely on the next-token prediction schema, which treats each token of the next interacted items as the sole target. This narrow focus 1) limits their ability to capture the nuanced structure of user preferences, and 2) overlooks the deep interaction between decoded identifiers and user behavior sequences. In response to these challenges, we propose RankGR, a Rank-enhanced Generative Retrieval method that incorporates listwise direct preference optimization for recommendation. RankGR decomposes the retrieval process into two complementary stages: the Initial Assessment Phase (IAP) and the Refined Scoring Phase (RSP). In IAP, we incorporate a novel listwise direct preference optimization strategy into GR, thus facilitating a more comprehensive understanding of the hierarchical user preferences and more effective partial-order modeling. The RSP then refines the top-λ candidates generated by IAP with interactions towards input sequences using a lightweight scoring module, leading to more precise candidate evaluation. Both phases are jointly optimized under a unified GR model, ensuring consistency and efficiency. Additionally, we implement several practical improvements in training and deployment, ultimately achieving a real-time system capable of handling nearly ten thousand requests per second. Extensive offline performance on both research and industrial datasets, as well as the online gains on the \"Guess You Like\" section of Taobao, validate the effectiveness and scalability of RankGR."
  },
  {
    "date": "2026-02-09",
    "title": "Modeling Tidal Disruption Events and Compact Object Plunges in Nuclear Star Clusters",
    "authors": "Philip Cho, Kai Wu, Francesco Flammini Dotti, Taras Panamarev, Rainer Spurzem",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08574v1",
    "source": "arXiv",
    "abstract": "We study tidal disruption events (TDEs) and compact object inspirals in nuclear star clusters (NSCs) hosting a central supermassive black hole (SMBH), focusing on their role in SMBH growth. Using the STARDISK version of the direct N-body code NBODY6++GPU, we perform pilot simulations with two improved models: one for mass fallback from TDEs and another for compact object plunges based on orbital decay timescales. Our results show that mass accretion via TDEs peaks within the first 2 Myr and decreases more rapidly for higher initial SMBH masses, with roughly half the disrupted stellar debris being accreted. Compact object accretion is confined mostly to orbits with pericenters between 4 and 27 Schwarzschild radii and is suppressed by an order of magnitude when inspiral criteria are applied."
  },
  {
    "date": "2026-02-09",
    "title": "Agent-Supported Foresight for AI Systemic Risks: AI Agents for Breadth, Experts for Judgment",
    "authors": "Leon Fröhling, Alessandro Giaconia, Edyta Paulina Bogucka, Daniele Quercia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08565v1",
    "source": "arXiv",
    "abstract": "AI impact assessments often stress near-term risks because human judgment degrades over longer horizons, exemplifying the Collingridge dilemma: foresight is most needed when knowledge is scarcest. To address long-term systemic risks, we introduce a scalable approach that simulates in-silico agents using the strategic foresight method of the Futures Wheel. We applied it to four AI uses spanning Technology Readiness Levels (TRLs): Chatbot Companion (TRL 9, mature), AI Toy (TRL 7, medium), Griefbot (TRL 5, low), and Death App (TRL 2, conceptual). Across 30 agent runs per use, agents produced 86-110 consequences, condensed into 27-47 unique risks. To benchmark the agent outputs against human perspectives, we collected evaluations from 290 domain experts and 7 leaders, and conducted Futures Wheel sessions with 42 experts and 42 laypeople. Agents generated many systemic consequences across runs. Compared with these outputs, experts identified fewer risks, typically less systemic but judged more likely, whereas laypeople surfaced more emotionally salient concerns that were generally less systemic. We propose a hybrid foresight workflow, wherein agents broaden systemic coverage, and humans provide contextual grounding. Our dataset is available at: https://social-dynamics.net/ai-risks/foresight."
  },
  {
    "date": "2026-02-09",
    "title": "M-Loss: Quantifying Model Merging Compatibility with Limited Unlabeled Data",
    "authors": "Tiantong Wang, Yiyang Duan, Haoyu Chen, Tiantong Wu, Wei Yang Bryan Lim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08564v1",
    "source": "arXiv",
    "abstract": "Training of large-scale models is both computationally intensive and often constrained by the availability of labeled data. Model merging offers a compelling alternative by directly integrating the weights of multiple source models without requiring additional data or extensive training. However, conventional model merging techniques, such as parameter averaging, often suffer from the unintended combination of non-generalizable features, especially when source models exhibit significant weight disparities. Comparatively, model ensembling generally provides more stable and superior performance that aggregates multiple models by averaging outputs. However, it incurs higher inference costs and increased storage requirements. While previous studies experimentally showed the similarities between model merging and ensembling, theoretical evidence and evaluation metrics remain lacking. To address this gap, we introduce Merging-ensembling loss (M-Loss), a novel evaluation metric that quantifies the compatibility of merging source models using very limited unlabeled data. By measuring the discrepancy between parameter averaging and model ensembling at layer and node levels, M-Loss facilitates more effective merging strategies. Specifically, M-Loss serves both as a quantitative criterion of the theoretical feasibility of model merging, and a guide for parameter significance in model pruning. Our theoretical analysis and empirical evaluations demonstrate that incorporating M-Loss into the merging process significantly improves the alignment between merged models and model ensembling, providing a scalable and efficient framework for accurate model consolidation."
  },
  {
    "date": "2026-02-09",
    "title": "Automating Computational Reproducibility in Social Science: Comparing Prompt-Based and Agent-Based Approaches",
    "authors": "Syed Mehtab Hussain Shah, Frank Hopfgartner, Arnim Bleier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08561v1",
    "source": "arXiv",
    "abstract": "Reproducing computational research is often assumed to be as simple as rerunning the original code with provided data. In practice, missing packages, fragile file paths, version conflicts, or incomplete logic frequently cause analyses to fail, even when materials are shared. This study investigates whether large language models and AI agents can automate the diagnosis and repair of such failures, making computational results easier to reproduce and verify. We evaluate this using a controlled reproducibility testbed built from five fully reproducible R-based social science studies. Realistic failures were injected, ranging from simple issues to complex missing logic, and two automated repair workflows were tested in clean Docker environments. The first workflow is prompt-based, repeatedly querying language models with structured prompts of varying context, while the second uses agent-based systems that inspect files, modify code, and rerun analyses autonomously. Across prompt-based runs, reproduction success ranged from 31-79 percent, with performance strongly influenced by prompt context and error complexity. Complex cases benefited most from additional context. Agent-based workflows performed substantially better, with success rates of 69-96 percent across all complexity levels. These results suggest that automated workflows, especially agent-based systems, can significantly reduce manual effort and improve reproduction success across diverse error types. Unlike prior benchmarks, our testbed isolates post-publication repair under controlled failure modes, allowing direct comparison of prompt-based and agent-based approaches."
  },
  {
    "date": "2026-02-09",
    "title": "QARM V2: Quantitative Alignment Multi-Modal Recommendation for Reasoning User Sequence Modeling",
    "authors": "Tian Xia, Jiaqi Zhang, Yueyang Liu, Hongjian Dou, Tingya Yin, Jiangxia Cao, Xulei Liang, Tianlu Xie, Lihao Liu, Xiang Chen, Shen Wang, Changxin Lao, Haixiang Gan, Jinkai Yu, Keting Cen, Lu Hao, Xu Zhang, Qiqiang Zhong, Zhongbo Sun, Yiyu Wang, Shuang Yang, Mingxin Wen, Xiangyu Wu, Shaoguo Liu, Tingting Gao, Zhaojie Liu, Han Li, Kun Gai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08559v1",
    "source": "arXiv",
    "abstract": "With the evolution of large language models (LLMs), there is growing interest in leveraging their rich semantic understanding to enhance industrial recommendation systems (RecSys). Traditional RecSys relies on ID-based embeddings for user sequence modeling in the General Search Unit (GSU) and Exact Search Unit (ESU) paradigm, which suffers from low information density, knowledge isolation, and weak generalization ability. While LLMs offer complementary strengths with dense semantic representations and strong generalization, directly applying LLM embeddings to RecSys faces critical challenges: representation unmatch with business objectives and representation unlearning end-to-end with downstream tasks. In this paper, we present QARM V2, a unified framework that bridges LLM semantic understanding with RecSys business requirements for user sequence modeling."
  },
  {
    "date": "2026-02-09",
    "title": "GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing",
    "authors": "Shih-Fang Chen, Jun-Cheng Chen, I-Hong Jhuo, Yen-Yu Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08550v1",
    "source": "arXiv",
    "abstract": "Human perception for effective object tracking in a 2D video stream arises from the implicit use of prior 3D knowledge combined with semantic reasoning. In contrast, most generic object tracking (GOT) methods primarily rely on 2D features of the target and its surroundings while neglecting 3D geometric cues, which makes them susceptible to partial occlusion, distractors, and variations in geometry and appearance. To address this limitation, we introduce GOT-Edit, an online cross-modality model editing approach that integrates geometry-aware cues into a generic object tracker from a 2D video stream. Our approach leverages features from a pre-trained Visual Geometry Grounded Transformer to enable geometric cue inference from only a few 2D images. To tackle the challenge of seamlessly combining geometry and semantics, GOT-Edit performs online model editing with null-space constrained updates that incorporate geometric information while preserving semantic discrimination, yielding consistently better performance across diverse scenarios. Extensive experiments on multiple GOT benchmarks demonstrate that GOT-Edit achieves superior robustness and accuracy, particularly under occlusion and clutter, establishing a new paradigm for combining 2D semantics with 3D geometric reasoning for generic object tracking."
  },
  {
    "date": "2026-02-09",
    "title": "How Do Language Models Understand Tables? A Mechanistic Analysis of Cell Location",
    "authors": "Xuanliang Zhang, Dingzirui Wang, Keyan Xu, Qingfu Zhu, Wanxiang Che",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08548v1",
    "source": "arXiv",
    "abstract": "While Large Language Models (LLMs) are increasingly deployed for table-related tasks, the internal mechanisms enabling them to process linearized two-dimensional structured tables remain opaque. In this work, we investigate the process of table understanding by dissecting the atomic task of cell location. Through activation patching and complementary interpretability techniques, we delineate the table understanding mechanism into a sequential three-stage pipeline: Semantic Binding, Coordinate Localization, and Information Extraction. We demonstrate that models locate the target cell via an ordinal mechanism that counts discrete delimiters to resolve coordinates. Furthermore, column indices are encoded within a linear subspace that allows for precise steering of model focus through vector arithmetic. Finally, we reveal that models generalize to multi-cell location tasks by multiplexing the identical attention heads identified during atomic location. Our findings provide a comprehensive explanation of table understanding within Transformer architectures."
  },
  {
    "date": "2026-02-09",
    "title": "Can Mirror Symmetry Challenge Local Realism? Probing Photon Entanglement from Positronium via Compton Scattering",
    "authors": "Junle Pei, Lina Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08541v1",
    "source": "arXiv",
    "abstract": "This study investigates photon entanglement generated from para-positronium decay by analyzing azimuthal correlations after the double Compton scattering with stationary electrons. We introduce a normalized correlation observable $\\mathcal{O}_1 = \\cos(2φ_1 - 2φ_2)/C_1$ to witness entanglement. In the absence of decoherence, $\\langle\\mathcal{O}_1\\rangle = -1$, corresponding to a maximally entangled Bell state. With decoherence parameterized by $ρ$, the expectation becomes $-(1-ρ)$, allowing direct experimental quantification of coherence loss. A prior symmetry analysis of the Compton scattering process within the quantum field theory (QFT) is provided, which establishes the mirror-symmetric nature of the single-photon angular distribution. We further examine a local hidden-variable theory (LHVT) under the angular-momentum conservation. Imposing the mirror symmetry with respect to the plane defined by the photon spin and momentum leads to a non-negative LHVT prediction for $\\langle \\sin^2θ_1 \\sin^2θ_2 \\cos(2φ_1-2φ_2)\\rangle$, contradicting the negative QFT prediction value for any $ρ< 1$. Thus, mirror symmetry serves as a novel criterion to exclude LHVT descriptions of the entangled state, whereas without preserving this symmetry, LHVTs can reproduce the correlations."
  },
  {
    "date": "2026-02-09",
    "title": "Coarse grained modeling of self assembled DNA 3D structure using pragmatic soft ellipsoid contact potential",
    "authors": "Abhirup Das, Jayashree Saha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08539v1",
    "source": "arXiv",
    "abstract": "In this paper, we present a coarse-grained model of DNA based on the soft ellipsoid contact potential (ECP) to evaluate the base pairing interaction properly. We extend the ellipsoid contact like potential model (ECP), suitably modified and used previously by our group to model lipid bilayer phases with considerable success. This potential is used for base-base interactions, along with other potentials to capture bending, dihedral and solvent effects. The model shows a phase transition during hybridization and is able to reproduce the experimental melting curves with sufficient adequacy. Thermodynamical, along with conformational characteristics and structural properties of our model are studied in detail."
  },
  {
    "date": "2026-02-09",
    "title": "The stability of boundary equilibria of three-dimensional Filippov systems",
    "authors": "David J. W. Simpson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08536v1",
    "source": "arXiv",
    "abstract": "For three-dimensional piecewise-smooth systems of ordinary differential equations, this paper characterises the stability of points that belong to a switching surface and are equilibria of exactly one of the two neighbouring pieces of the system. Stability is challenging to characterise when nearby orbits repeatedly switch between regular motion on one side of the switching surface, and sliding motion on the switching surface, as defined via Filippov's convention. We prove that in this case stability is governed by the behaviour of a global reinjection mechanism of a four-parameter family of piecewise-linear hybrid systems, and perform a detailed numerical study of this family."
  },
  {
    "date": "2026-02-09",
    "title": "Causal Schrödinger Bridges: Constrained Optimal Transport on Structural Manifolds",
    "authors": "Rui Wu, Li YongJun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08535v1",
    "source": "arXiv",
    "abstract": "Generative modeling typically seeks the path of least action via deterministic flows (ODE). While effective for in-distribution tasks, we argue that these deterministic paths become brittle under causal interventions, which often require transporting probability mass across low-density regions (\"off-manifold\") where the vector field is ill-defined. This leads to numerical instability and spurious correlations. In this work, we introduce the Causal Schrödinger Bridge (CSB), a framework that reformulates counterfactual inference as Entropic Optimal Transport. Unlike deterministic approaches that require strict invertibility, CSB leverages diffusion processes (SDEs) to robustly \"tunnel\" through support mismatches while strictly enforcing structural admissibility constraints. We prove the Structural Decomposition Theorem, showing that the global high-dimensional bridge factorizes into local, robust transitions. Empirical validation on high-dimensional interventions (Morpho-MNIST) demonstrates that CSB significantly outperforms deterministic baselines in structural consistency, particularly in regimes of strong, out-of-distribution treatments."
  },
  {
    "date": "2026-02-09",
    "title": "Global observables and identified-hadron production in pp, O-O and Pb-Pb collisions at LHC Run 3 energies with EPOS4",
    "authors": "Hirak Kumar Koley, Mitali Mondal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08534v1",
    "source": "arXiv",
    "abstract": "The observation of collectivity in small and large collision systems challenges our understanding of thermalization and particle production. EPOS4 models this via a dynamical core--corona separation, where high-density regions form a collectively expanding core while low-density regions hadronize via string fragmentation. Its microcanonical core hadronization improves the description of transverse momentum and multiplicity-dependent observables. We present EPOS4 predictions for pp, O-O and Pb-Pb collisions, with and without UrQMD, showing non-universal $\\langle p_T\\rangle$ scaling, significant hadronic-phase effects, and system-size-dependent $R_{AA}$ suppression. Charged-particle and transverse-energy densities show participant scaling; the transverse energy per charged particle is systematically larger in O--O than in Pb--Pb at comparable participant fraction, indicating a harder effective production in the lighter system. Identified-hadron spectra harden with event multiplicity with mass ordering and increasing core fractions. The mean transverse momentum exhibits a strong system dependence, with the steepest multiplicity evolution in pp, demonstrating that $\\langle p_T\\rangle$ does not follow universal multiplicity scaling. The $p/π$ ratio shows an enhanced intermediate-$p_T$ region; the suppression of the integrated $p/π$ at the highest Pb--Pb multiplicities is reproduced only with UrQMD, highlighting hadronic-phase effects. The nuclear modification factor shows sizeable suppression in Pb--Pb and substantial suppression in central O--O collisions. Blast-wave fits exhibit the anti-correlation between $T_{\\rm kin}$ and $\\langleβ_T\\rangle$, with UrQMD shifting the parameters towards lower $T_{\\rm kin}$ and higher $\\langleβ_T\\rangle$. These results provide a timely baseline for Run~3 measurements and for constraining the onset of medium-like effects across system size."
  },
  {
    "date": "2026-02-09",
    "title": "EvoCorps: An Evolutionary Multi-Agent Framework for Depolarizing Online Discourse",
    "authors": "Ning Lin, Haolun Li, Mingshu Liu, Chengyun Ruan, Kaibo Huang, Yukun Wei, Zhongliang Yang, Linna Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08529v1",
    "source": "arXiv",
    "abstract": "Polarization in online discourse erodes social trust and accelerates misinformation, yet technical responses remain largely diagnostic and post-hoc. Current governance approaches suffer from inherent latency and static policies, struggling to counter coordinated adversarial amplification that evolves in real-time. We present EvoCorps, an evolutionary multi-agent framework for proactive depolarization. EvoCorps frames discourse governance as a dynamic social game and coordinates roles for monitoring, planning, grounded generation, and multi-identity diffusion. A retrieval-augmented collective cognition core provides factual grounding and action--outcome memory, while closed-loop evolutionary learning adapts strategies as the environment and attackers change. We implement EvoCorps on the MOSAIC social-AI simulation platform for controlled evaluation in a multi-source news stream with adversarial injection and amplification. Across emotional polarization, viewpoint extremity, and argumentative rationality, EvoCorps improves discourse outcomes over an adversarial baseline, pointing to a practical path from detection and post-hoc mitigation to in-process, closed-loop intervention. The code is available at https://github.com/ln2146/EvoCorps."
  },
  {
    "date": "2026-02-09",
    "title": "Consumption-Investment with anticipative noise",
    "authors": "Mario Ayala, Benjamin Vallejo Jiménez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08527v1",
    "source": "arXiv",
    "abstract": "We revisit the classical Merton consumption--investment problem when risky-asset returns are modeled by stochastic differential equations interpreted through a general $α$-integral, interpolating between Itô, Stratonovich, and related conventions. Holding preferences and the investment opportunity set fixed, changing the noise interpretation modifies the effective drift of asset returns in a systematic way. For logarithmic utility and constant volatilities, we derive closed-form optimal policies in a market with $n$ risky assets: optimal consumption remains a fixed fraction of wealth, while optimal portfolio weights are shifted according to $θ_α^\\ast = V^{-1}(μ-r\\mathbf{1})+α\\,V^{-1}\\operatorname{diag}(V)\\mathbf{1}$, where $V$ is the return covariance matrix and $\\operatorname{diag}(V)$ denotes the diagonal matrix with the same diagonal as $V$. In the single-asset case this reduces to $θ_α^\\ast=(μ-r)/σ^{2}+α$. We then show that genuinely state-dependent effects arise when asset volatility is driven by a stochastic factor correlated with returns. In this setting, the $α$-interpretation generates an additional drift correction proportional to the instantaneous covariation between factor and return noise. As a canonical example, we analyze a Heston stochastic volatility model, where the resulting optimal risky exposure depends inversely on the current variance level."
  },
  {
    "date": "2026-02-09",
    "title": "Characteristics, Management, and Utilization of Muscles in Musculoskeletal Humanoids: Empirical Study on Kengoro and Musashi",
    "authors": "Kento Kawaharazuka, Kei Okada, Masayuki Inaba",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08518v1",
    "source": "arXiv",
    "abstract": "Various musculoskeletal humanoids have been developed so far, and numerous studies on control mechanisms have been conducted to leverage the advantages of their biomimetic bodies. However, there has not been sufficient and unified discussion on the diverse properties inherent in these musculoskeletal structures, nor on how to manage and utilize them. Therefore, this study categorizes and analyzes the characteristics of muscles, as well as their management and utilization methods, based on the various research conducted on the musculoskeletal humanoids we have developed, Kengoro and Musashi. We classify the features of the musculoskeletal structure into five properties: Redundancy, Independency, Anisotropy, Variable Moment Arm, and Nonlinear Elasticity. We then organize the diverse advantages and disadvantages of musculoskeletal humanoids that arise from the combination of these properties. In particular, we discuss body schema learning and reflex control, along with muscle grouping and body schema adaptation. Also, we describe the implementation of movements through an integrated system and discuss future challenges and prospects."
  },
  {
    "date": "2026-02-09",
    "title": "Preserving Hamiltonian Locality in Real-Space Coarse-Graining via Kernel Projection",
    "authors": "Sun Haoyuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08502v1",
    "source": "arXiv",
    "abstract": "Numerical simulations of critical lattice systems are fundamentally limited by critical slowing down, as long-range correlations are typically established through slow temporal equilibration. A physically constrained generative framework that replaces temporal relaxation with a spatial projection mechanism for critical systems is proposed. Using the two-dimensional Ising model at criticality as a benchmark, we introduce an energy-constrained kernel that synthesizes large-scale configurations from compact equilibrated seeds by enforcing Hamiltonian-level observables. The generated configurations are projected onto the nearest-neighbor energy manifold, ensuring thermodynamic consistency while retaining universal critical properties. We show that the resulting configurations reproduce scale-invariant spin correlations, Binder cumulants, and isotropic structure factors for lattice sizes exceeding 10,000, without iterative Monte Carlo equilibration. While not a strict renormalization group transformation, and motivated by renormalization ideas, the method provides a practical inverse mapping that retains universal features of criticality and enables efficient GPU-parallel generation of ultra-large critical ensembles."
  },
  {
    "date": "2026-02-09",
    "title": "Characterizing, Evaluating, and Optimizing Complex Reasoning",
    "authors": "Haoran Zhang, Yafu Li, Zhi Wang, Zhilin Wang, Shunkai Zhang, Xiaoye Qu, Yu Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08498v1",
    "source": "arXiv",
    "abstract": "Large Reasoning Models (LRMs) increasingly rely on reasoning traces with complex internal structures. However, existing work lacks a unified answer to three fundamental questions: (1) what defines high-quality reasoning, (2) how to reliably evaluate long, implicitly structured reasoning traces, and (3) how to use such evaluation signals for reasoning optimization. To address these challenges, we provide a unified perspective. (1) We introduce the ME$^2$ principle to characterize reasoning quality along macro- and micro-level concerning efficiency and effectiveness. (2) Built on this principle, we model reasoning traces as directed acyclic graphs (DAGs) and develop a DAG-based pairwise evaluation method, capturing complex reasoning structures. (3) Based on this method, we construct the TRM-Preference dataset and train a Thinking Reward Model (TRM) to evaluate reasoning quality at scale. Experiments show that thinking rewards serve as an effective optimization signal. At test time, selecting better reasoning leads to better outcomes (up to 19.3% gain), and during RL training, thinking rewards enhance reasoning and performance (up to 3.9% gain) across diverse tasks."
  },
  {
    "date": "2026-02-09",
    "title": "Empirical Study of Observable Sets in Multiclass Quantum Classification",
    "authors": "Paul San Sebastian, Mikel Cañizo, Roman Orus",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08485v1",
    "source": "arXiv",
    "abstract": "Variational quantum algorithms have gained attention as early applications of quantum computers for learning tasks. In the context of supervised learning, most of the works that tackle classification problems with parameterized quantum circuits constrain their scope to the setting of binary classification or perform multiclass classification via ensembles of binary classifiers (strategies such as one versus rest). Those few works that propose native multiclass models, however, do not justify the choice of observables that perform the classification. This work studies two main classification criteria in multiclass quantum machine learning: maximizing the expected value of an observable representing a class or maximizing the fidelity of the encoded quantum state with a reference state representing a class. To compare both approaches, sets of Pauli strings and sets of projectors into the computational basis are chosen as observables in the quantum machine learning models. Observing the empirical behavior of each model type, the effect of different observable set choices on the performance of quantum machine learning models is analyzed in the context of Barren Plateaus and Neural Collapse. The results provide insights that may guide the design of future multiclass quantum machine learning models."
  },
  {
    "date": "2026-02-09",
    "title": "Emergence of Superintelligence from Collective Near-Critical Dynamics in Reentrant Neural Fields",
    "authors": "Byung Gyu Chae",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08483v1",
    "source": "arXiv",
    "abstract": "Superintelligence is commonly envisioned as a quantitative extrapolation of human cognitive abilities driven by scale and computational power. Here we show that qualitative transitions in intelligence instead arise as dynamical phase transitions governed by collective critical dynamics. Building on a unified dynamical field-theoretic framework for cognition, we demonstrate that progressive collective coupling generated by reentrant mixing drives the system toward an infrared critical regime in which an extensive band of slow collective modes emerges. This spectral condensation reorganizes cognitive dynamics from localized relaxation to coherent motion along emergent low-dimensional manifolds. Through numerical analysis of the time-scale density of states, we identify robust power-law scaling of collective relaxation rates with well-defined critical exponents, placing the system within the universality class of self-organized critical many-body dynamics. Criticality alone would generically lead to instability. We further show that homeostatic regulation introduces a gapped stabilizing direction that protects the collective critical sector, yielding a dynamically maintained meta-stable infrared phase in which long-lived inference trajectories persist without collapse. The coexistence of scale-free collective dynamics and global stabilization defines a protected sector-critical regime in which coherence and internal flexibility coexist. Superintelligence therefore corresponds to a distinct dynamical stability class--a self-organized critical phase embedded within a stabilized cognitive manifold--rather than a smooth quantitative continuation of existing cognitive systems."
  },
  {
    "date": "2026-02-09",
    "title": "Existence and Regularity of Minimizers for a Plateau Approximation Problem",
    "authors": "Eve Machefert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08476v1",
    "source": "arXiv",
    "abstract": "In this paper, we study the functional introduced by the author in collaboration with Bonnivard, Bretin, and Lemenant, which is designed to approximate Plateau's problem. We establish the existence of a minimizer and prove its H{ö}lder regularity. Our results may be viewed as a generalization to higher-dimensional surfaces of the one-dimensional work of Bonnivard, Lemenant, and Millot on the approximation of the Steiner problem."
  },
  {
    "date": "2026-02-09",
    "title": "A building block of quantum repeaters for scalable quantum networks",
    "authors": "Wen-Zhao Liu, Ya-Bin Zhou, Jiu-Peng Chen, Bin Wang, Ao Teng, Xiao-Wen Han, Guang-Cheng Liu, Zhi-Jiong Zhang, Yi Yang, Feng-Guang Liu, ChaoHui Xue, Bo-Wen Yang, Jin Yang, Chao Zeng, Du-Ruo Pan, Ming-Yang Zheng, Xing-Jian Zhang, Cao Shen, Yi-Zheng Zhen, You Xiao, Hao Li, Li-Xing You, XiongFeng Ma, Qi Zhao, Feihu Xu, Ye Wang, Yong Wan, Qiang Zhang, Jian-Wei Pan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08472v1",
    "source": "arXiv",
    "abstract": "Quantum networks, integrating quantum communication, quantum metrology, and distributed quantum computing, could provide secure and efficient information transfer, high-resolution sensing, and an exponential speed-up in information processing. Deterministic entanglement distribution over long distances is a prerequisite for scalable quantum networks, enabling the utilization of device-independent quantum key distribution (DI-QKD) and quantum teleportation to achieve secure and efficient information transfer. However, the exponential photon loss in optical fibres prohibits efficient and deterministic entanglement distribution. Quantum repeaters, incorporating entanglement swapping and entanglement purification with quantum memories, offer the most promising means to overcome this limitation in fibre-based quantum networks. Despite numerous pioneering efforts toward realizing quantum repeaters, a critical bottleneck remains, as remote memory-memory entanglement suffers from decoherence more rapidly than it can be established and purified over long distances. We overcome this by developing long-lived trapped-ion memories, an efficient telecom interface, and a high-visibility single-photon entanglement protocol. This allows us to establish and maintain memory-memory entanglement over a 10 km fibre within the average entanglement establishment time for the same distance. As a direct application, we demonstrate metropolitan-scale DI-QKD, distilling 1,917 secret keys out of 4.05*10^5 Bell pairs over 10 km. We further report a positive key rate over 101 km in the asymptotic limit, extending the achievable distance by more than two orders of magnitude. Our work provides a critical building block for quantum repeaters and marks an important step toward scalable quantum networks."
  },
  {
    "date": "2026-02-09",
    "title": "A Two-Week In-the-Wild Study of Screen Filters and Camera Sliders for Smartphone Privacy in Public Spaces",
    "authors": "Andreas Tjeldflaat, Piero Romare, Yuki Onishi, Morten Fjeld, Bjørn Sætrevik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08465v1",
    "source": "arXiv",
    "abstract": "Smartphone usage in public spaces can raise privacy concerns, in terms of shoulder surfing and unintended camera capture. In real-world public space settings, we investigated the impact of tangible privacy-enhancing tools (here: screen filter and camera slider) on smartphone users' reported privacy perception, behavioral adaptations, usability and social dynamics. We conducted a mixed-method, in-the-wild study ($N = 22$) using off-the-shelf smartphone privacy tools. We investigated subjective behavioral transition by combining questionnaires with semi-structured interviews. Participants used the screen filter and the camera slider for two weeks; they reported changes in attitude and behavior after using a screen filter including screen visibility and comfort when using phones publicly. They explained decreased privacy-protective behaviors, such as actively covering their screens, suggesting a shift in perceived risk. Qualitative findings about the camera slider suggested underlying psychological mechanisms, including privacy awareness and concerns about social perception, while also offering insights regarding the tools' effectiveness."
  },
  {
    "date": "2026-02-09",
    "title": "Non-Markovianity induced by Pauli-twirling",
    "authors": "Joris Kattemölle, Balázs Gulácsi, Guido Burkard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08464v1",
    "source": "arXiv",
    "abstract": "Noise forms a central obstacle to effective quantum information processing. Recent experimental advances have enabled the tailoring of noise properties through Pauli twirling, transforming arbitrary noise channels into Pauli channels. This underpins theoretical descriptions of fault-tolerant quantum computation and forms an essential tool in noise characterization and error mitigation. Pauli-Lindblad channels have been introduced to aptly parameterize quasi-local Pauli errors across a quantum register, excluding negative Pauli-Lindblad parameters relying on the Markovianity of the underlying noise processes. We point out that caution is required when parameterizing channels as Pauli-Lindblad channels with nonnegative parameters. For this, we study the effects of Pauli twirling on Markovianity. We use the notion of Markovianity of a channel (rather than that of an entire semigroup) and prove a general Pauli channel is non-Markovian if and only if at least one of its Pauli-Lindblad parameters is negative. Using this, we show that Markovian quantum channels often become non-Markovian after Pauli twirling. The Pauli-twirling induced non-Markovianity necessitates the use of negative Pauli-Lindblad parameters for a correct noise description in experimentally realistic scenarios. An important example is the implementation of the $\\sqrt{X}$-gate under standard Markovian noise. As such, our results have direct implications for quantum error mitigation protocols that rely on accurate noise characterization."
  },
  {
    "date": "2026-02-09",
    "title": "Wave propagation in the frequency regime in one-dimensional quasiperiodic media -Limiting absorption principle",
    "authors": "Pierre Amenoagbadji, Sonia Fliss, Patrick Joly",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08442v1",
    "source": "arXiv",
    "abstract": "We study the one-dimensional Helmholtz equation with (possibly perturbed) quasiperiodic coefficients. Quasiperiodic functions are the restriction of higher dimensional periodic functions along a certain (irrational) direction. In classical settings, for real-valued frequencies, this equation is generally not well-posed: existence of solutions in L 2 is not guaranteed and uniqueness in L $\\infty$ may fail. This is a well-known difficulty of Helmholtz equations, but it has never been addressed in the quasiperiodic case. We tackle this issue by using the limiting absorption principle, which consists in adding some imaginary part (also called absorption) to the frequency in order to make the equation well-posed in L 2 , and then defining the physically relevant solution by making the absorption tend to zero. In previous work, we introduced a definition of the solution of the equation with absorption based on Dirichlet-to-Neumann (DtN) boundary conditions. This approach offers two key advantages: it facilitates the limiting process and has a direct numerical counterpart. In this work, we first explain why the DtN boundary conditions have to be replaced by Robin-to-Robin boundary conditions to make the absorption go to zero. We then prove, under technical assumptions on the frequency, that the limiting absorption principle holds and we propose a numerical method to compute the physical solution."
  },
  {
    "date": "2026-02-09",
    "title": "Towards FAIR Astrophysical Simulations",
    "authors": "Susanne Pfalzner, Stephan Hachinger, Jolanta Zjupa, Salvatore Cielo, Frank W. Wagner, Marcus Brüggen, Annika Hagemeier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08416v1",
    "source": "arXiv",
    "abstract": "Reproducibility is a cornerstone of science. FAIR (findable, accessible, interoperable, and reusable) data is often a vital step towards testing the reproducibility of results. The implementation of FAIR principles in the astrophysical simulation community is still varied. We approach the discussion of this topic mainly from a high-performance computing (HPC) point of view. We identify the main obstacles to FAIR astrophysics simulations: First, the vast datasets created in simulations on HPC facilities complicate FAIR data management. Second, missing incentives to fully share codes, results, and diagnostic data. Third, a lack of workflows that include data publication and technical support. Therefore, particularly smaller research groups struggle due to the unavailability of dedicated personnel and time in their efforts towards FAIR and open simulations. We propose actionable steps towards achieving ``FAIRer'' data and open source publication standards in numerical astrophysics. Our suggestions include low-threshold methods to fulfil the basic FAIR requirements as well as basic tools for FAIR (meta-)data generation and data/code publication. This work is a high-level overview intended to initiate discussions within the community, offering initial solutions to these challenges."
  },
  {
    "date": "2026-02-09",
    "title": "Reconfigurable Low-Complexity Architecture for High Resolution Doppler Velocity Estimation in Integrated Sensing and Communication System",
    "authors": "Aakanksha Tewari, Samarth Sharma Bhardwaj, Sumit J Darak, Shobha Sundar Ram",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08415v1",
    "source": "arXiv",
    "abstract": "In millimeter wave integrated sensing and communication (ISAC) systems for intelligent transportation, radar and communication share spectrum and hardware in a time division manner. Radar rapidly detects and localizes mobile users (MUs), after which communication proceeds through narrow beams identified by radar. Achieving fine Doppler resolution for MU clutter discrimination requires long coherent processing intervals, reducing communication time and throughput. To address this, we propose a reconfigurable architecture for Doppler estimation realized on a system on chip using hardware software codesign. The architecture supports algorithm level reconfiguration, dynamically switching between low-complexity, high-speed FFT-based coarse estimation and high complexity ESPRIT based fine estimation. We introduce modifications to ESPRIT that achieve 6.7 times faster execution while reducing memory and multiplier usage by 79% and 63%, respectively, compared to state of the art approaches, without compromising accuracy. Additionally, the reconfigurable architecture can switch to lower slow time packets under high SNR conditions, improving latency further by 2 times with no loss in performance."
  },
  {
    "date": "2026-02-09",
    "title": "Temporal Trends in Incidence of Dementia in a Birth Cohorts Analysis of the Framingham Heart Study",
    "authors": "Paula Staudt, Anika Schlosser, Annika Möhl, Martin Schumacher, Nadine Binder",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08414v1",
    "source": "arXiv",
    "abstract": "Background: Dementia leads to a high burden of disability and the number of dementia patients worldwide doubled between 1990 and 2016. Nevertheless, some studies indicated a decrease in dementia risk which may be due to a bias caused by conventional analysis methods that do not adequately account for missing disease information due to death. Methods: This study re-examines potential trends in dementia incidence over four decades in the Framingham Heart Study. We apply a multistate modeling framework tailored to interval-censored illness-death data and define three non-overlapping birth cohorts (1915-1924, 1925-1934, and 1935-1944). Trends are evaluated based on both dementia prevalence and dementia risk, using age as the underlying timescale. Additionally, age-conditional dementia probabilities stratified by sex are estimated. Results: A total of 731 out of 3828 individuals were diagnosed with dementia. The multistate model analysis revealed no temporal decline in dementia risk across birth cohorts, irrespective of sex. When stratified by sex and adjusted for education, women consistently exhibited higher lifetime age-conditional risks (46%-50%) than men (30%-34%) over the study period. Conclusions: We recommend using a combination of multistate approach and separation into birth cohorts to adequately estimate trends of disease risk in cohort studies as well as to communicate patient-relevant outcomes such age-conditional disease risks."
  },
  {
    "date": "2026-02-09",
    "title": "From Assistant to Double Agent: Formalizing and Benchmarking Attacks on OpenClaw for Personalized Local AI Agent",
    "authors": "Yuhang Wang, Feiming Xu, Zheng Lin, Guangyu He, Yuzhe Huang, Haichang Gao, Zhenxing Niu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08412v1",
    "source": "arXiv",
    "abstract": "Although large language model (LLM)-based agents, exemplified by OpenClaw, are increasingly evolving from task-oriented systems into personalized AI assistants for solving complex real-world tasks, their practical deployment also introduces severe security risks. However, existing agent security research and evaluation frameworks primarily focus on synthetic or task-centric settings, and thus fail to accurately capture the attack surface and risk propagation mechanisms of personalized agents in real-world deployments. To address this gap, we propose Personalized Agent Security Bench (PASB), an end-to-end security evaluation framework tailored for real-world personalized agents. Building upon existing agent attack paradigms, PASB incorporates personalized usage scenarios, realistic toolchains, and long-horizon interactions, enabling black-box, end-to-end security evaluation on real systems. Using OpenClaw as a representative case study, we systematically evaluate its security across multiple personalized scenarios, tool capabilities, and attack types. Our results indicate that OpenClaw exhibits critical vulnerabilities at different execution stages, including user prompt processing, tool usage, and memory retrieval, highlighting substantial security risks in personalized agent deployments. The code for the proposed PASB framework is available at https://github.com/AstorYH/PASB."
  },
  {
    "date": "2026-02-09",
    "title": "High-resolution X-ray spectroscopy of Cen X-3 with XMM-Newton",
    "authors": "J. J. Rodes-Roca, J. M. Torrejón, G. Sanjurjo-Ferrín, J. Planelles Villalva",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08408v1",
    "source": "arXiv",
    "abstract": "The spectral analysis of two XMM-Newton observations of the high-mass X-ray binary system Cen X-3 is presented. In particular, it is focused on the eclipse and out-of-eclipse spectra in order to compare the properties of the environment around the compact object. The high-resolution spectra obtained from the reflection grating spectrometer on board XMM-Newton was analysed focusing on studying eclipse and out-of-eclipse spectra separately. Several continuum models were explored in SPEX for which we studied the properties of emitting and absorbing matter depending on the emission and absorption lines identified in the spectra. It was found that the X-ray continuum is heavily absorbed by a neutral gas and photoionised matter. Emission lines from Si v, Mg xii, Mg xi, and Ne x were detected in the eclipse spectrum. In particular, H-like lines of Mg and Ne with a significance greater than 5 sigma in the eclipse spectrum and 3 sigma in the out-of-eclipse spectrum. But in the out-of-eclipse spectrum any absorption lines, if any, were detected with a significance less than 2 sigma. RGS light curve showed dips in the out-of-eclipse spectrum which are not due to an increase in the column absorption but may be produced by instabilities in the accretion stream. On the other hand, the level of counts above 20 was compatible with the X-ray background. A simple local continuum model was used to describe the He-like triplet of Ne and the derived values of R and G ratio parameters pointed out that the UV photospheric field should be important at the line production site and an electron density greater than 10(12) cm-3. As a consequence, a hybrid plasma may be present in the binary system."
  },
  {
    "date": "2026-02-09",
    "title": "Stationary densities in a weakly nonconserving asymmetric exclusion processes with finite resources",
    "authors": "Sourav Pal, Abhik Basu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08405v1",
    "source": "arXiv",
    "abstract": "Asymmetric exclusion process (TASEP) along a one-dimensional (1D) open channel sets the paradigm for 1D driven models and nonequilibrium phase transitions in open 1D models. Inspired by the phenomenologies of an open TASEP with Langmuir kinetics (Lk) and with finite resources, we study the stationary densities and phase transitions in a TASEP with Lk connected to a particle reservoir at its both ends. We calculate the stationary density profiles and the phase transitions. The resulting phase diagrams in the plane of the control parameters are significantly different from their counterparts in an open TASEP with Lk. In particular, some of the phases admissible in the open TASEP with Lk model are no longer possible. Intriguingly, our model that is closely related to a TASEP coupled with Lk on a ring with a point defect, admits more phases than the latter. Phenomenological implications of our results are discussed."
  },
  {
    "date": "2026-02-09",
    "title": "RealSynCol: a high-fidelity synthetic colon dataset for 3D reconstruction applications",
    "authors": "Chiara Lena, Davide Milesi, Alessandro Casella, Luca Carlini, Joseph C. Norton, James Martin, Bruno Scaglioni, Keith L. Obstein, Roberto De Sire, Marco Spadaccini, Cesare Hassan, Pietro Valdastri, Elena De Momi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08397v1",
    "source": "arXiv",
    "abstract": "Deep learning has the potential to improve colonoscopy by enabling 3D reconstruction of the colon, providing a comprehensive view of mucosal surfaces and lesions, and facilitating the identification of unexplored areas. However, the development of robust methods is limited by the scarcity of large-scale ground truth data. We propose RealSynCol, a highly realistic synthetic dataset designed to replicate the endoscopic environment. Colon geometries extracted from 10 CT scans were imported into a virtual environment that closely mimics intraoperative conditions and rendered with realistic vascular textures. The resulting dataset comprises 28\\,130 frames, paired with ground truth depth maps, optical flow, 3D meshes, and camera trajectories. A benchmark study was conducted to evaluate the available synthetic colon datasets for the tasks of depth and pose estimation. Results demonstrate that the high realism and variability of RealSynCol significantly enhance generalization performance on clinical images, proving it to be a powerful tool for developing deep learning algorithms to support endoscopic diagnosis."
  },
  {
    "date": "2026-02-09",
    "title": "Modalities, a PyTorch-native Framework For Large-scale LLM Training and Research",
    "authors": "Max Lübbering, Timm Ruland, Richard Rutmann, Felix Stollenwerk, David Fitzek, Michael Fromm, Alexander Weber, Rafet Sifa, Nicolas Flores-Herr, Joachim Köhler, Mehdi Ali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08387v1",
    "source": "arXiv",
    "abstract": "Today's LLM (pre-) training and research workflows typically allocate a significant amount of compute to large-scale ablation studies. Despite the substantial compute costs of these ablations, existing open-source frameworks provide limited tooling for these experiments, often forcing researchers to write their own wrappers and scripts. We propose Modalities, an end-to-end PyTorch-native framework that integrates data-driven LLM research with large-scale model training from two angles. Firstly, by integrating state-of-the-art parallelization strategies, it enables both efficient pretraining and systematic ablations at trillion-token and billion-parameter scale. Secondly, Modalities adopts modular design with declarative, self-contained configuration, enabling reproducibility and extensibility levels that are difficult to achieve out-of-the-box with existing LLM training frameworks."
  },
  {
    "date": "2026-02-09",
    "title": "Testing Backward-Flatness of Nonlinear Discrete-Time Systems",
    "authors": "Johannes Schrotshamer, Bernd Kolar, Markus Schöberl",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08385v1",
    "source": "arXiv",
    "abstract": "Despite ongoing research, testing the flatness of discrete-time systems remains a challenging problem. To date, only the property of forward-flatness - a special case of difference-flatness - can be checked in a computationally efficient manner. In this paper, we propose a systematic approach for testing backward-flatness, which is another special case of difference-flatness, and for deriving a corresponding backward-flat output. Additionally, we discuss the relationship between the Jacobian matrices associated with the flat parameterization of backward- and forward-flat systems and illustrate our results by an academic example."
  },
  {
    "date": "2026-02-09",
    "title": "Towards Real-World Industrial-Scale Verification: LLM-Driven Theorem Proving on seL4",
    "authors": "Jianyu Zhang, Fuyuan Zhang, Jiayi Lu, Jilin Hu, Xiaoyi Yin, Long Zhang, Feng Yang, Yongwang Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08384v1",
    "source": "arXiv",
    "abstract": "Formal methods (FM) are reliable but costly to apply, often requiring years of expert effort in industrial-scale projects such as seL4, especially for theorem proving. Recent advances in large language models (LLMs) have made automated theorem proving increasingly feasible. However, most prior work focuses on mathematics-oriented benchmarks such as miniF2F, with limited evaluation on real-world verification projects. The few studies that consider industrial-scale verification mostly rely on closed-source models with hundreds of billions of parameters, which cannot be locally deployed and incur substantial usage costs. In this paper, we propose AutoReal, an LLM-driven theorem proving method for real-world industrial-scale systems with support for lightweight local deployment. We evaluate AutoReal on the seL4-Isabelle verification project as a representative and challenging case study. AutoReal incorporates two key improvements: (1) chain-of-thought (CoT)-based proof training, which teaches the LLM the reasoning behind proof steps and enables step-wise explanations alongside proofs, and (2) context augmentation, which leverages proof context from the project to enhance LLM-driven proving. Based on the AutoReal methodology, we fine-tune a base model to obtain AutoReal-Prover, a compact 7B-scale prover for industrial-scale theorem proving. AutoReal-Prover achieves a 51.67% proof success rate on 660 theorems from seL4-designated Important Theories across all 10 seL4 proof categories, substantially outperforming prior attempts on seL4 (27.06%). To evaluate generalization, we further apply AutoReal-Prover to three security-related projects from the Archive of Formal Proofs (AFP), covering all 451 theorems and achieving a proof success rate of 53.88%. Overall, this work advances the application of LLM-driven theorem proving in real-world industrial-scale verification."
  },
  {
    "date": "2026-02-09",
    "title": "Beam Alignment in Multipath Environments for Integrated Sensing and Communication using Bandit Learning",
    "authors": "Akanksha Sneh, Shobha Sundar Ram, Sumit J Darak, Aakanksha Tewari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08380v1",
    "source": "arXiv",
    "abstract": "Prior works have explored multi-armed bandit (MAB) algorithms for the selection of optimal beams for millimeter-wave (mmW) communications between base station and mobile users. However, when the number of beams is large, the existing MAB algorithms are characterized by long exploration times, resulting in poor overall communication throughput. In this work, we propose augmenting the upper confidence bound (UCB) based MAB with integrated sensing and communication (ISAC) to address this limitation. The premise of the work is that the radar and communication functionalities share the same field-of-view and that communication mobile users are detected by the radar as mobile targets. The radar information is used for significantly reducing the number of candidate beams for the UCB, resulting in an overall reduction in the exploration time. Further, the radar information is used to estimate the realignment time in quasi-stationary scenarios. We have realized the MAB and radar signal processing algorithms on the system on chip (SoC) via hardware-software co-design (HSCD) and fixed-point analysis. We demonstrate the significant gain in execution time using accelerators. The simulations consider complex propagation channels involving direct and multipath, with simple and extended radar targets in the presence of significant static clutter. The resulting experiments show that the proposed ISAC-based MAB achieves a 35% reduction in the overall exploration time and 1.4 factor higher throughput as compared to the conventional MAB that is based only on communications."
  },
  {
    "date": "2026-02-09",
    "title": "Schrödinger bridge problem via empirical risk minimization",
    "authors": "Denis Belomestny, Alexey Naumov, Nikita Puchkin, Denis Suchkov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08374v1",
    "source": "arXiv",
    "abstract": "We study the Schrödinger bridge problem when the endpoint distributions are available only through samples. Classical computational approaches estimate Schrödinger potentials via Sinkhorn iterations on empirical measures and then construct a time-inhomogeneous drift by differentiating a kernel-smoothed dual solution. In contrast, we propose a learning-theoretic route: we rewrite the Schrödinger system in terms of a single positive transformed potential that satisfies a nonlinear fixed-point equation and estimate this potential by empirical risk minimization over a function class. We establish uniform concentration of the empirical risk around its population counterpart under sub-Gaussian assumptions on the reference kernel and terminal density. We plug the learned potential into a stochastic control representation of the bridge to generate samples. We illustrate performance of the suggested approach with numerical experiments."
  },
  {
    "date": "2026-02-09",
    "title": "Roadmap to Quantum Aesthetics",
    "authors": "Ivan C. H. Liu, Hsiao-Yuan Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08363v1",
    "source": "arXiv",
    "abstract": "Quantum mechanics occupies a central position in contemporary science while remaining largely inaccessible to direct sensory experience. This paper proposes a roadmap to quantum aesthetics that examines how quantum concepts become aesthetic phenomena through artistic mediation rather than direct representation. Two complementary and orthogonal approaches are articulated. The first, a pioneering top-down approach, employs text-prompt-based generative AI to probe quantum aesthetics as a collective cultural construct embedded in large-scale training data. By systematically modulating the linguistic weight of the term \"quantum,\" generative models are used as experimental environments to reveal how quantum imaginaries circulate within contemporary visual culture. The second, a bottom-up approach, derives aesthetic form directly from quantum-mechanical structures through the visualization of quantum-generated data, exemplified here by hydrogen atomic orbitals calculated from the Schrödinger equation. These approaches are framed not as competing methods but as intersecting paths within a navigable field of artistic research. They position quantum aesthetics as an emergent field of artistic research shaped by cultural imagination, computational mediation, and physical law, opening new directions for artistic practice and pedagogy at the intersection of art, data, artificial intelligence and quantum science."
  },
  {
    "date": "2026-02-09",
    "title": "Quantum-classical framework for many-fermion response and structure",
    "authors": "Weijie Du, Yangguang Yang, Zixin Liu, Chao Yang, James P. Vary",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08357v1",
    "source": "arXiv",
    "abstract": "Response functions are key observables for probing the structure and dynamics of many-body systems. We introduce and demonstrate a quantum-classical framework for computing response functions of general many-fermion systems that also provides the full bound-state spectrum. The framework employs the Lorentz integral transform and a new Hamiltonian input scheme that enables practical and scalable circuit constructions for general many-fermion Hamiltonians. Within this framework, we develop a hybrid strategy to evaluate the Lorentz integral and propose three protocols to extract response functions and bound-state structural information. As a demonstration, we apply the method to \\({}^{19}\\mathrm{O}\\) with realistic internucleon interactions, computing both the bound-state spectrum and the response function. We envision that our approach will open new avenues for exploring the structure and dynamics of a broad class of many-body systems across diverse fields."
  },
  {
    "date": "2026-02-09",
    "title": "Search for the QCD Critical Point in High Energy Nuclear Collisions: A Status Report",
    "authors": "Yu Zhang, Zhaohui Wang, Xiaofeng Luo, Nu Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08356v1",
    "source": "arXiv",
    "abstract": "We review recent results of net-proton multiplicity fluctuations from STAR experiment, aiming to locate the QCD critical point in high-energy nuclear collisions at RHIC. We show net-proton number cumulant and proton number factorial cumulant ratios up to fourth order using experimental data from RHIC BES-II Au+Au collisions in collider mode and fixed-target mode. The comparison is made between experimental data and non-critical model calculations from Lattice QCD, HRG, hydrodynamic simulations and transport model UrQMD. In addition, we discuss initial volume fluctuation effect, which plays significant role in fixed-target energies. Finally, an outlook on experimental research on the QCD critical point in future experiments will be presented."
  },
  {
    "date": "2026-02-09",
    "title": "Does Your Reasoning Model Implicitly Know When to Stop Thinking?",
    "authors": "Zixuan Huang, Xin Xia, Yuxi Ren, Jianbin Zheng, Xuanda Wang, Zhixia Zhang, Hongyan Xie, Songshi Liang, Zehao Chen, Xuefeng Xiao, Fuzhen Zhuang, Jianxin Li, Yikun Ban, Deqing Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08354v1",
    "source": "arXiv",
    "abstract": "Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy. In a further in-depth analysis of this phenomenon, we surprisingly uncover and empirically verify that LRMs implicitly know the appropriate time to stop thinking, while this capability is obscured by current sampling paradigms. Motivated by this, we introduce SAGE (Self-Aware Guided Efficient Reasoning), a novel sampling paradigm that unleashes this efficient reasoning potential. Furthermore, integrating SAGE as mixed sampling into group-based reinforcement learning (SAGE-RL) enables SAGE-RL to effectively incorporate SAGE-discovered efficient reasoning patterns into standard pass@1 inference, markedly enhancing both the reasoning accuracy and efficiency of LRMs across multiple challenging mathematical benchmarks."
  },
  {
    "date": "2026-02-09",
    "title": "What, Whether and How? Unveiling Process Reward Models for Thinking with Images Reasoning",
    "authors": "Yujin Zhou, Pengcheng Wen, Jiale Chen, Boqin Yin, Han Zhu, Jiaming Ji, Juntao Dai, Chi-Min Chan, Sirui Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08346v1",
    "source": "arXiv",
    "abstract": "The rapid advancement of Large Vision Language Models (LVLMs) has demonstrated excellent abilities in various visual tasks. Building upon these developments, the thinking with images paradigm has emerged, enabling models to dynamically edit and re-encode visual information at each reasoning step, mirroring human visual processing. However, this paradigm introduces significant challenges as diverse errors may occur during reasoning processes. This necessitates Process Reward Models (PRMs) for distinguishing positive and negative reasoning steps, yet existing benchmarks for PRMs are predominantly text-centric and lack comprehensive assessment under this paradigm. To address these gaps, this work introduces the first comprehensive benchmark specifically designed for evaluating PRMs under the thinking with images paradigm. Our main contributions are: (1) Through extensive analysis of reasoning trajectories and guided search experiments with PRMs, we define 7 fine-grained error types and demonstrate both the necessity for specialized PRMs and the potential for improvement. (2) We construct a comprehensive benchmark comprising 1,206 manually annotated thinking with images reasoning trajectories spanning 4 categories and 16 subcategories for fine-grained evaluation of PRMs. (3) Our experimental analysis reveals that current LVLMs fall short as effective PRMs, exhibiting limited capabilities in visual reasoning process evaluation with significant performance disparities across error types, positive evaluation bias, and sensitivity to reasoning step positions. These findings demonstrate the effectiveness of our benchmark and establish crucial foundations for advancing PRMs in LVLMs."
  },
  {
    "date": "2026-02-09",
    "title": "Generalized Wintgen inequalities for submanifolds of conformally flat manifolds",
    "authors": "Cihan Özgür, Adara M. Blaga",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08330v1",
    "source": "arXiv",
    "abstract": "We obtain generalized Wintgen inequalities for submanifolds in conformally flat manifolds. We give some applications for submanifolds in a Riemannian manifold of quasi-constant curvature. Equality cases are also considered."
  },
  {
    "date": "2026-02-09",
    "title": "An Attention-over-Attention Generative Model for Joint Multiple Intent Detection and Slot Filling",
    "authors": "Wei Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08322v1",
    "source": "arXiv",
    "abstract": "In task-oriented dialogue systems, spoken language understanding (SLU) is a critical component, which consists of two sub-tasks, intent detection and slot filling. Most existing methods focus on the single-intent SLU, where each utterance only has one intent. However, in real-world scenarios users usually express multiple intents in an utterance, which poses a challenge for existing dialogue systems and datasets. In this paper, we propose a generative framework to simultaneously address multiple intent detection and slot filling. In particular, an attention-over-attention decoder is proposed to handle the variable number of intents and the interference between the two sub-tasks by incorporating an inductive bias into the process of multi-task learning. Besides, we construct two new multi-intent SLU datasets based on single-intent utterances by taking advantage of the next sentence prediction (NSP) head of the BERT model. Experimental results demonstrate that our proposed attention-over-attention generative model achieves state-of-the-art performance on two public datasets, MixATIS and MixSNIPS, and our constructed datasets."
  },
  {
    "date": "2026-02-09",
    "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models",
    "authors": "Zijie Chen, Zhenghao Lin, Xiao Liu, Zhenzhong Lan, Yeyun Gong, Peng Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08321v1",
    "source": "arXiv",
    "abstract": "Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr.SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings."
  },
  {
    "date": "2026-02-09",
    "title": "Hybrid Method of Efficient Simulation of Physics Applications for a Quantum Computer",
    "authors": "Carla Rieger, Albert T. Schmitz, Gehad Salem, Massimiliano Incudini, Sofia Vallecorsa, Anne Y. Matsuura, Michele Grossi, Gian Giacomo Guerreschi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09020v1",
    "source": "arXiv",
    "abstract": "Quantum chemistry and materials science are among the most promising areas for demonstrating algorithmic quantum advantage and quantum utility due to their inherent quantum mechanical nature. Still, large-scale simulations of quantum circuits are essential for determining the problem size at which quantum solutions outperform classical methods. In this work, we present a novel hybrid simulation approach, forming a hybrid of a fullstate and a Clifford simulator, specifically designed to address the computational challenges associated with the time evolution of quantum chemistry Hamiltonians. Our method focuses on the efficient emulation of multi-qubit rotations, a critical component of Trotterized Hamiltonian evolution. By optimizing the representation and execution of multi-qubit operations leveraging the Pauli frame, our approach significantly reduces the computational cost of simulating quantum circuits, enabling more efficient simulations. Beyond its impact on chemistry applications, our emulation strategy has broad implications for any computational workload that relies heavily on multi-qubit rotations. By increasing the efficiency of quantum simulations, our method facilitates more accurate and cost-effective studies of complex quantum systems. We quantify the performance improvements and computational savings for this emulation strategy, and we obtain a speedup of a factor $\\approx 18$ ($\\approx 22$ with MPI) for our evaluated chemistry Hamiltonians with 24 qubits. Thus, we evaluate our integration of this emulation strategy into the Intel Quantum SDK, further bridging the gap between theoretical algorithm development and practical quantum software implementations."
  },
  {
    "date": "2026-02-09",
    "title": "CIC-Trap4Phish: A Unified Multi-Format Dataset for Phishing and Quishing Attachment Detection",
    "authors": "Fatemeh Nejati, Mahdi Rabbani, Mansur Mirani, Gunjan Piya, Igor Opushnyev, Ali A. Ghorbani, Sajjad Dadkhah",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09015v1",
    "source": "arXiv",
    "abstract": "Phishing attacks represents one of the primary attack methods which is used by cyber attackers. In many cases, attackers use deceptive emails along with malicious attachments to trick users into giving away sensitive information or installing malware while compromising entire systems. The flexibility of malicious email attachments makes them stand out as a preferred vector for attackers as they can embed harmful content such as malware or malicious URLs inside standard document formats. Although phishing email defenses have improved a lot, attackers continue to abuse attachments, enabling malicious content to bypass security measures. Moreover, another challenge that researches face in training advance models, is lack of an unified and comprehensive dataset that covers the most prevalent data types. To address this gap, we generated CIC-Trap4Phish, a multi-format dataset containing both malicious and benign samples across five categories commonly used in phishing campaigns: Microsoft Word documents, Excel spreadsheets, PDF files, HTML pages, and QR code images. For the first four file types, a set of execution-free static feature pipeline was proposed, designed to capture structural, lexical, and metadata-based indicators without the need to open or execute files. Feature selection was performed using a combination of SHAP analysis and feature importance, yielding compact, discriminative feature subsets for each file type. The selected features were evaluated by using lightweight machine learning models, including Random Forest, XGBoost, and Decision Tree. All models demonstrate high detection accuracy across formats. For QR code-based phishing (quishing), two complementary methods were implemented: image-based detection by employing Convolutional Neural Networks (CNNs) and lexical analysis of decoded URLs using recent lightweight language models."
  },
  {
    "date": "2026-02-09",
    "title": "ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation",
    "authors": "Zihan Yang, Shuyuan Tu, Licheng Zhang, Qi Dai, Yu-Gang Jiang, Zuxuan Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09014v1",
    "source": "arXiv",
    "abstract": "Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps, motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as velocities evolve across timesteps, thereby leading to quality degradation. To address this limitation, we propose ArcFlow, a few-step distillation framework that explicitly employs non-linear flow trajectories to approximate pre-trained teacher trajectories. Concretely, ArcFlow parameterizes the velocity field underlying the inference trajectory as a mixture of continuous momentum processes. This enables ArcFlow to capture velocity evolution and extrapolate coherent velocities to form a continuous non-linear trajectory within each denoising step. Importantly, this parameterization admits an analytical integration of this non-linear trajectory, which circumvents numerical discretization errors and results in high-precision approximation of the teacher trajectory. To train this parameterization into a few-step generator, we implement ArcFlow via trajectory distillation on pre-trained teacher models using lightweight adapters. This strategy ensures fast, stable convergence while preserving generative diversity and quality. Built on large-scale models (Qwen-Image-20B and FLUX.1-dev), ArcFlow only fine-tunes on less than 5% of original parameters and achieves a 40x speedup with 2 NFEs over the original multi-step teachers without significant quality degradation. Experiments on benchmarks show the effectiveness of ArcFlow both qualitatively and quantitatively."
  },
  {
    "date": "2026-02-09",
    "title": "Counting Barcodes with the same Betti Curve",
    "authors": "Henry Ashley, Håvard Bakke Bjerkevik, Justin Curry, Riley Decker, Robert Green",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09011v1",
    "source": "arXiv",
    "abstract": "This paper considers an important inverse problem in topological data analysis (TDA): How many different barcodes produce the same Betti curve? Equivalently, given a function $β\\colon [n]=\\{1<\\cdots< n\\} \\to \\mathbb{Z}_{\\geq 0}$, how many different ways can we write $β$ as a sum of indicator functions supported on intervals in $[n]$? Our answer to this question is to connect persistent homology with the study of the Kostant partition function and the enumerative combinatorics for so-called \"magic\" juggling sequences studied by Ronald Graham and others. Specifically, we prove an equivalence between our inverse problem and corresponding statements in these other two settings. From an applications and statistics point of view, our work provides a quantification of how lossy the TDA pipeline is when moving from persistent homology to persistent Betti numbers."
  },
  {
    "date": "2026-02-09",
    "title": "CLUE: Crossmodal disambiguation via Language-vision Understanding with attEntion",
    "authors": "Mouad Abrini, Mohamed Chetouani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08999v1",
    "source": "arXiv",
    "abstract": "With the increasing integration of robots into daily life, human-robot interaction has become more complex and multifaceted. A critical component of this interaction is Interactive Visual Grounding (IVG), through which robots must interpret human intentions and resolve ambiguity. Existing IVG models generally lack a mechanism to determine when to ask clarification questions, as they implicitly rely on their learned representations. CLUE addresses this gap by converting the VLM's cross-modal attention into an explicit, spatially grounded signal for deciding when to ask. We extract text to image attention maps and pass them to a lightweight CNN to detect referential ambiguity, while a LoRA fine-tuned decoder conducts the dialog and emits grounding location tokens. We train on a real-world interactive dataset for IVG, and a mixed ambiguity set for the detector. With InViG-only supervision, our model surpasses a state-of-the-art method while using parameter-efficient fine-tuning. Similarly, the ambiguity detector outperforms prior baselines. Overall, CLUE turns the internal cross-modal attention of a VLM into an explicit, spatially grounded signal for deciding when to ask. The data and code are publicly available at: mouadabrini.github.io/clue"
  },
  {
    "date": "2026-02-09",
    "title": "Generalizing Sports Feedback Generation by Watching Competitions and Reading Books: A Rock Climbing Case Study",
    "authors": "Arushi Rai, Adriana Kovashka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08996v1",
    "source": "arXiv",
    "abstract": "While there is rapid progress in video-LLMs with advanced reasoning capabilities, prior work shows that these models struggle on the challenging task of sports feedback generation and require expensive and difficult-to-collect finetuning feedback data for each sport. This limitation is evident from the poor generalization to sports unseen during finetuning. Furthermore, traditional text generation evaluation metrics (e.g., BLEU-4, METEOR, ROUGE-L, BERTScore), originally developed for machine translation and summarization, fail to capture the unique aspects of sports feedback quality. To address the first problem, using rock climbing as our case study, we propose using auxiliary freely-available web data from the target domain, such as competition videos and coaching manuals, in addition to existing sports feedback from a disjoint, source domain to improve sports feedback generation performance on the target domain. To improve evaluation, we propose two evaluation metrics: (1) specificity and (2) actionability. Together, our approach enables more meaningful and practical generation of sports feedback under limited annotations."
  },
  {
    "date": "2026-02-09",
    "title": "When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents",
    "authors": "Yuting Ning, Jaylen Jones, Zhehao Zhang, Chentao Ye, Weitong Ruan, Junyi Li, Rahul Gupta, Huan Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08995v1",
    "source": "arXiv",
    "abstract": "Computer-use agents (CUAs) have made tremendous progress in the past year, yet they still frequently produce misaligned actions that deviate from the user's original intent. Such misaligned actions may arise from external attacks (e.g., indirect prompt injection) or from internal limitations (e.g., erroneous reasoning). They not only expose CUAs to safety risks, but also degrade task efficiency and reliability. This work makes the first effort to define and study misaligned action detection in CUAs, with comprehensive coverage of both externally induced and internally arising misaligned actions. We further identify three common categories in real-world CUA deployment and construct MisActBench, a benchmark of realistic trajectories with human-annotated, action-level alignment labels. Moreover, we propose DeAction, a practical and universal guardrail that detects misaligned actions before execution and iteratively corrects them through structured feedback. DeAction outperforms all existing baselines across offline and online evaluations with moderate latency overhead: (1) On MisActBench, it outperforms baselines by over 15% absolute in F1 score; (2) In online evaluation, it reduces attack success rate by over 90% under adversarial settings while preserving or even improving task success rate in benign environments."
  },
  {
    "date": "2026-02-09",
    "title": "Rhythms of Recovery: Patient-Centered Virtual Reality Exergame for Physical Rehabilitation in the Intensive Care Unit",
    "authors": "Sangjun Eom, Tianyi Hu, Wenyi Xu, Liheng Zou, Ernesto Escobar, Gabriel Streisfeld, Anna Mall, Bradi Granger, Maria Gorlatova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08994v1",
    "source": "arXiv",
    "abstract": "Early mobilization is a structured protocol designed to facilitate motor recovery in intensive care unit (ICU) patients with ICU-acquired weakness. This process is typically implemented by an interdisciplinary team of nurses, physical therapists, and other healthcare professionals. However, its application is often constrained by the patients' critical conditions, limited mobility, and the challenges of coordinating care within resource-intensive ICU environments. In this study, we developed a patient-centered virtual reality (VR) exergame through an interdisciplinary design process involving clinicians and therapists, tailored to the constraints of critical care. The exergame incorporates progressive mobility levels that mirror early mobilization practices, and includes an embodied avatar to provide guidance and motivation. Using Meta Quest 3 body tracking, the system captures and visualizes patients' movements, thereby providing motivational engagement and quantifiable mobility metrics. We evaluated the exergame in two stages: a dual-user study involving healthy participants and healthcare professionals or students (N = 13), and a subsequent study with cardiothoracic ICU patients (N = 18) to assess feasibility, design validity, and clinical acceptance. Across both studies, participants reported high enjoyment and engagement without discomfort or stress. Furthermore, patients demonstrated increases in movement speed, range of motion, and workspace volume of the upper body across game levels. Physiological monitoring further indicated that the exergame elicited exertion without inducing excessive cardiovascular responses. These findings highlight the feasibility of VR exergames as a clinically acceptable and engaging adjunct to early mobilization in critical care, offering a novel pathway to improve rehabilitation outcomes for ICU patients."
  },
  {
    "date": "2026-02-09",
    "title": "Analyzing Vaccine Manufacturing Supply Chain Disruptions for Pandemic Preparedness using Discrete-Event Simulation",
    "authors": "Robin Kelchtermans, Valentijn Stienen, Guido Dietrich, Mauro Bernuzzi, Nico Vandaele",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08988v1",
    "source": "arXiv",
    "abstract": "The COVID-19 pandemic exposed critical vulnerabilities in vaccine supply chains, highlighting the need for robust manufacturing for rapid pandemic response to support CEPI's 100 Days Mission. We develop a discrete-event simulation model to analyze supply chain disruptions and enables policymakers and vaccine manufacturers to quantify disruptions and assess mitigation strategies. Unlike prior studies examining components in isolation, our approach integrates production processes, quality assurance and control (QA/QC) activities, and raw material procurement to capture system-wide dynamics. A detailed mRNA case study analyzes disruption scenarios for a facility targeting 50 million doses: facility shutdowns, workforce reductions, raw material shortages, infrastructure failures, extended procurement lead times, and increased QA/QC capacity. Three main insights emerge. First, QA/QC personnel are the primary bottleneck, with utilization reaching 84.5% under normal conditions while machine utilization remains below 33%. Doubling QA/QC capacity increases annual output by 79.1%, offering greater returns than equipment investments. Second, raw material disruptions are highly detrimental, with extended lead times reducing three-year output by 19.6% and causing stockouts during 51.8% of production time. Third, the model shows differential resilience: acute disruptions (workforce shortages, shutdowns, power outages) allow recovery within 6 to 9 weeks, whereas chronic disruptions (supply delays) cause prolonged performance degradation."
  },
  {
    "date": "2026-02-09",
    "title": "Forward-mode automatic differentiation for the tensor renormalization group and its relation to the impurity method",
    "authors": "Yuto Sugimoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08987v1",
    "source": "arXiv",
    "abstract": "We propose a forward-mode automatic differentiation (AD) framework for tensor renormalization group (TRG) methods. In this approach, evaluating the derivatives of the partition function up to order $k$ increases the matrix-multiplication cost by a factor of $(k+1)(k+2)/2$ compared to computing the free energy alone, while the memory footprint is only $k$ times that of the original calculation. In the limit where the derivatives of the SVD are neglected, we establish a theoretical correspondence between our forward-mode AD and conventional impurity methods. Numerically, we find that the proposed AD algorithm can calculate internal energy and specific heat significantly higher accuracy than the impurity method at comparable computational cost. We also provide a practical procedure to extract critical exponents from derivatives of the renormalized tensor in TRG calculations in both two and three dimensions."
  },
  {
    "date": "2026-02-09",
    "title": "Granulation signatures as seen by Kepler short-cadence data. I. A decoupling between granulation and oscillation timescales for dwarfs",
    "authors": "Jens R. Larsen, Mia S. Lundkvist, Martin B. Nielsen, Guy R. Davies, Yixiao Zhou, Mikkel N. Lund",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08978v1",
    "source": "arXiv",
    "abstract": "Granulation is the observable signature of convection in envelopes of low-mass stars, forming the background in stellar power spectra. While well-studied in evolved giants, granulation on the MS has received less attention. We here study and characterise granulation signatures of MS and SGB stars, extending previous studies of giants to provide a continuous physical picture across evolutionary stages. We analyse 753 Kepler short-cadence stars using a Bayesian nested-sampling framework to evaluate three background descriptions and compare model preferences. This yields full posterior distributions for all parameters, enabling robust comparisons across a diverse stellar sample. No universal preference between background models is found. Assuming a Gaussian oscillation envelope, $ν_\\mathrm{max}$ estimates are sensitive to model misspecification, with the resulting systematics exceeding the formal uncertainties. The envelope width scales with $ν_\\mathrm{max}$ across models and shows a dependence on effective temperature. Total granulation amplitudes in dwarfs broadly follow giant-based scalings, however a decoupling appears between the timescale of the primary granulation and the oscillations for MS stars cooler than the Sun. The prolonged granulation timescale is reproduced by 3D simulations of a K-dwarf, driven by reduced convective velocities due to more efficient convective energy transport in denser envelopes. The prolonged granulation timescale increases the frequency separation to the oscillation excess, potentially aiding seismic detectability, while the reduced convective velocities may influence the excitation of stellar oscillations and relate to the low amplitudes observed in cool dwarfs. Finally, we contribute a dataset linking granulation, oscillations, and stellar parameters, providing a foundation for future investigations into their interdependence across the HR diagram."
  },
  {
    "date": "2026-02-09",
    "title": "Lightweight Call Signaling and Peer-to-Peer Control of WebRTC Video Conferencing",
    "authors": "Kundan Singh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08975v1",
    "source": "arXiv",
    "abstract": "We present the software architecture and implementation of our web-based multiparty video conference application. It does not use a media server. For call signaling, it either piggybacks on existing push notifications via a lightweight notification server, or utilizes email messages to further remove that server dependency. For conference control and data storage, it creates a peer-to-peer network of the clients participating in the call. Our prototype client web app can be installed as a browser extension, or a progressive web app on desktop and mobile. It uses WebRTC data channels and media streams for the control and media paths in implementing a full featured video conferencing with audio, video, text and screen sharing. The challenges faced and the techniques used in creating our lightweight or serverless system are useful to other low-end WebRTC applications that intend to save cost on server maintenance or paid subscriptions for multiparty video calls."
  },
  {
    "date": "2026-02-09",
    "title": "Grow with the Flow: 4D Reconstruction of Growing Plants with Gaussian Flow Fields",
    "authors": "Weihan Luo, Lily Goli, Sherwin Bahmani, Felix Taubner, Andrea Tagliasacchi, David B. Lindell",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08958v1",
    "source": "arXiv",
    "abstract": "Modeling the time-varying 3D appearance of plants during their growth poses unique challenges: unlike many dynamic scenes, plants generate new geometry over time as they expand, branch, and differentiate. Recent motion modeling techniques are ill-suited to this problem setting. For example, deformation fields cannot introduce new geometry, and 4D Gaussian splatting constrains motion to a linear trajectory in space and time and cannot track the same set of Gaussians over time. Here, we introduce a 3D Gaussian flow field representation that models plant growth as a time-varying derivative over Gaussian parameters -- position, scale, orientation, color, and opacity -- enabling nonlinear and continuous-time growth dynamics. To initialize a sufficient set of Gaussian primitives, we reconstruct the mature plant and learn a process of reverse growth, effectively simulating the plant's developmental history in reverse. Our approach achieves superior image quality and geometric accuracy compared to prior methods on multi-view timelapse datasets of plant growth, providing a new approach for appearance modeling of growing 3D structures."
  },
  {
    "date": "2026-02-09",
    "title": "Coulomb corrections for the non-flip and spin-flip electromagnetic $\\boldsymbol{p}^\\uparrow\\!\\boldsymbol{A}$ amplitudes",
    "authors": "Andrei Poblaguev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08946v1",
    "source": "arXiv",
    "abstract": "It is demonstrated that, within the eikonal approach, the Coulomb corrections to the elastic electromagnetic non-flip and spin-flip proton--nucleus amplitudes are identical when the two amplitudes share the same exponential form factors. This result allows Coulomb corrections to be computed numerically, and with high precision, for both electromagnetic and hadronic elastic $p^{\\uparrow}A$ amplitudes in the massless-photon limit, including the effects of soft magnetic photon exchange. The method relies on analytical expressions and numerical integrations over a finite impact-parameter range with nonsingular integrands, providing a practical and systematically controlled framework for phenomenological applications."
  },
  {
    "date": "2026-02-09",
    "title": "Artificial Magnetic Conductor Frame to Improve Impedance Matching and Radiation Symmetry in 2$\\times$2 Array for 6G Applications",
    "authors": "Edoardo Giusti, Krishan Kumar Tiwari, C. J. Reddy, Danilo Brizi, Agostino Monorchio, Giuseppe Caire",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08943v1",
    "source": "arXiv",
    "abstract": "An Artificial Magnetic Conductor (AMC) frame capable of improving the impedance matching of a 2$\\times$2 array for 6G applications without degrading isolation performance is presented. The proposed frame is integrated into the array without modifying the single radiating element design. By relying on accurate full-wave simulations, it results that the addition of the frame restores the impedance matching performance, achieving a bandwidth of 1.5 GHz at 28 GHz. The isolation between each port remains under -15 dB within the operating band, thanks to the vias in the rectangular patch metasurface. Moreover, the overall structure exhibits a gain of 11.81 dBi with an aperture efficiency of 69$\\%$, satisfactorily for broadband communication purposes. The proposed AMC frame represents an effective method for improving array performance without the need to alter the shape or dimensions of the single radiating element."
  },
  {
    "date": "2026-02-09",
    "title": "How University Disability Services Professionals Write Image Descriptions for HCI Figures Using Generative AI",
    "authors": "Muhammad Raees, Yugo Iwamoto, Konstantinos Papangelis, Jamison Heard, Garreth W. Tigwell",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08937v1",
    "source": "arXiv",
    "abstract": "Disability Services Office (DSO) professionals at higher education institutions write alt text for {visual content}. However, due to the complexity of visual content, such as HCI figures in research publications, DSO professionals can struggle to write high-quality alt text if they lack subject expertise. Generative AI has shown potential in understanding figures and writing their descriptions, yet its support for DSO professionals is underexplored, and limited work evaluates the quality of alt text generated with AI assistance. In this work, we conducted two studies: first, we investigated generative AI support for writing alt text for HCI figures with 12 DSO professionals. Second, we recruited 11 HCI experts to evaluate the alt text written by DSO professionals. Findings show that alt text written solely by DSO professionals has lower quality than alt text written with AI assistance. AI assistance also helped DSO professionals write alt text more quickly and with greater confidence; however, they reported inefficiencies in interactions with the AI. Our work contributes to exploring AI support for non-subject expert accessibility professionals."
  },
  {
    "date": "2026-02-09",
    "title": "Colloidal logic-gate circuits can process environmental signals and autonomously perform tasks",
    "authors": "Jiang-Xing Chen, Jia-Qi Hu, Raymond Kapral",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08936v1",
    "source": "arXiv",
    "abstract": "Cooperative collective dynamics is a principal determinant of the ability of synthetic micromotors to perform specific functions. However, realizing controllable and predictable collective behavior in complex physiological environments remains a significant challenge. Here, we show that collections of enzyme-coated colloids can be designed as various chemical logic gates, which subsequently can be organized into functional logic circuits. These circuits take environmental information as input signals and process it to produce output chemical species needed to achieve specific goals. The chemical computation performed by the circuit endows the active colloidal system with the ability to sense its surroundings and autonomously coordinate its collective motion. The results of simulations of several examples are presented, where self-assembled colloidal circuits can identify invasive threats by their signals, produce and deliver chemicals to the targets to suppress their activity. The results of this work can aid in the design of experimental chemical logic circuits through micromotor self-assembly that autonomously respond to environmental cues to execute specific tasks."
  },
  {
    "date": "2026-02-09",
    "title": "Spacetime singularities and incompleteness: epistemic and ontological remarks",
    "authors": "Gustavo E. Romero",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08931v1",
    "source": "arXiv",
    "abstract": "I argue that spacetime singularities entail no ontological commitment to material entities. First, I show that Penrose's singularity theorem is best understood as a theorem of incompleteness, it demonstrates the failure of specific spacetime models within General Relativity (or any theory incorporating the Raychaudhuri equation) under certain general conditions. Although this has been done before, I adopt a novel approach based on differentiating between physical and purely formal assumptions in the axiomatic foundation of general relativity. Next, I compare Penrose's result with Gödel's incompleteness theorem, highlighting key similarities and differences. Finally, I draw philosophical conclusions regarding the limits and prospects of our epistemic reconstructions of the physical world."
  },
  {
    "date": "2026-02-09",
    "title": "AMS-HD: Hyperdimensional Computing for Real-Time and Energy-Efficient Acute Mountain Sickness Detection",
    "authors": "Abu Masum, Mehran Moghadam, M. Hassan Najafi, Bige Unluturk, Ulkuhan Guler, Sercan Aygun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08916v1",
    "source": "arXiv",
    "abstract": "Altitude sickness is a potentially life-threatening condition that impacts many individuals traveling to elevated altitudes. Timely detection is critical as symptoms can escalate rapidly. Early recognition enables simple interventions such as descent, oxygen, or medication, and prompt treatment can save lives by significantly lowering the risk of severe complications. Although conventional machine learning (ML) techniques have been applied to identify altitude sickness using physiological signals, such as heart rate, oxygen saturation, respiration rate, blood pressure, and body temperature, they often struggle to balance predictive performance with low hardware demands. In contrast, hyperdimensional computing (HDC) remains under-explored for this task with limited biomedical features, where it may offer a compelling alternative to existing classification models. Its vector symbolic framework is inherently suited to hardware-efficient design, making it a strong candidate for low-power systems like wearables. Leveraging lightweight computation and efficient streamlined memory usage, HDC enables real-time detection of altitude sickness from physiological parameters collected by wearable devices, achieving accuracy comparable to that of traditional ML models. We present AMS-HD, a novel system that integrates tailored feature extraction and Hadamard HV encoding to enhance both the precision and efficiency of HDC-based detection. This framework is well-positioned for deployment in wearable health monitoring platforms, enabling continuous, on-the-go tracking of acute altitude sickness."
  },
  {
    "date": "2026-02-09",
    "title": "Positive Distribution Shift as a Framework for Understanding Tractable Learning",
    "authors": "Marko Medvedev, Idan Attias, Elisabetta Cornacchia, Theodor Misiakiewicz, Gal Vardi, Nathan Srebro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08907v1",
    "source": "arXiv",
    "abstract": "We study a setting where the goal is to learn a target function f(x) with respect to a target distribution D(x), but training is done on i.i.d. samples from a different training distribution D'(x), labeled by the true target f(x). Such a distribution shift (here in the form of covariate shift) is usually viewed negatively, as hurting or making learning harder, and the traditional distribution shift literature is mostly concerned with limiting or avoiding this negative effect. In contrast, we argue that with a well-chosen D'(x), the shift can be positive and make learning easier -- a perspective called Positive Distribution Shift (PDS). Such a perspective is central to contemporary machine learning, where much of the innovation is in finding good training distributions D'(x), rather than changing the training algorithm. We further argue that the benefit is often computational rather than statistical, and that PDS allows computationally hard problems to become tractable even using standard gradient-based training. We formalize different variants of PDS, show how certain hard classes are easily learnable under PDS, and make connections with membership query learning."
  },
  {
    "date": "2026-02-09",
    "title": "Accelerated Stabilization of Switched Linear MIMO Systems using Generalized Homogeneity",
    "authors": "Moussa Labbadi, Andrey Polyakov, Denis Efimov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08903v1",
    "source": "arXiv",
    "abstract": "This paper addresses the problem of exponential and accelerated finite-time, as well as nearly fixed-time, stabilization of switched linear MIMO systems. The proposed approach relies on a generalized homogenization framework for switched linear systems and employs implicit Lyapunov functions for control design, covering both common and multiple Lyapunov function settings. Linear matrix equations and inequalities are derived to characterize the dilation generator and to synthesize the controller gains. Robustness of the resulting control laws with respect to system uncertainties and external disturbances is analyzed. The effectiveness of the proposed approach is illustrated through numerical examples."
  },
  {
    "date": "2026-02-09",
    "title": "GSS: Gated Subspace Steering for Selective Memorization Mitigation in LLMs",
    "authors": "Xuanqi Zhang, Haoyang Shang, Xiaoxiao Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08901v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) can memorize and reproduce training sequences verbatim -- a tendency that undermines both generalization and privacy. Existing mitigation methods apply interventions uniformly, degrading performance on the majority of tokens that generalize normally. We show empirically that memorization is sparse, intermittent, and token-conditioned, suggesting that effective mitigation requires context-aware intervention rather than static parameter modification. To this end, we propose a novel and effective selective memorization mitigation method -- Gated Subspace Steering (GSS), which decomposes intervention into a probe (detecting memorization-relevant activations) and a steer (applying targeted correction only when the probe exceeds a threshold). The optimal probe-steer pair emerges from a principled optimization framework based on optimal subspace steering. Experiments on four benchmarks show GSS matches or exceeds state-of-the-art memorization reduction while requiring $100-1000 \\times$ less compute than optimization-based alternatives. Furthermore, we provide new theoretical insights into the geometry of memorization in neural representations."
  },
  {
    "date": "2026-02-09",
    "title": "Winner's Curse Drives False Promises in Data-Driven Decisions: A Case Study in Refugee Matching",
    "authors": "Hamsa Bastani, Osbert Bastani, Bryce McLaughlin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08892v1",
    "source": "arXiv",
    "abstract": "A major challenge in data-driven decision-making is accurate policy evaluation-i.e., guaranteeing that a learned decision-making policy achieves the promised benefits. A popular strategy is model-based policy evaluation, which estimates a model from data to infer counterfactual outcomes. This strategy is known to produce unwarrantedly optimistic estimates of the true benefit due to the winner's curse. We searched the recent literature on data-driven decision-making, identifying a sample of 55 papers published in the Management Science in the past decade; all but two relied on this flawed methodology. Several common justifications are provided: (1) the estimated models are accurate, stable, and well-calibrated, (2) the historical data uses random treatment assignment, (3) the model family is well-specified, and (4) the evaluation methodology uses sample splitting. Unfortunately, we show that no combination of these justifications avoids the winner's curse. First, we provide a theoretical analysis demonstrating that the winner's curse can cause large, spurious reported benefits even when all these justifications hold. Second, we perform a simulation study based on the recent and consequential data-driven refugee matching problem. We construct a synthetic refugee matching environment (calibrated to closely match the real setting) but designed so that no assignment policy can improve expected employment compared to random assignment. Model-based methods report large, stable gains of around 60% even when the true effect is zero; these gains are on par with improvements of 22-75% reported in the literature. Our results provide strong evidence against model-based evaluation."
  },
  {
    "date": "2026-02-09",
    "title": "Almost sure null bankruptcy of testing-by-betting strategies",
    "authors": "Hongjian Wang, Shubhada Agrawal, Aaditya Ramdas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08888v1",
    "source": "arXiv",
    "abstract": "The bounded mean betting procedure serves as a crucial interface between the domains of (1) sequential, anytime-valid statistical inference, and (2) online learning and portfolio selection algorithms. While recent work in both domains has established the exponential wealth growth of numerous betting strategies under any alternative distribution, the tightness of the inverted confidence sets, and the pathwise minimax regret bounds, little has been studied regarding the asymptotics of these strategies under the null hypothesis. Under the null, a strategy induces a wealth martingale converging to some random variable that can be zero (bankrupt) or non-zero (non-bankrupt, e.g. when it eventually stops betting). In this paper, we show the conceptually intuitive but technically nontrivial fact that these strategies (universal portfolio, Krichevsky-Trofimov, GRAPA, hedging, etc.) all go bankrupt with probability one, under any non-degenerate null distribution. Part of our analysis is based on the subtle almost sure divergence of various sums of $\\sum O_p(n^{-1})$ type, a result of independent interest. We also demonstrate the necessity of null bankruptcy by showing that non-bankrupt strategies are all improvable in some sense. Our results significantly deepen our understanding of these betting strategies as they qualify their behavior on \"almost all paths\", whereas previous results are usually on \"all paths\" (e.g. regret bounds) or \"most paths\" (e.g. concentration inequalities and confidence sets)."
  },
  {
    "date": "2026-02-09",
    "title": "Quantum Riemannian Cubics with Obstacle Avoidance for Quantum Geometric Model Predictive Control",
    "authors": "Leonardo Colombo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08881v1",
    "source": "arXiv",
    "abstract": "We propose a geometric model predictive control framework for quantum systems subject to smoothness and state constraints. By formulating quantum state evolution intrinsically on the projective Hilbert space, we penalize covariant accelerations to generate smooth trajectories in the form of Riemannian cubics, while incorporating state-dependent constraints through potential functions. A structure-preserving variational discretization enables receding-horizon implementation, and a Lyapunov-type stability result is established for the closed-loop system. The approach is illustrated on the Bloch sphere for a two-level quantum system, providing a viable pathway toward predictive feedback control of constrained quantum dynamics."
  },
  {
    "date": "2026-02-09",
    "title": "Differentiable Logical Programming for Quantum Circuit Discovery and Optimization",
    "authors": "Antonin Sulc",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08880v1",
    "source": "arXiv",
    "abstract": "Designing high-fidelity quantum circuits remains challenging, and current paradigms often depend on heuristic, fixed-ansatz structures or rule-based compilers that can be suboptimal or lack generality. We introduce a neuro-symbolic framework that reframes quantum circuit design as a differentiable logic programming problem. Our model represents a scaffold of potential quantum gates and parameterized operations as a set of learnable, continuous ``truth values'' or ``switches,'' $s \\in [0, 1]^N$. These switches are optimized via standard gradient descent to satisfy a user-defined set of differentiable, logical axioms (e.g., correctness, simplicity, robustness). We provide a theoretical formulation bridging continuous logic (via T-norms) and unitary evolution (via geodesic interpolation), while addressing the barren plateau problem through biased initialization. We illustrate the approach on tasks including discovery of a 4-qubit Quantum Fourier Transform (QFT) from a scaffold of 21 candidate gates. We also report a hardware-aware adaptation experiment on the 133-qubit IBM Torino processor, where the method improved fidelity by 59.3 percentage points in a localized routing task while adapting to hardware failures."
  },
  {
    "date": "2026-02-09",
    "title": "Large Language Models for Geolocation Extraction in Humanitarian Crisis Response",
    "authors": "G. Cafferata, T. Demarco, K. Kalimeri, Y. Mejova, M. G. Beiró",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08872v1",
    "source": "arXiv",
    "abstract": "Humanitarian crises demand timely and accurate geographic information to inform effective response efforts. Yet, automated systems that extract locations from text often reproduce existing geographic and socioeconomic biases, leading to uneven visibility of crisis-affected regions. This paper investigates whether Large Language Models (LLMs) can address these geographic disparities in extracting location information from humanitarian documents. We introduce a two-step framework that combines few-shot LLM-based named entity recognition with an agent-based geocoding module that leverages context to resolve ambiguous toponyms. We benchmark our approach against state-of-the-art pretrained and rule-based systems using both accuracy and fairness metrics across geographic and socioeconomic dimensions. Our evaluation uses an extended version of the HumSet dataset with refined literal toponym annotations. Results show that LLM-based methods substantially improve both the precision and fairness of geolocation extraction from humanitarian texts, particularly for underrepresented regions. By bridging advances in LLM reasoning with principles of responsible and inclusive AI, this work contributes to more equitable geospatial data systems for humanitarian response, advancing the goal of leaving no place behind in crisis analytics."
  },
  {
    "date": "2026-02-09",
    "title": "A cavity-mediated reconfigurable coupling scheme for superconducting qubits",
    "authors": "Shinyoung Hwang, Sangyeon Lee, Eunjong Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08869v1",
    "source": "arXiv",
    "abstract": "Superconducting qubits have achieved remarkable progress in gate fidelity and coherence, yet their typical nearest-neighbor connectivity presents constraints for implementing complex quantum circuits. Here, we introduce a cavity-mediated coupling architecture in which a shared cavity mode, accessed through tunable qubit-cavity couplers, enables dynamically reconfigurable interactions between non-adjacent qubits. By selectively activating the couplers, we demonstrate that high-fidelity iSWAP and CZ gates can be performed within 50 ns with simulated coherent error below $10^{-4}$, while residual $ZZ$ interaction during idling remains below a few kilohertz. Extending to a four-qubit system, we also simulate gates between every qubit pair by selectively enabling the couplers with low qubit crosstalk. This approach provides a practical route toward enhanced interaction flexibility in superconducting quantum processors and may serve as a useful building block for devices that benefit from selective non-local coupling."
  },
  {
    "date": "2026-02-09",
    "title": "Understanding Dynamic Compute Allocation in Recurrent Transformers",
    "authors": "Ibraheem Muhammad Moosa, Suhas Lohit, Ye Wang, Moitreya Chatterjee, Wenpeng Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08864v1",
    "source": "arXiv",
    "abstract": "Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state."
  },
  {
    "date": "2026-02-09",
    "title": "High-brightness fiber-based Sagnac source of entangled photon pairs for multiplexed quantum networks",
    "authors": "Tess Troisi, Yoann Pelet, Romain Dalidet, Gregory Sauder, Olivier Alibart, Sébastien Tanzilli, Anthony Martin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08863v1",
    "source": "arXiv",
    "abstract": "A fully fibered source of entangled photon pairs based on a nonlinear Sagnac interferometer is reported. Operating at telecom wavelengths, the source relies exclusively on standard fiber-optic components and periodically poled lithium niobate (PPLN) waveguides, resulting in a compact, robust, and field-deployable architecture. The generation stage supports both polarization and energy-time entanglement without modification, enabling versatile operation depending on the targeted application. Broadband spontaneous parametric down-conversion allows dense wavelength-division multiplexing over the telecom C and L bands. High normalized brightness (10.3 kpairs/s/nm/mW$^2$) is achieved on a standard 100 GHz ITU channel pair, together with high entanglement quality. Polarization and energy-time encodings are characterized through state tomography and two-photon interference measurements, yielding fidelities, purities, and visibilities exceeding 96 % over multiple wavelength channels. The stability and reproducibility of the source are further evaluated through long-duration operation in a network environment. These results demonstrate that the proposed Sagnac source constitutes a practical and scalable building block for future plug-and-play quantum communication and quantum networking platforms."
  },
  {
    "date": "2026-02-09",
    "title": "Near-optimal Swap Regret Minimization for Convex Losses",
    "authors": "Lunjia Hu, Jon Schneider, Yifan Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08862v1",
    "source": "arXiv",
    "abstract": "We give a randomized online algorithm that guarantees near-optimal $\\widetilde O(\\sqrt T)$ expected swap regret against any sequence of $T$ adaptively chosen Lipschitz convex losses on the unit interval. This improves the previous best bound of $\\widetilde O(T^{2/3})$ and answers an open question of Fishelson et al. [2025b]. In addition, our algorithm is efficient: it runs in $\\mathsf{poly}(T)$ time. A key technical idea we develop to obtain this result is to discretize the unit interval into bins at multiple scales of granularity and simultaneously use all scales to make randomized predictions, which we call multi-scale binning and may be of independent interest. A direct corollary of our result is an efficient online algorithm for minimizing the calibration error for general elicitable properties. This result does not require the Lipschitzness assumption of the identification function needed in prior work, making it applicable to median calibration, for which we achieve the first $\\widetilde O(\\sqrt T)$ calibration error guarantee."
  },
  {
    "date": "2026-02-09",
    "title": "Rigidity of homogeneous Lamé systems",
    "authors": "Joonas Ilmavirta, Teemu Saksala, Lili Yan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08860v1",
    "source": "arXiv",
    "abstract": "In this short paper, we show that any Lamé system whose Dirichlet-to-Neumann map for the elastic wave equation agrees with the one arising from the homogeneous Lamé system must actually be homogeneous. We do not need to impose any assumptions for the Lamé coefficients that we aim to recover. We use the fact that the homogeneous system gives rise to a geometry that is both simple and admits a strictly convex foliation."
  },
  {
    "date": "2026-02-09",
    "title": "Discovering Interpretable Algorithms by Decompiling Transformers to RASP",
    "authors": "Xinting Huang, Aleksandra Bakalova, Satwik Bhattamishra, William Merrill, Michael Hahn",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08857v1",
    "source": "arXiv",
    "abstract": "Recent work has shown that the computations of Transformers can be simulated in the RASP family of programming languages. These findings have enabled improved understanding of the expressive capacity and generalization abilities of Transformers. In particular, Transformers have been suggested to length-generalize exactly on problems that have simple RASP programs. However, it remains open whether trained models actually implement simple interpretable programs. In this paper, we present a general method to extract such programs from trained Transformers. The idea is to faithfully re-parameterize a Transformer as a RASP program and then apply causal interventions to discover a small sufficient sub-program. In experiments on small Transformers trained on algorithmic and formal language tasks, we show that our method often recovers simple and interpretable RASP programs from length-generalizing transformers. Our results provide the most direct evidence so far that Transformers internally implement simple RASP programs."
  },
  {
    "date": "2026-02-09",
    "title": "Cooperative Sovereignty on Mars: Lessons from the International Telecommunication Union and Universal Postal Union",
    "authors": "Alexander H. Ferdinand Ferguson, Jacob Haqq-Misra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08853v1",
    "source": "arXiv",
    "abstract": "As humans make ambitious efforts toward long-duration activities beyond Earth, new challenges will continue to emerge that highlight the need for governance frameworks capable of managing shared resources and technical standards in order to sustain human life in these hostile environments. Earth-based governance models of cooperative sovereignty can inform governance mechanisms for future Mars settlements, particularly regarding inter-settlement relations and the technical coordination required for multiple independent settlements to coexist. This study analyzes the International Telecommunication Union (ITU) and the Universal Postal Union (UPU), two of the oldest international organizations, which have successfully established evolving standards across sovereign nations. This analysis of the development and governance structures of these two organizations, and how they resolved key sovereignty issues, reveals principles that could be applicable to future settlements beyond Earth, particularly on Mars. Key insights include the strategic necessity of institutional neutrality, the management of asymmetric power relations, and the governance of shared resources under conditions of mutual vulnerability. The study distinguishes between a \"Survival Layer\" of technical standards essential for immediate safety and an \"Operational Layer\" governing economic and political activities, suggesting different governance approaches for each. Although some of these examples of cooperative sovereignty on Earth might not be sufficient for Mars due to its unique environment, lessons from the ITU and UPU case studies offer valuable strategies for designing flexible and sustainable governance models that can function from inception through explicit Earth-based coordination."
  },
  {
    "date": "2026-02-09",
    "title": "Mitchell rank for supercompactness",
    "authors": "Erin Carmody",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08852v1",
    "source": "arXiv",
    "abstract": "This paper defines a Mitchell rank for supercompact cardinals. If $κ$ is a $θ$-supercompact cardinal then $o_{θ-sc}(κ) = \\sup \\{ o_{θ-sc}(μ) + 1 \\ | \\ μ\\in m(κ)\\}$, where $m(κ)$ is the collection of normal fine measures on $P_κθ$. We show how to force to kill the degree of a measurable cardinal $κ$ to any specified degree which is less than or equal to the degree of $κ$ in the ground model. We will also show how to softly kill the Mitchell rank for supercompactness of any supercompact cardinal so that in the forcing extension it is any desired degree less than or equal to it's degree in the ground model, along with some results concerning strongly compact cardinals."
  },
  {
    "date": "2026-02-09",
    "title": "Ancient solutions to free boundary mean curvature flow",
    "authors": "Theodora Bourni, Giada Franz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08850v1",
    "source": "arXiv",
    "abstract": "We establish rigidity results for ancient solutions to the free boundary mean curvature flow in manifolds with convex boundary. In particular, we show that any free boundary minimal hypersurface of Morse index I admits an I-parameter family of ancient solutions that emanate from it. Moreover, among ancient solutions that backward converge exponentially fast to the minimal hypersurface, these exhaust all possibilities. Additionally, we construct a smooth free boundary mean convex foliation around an unstable free boundary minimal hypersurface that enables us to provide a more detailed geometric description of mean-convex ancient solutions that backward converge to that minimal surface."
  },
  {
    "date": "2026-02-09",
    "title": "Finite-Time Teleoperation of Euler-Lagrange Systems via Energy-Shaping",
    "authors": "Lazaro F. Torres, Carlos I. Aldana, Emmanuel Nuño, Emmanuel Cruz-Zavala",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08845v1",
    "source": "arXiv",
    "abstract": "This paper proposes a family of finite-time controllers for the bilateral teleoperation of fully actuated nonlinear Euler-Lagrange systems. Based on the energy-shaping framework and under the standard assumption of passive interactions with the human and the environment, the controllers ensure that the position error and velocities globally converge to zero in the absence of time delays. In this case, the closed-loop system admits a homogeneous approximation of negative degree, and thus the control objective is achieved in finite-time. The proposed controllers are simple, continuous-time proportional-plus-damping-injection schemes, validated through both simulation and experimental results."
  },
  {
    "date": "2026-02-09",
    "title": "Test-retest Reliability of Psychophysical Tasks Using Structured Light-Induced Entoptic Phenomena",
    "authors": "Taranjit Singh, Mukhit Kulmaganbetov, Zhangting Wang, Dmitry Pushin, Benjamin Thompson, Andrew Silva, Melanie Mungalsingh, Iman Salehi, Davis Garrad, David Cory, Dusan Sarenac",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08836v1",
    "source": "arXiv",
    "abstract": "Structured light (SL)-induced polarization perception presents a promising method for the early detection of macular diseases such as age-related macular degeneration. We investigated the test-retest reliability of a psychophysical task using SL-based stimuli to induce entoptic patterns in individuals with healthy vision. Twenty-eight participants underwent thorough eye examinations to confirm they had healthy eyes and good vision (logMAR BCVA ~0.00). Of these, 25 participants (n=50 eyes) aged 21 to 75 completed two identical tasks separated by 1 to 14 days. Using SL-based stimuli that produced a rotating entoptic pattern containing 22 azimuthal brushes, we measured the retinal eccentricity threshold $R_T$ at which participants could reliably identify the direction of rotation by varying the size of a central obstruction. This threshold reflects the visual angle of the pattern for each participant. We calculated the reliability coefficient (intraclass correlation coefficient, ICC) using a two-way mixed-effects model and conducted a Bland-Altman analysis to assess test-retest reliability. The ICC was 0.83 [95% CI: 0.62 - 0.93] for right eyes (RE) and 0.93 [95% CI: 0.84 - 0.97] for left eyes (LE), indicating good reliability. The Bland-Altman analysis showed a mean difference of -0.32° (SD: 1.51) and -0.12° (SD: 1.03) for RE and LE respectively between the first and second sessions, with limits of agreement ranging from -3.28° to 2.64° and -2.14° to 1.89° for RE and LE respectively, confirming strong agreement and no significant bias. These results demonstrate that SL-based psychophysical tasks are a reliable method for assessing polarization perception, potentially improving screening for diseases affecting macular health."
  },
  {
    "date": "2026-02-09",
    "title": "Kirin: Improving ANN efficiency with SNN Hybridization",
    "authors": "Chenyu Wang, Zhanglu Yan, Zhi Zhou, Xu Chen, Weng-Fai Wong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08817v1",
    "source": "arXiv",
    "abstract": "Artificial neural networks (ANNs), particularly large language models (LLMs), demonstrate powerful inference capabilities but consume substantial energy. Conversely, spiking neural networks (SNNs) exhibit exceptional energy efficiency due to their binary and event-driven characteristics, thus motivating the study of ANN-to-SNN conversion. In this process, quantization plays a pivotal role, mapping LLMs' floating-point parameters to discrete SNN parameters via the temporal dimension of the time window. However, several challenges remain in the conversion process: (i) converting high bit-width quantization values into binary spikes requires longer time windows, increasing system latency; and (ii) the inherent trade-off between the information loss of single-spike schemes and the energy costs of multi-spike ones in SNN. To address these challenges, we propose Kirin, a integer and spike hybrid based SNN to achieve accuracy lossless ANN-to-SNN conversion with time and energy efficiency. Specifically, we first propose a Spike Matrix Hybridization strategy that encoding low bit-width parameters that leading to small time window size into binary spikes while preserving the rest in integer format, thereby reducing the overall latency of SNN execution. Second, we introduce a silence threshold mechanism to regulate the timing of single-spike firing, ensuring the output is mathematically equivalent to the LLM's output and preserves accuracy. Experimental results demonstrate that Kirin, under a W4A4\\&8 quantization setting, achieves near-FP16 accuracy while reducing energy consumption by up to 84.66\\% and shortening time steps by 93.75\\%."
  },
  {
    "date": "2026-02-09",
    "title": "On Sidon sets with squares, cubes and quartics in short intervals",
    "authors": "M. Z. Garaev, F. M. Garayev, S. V. Konyagin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08807v1",
    "source": "arXiv",
    "abstract": "Representative examples of our results are as follows. For any positive integer $N$ the equation $$ x^3+y^3=z^3+t^3, \\quad x,y,z,t\\in \\mathbb{N}, \\quad \\{x,y\\}\\not=\\{z,t\\} $$ has no solutions satisfying $$ N\\le x,y,z,t < N+\\Bigl(\\frac{38}{3}N+\\frac{1297}{36}\\Bigr)^{1/2}+\\frac{19}{6}. $$ The strict inequality ``$<$\" can not be substituted by ``$\\le$\", that is, there exist infinitely many positive integers $N$ such that the equation has a solution with $$ N\\le x,y,z,t \\le N+\\Bigl(\\frac{38}{3}N+\\frac{1297}{36}\\Bigr)^{1/2}+\\frac{19}{6}. $$ There is an absolute constant $c>0$ such that for any positive integer $N$ the equation has a solution satisfying $$ N\\le x,y,z,t \\le N+cN^{2/3}. $$ For any $\\varepsilon>0$ there exist infinitely many positive integers $N$ such that the equation has no solutions satisfying $$ N\\le x,y,z,t \\le N+N^{4/7-\\varepsilon}. $$ There is an absolute constant $c>0$ such that for any positive integer $N$ the equation $$ x^4+y^4=z^4+t^4,\\quad x,y,z,t\\in\\mathbb{N}, \\quad \\{x,y\\}\\not=\\{z,t\\}, $$ has no solutions satisfying $$ N\\le x,y,z,t \\le N+cN^{3/5}. $$ There is an absolute constant $c>0$ such that for any positive integer $N$ this equation has a solution satisfying $$ N\\le x,y,z,t \\le N+cN^{12/13}. $$"
  },
  {
    "date": "2026-02-09",
    "title": "A melting mode of frozen sessile droplets with unmelted ice layer deposited at the bottom",
    "authors": "Jiawang Cui, Yugang Zhao, Tianyou Wang, Zhizhao Che",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08803v1",
    "source": "arXiv",
    "abstract": "Water-repellent properties of superhydrophobic surfaces make them promising for anti-icing and deicing applications. Through experimental visualization of frozen sessile droplets undergoing melting on superhydrophobic surfaces, we identify a melting mode with the unmelted ice layer deposited at the bottom of the melting droplet, even though the density of ice is lower than that of water. In the deposited mode of the melting process, the time required for the frozen droplet to melt completely is much shorter than that in the floating mode. Force analysis shows that the melted fluid flows along the gas-liquid interface toward the top of the melting droplet, thereby exerting force and then suppressing the upward movement of the unmelted ice layer. Moreover, the flow within the liquid film formed between the unmelted ice layer and the heating wall is dominated by the viscous force, which has a lubrication effect and maintains the deposition of the unmelted ice layer. High heating temperature, large contact angle, and low particle concentration are helpful for the occurrence of the deposited mode."
  },
  {
    "date": "2026-02-09",
    "title": "Verifying DNN-based Semantic Communication Against Generative Adversarial Noise",
    "authors": "Thanh Le, Hai Duong, ThanhVu Nguyen, Takeshi Matsumura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08801v1",
    "source": "arXiv",
    "abstract": "Safety-critical applications like autonomous vehicles and industrial IoT are adopting semantic communication (SemCom) systems using deep neural networks to reduce bandwidth and increase transmission speed by transmitting only task-relevant semantic features. However, adversarial attacks against these DNN-based SemCom systems can cause catastrophic failures by manipulating transmitted semantic features. Existing defense mechanisms rely on empirical approaches provide no formal guarantees against the full spectrum of adversarial perturbations. We present VSCAN, a neural network verification framework that provides mathematical robustness guarantees by formulating adversarial noise generation as mixed integer programming and verifying end-to-end properties across multiple interconnected networks (encoder, decoder, and task model). Our key insight is that realistic adversarial constraints (power limitations and statistical undetectability) can be encoded as logical formulae to enable efficient verification using state-of-the-art DNN verifiers. Our evaluation on 600 verification properties characterizing various attacker's capabilities shows VSCAN matches attack methods in finding vulnerabilities while providing formal robustness guarantees for 44% of properties -- a significant achievement given the complexity of multi-network verification. Moreover, we reveal a fundamental security-efficiency tradeoff: compact 16-dimensional latent spaces achieve 50% verified robustness compared to 64-dimensional spaces."
  },
  {
    "date": "2026-02-09",
    "title": "Joint Channel Sounding and Source-Channel Coding for MIMO-OFDM Systems: Deep Unified Encoding and Parallel Flow-Matching Decoding",
    "authors": "Hao Jiang, Xiaojun Yuan, Qinghua Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08795v1",
    "source": "arXiv",
    "abstract": "In this work, we propose a deep unified (DU) encoder that embeds source information in a codeword that contains sufficient redundancy to handle both channel and source uncertainties, without enforcing an explicit pilot-data separation. At the receiver, we design a parallel flow-matching (PFM) decoder that leverages flow-based generative priors to jointly estimate the channel and the source, yielding much more efficient inference than the existing diffusion-based approaches. To benchmark performance limits, we derive the Bayesian Cramér-Rao bound (BCRB) for the joint channel and source estimation problem. Extensive simulations over block-fading MIMO-OFDM channels demonstrate that the proposed DU-PFM approach drastically outperforms the state-of-the-art methods in both channel estimation accuracy and source reconstruction quality."
  },
  {
    "date": "2026-02-09",
    "title": "The size of $2$-Selmer groups for the $\\fracπ{3}$-congruent number problem",
    "authors": "Kushal Bhowmick, Aprameyo Pal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08912v1",
    "source": "arXiv",
    "abstract": "Our main objective in this paper is to study the average rank of the $2$-Selmer group of the elliptic curve associated with the $\\fracπ{3}$-congruent number problem. Following Heath-Brown's strategy, we could find an asymptotic formula for the size of the relaxed $2$-Selmer groups, which has several consequences towards the average of $2$-Selmer ranks and $\\fracπ{3}$-congruent number problem. Indeed, we could find an unconditional positive density of $2$-Selmer rank being $1$ or $3$, among the positive square-free integers $n\\equiv 13\\pmod{24}$ having all the prime divisors congruent to $1$ modulo $4$ and an unconditional positive density of $2$-Selmer rank being $0$ or $2$, among the positive square-free integers $n\\equiv 5\\pmod{24}$ having all the prime divisors congruent to $1$ modulo $4$."
  },
  {
    "date": "2026-02-09",
    "title": "Inverting Data Transformations via Diffusion Sampling",
    "authors": "Jinwoo Kim, Sékou-Oumar Kaba, Jiyun Park, Seunghoon Hong, Siamak Ravanbakhsh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08267v1",
    "source": "arXiv",
    "abstract": "We study the problem of transformation inversion on general Lie groups: a datum is transformed by an unknown group element, and the goal is to recover an inverse transformation that maps it back to the original data distribution. Such unknown transformations arise widely in machine learning and scientific modeling, where they can significantly distort observations. We take a probabilistic view and model the posterior over transformations as a Boltzmann distribution defined by an energy function on data space. To sample from this posterior, we introduce a diffusion process on Lie groups that keeps all updates on-manifold and only requires computations in the associated Lie algebra. Our method, Transformation-Inverting Energy Diffusion (TIED), relies on a new trivialized target-score identity that enables efficient score-based sampling of the transformation posterior. As a key application, we focus on test-time equivariance, where the objective is to improve the robustness of pretrained neural networks to input transformations. Experiments on image homographies and PDE symmetries demonstrate that TIED can restore transformed inputs to the training distribution at test time, showing improved performance over strong canonicalization and sampling baselines. Code is available at https://github.com/jw9730/tied."
  },
  {
    "date": "2026-02-09",
    "title": "A Statistical Framework for Alignment with Biased AI Feedback",
    "authors": "Xintao Xia, Zhiqiu Xia, Linjun Zhang, Zhanrui Cai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08259v1",
    "source": "arXiv",
    "abstract": "Modern alignment pipelines are increasingly replacing expensive human preference labels with evaluations from large language models (LLM-as-Judge). However, AI labels can be systematically biased compared to high-quality human feedback datasets. In this paper, we develop two debiased alignment methods within a general framework that accommodates heterogeneous prompt-response distributions and external human feedback sources. Debiased Direct Preference Optimization (DDPO) augments standard DPO with a residual-based correction and density-ratio reweighting to mitigate systematic bias, while retaining DPO's computational efficiency. Debiased Identity Preference Optimization (DIPO) directly estimates human preference probabilities without imposing a parametric reward model. We provide theoretical guarantees for both methods: DDPO offers a practical and computationally efficient solution for large-scale alignment, whereas DIPO serves as a robust, statistically optimal alternative that attains the semiparametric efficiency bound. Empirical studies on sentiment generation, summarization, and single-turn dialogue demonstrate that the proposed methods substantially improve alignment efficiency and recover performance close to that of an oracle trained on fully human-labeled data."
  },
  {
    "date": "2026-02-09",
    "title": "ZK-Rollup for Hyperledger Fabric: Architecture and Performance Evaluation",
    "authors": "Sania Siddiqui, Neha, Hari Babu K",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08870v1",
    "source": "arXiv",
    "abstract": "A big challenge posed in blockchain centric platforms is achieving scalability while also preserving user privacy. This report details the design, implementation and evaluation of a Layer-2 scaling solution for Hyperledger Fabric using Zero Knowledge Rollups (ZK Rollups). The proposed architecture introduces an off chain sequencer that accepts transactions immediately and sends them for batching into a Merkle tree based rollup, using ZK proofs to attest to the correctness and verifiability of the entire batch. The design aims to decouple transaction ingestion from actual on chain settlements to address Fabric scalability limitations and increase throughput under high load conditions. The baseline architecture in Hyperledger Fabric constrains transaction requests due to endorsement, ordering and validation phases, leading to a throughput of 5 to 7 TPS with an average latency of 4 seconds. Our Layer-2 solution achieves an ingestion throughput of 70 to 100 TPS, leading to an increase of nearly ten times due to the sequencer immediate acceptance of each transaction and reducing client perceived latency by nearly eighty percent to 700 to 1000 milliseconds. This work demonstrates that integrating ZK Rollups in Hyperledger Fabric enhances scalability while not compromising the security guarantees of a permissioned blockchain network."
  },
  {
    "date": "2026-02-09",
    "title": "Probing Light Dark Particles in Neutrino Scattering Experiments",
    "authors": "Ruofei Feng, Shao-Feng Ge, Yongchao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08314v1",
    "source": "arXiv",
    "abstract": "In this work we investigate the production of a dark fermionic particle $χ$ in the neutrino scattering experiments. In the framework of effective field theory, such process can be induced by the effective four-fermion interactions involving neutrinos, the dark particle $χ$ and standard model particles. In particular, we examine the constraints on the effective couplings from the neutrinos scattering off nuclei in the COHERENT and CONUS+ experiments as well as the prospects at the DUNE near detector from neutrino-electron scattering. It turns out the current COHERENT and CONUS+ constraints on the cutoff scales are less stringent than those from the existing Large Hadron Collider data. However, the DUNE near detector could probe the cutoff scales beyond the existing CHARM II and LEP limits up to roughly 1 TeV, for the dark particle mass up to roughly 50 MeV."
  },
  {
    "date": "2026-02-09",
    "title": "W-SLDA Toolkit: A simulation platform for ultracold Fermi gases",
    "authors": "Gabriel Wlazłowski, Piotr Magierski, Michael McNeil Forbes, Aurel Bulgac",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08982v1",
    "source": "arXiv",
    "abstract": "We present the W-SLDA Toolkit, a general-purpose software package for simulating ultracold Fermi gases within the framework of density functional theory and its time-dependent extensions. The toolkit enables fully microscopic studies of interacting superfluid systems across the BCS-BEC crossover, including spin-imbalanced configurations and arbitrary external geometries. It provides both static and time-dependent solvers capable of describing a broad range of phenomena in one-, two-, and three-dimensional settings. In addition, the toolkit incorporates functionality for solving the standard Bogoliubov-de Gennes equations for fermions, extending its applicability to other physical systems such as superconductors. The code is implemented in C with GPU acceleration and is optimized for hybrid CPU/GPU execution on modern high-performance computing platforms. It ensures scalability on leadership-class supercomputers, enabling fully three-dimensional simulations with large atomic numbers, and allows for direct benchmarks of ultracold-atom experimental setups. Its modular architecture facilitates straightforward extensions, user customization, and seamless interoperability with other scientific software frameworks. Furthermore, an extensive collection of practical usage examples is provided through the integrated reproducibility packs functionality, ensuring transparency and reproducibility of computational results."
  },
  {
    "date": "2026-02-09",
    "title": "Finite generation of Noether-Lefschetz divisors and the slope of the moduli space of cubic fourfolds",
    "authors": "Ignacio Barros, Shi He, Paul Kiefer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08463v1",
    "source": "arXiv",
    "abstract": "We study divisors on moduli spaces of cubic fourfolds with simple singularities and of quasi-polarized K3 surfaces of degree $2d$. For the moduli space of cubic fourfolds, we introduce a slope quantity to characterize the effective cone and prove an explicit bound for it. For the K3 moduli spaces, we give an explicit finite presentation of the rational Picard group by showing that it is generated by Noether-Lefschetz divisors of discriminant less than or equal to $4d$. As a byproduct, we obtain two explicit expressions for the Hodge class in terms of Noether-Lefschetz divisors, and we indicate analogous results for higher-codimension Noether-Lefschetz cycles."
  },
  {
    "date": "2026-02-09",
    "title": "Cascaded Optomechanical Sensing for Small Signals",
    "authors": "Marta Maria Marchese, Daniel Braun, Stefan Nimmrichter, Dennis Rätzel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08981v1",
    "source": "arXiv",
    "abstract": "We propose a sensing scheme for detecting weak forces that achieves Heisenberg-limited sensitivity without relying on entanglement or other non-classical resources. Our scheme utilizes coherent averaging across a chain of N optomechanical cavities, unidirectionally coupled via a laser beam. As the beam passes through the cavities, it accumulates phase shifts induced by a common external force acting on the mechanical elements. Remarkably, this fully classical approach achieves the sensitivity scaling typically associated with quantum-enhanced protocols, providing a robust and experimentally feasible route to precision sensing. Potential applications range from high-sensitivity gravitational field measurements at the Large Hadron Collider to probing dark matter interactions and detecting gravitational waves. This work opens a new pathway for leveraging coherent light-matter interactions for force sensing."
  },
  {
    "date": "2026-02-09",
    "title": "GHz-rate polarization-based QKD system for fiber and satellite applications",
    "authors": "Matías Rubén Bolaños, Edoardo Rossi, Federico Berra, Alberto De Toni, Ilektra Karakosta-Amarantidou, Daniel Christian Lawo, Costantino Agnesi, Marco Avesani, Andrea Stanco, Francesco Vedovato, Paolo Villoresi, Giuseppe Vallone",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08908v1",
    "source": "arXiv",
    "abstract": "Quantum key distribution (QKD) leverages the principles of quantum mechanics to exchange a secret key between two parties. Despite its promising features, QKD also faces several practical challenges such as transmission loss, noise in quantum channels and finite key size effects. Addressing these issues is crucial for the large-scale deployment of QKD in fiber and satellite networks. In this paper, we present a 1550 nm QKD system realizing the efficient-BB84 protocol and based on the iPOGNAC scheme. The system achieved repetition rates up to 1.5~GHz and showed an intrinsic QBER of $\\sim 0.4\\%$. The system was first tested on a laboratory fiber link and then on an intermodal link in the field, consisting of both deployed fiber and a 620 m free-space channel. The experiment was performed in daylight conditions, exploiting the Qubit4Sync synchronization protocol. With this trial, we achieved a new benchmark for free-space BB84 QKD systems by generating a sustained secret key rate (SKR) above 1~Mb/s for 1 hour. Finally, exploiting a recently discovered finite-size bound, we achieved a secure key rate of about 10 Mb/s at low losses (5 dB), and around 6.5~kb/s in the high-loss (38.5 dB), low block length ($N=10^4$) regime. The latter results demonstrate the system's suitability for highly lossy and time-constrained scenarios such as QKD from low Earth orbit satellites."
  },
  {
    "date": "2026-02-09",
    "title": "LakeHopper: Cross Data Lakes Column Type Annotation through Model Adaptation",
    "authors": "Yushi Sun, Xujia Li, Nan Tang, Quanqing Xu, Chuanhui Yang, Lei Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08793v1",
    "source": "arXiv",
    "abstract": "Column type annotation is vital for tasks like data cleaning, integration, and visualization. Recent solutions rely on resource-intensive language models fine-tuned on well-annotated columns from a particular set of tables, i.e., a source data lake. In this paper, we study whether we can adapt an existing pre-trained LM-based model to a new (i.e., target) data lake to minimize the annotations required on the new data lake. However, challenges include the source-target knowledge gap, selecting informative target data, and fine-tuning without losing shared knowledge exist. We propose LakeHopper, a framework that identifies and resolves the knowledge gap through LM interactions, employs a cluster-based data selection scheme for unannotated columns, and uses an incremental fine-tuning mechanism that gradually adapts the source model to the target data lake. Our experimental results validate the effectiveness of LakeHopper on two different data lake transfers under both low-resource and high-resource settings."
  },
  {
    "date": "2026-02-09",
    "title": "Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems",
    "authors": "Hao Dong, Eleni Chatzi, Olga Fink",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08792v1",
    "source": "arXiv",
    "abstract": "The pantograph-catenary interface is essential for ensuring uninterrupted and reliable power delivery in electrified rail systems. However, electrical arcing at this interface poses serious risks, including accelerated wear of contact components, degraded system performance, and potential service disruptions. Detecting arcing events at the pantograph-catenary interface is challenging due to their transient nature, noisy operating environment, data scarcity, and the difficulty of distinguishing arcs from other similar transient phenomena. To address these challenges, we propose a novel multimodal framework that combines high-resolution image data with force measurements to more accurately and robustly detect arcing events. First, we construct two arcing detection datasets comprising synchronized visual and force measurements. One dataset is built from data provided by the Swiss Federal Railways (SBB), and the other is derived from publicly available videos of arcing events in different railway systems and synthetic force data that mimic the characteristics observed in the real dataset. Leveraging these datasets, we propose MultiDeepSAD, an extension of the DeepSAD algorithm for multiple modalities with a new loss formulation. Additionally, we introduce tailored pseudo-anomaly generation techniques specific to each data type, such as synthetic arc-like artifacts in images and simulated force irregularities, to augment training data and improve the discriminative ability of the model. Through extensive experiments and ablation studies, we demonstrate that our framework significantly outperforms baseline approaches, exhibiting enhanced sensitivity to real arcing events even under domain shifts and limited availability of real arcing observations."
  },
  {
    "date": "2026-02-09",
    "title": "Positive mass theorems for manifolds with ALH toroidal ends",
    "authors": "Gregory J. Galloway, Tin-Yau Tsang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08789v1",
    "source": "arXiv",
    "abstract": "In work with P. Chruściel, L. Nguyen and T.-T. Paetz [8], a positive mass theorem was obtained for asymptotically locally hyperbolic manifolds with boundary, having a toroidal end. The proof made use of properties of marginally outer trapped surfaces (MOTS). Here we present some new PMT results for such manifolds, but without boundary, which allow for other more general ends. The proofs, while still MOTS-based, involve a more elaborate technique (related to $μ$-bubbles) introduced in work of D. A. Lee, M. Lesourd, and R. Unger [20] for manifolds with an asymptotically flat end, and further developed in [23] for manifolds with an asymptotically hyperbolic end."
  },
  {
    "date": "2026-02-09",
    "title": "Accessibility and Serviceability Assessment to Inform Offshore Wind Energy Development and Operations off the U.S. East Coast",
    "authors": "Cory Petersen, Feng Ye, Jiaxiang Ji, Josh Kohut, Ahmed Aziz Ezzat, David Saginaw, Avril Montanti, Jack Cammarota",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08787v1",
    "source": "arXiv",
    "abstract": "The economic success of offshore wind energy projects relies on accurate projections of the construction, and operations and maintenance (O&M) costs. These projections must consider the logistical complexities introduced by adverse met-ocean conditions that can prohibit access to the offshore assets for sustained periods of time. In response, the goal of this study is two-fold: (1) to provide high-resolution estimates of the accessibility of key offshore wind energy areas in the United States (U.S.) East Coast--a region with significant offshore wind energy potential; and (2) to introduce a new operational metric, called serviceability, as motivated by the need to assess the accessibility of an offshore asset along a vessel travel path, rather than at a specific site, as commonly carried out in the literature. We hypothesize that serviceability is more relevant to offshore operations than accessibility, since it more realistically reflects the success and safety of a vessel operation along its journey from port to site and back. Our analysis reveals high temporal and spatial variations in accessibility and serviceability, even for proximate offshore locations. We also find that solely relying on numerical met-ocean data can introduce considerable bias in estimating accessibility and serviceability, raising the need for a statistical treatment that combines both numerical and observational data sources, such as the one proposed herein. Collectively, our analysis sheds light on the value of high-resolution met-ocean information and models in supporting offshore operations, including but not limited to future offshore wind energy developments."
  },
  {
    "date": "2026-02-09",
    "title": "Empirically Understanding the Value of Prediction in Allocation",
    "authors": "Unai Fischer-Abaigar, Emily Aiken, Christoph Kern, Juan Carlos Perdomo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08786v1",
    "source": "arXiv",
    "abstract": "Institutions increasingly use prediction to allocate scarce resources. From a design perspective, better predictions compete with other investments, such as expanding capacity or improving treatment quality. Here, the big question is not how to solve a specific allocation problem, but rather which problem to solve. In this work, we develop an empirical toolkit to help planners form principled answers to this question and quantify the bottom-line welfare impact of investments in prediction versus other policy levers such as expanding capacity and improving treatment quality. Applying our framework in two real-world case studies on German employment services and poverty targeting in Ethiopia, we illustrate how decision-makers can reliably derive context-specific conclusions about the relative value of prediction in their allocation problem. We make our software toolkit, rvp, and parts of our data available in order to enable future empirical work in this area."
  },
  {
    "date": "2026-02-09",
    "title": "Amortising Inference and Meta-Learning Priors in Neural Networks",
    "authors": "Tommy Rochussen, Vincent Fortuin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08782v1",
    "source": "arXiv",
    "abstract": "One of the core facets of Bayesianism is in the updating of prior beliefs in light of new evidence$\\text{ -- }$so how can we maintain a Bayesian approach if we have no prior beliefs in the first place? This is one of the central challenges in the field of Bayesian deep learning, where it is not clear how to represent beliefs about a prediction task by prior distributions over model parameters. Bridging the fields of Bayesian deep learning and probabilistic meta-learning, we introduce a way to $\\textit{learn}$ a weights prior from a collection of datasets by introducing a way to perform per-dataset amortised variational inference. The model we develop can be viewed as a neural process whose latent variable is the set of weights of a BNN and whose decoder is the neural network parameterised by a sample of the latent variable itself. This unique model allows us to study the behaviour of Bayesian neural networks under well-specified priors, use Bayesian neural networks as flexible generative models, and perform desirable but previously elusive feats in neural processes such as within-task minibatching or meta-learning under extreme data-starvation."
  },
  {
    "date": "2026-02-09",
    "title": "The Unseen Species Problem Revisited",
    "authors": "Edward Eriksson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08769v1",
    "source": "arXiv",
    "abstract": "The unseen species problem is a classical problem in statistics. It asks us to, given n i.i.d. samples from an unknown discrete distribution over an unknown set, predict how many never before seen outcomes would be observed if m additional samples were collected. For small m we show the classical but poorly understood Good-Toulmin estimator to be minimax optimal to within a factor 2 and resolve the open problem of constructing principled prediction intervals for it. For intermediate m we propose a new estimator which achieves the minimax error for linear estimators up to an explicit multiplicative constant. Our estimator vastly outperforms the standard Smoothed Good-Toulmin estimator in the worst case and performs substantially better on several real data sets, namely those with many rare species. For large m we show that a previously mentioned estimator which did not have known rate guarantees actually achieves a marginally better rate than subsequent work. We find that this marginal rate improvement translates to meaningfully better performance in practice. We show in all three regimes that the same methods also achieve the same rate on incidence data, without further independence assumptions, provided that the sets are of bounded size. We establish, by means of bounded size biased couplings, concentration for some natural functionals of sequences of i.i.d. discrete-set-valued random variables which may be of independent interest."
  },
  {
    "date": "2026-02-09",
    "title": "Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas",
    "authors": "Micah Villmow",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08765v1",
    "source": "arXiv",
    "abstract": "LLM-based tools are automating more software development tasks at a rapid pace, but there is no rigorous way to evaluate how different architectural choices -- prompts, skills, tools, multi-agent setups -- materially affect both capability and cost. This paper introduces Scylla, an evaluation framework for benchmarking agentic coding tools through structured ablation studies that uses seven testing tiers (T0-T6) progressively adding complexity to isolate what directly influences results and how. The key metric is Cost-of-Pass (CoP): the expected dollar cost to get one correct solution, which directly quantifies the trade-off between complexity and efficiency. The framework is model-agnostic, designed to work with any CLI tool; this paper demonstrates it with Claude Sonnet 4.5, using multiple LLM judges (Opus 4.5, Sonnet 4.5, Haiku 4.5) from the same vendor for evaluation consensus, where judges score results using direct tests, human-designed LLM-evaluated rubrics, and qualitative assessment. The result is a reproducible framework that quantifies trade-offs between agent complexity and actual outcomes, suggesting that architectural complexity does not always improve quality."
  },
  {
    "date": "2026-02-09",
    "title": "Total Roman bondage number of a graph",
    "authors": "Fahimeh Khosh-Ahang Ghasr, Sakineh Nazari-Moghaddam",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08758v1",
    "source": "arXiv",
    "abstract": "A total Roman dominating function (TRDF) on a graph $G$ with no isolated vertices is a function $f:V(G)\\to\\{0,1,2\\}$ such that every vertex $v$ with $f(v)=0$ has a neighbor assigned $2$, and the subgraph induced by $\\{v:f(v)>0\\}$ has no isolated vertices. The total Roman domination number $γ_{tR}(G)$ is the minimum weight of a TRDF on $G$. The total Roman bondage number $b_{tR}(G)$ is the minimum cardinality of an edge set $E'\\subseteq E(G)$ such that $G-E'$ has no isolated vertices and $γ_{tR}(G-E')>γ_{tR}(G)$; if no such $E'$ exists, $b_{tR}(G)=\\infty$. We prove that deciding whether $b_{tR}(G)\\leq k$ is NP-complete for arbitrary graphs. We establish sharp bounds, including $γ_{tR}(G)+1\\leq γ_{tR}(G-B)\\leq γ_{tR}(G)+2$ for any $b_{tR}(G)$-set $B$ (both sharp), and $b_{tR}(G)\\geq \\max\\{δ(G),b(G)\\}$ when $γ_{tR}(G)=3β(G)$. We characterize graphs with $b_{tR}(G)=\\infty$ and provide a necessary and sufficient condition for $b_{tR}(G)=1$. Exact values are determined for complete graphs, complete bipartite graphs, brooms, double brooms, wheels and wounded spiders. Further upper bounds are given in terms of order, diameter, girth, and structural features."
  },
  {
    "date": "2026-02-09",
    "title": "Stability and stabilization of semilinear single-track vehicle models with distributed tire friction dynamics via singular perturbation analysis",
    "authors": "Luigi Romano, Ole Morten Aamo, Miroslav Krstić, Jan Åslund, Erik Frisk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08757v1",
    "source": "arXiv",
    "abstract": "This paper investigates the stability and stabilization of semilinear single-track vehicle models with distributed tire friction dynamics, modeled as interconnections of ordinary differential equations (ODEs) and hyperbolic partial differential equations (PDEs). Motivated by the long-standing practice of neglecting transient tire dynamics in vehicle modeling and control, a rigorous justification is provided for such simplifications using singular perturbation theory. A perturbation parameter, defined as the ratio between a characteristic rolling contact length and the vehicle's longitudinal speed, is introduced to formalize the time-scale separation between rigid-body motion and tire dynamics. For sufficiently small values of this parameter, it is demonstrated that standard finite-dimensional techniques can be applied to analyze the local stability of equilibria and to design stabilizing controllers. Both state-feedback and output-feedback designs are considered, under standard stabilizability and detectability assumptions. Whilst the proposed controllers follow classical approaches, the novelty of the work lies in establishing the first mathematical framework that rigorously connects distributed tire models with conventional vehicle dynamics. The results reconcile decades of empirical findings with a formal theoretical foundation and open new perspectives for the analysis and control of ODE-PDE systems with distributed friction in automotive applications."
  },
  {
    "date": "2026-02-09",
    "title": "MVAnimate: Enhancing Character Animation with Multi-View Optimization",
    "authors": "Tianyu Sun, Zhoujie Fu, Bang Zhang, Guosheng Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08753v1",
    "source": "arXiv",
    "abstract": "The demand for realistic and versatile character animation has surged, driven by its wide-ranging applications in various domains. However, the animation generation algorithms modeling human pose with 2D or 3D structures all face various problems, including low-quality output content and training data deficiency, preventing the related algorithms from generating high-quality animation videos. Therefore, we introduce MVAnimate, a novel framework that synthesizes both 2D and 3D information of dynamic figures based on multi-view prior information, to enhance the generated video quality. Our approach leverages multi-view prior information to produce temporally consistent and spatially coherent animation outputs, demonstrating improvements over existing animation methods. Our MVAnimate also optimizes the multi-view videos of the target character, enhancing the video quality from different views. Experimental results on diverse datasets highlight the robustness of our method in handling various motion patterns and appearances."
  },
  {
    "date": "2026-02-09",
    "title": "Synergistic cross-modal learning for experimental NMR-based structure elucidation",
    "authors": "Fanjie Xu, Jinyuan Hu, Jingxiang Zou, Junjie Wang, Boying Huang, Zhifeng Gao, Xiaohong Ji, Weinan E, Zhong-Qun Tian, Fujie Tang, Jun Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08752v1",
    "source": "arXiv",
    "abstract": "One-dimensional nuclear magnetic resonance (NMR) spectroscopy is essential for molecular structure elucidation in organic synthesis, drug discovery, natural product characterization, and metabolomics, yet its interpretation remains heavily dependent on expert knowledge and difficult to scale. Although machine learning has been applied to NMR spectrum prediction, library retrieval, and structure generation, these tasks have evolved in isolation using simulated data and incompatible spectral representations, limiting their utility under real experimental scenarios.Here we present NMRPeak, a unified cross-modal learning system that integrates these three tasks through experimentally grounded design. We curate approximately 1.8 million experimental and simulated spectra to construct the largest benchmark for NMR-based structure elucidation and systematically quantify the distribution shift between these domains. We introduce a chemically-aware adaptive tokenizer that dynamically balances discretization granularity to preserve spectral semantics while controlling vocabulary size, and an assignment-free peak-aware similarity metric that enables direct comparison between predicted and experimental spectra. Through a unified molecule-to-spectrum paradigm and synergistic coupling of prediction, retrieval, and generation modules, NMRPeak achieves transformative performance on experimental benchmarks: it overcomes the longstanding simulation-to-experiment gap in spectrum prediction while delivering over 95% top-1 accuracy in molecular retrieval and approximately 75% top-1 accuracy in stereochemistry-aware de novo structure generation. These capabilities establish a foundation for automated, high-throughput molecular structure elucidation in organic synthesis, drug discovery, and chemical biology."
  },
  {
    "date": "2026-02-09",
    "title": "Central Dogma Transformer II: An AI Microscope for Understanding Cellular Regulatory Mechanisms",
    "authors": "Nobuyuki Ota",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08751v1",
    "source": "arXiv",
    "abstract": "Current biological AI models lack interpretability -- their internal representations do not correspond to biological relationships that researchers can examine. Here we present CDT-II, an \"AI microscope\" whose attention maps are directly interpretable as regulatory structure. By mirroring the central dogma in its architecture, each attention mechanism corresponds to a specific biological relationship: DNA self-attention for genomic relationships, RNA self-attention for gene co-regulation, and DNA-to-RNA cross-attention for transcriptional control. Using only genomic embeddings and raw per-cell expression, CDT-II enables experimental biologists to observe regulatory networks in their own data. Applied to K562 CRISPRi data, CDT-II predicts perturbation effects (per-gene mean $r = 0.84$) and recovers the GFI1B regulatory network without supervision (6.6-fold enrichment, $P = 3.5 \\times 10^{-17}$). Two distinct attention mechanisms converge on an RNA processing module ($P = 1 \\times 10^{-16}$). CDT-II establishes mechanism-oriented AI as an alternative to task-oriented approaches, revealing regulatory structure rather than merely optimizing predictions."
  },
  {
    "date": "2026-02-09",
    "title": "PARD: Enhancing Goodput for Inference Pipeline via Proactive Request Dropping",
    "authors": "Zhixin Zhao, Yitao Hu, Simin Chen, Mingfang Ji, Wei Yang, Yuhao Zhang, Laiping Zhao, Wenxin Li, Xiulong Liu, Wenyu Qu, Hao Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08747v1",
    "source": "arXiv",
    "abstract": "Modern deep neural network (DNN) applications integrate multiple DNN models into inference pipelines with stringent latency requirements for customized tasks. To mitigate extensive request timeouts caused by accumulation, systems for inference pipelines commonly drop a subset of requests so the remaining ones can satisfy latency constraints. Since it is commonly believed that request dropping adversely affects goodput, existing systems only drop requests when they have to, which we call reactive dropping. However, this reactive policy can not maintain high goodput, as it neither makes timely dropping decisions nor identifies the proper set of requests to drop, leading to issues of dropping requests too late or dropping the wrong set of requests. We propose that the inference system should proactively drop certain requests in advance to enhance the goodput across the entire workload. To achieve this, we design an inference system PARD. It enhances goodput with timely and precise dropping decisions by integrating a proactive dropping method that decides when to drop requests using runtime information of the inference pipeline, and an adaptive request priority mechanism that selects which specific requests to drop based on remaining latency budgets and workload intensity. Evaluation on a cluster of 64 GPUs over real-world workloads shows that PARD achieves $16\\%$-$176\\%$ higher goodput than the state of the art while reducing the drop rate and wasted computation resources by $1.6\\times$-$17\\times$ and $1.5\\times$-$62\\times$ respectively."
  },
  {
    "date": "2026-02-09",
    "title": "On the Expressive Power of GNNs for Boolean Satisfiability",
    "authors": "Saku Peltonen, Roger Wattenhofer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08745v1",
    "source": "arXiv",
    "abstract": "Machine learning approaches to solving Boolean Satisfiability (SAT) aim to replace handcrafted heuristics with learning-based models. Graph Neural Networks have emerged as the main architecture for SAT solving, due to the natural graph representation of Boolean formulas. We analyze the expressive power of GNNs for SAT solving through the lens of the Weisfeiler-Leman (WL) test. As our main result, we prove that the full WL hierarchy cannot, in general, distinguish between satisfiable and unsatisfiable instances. We show that indistinguishability under higher-order WL carries over to practical limitations for WL-bounded solvers that set variables sequentially. We further study the expressivity required for several important families of SAT instances, including regular, random and planar instances. To quantify expressivity needs in practice, we conduct experiments on random instances from the G4SAT benchmark and industrial instances from the International SAT Competition. Our results suggest that while random instances are largely distinguishable, industrial instances often require more expressivity to predict a satisfying assignment."
  },
  {
    "date": "2026-02-09",
    "title": "Empirical Evaluation of SMOTE in Android Malware Detection with Machine Learning: Challenges and Performance in CICMalDroid 2020",
    "authors": "Diego Ferreira Duarte, Andre Augusto Bortoli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08744v1",
    "source": "arXiv",
    "abstract": "Malware, malicious software designed to damage computer systems and perpetrate scams, is proliferating at an alarming rate, with thousands of new threats emerging daily. Android devices, prevalent in smartphones, smartwatches, tablets, and IoTs, represent a vast attack surface, making malware detection crucial. Although advanced analysis techniques exist, Machine Learning (ML) emerges as a promising tool to automate and accelerate the discovery of these threats. This work tests ML algorithms in detecting malicious code from dynamic execution characteristics. For this purpose, the CICMalDroid2020 dataset, composed of dynamically obtained Android malware behavior samples, was used with the algorithms XGBoost, Naıve Bayes (NB), Support Vector Classifier (SVC), and Random Forest (RF). The study focused on empirically evaluating the impact of the SMOTE technique, used to mitigate class imbalance in the data, on the performance of these models. The results indicate that, in 75% of the tested configurations, the application of SMOTE led to performance degradation or only marginal improvements, with an average loss of 6.14 percentage points. Tree-based algorithms, such as XGBoost and Random Forest, consistently outperformed the others, achieving weighted recall above 94%. It is inferred that SMOTE, although widely used, did not prove beneficial for Android malware detection in the CICMalDroid2020 dataset, possibly due to the complexity and sparsity of dynamic characteristics or the nature of malicious relationships. This work highlights the robustness of tree-ensemble models, such as XGBoost, and suggests that algorithmic data balancing approaches may be more effective than generating synthetic instances in certain cybersecurity scenarios"
  },
  {
    "date": "2026-02-09",
    "title": "The Nysa family as the main source of unequilibrated LL ordinary chondrites",
    "authors": "M. Marsset, P. Vernazza, M. Brož, C. Avdellidou, C. A. Thomas, L. McGraw, A. Madden-Watson, K. Minker, M. Monnereau, F. E. DeMeo, R. P. Binzel, M. Mahlke, B. Carry, J. Hanuš, P. N. Simon, B. Yang, P. Beck, M. Birlan, E. Jehin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08732v1",
    "source": "arXiv",
    "abstract": "Context. The origin of the petrologic diversity observed in ordinary chondrites (OCs), the most common meteorites on Earth, remains debated. Competing models invoke either depth-dependent sampling of a single thermally stratified (\"onion-shell\") parent body or contributions from multiple distinct parent bodies. Aims. We aim to determine which of the two models is preferred for LL chondrites. These are unique among OCs in exhibiting a bimodal petrologic distribution, with most meteorites being LL3 or LL6. Methods. We compare the spectral and mineralogical properties of LL chondrites and corresponding LL-chondrite-like near-Earth objects (NEOs) with their possible sources in the main asteroid belt. We also model the thermal histories of the proposed parent bodies, based on revised estimates of parent-body sizes. Results. The spectral and mineralogical diversity of LL chondrites is consistent with contributions from the bright, S-type component of the Nysa family (NysaS) and the Flora family, with NysaS supplying mainly low-petrologic-type material and Flora higher-grade material. Unequilibrated, LL3 chondrites appear to originate exclusively from NysaS. Similarly, LL-chondrite-like NEOs form two distinct subpopulations consistent with origins in these same families. Conclusions. Our results favour multiple parent bodies for LL chondrites. The petrologic differences between the NysaS and Flora parent bodies indicate that planetesimal accretion within the OC reservoir extended over 0.5-0.7 Myr."
  },
  {
    "date": "2026-02-09",
    "title": "Conformally flat factorization homology in Ind-Hilbert spaces and Conformal field theory",
    "authors": "Yuto Moriwaki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08729v1",
    "source": "arXiv",
    "abstract": "We propose a metric-dependent geometric variant of factorization homology in conformally flat Riemannian geometry for $d \\geq 2$. We introduce a symmetric monoidal category of germs of d-dimensional Riemannian manifolds and orientation-preserving conformal open embeddings, and its full monoidal subcategory generated by flat disks. A conformally flat $d$-disk algebra is a symmetric monoidal functor from this disk category to a target category; in this paper we take the target to be $\\mathrm{IndHilb}$, the ind-category of Hilbert spaces, which provides a mathematical formulation of $d$-dimensional conformal field theories. The (1-categorical) left Kan extension of an $\\mathrm{IndHilb}$-valued conformally flat $d$-disk algebra defines a metric-dependent invariant of conformally flat manifolds. Under suitable positivity and continuity assumptions, we prove that its value on the standard sphere $(S^d,g_{\\mathrm{std}})$ reproduces the sphere partition function of the associated conformal field theory. For $d>2$, we construct nontrivial $\\mathrm{IndHilb}$-valued conformally flat $d$-disk algebras from unitary representations of $\\mathrm{SO}^+(d,1)$."
  },
  {
    "date": "2026-02-09",
    "title": "Artifact Reduction in Undersampled 3D Cone-Beam CTs using a Hybrid 2D-3D CNN Framework",
    "authors": "Johannes Thalhammer, Tina Dorosti, Sebastian Peterhansl, Daniela Pfeiffer, Franz Pfeiffer, Florian Schaff",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08727v1",
    "source": "arXiv",
    "abstract": "Undersampled CT volumes minimize acquisition time and radiation exposure but introduce artifacts degrading image quality and diagnostic utility. Reducing these artifacts is critical for high-quality imaging. We propose a computationally efficient hybrid deep-learning framework that combines the strengths of 2D and 3D models. First, a 2D U-Net operates on individual slices of undersampled CT volumes to extract feature maps. These slice-wise feature maps are then stacked across the volume and used as input to a 3D decoder, which utilizes contextual information across slices to predict an artifact-free 3D CT volume. The proposed two-stage approach balances the computational efficiency of 2D processing with the volumetric consistency provided by 3D modeling. The results show substantial improvements in inter-slice consistency in coronal and sagittal direction with low computational overhead. This hybrid framework presents a robust and efficient solution for high-quality 3D CT image post-processing. The code of this project can be found on github: https://github.com/J-3TO/2D-3DCNN_sparseview/."
  },
  {
    "date": "2026-02-09",
    "title": "QUOKA: Query-Oriented KV Selection For Efficient LLM Prefill",
    "authors": "Dalton Jones, Junyoung Park, Matthew Morse, Mingu Lee, Chris Lott, Harper Langston",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08722v1",
    "source": "arXiv",
    "abstract": "We present QUOKA: Query-oriented KV selection for efficient attention, a training-free and hardware agnostic sparse attention algorithm for accelerating transformer inference under chunked prefill. While many queries focus on a smaller group of keys in the attention operator, we observe that queries with low cosine similarity with respect to the mean query interact more strongly with more keys and have the greatest contribution to final attention logits. By prioritizing these low cosine similarity queries, the behavior of full attention during the prefill stage can be closely approximated. QUOKA leverages this observation, accelerating attention by (1) first retaining a small set of representative queries and (2) then subselectin the keys most aligned with those queries. Through experiments on Needle-In-A-Haystack, LongBench, RULER, and Math500, we show that, while realizing a 3x reduction in time-to-first-token, 5x speedup in attention on Nvidia GPUs and up to nearly a 7x speedup on Intel Xeon CPUs, QUOKA achieves near-baseline accuracy, utilizing 88% fewer key-value pairs per attention evaluation."
  },
  {
    "date": "2026-02-09",
    "title": "Approximate-EFX Allocations with Ordinal and Limited Cardinal Information",
    "authors": "Aris Filos-Ratsikas, Georgios Kalantzis, Alexandros A. Voudouris",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08714v1",
    "source": "arXiv",
    "abstract": "We study a discrete fair division problem where $n$ agents have additive valuation functions over a set of $m$ goods. We focus on the well-known $α$-EFX fairness criterion, according to which the envy of an agent for another agent is bounded multiplicatively by $α$, after the removal of any good from the envied agent's bundle. The vast majority of the literature has studied $α$-EFX allocations under the assumption that full knowledge of the valuation functions of the agents is available. Motivated by the established literature on the distortion in social choice, we instead consider $α$-EFX algorithms that operate under limited information on these functions. In particular, we assume that the algorithm has access to the ordinal preference rankings, and is allowed to make a small number of queries to obtain further access to the underlying values of the agents for the goods. We show (near-optimal) tradeoffs between the values of $α$ and the number of queries required to achieve those, with a particular focus on constant EFX approximations. We also consider two interesting special cases, namely instances with a constant number of agents, or with two possible values, and provide improved positive results."
  },
  {
    "date": "2026-02-09",
    "title": "TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions",
    "authors": "Linli Yao, Yuancheng Wei, Yaojie Zhang, Lei Li, Xinlong Chen, Feifan Song, Ziyue Wang, Kun Ouyang, Yuanxin Liu, Lingpeng Kong, Qi Liu, Pengfei Wan, Kun Gai, Yuanxing Zhang, Xu Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08711v1",
    "source": "arXiv",
    "abstract": "This paper proposes Omni Dense Captioning, a novel task designed to generate continuous, fine-grained, and structured audio-visual narratives with explicit timestamps. To ensure dense semantic coverage, we introduce a six-dimensional structural schema to create \"script-like\" captions, enabling readers to vividly imagine the video content scene by scene, akin to a cinematographic screenplay. To facilitate research, we construct OmniDCBench, a high-quality, human-annotated benchmark, and propose SodaM, a unified metric that evaluates time-aware detailed descriptions while mitigating scene boundary ambiguity. Furthermore, we construct a training dataset, TimeChatCap-42K, and present TimeChat-Captioner-7B, a strong baseline trained via SFT and GRPO with task-specific rewards. Extensive experiments demonstrate that TimeChat-Captioner-7B achieves state-of-the-art performance, surpassing Gemini-2.5-Pro, while its generated dense descriptions significantly boost downstream capabilities in audio-visual reasoning (DailyOmni and WorldSense) and temporal grounding (Charades-STA). All datasets, models, and code will be made publicly available at https://github.com/yaolinli/TimeChat-Captioner."
  },
  {
    "date": "2026-02-09",
    "title": "FactSim: Fact-Checking for Opinion Summarization",
    "authors": "Leandro Anghinoni, Jorge Sanchez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08709v1",
    "source": "arXiv",
    "abstract": "We explore the need for more comprehensive and precise evaluation techniques for generative artificial intelligence (GenAI) in text summarization tasks, specifically in the area of opinion summarization. Traditional methods, which leverage automated metrics to compare machine-generated summaries from a collection of opinion pieces, e.g. product reviews, have shown limitations due to the paradigm shift introduced by large language models (LLM). This paper addresses these shortcomings by proposing a novel, fully automated methodology for assessing the factual consistency of such summaries. The method is based on measuring the similarity between the claims in a given summary with those from the original reviews, measuring the coverage and consistency of the generated summary. To do so, we rely on a simple approach to extract factual assessment from texts that we then compare and summarize in a suitable score. We demonstrate that the proposed metric attributes higher scores to similar claims, regardless of whether the claim is negated, paraphrased, or expanded, and that the score has a high correlation to human judgment when compared to state-of-the-art metrics."
  },
  {
    "date": "2026-02-09",
    "title": "Laplacian Pair State Transfer on Total Graphs",
    "authors": "Akash Kalita, Bikash Bhattacharjya",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08684v1",
    "source": "arXiv",
    "abstract": "The total graph of a graph $G$, denoted $\\mathcal{T}(G)$, is defined as the graph whose vertex set is the union of the vertex set of $G$ and the edge set of $G$ such that two vertices of $\\mathcal{T}(G)$ are adjacent if the corresponding elements of $G$ are adjacent or incident. In this paper, we investigate Laplacian perfect pair state transfer and Laplacian pretty good pair state transfer on $\\mathcal{T}(G)$, where $G$ is an $r$-regular graph. We prove that if $r>2$ and $r+1$ is not a Laplacian eigenvalue of $G$, then $\\mathcal{T}(G)$ fails to exhibit Laplacian perfect pair state transfer. We also prove that if $G$ is a complete graph on more than three vertices, then $\\mathcal{T}(G)$ fails to exhibit Laplacian perfect pair state transfer. Further, we prove that under some mild conditions, $\\mathcal{T}(G)$ exhibits Laplacian pretty good pair state transfer, where $G$ is an $r$-regular graph such that $r>2$ and $r+1$ is not a Laplacian eigenvalue of $G$. We use these conditions to obtain infinitely many total graphs exhibiting Laplacian pretty good pair state transfer."
  },
  {
    "date": "2026-02-09",
    "title": "OneVision-Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence",
    "authors": "Feilong Tang, Xiang An, Yunyao Yan, Yin Xie, Bin Qin, Kaicheng Yang, Yifei Shen, Yuanhan Zhang, Chunyuan Li, Shikun Feng, Changrui Chen, Huajie Tan, Ming Hu, Manyuan Zhang, Bo Li, Ziyong Feng, Ziwei Liu, Zongyuan Ge, Jiankang Deng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08683v1",
    "source": "arXiv",
    "abstract": "Hypothesis. Artificial general intelligence is, at its core, a compression problem. Effective compression demands resonance: deep learning scales best when its architecture aligns with the fundamental structure of the data. These are the fundamental principles. Yet, modern vision architectures have strayed from these truths: visual signals are highly redundant, while discriminative information, the surprise, is sparse. Current models process dense pixel grids uniformly, wasting vast compute on static background rather than focusing on the predictive residuals that define motion and meaning. We argue that to solve visual understanding, we must align our architectures with the information-theoretic principles of video, i.e., Codecs. Method. OneVision-Encoder encodes video by compressing predictive visual structure into semantic meaning. By adopting Codec Patchification, OV-Encoder abandons uniform computation to focus exclusively on the 3.1%-25% of regions rich in signal entropy. To unify spatial and temporal reasoning under irregular token layouts, OneVision-Encoder employs a shared 3D RoPE and is trained with a large-scale cluster discrimination objective over more than one million semantic concepts, jointly capturing object permanence and motion dynamics. Evidence. The results validate our core hypothesis: efficiency and accuracy are not a trade-off; they are positively correlated. When integrated into LLM, it consistently outperforms strong vision backbones such as Qwen3-ViT and SigLIP2 across 16 image, video, and document understanding benchmarks, despite using substantially fewer visual tokens and pretraining data. Notably, on video understanding tasks, OV-Encoder achieves an average improvement of 4.1% over Qwen3-ViT. Codec-aligned, patch-level sparsity is a foundational principle, enabling OV-Encoder as a scalable engine for next-generation visual generalists."
  },
  {
    "date": "2026-02-09",
    "title": "SRSUPM: Sequential Recommender System Based on User Psychological Motivation",
    "authors": "Yicheng Di, Yuan Liu, Zhi Chen, Jingcai Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08667v1",
    "source": "arXiv",
    "abstract": "Sequential recommender infers users' evolving psychological motivations from historical interactions to recommend the next preferred items. Most existing methods compress recent behaviors into a single vector and optimize it toward a single observed target item, but lack explicit modeling of psychological motivation shift. As a result, they struggle to uncover the distributional patterns across different shift degrees and to capture collaborative knowledge that is sensitive to psychological motivation shift. We propose a general framework, the Sequential Recommender System Based on User Psychological Motivation, to enhance sequential recommenders with psychological motivation shift-aware user modeling. Specifically, the Psychological Motivation Shift Assessment quantitatively measures psychological motivation shift; guided by PMSA, the Shift Information Construction models dynamically evolving multi-level shift states, and the Psychological Motivation Shift-driven Information Decomposition decomposes and regularizes representations across shift levels. Moreover, the Psychological Motivation Shift Information Matching strengthens collaborative patterns related to psychological motivation shift to learn more discriminative user representations. Extensive experiments on three public benchmarks show that SRSUPM consistently outperforms representative baselines on diverse sequential recommender tasks."
  },
  {
    "date": "2026-02-09",
    "title": "Enhanced third harmonic response of the PtTe$_2$ transition metal dichalcogenide",
    "authors": "Leone Di Mauro Villari, Simone Grillo, Olivia Pulci, Salvatore Macis, Stefano Lupi, Andrea Marini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08663v1",
    "source": "arXiv",
    "abstract": "We investigate the third harmonic response of platinum ditelluride (PtTe$_2$), a Dirac semimetal belonging to the transition metal dichalcogenides class. Due to its topological properties, this material has drawn a lot of attention, particularly because it hosts type-II (super-critically tilted) Dirac fermions in the $\\rm A-Γ-\\rm A$ high symmetry direction. Adopting a low-energy model fitted directly from density functional theory band structure simulations, we calculate analytically the nonlinear conductivity. We observe that third-order optical nonlinearities are efficiently modulated by the cones tilting, which produces a significant enhancement of the nonlinear susceptibility. Our results, besides shedding light on topological transitions of platinum ditelluride, are relevant for future nanophotonic devices exploiting the tunable nonlinear properties of type-II Dirac fermions."
  },
  {
    "date": "2026-02-09",
    "title": "Numerical solution of the two-dimensional Calderon problem for domains close to a disk",
    "authors": "Vladimir A. Sharafutdinov, Konstantin V. Storozhuk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08662v1",
    "source": "arXiv",
    "abstract": "For a compact Riemannian surface $(M,g)$ with non-empty boundary $Γ$, the Dirichlet-to-Neumann operator (DtN-map) $Λ_g:C^\\infty(Γ)\\to C^\\infty(Γ)$ is defined by $Λ_gf=\\left.\\frac{\\partial u}{\\partialν}\\right|_Γ$, where $ν$ is the unit outer normal vector to the boundary and $u$ is the solution to the Dirichlet problem $Δ_gu=0,\\ u|_Γ=f$. The Calderón problem consists of recovering a Riemannian surface from its DtN-map. It is well known that $(M,g)$ is determined by $Λ_g$ uniquely up to a conformal equivalence. We suggest a method for numerical solution of the Calderón problem. The method works well at least for Riemannian surfaces $(M,g)$ close to $({D},e)$, where ${D}=\\{(x,y)\\mid x^2+y^2\\le1\\}$ is the unit disk and $e=dx^2+dy^2$ is the Euclidean metric. Our numerical examples confirm the statement: the DtN-map is very sensitive to small deviations of the shape of a domain."
  },
  {
    "date": "2026-02-09",
    "title": "Ecosystems in the Anthropocene: transformative drivers",
    "authors": "Clara de Goes Monteiro de Carvalho Guimaraes, Pablo Jose Francisco Pena Rodrigues",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08656v1",
    "source": "arXiv",
    "abstract": "Human activity has an enormous impact on Earth, changing organisms, environments and landscapes, leading to the decline of original ecosystems and irreversible changes that create new combinations of living beings and materials. As a result, ecosystems with new properties and new species pools are emerging. Here, we explore a set of transformative drivers, which can act either individually or in synergy. The expansion of novel ecosystems (hybrids of natural and agricultural systems) is a sign of irreversible, human-induced change. Human growth, adaptation to climate change, urban expansion and geoengineering are powerful transformative drivers which are expected to have a high impact, creating novel ecosystems. In contrast, less transformative drivers such as degrowth, biocentrism, ecological restoration and low-impact agriculture can mitigate human impacts, leading to adaptation, resilience and sustainability, while conserving original ecosystems. This requires a new approach, incorporating new ecological, ethical and cultural perspectives, to keep ecosystems functional and healthy."
  },
  {
    "date": "2026-02-09",
    "title": "IceCube's Sensitivity Prospects to MeV-Scale Axion-Like Particles from Core-Collapse Supernovae",
    "authors": "Nora Valtonen-Mattila, Shlok Shah, Segev BenZvi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08649v1",
    "source": "arXiv",
    "abstract": "We present a novel framework to estimate the sensitivity and discovery potential of IceCube to axion-like particles (ALPs) produced in core-collapse supernovae (CCSNe), covering ALP masses from 1 MeV to several hundred MeV. A key feature of this work is the explicit handling of the final-state leptons produced in ALP interactions with $^{16}$O nuclei and protons, which can generate Cherenkov light detectable in IceCube. These processes are being fully integrated into a detector-level simulation chain, enabling realistic detector signal modeling beyond existing estimates. The framework enables sensitivity forecasts for both direct detection and constraints based on time delays relative to the neutrino burst, across a range of ALP emission models. This approach may also extend to other MeV-scale dark sector particles. Preliminary sensitivity estimates are in progress and will be presented."
  },
  {
    "date": "2026-02-09",
    "title": "Universal Approximation Theorems for Dynamical Systems with Infinite-Time Horizon Guarantees",
    "authors": "Abel Sagodi, Il Memming Park",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08640v1",
    "source": "arXiv",
    "abstract": "Universal approximation theorems establish the expressive capacity of neural network architectures. For dynamical systems, existing results are limited to finite time horizons or systems with a globally stable equilibrium, leaving multistability and limit cycles unaddressed. We prove that Neural ODEs achieve $\\varepsilon$-$δ$ closeness -- trajectories within error $\\varepsilon$ except for initial conditions of measure $< δ$ -- over the \\emph{infinite} time horizon $[0,\\infty)$ for three target classes: (1) Morse-Smale systems (a structurally stable class) with hyperbolic fixed points, (2) Morse-Smale systems with hyperbolic limit cycles via exact period matching, and (3) systems with normally hyperbolic continuous attractors via discretization. We further establish a temporal generalization bound: $\\varepsilon$-$δ$ closeness implies $L^p$ error $\\leq \\varepsilon^p + δ\\cdot D^p$ for all $t \\geq 0$, bridging topological guarantees to training metrics. These results provide the first universal approximation framework for multistable infinite-horizon dynamics."
  },
  {
    "date": "2026-02-09",
    "title": "LEFT: Learnable Fusion of Tri-view Tokens for Unsupervised Time Series Anomaly Detection",
    "authors": "Dezheng Wang, Tong Chen, Guansong Pang, Congyan Chen, Shihua Li, Hongzhi Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08638v1",
    "source": "arXiv",
    "abstract": "As a fundamental data mining task, unsupervised time series anomaly detection (TSAD) aims to build a model for identifying abnormal timestamps without assuming the availability of annotations. A key challenge in unsupervised TSAD is that many anomalies are too subtle to exhibit detectable deviation in any single view (e.g., time domain), and instead manifest as inconsistencies across multiple views like time, frequency, and a mixture of resolutions. However, most cross-view methods rely on feature or score fusion and do not enforce analysis-synthesis consistency, meaning the frequency branch is not required to reconstruct the time signal through an inverse transform, and vice versa. In this paper, we present Learnable Fusion of Tri-view Tokens (LEFT), a unified unsupervised TSAD framework that models anomalies as inconsistencies across complementary representations. LEFT learns feature tokens from three views of the same input time series: frequency-domain tokens that embed periodicity information, time-domain tokens that capture local dynamics, and multi-scale tokens that learns abnormal patterns at varying time series granularities. By learning a set of adaptive Nyquist-constrained spectral filters, the original time series is rescaled into multiple resolutions and then encoded, allowing these multi-scale tokens to complement the extracted frequency- and time-domain information. When generating the fused representation, we introduce a novel objective that reconstructs fine-grained targets from coarser multi-scale structure, and put forward an innovative time-frequency cycle consistency constraint to explicitly regularize cross-view agreement. Experiments on real-world benchmarks show that LEFT yields the best detection accuracy against SOTA baselines, while achieving a 5x reduction on FLOPs and 8x speed-up for training."
  },
  {
    "date": "2026-02-09",
    "title": "Supporting Effective Goal Setting with LLM-Based Chatbots",
    "authors": "Michel Schimpf, Sebastian Maier, Anton Wyrowski, Lara Christoforakos, Stefan Feuerriegel, Thomas Bohné",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08636v1",
    "source": "arXiv",
    "abstract": "Each day, individuals set behavioral goals such as eating healthier, exercising regularly, or increasing productivity. While psychological frameworks (i.e., goal setting and implementation intentions) can be helpful, they often need structured external support, which interactive technologies can provide. We thus explored how large language model (LLM)-based chatbots can apply these frameworks to guide users in setting more effective goals. We conducted a preregistered randomized controlled experiment ($N = 543$) comparing chatbots with different combinations of three design features: guidance, suggestions, and feedback. We evaluated goal quality using subjective and objective measures. We found that, while guidance is already helpful, it is the addition of feedback that makes LLM-based chatbots effective in supporting participants' goal setting. In contrast, adaptive suggestions were less effective. Altogether, our study shows how to design chatbots by operationalizing psychological frameworks to provide effective support for reaching behavioral goals."
  },
  {
    "date": "2026-02-09",
    "title": "Do Multilingual LLMs have specialized language heads?",
    "authors": "Muhammad Naufil",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08625v1",
    "source": "arXiv",
    "abstract": "Multilingual large language models (LLMs) have gained significant popularity for their ability to process and generate text across multiple languages. However, deploying these models in production can be inefficient when only a subset of the supported languages is of interest. There has been some research conducted on identifying whether machine translation models have language-specific or language-agnostic heads, however no research has been conducted for multilingual LLMs, to the best of our knowledge, that as we know are capable of performing diverse tasks beyond just translation. This paper explores whether multilingual LLMs have specialized language attention heads for each language, and investigates the possibility of removing language-specific heads for unwanted languages without degrading performance in the targeted languages. Our findings could inform more efficient deployment strategies for multilingual LLMs, enabling reduced model complexity while maintaining high accuracy for targeted languages."
  },
  {
    "date": "2026-02-09",
    "title": "From Raw Data to Shared 3D Semantics: Task-Oriented Communication for Multi-Robot Collaboration",
    "authors": "Ruibo Xue, Jiedan Tan, Fang Liu, Jingwen Tong, Taotao Wang, Shuoyao Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08624v1",
    "source": "arXiv",
    "abstract": "Multi-robot systems (MRS) rely on exchanging raw sensory data to cooperate in complex three-dimensional (3D) environments. However, this strategy often leads to severe communication congestion and high transmission latency, significantly degrading collaboration efficiency. This paper proposes a decentralized task-oriented semantic communication framework for multi-robot collaboration in unknown 3D environments. Each robot locally extracts compact, task-relevant semantics using a lightweight Pixel Difference Network (PiDiNet) with geometric processing. It shares only these semantic updates to build a task-sufficient 3D scene representation that supports cooperative perception, navigation, and object transport. Our numerical results show that the proposed method exhibits a dramatic reduction in communication overhead from $858.6$ Mb to $4.0$ Mb (over $200\\times$ compression gain) while improving collaboration efficiency by shortening task completion from $1,054$ to $281$ steps."
  },
  {
    "date": "2026-02-09",
    "title": "Improving Reconstruction of Representation Autoencoder",
    "authors": "Siyu Liu, Chujie Qin, Hubery Yin, Qixin Yan, Zheng-Peng Duan, Chen Li, Jing Lyu, Chun-Le Guo, Chongyi Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08620v1",
    "source": "arXiv",
    "abstract": "Recent work leverages Vision Foundation Models as image encoders to boost the generative performance of latent diffusion models (LDMs), as their semantic feature distributions are easy to learn. However, such semantic features often lack low-level information (\\eg, color and texture), leading to degraded reconstruction fidelity, which has emerged as a primary bottleneck in further scaling LDMs. To address this limitation, we propose LV-RAE, a representation autoencoder that augments semantic features with missing low-level information, enabling high-fidelity reconstruction while remaining highly aligned with the semantic distribution. We further observe that the resulting high-dimensional, information-rich latent make decoders sensitive to latent perturbations, causing severe artifacts when decoding generated latent and consequently degrading generation quality. Our analysis suggests that this sensitivity primarily stems from excessive decoder responses along directions off the data manifold. Building on these insights, we propose fine-tuning the decoder to increase its robustness and smoothing the generated latent via controlled noise injection, thereby enhancing generation quality. Experiments demonstrate that LV-RAE significantly improves reconstruction fidelity while preserving the semantic abstraction and achieving strong generative quality. Our code is available at https://github.com/modyu-liu/LVRAE."
  },
  {
    "date": "2026-02-09",
    "title": "Overview and Comparison of AVS Point Cloud Compression Standard",
    "authors": "Wei Gao, Wenxu Gao, Xingming Mu, Changhao Peng, Ge Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08613v1",
    "source": "arXiv",
    "abstract": "Point cloud is a prevalent 3D data representation format with significant application values in immersive media, autonomous driving, digital heritage protection, etc. However, the large data size of point clouds poses challenges to transmission and storage, which influences the wide deployments. Therefore, point cloud compression plays a crucial role in practical applications for both human and machine perception optimization. To this end, the Moving Picture Experts Group (MPEG) has established two standards for point cloud compression, including Geometry-based Point Cloud Compression (G-PCC) and Video-based Point Cloud Compression (V-PCC). In the meantime, the Audio Video coding Standard (AVS) Workgroup of China also have launched and completed the development for its first generation point cloud compression standard, namely AVS PCC. This new standardization effort has adopted many new coding tools and techniques, which are different from the other counterpart standards. This paper reviews the AVS PCC standard from two perspectives, i.e., the related technologies and performance comparisons."
  },
  {
    "date": "2026-02-09",
    "title": "OneLive: Dynamically Unified Generative Framework for Live-Streaming Recommendation",
    "authors": "Shen Wang, Yusheng Huang, Ruochen Yang, Shuang Wen, Pengbo Xu, Jiangxia Cao, Yueyang Liu, Kuo Cai, Chengcheng Guo, Shiyao Wang, Xinchen Luo, Qiang Luo, Ruiming Tang, Shuang Yang, Zhaojie Liu, Guorui Zhou, Han Li, Kun Gai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08612v1",
    "source": "arXiv",
    "abstract": "Live-streaming recommender system serves as critical infrastructure that bridges the patterns of real-time interactions between users and authors. Similar to traditional industrial recommender systems, live-streaming recommendation also relies on cascade architectures to support large-scale concurrency. Recent advances in generative recommendation unify the multi-stage recommendation process with Transformer-based architectures, offering improved scalability and higher computational efficiency. However, the inherent complexity of live-streaming prevents the direct transfer of these methods to live-streaming scenario, where continuously evolving content, limited lifecycles, strict real-time constraints, and heterogeneous multi-objectives introduce unique challenges that invalidate static tokenization and conventional model framework. To address these issues, we propose OneLive, a dynamically unified generative recommendation framework tailored for live-streaming scenario. OneLive integrates four key components: (i) A Dynamic Tokenizer that continuously encodes evolving real-time live content fused with behavior signal through residual quantization; (ii) A Time-Aware Gated Attention mechanism that explicitly models temporal dynamics for timely decision making; (iii) An efficient decoder-only generative architecture enhanced with Sequential MTP and QK Norm for stable training and accelerated inference; (iv) A Unified Multi-Objective Alignment Framework reinforces policy optimization for personalized preferences."
  },
  {
    "date": "2026-02-09",
    "title": "Dynamical Mordell-Lang conjecture for split self-maps of affine curve times projective curve",
    "authors": "Junyi Xie, She Yang, Aoyang Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08608v1",
    "source": "arXiv",
    "abstract": "We prove the dynamical Mordell-Lang conjecture for product of endomorphisms of an affine curve and a projective curve over $\\overline{\\mathbb{Q}}$."
  },
  {
    "date": "2026-02-09",
    "title": "Tikhonov regularization-based reconstruction of partial scattering functions obtained from contrast variation small-angle neutron scattering",
    "authors": "Manabu Machida, Koichi Mayumi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08601v1",
    "source": "arXiv",
    "abstract": "Contrast variation small-angle neutron scattering (CV-SANS) has been widely employed for nano structural analysis of multicomponent systems. In CV-SANS experiments, scattering intensities of samples with different scattering co\\ ntrasts are decomposed into partial scattering functions, corresponding to structure of each component and cross-correlation between different components, by singular value decomposition (SVD). However, the estimation of partial scattering functions with small absolute values often suffers from instability due to the significant differences in the singular values. In this paper, we propose a remedy for this instability by introducing the Tikhonov regularization, which ensures more stable reconstruction of the partial scattering functions."
  },
  {
    "date": "2026-02-09",
    "title": "Beyond Scalar Scores: Reinforcement Learning for Error-Aware Quality Estimation of Machine Translation",
    "authors": "Archchana Sindhujan, Girish A. Koushik, Shenbin Qian, Diptesh Kanojia, Constantin Orăsan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08600v1",
    "source": "arXiv",
    "abstract": "Quality Estimation (QE) aims to assess the quality of machine translation (MT) outputs without relying on reference translations, making it essential for real-world, large-scale MT evaluation. Large Language Models (LLMs) have shown significant promise in advancing the field of quality estimation of machine translation. However, most of the QE approaches solely rely on scalar quality scores, offering no explicit information about the translation errors that should drive these judgments. Moreover, for low-resource languages where annotated QE data is limited, existing approaches struggle to achieve reliable performance. To address these challenges, we introduce the first segment-level QE dataset for English to Malayalam, a severely resource-scarce language pair in the QE domain, comprising human-annotated Direct Assessment (DA) scores and Translation Quality Remarks (TQR), which are short, contextual, free-form annotator comments that describe translation errors. We further introduce ALOPE-RL, a policy-based reinforcement learning framework that trains efficient adapters based on policy rewards derived from DA score and TQR. Integrating error-aware rewards with ALOPE-RL, enables LLMs to reason about translation quality beyond numeric scores. Despite being trained on a small-scale QE dataset, ALOPE-RL achieves state-of-the-art performance on English to Malayalam QE using compact LLMs (<=4B parameters}) fine-tuned with LoRA and 4-bit quantization, outperforming both larger LLM-based baselines and leading encoder-based QE models. Our results demonstrate that error-aware, policy-based learning can deliver strong QE performance under limited data and compute budgets. We release our dataset, code, and trained models to support future research."
  },
  {
    "date": "2026-02-09",
    "title": "Residential Peak Load Reduction via Direct Load Control under Limited Information",
    "authors": "Katharina Kaiser, Gustavo Valverde, Gabriela Hug",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08598v1",
    "source": "arXiv",
    "abstract": "Thermostatically controlled loads and electric vehicles offer flexibility to reduce power peaks in low-voltage distribution networks. This flexibility can be maximized if the devices are coordinated centrally, given some level of information about the controlled devices. In this paper, we propose novel optimization-based control schemes with prediction capabilities that utilize limited information from heat pumps, electric water heaters, and electric vehicles. The objective is to flatten the total load curve seen by the distribution transformer by restricting the times at which the available flexible loads are allowed to operate, subject to the flexibility constraints of the loads to preserve customers' comfort. The original scheme was tested in a real-world setup, considering both winter and summer days. The pilot results confirmed the technical feasibility but also informed the design of an improved version of the controller. Computer simulations using the adjusted controller show that, compared to the original formulation, the improved scheme achieves greater peak reductions in summer. Additionally, comparisons were made with an ideal controller, which assumes perfect knowledge of the inflexible load profile, the models of the controlled devices, the hot water and space heating demand, and future electric vehicle charging sessions. The proposed scheme with limited information achieves almost half of the potential average daily peak reduction that the ideal controller with perfect knowledge would achieve."
  },
  {
    "date": "2026-02-09",
    "title": "An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture",
    "authors": "Roland Bertin-Johannet, Lara Scipio, Leopold Maytié, Rufin VanRullen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08597v1",
    "source": "arXiv",
    "abstract": "Global Workspace Theory (GWT), inspired by cognitive neuroscience, posits that flexible cognition could arise via the attentional selection of a relevant subset of modalities within a multimodal integration system. This cognitive framework can inspire novel computational architectures for multimodal integration. Indeed, recent implementations of GWT have explored its multimodal representation capabilities, but the related attention mechanisms remain understudied. Here, we propose and evaluate a top-down attention mechanism to select modalities inside a global workspace. First, we demonstrate that our attention mechanism improves noise robustness of a global workspace system on two multimodal datasets of increasing complexity: Simple Shapes and MM-IMDb 1.0. Second, we highlight various cross-task and cross-modality generalization capabilities that are not shared by multimodal attention models from the literature. Comparing against existing baselines on the MM-IMDb 1.0 benchmark, we find our attention mechanism makes the global workspace competitive with the state of the art."
  },
  {
    "date": "2026-02-09",
    "title": "Betti Numbers of Negatively Curved Orbifolds with Coefficients in Arbitrary Fields",
    "authors": "Guy Kapon, Raz Slutsky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08595v1",
    "source": "arXiv",
    "abstract": "We show that the Betti numbers of finite-volume negatively curved orbifolds grow at most linearly with the volume, with coefficients in an arbitrary field. In particular, this gives a linear bound for the Betti numbers of finite-volume hyperbolic orbifolds over $\\mathbb{F}_p$. This extends a theorem of Gromov from manifolds to orbifolds in negative curvature, and answers a question of Samet, by strengthening his theorem from characteristic $0$ to arbitrary characteristic. The key new input is a quantitative bound on the homology of spherical quotients."
  },
  {
    "date": "2026-02-09",
    "title": "TFMLinker: Universal Link Predictor by Graph In-Context Learning with Tabular Foundation Models",
    "authors": "Tianyin Liao, Chunyu Hu, Yicheng Sui, Xingxuan Zhang, Peng Cui, Jianxin Li, Ziwei Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08592v1",
    "source": "arXiv",
    "abstract": "Link prediction is a fundamental task in graph machine learning with widespread applications such as recommendation systems, drug discovery, knowledge graphs, etc. In the foundation model era, how to develop universal link prediction methods across datasets and domains becomes a key problem, with some initial attempts adopting Graph Foundation Models utilizing Graph Neural Networks and Large Language Models. However, the existing methods face notable limitations, including limited pre-training scale or heavy reliance on textual information. Motivated by the success of tabular foundation models (TFMs) in achieving universal prediction across diverse tabular datasets, we explore an alternative approach by TFMs, which are pre-trained on diverse synthetic datasets sampled from structural causal models and support strong in-context learning independent of textual attributes. Nevertheless, adapting TFMs for link prediction faces severe technical challenges such as how to obtain the necessary context and capture link-centric topological information. To solve these challenges, we propose TFMLinker (Tabular Foundation Model for Link Predictor), aiming to leverage the in-context learning capabilities of TFMs to perform link prediction across diverse graphs without requiring dataset-specific fine-tuning. Specifically, we first develop a prototype-augmented local-global context module to construct context that captures both graph-specific and cross-graph transferable patterns. Next, we design a universal topology-aware link encoder to capture link-centric topological information and generate link representations as inputs for the TFM. Finally, we employ the TFM to predict link existence through in-context learning. Experiments on 6 graph benchmarks across diverse domains demonstrate the superiority of our method over state-of-the-art baselines without requiring dataset-specific finetuning."
  },
  {
    "date": "2026-02-09",
    "title": "FairRARI: A Plug and Play Framework for Fairness-Aware PageRank",
    "authors": "Emmanouil Kariotakis, Aritra Konar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08589v1",
    "source": "arXiv",
    "abstract": "PageRank (PR) is a fundamental algorithm in graph machine learning tasks. Owing to the increasing importance of algorithmic fairness, we consider the problem of computing PR vectors subject to various group-fairness criteria based on sensitive attributes of the vertices. At present, principled algorithms for this problem are lacking - some cannot guarantee that a target fairness level is achieved, while others do not feature optimality guarantees. In order to overcome these shortcomings, we put forth a unified in-processing convex optimization framework, termed FairRARI, for tackling different group-fairness criteria in a ``plug and play'' fashion. Leveraging a variational formulation of PR, the framework computes fair PR vectors by solving a strongly convex optimization problem with fairness constraints, thereby ensuring that a target fairness level is achieved. We further introduce three different fairness criteria which can be efficiently tackled using FairRARI to compute fair PR vectors with the same asymptotic time-complexity as the original PR algorithm. Extensive experiments on real-world datasets showcase that FairRARI outperforms existing methods in terms of utility, while achieving the desired fairness levels across multiple vertex groups; thereby highlighting its effectiveness."
  },
  {
    "date": "2026-02-09",
    "title": "Orientation-driven route to an intrinsic insulating ferromagnetic state in manganite superlattices",
    "authors": "Priyanka Aggarwal, Kirill B. Agapev, Sagar Sarkar, Biplab Sanyal, Igor Di Marco, Fabrizio Cossu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08573v1",
    "source": "arXiv",
    "abstract": "Increasing precision in the growth of superlattices sparks hope in applications that may arise from engineering layered structures. Heterostructuring and functionalization of magnetic oxides have been very popular due to their versatility and readiness for integration in modern electronics. In this study, we provide yet another example of this phenomenology by predicting that an insulating ferromagnetic state can be realized in superlattices of LaMnO$_3$ and SrTiO$_3$ oriented along the (111) direction. In strike contrast with respect to other orientations, these properties are not of extrinsic origin but arise from the interplay of structural order, strain and quantum confinement. The bandgap is shown to be either direct and indirect, depending on the precise composition, which can be explained in terms of the geometrical properties of (111)-oriented bilayers of LaMnO$_3$. The electronic structure shows narrow bands indicating localized $e_g$ states for all the investigated superlattices. These features and the analysis of the inter-atomic magnetic coupling suggest that the investigated superlattices behave as a Kugel-Khomskii material, at least for the explored compositions. Our results provide not only a new route to an insulating ferromagnet, but also novel insight into the intricate interplay between lattice symmetry, Hubbard physics and Hund's coupling to be exploited in next-generation spintronic applications."
  },
  {
    "date": "2026-02-09",
    "title": "Precipitation induced recrystallisation (PIX) in a Ti-Fe-Mo bcc-superalloy driven by lattice misfit",
    "authors": "Neal M. Parkes, Kan Ma, Ben Poole, Chris Hardie, Alexander J. Knowles",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08572v1",
    "source": "arXiv",
    "abstract": "Beta-Ti bcc-superalloys, comprising an A2 beta-Ti matrix reinforced by ordered intermetallic B2 beta-prime-TiFe precipitates, exhibit an unusual recrystallisation that occurs with no externally applied strain (i.e. no thermomechanical processing). Thermal ageing at 750 degrees Celsius for 72 h results in refinement of the grain size from 364 um to 30 um. This grain refinement is driven by discontinuous precipitation of beta-prime-TiFe lamellae with the beta-Ti matrix from grain/phase boundaries, which is associated with significant misorientation and increased dislocation density, attributed as precipitation induced recrystallisation (PIX)."
  },
  {
    "date": "2026-02-09",
    "title": "Head-to-Head autonomous racing at the limits of handling in the A2RL challenge",
    "authors": "Simon Hoffmann, Simon Sagmeister, Tobias Betz, Joscha Bongard, Sascha Büttner, Dominic Ebner, Daniel Esser, Georg Jank, Sven Goblirsch, Alexander Langmann, Maximilian Leitenstern, Levent Ögretmen, Phillip Pitschi, Ann-Kathrin Schwehn, Cornelius Schröder, Marcel Weinmann, Frederik Werner, Boris Lohmann, Johannes Betz, Markus Lienkamp",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08571v1",
    "source": "arXiv",
    "abstract": "Autonomous racing presents a complex challenge involving multi-agent interactions between vehicles operating at the limit of performance and dynamics. As such, it provides a valuable research and testing environment for advancing autonomous driving technology and improving road safety. This article presents the algorithms and deployment strategies developed by the TUM Autonomous Motorsport team for the inaugural Abu Dhabi Autonomous Racing League (A2RL). We showcase how our software emulates human driving behavior, pushing the limits of vehicle handling and multi-vehicle interactions to win the A2RL. Finally, we highlight the key enablers of our success and share our most significant learnings."
  },
  {
    "date": "2026-02-09",
    "title": "Approximate Cartesian Tree Matching with Substitutions",
    "authors": "Panagiotis Charalampopoulos, Jonas Ellert, Manal Mohamed",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08570v1",
    "source": "arXiv",
    "abstract": "The Cartesian tree of a sequence captures the relative order of the sequence's elements. In recent years, Cartesian tree matching has attracted considerable attention, particularly due to its applications in time series analysis. Consider a text $T$ of length $n$ and a pattern $P$ of length $m$. In the exact Cartesian tree matching problem, the task is to find all length-$m$ fragments of $T$ whose Cartesian tree coincides with the Cartesian tree $CT(P)$ of the pattern. Although the exact version of the problem can be solved in linear time [Park et al., TCS 2020], it remains rather restrictive; for example, it is not robust to outliers in the pattern. To overcome this limitation, we consider the approximate setting, where the goal is to identify all fragments of $T$ that are close to some string whose Cartesian tree matches $CT(P)$. In this work, we quantify closeness via the widely used Hamming distance metric. For a given integer parameter $k>0$, we present an algorithm that computes all fragments of $T$ that are at Hamming distance at most $k$ from a string whose Cartesian tree matches $CT(P)$. Our algorithm runs in time $\\mathcal O(n \\sqrt{m} \\cdot k^{2.5})$ for $k \\leq m^{1/5}$ and in time $\\mathcal O(nk^5)$ for $k \\geq m^{1/5}$, thereby improving upon the state-of-the-art $\\mathcal O(nmk)$-time algorithm of Kim and Han [TCS 2025] in the regime $k = o(m^{1/4})$. On the way to our solution, we develop a toolbox of independent interest. First, we introduce a new notion of periodicity in Cartesian trees. Then, we lift multiple well-known combinatorial and algorithmic results for string matching and periodicity in strings to Cartesian tree matching and periodicity in Cartesian trees."
  },
  {
    "date": "2026-02-09",
    "title": "Stateless Yet Not Forgetful: Implicit Memory as a Hidden Channel in LLMs",
    "authors": "Ahmed Salem, Andrew Paverd, Sahar Abdelnabi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08563v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are commonly treated as stateless: once an interaction ends, no information is assumed to persist unless it is explicitly stored and re-supplied. We challenge this assumption by introducing implicit memory-the ability of a model to carry state across otherwise independent interactions by encoding information in its own outputs and later recovering it when those outputs are reintroduced as input. This mechanism does not require any explicit memory module, yet it creates a persistent information channel across inference requests. As a concrete demonstration, we introduce a new class of temporal backdoors, which we call time bombs. Unlike conventional backdoors that activate on a single trigger input, time bombs activate only after a sequence of interactions satisfies hidden conditions accumulated via implicit memory. We show that such behavior can be induced today through straightforward prompting or fine-tuning. Beyond this case study, we analyze broader implications of implicit memory, including covert inter-agent communication, benchmark contamination, targeted manipulation, and training-data poisoning. Finally, we discuss detection challenges and outline directions for stress-testing and evaluation, with the goal of anticipating and controlling future developments. To promote future research, we release code and data at: https://github.com/microsoft/implicitMemory."
  },
  {
    "date": "2026-02-09",
    "title": "DNS: Data-driven Nonlinear Smoother for Complex Model-free Process",
    "authors": "Fredrik Cumlin, Anubhab Ghosh, Saikat Chatterjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08560v1",
    "source": "arXiv",
    "abstract": "We propose data-driven nonlinear smoother (DNS) to estimate a hidden state sequence of a complex dynamical process from a noisy, linear measurement sequence. The dynamical process is model-free, that is, we do not have any knowledge of the nonlinear dynamics of the complex process. There is no state-transition model (STM) of the process available. The proposed DNS uses a recurrent architecture that helps to provide a closed-form posterior of the hidden state sequence given the measurement sequence. DNS learns in an unsupervised manner, meaning the training dataset consists of only measurement data and no state data. We demonstrate DNS using simulations for smoothing of several stochastic dynamical processes, including a benchmark Lorenz system. Experimental results show that the DNS is significantly better than a deep Kalman smoother (DKS) and an iterative data-driven nonlinear state estimation (iDANSE) smoother."
  },
  {
    "date": "2026-02-09",
    "title": "Global Rotation Equivariant Phase Modeling for Speech Enhancement with Deep Magnitude-Phase Interaction",
    "authors": "Chengzhong Wang, Andong Li, Dingding Yao, Junfeng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08556v1",
    "source": "arXiv",
    "abstract": "While deep learning has advanced speech enhancement (SE), effective phase modeling remains challenging, as conventional networks typically operate within a flat Euclidean feature space, which is not easy to model the underlying circular topology of the phase. To address this, we propose a manifold-aware magnitude-phase dual-stream framework that aligns the phase stream with its intrinsic circular geometry by enforcing Global Rotation Equivariance (GRE) characteristic. Specifically, we introduce a Magnitude-Phase Interactive Convolutional Module (MPICM) for modulus-based information exchange and a Hybrid-Attention Dual-FFN (HADF) bottleneck for unified feature fusion, both of which are designed to preserve GRE in the phase stream. Comprehensive evaluations are conducted across phase retrieval, denoising, dereverberation, and bandwidth extension tasks to validate the superiority of the proposed method over multiple advanced baselines. Notably, the proposed architecture reduces Phase Distance by over 20\\% in the phase retrieval task and improves PESQ by more than 0.1 in zero-shot cross-corpus denoising evaluations. The overall superiority is also established in universal SE tasks involving mixed distortions. Qualitative analysis further reveals that the learned phase features exhibit distinct periodic patterns, which are consistent with the intrinsic circular nature of the phase. The source code is available at https://github.com/wangchengzhong/RENet."
  },
  {
    "date": "2026-02-09",
    "title": "Three Lessons from Citizen-Centric Participatory AI Design",
    "authors": "Eike Schneiders, Sarah Kiden, Beining Zhang, Bruno Rafael Queiros Arcanjo, Zhaoxing Li, Ezhilarasi Periyathambi, Vahid Yazdanpanah, Sebastian Stein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08554v1",
    "source": "arXiv",
    "abstract": "This workshop paper examines challenges in designing agentic AI systems from a citizen-centric perspective. Drawing on three participatory workshops conducted in 2025 with members of the general public and cross-sector stakeholders, we explore how societal values and expectations shape visions of future AI agents. Using constructive design research methods, participants engaged in storytelling and lo-fi prototyping to reflect on potential community impacts. We identify three key challenges: enabling meaningful and sustained public engagement, establishing a shared language between experts and lay participants, and translating speculative participant input into implementable systems. We argue that reflexive, long-term participation is essential for responsible and actionable citizen-centric AI development."
  },
  {
    "date": "2026-02-09",
    "title": "Pressure induced electronic band evolution and observation of superconductivity in the Dirac semimetal ZrTe5",
    "authors": "Sanskar Mishra, Nagendra Singh, Vinod K. Gangwar, Rajan Walia, Jianping Sun, Genfu Chen, Dilip Bhoi, Sandip Chatterjee, Yoshiya Uwatoko, Jinguang Cheng, Prashant Shahi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08547v1",
    "source": "arXiv",
    "abstract": "We report a comprehensive investigation of the pressure effects on the magnetotransport properties of the topological material ZrTe5 within 1 to 8 GPa pressure range. With increasing pressure, the characteristic peak (Tp) in its electrical resistivity first shifts to higher temperature and then moves quickly towards the lower temperature before disappearing eventually at 6 GPa. Beyond 6 GPa, the system exhibits metallic behavior across the entire temperature range, and superconductivity emerges below Tc = 1.8 K at 8 GPa. Based on the systematic magnetotransport measurement under pressure, we demonstrate that the superconductivity occurs following a significant electronic structure modulation possibly due to pressure induced structural changes near 6 GPa, which coincides with dramatic enhancement of the magnetoresistance (MR) reaching up to 1400 percent. Our experimental results are substantiated by density functional theory calculations as the application of pressure drastically alters the density of states near the Fermi level. Notably, multiple hole pockets emerge at the Fermi level from 4 GPa onward, and their contributions are further enhanced with increasing pressure. The combined experimental and theoretical investigation reveals a comprehensive evolution of electronic structure of Dirac semimetal ZrTe5 under pressure and suggest a possible link between the Fermi surface reconstruction in the pressure range of structural transition and emergence of superconductivity"
  },
  {
    "date": "2026-02-09",
    "title": "Incremental (k, z)-Clustering on Graphs",
    "authors": "Emilio Cruciani, Sebastian Forster, Antonis Skarlatos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08542v1",
    "source": "arXiv",
    "abstract": "Given a weighted undirected graph, a number of clusters $k$, and an exponent $z$, the goal in the $(k, z)$-clustering problem on graphs is to select $k$ vertices as centers that minimize the sum of the distances raised to the power $z$ of each vertex to its closest center. In the dynamic setting, the graph is subject to adversarial edge updates, and the goal is to maintain explicitly an exact $(k, z)$-clustering solution in the induced shortest-path metric. While efficient dynamic $k$-center approximation algorithms on graphs exist [Cruciani et al. SODA 2024], to the best of our knowledge, no prior work provides similar results for the dynamic $(k,z)$-clustering problem. As the main result of this paper, we develop a randomized incremental $(k, z)$-clustering algorithm that maintains with high probability a constant-factor approximation in a graph undergoing edge insertions with a total update time of $\\tilde O(k m^{1+o(1)}+ k^{1+\\frac{1}λ} m)$, where $λ\\geq 1$ is an arbitrary fixed constant. Our incremental algorithm consists of two stages. In the first stage, we maintain a constant-factor bicriteria approximate solution of size $\\tilde{O}(k)$ with a total update time of $m^{1+o(1)}$ over all adversarial edge insertions. This first stage is an intricate adaptation of the bicriteria approximation algorithm by Mettu and Plaxton [Machine Learning 2004] to incremental graphs. One of our key technical results is that the radii in their algorithm can be assumed to be non-decreasing while the approximation ratio remains constant, a property that may be of independent interest. In the second stage, we maintain a constant-factor approximate $(k,z)$-clustering solution on a dynamic weighted instance induced by the bicriteria approximate solution. For this subproblem, we employ a dynamic spanner algorithm together with a static $(k,z)$-clustering algorithm."
  },
  {
    "date": "2026-02-09",
    "title": "Craig Interpolation in Program Verification",
    "authors": "Philipp Rümmer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08532v1",
    "source": "arXiv",
    "abstract": "Craig interpolation is used in program verification for automating key tasks such as the inference of loop invariants and the computation of program abstractions. This chapter covers some of the most important techniques that have been developed in this context over the last years, focusing on two aspects: the derivation of Craig interpolants modulo the theories and data types used in verification and the basic design of verification algorithms applying interpolation."
  },
  {
    "date": "2026-02-09",
    "title": "PIT: A Dynamic Personalized Item Tokenizer for End-to-End Generative Recommendation",
    "authors": "Huanjie Wang, Xinchen Luo, Honghui Bao, Zhang Zixing, Lejian Ren, Yunfan Wu, Hongwei Zhang, Liwei Guan, Guang Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08530v1",
    "source": "arXiv",
    "abstract": "Generative Recommendation has revolutionized recommender systems by reformulating retrieval as a sequence generation task over discrete item identifiers. Despite the progress, existing approaches typically rely on static, decoupled tokenization that ignores collaborative signals. While recent methods attempt to integrate collaborative signals into item identifiers either during index construction or through end-to-end modeling, they encounter significant challenges in real-world production environments. Specifically, the volatility of collaborative signals leads to unstable tokenization, and current end-to-end strategies often devolve into suboptimal two-stage training rather than achieving true co-evolution. To bridge this gap, we propose PIT, a dynamic Personalized Item Tokenizer framework for end-to-end generative recommendation, which employs a co-generative architecture that harmonizes collaborative patterns through collaborative signal alignment and synchronizes item tokenizer with generative recommender via a co-evolution learning. This enables the dynamic, joint, end-to-end evolution of both index construction and recommendation. Furthermore, a one-to-many beam index ensures scalability and robustness, facilitating seamless integration into large-scale industrial deployments. Extensive experiments on real-world datasets demonstrate that PIT consistently outperforms competitive baselines. In a large-scale deployment at Kuaishou, an online A/B test yielded a substantial 0.402% uplift in App Stay Time, validating the framework's effectiveness in dynamic industrial environments."
  },
  {
    "date": "2026-02-09",
    "title": "A light DM model for large $B \\to K + \\mbox{invisible}$ and $K \\to π+ \\mbox{invisible}$ decays and its implications for $B_s-\\bar B_s$ mixing and neutron EDM",
    "authors": "Xuan Hong, Xiao-Gang He, Ming-Wei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08523v1",
    "source": "arXiv",
    "abstract": "We present a light dark matter model with sizable invisible rare meson decays to accommodate possible larger than standard model (SM) predictions for both $B^+\\to K^+ν\\barν$ by Belle II and $K^+\\toπ^+ν\\bar ν$ by NA62. Since the emitted neutrinos are unobserved, the excesses may be due to light dark matter pairs in the final states. We show that it is possible to realize this by a UV-complete model based on a two Higgs doublet model. The neutral spin-zero Higgs bosons (scalar or pseudoscalar) mediating dark matter interaction, can also produce some effects at low energies which modify the SM predictions significantly. In particular we find large testable consequences for $B_s - \\bar B_s$ mixing due to splitting of scalar and pseudoscalar masses, and also neutron EDM. We find that there is a cancellation due to exchange of neutral spin-zero particle for neutron EDM in general, but QCD running will lift this cancellation.This is generally true for any neutral Higgs contributions. However, we find that such a cancellation does not happen for charged scalar contribution. The allowed CP violating phase in the Yukawa sector can produce a neutron EDM experimental bound."
  },
  {
    "date": "2026-02-09",
    "title": "Reinforcement Inference: Leveraging Uncertainty for Self-Correcting Language Model Reasoning",
    "authors": "Xinhai Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08520v1",
    "source": "arXiv",
    "abstract": "Modern large language models (LLMs) are often evaluated and deployed under a \\emph{one-shot, greedy} inference protocol, especially in professional settings that require deterministic behavior. This regime can systematically under-estimate a fixed model's true capability: many errors arise not from missing knowledge, but from premature commitment under internal ambiguity. We introduce \\emph{Reinforcement Inference}, an entropy-aware inference-time control strategy that uses the model's own uncertainty to selectively invoke a second, more deliberate reasoning attempt, enabling stronger performance \\emph{without any retraining}. On 12,032 MMLU-Pro questions across 14 subjects, using DeepSeek-v3.2 with deterministic decoding in a zero-shot setting, Reinforcement Inference improves accuracy from 60.72\\% to 84.03\\%, while only incurring 61.06\\% additional inference calls. A 100\\% re-asking ablation reaches 84.35\\%, indicating that uncertainty-aware selection captures most of the attainable improvement with substantially less compute. Moreover, a \\emph{prompt-only} ablation underperforms the baseline, suggesting that the gains are not explained by generic `` your output had high entropy, think step-by-step'' prompting alone. Beyond providing a practical inference-time upgrade, our results suggest a broader \\emph{entropy-aware} paradigm for measuring and expanding model capability: because modern decoder-based models generate outputs autoregressively, entropy and related confidence measures arise naturally as first-class control signals during generation. The resulting gap between one-pass greedy inference and uncertainty-conditioned deliberation offers a diagnostic lens on an LLM's latent reasoning horizon and motivates future training objectives that explicitly constrain correctness--confidence alignment."
  },
  {
    "date": "2026-02-09",
    "title": "Do physics-informed neural networks (PINNs) need to be deep? Shallow PINNs using the Levenberg-Marquardt algorithm",
    "authors": "Muhammad Luthfi Shahab, Imam Mukhlash, Hadi Susanto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08515v1",
    "source": "arXiv",
    "abstract": "This work investigates the use of shallow physics-informed neural networks (PINNs) for solving forward and inverse problems of nonlinear partial differential equations (PDEs). By reformulating PINNs as nonlinear systems, the Levenberg-Marquardt (LM) algorithm is employed to efficiently optimize the network parameters. Analytical expressions for the neural network derivatives with respect to the input variables are derived, enabling accurate and efficient computation of the Jacobian matrix required by LM. The proposed approach is tested on several benchmark problems, including the Burgers, Schrödinger, Allen-Cahn, and three-dimensional Bratu equations. Numerical results demonstrate that LM significantly outperforms BFGS in terms of convergence speed, accuracy, and final loss values, even when using shallow network architectures with only two hidden layers. These findings indicate that, for a wide class of PDEs, shallow PINNs combined with efficient second-order optimization methods can provide accurate and computationally efficient solutions for both forward and inverse problems."
  },
  {
    "date": "2026-02-09",
    "title": "A Machine Learning Enabled MDO for Bio-Inspired Autonomous Underwater Gliders",
    "authors": "Andrea Serani, Giorgio Palma, Jeroen Wackers, Matteo Diez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08508v1",
    "source": "arXiv",
    "abstract": "The preliminary design of AUGs is intrinsically challenging due to the strong coupling between the external hydrodynamic shape, the hydrostatic balance, the structural integrity, and internal packaging constraints. This complexity is further amplified for bio-inspired configurations, whose rich geometric parametrizations lead to high-dimensional design spaces that are difficult to explore using conventional optimization approaches. This work presents a ML-enabled bi-level multidisciplinary design optimization (MDO) framework for the performance-driven design of a manta-ray-inspired AUG. At the upper level, hydrodynamically efficient external geometries are explored in a reduced design space obtained through physics-driven parametric model embedding, which identifies a low-dimensional latent representation directly correlated with the lift, drag, and pressure distributions. At the lower level, a constrained internal sizing problem determines the minimum feasible empty weight by accounting for structural, hydrostatic, geometric, and payload constraints. To render the resulting bi-level problem computationally tractable, a multi-fidelity surrogate-based optimization strategy is adopted, combining low- and high-fidelity hydrodynamic models with stochastic radial basis function surrogates and adaptive Bayesian sampling. The framework enables efficient exploration of the coupled design space while rigorously managing model uncertainty and computational cost. The optimized configurations exhibit a 14.7\\% improvement in maximum hydrodynamic efficiency and a 12.8\\% reduction in empty weight relative to the baseline design, while satisfying all disciplinary constraints. These results demonstrate that the integration of physics-driven dimensionality reduction and multi-fidelity machine learning enables scalable and physically consistent MDO of complex bio-inspired underwater vehicles."
  },
  {
    "date": "2026-02-09",
    "title": "Mellin-Space Prony Representability of Linear Viscoelastic Models",
    "authors": "Dimiter Prodanov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08506v1",
    "source": "arXiv",
    "abstract": "Linear viscoelasticity is universally described by relaxation functions, which are continuous in relaxation times. Yet experimentally, measurements are necessarily discrete and band-limited, creating a fundamental gap between the continuous mathematical description and empirical observations. While Laplace-domain rational moduli admit finite Prony representations, using Mellin space analysis requires a deeper structural criterion. This work proves that finite Prony series representation holds if and only if the arithmetic pole lattices of Gamma factors in the Mellin transform of the complex modulus align exactly with those of a trial kernel, with residues satisfying decoupled first-order recurrences along aligned sublattices. This maximal criterion classifies classical models (Maxwell, standard linear solid) as finitely representable and fractional models (power-law, Cole--Cole, Zener, Gaussian) as transcendentally representable via infinite Prony ladders, yielding a complete analytical pole-lattice taxonomy of viscoelastic material models."
  },
  {
    "date": "2026-02-09",
    "title": "Giant Magnetocaloric Effect in a High-Spin Shastry-Sutherland Dipolar Magnet",
    "authors": "Jianjian Gong, Junsen Wang, Junsen Xiang, Zhaojun Mo, Lei Zhang, Xinyang Liu, Xuetong He, Lu Tian, Zhixing Ye, Huicai Xie, Xucai Kan, Xinqiang Gao, Zhenxing Li, Peijie Sun, Shouguo Wang, Wei Li, Baogen Shen, Jun Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08497v1",
    "source": "arXiv",
    "abstract": "The Shastry-Sutherland lattice is a prototypical frustrated quantum magnet. It is notable for its exactly solvable dimer-singlet ground state and hosts a wealth of magnetic phenomena under external fields. Here, this work investigates the high-spin (S = 7/2) Eu-based magnet Eu2MgSi2O7 (EMSO) using low-temperature magnetothermal measurements and Monte Carlo simulations, revealing a giant magnetocaloric effect (MCE) in this Shastry-Sutherland compound. The entropy change peak value is found to be 55.0 J kg-1 K-1 under a field change of B = 0-4 T, approximately 1.5 times larger than the commercial Gd3Ga5O12 (GGG). Adiabatic demagnetization refrigeration achieves a lowest temperature of 151 mK, deeply into the sub-Kelvin regime. Furthermore, a distinctive cooling effect persists below about 1 T, a characteristic absent for conventional magnetic coolants. A dipolar Shastry-Sutherland model is introduced as a minimal model to describe this system; in particular, the experimentally revealed 1/3 magnetization pseudo-plateau can be ascribed to the presence of dipolar couplings between Eu2+ ions, further stabilized by the thermal fluctuations, explaining the persistent cooling effect. This work establishes EMSO as a novel platform for exploring the dipolar Shastry-Sutherland system and for sub-Kelvin adiabatic demagnetization refrigeration."
  },
  {
    "date": "2026-02-09",
    "title": "The Banach-Tarski paradox in complete discretely valued fields",
    "authors": "Kamil Orzechowski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08494v1",
    "source": "arXiv",
    "abstract": "We prove some results related to the classical Banach--Tarski paradox in the setting of a field $\\mathbb{K}$ that is complete with respect to a discrete non-Archimedean valuation (e.g., when $\\mathbb{K}$ is the field $\\mathbb{Q}_p$ of $p$-adic numbers for a prime $p$). Namely, the field $\\mathbb{K}$, as well as all balls and spheres in $\\mathbb{K}$, admit a paradoxical decomposition with respect to the isometry group of $\\mathbb{K}$. Such decompositions can be realized using pieces with the Baire property if $\\mathbb{K}$ is separable. Under the additional assumption of local compactness of $\\mathbb{K}$ (e.g., when $\\mathbb{K}=\\mathbb{Q}_p$), any two bounded subsets of $\\mathbb{K}$ with nonempty interiors are equidecomposable with respect to the isometry group of $\\mathbb{K}$. Our results complete the study of paradoxical decompositions in the non-Archimedean setting, addressing the one-dimensional case and building on earlier work for higher-dimensional normed spaces over $\\mathbb{K}$ with respect to groups of affine isometries."
  },
  {
    "date": "2026-02-09",
    "title": "Enhanced Food Category Recognition under Illumination-Induced Domain Shift",
    "authors": "Keonvin Park, Aditya Pal, Jin Hong Mok",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08491v1",
    "source": "arXiv",
    "abstract": "Visual food recognition systems deployed in real-world environments, such as automated conveyor-belt inspection, are highly sensitive to domain shifts caused by illumination changes. While recent studies have shown that lighting variations can significantly distort food perception by both humans and AI, existing works are often limited to single food categories or controlled settings, and most public food datasets lack explicit illumination annotations. In this work, we investigate illumination-induced domain shift in multi-class food category recognition using two widely adopted datasets, Food-101 and Fruits-360. We demonstrate substantial accuracy degradation under cross-dataset evaluation due to mismatched visual conditions. To address this challenge, we construct synthetic illumination-augmented datasets by systematically varying light temperature and intensity, enabling controlled robustness analysis without additional labels. We further evaluate cross-dataset transfer learning and domain generalization, with a focus on illumination-sensitive target categories such as apple-based classes. Experimental results show that illumination-aware augmentation significantly improves recognition robustness under domain shift while preserving real-time performance. Our findings highlight the importance of illumination robustness and provide practical insights for deploying reliable food recognition systems in real-world inspection scenarios."
  },
  {
    "date": "2026-02-09",
    "title": "Construction of two-bubble solutions for the energy-critical Hartree equation",
    "authors": "Jacek Jendrej, Xuemei Li, Guixiang Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08490v1",
    "source": "arXiv",
    "abstract": "We construct a pure two-bubble solution for the focusing, energy-critical Hartree equation in space dimension $N \\geq 7$. The constructed solution is spherically symmetric, global in (at least) the negative time direction and asymptotically behaves as a superposition of two ground states (or bubbles) both centered at the origin, with the ratio of their length scales converging to $0$ and the phases of the two bubbles form the right angle. The main arguments are the modulation analysis, the bootstrap argument and the topological argument. The main novelty with respect to existing constructions of pure two-bubble solutions is the nonlocal interaction, which is more complex to analyze."
  },
  {
    "date": "2026-02-09",
    "title": "Beyond Correctness: Learning Robust Reasoning via Transfer",
    "authors": "Hyunseok Lee, Soheil Abbasloo, Jihoon Tack, Jinwoo Shin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08489v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently strengthened LLM reasoning, but its focus on final answer correctness leaves a critical gap: it does not ensure the robustness of the reasoning process itself. We adopt a simple philosophical view, robust reasoning should remain useful beyond the mind that produced it, and treat reasoning as a form of meaning transfer that must survive truncation, reinterpretation, and continuation. Building on this principle, we introduce Reinforcement Learning with Transferable Reward (RLTR), which operationalizes robustness via transfer reward that tests whether a partial reasoning prefix from one model can guide a separate model to the correct answer. This encourages LLMs to produce reasoning that is stable, interpretable, and genuinely generalizable. Our approach improves sampling consistency while improving final answer accuracy, and it reaches comparable performance in substantially fewer training steps. For example, on MATH500, RLTR achieves a +3.6%p gain in Maj@64 compared to RLVR and matches RLVR's average accuracy with roughly 2.5x fewer training steps, providing both more reliable reasoning and significantly more sample efficient."
  },
  {
    "date": "2026-02-09",
    "title": "On the Existence of Steady States for Blended Gas Flow with Non-Constant Compressibility Factor on Networks",
    "authors": "Simone Göttlich, Michael Schuster, Alena Ulke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08481v1",
    "source": "arXiv",
    "abstract": "In this paper, we study hydrogen-natural gas mixtures transported through pipeline networks. The flow is modeled by the isothermal Euler equations with a pressure law involving a non-constant, composition-dependent compressibility factor. For a broad class of such compressibility models, we prove the existence of steady-state solutions on networks containing compressor stations. The analysis is based on an implicit representation of the pressure profiles and a continuity argument that overcomes the discontinuous dependence of the gas composition on the flow direction. Numerical examples illustrate the influence of different compressibility models on the resulting states."
  },
  {
    "date": "2026-02-09",
    "title": "Some notes on tensor triangular geometry",
    "authors": "Greg Stevenson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08480v1",
    "source": "arXiv",
    "abstract": "These are notes from the lectures I gave at the Oberwolfach seminar `Tensor Triangular Geometry and Interactions' which was held in October 2025. The aim of these notes is to give an introduction to tensor triangular geometry, for both small and large categories, through the lens of lattice theory. We do not try to be exhaustive and this is reflected in both the content and the bibliography. For instance we are quite light on triangulated preliminaries, especially for compactly generated categories. The first three sections treat the essentially small case and conclude with a tensor triangular proof of Thomason's theorem computing the spectrum of the perfect complexes on a quasi-compact and quasi-separated scheme. The last section treats the compactly generated case. This final section is somewhat experimental and contains some new thoughts."
  },
  {
    "date": "2026-02-09",
    "title": "Gesture Matters: Pedestrian Gesture Recognition for AVs Through Skeleton Pose Evaluation",
    "authors": "Alif Rizqullah Mahdi, Mahdi Rezaei, Natasha Merat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08479v1",
    "source": "arXiv",
    "abstract": "Gestures are a key component of non-verbal communication in traffic, often helping pedestrian-to-driver interactions when formal traffic rules may be insufficient. This problem becomes more apparent when autonomous vehicles (AVs) struggle to interpret such gestures. In this study, we present a gesture classification framework using 2D pose estimation applied to real-world video sequences from the WIVW dataset. We categorise gestures into four primary classes (Stop, Go, Thank & Greet, and No Gesture) and extract 76 static and dynamic features from normalised keypoints. Our analysis demonstrates that hand position and movement velocity are especially discriminative in distinguishing between gesture classes, achieving a classification accuracy score of 87%. These findings not only improve the perceptual capabilities of AV systems but also contribute to the broader understanding of pedestrian behaviour in traffic contexts."
  },
  {
    "date": "2026-02-09",
    "title": "A Multi-physics Simulation Framework for High-power Microwave Counter-unmanned Aerial System Design and Performance Evaluation",
    "authors": "Akbar Anbar Jafari, Gholamreza Anbarjafari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08477v1",
    "source": "arXiv",
    "abstract": "The proliferation of small unmanned aerial systems (sUAS) operating under autonomous guidance has created an urgent need for non-kinetic neutralization methods that are immune to conventional radio-frequency jamming. This paper presents a comprehensive multi-physics simulation framework for the design and performance evaluation of a high-power microwave (HPM) counter-UAS system operating at 2.45\\,GHz. The framework integrates electromagnetic propagation modelling, antenna pattern analysis, electromagnetic coupling to unshielded drone wiring harnesses, and a sigmoid-based semiconductor damage probability model calibrated to published CMOS latchup thresholds. A 10{,}000-trial Monte Carlo analysis incorporating stochastic variations in transmitter power, antenna pointing error, target wire orientation, polarization mismatch, and component damage thresholds yields system-level kill probabilities with 95\\% confidence intervals. For a baseline configuration of 25\\,kW continuous-wave power and a 60\\,cm parabolic reflector (21.2\\,dBi gain), the Monte Carlo simulation predicts a kill probability of $51.4\\pm1.0$\\% at 20\\,m, decreasing to $13.1\\pm0.7$\\% at 40\\,m. Pulsed operation at 500\\,kW peak power (1\\% duty cycle) extends the 90\\% kill range from approximately 18\\,m to 88\\,m. The framework further provides parametric design maps, safety exclusion zone calculations compliant with ICNIRP 2020 guidelines, thermal management requirements, and waveguide mode analysis. All simulation codes and results are provided for full reproducibility."
  },
  {
    "date": "2026-02-09",
    "title": "GaLactic and Extragalactic All-sky Murchison Widefield Array survey eXtended (GLEAM-X) III: Galactic Plane",
    "authors": "S. Mantovanini, N. Hurley-Walker, K. Ross, S. W. Duchesne, G. Anderson, T. J. Galvin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08475v1",
    "source": "arXiv",
    "abstract": "We present the third data release for the Galactic and Extragalactic All-Sky Murchison Widefield Array eXtended (GLEAM-X) survey, covering = 3800 deg2 of the southern Galactic Plane (GP) with \\ang{233} < l < \\ang{44} and |b| < \\ang{11} across a frequency range of 72 - 231 MHz divided into 20 sub-bands. GLEAM-X observations were taken using the \"extended\" Phase-II configuration of the Murchison Widefield Array (MWA), which features baselines ranging from approximately 12 m to 5 km. This configuration limits sensitivity to the diffuse structure of the GP, with an angular resolution range of about 45'' to 2'. To achieve lower noise levels while being sensitive to a wide range of spatial scales (45''- \\ang{15}), we combined these observations with the previous Galactic and Extragalactic All-Sky Murchison Widefield Array (GLEAM) survey. For the area covered, we provide images spanning the whole frequency range. A wide-band image over 170 - 231 MHz, with RMS noise of = 3 - 6 mJy/beam and source position accuracy within 1 arcseconds, is then used to perform source-finding, which yields 98,207 elements measured across 20 x 7.68 MHz frequency bands. The catalogue is 90% complete at 50 mJy within \\ang{233} < l < \\ang{324} and at 125 mJy in \\ang{290} < l < \\ang{44}, while it is 99.3% reliable overall. All the images and the catalogue are available online for download."
  },
  {
    "date": "2026-02-09",
    "title": "Low Rank Transformer for Multivariate Time Series Anomaly Detection and Localization",
    "authors": "Charalampos Shimillas, Kleanthis Malialis, Konstantinos Fokianos, Marios M. Polycarpou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08467v1",
    "source": "arXiv",
    "abstract": "Multivariate time series (MTS) anomaly diagnosis, which encompasses both anomaly detection and localization, is critical for the safety and reliability of complex, large-scale real-world systems. The vast majority of existing anomaly diagnosis methods offer limited theoretical insights, especially for anomaly localization, which is a vital but largely unexplored area. The aim of this contribution is to study the learning process of a Transformer when applied to MTS by revealing connections to statistical time series methods. Based on these theoretical insights, we propose the Attention Low-Rank Transformer (ALoRa-T) model, which applies low-rank regularization to self-attention, and we introduce the Attention Low-Rank score, effectively capturing the temporal characteristics of anomalies. Finally, to enable anomaly localization, we propose the ALoRa-Loc method, a novel approach that associates anomalies to specific variables by quantifying interrelationships among time series. Extensive experiments and real data analysis, show that the proposed methodology significantly outperforms state-of-the-art methods in both detection and localization tasks."
  },
  {
    "date": "2026-02-09",
    "title": "Reliability-aware Execution Gating for Near-field and Off-axis Vision-guided Robotic Alignment",
    "authors": "Ning Hu, Senhao Cao, Maochen Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08466v1",
    "source": "arXiv",
    "abstract": "Vision-guided robotic systems are increasingly deployed in precision alignment tasks that require reliable execution under near-field and off-axis configurations. While recent advances in pose estimation have significantly improved numerical accuracy, practical robotic systems still suffer from frequent execution failures even when pose estimates appear accurate. This gap suggests that pose accuracy alone is insufficient to guarantee execution-level reliability. In this paper, we reveal that such failures arise from a deterministic geometric error amplification mechanism, in which small pose estimation errors are magnified through system structure and motion execution, leading to unstable or failed alignment. Rather than modifying pose estimation algorithms, we propose a Reliability-aware Execution Gating mechanism that operates at the execution level. The proposed approach evaluates geometric consistency and configuration risk before execution, and selectively rejects or scales high-risk pose updates. We validate the proposed method on a real UR5 robotic platform performing single-step visual alignment tasks under varying camera-target distances and off-axis configurations. Experimental results demonstrate that the proposed execution gating significantly improves task success rates, reduces execution variance, and suppresses tail-risk behavior, while leaving average pose accuracy largely unchanged. Importantly, the proposed mechanism is estimator-agnostic and can be readily integrated with both classical geometry-based and learning-based pose estimation pipelines. These results highlight the importance of execution-level reliability modeling and provide a practical solution for improving robustness in near-field vision-guided robotic systems."
  },
  {
    "date": "2026-02-09",
    "title": "Estimating Aleatoric Uncertainty in the Causal Treatment Effect",
    "authors": "Liyuan Xu, Bijan Mazaheri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08461v1",
    "source": "arXiv",
    "abstract": "Previous work on causal inference has primarily focused on averages and conditional averages of treatment effects, with significantly less attention on variability and uncertainty in individual treatment responses. In this paper, we introduce the variance of the treatment effect (VTE) and conditional variance of treatment effect (CVTE) as the natural measure of aleatoric uncertainty inherent in treatment responses, and we demonstrate that these quantities are identifiable from observed data under mild assumptions, even in the presence of unobserved confounders. We further propose nonparametric kernel-based estimators for VTE and CVTE, and our theoretical analysis establishes their convergence. We also test the performance of our method through extensive empirical experiments on both synthetic and semi-simulated datasets, where it demonstrates superior or comparable performance to naive baselines."
  },
  {
    "date": "2026-02-09",
    "title": "Hybrid Pooling with LLMs via Relevance Context Learning",
    "authors": "David Otero, Javier Parapar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08457v1",
    "source": "arXiv",
    "abstract": "High-quality relevance judgements over large query sets are essential for evaluating Information Retrieval (IR) systems, yet manual annotation remains costly and time-consuming. Large Language Models (LLMs) have recently shown promise as automatic relevance assessors, but their reliability is still limited. Most existing approaches rely on zero-shot prompting or In-Context Learning (ICL) with a small number of labeled examples. However, standard ICL treats examples as independent instances and fails to explicitly capture the underlying relevance criteria of a topic, restricting its ability to generalize to unseen query-document pairs. To address this limitation, we introduce Relevance Context Learning (RCL), a novel framework that leverages human relevance judgements to explicitly model topic-specific relevance criteria. Rather than directly using labeled examples for in-context prediction, RCL first prompts an LLM (Instructor LLM) to analyze sets of judged query-document pairs and generate explicit narratives that describe what constitutes relevance for a given topic. These relevance narratives are then used as structured prompts to guide a second LLM (Assessor LLM) in producing relevance judgements. To evaluate RCL in a realistic data collection setting, we propose a hybrid pooling strategy in which a shallow depth-\\textit{k} pool from participating systems is judged by human assessors, while the remaining documents are labeled by LLMs. Experimental results demonstrate that RCL substantially outperforms zero-shot prompting and consistently improves over standard ICL. Overall, our findings indicate that transforming relevance examples into explicit, context-aware relevance narratives is a more effective way of exploiting human judgements for LLM-based IR dataset construction."
  },
  {
    "date": "2026-02-09",
    "title": "Modeling Concurrent Multi-Agent Systems",
    "authors": "Senthil Rajasekaran, Moshe Y. Vardi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08452v1",
    "source": "arXiv",
    "abstract": "Recent work in the field of multi-agent systems has sought to use techniques and concepts from the field of formal methods to provide rigorous theoretical analysis and guarantees on complex systems where multiple agents strategically interact, leading to the creation of the field of equilibrium analysis, which studies equilibria concepts from the field of game theory through a complexity-theoretic lens. Multi-agent systems, however, are complex mathematical objects, and, therefore, defining them in a precise mathematical manner is non-trivial. As a result, researchers often considered more restrictive models that are easier to model but lack expressive power or simply omit critical complexity-theoretic results in their analysis. This paper addresses this problem by carefully analyzing and contrasting complexity-theoretic results in the explicit model, a mathematically precise formulation of the models commonly used in the literature, and the circuit-based model, a novel model that addresses the problems found in the literature. The utility of the circuit-based model is demonstrated through a comprehensive analysis that considers upper and lower bounds for the realizability and verification problems, the two most important decision problems in equilibrium analysis, for both models. By conducting this analysis, we see that problematic issues that are endemic to the explicit model and the equilibrium analysis literature as a whole are adequately handled by the circuit-based model."
  },
  {
    "date": "2026-02-09",
    "title": "Vista: Scene-Aware Optimization for Streaming Video Question Answering under Post-Hoc Queries",
    "authors": "Haocheng Lu, Nan Zhang, Wei Tao, Xiaoyang Qu, Guokuan Li, Jiguang Wan, Jianzong Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08448v1",
    "source": "arXiv",
    "abstract": "Streaming video question answering (Streaming Video QA) poses distinct challenges for multimodal large language models (MLLMs), as video frames arrive sequentially and user queries can be issued at arbitrary time points. Existing solutions relying on fixed-size memory or naive compression often suffer from context loss or memory overflow, limiting their effectiveness in long-form, real-time scenarios. We present Vista, a novel framework for scene-aware streaming video QA that enables efficient and scalable reasoning over continuous video streams. The innovation of Vista can be summarized in three aspects: (1) scene-aware segmentation, where Vista dynamically clusters incoming frames into temporally and visually coherent scene units; (2) scene-aware compression, where each scene is compressed into a compact token representation and stored in GPU memory for efficient index-based retrieval, while full-resolution frames are offloaded to CPU memory; and (3) scene-aware recall, where relevant scenes are selectively recalled and reintegrated into the model input upon receiving a query, enabling both efficiency and completeness. Vista is model-agnostic and integrates seamlessly with a variety of vision-language backbones, enabling long-context reasoning without compromising latency or memory efficiency. Extensive experiments on StreamingBench demonstrate that Vista achieves state-of-the-art performance, establishing a strong baseline for real-world streaming video understanding."
  },
  {
    "date": "2026-02-09",
    "title": "Stratification of the AGN-Driven multi-phase outflows in the dwarf Seyfert galaxy NGC 4395",
    "authors": "Payel Nandi, Luis Colina, Rogemar A. Riffel, Miguel Pereira Santaella, C. S. Stalin, D. J. Saikia, Javier Alvarez-Marquez, Markus Kissler-Patig",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08447v1",
    "source": "arXiv",
    "abstract": "We present a multi-wavelength study of nuclear outflows in the nearby dwarf Seyfert galaxy NGC~4395, which hosts an intermediate-mass black hole. Using \\textit{JWST}/NIRSpec and MIRI IFU spectroscopy (1.66--28.6~$μ$m), together with ALMA and Gemini/GMOS data, we probe the ionised and molecular gas on parsec scales. The JWST nuclear spectra reveal 134 emission lines, including H\\,\\textsc{i}, He, numerous fine-structure lines, H$_2$ rotational/ro-vibrational transitions, and several PAH bands. Modelling of the H$_2$ rotational lines reveals three warm/hot molecular components ($T\\!\\approx\\!580$, 1480, and 2900~K), along with a cold ($<50$~K) phase traced by ALMA CO(2--1). Outflow signatures are detected in cold and warm/hot molecular gas, in H\\,\\textsc{i}, and in 36 fine-structure lines spanning ionisation potentials of 7.6--300~eV. Ionised outflow velocities range from 127 to 716~km\\,s$^{-1}$, with blueshifted and redshifted components consistent with a stratified biconical geometry. The cold molecular gas shows a mass outflow rate nearly 1--2 orders of magnitude larger than that of the warm/hot molecular and ionised phases. The kinetic coupling efficiency is 0.003--0.12\\% for the coronal-line gas and 0.4--1.4\\% for the H\\,\\textsc{i} outflow, indicating that only the low-ionisation gas significantly impacts the surrounding ISM. Outflow velocity and the fraction of flux in the outflowing component increase with ionisation potential, implying that the most highly ionised gas originates closest to the AGN and is most efficiently accelerated."
  },
  {
    "date": "2026-02-09",
    "title": "Azimuthally polarized terahertz radiation generation using radially polarized laser pulse in magnetized plasma",
    "authors": "Shivani Aggarwal, Dinkar Mishra, Saumya Singh, Bhupesh Kumar, Pallavi Jha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08438v1",
    "source": "arXiv",
    "abstract": "An analytical formulation of a radially polarized laser pulse propagating in a homogeneous, magnetized plasma is presented using Lorentz force, continuity and Maxwells equations. Perturbation technique and quasi-static approximation (QSA) have been used to study the generated fields in nonlinear regime. The generated slow, oscillating, transverse electric and magnetic fields having equal amplitude, constitute a radiation field having frequency in the terahertz (THz) range. Particle-in-cell (PIC) simulation code FBPIC is used to validate analytical findings. Simulation studies also show that the generated THz radiation field propagates beyond the plasma boundary, indicating coherent electromagnetic radiation emission. Furthermore, the field amplitude scales nonlinearly with plasma density and increases linearly with external magnetic field strength, highlighting the role of these parameters in controlling radiation amplitude."
  },
  {
    "date": "2026-02-09",
    "title": "CSPR-Net: Self-supervised Curved Surface Projection Rectification Network for Geometric Distortion Correction in Non-planar Projections",
    "authors": "Kejin Peng, Jia Wei, Xiang Hao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08433v1",
    "source": "arXiv",
    "abstract": "Projecting images onto non-planar surfaces inevitably introduces geometric distortions that degrade visual quality. Traditional correction methods often require tedious manual calibration or structured light sequences to establish pixel-wise correspondences. In this paper, we develop the Curved Surface Projection Rectification Network (CSPR-Net), a self-supervised deep learning framework for automated distortion correction. Our approach employs dual coordinate-based neural networks to learn the bi-directional mapping between the projector and camera spaces. By enforcing a robust cycle-consistency constraint, CSPR-Net autonomously resolves complex geometric transformations without requiring ground-truth deformation fields. Furthermore, a gradient-based loss function is introduced to mitigate the impact of complex ambient light interference and accurately capture high-frequency geometric variations. Quantitative evaluations in physical experimental scenarios demonstrate that CSPR-Net achieves a 20.7% improvement in end-to-end fidelity (SSIM) and outperforms the polynomial baseline by 3.8% and 5.4% in forward and inverse mapping in terms of SSIM respectively, effectively generating high-precision pre-warped images for seamless projection."
  },
  {
    "date": "2026-02-09",
    "title": "Understanding and Optimizing Attention-Based Sparse Matching for Diverse Local Features",
    "authors": "Qiang Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08430v1",
    "source": "arXiv",
    "abstract": "We revisit the problem of training attention-based sparse image matching models for various local features. We first identify one critical design choice that has been previously overlooked, which significantly impacts the performance of the LightGlue model. We then investigate the role of detectors and descriptors within the transformer-based matching framework, finding that detectors, rather than descriptors, are often the primary cause for performance difference. Finally, we propose a novel approach to fine-tune existing image matching models using keypoints from a diverse set of detectors, resulting in a universal, detector-agnostic model. When deployed as a zero-shot matcher for novel detectors, the resulting model achieves or exceeds the accuracy of models specifically trained for those features. Our findings offer valuable insights for the deployment of transformer-based matching models and the future design of local features."
  },
  {
    "date": "2026-02-09",
    "title": "Analysis of the Hopfield Model Incorporating the Effects of Unlearning",
    "authors": "Shuta Takeuchi, Takashi Takahashi, Yoshiyuki Kabashima",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08428v1",
    "source": "arXiv",
    "abstract": "We analyze a variant of the Hopfield model that incorporates an unlearning mechanism based on spin correlations in the high-temperature regime. In the large system limit where extensively many patterns are stored, we employ the replica method under the replica symmetric ansatz to characterize the model analytically. Our analysis provides a systematic and self-consistent framework that yields order-parameter equations and stability conditions at finite temperatures over a wide range of parameter settings. The resulting theory accurately captures the behavior of the signal-to-noise ratio, the memory capacity, and the criteria for selecting optimal hyperparameters, in agreement with the qualitative findings of Nokura (1996 \\textit{J. Phys. A: Math. Gen.} \\textbf{29} 3871). Moreover, the theoretical predictions show good agreement with numerical simulations, supporting the conclusion that unlearning enhances memory capacity by suppressing spurious memories."
  },
  {
    "date": "2026-02-09",
    "title": "Prism: Spectral-Aware Block-Sparse Attention",
    "authors": "Xinghao Wang, Pengyu Wang, Xiaoran Liu, Fangxu Liu, Jason Chu, Kai Song, Xipeng Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08426v1",
    "source": "arXiv",
    "abstract": "Block-sparse attention is promising for accelerating long-context LLM pre-filling, yet identifying relevant blocks efficiently remains a bottleneck. Existing methods typically employ coarse-grained attention as a proxy for block importance estimation, but often resort to expensive token-level searching or scoring, resulting in significant selection overhead. In this work, we trace the inaccuracy of standard coarse-grained attention via mean pooling to a theoretical root cause: the interaction between mean pooling and Rotary Positional Embeddings (RoPE). We prove that mean pooling acts as a low-pass filter that induces destructive interference in high-frequency dimensions, effectively creating a \"blind spot\" for local positional information (e.g., slash patterns). To address this, we introduce Prism, a training-free spectral-aware approach that decomposes block selection into high-frequency and low-frequency branches. By applying energy-based temperature calibration, Prism restores the attenuated positional signals directly from pooled representations, enabling block importance estimation using purely block-level operations, thereby improving efficiency. Extensive evaluations confirm that Prism maintains accuracy parity with full attention while delivering up to $\\mathbf{5.1\\times}$ speedup."
  },
  {
    "date": "2026-02-09",
    "title": "SAT Encodings for Bandwidth Coloring: A Systematic Design Study",
    "authors": "Duc Trung Kim Nguyen, Tuyen Van Kieu, Khanh Van To",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08423v1",
    "source": "arXiv",
    "abstract": "The Bandwidth Coloring Problem (BCP) generalizes graph coloring by enforcing minimum separation constraints between adjacent vertices and arises in frequency assignment applications. While SAT-based approaches have shown promise for exact BCP solving, the encoding design space remains largely unexplored. This paper presents a systematic study of SAT encodings for the BCP, proposing a unified framework with six encoding methods across three categories: one-variable, two-variable, and block encodings. We evaluate the impact of key features including incremental solving and symmetry breaking. While symmetry breaking has been studied for graph coloring, it has not been systematically evaluated for SAT-based BCP solvers. Our analysis reveals significant interaction effects between encoding choices and solver configurations. The proposed framework achieves state-of-the-art performance on GEOM and MS-CAP benchmarks. Block encodings solve GEOM120b, the hardest instance, to proven optimality in approximately 1000 seconds, whereas previous methods could not solve it within a one-hour time limit."
  },
  {
    "date": "2026-02-09",
    "title": "Decentralized Intent-Based Multi-Robot Task Planner with LLM Oracles on Hyperledger Fabric",
    "authors": "Farhad Keramat, Salma Salimi, Tomi Westerlund",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08421v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have opened new opportunities for transforming natural language user intents into executable actions. This capability enables embodied AI agents to perform complex tasks, without involvement of an expert, making human-robot interaction (HRI) more convenient. However these developments raise significant security and privacy challenges such as self-preferencing, where a single LLM service provider dominates the market and uses this power to promote their own preferences. LLM oracles have been recently proposed as a mechanism to decentralize LLMs by executing multiple LLMs from different vendors and aggregating their outputs to obtain a more reliable and trustworthy final result. However, the accuracy of these approaches highly depends on the aggregation method. The current aggregation methods mostly use semantic similarity between various LLM outputs, not suitable for robotic task planning, where the temporal order of tasks is important. To fill the gap, we propose an LLM oracle with a new aggregation method for robotic task planning. In addition, we propose a decentralized multi-robot infrastructure based on Hyperledger Fabric that can host the proposed oracle. The proposed infrastructure enables users to express their natural language intent to the system, which then can be decomposed into subtasks. These subtasks require coordinating different robots from different vendors, while enforcing fine-grained access control management on the data. To evaluate our methodology, we created the SkillChain-RTD benchmark made it publicly available. Our experimental results demonstrate the feasibility of the proposed architecture, and the proposed aggregation method outperforms other aggregation methods currently in use."
  },
  {
    "date": "2026-02-09",
    "title": "The Finite Geometry of Breaking Quantum Secrets",
    "authors": "Péter Lévay, Metod Saniga",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08410v1",
    "source": "arXiv",
    "abstract": "Using a finite geometric framework for studying the pentagon and heptagon codes we show that the concepts of quantum secret sharing and contextuality can be studied in a nice and unified manner. The basic idea is a careful study of the respective $2+3$ and $3+4$ tensorial factorizations of the elements of the stabilizer groups of these codes. It is demonstrated in detail how finite geometric structures entailing a specific three-qubit (resp. four-qubit) embedding of binary symplectic polar spaces of rank two (resp. three), corresponding to these factorizations, govern issues of contextuality and entanglement needed for a geometric understanding of quantum secret sharing. Using these results for the $(3,5)$ and $(4,7)$ threshold schemes explicit secret breaking protocols are derived. Our results hint at a novel geometric way of looking at contextual configurations."
  },
  {
    "date": "2026-02-09",
    "title": "Thermodynamic modes of a quasiperiodic mobility-edge system in a quantum Otto cycle",
    "authors": "Ao Zhou, Shujie Cheng, Gao Xianlong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08378v1",
    "source": "arXiv",
    "abstract": "We investigate thermodynamic operation of a quasiperiodic lattice with an exact mobility edge, described by the Biddle--Das Sarma model. We use this model as the working medium of a quantum Otto cycle and map its operating mode as a function of the hopping-range parameter $p$, the initial and final potential strengths $V_i$ and $V_f$, and two idealized protocols for the isolated strokes. In a near-adiabatic (state-frozen) protocol, where the density matrix is approximately unchanged during the isolated strokes, the cycle supports only two modes: a \\emph{heater} and an \\emph{accelerator}. In an adiabatic protocol, where level populations are preserved while the spectrum is deformed, two additional modes appear: a \\emph{heat engine} and a \\emph{refrigerator}. Our results show that mobility-edge systems can realize multiple thermodynamic functions within a single platform and provide guidance for switching between modes by tuning $p$, $V_i$, and $V_f$."
  },
  {
    "date": "2026-02-09",
    "title": "Remainder terms and sharp quantitative stability for a nonlocal Sobolev inequality on the Heisenberg group",
    "authors": "Wenjing Chen, Zexi Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08375v1",
    "source": "arXiv",
    "abstract": "In this paper, we study the following nonlocal Sobolev inequality on the Heisenberg group \\begin{equation}\\label{eq:HLS} S_{HL}(Q,μ) \\left(\\int_{\\mathbb{H}^{n}}\\int_{\\mathbb{H}^{n}}\\frac{|u(ξ)|^{Q^{\\ast}_μ}|u(η)|^{Q^{\\ast}_μ}}{|η^{-1}ξ|^μ}{d}ξ{d}η\\right)^{\\frac{1}{Q^{\\ast}_μ}}\\leq \\int_{\\mathbb{H}^{n}}|\\nabla_{\\mathbb{H}}u|^{2}dξ,\\quad \\forall \\, u\\in S^{1,2}(\\mathbb{H}^{n}), \\end{equation} where $Q=2n+2$ is the homogeneous dimension of the Heisenberg group $\\mathbb{H}^{n}$, $n\\geq1$, $μ\\in(0,Q)$, $Q^{\\ast}_μ=\\frac{2Q-μ}{Q-2}$ is the upper critical exponent in the sense of the Hardy-Littlewood-Sobolev inequality and the Folland-Stein-Sobolev inequality on the Heisenberg group, $S_{HL}(Q,μ)$ is the sharp constant of \\eqref{eq:HLS}, and $S^{1,2}(\\mathbb{H}^{n})$ is the Folland-Stein-Sobolev space. %of the nonlocal-Sobolev inequality. It is well-known that, up to a translation and suitable scaling, \\begin{equation}\\label{eq:abs} -Δ_{\\mathbb{H}} u=\\left(\\int_{\\mathbb{H}^{n}}\\frac{|u(η)| ^{Q^{\\ast}_μ}}{|η^{-1}ξ|^μ}{d}η\\right)|u|^{Q_μ^*-2}u,~~u\\in S^{1,2}(\\mathbb{H}^{n}) \\end{equation} is the Euler-Lagrange equation corresponding to the associated minimization problem. On the one hand, we show the existence of a gradient-type remainder term for inequality \\eqref{eq:HLS} when $Q\\geq4$, $μ\\in (0,4]$, and as a corollary, derive the existence of a remainder term in the weak $L^{\\frac{Q}{Q-2}}$-norm on bounded domains. On the other hand, we establish the quantitative stability of critical points for equation \\eqref{eq:abs} in the multi-bubble case when $Q=4$ and $μ\\in (2,4)$."
  },
  {
    "date": "2026-02-09",
    "title": "Dynamic Regret via Discounted-to-Dynamic Reduction with Applications to Curved Losses and Adam Optimizer",
    "authors": "Yan-Feng Xie, Yu-Jie Zhang, Peng Zhao, Zhi-Hua Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08372v1",
    "source": "arXiv",
    "abstract": "We study dynamic regret minimization in non-stationary online learning, with a primary focus on follow-the-regularized-leader (FTRL) methods. FTRL is important for curved losses and for understanding adaptive optimizers such as Adam, yet existing dynamic regret analyses are less explored for FTRL. To address this, we build on the discounted-to-dynamic reduction and present a modular way to obtain dynamic regret bounds of FTRL-related problems. Specifically, we focus on two representative curved losses: linear regression and logistic regression. Our method not only simplifies existing proofs for the optimal dynamic regret of online linear regression, but also yields new dynamic regret guarantees for online logistic regression. Beyond online convex optimization, we apply the reduction to analyze the Adam optimizers, obtaining optimal convergence rates in stochastic, non-convex, and non-smooth settings. The reduction also enables a more detailed treatment of Adam with two discount parameters $(β_1,β_2)$, leading to new results for both clipped and clip-free variants of Adam optimizers."
  },
  {
    "date": "2026-02-09",
    "title": "ViGoEmotions: A Benchmark Dataset For Fine-grained Emotion Detection on Vietnamese Texts",
    "authors": "Hung Quang Tran, Nam Tien Pham, Son T. Luu, Kiet Van Nguyen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08371v1",
    "source": "arXiv",
    "abstract": "Emotion classification plays a significant role in emotion prediction and harmful content detection. Recent advancements in NLP, particularly through large language models (LLMs), have greatly improved outcomes in this field. This study introduces ViGoEmotions -- a Vietnamese emotion corpus comprising 20,664 social media comments in which each comment is classified into 27 fine-grained distinct emotions. To evaluate the quality of the dataset and its impact on emotion classification, eight pre-trained Transformer-based models were evaluated under three preprocessing strategies: preserving original emojis with rule-based normalization, converting emojis into textual descriptions, and applying ViSoLex, a model-based lexical normalization system. Results show that converting emojis into text often improves the performance of several BERT-based baselines, while preserving emojis yields the best results for ViSoBERT and CafeBERT. In contrast, removing emojis generally leads to lower performance. ViSoBERT achieved the highest Macro F1-score of 61.50% and Weighted F1-score of 63.26%. Strong performance was also observed from CafeBERT and PhoBERT. These findings highlight that while the proposed corpus can support diverse architectures effectively, preprocessing strategies and annotation quality remain key factors influencing downstream performance."
  },
  {
    "date": "2026-02-09",
    "title": "Wide-angle emission in cylindrical moiré lattices enabled by rolling origami",
    "authors": "Min Tang, Fanzhou Lv, Haiyun Dong, Jiawei Wang, Chaoyuan Jin, Tun Cao, Ching Hua Lee, Ronny Thomale, Sebastian Klembt, Yana Vaynzof, Libo Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08364v1",
    "source": "arXiv",
    "abstract": "Twisted photonic lattices that form moiré superlattices have attracted significant attention owing to their unique properties, such as strong field confinement and high-quality factors, in which the localized optical modes can serve as efficient light sources. However, in conventional moiré lattices, the emission direction of confined modes is typically fixed, and achieving a broad range of emission angles through simple modulation remains a significant challenge. Here, we design and fabricate single-layer moiré photonic lattices into cylindrical geometries using a nanomembrane origami technique. This approach enables wide-angle localized-mode emission while maintaining stable single-mode operation and excellent spectral uniformity. The moiré supercells support localized flat-band modes under various effective twist angles, resulting in the observation of periodic localized-mode emission over a wide range of azimuthal angles. Our research provides an approach for developing moiré light sources on curved surfaces, offering significant potential in applications that demand spatial light control, including three dimensional imaging, light detection and ranging, and topological states manipulation."
  },
  {
    "date": "2026-02-09",
    "title": "Circuit Representations of Random Forests with Applications to XAI",
    "authors": "Chunxi Ji, Adnan Darwiche",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08362v1",
    "source": "arXiv",
    "abstract": "We make three contributions in this paper. First, we present an approach for compiling a random forest classifier into a set of circuits, where each circuit directly encodes the instances in some class of the classifier. We show empirically that our proposed approach is significantly more efficient than existing similar approaches. Next, we utilize this approach to further obtain circuits that are tractable for computing the complete and general reasons of a decision, which are instance abstractions that play a fundamental role in computing explanations. Finally, we propose algorithms for computing the robustness of a decision and all shortest ways to flip it. We illustrate the utility of our contributions by using them to enumerate all sufficient reasons, necessary reasons and contrastive explanations of decisions; to compute the robustness of decisions; and to identify all shortest ways to flip the decisions made by random forest classifiers learned from a wide range of datasets."
  },
  {
    "date": "2026-02-09",
    "title": "Estimating the Shannon Entropy Using the Pitman--Yor Process",
    "authors": "Takato Hashino, Koji Tsukuda",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08347v1",
    "source": "arXiv",
    "abstract": "The Shannon entropy is a fundamental measure for quantifying diversity and model complexity in fields such as information theory, ecology, and genetics. However, many existing studies assume that the number of species is known, an assumption that is often unrealistic in practice. In recent years, efforts have been made to relax this restriction. Motivated by these developments, this study proposes an entropy estimation method based on the Pitman--Yor process, a representative approach in Bayesian nonparametrics. By approximating the true distribution as an infinite-dimensional process, the proposed method enables stable estimation even when the number of observed species is smaller than the true number of species. This approach provides a principled way to deal with the uncertainty in species diversity and enhances the reliability and robustness of entropy-based diversity assessment. In addition, we investigate the convergence property of the Shannon entropy for regularly varying distributions and use this result to establish the consistency of the proposed estimator. Finally, we demonstrate the effectiveness of the proposed method through numerical experiments."
  },
  {
    "date": "2026-02-09",
    "title": "The simplified quantum circuits for implementing quantum teleportation",
    "authors": "Wen-Xiu Zhang, Guo-Zhu Song, Hai-Rui Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08345v1",
    "source": "arXiv",
    "abstract": "It is crucial to design quantum circuits as small as possible and as shallow as possible for quantum information processing tasks. We design quantum circuits with simplified gate-count, cost, and depth for implementing quantum teleportation among various entangled channels. Here the gate-count/cost/depth of the Greenberger-Horne-Zeilinger-based quantum teleportation is reduced from 10/6/8 to 9/4/6, the two-qubit-cluster-based quantum teleportation is reduced from 9/4/5 to 6/3/5, the three-qubit-cluster-based quantum teleportation is reduced from 12/6/7 to 8/4/5, the Brown-based quantum teleportation is reduced from 25/15/17 to 18/8/7, the Borras-based quantum teleportation is reduced from 36/25/20 to 15/8/11, and the entanglement-swapping-based quantum teleportation is reduced from 13/8/8 to 10/5/5. Note that, no feed-forward recover operation is required in the simplified schemes. Moreover, the experimentally demonstrations on IBM quantum computer indicate that our simplified and compressed schemes can be realized with good fidelity."
  },
  {
    "date": "2026-02-09",
    "title": "Effect-Level Validation for Causal Discovery",
    "authors": "Hoang Dang, Luan Pham, Minh Nguyen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08340v1",
    "source": "arXiv",
    "abstract": "Causal discovery is increasingly applied to large-scale telemetry data to estimate the effects of user-facing interventions, yet its reliability for decision-making in feedback-driven systems with strong self-selection remains unclear. In this paper, we propose an effect-centric, admissibility-first framework that treats discovered graphs as structural hypotheses and evaluates them by identifiability, stability, and falsification rather than by graph recovery accuracy alone. Empirically, we study the effect of early exposure to competitive gameplay on short-term retention using real-world game telemetry. We find that many statistically plausible discovery outputs do not admit point-identified causal queries once minimal temporal and semantic constraints are enforced, highlighting identifiability as a critical bottleneck for decision support. When identification is possible, several algorithm families converge to similar, decision-consistent effect estimates despite producing substantially different graph structures, including cases where the direct treatment-outcome edge is absent and the effect is preserved through indirect causal pathways. These converging estimates survive placebo, subsampling, and sensitivity refutation. In contrast, other methods exhibit sporadic admissibility and threshold-sensitive or attenuated effects due to endpoint ambiguity. These results suggest that graph-level metrics alone are inadequate proxies for causal reliability for a given target query. Therefore, trustworthy causal conclusions in telemetry-driven systems require prioritizing admissibility and effect-level validation over causal structural recovery alone."
  },
  {
    "date": "2026-02-09",
    "title": "CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT",
    "authors": "Chengyi Du, Yazhe Niu, Dazhong Shen, Luxin Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08339v1",
    "source": "arXiv",
    "abstract": "Recent advances in vision-language models (VLMs) have markedly improved image-text alignment, yet they still fall short of human-like visual reasoning. A key limitation is that many VLMs rely on surface correlations rather than building logically coherent structured representations, which often leads to missed higher-level semantic structure and non-causal relational understanding, hindering compositional and verifiable reasoning. To address these limitations by introducing human models into the reasoning process, we propose CoTZero, an annotation-free paradigm with two components: (i) a dual-stage data synthesis approach and (ii) a cognition-aligned training method. In the first component, we draw inspiration from neurocognitive accounts of compositional productivity and global-to-local analysis. In the bottom-up stage, CoTZero extracts atomic visual primitives and incrementally composes them into diverse, structured question-reasoning forms. In the top-down stage, it enforces hierarchical reasoning by using coarse global structure to guide the interpretation of local details and causal relations. In the cognition-aligned training component, built on the synthesized CoT data, we introduce Cognitively Coherent Verifiable Rewards (CCVR) in Reinforcement Fine-Tuning (RFT) to further strengthen VLMs' hierarchical reasoning and generalization, providing stepwise feedback on reasoning coherence and factual correctness. Experiments show that CoTZero achieves an F1 score of 83.33 percent on our multi-level semantic inconsistency benchmark with lexical-perturbation negatives, across both in-domain and out-of-domain settings. Ablations confirm that each component contributes to more interpretable and human-aligned visual reasoning."
  },
  {
    "date": "2026-02-09",
    "title": "Language-Guided Transformer Tokenizer for Human Motion Generation",
    "authors": "Sheng Yan, Yong Wang, Xin Du, Junsong Yuan, Mengyuan Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08337v1",
    "source": "arXiv",
    "abstract": "In this paper, we focus on motion discrete tokenization, which converts raw motion into compact discrete tokens--a process proven crucial for efficient motion generation. In this paradigm, increasing the number of tokens is a common approach to improving motion reconstruction quality, but more tokens make it more difficult for generative models to learn. To maintain high reconstruction quality while reducing generation complexity, we propose leveraging language to achieve efficient motion tokenization, which we term Language-Guided Tokenization (LG-Tok). LG-Tok aligns natural language with motion at the tokenization stage, yielding compact, high-level semantic representations. This approach not only strengthens both tokenization and detokenization but also simplifies the learning of generative models. Furthermore, existing tokenizers predominantly adopt convolutional architectures, whose local receptive fields struggle to support global language guidance. To this end, we propose a Transformer-based Tokenizer that leverages attention mechanisms to enable effective alignment between language and motion. Additionally, we design a language-drop scheme, in which language conditions are randomly removed during training, enabling the detokenizer to support language-free guidance during generation. On the HumanML3D and Motion-X generation benchmarks, LG-Tok achieves Top-1 scores of 0.542 and 0.582, outperforming state-of-the-art methods (MARDM: 0.500 and 0.528), and with FID scores of 0.057 and 0.088, respectively, versus 0.114 and 0.147. LG-Tok-mini uses only half the tokens while maintaining competitive performance (Top-1: 0.521/0.588, FID: 0.085/0.071), validating the efficiency of our semantic representations."
  },
  {
    "date": "2026-02-09",
    "title": "UReason: Benchmarking the Reasoning Paradox in Unified Multimodal Models",
    "authors": "Cheng Yang, Chufan Shi, Bo Shui, Yaokang Wu, Muzi Tao, Huijuan Wang, Ivan Yee Lee, Yong Liu, Xuezhe Ma, Taylor Berg-Kirkpatrick",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08336v1",
    "source": "arXiv",
    "abstract": "To elicit capabilities for addressing complex and implicit visual requirements, recent unified multimodal models increasingly adopt chain-of-thought reasoning to guide image generation. However, the actual effect of reasoning on visual synthesis remains unclear. We present UReason, a diagnostic benchmark for reasoning-driven image generation that evaluates whether reasoning can be faithfully executed in pixels. UReason contains 2,000 instances across five task families: Code, Arithmetic, Spatial, Attribute, and Text reasoning. To isolate the role of reasoning traces, we introduce an evaluation framework comparing direct generation, reasoning-guided generation, and de-contextualized generation which conditions only on the refined prompt. Across eight open-source unified models, we observe a consistent Reasoning Paradox: Reasoning traces generally improve performance over direct generation, yet retaining intermediate thoughts as conditioning context often hinders visual synthesis, and conditioning only on the refined prompt yields substantial gains. Our analysis suggests that the bottleneck lies in contextual interference rather than insufficient reasoning capacity. UReason provides a principled testbed for studying reasoning in unified models and motivates future methods that effectively integrate reasoning for visual generation while mitigating interference."
  },
  {
    "date": "2026-02-09",
    "title": "Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System",
    "authors": "Yanming Li, Xuelin Zhang, WenJie Lu, Ziye Tang, Maodong Wu, Haotian Luo, Tongtong Wu, Zijie Peng, Hongze Mi, Yibo Feng, Naiqiang Tan, Chao Huang, Hong Chen, Li Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08335v1",
    "source": "arXiv",
    "abstract": "Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specific functional agent is responsible for the success or failure of decision trajectories. Existing methods typically rely on sparse or globally broadcast rewards, failing to capture individual contributions and leading to inefficient reinforcement learning. To address these limitations, we introduce the Shapley-based Hierarchical Attribution for Reinforcement Policy (SHARP), a novel framework for optimizing multi-agent reinforcement learning via precise credit attribution. SHARP effectively stabilizes training by normalizing agent-specific advantages across trajectory groups, primarily through a decomposed reward mechanism comprising a global broadcast-accuracy reward, a Shapley-based marginal-credit reward for each agent, and a tool-process reward to improve execution efficiency. Extensive experiments across various real-world benchmarks demonstrate that SHARP significantly outperforms recent state-of-the-art baselines, achieving average match improvements of 23.66% and 14.05% over single-agent and multi-agent approaches, respectively."
  },
  {
    "date": "2026-02-09",
    "title": "Personalized Autonomous Driving via Optimal Control with Clearance Constraints from Questionnaires",
    "authors": "Yongjae Lim, Dabin Kim, H. Jin Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08326v1",
    "source": "arXiv",
    "abstract": "Driving without considering the preferred separation distance from surrounding vehicles may cause discomfort for users. To address this limitation, we propose a planning framework that explicitly incorporates user preferences regarding the desired level of safe clearance from surrounding vehicles. We design a questionnaire purposefully tailored to capture user preferences relevant to our framework, while minimizing unnecessary questions. Specifically, the questionnaire considers various interaction-relevant factors, including the surrounding vehicle's size, speed, position, and maneuvers of surrounding vehicles, as well as the maneuvers of the ego vehicle. The response indicates the user-preferred clearance for the scenario defined by the question and is incorporated as constraints in the optimal control problem. However, it is impractical to account for all possible scenarios that may arise in a driving environment within a single optimal control problem, as the resulting computational complexity renders real-time implementation infeasible. To overcome this limitation, we approximate the original problem by decomposing it into multiple subproblems, each dealing with one fixed scenario. We then solve these subproblems in parallel and select one using the cost function from the original problem. To validate our work, we conduct simulations using different user responses to the questionnaire. We assess how effectively our planner reflects user preferences compared to preference-agnostic baseline planners by measuring preference alignment."
  },
  {
    "date": "2026-02-09",
    "title": "A numerical study for tempered time-fractional advection-dispersion equation on graded meshes",
    "authors": "Liangcai Huang, Lin Li, Shujuan Lü",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08325v1",
    "source": "arXiv",
    "abstract": "In this paper, we develop a second-order accurate time-stepping scheme for the tempered time-fractional advection-dispersion equation based on a sum-of-exponentials (SOE) approximation to the convolution kernel involved in the fractional derivative. To effectively resolve the weak initial-time singularity at t=0, graded temporal meshes are employed. A fully discrete scheme is constructed by coupling the proposed half-time-level temporal discretization with a finite difference method in space. Compared with the classical L1 scheme, the proposed SOE-based method achieves the same global convergence order while reducing both storage requirements and computational cost. Specifically, the storage demand is reduced from O(MN) to O(MN_exp), and the computational complexity is lowered from O(MN^2) to O(MN N_exp), where M and N denote the numbers of spatial and temporal grid points, respectively, and N_exp is the number of exponential terms used in the SOE approximation. The unique solvability, stability and accuracy of the resulting scheme are rigorously analyzed. Several numerical results are presented to confirm the sharpness of the error analysis and to demonstrate the efficiency of the proposed method."
  },
  {
    "date": "2026-02-09",
    "title": "Antiferromagnetic Tunnel Junctions (AFMTJs) for In-Memory Computing: Modeling and Case Study",
    "authors": "Yousuf Choudhary, Tosiron Adegbija",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08323v1",
    "source": "arXiv",
    "abstract": "Antiferromagnetic Tunnel Junctions (AFMTJs) enable picosecond switching and femtojoule writes through ultrafast sublattice dynamics. We present the first end-to-end AFMTJ simulation framework integrating multi-sublattice Landau-Lifshitz-Gilbert (LLG) dynamics with circuit-level modeling. SPICE-based simulations show that AFMTJs achieve ~8x lower write latency and ~9x lower write energy than conventional MTJs. When integrated into an in-memory computing architecture, AFMTJs deliver 17.5x average speedup and nearly 20x energy savings versus a CPU baseline-significantly outperforming MTJ-based IMC. These results establish AFMTJs as a compelling primitive for scalable, low-power computing."
  },
  {
    "date": "2026-02-09",
    "title": "Is Flow Matching Just Trajectory Replay for Sequential Data?",
    "authors": "Soon Hoe Lim, Shizheng Lin, Michael W. Mahoney, N. Benjamin Erichson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08318v1",
    "source": "arXiv",
    "abstract": "Flow matching (FM) is increasingly used for time-series generation, but it is not well understood whether it learns a general dynamical structure or simply performs an effective \"trajectory replay\". We study this question by deriving the velocity field targeted by the empirical FM objective on sequential data, in the limit of perfect function approximation. For the Gaussian conditional paths commonly used in practice, we show that the implied sampler is an ODE whose dynamics constitutes a nonparametric, memory-augmented continuous-time dynamical system. The optimal field admits a closed-form expression as a similarity-weighted mixture of instantaneous velocities induced by past transitions, making the dataset dependence explicit and interpretable. This perspective positions neural FM models trained by stochastic optimization as parametric surrogates of an ideal nonparametric solution. Using the structure of the optimal field, we study sampling and approximation schemes that improve the efficiency and numerical robustness of ODE-based generation. On nonlinear dynamical system benchmarks, the resulting closed-form sampler yields strong probabilistic forecasts directly from historical transitions, without training."
  },
  {
    "date": "2026-02-09",
    "title": "Fast Flow Matching based Conditional Independence Tests for Causal Discovery",
    "authors": "Shunyu Zhao, Yanfeng Yang, Shuai Li, Kenji Fukumizu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08315v1",
    "source": "arXiv",
    "abstract": "Constraint-based causal discovery methods require a large number of conditional independence (CI) tests, which severely limits their practical applicability due to high computational complexity. Therefore, it is crucial to design an algorithm that accelerates each individual test. To this end, we propose the Flow Matching-based Conditional Independence Test (FMCIT). The proposed test leverages the high computational efficiency of flow matching and requires the model to be trained only once throughout the entire causal discovery procedure, substantially accelerating causal discovery. According to numerical experiments, FMCIT effectively controls type-I error and maintains high testing power under the alternative hypothesis, even in the presence of high-dimensional conditioning sets. In addition, we further integrate FMCIT into a two-stage guided PC skeleton learning framework, termed GPC-FMCIT, which combines fast screening with guided, budgeted refinement using FMCIT. This design yields explicit bounds on the number of CI queries while maintaining high statistical power. Experiments on synthetic and real-world causal discovery tasks demonstrate favorable accuracy-efficiency trade-offs over existing CI testing methods and PC variants."
  },
  {
    "date": "2026-02-09",
    "title": "An Algorithm for Diagonalizing Matrices of Formal Power Series",
    "authors": "Zihao Dai, Hao Liang, Jingyu Lu, Lihong Zhi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08313v1",
    "source": "arXiv",
    "abstract": "This paper studies the unitary diagonalization of matrices over formal power series rings. Our main result shows that a normal matrix is unitarily diagonalizable if and only if its minimal polynomial completely splits over the ring and the associated spectral projections have entries in the ring. Building on this characterization, we develop an algorithm for deciding the unitary diagonalizability of matrices over regular local rings of algebraic varieties. A central ingredient of the algorithm is a decision procedure for determining whether a polynomial splits over a formal power series ring; we establish this using techniques from prime decomposition and the relative smoothness of integral closures in ramification theory."
  },
  {
    "date": "2026-02-09",
    "title": "CAE-AV: Improving Audio-Visual Learning via Cross-modal Interactive Enrichment",
    "authors": "Yunzuo Hu, Wen Li, Jing Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08309v1",
    "source": "arXiv",
    "abstract": "Audio-visual learning suffers from modality misalignment caused by off-screen sources and background clutter, and current methods usually amplify irrelevant regions or moments, leading to unstable training and degraded representation quality. To address this challenge, we proposed a novel Caption-aligned and Agreement-guided Enhancement framework (CAE-AV) for audio-visual learning, which used two complementary modules: Cross-modal Agreement-guided Spatio-Temporal Enrichment (CASTE) and Caption-Aligned Saliency-guided Enrichment (CASE) to relieve audio-visual misalignment. CASTE dynamically balances spatial and temporal relations by evaluating frame-level audio-visual agreement, ensuring that key information is captured from both preceding and subsequent frames under misalignment. CASE injects cross-modal semantic guidance into selected spatio-temporal positions, leveraging high-level semantic cues to further alleviate misalignment. In addition, we design lightweight objectives, caption-to-modality InfoNCE, visual-audio consistency, and entropy regularization to guide token selection and strengthen cross-modal semantic alignment. With frozen backbones, CAE-AV achieves state-of-the-art performance on AVE, AVVP, AVS, and AVQA benchmarks, and qualitative analyses further validate its robustness against audio-visual misalignment."
  },
  {
    "date": "2026-02-09",
    "title": "Spectral Analysis of the Schrödinger Operator for the Incommensurate System",
    "authors": "Yan Li, Yujian Song, Aihui Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08308v1",
    "source": "arXiv",
    "abstract": "Many novel and unique physical phenomena of incommensurate systems can be illustrated and predicted using the spectra of the associated Schrödinger operators. However, the absence of periodicity in these systems poses significant challenges for obtaining the spectral information. In this paper, by embedding the system into higher dimensions together with introducing a regularization technique, we prove that the spectrum of the Schrödinger operator for the incommensurate system can be approximated by the spectra of a family of regularized Schrödinger operators, which are elliptic, retain periodicity, and enjoy favorable analytic and spectral properties. We also show the existence of Bloch-type solutions to the Schrödinger equation for the incommensurate system, which can be well approximated by the Bloch solutions to the equations associated with the regularized operators. Our analysis provides a theoretical support for understanding and computing the incommensurate systems."
  },
  {
    "date": "2026-02-09",
    "title": "JUSTICE: Judicial Unified Synthesis Through Intermediate Conclusion Emulation for Automated Judgment Document Generation",
    "authors": "Binglin Wu, Yingyi Zhang, Xiannneg Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08305v1",
    "source": "arXiv",
    "abstract": "Automated judgment document generation is a significant yet challenging legal AI task. As the conclusive written instrument issued by a court, a judgment document embodies complex legal reasoning. However, existing methods often oversimplify this complex process, particularly by omitting the ``Pre-Judge'' phase, a crucial step where human judges form a preliminary conclusion. This omission leads to two core challenges: 1) the ineffective acquisition of foundational judicial elements, and 2) the inadequate modeling of the Pre-Judge process, which collectively undermine the final document's legal soundness. To address these challenges, we propose \\textit{\\textbf{J}udicial \\textbf{U}nified \\textbf{S}ynthesis \\textbf{T}hrough \\textbf{I}ntermediate \\textbf{C}onclusion \\textbf{E}mulation} (JUSTICE), a novel framework that emulates the ``Search $\\rightarrow$ Pre-Judge $\\rightarrow$ Write'' cognitive workflow of human judges. Specifically, it introduces the Pre-Judge stage through three dedicated components: Referential Judicial Element Retriever (RJER), Intermediate Conclusion Emulator (ICE), and Judicial Unified Synthesizer (JUS). RJER first retrieves legal articles and a precedent case to establish a referential foundation. ICE then operationalizes the Pre-Judge phase by generating a verifiable intermediate conclusion. Finally, JUS synthesizes these inputs to craft the final judgment. Experiments on both an in-domain legal benchmark and an out-of-distribution dataset show that JUSTICE significantly outperforms strong baselines, with substantial gains in legal accuracy, including a 4.6\\% improvement in prison term prediction. Our findings underscore the importance of explicitly modeling the Pre-Judge process to enhance the legal coherence and accuracy of generated judgment documents."
  },
  {
    "date": "2026-02-09",
    "title": "Algebraic Properties of the Ideal of Spectral Invariants for the Discrete Laplacian",
    "authors": "Matthew Faust, Leo Friedman, Gavin O'Malley, Rolando Ramos, Aaryan Sharma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08304v1",
    "source": "arXiv",
    "abstract": "Let $Γ=q_1\\mathbb{Z}\\oplus q_2 \\mathbb{Z}\\oplus\\cdots\\oplus q_d\\mathbb{Z}$, with $q_j\\in \\mathbb{Z}^+$ for each $j\\in \\{1,\\ldots,d\\}$, and denote by $Δ$ the discrete Laplacian on $\\ell^2\\left( \\mathbb{Z}^d\\right)$. We describe various algebraic properties of the ideal of spectral invariants for the discrete Laplacian when $d=1$, including a construction of a Gröbner basis. We also present various collections of complex $Γ$-periodic potentials $V$ that are such that $Δ$ and $Δ+ V$ are Floquet isospectral. We end with a discussion of the general setting, where the $q_i$ are taken to be vectors in $\\mathbb{Z}^d$."
  },
  {
    "date": "2026-02-09",
    "title": "Experimental Realization of Koopman-Model Predictive Control for an AC-DC Converter",
    "authors": "Shun Hirose, Shiu Mochiyama, Yoshihiko Susuki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08303v1",
    "source": "arXiv",
    "abstract": "This paper experimentally demonstrates the Koopman-Model Predictive Control (K-MPC) for a real AC-DC converter. The converter is typically modeled with a nonlinear time-variant plant. We introduce a new dynamical approach to lifting measurable dynamics from the plant and constructing a linear time-invariant model that is consistent with control objectives of the converter. We show that the lifting approach, combined with the K-MPC controller, performs well across the full experimental system and outperforms existing control strategies in terms of both steady-state and transient responses."
  },
  {
    "date": "2026-02-09",
    "title": "Automatic Generation of Polynomial Symmetry Breaking Constraints",
    "authors": "Madalina Erascu, Johannes Middeke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08297v1",
    "source": "arXiv",
    "abstract": "Symmetry in integer programming causes redundant search and is often handled with symmetry breaking constraints that remove as many equivalent solutions as possible. We propose an algebraic method which allows to generate a random family of polynomial inequalities which can be used as symmetry breakers. The method requires as input an arbitrary base polynomial and a group of permutations which is specific to the integer program. The computations can be easily carried out in any major symbolic computation software. In order to test our approach, we describe a case study on near half-capacity 0-1 bin packing instances which exhibit substantial symmetries. We statically generate random quadratic breakers and add them to a baseline integer programming problem which we then solve with Gurobi. It turns out that simple symmetry breakers, especially combining few variables and permutations, most consistently reduce work time."
  },
  {
    "date": "2026-02-09",
    "title": "MonkeyTree: Near-Minimal Congestion for Multi-tenant Training via Migration",
    "authors": "Anton A. Zabreyko, Weiyang Wang, Manya Ghobadi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08296v1",
    "source": "arXiv",
    "abstract": "We present MonkeyTree, the first system to mitigate network congestion in multi-tenant GPU clusters through job-migration based defragmentation rather than network-layer techniques. As cloud operators co-locate ML training jobs on shared, oversubscribed networks, congestion degrades training throughput for over a third of jobs. Prior approaches either rely on routing and flow scheduling--which we show have fundamental limits when traffic exceeds capacity--or require costly full-bisection bandwidth topologies with packet spraying. MonkeyTree exploits characteristics of ML training traffic: ring-based collectives generate exactly one cross-rack flow per rack a job spans, making congestion-free placements achievable. The sparse constraint structure admits abundant valid configurations, making them easy to reach with few migrations. Once reached, low fragmentation is self-reinforcing, as new arrivals disturb only a few racks. MonkeyTree formulates defragmentation as an integer linear program that minimizes worker movements, subject to per-rack fragmentation bounds. We prove a tight bound showing any placement can be defragmented to at most two cross-rack fragments per ToR, and extend the formulation to hybrid parallelism with multiple rings per server. Migration is implemented via in-memory checkpoint-and-restore over RDMA, incurring only 9.02 seconds of system overhead end-to-end per worker. We evaluate MonkeyTree using a custom simulator modeling clusters of up to 2,048 H200 GPUs and prototype on a five-node A100 testbed. MonkeyTree improves average job completion time by 14 percent over the next best baseline on a cluster of 1,024 GPUs with a 4:1 oversubscription. With a high 16:1 oversubscription ratio and 2,048 GPUs, MonkeyTree keeps p99 job completion time within 5 percent of ideal."
  },
  {
    "date": "2026-02-09",
    "title": "When Does Context Help? Error Dynamics of Contextual Information in Large Language Models",
    "authors": "Dingzirui Wang, Xuanliang Zhang, Keyan Xu, Qingfu Zhu, Wanxiang Che, Yang Deng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08294v1",
    "source": "arXiv",
    "abstract": "Contextual information at inference time, such as demonstrations, retrieved knowledge, or interaction history, can substantially improve large language models (LLMs) without parameter updates, yet its theoretical role remains poorly understood beyond specific settings such as in-context learning (ICL). We present a unified theoretical framework for analyzing the effect of arbitrary contextual information in Transformer-based LLMs. Our analysis characterizes contextual influence through output error dynamics. In a single-layer Transformer, we prove that the context-conditioned error vector decomposes additively into the baseline error vector and a contextual correction vector. This yields necessary geometric conditions for error reduction: the contextual correction must align with the negative baseline error and satisfy a norm constraint. We further show that the contextual correction norm admits an explicit upper bound determined by context-query relevance and complementarity. These results extend to multi-context and multi-layer Transformers. Experiments across ICL, retrieval-augmented generation, and memory evolution validate our theory and motivate a principled context selection strategy that improves performance by $0.6\\%$."
  },
  {
    "date": "2026-02-09",
    "title": "Invariant-domain preserving IMEX schemes for the nonequilibrium Gray Radiation-Hydrodynamics equations Part I",
    "authors": "Jean-Luc Guermond, Eric J. Tovar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08291v1",
    "source": "arXiv",
    "abstract": "In this work we introduce an implicit-explicit invariant-domain preserving approximation of the nonequilibrium gray radiation-hydrodynamics equations. A time and space approximation of the system is proposed using a novel split of the equations composed of three elementary subsystems, two hyperbolic and one parabolic. The approximation thus realized is proved to be consistent, conservative, invariant-domain preserving, and first-order accurate. The proposed method is a stepping stone for achieving higher-order accuracy in space and time in the forthcoming second part of this work. The method is numerically illustrated and shown to converge as advertised. This paper is dedicated to the memory of Peter Lax."
  },
  {
    "date": "2026-02-09",
    "title": "Characterizations of Conditional Mutual Independence: Equivalence and Implication",
    "authors": "Laigang Guo, Tao Guo, Raymond W. Yeung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08279v1",
    "source": "arXiv",
    "abstract": "Conditional independence, and more generally conditional mutual independence, are central notions in probability theory. In their general forms, they include functional dependence as a special case. In this paper, we tackle two fundamental problems related to conditional mutual independence. Let $K$ and $K'$ be two conditional mutual independncies (CMIs) defined on a finite set of discrete random variables. We have obtained a necessary and sufficient condition for i) $K$ is equivalent to $K'$; ii) $K$ implies $K'$. These characterizations are in terms of a canonical form introduced for conditional mutual independence."
  },
  {
    "date": "2026-02-09",
    "title": "Towards CXL Resilience to CPU Failures",
    "authors": "Antonis Psistakis, Burak Ocalan, Chloe Alverti, Fabien Chaix, Ramnatthan Alagappan, Josep Torrellas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08271v1",
    "source": "arXiv",
    "abstract": "Compute Express Link (CXL) 3.0 and beyond allows the compute nodes of a cluster to share data with hardware cache coherence and at the granularity of a cache line. This enables shared-memory semantics for distributed computing, but introduces new resilience challenges: a node failure leads to the loss of the dirty data in its caches, corrupting application state. Unfortunately, the CXL specification does not consider processor failures. Moreover, when a component fails, the specification tries to isolate it and continue application execution; there is no attempt to bring the application to a consistent state. To address these limitations, this paper extends the CXL specification to be resilient to node failures, and to correctly recover the application after node failures. We call the system ReCXL. To handle the failure of nodes, ReCXL augments the coherence transaction of a write with messages that propagate the update to a small set of other nodes (i.e., Replicas). Replicas save the update in a hardware Logging Unit. Such replication ensures resilience to node failures. Then, at regular intervals, the Logging Units dump the updates to memory. Recovery involves using the logs in the Logging Units to bring the directory and memory to a correct state. Our evaluation shows that ReCXL enables fault-tolerant execution with only a 30% slowdown over the same platform with no fault-tolerance support."
  },
  {
    "date": "2026-02-09",
    "title": "A Unified Framework for Multimodal Image Reconstruction and Synthesis using Denoising Diffusion Models",
    "authors": "Weijie Gan, Xucheng Wang, Tongyao Wang, Wenshang Wang, Chunwei Ying, Yuyang Hu, Yasheng Chen, Hongyu An, Ulugbek S. Kamilov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08249v1",
    "source": "arXiv",
    "abstract": "Image reconstruction and image synthesis are important for handling incomplete multimodal imaging data, but existing methods require various task-specific models, complicating training and deployment workflows. We introduce Any2all, a unified framework that addresses this limitation by formulating these disparate tasks as a single virtual inpainting problem. We train a single, unconditional diffusion model on the complete multimodal data stack. This model is then adapted at inference time to ``inpaint'' all target modalities from any combination of inputs of available clean images or noisy measurements. We validated Any2all on a PET/MR/CT brain dataset. Our results show that Any2all can achieve excellent performance on both multimodal reconstruction and synthesis tasks, consistently yielding images with competitive distortion-based performance and superior perceptual quality over specialized methods."
  },
  {
    "date": "2026-02-09",
    "title": "Structural transparency of societal AI alignment through Institutional Logics",
    "authors": "Atrisha Sarkar, Isam Faik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08246v1",
    "source": "arXiv",
    "abstract": "The field of AI alignment is increasingly concerned with the questions of how values are integrated into the design of generative AI systems and how their integration shapes the social consequences of AI. However, existing transparency frameworks focus on the informational aspects of AI models, data, and procedures, while the institutional and organizational forces that shape alignment decisions and their downstream effects remain underexamined in both research and practice. To address this gap, we develop a framework of \\emph{structural transparency} for analyzing organizational and institutional decisions concerning AI alignment, drawing on the theoretical lens of Institutional Logics. We develop a categorization of organizational decisions that are present in the governance of AI alignment, and provide an explicit analytical approach to examining them. We operationalize the framework through five analytical components, each with an accompanying \"analyst recipe\" that collectively identify the primary institutional logics and their internal relationships, external disruptions to existing social orders, and finally, how the structural risks of each institutional logic are mapped to a catalogue of sociotechnical harms. The proposed concept of structural transparency enables analysts to complement existing approached based on informational transparency with macro-level analyses that capture the institutional dynamics and consequences of decisions regarding AI alignment."
  },
  {
    "date": "2026-02-09",
    "title": "On convexity and efficiency in semantic systems",
    "authors": "Nathaniel Imel, Noga Zaslavasky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08238v1",
    "source": "arXiv",
    "abstract": "There are two widely held characterizations of human semantic category systems: (1) they form convex partitions of conceptual spaces, and (2) they are efficient for communication. While prior work observed that convexity and efficiency co-occur in color naming, the analytical relation between them and why they co-occur have not been well understood. We address this gap by combining analytical and empirical analyses that build on the Information Bottleneck (IB) framework for semantic efficiency. First, we show that convexity and efficiency are distinct in the sense that neither entails the other: there are convex systems which are inefficient, and optimally-efficient systems that are non-convex. Crucially, however, the IB-optimal systems are mostly convex in the domain of color naming, explaining the main empirical basis for the convexity approach. Second, we show that efficiency is a stronger predictor for discriminating attested color naming systems from hypothetical variants, with convexity adding negligible improvement on top of that. Finally, we discuss a range of empirical phenomena that convexity cannot account for but efficiency can. Taken together, our work suggests that while convexity and efficiency can yield similar structural observations, they are fundamentally distinct, with efficiency providing a more comprehensive account of semantic typology."
  },
  {
    "date": "2026-02-09",
    "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning",
    "authors": "Shoubin Yu, Yue Zhang, Zun Wang, Jaehong Yoon, Huaxiu Yao, Mingyu Ding, Mohit Bansal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08236v1",
    "source": "arXiv",
    "abstract": "Despite rapid progress in Multimodal Large Language Models (MLLMs), visual spatial reasoning remains unreliable when correct answers depend on how a scene would appear under unseen or alternative viewpoints. Recent work addresses this by augmenting reasoning with world models for visual imagination, but questions such as when imagination is actually necessary, how much of it is beneficial, and when it becomes harmful, remain poorly understood. In practice, indiscriminate imagination can increase computation and even degrade performance by introducing misleading evidence. In this work, we present an in-depth analysis of test-time visual imagination as a controllable resource for spatial reasoning. We study when static visual evidence is sufficient, when imagination improves reasoning, and how excessive or unnecessary imagination affects accuracy and efficiency. To support this analysis, we introduce AVIC, an adaptive test-time framework with world models that explicitly reasons about the sufficiency of current visual evidence before selectively invoking and scaling visual imagination. Across spatial reasoning benchmarks (SAT, MMSI) and an embodied navigation benchmark (R2R), our results reveal clear scenarios where imagination is critical, marginal, or detrimental, and show that selective control can match or outperform fixed imagination strategies with substantially fewer world-model calls and language tokens. Overall, our findings highlight the importance of analyzing and controlling test-time imagination for efficient and reliable spatial reasoning."
  },
  {
    "date": "2026-02-09",
    "title": "When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents",
    "authors": "Jaylen Jones, Zhehao Zhang, Yuting Ning, Eric Fosler-Lussier, Pierre-Luc St-Charles, Yoshua Bengio, Dawn Song, Yu Su, Huan Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08235v1",
    "source": "arXiv",
    "abstract": "Although computer-use agents (CUAs) hold significant potential to automate increasingly complex OS workflows, they can demonstrate unsafe unintended behaviors that deviate from expected outcomes even under benign input contexts. However, exploration of this risk remains largely anecdotal, lacking concrete characterization and automated methods to proactively surface long-tail unintended behaviors under realistic CUA scenarios. To fill this gap, we introduce the first conceptual and methodological framework for unintended CUA behaviors, by defining their key characteristics, automatically eliciting them, and analyzing how they arise from benign inputs. We propose AutoElicit: an agentic framework that iteratively perturbs benign instructions using CUA execution feedback, and elicits severe harms while keeping perturbations realistic and benign. Using AutoElicit, we surface hundreds of harmful unintended behaviors from state-of-the-art CUAs such as Claude 4.5 Haiku and Opus. We further evaluate the transferability of human-verified successful perturbations, identifying persistent susceptibility to unintended behaviors across various other frontier CUAs. This work establishes a foundation for systematically analyzing unintended behaviors in realistic computer-use settings."
  },
  {
    "date": "2026-02-09",
    "title": "Distribution-Free Robust Functional Predict-Then-Optimize",
    "authors": "Yash Patel, Ambuj Tewari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08215v1",
    "source": "arXiv",
    "abstract": "The solution of PDEs in decision-making tasks is increasingly being undertaken with the help of neural operator surrogate models due to the need for repeated evaluation. Such methods, while significantly more computationally favorable compared to their numerical counterparts, fail to provide any calibrated notions of uncertainty in their predictions. Current methods approach this deficiency typically with ensembling or Bayesian posterior estimation. However, these approaches either require distributional assumptions that fail to hold in practice or lack practical scalability, limiting their applications in practice. We, therefore, propose a novel application of conformal prediction to produce distribution-free uncertainty quantification over the function spaces mapped by neural operators. We then demonstrate how such prediction regions enable a formal regret characterization if leveraged in downstream robust decision-making tasks. We further demonstrate how such posited robust decision-making tasks can be efficiently solved using an infinite-dimensional generalization of Danskin's Theorem and calculus of variations and empirically demonstrate the superior performance of our proposed method over more restrictive modeling paradigms, such as Gaussian Processes, across several engineering tasks."
  },
  {
    "date": "2026-02-09",
    "title": "Generative Regression for Left Ventricular Ejection Fraction Estimation from Echocardiography Video",
    "authors": "Jinrong Lv, Xun Gong, Zhaohuan Li, Weili Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08202v1",
    "source": "arXiv",
    "abstract": "Estimating Left Ventricular Ejection Fraction (LVEF) from echocardiograms constitutes an ill-posed inverse problem. Inherent noise, artifacts, and limited viewing angles introduce ambiguity, where a single video sequence may map not to a unique ground truth, but rather to a distribution of plausible physiological values. Prevailing deep learning approaches typically formulate this task as a standard regression problem that minimizes the Mean Squared Error (MSE). However, this paradigm compels the model to learn the conditional expectation, which may yield misleading predictions when the underlying posterior distribution is multimodal or heavy-tailed -- a common phenomenon in pathological scenarios. In this paper, we investigate the paradigm shift from deterministic regression toward generative regression. We propose the Multimodal Conditional Score-based Diffusion model for Regression (MCSDR), a probabilistic framework designed to model the continuous posterior distribution of LVEF conditioned on echocardiogram videos and patient demographic attribute priors. Extensive experiments conducted on the EchoNet-Dynamic, EchoNet-Pediatric, and CAMUS datasets demonstrate that MCSDR achieves state-of-the-art performance. Notably, qualitative analysis reveals that the generation trajectories of our model exhibit distinct behaviors in cases characterized by high noise or significant physiological variability, thereby offering a novel layer of interpretability for AI-aided diagnosis."
  },
  {
    "date": "2026-02-09",
    "title": "Interpretable Dynamic Network Modeling of Tensor Time Series via Kronecker Time-Varying Graphical Lasso",
    "authors": "Shingo Higashiguchi, Koki Kawabata, Yasuko Matsubara, Yasushi Sakurai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08197v1",
    "source": "arXiv",
    "abstract": "With the rapid development of web services, large amounts of time series data are generated and accumulated across various domains such as finance, healthcare, and online platforms. As such data often co-evolves with multiple variables interacting with each other, estimating the time-varying dependencies between variables (i.e., the dynamic network structure) has become crucial for accurate modeling. However, real-world data is often represented as tensor time series with multiple modes, resulting in large, entangled networks that are hard to interpret and computationally intensive to estimate. In this paper, we propose Kronecker Time-Varying Graphical Lasso (KTVGL), a method designed for modeling tensor time series. Our approach estimates mode-specific dynamic networks in a Kronecker product form, thereby avoiding overly complex entangled structures and producing interpretable modeling results. Moreover, the partitioned network structure prevents the exponential growth of computational time with data dimension. In addition, our method can be extended to stream algorithms, making the computational time independent of the sequence length. Experiments on synthetic data show that the proposed method achieves higher edge estimation accuracy than existing methods while requiring less computation time. To further demonstrate its practical value, we also present a case study using real-world data. Our source code and datasets are available at https://github.com/Higashiguchi-Shingo/KTVGL."
  },
  {
    "date": "2026-02-09",
    "title": "Anderson localization on quantum graphs coded by elements of a subshift of finite type",
    "authors": "Oleg Safronov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08196v1",
    "source": "arXiv",
    "abstract": "We study Schrödinger operators on quantum graphs where the number of edges between points is determined by orbits of a \"shift of finite type\". We prove Anderson localization for these systems."
  },
  {
    "date": "2026-02-09",
    "title": "Adoption of Large Language Models in Scrum Management: Insights from Brazilian Practitioners",
    "authors": "Mirko Perkusich, Danyllo Albuquerque, Allysson Allex Araújo, Matheus Paixão, Rohit Gheyi, Marcos Kalinowski, Angelo Perkusich",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08192v1",
    "source": "arXiv",
    "abstract": "Scrum is widely adopted in software project management due to its adaptability and collaborative nature. The recent emergence of Large Language Models (LLMs) has created new opportunities to support knowledge-intensive Scrum practices. However, existing research has largely focused on technical activities such as coding and testing, with limited evidence on the use of LLMs in management-related Scrum activities. In this study, we investigate the use of LLMs in Scrum management activities through a survey of 70 Brazilian professionals. Among them, 49 actively use Scrum, and 33 reported using LLM-based assistants in their Scrum practices. The results indicate a high level of proficiency and frequent use of LLMs, with 85% of respondents reporting intermediate or advanced proficiency and 52% using them daily. LLM use concentrates on exploring Scrum practices, with artifacts and events receiving targeted yet uneven support, whereas broader management tasks appear to be adopted more cautiously. The main benefits include increased productivity (78%) and reduced manual effort (75%). However, several critical risks remain, as respondents report 'almost correct' outputs (81%), confidentiality concerns (63%), and hallucinations during use (59%). This work provides one of the first empirical characterizations of LLM use in Scrum management, identifying current practices, quantifying benefits and risks, and outlining directions for responsible adoption and integration in Agile environments."
  },
  {
    "date": "2026-02-09",
    "title": "$\\star$-translation for Varsovian models",
    "authors": "Farmer Schlutzenberg",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08184v1",
    "source": "arXiv",
    "abstract": "The technique of $\\star$-translation is important in arguments calibrating the strengths of determinacy theories against large cardinals, for example in [9] and [1] in the paper's bibliography. It has also been used in analysing the internal theory of mice, for example in [5], [3], [6]. We give a detailed development of $\\star$-translation, slightly strengthening the large cardinal level in the development of [1]. We then develop a variant of $\\star$-translation for Varsovian models, in which certain extenders overlapping the Woodin cardinal are total, and used to directly induce extenders on the sequence of the $\\star$-translation (details for this component are missing from this draft). This variant was used in [3] and [6], where it was outlined but not developed in detail. We use the material to verify the star-translation hypothesis of [5] and deduce some self-iterability facts."
  },
  {
    "date": "2026-02-09",
    "title": "The enumeration of odd spanning trees in graphs",
    "authors": "Shaohan Xu, Kexiang Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08179v1",
    "source": "arXiv",
    "abstract": "A graph is odd if all of its vertices have odd degrees. In particular, an odd spanning tree in a connected graph is a spanning tree in which all vertices have odd degrees. In this paper we establish a unified technique to enumerate odd spanning trees of a graph $G$ in terms of a multivariable polynomial associated with $G$ and indeterminates $\\{x_{i}:v_i\\in V(G)\\}$. As applications, the enumerative formulas for odd spanning trees in complete graphs, complete multipartite graphs, almost complete graphs, complete split graphs and Ferrers graphs are, respectively, derived from our work."
  },
  {
    "date": "2026-02-09",
    "title": "Implicit regularization of normalized gradient descent",
    "authors": "Cédric Josz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08177v1",
    "source": "arXiv",
    "abstract": "How to find flat minima? We propose running normalized gradient descent, usually reserved for nonsmooth optimization, with sufficiently slowly diminishing step sizes. This induces implicit regularization towards flat minima if an appropriate Lyapunov functions exists in the gradient dynamics. Our analysis shows that implicit regularization is intrinsically a question of nonsmooth analysis, for which we deploy the full power of variational analysis and stratification theory."
  },
  {
    "date": "2026-02-09",
    "title": "A Causal Machine Learning Framework for Treatment Personalization in Clinical Trials: Application to Ulcerative Colitis",
    "authors": "Cristian Minoccheri, Sophia Tesic, Kayvan Najarian, Ryan Stidham",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08171v1",
    "source": "arXiv",
    "abstract": "Randomized controlled trials estimate average treatment effects, but treatment response heterogeneity motivates personalized approaches. A critical question is whether statistically detectable heterogeneity translates into improved treatment decisions -- these are distinct questions that can yield contradictory answers. We present a modular causal machine learning framework that evaluates each question separately: permutation importance identifies which features predict heterogeneity, best linear predictor (BLP) testing assesses statistical significance, and doubly robust policy evaluation measures whether acting on the heterogeneity improves patient outcomes. We apply this framework to patient-level data from the UNIFI maintenance trial of ustekinumab in ulcerative colitis, comparing placebo, standard-dose ustekinumab every 12 weeks, and dose-intensified ustekinumab every 8 weeks, using cross-fitted X-learner models with baseline demographics, medication history, week-8 clinical scores, laboratory biomarkers, and video-derived endoscopic features. BLP testing identified strong associations between endoscopic features and treatment effect heterogeneity for ustekinumab versus placebo, yet doubly robust policy evaluation showed no improvement in expected remission from incorporating endoscopic features, and out-of-fold multi-arm evaluation showed worse performance. Diagnostic comparison of prognostic contribution against policy value revealed that endoscopic scores behaved as disease severity markers -- improving outcome prediction in untreated patients but adding noise to treatment selection -- while clinical variables (fecal calprotectin, age, CRP) captured the decision-relevant variation. These results demonstrate that causal machine learning applications to clinical trials should include policy-level evaluation alongside heterogeneity testing."
  },
  {
    "date": "2026-02-09",
    "title": "TwinRL-VLA: Digital Twin-Driven Reinforcement Learning for Real-World Robotic Manipulation",
    "authors": "Qinwen Xu, Jiaming Liu, Rui Zhou, Shaojun Shi, Nuowei Han, Zhuoyang Liu, Chenyang Gu, Shuo Gu, Yang Yue, Gao Huang, Wenzhao Zheng, Sirui Han, Peng Jia, Shanghang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09023v1",
    "source": "arXiv",
    "abstract": "Despite strong generalization capabilities, Vision-Language-Action (VLA) models remain constrained by the high cost of expert demonstrations and insufficient real-world interaction. While online reinforcement learning (RL) has shown promise in improving general foundation models, applying RL to VLA manipulation in real-world settings is still hindered by low exploration efficiency and a restricted exploration space. Through systematic real-world experiments, we observe that the effective exploration space of online RL is closely tied to the data distribution of supervised fine-tuning (SFT). Motivated by this observation, we propose TwinRL, a digital twin-real-world collaborative RL framework designed to scale and guide exploration for VLA models. First, a high-fidelity digital twin is efficiently reconstructed from smartphone-captured scenes, enabling realistic bidirectional transfer between real and simulated environments. During the SFT warm-up stage, we introduce an exploration space expansion strategy using digital twins to broaden the support of the data trajectory distribution. Building on this enhanced initialization, we propose a sim-to-real guided exploration strategy to further accelerate online RL. Specifically, TwinRL performs efficient and parallel online RL in the digital twin prior to deployment, effectively bridging the gap between offline and online training stages. Subsequently, we exploit efficient digital twin sampling to identify failure-prone yet informative configurations, which are used to guide targeted human-in-the-loop rollouts on the real robot. In our experiments, TwinRL approaches 100% success in both in-distribution regions covered by real-world demonstrations and out-of-distribution regions, delivering at least a 30% speedup over prior real-world RL methods and requiring only about 20 minutes on average across four tasks."
  },
  {
    "date": "2026-02-09",
    "title": "$χ_{0}$: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies",
    "authors": "Checheng Yu, Chonghao Sima, Gangcheng Jiang, Hai Zhang, Haoguang Mai, Hongyang Li, Huijie Wang, Jin Chen, Kaiyang Wu, Li Chen, Lirui Zhao, Modi Shi, Ping Luo, Qingwen Bu, Shijia Peng, Tianyu Li, Yibo Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09021v1",
    "source": "arXiv",
    "abstract": "High-reliability long-horizon robotic manipulation has traditionally relied on large-scale data and compute to understand complex real-world dynamics. However, we identify that the primary bottleneck to real-world robustness is not resource scale alone, but the distributional shift among the human demonstration distribution, the inductive bias learned by the policy, and the test-time execution distribution -- a systematic inconsistency that causes compounding errors in multi-stage tasks. To mitigate these inconsistencies, we propose $χ_{0}$, a resource-efficient framework with effective modules designated to achieve production-level robustness in robotic manipulation. Our approach builds off three technical pillars: (i) Model Arithmetic, a weight-space merging strategy that efficiently soaks up diverse distributions of different demonstrations, varying from object appearance to state variations; (ii) Stage Advantage, a stage-aware advantage estimator that provides stable, dense progress signals, overcoming the numerical instability of prior non-stage approaches; and (iii) Train-Deploy Alignment, which bridges the distribution gap via spatio-temporal augmentation, heuristic DAgger corrections, and temporal chunk-wise smoothing. $χ_{0}$ enables two sets of dual-arm robots to collaboratively orchestrate long-horizon garment manipulation, spanning tasks from flattening, folding, to hanging different clothes. Our method exhibits high-reliability autonomy; we are able to run the system from arbitrary initial state for consecutive 24 hours non-stop. Experiments validate that $χ_{0}$ surpasses the state-of-the-art $π_{0.5}$ in success rate by nearly 250%, with only 20-hour data and 8 A100 GPUs. Code, data and models will be released to facilitate the community."
  },
  {
    "date": "2026-02-09",
    "title": "Raster2Seq: Polygon Sequence Generation for Floorplan Reconstruction",
    "authors": "Hao Phung, Hadar Averbuch-Elor",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09016v1",
    "source": "arXiv",
    "abstract": "Reconstructing a structured vector-graphics representation from a rasterized floorplan image is typically an important prerequisite for computational tasks involving floorplans such as automated understanding or CAD workflows. However, existing techniques struggle in faithfully generating the structure and semantics conveyed by complex floorplans that depict large indoor spaces with many rooms and a varying numbers of polygon corners. To this end, we propose Raster2Seq, framing floorplan reconstruction as a sequence-to-sequence task in which floorplan elements--such as rooms, windows, and doors--are represented as labeled polygon sequences that jointly encode geometry and semantics. Our approach introduces an autoregressive decoder that learns to predict the next corner conditioned on image features and previously generated corners using guidance from learnable anchors. These anchors represent spatial coordinates in image space, hence allowing for effectively directing the attention mechanism to focus on informative image regions. By embracing the autoregressive mechanism, our method offers flexibility in the output format, enabling for efficiently handling complex floorplans with numerous rooms and diverse polygon structures. Our method achieves state-of-the-art performance on standard benchmarks such as Structure3D, CubiCasa5K, and Raster2Graph, while also demonstrating strong generalization to more challenging datasets like WAFFLE, which contain diverse room structures and complex geometric variations."
  },
  {
    "date": "2026-02-09",
    "title": "ANCRe: Adaptive Neural Connection Reassignment for Efficient Depth Scaling",
    "authors": "Yilang Zhang, Bingcong Li, Niao He, Georgios B. Giannakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09009v1",
    "source": "arXiv",
    "abstract": "Scaling network depth has been a central driver behind the success of modern foundation models, yet recent investigations suggest that deep layers are often underutilized. This paper revisits the default mechanism for deepening neural networks, namely residual connections, from an optimization perspective. Rigorous analysis proves that the layout of residual connections can fundamentally shape convergence behavior, and even induces an exponential gap in convergence rates. Prompted by this insight, we introduce adaptive neural connection reassignment (ANCRe), a principled and lightweight framework that parameterizes and learns residual connectivities from the data. ANCRe adaptively reassigns residual connections with negligible computational and memory overhead ($<1\\%$), while enabling more effective utilization of network depth. Extensive numerical tests across pre-training of large language models, diffusion models, and deep ResNets demonstrate consistently accelerated convergence, boosted performance, and enhanced depth efficiency over conventional residual connections."
  },
  {
    "date": "2026-02-09",
    "title": "ShapeCond: Fast Shapelet-Guided Dataset Condensation for Time Series Classification",
    "authors": "Sijia Peng, Yun Xiong, Xi Chen, Yi Xie, Guanzhi Li, Yanwei Yu, Yangyong Zhu, Zhiqiang Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09008v1",
    "source": "arXiv",
    "abstract": "Time series data supports many domains (e.g., finance and climate science), but its rapid growth strains storage and computation. Dataset condensation can alleviate this by synthesizing a compact training set that preserves key information. Yet most condensation methods are image-centric and often fail on time series because they miss time-series-specific temporal structure, especially local discriminative motifs such as shapelets. In this work, we propose ShapeCond, a novel and efficient condensation framework for time series classification that leverages shapelet-based dataset knowledge via a shapelet-guided optimization strategy. Our shapelet-assisted synthesis cost is independent of sequence length: longer series yield larger speedups in synthesis (e.g., 29$\\times$ faster over prior state-of-the-art method CondTSC for time-series condensation, and up to 10,000$\\times$ over naively using shapelets on the Sleep dataset with 3,000 timesteps). By explicitly preserving critical local patterns, ShapeCond improves downstream accuracy and consistently outperforms all prior state-of-the-art time series dataset condensation methods across extensive experiments. Code is available at https://github.com/lunaaa95/ShapeCond."
  },
  {
    "date": "2026-02-09",
    "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
    "authors": "Haodong Li, Jingwei Wu, Quan Sun, Guopeng Li, Juanxi Tian, Huanyu Zhang, Yanlin Lai, Ruichuan An, Hongbo Peng, Yuhong Dai, Chenxi Li, Chunmei Qing, Jia Wang, Ziyang Meng, Zheng Ge, Xiangyu Zhang, Daxin Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09007v1",
    "source": "arXiv",
    "abstract": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench."
  },
  {
    "date": "2026-02-09",
    "title": "ARO: A New Lens On Matrix Optimization For Large Models",
    "authors": "Wenbo Gong, Javier Zazo, Qijun Luo, Puqian Wang, James Hensman, Chao Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09006v1",
    "source": "arXiv",
    "abstract": "Matrix-based optimizers have attracted growing interest for improving LLM training efficiency, with significant progress centered on orthogonalization/whitening based methods. While yielding substantial performance gains, a fundamental question arises: can we develop new paradigms beyond orthogonalization, pushing the efficiency frontier further? We present \\textbf{Adaptively Rotated Optimization (ARO}, a new matrix optimization framework that treats gradient rotation as a first class design principle. ARO accelerates LLM training by performing normed steepest descent in a rotated coordinate system, where the rotation is determined by a novel norm-informed policy. This perspective yields update rules that go beyond existing orthogonalization and whitening optimizers, improving sample efficiency in practice. To make comparisons reliable, we propose a rigorously controlled benchmarking protocol that reduces confounding and bias. Under this protocol, ARO consistently outperforms AdamW (by 1.3 $\\sim$1.35$\\times$) and orthogonalization methods (by 1.1$\\sim$1.15$\\times$) in LLM pretraining at up to 8B activated parameters, and up to $8\\times$ overtrain budget, without evidence of diminishing returns. Finally, we discuss how ARO can be reformulated as a symmetry-aware optimizer grounded in rotational symmetries of residual streams, motivating advanced designs that enable computationally efficient exploitation of cross-layer/cross module couplings."
  },
  {
    "date": "2026-02-09",
    "title": "Reverse Online Guessing Attacks on PAKE Protocols",
    "authors": "Eloise Christian, Tejas Gadwalkar, Arthur Azevedo de Amorim, Edward V. Zieglar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08993v1",
    "source": "arXiv",
    "abstract": "Though not yet widely deployed, password-authenticated key exchange (PAKE) protocols have been the subject of several recent standardization efforts, partly because of their resistance against various guessing attacks, but also because they do not require a public-key infrastructure (PKI), making them naturally resistant against PKI failures. The goal of this paper is to reevaluate the PAKE model by noting that the absence of a PKI -- or, more generally, of a mechanism aside from the password for authenticating the server -- makes such protocols vulnerable to reverse online guessing attacks, in which an adversary attempts to validate password guesses by impersonating a server. While their logic is similar to traditional guessing, where the attacker impersonates a client, reverse guessing poses a unique risk because the burden of detection is shifted to the clients, rendering existing defenses against traditional guessing moot. Our results demonstrate that reverse guessing is particularly effective when an adversary attacks clients indiscriminately, such as in phishing or password-spraying attacks, or for applications with automated login processes or a universal password, such as WPA3-SAE. Our analysis suggests that stakeholders should, by default, authenticate the server using more stringent measures than just the user's password, and that a password-only mode of operation should be a last resort against catastrophic security failures when other authentication mechanisms are not available."
  },
  {
    "date": "2026-02-09",
    "title": "Improving Detection of Rare Nodes in Hierarchical Multi-Label Learning",
    "authors": "Isaac Xu, Martin Gillis, Ayushi Sharma, Benjamin Misiuk, Craig J. Brown, Thomas Trappenberg",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08986v1",
    "source": "arXiv",
    "abstract": "In hierarchical multi-label classification, a persistent challenge is enabling model predictions to reach deeper levels of the hierarchy for more detailed or fine-grained classifications. This difficulty partly arises from the natural rarity of certain classes (or hierarchical nodes) and the hierarchical constraint that ensures child nodes are almost always less frequent than their parents. To address this, we propose a weighted loss objective for neural networks that combines node-wise imbalance weighting with focal weighting components, the latter leveraging modern quantification of ensemble uncertainties. By emphasizing rare nodes rather than rare observations (data points), and focusing on uncertain nodes for each model output distribution during training, we observe improvements in recall by up to a factor of five on benchmark datasets, along with statistically significant gains in $F_{1}$ score. We also show our approach aids convolutional networks on challenging tasks, as in situations with suboptimal encoders or limited data."
  },
  {
    "date": "2026-02-09",
    "title": "Beyond Transcripts: A Renewed Perspective on Audio Chaptering",
    "authors": "Fabian Retkowski, Maike Züfle, Thai Binh Nguyen, Jan Niehues, Alexander Waibel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08979v1",
    "source": "arXiv",
    "abstract": "Audio chaptering, the task of automatically segmenting long-form audio into coherent sections, is increasingly important for navigating podcasts, lectures, and videos. Despite its relevance, research remains limited and text-based, leaving key questions unresolved about leveraging audio information, handling ASR errors, and transcript-free evaluation. We address these gaps through three contributions: (1) a systematic comparison between text-based models with acoustic features, a novel audio-only architecture (AudioSeg) operating on learned audio representations, and multimodal LLMs; (2) empirical analysis of factors affecting performance, including transcript quality, acoustic features, duration, and speaker composition; and (3) formalized evaluation protocols contrasting transcript-dependent text-space protocols with transcript-invariant time-space protocols. Our experiments on YTSeg reveal that AudioSeg substantially outperforms text-based approaches, pauses provide the largest acoustic gains, and MLLMs remain limited by context length and weak instruction following, yet MLLMs are promising on shorter audio."
  },
  {
    "date": "2026-02-09",
    "title": "Contraction Metric Based Safe Reinforcement Learning Force Control for a Hydraulic Actuator with Real-World Training",
    "authors": "Lucca Maitan, Lucas Toschi, Cícero Zanette, Elisa G. Vergamini, Leonardo F. Santos, Thiago Boaventura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08977v1",
    "source": "arXiv",
    "abstract": "Force control in hydraulic actuators is notoriously difficult due to strong nonlinearities, uncertainties, and the high risks associated with unsafe exploration during learning. This paper investigates safe reinforcement learning (RL) for hy draulic force control with real-world training using contraction metric certificates. A data-driven model of a hydraulic actuator, identified from experimental data, is employed for simulation based pretraining of a Soft Actor-Critic (SAC) policy that adapts the PI gains of a feedback-linearization (FL) controller. To reduce instability during online training, we propose a quadratic-programming (QP) contraction filter that leverages a learned contraction metric to enforce approximate exponential convergence of trajectories, applying minimal corrections to the policy output. The approach is validated on a hydraulic test bench, where the RL controller is trained directly on hardware and benchmarked against a simulation-trained agent and a fixed-gain baseline. Experimental results show that real-hardware training improves force-tracking performance compared to both alternatives, while the contraction filter mitigates chattering and instabilities. These findings suggest that contraction-based certificates can enable safe RL in high force hydraulic systems, though robustness at extreme operating conditions remains a challenge."
  },
  {
    "date": "2026-02-09",
    "title": "Distributionally Robust Optimization via Generative Ambiguity Modeling",
    "authors": "Jiaqi Wen, Jianyi Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08976v1",
    "source": "arXiv",
    "abstract": "This paper studies Distributionally Robust Optimization (DRO), a fundamental framework for enhancing the robustness and generalization of statistical learning and optimization. An effective ambiguity set for DRO must involve distributions that remain consistent to the nominal distribution while being diverse enough to account for a variety of potential scenarios. Moreover, it should lead to tractable DRO solutions. To this end, we propose generative model-based ambiguity sets that capture various adversarial distributions beyond the nominal support space while maintaining consistency with the nominal distribution. Building on this generative ambiguity modeling, we propose DRO with Generative Ambiguity Set (GAS-DRO), a tractable DRO algorithm that solves the inner maximization over the parameterized generative model space. We formally establish the stationary convergence performance of GAS-DRO. We implement GAS-DRO with a diffusion model and empirically demonstrate its superior Out-of-Distribution (OOD) generalization performance in ML tasks."
  },
  {
    "date": "2026-02-09",
    "title": "WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models",
    "authors": "Yu Shang, Zhuohang Li, Yiding Ma, Weikang Su, Xin Jin, Ziyou Wang, Xin Zhang, Yinzhou Tang, Chen Gao, Wei Wu, Xihui Liu, Dhruv Shah, Zhaoxiang Zhang, Zhibo Chen, Jun Zhu, Yonghong Tian, Tat-Seng Chua, Wenwu Zhu, Yong Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08971v1",
    "source": "arXiv",
    "abstract": "While world models have emerged as a cornerstone of embodied intelligence by enabling agents to reason about environmental dynamics through action-conditioned prediction, their evaluation remains fragmented. Current evaluation of embodied world models has largely focused on perceptual fidelity (e.g., video generation quality), overlooking the functional utility of these models in downstream decision-making tasks. In this work, we introduce WorldArena, a unified benchmark designed to systematically evaluate embodied world models across both perceptual and functional dimensions. WorldArena assesses models through three dimensions: video perception quality, measured with 16 metrics across six sub-dimensions; embodied task functionality, which evaluates world models as data engines, policy evaluators, and action planners integrating with subjective human evaluation. Furthermore, we propose EWMScore, a holistic metric integrating multi-dimensional performance into a single interpretable index. Through extensive experiments on 14 representative models, we reveal a significant perception-functionality gap, showing that high visual quality does not necessarily translate into strong embodied task capability. WorldArena benchmark with the public leaderboard is released at https://worldarena.ai, providing a framework for tracking progress toward truly functional world models in embodied AI."
  },
  {
    "date": "2026-02-09",
    "title": "Hyperactive Minority Alter the Stability of Community Notes",
    "authors": "Jacopo Nudo, Eugenio Nerio Nemmi, Edoardo Loru, Alessandro Mei, Walter Quattrociocchi, Matteo Cinelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08970v1",
    "source": "arXiv",
    "abstract": "As platforms increasingly scale down professional fact-checking, community-based alternatives are promoted as more transparent and democratic. The main substitute being proposed is community-based contextualization, most notably Community Notes on X, where users write annotations and collectively rate their helpfulness under a consensus-oriented algorithm. This shift raises a basic empirical question: to what extent do users' social dynamics affect the emergence of Community Notes? We address this question by characterizing participation and political behavior, using the full public release of notes and ratings (between 2021 and 2025). We show that contribution activity is highly concentrated: a small minority of users accounts for a disproportionate share of ratings. Crucially, these high-activity contributors are not neutral volunteers: they are selective in the content they engage with and substantially more politically polarized than the overall contributor population. We replicate the notes' emergence process by integrating the open-source implementation of the Community Notes consensus algorithm used in production. This enables us to conduct counterfactual simulations that modify the display status of notes by varying the pool of raters. Our results reveal that the system is structurally unstable: the emergence and visibility of notes often depend on the behavior of a few dozen highly active users, and even minor perturbations in their participation can lead to markedly different outcomes. In sum, rather than decentralizing epistemic authority, community-based fact-checking on X reconfigures it, concentrating substantial power in the hands of a small, polarized group of highly active contributors."
  },
  {
    "date": "2026-02-09",
    "title": "Symplectic excision and distance rigidity",
    "authors": "Yoel Groman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08969v1",
    "source": "arXiv",
    "abstract": "We consider various notions of completeness in symplectic topology and ask two related questions. Does a complete open symplectic manifold remain complete after excising a subset? Can two sets be made arbitrarily far apart by adjusting the almost complex structure within an appropriate class of complete almost complex structures? We find rigidity phenomena when the excised set is a symplectic hypersurface. These arise from certain open Gromov-Witten invariants. We contrast this with flexibility that often occurs when the excised set is coisotropic. We also briefly touch on the opposite question of obstructions to existence of a complete symplectic structure compatible with a given complex structure. For the notion of completeness we first consider the traditional notion of geometric boundedness. We then introduce a broader notion of normalized completeness, related to the notion of intermittent boundedness of \\cite{GromanFloerOpen}, which depends on $C^0$ properties and is a contractible condition. Finally we speculate about the relation to a Fukaya-categorical notion of completeness."
  },
  {
    "date": "2026-02-09",
    "title": "Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning",
    "authors": "John Gardiner, Orlando Romero, Brendan Tivnan, Nicolò Dal Fabbro, George J. Pappas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08965v1",
    "source": "arXiv",
    "abstract": "The inability to communicate poses a major challenge to coordination in multi-agent reinforcement learning (MARL). Prior work has explored correlating local policies via shared randomness, sometimes in the form of a correlation device, as a mechanism to assist in decentralized decision-making. In contrast, this work introduces the first framework for training MARL agents to exploit shared quantum entanglement as a coordination resource, which permits a larger class of communication-free correlated policies than shared randomness alone. This is motivated by well-known results in quantum physics which posit that, for certain single-round cooperative games with no communication, shared quantum entanglement enables strategies that outperform those that only use shared randomness. In such cases, we say that there is quantum advantage. Our framework is based on a novel differentiable policy parameterization that enables optimization over quantum measurements, together with a novel policy architecture that decomposes joint policies into a quantum coordinator and decentralized local actors. To illustrate the effectiveness of our proposed method, we first show that we can learn, purely from experience, strategies that attain quantum advantage in single-round games that are treated as black box oracles. We then demonstrate how our machinery can learn policies with quantum advantage in an illustrative multi-agent sequential decision-making problem formulated as a decentralized partially observable Markov decision process (Dec-POMDP)."
  },
  {
    "date": "2026-02-09",
    "title": "A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents",
    "authors": "Raghu Arghal, Fade Chen, Niall Dalton, Evgenii Kortukov, Calum McNamara, Angelos Nalmpantis, Moksh Nirvaan, Gabriele Sarti, Mario Giulianelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08964v1",
    "source": "arXiv",
    "abstract": "Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models' internal representations. As a case study, we examine an LLM agent navigating a 2D grid world toward a goal state. Behaviourally, we evaluate the agent against an optimal policy across varying grid sizes, obstacle densities, and goal structures, finding that performance scales with task difficulty while remaining robust to difficulty-preserving transformations and complex goal structures. We then use probing methods to decode the agent's internal representations of the environment state and its multi-step action plans. We find that the LLM agent non-linearly encodes a coarse spatial map of the environment, preserving approximate task-relevant cues about its position and the goal location; that its actions are broadly consistent with these internal representations; and that reasoning reorganises them, shifting from broader environment structural cues toward information supporting immediate action selection. Our findings support the view that introspective examination is required beyond behavioural evaluations to characterise how agents represent and pursue their objectives."
  },
  {
    "date": "2026-02-09",
    "title": "Reduced-order Control and Geometric Structure of Learned Lagrangian Latent Dynamics",
    "authors": "Katharina Friedl, Noémie Jaquier, Seungyeon Kim, Jens Lundell, Danica Kragic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08963v1",
    "source": "arXiv",
    "abstract": "Model-based controllers can offer strong guarantees on stability and convergence by relying on physically accurate dynamic models. However, these are rarely available for high-dimensional mechanical systems such as deformable objects or soft robots. While neural architectures can learn to approximate complex dynamics, they are either limited to low-dimensional systems or provide only limited formal control guarantees due to a lack of embedded physical structure. This paper introduces a latent control framework based on learned structure-preserving reduced-order dynamics for high-dimensional Lagrangian systems. We derive a reduced tracking law for fully actuated systems and adopt a Riemannian perspective on projection-based model-order reduction to study the resulting latent and projected closed-loop dynamics. By quantifying the sources of modeling error, we derive interpretable conditions for stability and convergence. We extend the proposed controller and analysis to underactuated systems by introducing learned actuation patterns. Experimental results on simulated and real-world systems validate our theoretical investigation and the accuracy of our controllers."
  },
  {
    "date": "2026-02-09",
    "title": "Modeling 3D Pedestrian-Vehicle Interactions for Vehicle-Conditioned Pose Forecasting",
    "authors": "Guangxun Zhu, Xuan Liu, Nicolas Pugeault, Chongfeng Wei, Edmond S. L. Ho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08962v1",
    "source": "arXiv",
    "abstract": "Accurately predicting pedestrian motion is crucial for safe and reliable autonomous driving in complex urban environments. In this work, we present a 3D vehicle-conditioned pedestrian pose forecasting framework that explicitly incorporates surrounding vehicle information. To support this, we enhance the Waymo-3DSkelMo dataset with aligned 3D vehicle bounding boxes, enabling realistic modeling of multi-agent pedestrian-vehicle interactions. We introduce a sampling scheme to categorize scenes by pedestrian and vehicle count, facilitating training across varying interaction complexities. Our proposed network adapts the TBIFormer architecture with a dedicated vehicle encoder and pedestrian-vehicle interaction cross-attention module to fuse pedestrian and vehicle features, allowing predictions to be conditioned on both historical pedestrian motion and surrounding vehicles. Extensive experiments demonstrate substantial improvements in forecasting accuracy and validate different approaches for modeling pedestrian-vehicle interactions, highlighting the importance of vehicle-aware 3D pose prediction for autonomous driving. Code is available at: https://github.com/GuangxunZhu/VehCondPose3D"
  },
  {
    "date": "2026-02-09",
    "title": "Dimensional regimes in Kolmogorov Flow",
    "authors": "Melisa Y. Vinograd, Joaquin Cullen, Patricio Clark di Leoni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08960v1",
    "source": "arXiv",
    "abstract": "We study the dimensionality of two-dimensional Kolmogorov flows over a wide range of Reynolds numbers and forcing wavenumbers $k_f=\\{2,4,8\\}$ using two complementary approaches: convolutional autoencoders and a Kaplan-Yorke estimation based on Lyapunov analysis. As the Reynolds number increases, two distinct transitions are observed: the first corresponds to the destabilization of a periodic orbit, while the second marks the saturation of the large-scale motions. When expressed in terms of the forcing Reynolds number, these transitions occur at nearly the same value for all forcing wavenumbers, suggesting a universal scaling with respect to the forcing scale. By filtering the data to retain only the large-scale range ($k < k_f$), we show that the dimensionality estimated by the autoencoders also saturates at the second transition, implying that once the large scales are fully developed, the subsequent increase in dynamical activity occurs predominantly at smaller scales. At higher Reynolds numbers, the Kaplan-Yorke dimension ceases to grow, revealing its limited sensitivity to the nonlinear interactions that dominate in this regime. Both the Kaplan-Yorke saturation dimension and the filtered large-scale dimensionalities exhibit a linear dependence on $k_f$, indicating that the number of active degrees of freedom scales with the forcing scale rather than with the total number of available Fourier modes."
  },
  {
    "date": "2026-02-09",
    "title": "On the pseudorandom properties of filtered Legendre symbol sequences using three polynomials",
    "authors": "Katalin Gyarmati, Károly Müllner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08957v1",
    "source": "arXiv",
    "abstract": "The primary objective of this section is to demonstrate that the actual pseudorandom measures of our construction are significantly smaller than the theoretical upper bounds derived from the Weil theorem. Regarding the family of sequences, we note that the construction $E_{f,g,h}$ allows for a large variety of sequences by choosing different triples of polynomials. While the detailed analysis of the cross-correlation measure of such a family is a challenging problem and lies beyond the scope of the present paper, the structure of the construction suggests that sequences generated by different polynomials will remain nearly orthogonal. Indeed, since each sequence is built from distinct Legendre symbol sequences with proven low correlation, their combinations are expected to maintain the same level of independence."
  },
  {
    "date": "2026-02-09",
    "title": "CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute",
    "authors": "Chen Jin, Ryutaro Tanno, Tom Diethe, Philip Teare",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08948v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers."
  },
  {
    "date": "2026-02-09",
    "title": "Derived algebras on formal stacks and prismatic gauges",
    "authors": "Shubhankar Sahai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08942v1",
    "source": "arXiv",
    "abstract": "This paper studies how the theory of derived algebras (in the sense of Bhatt-Mathew and Raksit) interacts with formal derived geometry, specifically the formal derived stacks which show up in the theory of prismatization. As an application we prove some classification theorems for derived algebras in quasi-coherent sheaves on a certain class of filtered \\emph{formal} stacks, which includes those whose quasi-coherent sheaves are prismatic gauges over a perfectoid ring. Along the way, among other things, we study the behavior of derived algebras along schematic quasi-affine morphisms in derived geometry, and for example, classify derived algebras on the source as precisely those derived algebras on the target which receive a map from the pushforward of the structure sheaf of the source. We also indicate how to extend some of our results to (formal) classifying stacks of diagonalizable group schemes. As an aside, we also show some classification theorems even for quasi-coherent sheaves on formal stacks which (to our knowledge) weren't available in the literature on derived geometry previously. These results are motivated by forthcoming work of the author but hoped to be generally useful."
  },
  {
    "date": "2026-02-09",
    "title": "Provably robust learning of regression neural networks using $β$-divergences",
    "authors": "Abhik Ghosh, Suryasis Jana",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08933v1",
    "source": "arXiv",
    "abstract": "Regression neural networks (NNs) are most commonly trained by minimizing the mean squared prediction error, which is highly sensitive to outliers and data contamination. Existing robust training methods for regression NNs are often limited in scope and rely primarily on empirical validation, with only a few offering partial theoretical guarantees. In this paper, we propose a new robust learning framework for regression NNs based on the $β$-divergence (also known as the density power divergence) which we call `rRNet'. It applies to a broad class of regression NNs, including models with non-smooth activation functions and error densities, and recovers the classical maximum likelihood learning as a special case. The rRNet is implemented via an alternating optimization scheme, for which we establish convergence guarantees to stationary points under mild, verifiable conditions. The (local) robustness of rRNet is theoretically characterized through the influence functions of both the parameter estimates and the resulting rRNet predictor, which are shown to be bounded for suitable choices of the tuning parameter $β$, depending on the error density. We further prove that rRNet attains the optimal 50\\% asymptotic breakdown point at the assumed model for all $β\\in(0, 1]$, providing a strong global robustness guarantee that is largely absent for existing NN learning methods. Our theoretical results are complemented by simulation experiments and real-data analyses, illustrating practical advantages of rRNet over existing approaches in both function approximation problems and prediction tasks with noisy observations."
  },
  {
    "date": "2026-02-09",
    "title": "Online monotone density estimation and log-optimal calibration",
    "authors": "Rohan Hore, Ruodu Wang, Aaditya Ramdas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08927v1",
    "source": "arXiv",
    "abstract": "We study the problem of online monotone density estimation, where density estimators must be constructed in a predictable manner from sequentially observed data. We propose two online estimators: an online analogue of the classical Grenander estimator, and an expert aggregation estimator inspired by exponential weighting methods from the online learning literature. In the well-specified stochastic setting, where the underlying density is monotone, we show that the expected cumulative log-likelihood gap between the online estimators and the true density admits an $O(n^{1/3})$ bound. We further establish a $\\sqrt{n\\log{n}}$ pathwise regret bound for the expert aggregation estimator relative to the best offline monotone estimator chosen in hindsight, under minimal regularity assumptions on the observed sequence. As an application of independent interest, we show that the problem of constructing log-optimal p-to-e calibrators for sequential hypothesis testing can be formulated as an online monotone density estimation problem. We adapt the proposed estimators to build empirically adaptive p-to-e calibrators and establish their optimality. Numerical experiments illustrate the theoretical results."
  },
  {
    "date": "2026-02-09",
    "title": "\"I Don't Trust Any Professional Research Tool\": A Re-Imagination of Knowledge Production Workflows by, with, and for Blind and Low-Vision Researchers",
    "authors": "Omar Khan, JooYoung Seo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08925v1",
    "source": "arXiv",
    "abstract": "Research touts universal participation through accessibility initiatives, yet blind and low-vision (BLV) researchers face systematic exclusion as visual representations dominate modern research workflows. To materialize inclusive processes, we, as BLV researchers, examined how our peers combat inaccessible infrastructures. Through an explanatory sequential mixed-methods approach, we conducted a cross-sectional, observational survey (n=57) and follow-up semi-structured interviews (n=15), analyzing open-ended data using reflexive thematic analysis and framing findings through activity theory to highlight research's systemic shortcomings. We expose how BLV researchers sacrifice autonomy and shoulder physical burdens, with nearly one-fifth unable to independently perform literature review or evaluate visual outputs, delegating tasks to sighted colleagues or relying on AI-driven retrieval to circumvent fatigue. Researchers also voiced frustration with specialized tools, citing developers' performative responses and losing deserved professional accolades. We seek follow-through on research's promises through design recommendations that reconceptualize accessibility as fundamental to successful research and supporting BLV scholars' workflows."
  },
  {
    "date": "2026-02-09",
    "title": "Zero-freeness of a multivariate monomer-dimer-cycle polynomial on bounded-degree graphs",
    "authors": "Gabriel Coutinho, Paula M. S. Fialho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08919v1",
    "source": "arXiv",
    "abstract": "We initiate the study of a multivariate graph polynomial $Φ_G(x,y,z)$ that interpolates between classical counting polynomials for matchings and for cycle structures arising in the Harary--Sachs expansion of the characteristic polynomial. We focus on analytic properties and computational consequences. Our main contribution is an explicit, degree-uniform zero-free region for $Φ_G$ on bounded-degree graphs, obtained via the Fernández--Procacci convergence criterion for abstract polymer gases."
  },
  {
    "date": "2026-02-09",
    "title": "GEMSS: A Variational Bayesian Method for Discovering Multiple Sparse Solutions in Classification and Regression Problems",
    "authors": "Kateřina Henclová, Václav Šmídl",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08913v1",
    "source": "arXiv",
    "abstract": "Selecting interpretable feature sets in underdetermined ($n \\ll p$) and highly correlated regimes constitutes a fundamental challenge in data science, particularly when analyzing physical measurements. In such settings, multiple distinct sparse subsets may explain the response equally well. Identifying these alternatives is crucial for generating domain-specific insights into the underlying mechanisms, yet conventional methods typically isolate a single solution, obscuring the full spectrum of plausible explanations. We present GEMSS (Gaussian Ensemble for Multiple Sparse Solutions), a variational Bayesian framework specifically designed to simultaneously discover multiple, diverse sparse feature combinations. The method employs a structured spike-and-slab prior for sparsity, a mixture of Gaussians to approximate the intractable multimodal posterior, and a Jaccard-based penalty to further control solution diversity. Unlike sequential greedy approaches, GEMSS optimizes the entire ensemble of solutions within a single objective function via stochastic gradient descent. The method is validated on a comprehensive benchmark comprising 128 synthetic experiments across classification and regression tasks. Results demonstrate that GEMSS scales effectively to high-dimensional settings ($p=5000$) with sample size as small as $n = 50$, generalizes seamlessly to continuous targets, handles missing data natively, and exhibits remarkable robustness to class imbalance and Gaussian noise. GEMSS is available as a Python package 'gemss' at PyPI. The full GitHub repository at https://github.com/kat-er-ina/gemss/ also includes a free, easy-to-use application suitable for non-coders."
  },
  {
    "date": "2026-02-09",
    "title": "Structural coarse-graining enables noise-robust functional connectivity and reveals hidden inter-subject variability",
    "authors": "Izaro Fernandez-Iriondo, Antonio Jimenez-Marin, Jesus Cortes, Pablo Villegas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08910v1",
    "source": "arXiv",
    "abstract": "Functional connectivity estimates are highly sensitive to analysis choices and can be dominated by noise when the number of sampled time points is small relative to network dimensionality. This issue is particularly acute in fMRI, where scan resolution is limited. Because scan duration is constrained by practical factors (e.g., motion and fatigue), many datasets remain statistically underpowered for high-dimensional correlation estimation. We introduce a framework that combines diffusion-based structural coarse-graining with spectral noise filtering to recover statistically reliable functional networks from temporally limited data. The method reduces network dimensionality by grouping regions according to diffusion-defined communication. This produces coarse-grained networks with dimensions compatible with available time points, enabling random matrix filtering of noise-dominated modes. We benchmark three common FC pipelines against our approach. We find that raw-signal correlations are strongly influenced by non-stationary fluctuations that can reduce apparent inter-subject variability under limited sampling conditions. In contrast, our pipeline reveals a broader, multimodal landscape of inter-subject variability. These large-scale organization patterns are largely obscured by standard pipelines. Together, these results provide a practical route to reliable functional networks under realistic sampling constraints. This strategy helps separate noise-driven artifacts from reproducible patterns of human brain variability."
  },
  {
    "date": "2026-02-09",
    "title": "Switching Point Optimization for Abstract Parabolic Equations",
    "authors": "Christian Meyer, Alimhan Musalatov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08906v1",
    "source": "arXiv",
    "abstract": "This work is concerned with a switching point optimization problem governed by a semilinear parabolic equation in abstract function spaces. It is shown that the switching-point-to-control mapping is continuously Fréchet-differentiable when considered with values in the dual of Hölder continuous functions in time. By treating the state equation in weak form based on the concept of maximal parabolic regularity, one can then show that the reduced objective is continuously differentiable w.r.t.\\ the switching points which allows to use gradient-based method like the proximal gradient method for its minimization. In order to apply the known convergence results of this method, the gradient of the reduced objective must be Lipschitz continuous, which requires additional assumptions on the data. Numerical experiments confirm our theoretical findings, but also illustrate that such a method will in general not be able to solve the problem up to global optimality due to the non-convex nature of the switching-point-to-control map."
  },
  {
    "date": "2026-02-09",
    "title": "Denoise Stepwise Signals by Diffusion Model Based Approach",
    "authors": "Xingdi Tong, Chenyu Wen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08904v1",
    "source": "arXiv",
    "abstract": "Stepwise signals are ubiquitous in single-molecule detections, where abrupt changes in signal levels typically correspond to molecular conformational changes or state transitions. However, these features are inevitably obscured by noise, leading to uncertainty in estimating both signal levels and transition points. Traditional frequency-domain filtering is ineffective for denoising stepwise signals, as edge-related high-frequency components strongly overlap with noise. Although Hidden Markov Model-based approaches are widely used, they rely on stationarity assumptions and are not specifically designed for signal denoising. Here, we propose a diffusion model-based algorithm for stepwise signal denoising, named the Stepwise Signal Diffusion Model (SSDM). During training, SSDM learns the statistical structure of stepwise signals via a forward diffusion process that progressively adds noise. In the following reverse process, the model reconstructs clean signals from noisy observations, integrating a multi-scale convolutional network with an attention mechanism. Training data are generated by simulating stepwise signals through a Markov process with additive Gaussian noise. Across a broad range of signal-to-noise ratios, SSDM consistently outperforms traditional methods in both signal level reconstruction and transition point detection. Its effectiveness is further demonstrated on experimental data from single-molecule Forster Resonance Energy Transfer and nanopore DNA translocation measurements. Overall, SSDM provides a general and robust framework for recovering stepwise signals in various single-molecule detections and other physical systems exhibiting discrete state transitions."
  },
  {
    "date": "2026-02-09",
    "title": "Anisotropy, frustration and saddle point in the twisted Kagome antiferromagnet ErPdPb",
    "authors": "Resham Babu Regmi, Sk Jamaluddin, Y. Lee, Hari Bhandari, Po-Hao Chang, Peter E. Siegfried, Abhijeet Nayak, Mohamed El Gazzah, Bence G. Márkus, Anna Nyáry, Zachary T. Messegee, Miya P. Zhao, Xiaoyan Tan, László Forró, Liqin Ke, Igor I. Mazin, Nirmal J. Ghimire",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08900v1",
    "source": "arXiv",
    "abstract": "The kagome lattice, with its inherent geometric frustration, provides a rich platform for exploring intriguing magnetic phenomena and topological electronic structures. In reduced-symmetry structures, such as twisted kagome systems involving rare earth elements, additional anisotropy can arise, enabling intriguing properties including spin-ice states, magnetocaloric effects, noncollinear magnetic ordering, and anomalous Hall effect. Here, we report the synthesis of single crystals of ErPdPb, which features a twisted kagome lattice net of Er atoms within the hexagonal ZrNiAl-type structure, and we investigate its magnetic, electronic, and thermal properties. The material exhibits antiferromagnetic ordering below 2.2 K, consistently observed in magnetic, transport, and heat capacity measurements. Magnetization measurements reveal 1/3 metamagnetic steps along the c-axis below the Néel temperature, suggesting an Ising-spin-like state on the twisted kagome lattice. A pronounced anisotropy between in-plane and out-of-plane resistivity is observed throughout the temperature range of 1.8-300 K, and the compound exhibits a significant frustration index of 13.6 (12.7) along the c-axis (ab-plane). Heat capacity measurements show a broad hump at 2.2 K, with an additional increase below 0.5 K. The anisotropic magnetic properties are further explored through density functional theory (DFT) calculations, which suggest strong easy-axis anisotropy, consistent with experimental magnetic measurements and crystal-field model expectations, and quasi-one-dimensional bands and a spin-split saddle point at the zone center."
  },
  {
    "date": "2026-02-09",
    "title": "Discovery of a double white dwarf in the Galactic globular cluster NGC 6397",
    "authors": "Fabian Göttgens, Marilyn Latour, Ulrich Heber, Sebastian Kamann, Kyle Kremer, Sven Martens, Stefan Dreizler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08898v1",
    "source": "arXiv",
    "abstract": "Binaries in the cores of globular clusters are known to prevent the gravitational collapse of the cluster, and simulations predict that the core of NGC 6397 contains a large number of white dwarfs (WDs), of which many are expected to be part of a binary system. In this work, we report the discovery of a compact binary system consisting of two WDs in the centre of the Galactic globular cluster NGC 6397. The system, known in the literature as NF1, was observed as part of a MUSE radial-velocity survey aiming at characterizing the binary population in the centre of NGC 6397. The spectral analysis of NF1 provides an effective temperature of 16000 K and a surface gravity (log g) of 5.72 (cgs), which is consistent with an extremely low-mass He-core WD nature. This is further supported by the mass of 0.23 +/- 0.03 Msun obtained from fitting the star's spectral energy distribution using its HST magnitude in various filters. The system has a circular orbit with a period of 0.54 days. The radial velocities show a large semi-amplitude of 200 km/s, implying a minimum mass of 0.78 Msun for the invisible companion, which is likely another WD, or a neutron star if the inclination of the system is smaller than about 50 deg. Some significant residuals in radial velocity remain with our best orbital solution and we tested whether a model with a third body can explain these deviations. While this possibility seems promising, additional measurements are needed to confirm whether the star is actually part of a triple system."
  },
  {
    "date": "2026-02-09",
    "title": "Chaos, the Critical Phenomenon in Phase Space: Feigenbaum Constants and Critical Exponents",
    "authors": "Yonghui Xia, Hongtao Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08895v1",
    "source": "arXiv",
    "abstract": "Chaos in both dissipative systems and conservative systems is investigated on the approach of renormalization group. It is found that the chaos is regarded as the critical phenomenon of equilibrium statistics in phase space. The two Feigenbaum constants in the period-doubling bifurcation systems correspond to two independent critical exponents, which are universal and can be adopted to distinguish the classes of chaos. For the conservative systems, due to the critical nature of the chaos, the isolated systems with different parameters are correlated in the phase space, and therefore the isolated system is no longer isolated in the phase space. The information of conservative systems is irreversibly lost over time, which leads to the increase entropy in an isolated system, and the contradiction between the second law of thermodynamics and the reversibility of isolated systems can be resolved."
  },
  {
    "date": "2026-02-09",
    "title": "Scalable Delphi: Large Language Models for Structured Risk Estimation",
    "authors": "Tobias Lorenz, Mario Fritz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08889v1",
    "source": "arXiv",
    "abstract": "Quantitative risk assessment in high-stakes domains relies on structured expert elicitation to estimate unobservable properties. The gold standard - the Delphi method - produces calibrated, auditable judgments but requires months of coordination and specialist time, placing rigorous risk assessment out of reach for most applications. We investigate whether Large Language Models (LLMs) can serve as scalable proxies for structured expert elicitation. We propose Scalable Delphi, adapting the classical protocol for LLMs with diverse expert personas, iterative refinement, and rationale sharing. Because target quantities are typically unobservable, we develop an evaluation framework based on necessary conditions: calibration against verifiable proxies, sensitivity to evidence, and alignment with human expert judgment. We evaluate in the domain of AI-augmented cybersecurity risk, using three capability benchmarks and independent human elicitation studies. LLM panels achieve strong correlations with benchmark ground truth (Pearson r=0.87-0.95), improve systematically as evidence is added, and align with human expert panels - in one comparison, closer to a human panel than the two human panels are to each other. This demonstrates that LLM-based elicitation can extend structured expert judgment to settings where traditional methods are infeasible, reducing elicitation time from months to minutes."
  },
  {
    "date": "2026-02-09",
    "title": "Weak and reversed magnetic shear effects on internal kink and fishbone modes",
    "authors": "Weikang Cai, Ping Zhu, Zhi Zhang, Shiwei Xue, Sui Wan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08884v1",
    "source": "arXiv",
    "abstract": "Advanced tokamak scenarios often feature weak or reversed magnetic shear configurations. In this study, the hybrid kinetic-MHD model implemented in the NIMROD code is used to investigate the effects of reversed magnetic shear on internal kink and fishbone mode in a circular shaped limiter tokamak. In the absence of energetic particles (EPs), the mode growth rate initially increases and then decreases as the magnetic shear changes from positive to negative, indicating stabilizing effects of the reversed magnetic shear on the internal kink mode. In the presence of EPs, when the reversed magnetic shear region is sufficiently narrow, the transition from internal kink/fishbone modes to double kink/fishbone modes takes place, and the stabilizing effects of the reversed magnetic shear can significantly dominate the destabilization of EPs. For non-resonant modes, the EP beta fraction $β_f$ for excitation increases with $q_{min}$, concurrent with progressively lower growth rates in non-resonant fishbone modes. When the equilibrium profile has an internal transport barrier (ITB), broader ITB widths suppress internal kink modes more effectively, whereas steeper temperature gradients strengthen EP stabilization."
  },
  {
    "date": "2026-02-09",
    "title": "A mapping method of age estimation for binary stars: Application to the $α$ Centauri system A and B",
    "authors": "F. Thévenin, V. A. Baturin, A. V. Oreshina, P. Morel, S. V. Ayukov, L. Bigot, A. B. Gorshkov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08879v1",
    "source": "arXiv",
    "abstract": "Given the wealth of data provided by Gaia and the upcoming PLATO mission, it is essential to improve stellar models to obtain accurate stellar ages. Our objective is to apply a mapping technique to estimate the age of a system and the initial chemical composition. We also evaluate the influence of observational uncertainties in mass and heavy-element mixtures on results. We applied an inverse calibration method to the evolution of a multiple stellar system, assuming that the stars share the same age and initial chemical composition. This approach determines age, the initial mass fractions of helium ($Y_{ini}$) and heavy elements ($Z_{ini}$), as well as the convective mixing-length parameters ($α_A $ and $α_B$). It uses the observed luminosities ($L_A$ and $L_B$), radii ($R_A$ and $R_B$), and surface chemical compositions ($Z/X_A$ and $Z/X_B$). We used the most recent observational data for $M$, $R$, $L$, and $[Fe/H]$ of $α$ Centauri A and B as input data for our method. We compared two assumptions for the $Z/X$ ratio, following the results for the solar composition. For an assumed high solar $Z/X_\\odot =0.0245$, we obtain an age of $7.8 \\pm 0.6$ Ga, $Y_{ini} = 0.284 \\pm 0.004$, and $Z_{ini} = 0.0335 \\pm 0.0015$. For a low solar $Z/X_\\odot = 0.0181$, the derived age is $8.7 \\pm 0.6$ Ga, $Y_{ini} = 0.267 \\pm 0.008$, and $Z_{ini} = 0.025 \\pm 0.002$. Observational errors in the stellar masses of $\\pm$0.002 lead to an age error of 0.6 Ga. Overshooting of $0.05-0.20H_p$ at the boundary of the convective core increases the age by $0.6-2.1$ Ga. Models with higher $Z/X$ and radiative cores, with ages of $7.2-7.8$ Ga, appear preferable and show better agreement with the observed asteroseismic frequencies."
  },
  {
    "date": "2026-02-09",
    "title": "On medial Latin quandles and affine modules",
    "authors": "Luc Ta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08875v1",
    "source": "arXiv",
    "abstract": "In this note, we show that the category of Latin (resp. commutative) medial quandles is equivalent to the category of affine modules over a certain Laurent polynomial ring (resp. the dyadic rationals). As applications, we describe free objects in these categories and obtain a structure theorem for finitely generated medial commutative quandles. We also characterize racks whose duals are commutative. Collectively, this solves two open problems of Bardakov and Elhamdadi (arXiv:2601.07057v2)."
  },
  {
    "date": "2026-02-09",
    "title": "Is Reasoning Capability Enough for Safety in Long-Context Language Models?",
    "authors": "Yu Fu, Haz Sameen Shahgir, Huanli Gong, Zhipeng Wei, N. Benjamin Erichson, Yue Dong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08874v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) increasingly combine long-context processing with advanced reasoning, enabling them to retrieve and synthesize information distributed across tens of thousands of tokens. A hypothesis is that stronger reasoning capability should improve safety by helping models recognize harmful intent even when it is not stated explicitly. We test this hypothesis in long-context settings where harmful intent is implicit and must be inferred through reasoning, and find that it does not hold. We introduce compositional reasoning attacks, a new threat model in which a harmful query is decomposed into incomplete fragments that scattered throughout a long context. The model is then prompted with a neutral reasoning query that induces retrieval and synthesis, causing the harmful intent to emerge only after composition. Evaluating 14 frontier LLMs on contexts up to 64k tokens, we uncover three findings: (1) models with stronger general reasoning capability are not more robust to compositional reasoning attacks, often assembling the intent yet failing to refuse; (2) safety alignment consistently degrades as context length increases; and (3) inference-time reasoning effort is a key mitigating factor: increasing inference-time compute reduces attack success by over 50 percentage points on GPT-oss-120b model. Together, these results suggest that safety does not automatically scale with reasoning capability, especially under long-context inference."
  },
  {
    "date": "2026-02-09",
    "title": "TiFRe: Text-guided Video Frame Reduction for Efficient Video Multi-modal Large Language Models",
    "authors": "Xiangtian Zheng, Zishuo Wang, Yuxin Peng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08861v1",
    "source": "arXiv",
    "abstract": "With the rapid development of Large Language Models (LLMs), Video Multi-Modal Large Language Models (Video MLLMs) have achieved remarkable performance in video-language tasks such as video understanding and question answering. However, Video MLLMs face high computational costs, particularly in processing numerous video frames as input, which leads to significant attention computation overhead. A straightforward approach to reduce computational costs is to decrease the number of input video frames. However, simply selecting key frames at a fixed frame rate (FPS) often overlooks valuable information in non-key frames, resulting in notable performance degradation. To address this, we propose Text-guided Video Frame Reduction (TiFRe), a framework that reduces input frames while preserving essential video information. TiFRe uses a Text-guided Frame Sampling (TFS) strategy to select key frames based on user input, which is processed by an LLM to generate a CLIP-style prompt. Pre-trained CLIP encoders calculate the semantic similarity between the prompt and each frame, selecting the most relevant frames as key frames. To preserve video semantics, TiFRe employs a Frame Matching and Merging (FMM) mechanism, which integrates non-key frame information into the selected key frames, minimizing information loss. Experiments show that TiFRe effectively reduces computational costs while improving performance on video-language tasks."
  },
  {
    "date": "2026-02-09",
    "title": "Spin-active chlorine-related centers in 4H-SiC with telecom-band emissions",
    "authors": "Danial Shafizadeh, Misagh Ghezellou, Viktor M. Bobal, Lasse Vines, Jawad Ul-Hassan, Valdas Jokubavicius, Nguyen T. Son, Ivan G. Ivanov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08854v1",
    "source": "arXiv",
    "abstract": "A photoluminescence (PL) and magnetic resonance investigation of a defect in chlorine-implanted 4H-SiC is presented. This Cl-related center emits light at telecom wavelengths with zero-phonon lines in the range 1350-1540 nm. Its four configurations exhibit stable PL spectra characterized by narrow zero-phonon lines. For the two configurations that emit light at the C-band, a Debye-Waller factor in the range 22-25% is estimated. Optically detected magnetic resonance confirms that the Cl-related center is spin active and stable at room temperature with the zero-field splitting in the range of 1.0-1.4 GHz. The combined optical and spin properties suggest this center to be a highly promising candidate for scalable quantum networks."
  },
  {
    "date": "2026-02-09",
    "title": "The contribution of neutral gas to Faraday tomographic data at low frequencies. A first extensive comparison between real and synthetic data",
    "authors": "Jack Berat, Marc-Antoine Miville-Deschênes, Andrea Bracco, Patrick Hennebelle, Jeremy Scholtys",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08839v1",
    "source": "arXiv",
    "abstract": "LOFAR observations of diffuse interstellar polarization at meter wavelengths reveal intricate polarized intensity structures with an unexpected correlation with neutral HI filaments that could not be reproduced in simulations with low cold neutral medium (CNM) abundance. We investigate whether MHD simulations of thermally bi-stable neutral interstellar medium, with a range of CNM fraction, can reproduce the properties of the 3C196 field, the high Galactic latitude test field. Using 50 pc simulations with varying levels of turbulence and compressibility, we generated synthetic 21 cm and synchrotron observations, including instrumental noise and beam effects, for different line-of-sight orientations relative to the magnetic field. We developed MOOSE, a code to generate synthetic synchrotron polarization and Faraday tomography. We also developed a metric based on the HOG algorithm, to quantify the relative contribution of cold and warm neutral medium structures to the Faraday tomographic data. The synthetic observations show levels of polarization intensity and RM values comparable to the 3C196 field, indicating that thermal electrons associated with the neutral HI phase can account for a significant fraction of the synchrotron polarized emission at 100-200 MHz. The simulations consistently reveal a correlation between CNM and Faraday tomographic structures that depends on turbulence level, magnetic field orientation, and observational noise, but only weakly on CNM fraction. We found slightly weaker CNM-Synchrotron polarized emission correlation level than observed in the 3C196 field. These results suggest that low-frequency polarimetric observations provide a valuable probe of magnetic-field morphology in the multi-phase Solar-neighborhood ISM, while simultaneously underscoring the need for improved modeling of the turbulent, multi-phase, and partially ionized interstellar medium."
  },
  {
    "date": "2026-02-09",
    "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning",
    "authors": "Andrés Holgado-Sánchez, Peter Vamplew, Richard Dazeley, Sascha Ossowski, Holger Billhardt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08835v1",
    "source": "arXiv",
    "abstract": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences. We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values."
  },
  {
    "date": "2026-02-09",
    "title": "Oxi-Shapes: Tropical geometric analysis of bounded redox proteomic state spaces",
    "authors": "James N. Cobley",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08832v1",
    "source": "arXiv",
    "abstract": "Redox proteomics generates bounded biochemical measurements that are categorically mismatched to conventional linear algebraic formalisms. This work introduces Oxi-Shapes, a tropical geometric framework for the measurement-native analysis of bounded redox proteomic data. Oxi-Shapes represents cysteine oxidation as a scalar field over a discrete lattice, enabling global and site-wise analysis without rescaling, interpolation, or kinetic assumptions. At the global level, the framework yields internal redox entropy, lattice curvature, and derived energy functionals that characterise the geometric structure of the redox proteome. At the site level, Oxi-Shapes defines a bounded change space that makes explicit hard geometric constraints on admissible redox transitions and enables a normalised signed representation of site-wise change as a fraction of available redox freedom. Applied to an ageing mouse brain dataset, Oxi-Shapes reveals that a small decrease in mean oxidation arises from a profound redistribution of site-wise redox states, with thousands of residues shifting toward the reduced absorbing boundary. These results demonstrate that categorically correct algebraic representations expose structure in proteomic data that is inaccessible to mean-centric or unbounded analyses."
  },
  {
    "date": "2026-02-09",
    "title": "Enhancing Generative AI Image Refinement with Scribbles and Annotations: A Comparative Study of Multimodal Prompts",
    "authors": "Hyerim Park, Phuong Thao Tran, Andre Luckow, Ceenu George, Michael Sedlmair, Malin Eiband",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08830v1",
    "source": "arXiv",
    "abstract": "Generative AI (GenAI) image tools are increasingly used in design practice, enabling rapid ideation but offering limited support for refinement tasks such as adjusting layout, scale, or visual attributes. While text prompts and inpainting allow localized edits, they often remain inefficient or ambiguous for precise, in-context, and iterative refinement -- motivating the exploration of alternative methods. This work examines how pen-based scribbles and annotations can enhance GenAI image refinement. A formative study with seven professional designers informed a prototype supporting three input modalities: text-only, visual-only, and combined prompting. A within-subjects study with 30 designers and design students compared these modalities across closed- and open-ended tasks, evaluating expressiveness, efficiency, workload, user experience, iteration, and multimodal strategies. Visual prompts improved clarity and speed for spatial edits while reducing workload, whereas text remained effective for semantic and global changes. The combined modality received the highest overall ratings, enabling complementary use, balancing spatial precision with semantic detail, and supporting smoother iteration. Task-specific preferences also emerged: adding new objects often required both modalities, while moving or modifying elements was typically handled through visual input. This work contributes (1) an empirical comparison of multimodal prompting for GenAI refinement, (2) a prototype integrating scribbles and annotations, and (3) insights into designers' multimodal strategies to inform future GenAI interfaces that better support refinement in GenAI-supported design workflows."
  },
  {
    "date": "2026-02-09",
    "title": "Affective Flow Language Model for Emotional Support Conversation",
    "authors": "Chenghui Zou, Ning Wang, Tiesunlong Shen, Luwei Xiao, Chuan Ma, Xiangpeng Li, Rui Mao, Erik Cambria",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08826v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow."
  },
  {
    "date": "2026-02-09",
    "title": "New Approach to Superflare Energy Determination",
    "authors": "Petr Heinzel, Robert Falewicz, Kamil Bicz, Paweł Preś",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08814v1",
    "source": "arXiv",
    "abstract": "We present a new method for estimating the total energy radiated by stellar flares in broad-band continua, which assumes a constant emitting area but incorporates a time-dependent temperature evolution. This physically motivated approach offers an alternative to the commonly used method that assumes a fixed flare temperature about of 10 000\\,K and variable area. By allowing the temperature to vary over time while keeping the emitting area constant, our method captures more realistic flare behaviour. This time-dependent treatment of the flare temperature is supported by numerous solar observations, numerical simulations, and multiwavelength studies of active stars. We demonstrate that using peak flare temperatures estimated from a semi-empirical model grid, rather than assuming an ad-hoc flare temperature value, improves the accuracy of total energy estimates. Although the most precise results still require a multi-band photometry/spectroscopy or independently constrained flare temperatures, our method offers a practical and scalable solution for single-band observations. It is particularly well suited for main-sequence stars of spectral types K4 and later with known effective temperatures. Finally we discuss how the flare continuum behaves under varying chromospheric conditions. Our method improves flare energy estimates by incorporating a physically relevant time-dependent temperature evolution and empirically derived peak temperatures, rather than assuming a constant 10 000\\,K value. This modification reduces systematic errors that can reach factors up to ten as compared to previous estimates. We proved this on a sample of 50,320 TESS flares."
  },
  {
    "date": "2026-02-09",
    "title": "Which $F_3$-by-$\\mathbb{Z}$s are CAT(0)?",
    "authors": "Leo Delage",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08759v1",
    "source": "arXiv",
    "abstract": "In this note we point out a mistake in theorem 4.4 of [Sam06], which states that a semidirect product $F_3\\rtimes_φ\\mathbb{Z}$ whose defining automorphism $φ$ is unipotent-polynomially-growing and fixes a free factor of rank $2$ is a CAT(0) group. We give and prove the corrected statement: such a group is CAT(0), if and only if $φ$ is the identity or if the element of $F_2$ twisting the non-fixed generator is not in the commutator subgroup of $F_2$. This gives new examples of free-by-cyclic groups that cannot act properly by semisimple isometries on a CAT(0) space, that are similar to {Gersten}'s examples [Ger94]. We also construct CAT(0) structures for new examples of $F_3$-by-$\\mathbb{Z}$s by thickening the strips in Bridson's tree of spaces construction [BH99]."
  },
  {
    "date": "2026-02-09",
    "title": "$\\texttt{lrnnx}$: A library for Linear RNNs",
    "authors": "Karan Bania, Soham Kalburgi, Manit Tanwar, Dhruthi, Aditya Nagarsekar, Harshvardhan Mestha, Naman Chibber, Raj Deshmukh, Anish Sathyanarayanan, Aarush Rathore, Pratham Chheda",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08810v1",
    "source": "arXiv",
    "abstract": "Linear recurrent neural networks (LRNNs) provide a structured approach to sequence modeling that bridges classical linear dynamical systems and modern deep learning, offering both expressive power and theoretical guarantees on stability and trainability. In recent years, multiple LRNN-based architectures have been proposed, each introducing distinct parameterizations, discretization schemes, and implementation constraints. However, existing implementations are fragmented across different software frameworks, often rely on framework-specific optimizations, and in some cases require custom CUDA kernels or lack publicly available code altogether. As a result, using, comparing, or extending LRNNs requires substantial implementation effort. To address this, we introduce $\\texttt{lrnnx}$, a unified software library that implements several modern LRNN architectures under a common interface. The library exposes multiple levels of control, allowing users to work directly with core components or higher-level model abstractions. $\\texttt{lrnnx}$ aims to improve accessibility, reproducibility, and extensibility of LRNN research and applications. We make our code available under a permissive MIT license."
  },
  {
    "date": "2026-02-09",
    "title": "Nearly tight bound for rainbow clique subdivisions in properly edge-colored graphs and applications",
    "authors": "Peiru Kuang, Yan Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08390v1",
    "source": "arXiv",
    "abstract": "An edge-colored graph is said to be rainbow if all its edges have distinct colors. In this paper, we study the rainbow analogue of a fundamental result of Mader [\\emph{Math. Ann.} \\textbf{174} (1967), 265--268] on the existence of subdivisions in graphs with large average degree. This is part of the study of rainbow analogues of classical Turán problems, a framework systematically introduced by Keevash, Mubayi, Sudakov and Verstraëte [\\emph{Combin. Probab. Comput.} \\textbf{16} (2007), 109--126]. We prove that every properly edge-colored graph on $n$ vertices with average degree at least $t^2(\\log n)^{1+o(1)}$ contains a rainbow subdivision of $K_t$. When $t$ is a constant, this bound is tight up to the $o(1)$ term. So it essentially resolves a question raised by Jiang, Methuku and Yepremyan [\\emph{European J. Combin.} \\textbf{110} (2023), 103675] on rainbow clique subdivisions, and also implies a result of Alon, Bucić, Sauermann, Zakharov and Zamir [\\emph{Proc. Lond. Math. Soc.} \\textbf{130} (2025), e70044] on rainbow cycles. In addition, we present several applications of our result to problems in additive combinatorics, number theory and coding theory."
  },
  {
    "date": "2026-02-09",
    "title": "ModARO: A Modular Approach to Architecture Reconstruction of Distributed Microservice Codebases",
    "authors": "Oscar Manglaras, Alex Farkas, Thomas Woolford, Christoph Treude, Markus Wagner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08181v1",
    "source": "arXiv",
    "abstract": "Microservice architectures promote small, independently developed services, but increase overall architectural complexity. It is crucial that developers understand the architecture and how changes to a service affect the overall system, but rapid and independent development of services increases the risk of architectural drift and discourages the creation and maintenance of documentation. Automatic architecture reconstruction can help avoid these issues, but it is difficult to reuse reconstruction code across multiple projects, as all use different combinations of technologies and project-specific conventions. Reconstruction of architecture-level details is further complicated by the tendency to split microservices into separate repositories, preventing a full view of the system from any one codebase. In this paper, we present and evaluate ModARO, an approach to microservice architecture reconstruction that allows writing modular reconstruction code ('extractors') for any technologies and reusing them across different projects, independent of the surrounding technology stack or whether or not the services are split into multiple codebases. We demonstrate the effectiveness of our approach by configuring ModARO to reconstruct 10 open source projects, and we validate the usefulness and usability of ModARO against a state-of-the-art baseline in a user study with 8 industry practitioners. Using this approach, developers can assemble or create extractors tailored to their technology stacks and distribute architecture reconstruction across repositories, enabling integration into repository CI/CD pipelines."
  },
  {
    "date": "2026-02-09",
    "title": "The Presort Hierarchy for Geometric Problems",
    "authors": "Ivor van der Hoog, Eva Rotenberg, Jack Spalding-Jamieson, Lasse Wulf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08843v1",
    "source": "arXiv",
    "abstract": "Many fundamental problems in computational geometry admit no algorithm running in $o(n \\log n)$ time for $n$ planar input points, via classical reductions from sorting. Prominent examples include the computation of convex hulls, quadtrees, onion layer decompositions, Euclidean minimum spanning trees, KD-trees, Voronoi diagrams, and decremental closest-pair. A classical result shows that, given $n$ points sorted along a single direction, the convex hull can be constructed in linear time. Subsequent works established that for all of the other above problems, this information does not suffice. In 1989, Aggarwal, Guibas, Saxe, and Shor asked: Under which conditions can a Voronoi diagram be computed in $o(n \\log n)$ time? Since then, the question of whether sorting along TWO directions enables a $o(n \\log n)$-time algorithm for such problems has remained open and has been repeatedly mentioned in the literature. In this paper, we introduce the Presort Hierarchy: A problem is 1-Presortable if, given a sorting along one axis, it permits a (possibly randomised) $o(n \\log n)$-time algorithm. It is 2-Presortable if sortings along both axes suffice. It is Presort-Hard otherwise. Our main result is that quadtrees, and by extension Delaunay triangulations, Voronoi diagrams, and Euclidean minimum spanning trees, are 2-Presortable: we present an algorithm with expected running time $O(n \\sqrt{\\log n})$. This addresses the longstanding open problem posed by Aggarwal, Guibas, Saxe, and Shor (albeit randomised). We complement this result by showing that some of the other above geometric problems are also 2-Presortable or Presort-Hard."
  },
  {
    "date": "2026-02-09",
    "title": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
    "authors": "Annemette Brok Pirchert, Jacob Nielsen, Mogens Henrik From, Lukas Galke Poech, Peter Schneider-Kamp",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08818v1",
    "source": "arXiv",
    "abstract": "Recent advances in mixture-of-experts architectures have shown that individual experts models can be trained federatedly, i.e., in isolation from other experts by using a common base model to facilitate coordination. However, we hypothesize that full-sized experts may not be necessary for all domains and that instead low-rank adapters may be sufficient. Here, we introduce FlexMoRE, a Flexible Mixture of Rank-heterogenous Experts, which may be either full-sized experts or adapters of a suitable rank. We systematically investigate the trade-off between expert rank and downstream task performance by evaluating $6$ experts with ranks $2^0$ to $2^{14}$ resulting in experiments covering 150 mixtures (96 with 2 experts, 54 with 7 experts) that are evaluated across $120$ tasks. For our experiments, we build on FlexOlmo and turn its pre-trained experts into low-rank versions. Our regression analysis from expert rank to downstream task performance reveals that the best-performing rank is substantially higher for reasoning-heavy benchmarks than for knowledge-heavy benchmarks. These findings on rank sensitivity come with direct implications for memory efficiency: Using optimal ranks, FlexMoRE yields improved downstream task performance (average score $47.18$) compared to the baseline FlexOlmo-style mixture of full-sized experts (average score $45.46$) at less than one third the parameters ($10.75$B for FlexMoRE vs. $33.27$B for FlexOlmo). All code will be made available."
  },
  {
    "date": "2026-02-09",
    "title": "On the Inefficiency of Social Learning",
    "authors": "Florian Brandl, Wanying Huang, Atulya Jain",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08812v1",
    "source": "arXiv",
    "abstract": "We study whether a social planner can improve the efficiency of learning, measured by the expected total welfare loss, in a sequential decision-making environment. Agents arrive in order and each makes a binary action based on their private signal and the social information they observe. The planner can intervene by jointly designing the social information disclosed to agents and offering monetary transfers contingent on agents' actions. We show that, despite such flexibility, efficient learning cannot be restored with a finite budget: whenever learning is inefficient without intervention, no combination of information disclosure and transfers can achieve efficient learning while keeping total expected transfers finite."
  },
  {
    "date": "2026-02-09",
    "title": "Review of thermodynamic structures and structure-preserving discretisations of Cahn--Hilliard-type models",
    "authors": "Aaron Brunk, Marco F. P. ten Eikelder, Marvin Fritz, Dennis Höhn, Dennis Trautwein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08791v1",
    "source": "arXiv",
    "abstract": "The Cahn-Hilliard equation and extensions, notably the Cahn-Hilliard-Darcy and Cahn-Hilliard-Navier-Stokes systems, provide widely used frameworks for coupling interfacial thermodynamics with flow. This review surveys the thermodynamic structures underlying these models, focusing on the formulation of free energy functionals, dissipation mechanisms, and variational principles. We compare structural properties, emphasizing how these models encode conservation laws and energy dissipation. A central theme is the translation of these thermodynamic structures into numerical practice by providing representative discretisation strategies that aim to preserve mass conservation, stability, and energy decay. Particular attention is paid to the trade-offs between accuracy, efficiency, and structure preservation in large-scale simulations."
  },
  {
    "date": "2026-02-09",
    "title": "The Yang--Mills measure on compact surfaces as a universal scaling limit of lattice gauge models",
    "authors": "Nguyen Viet Dang, Elias Nohra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08591v1",
    "source": "arXiv",
    "abstract": "In this article, we study the 2 dimensional Yang-Mills measure on compact surfaces from a unified continuum and discrete perspective. We construct the Yang-Mills measure as a random distributional 1-form on surfaces of arbitrary genus equipped with an arbitrary smooth area form, using geometric tools based on zero-area bands and cylindrical resolutions. This yields a canonical bulk-singular decomposition of the measure, reflecting the topology of the surface. We prove a universality theorem stating that the continuum Yang-Mills measure arises as the scaling limit of a wide class of lattice gauge theories, including Wilson, Manton, and Villain actions, on any compact surface. We study the convergence in natural spaces of distributions with anisotropic regularity. As further consequences, we obtain a new intrinsic construction of the Yang-Mills measure, independent of the previous constructions in the literature, and prove the convergence of correlation functions and Segal amplitudes on all compact surfaces."
  },
  {
    "date": "2026-02-09",
    "title": "Influence of the Reynolds number on non-Newtonian flow in thin porous media",
    "authors": "Maria Anguiano, Matthieu Bonnivard, Francisco J. Suarez-Grau",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08555v1",
    "source": "arXiv",
    "abstract": "We study the effect of the Reynolds number on the flow of a generalized Newtonian fluid through a thin porous medium in $\\mathbb{R}^3$. This medium is a domain of thickness $\\varepsilon \\ll 1$, perforated by periodically distributed solid cylinders of size $\\varepsilon$. We consider the nonlinear stationary Navier-Stokes system with viscosity following the Carreau law. Using tools from homogenization theory and assuming that the Reynolds number scales as $\\varepsilon^{-γ}$, where $γ$ is a real constant, we prove the existence of a critical Reynolds number of order $1/\\varepsilon$, in the sense that the inertial term in the Navier-Stokes system has no influence in the limit if the Reynolds number is of order smaller than or equal to $1/\\varepsilon$ (i.e. $γ= 1$). In this case, we derive linear or nonlinear Darcy laws connecting velocity to pressure gradient. Conversely, we expect a contribution from the inertial term in the homogenized problem if the Reynolds number is greater than $1/\\varepsilon$. Finally, we propose a numerical method to solve nonlinear Darcy laws describing effective flow in the critical case and demonstrate its practical applicability on several examples."
  },
  {
    "date": "2026-02-09",
    "title": "Grover Adaptive Search with Problem-Specific State Preparation",
    "authors": "Maximilian Hess, Lilly Palackal, Abhishek Awasthi, Peter J. Eder, Manuel Schnaus, Laurin Demmler, Karen Wintersperger, Joseph Doetsch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08418v1",
    "source": "arXiv",
    "abstract": "Grover's search algorithm is one of the basic building block in the world of quantum algorithms. Successfully applying it to combinatorial optimization problems is a subtle challenge. As a quadratic speedup is not enough to naively search an exponentially large space, the search has to be complemented with a state preparation routine which increases the amplitudes of promising states by exploiting the problem structure. In this paper, we build upon previous work by Baertschi and Eidenbenz to construct heuristic state preparation routines for the Traveling Salesperson Problem (TSP), mimicking the well-known classical Lin-Kernighan heuristic. With our heuristic, we aim to achieve a reasonable approximation ratio with only a polynomial number of Grover iterations. Further, we compare several algorithmic settings relating to termination criteria and the choice of Grover iterations when the number of marked solutions is unknown."
  },
  {
    "date": "2026-02-09",
    "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design",
    "authors": "Baoyun Zhao, He Wang, Liang Zeng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08253v1",
    "source": "arXiv",
    "abstract": "While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions."
  },
  {
    "date": "2026-02-09",
    "title": "Discrete Adjoint Schrödinger Bridge Sampler",
    "authors": "Wei Guo, Yuchen Zhu, Xiaochen Du, Juno Nam, Yongxin Chen, Rafael Gómez-Bombarelli, Guan-Horng Liu, Molei Tao, Jaemoo Choi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08243v1",
    "source": "arXiv",
    "abstract": "Learning discrete neural samplers is challenging due to the lack of gradients and combinatorial complexity. While stochastic optimal control (SOC) and Schrödinger bridge (SB) provide principled solutions, efficient SOC solvers like adjoint matching (AM), which excel in continuous domains, remain unexplored for discrete spaces. We bridge this gap by revealing that the core mechanism of AM is $\\mathit{state}\\text{-}\\mathit{space~agnostic}$, and introduce $\\mathbf{discrete~ASBS}$, a unified framework that extends AM and adjoint Schrödinger bridge sampler (ASBS) to discrete spaces. Theoretically, we analyze the optimality conditions of the discrete SB problem and its connection to SOC, identifying a necessary cyclic group structure on the state space to enable this extension. Empirically, discrete ASBS achieves competitive sample quality with significant advantages in training efficiency and scalability."
  },
  {
    "date": "2026-02-09",
    "title": "An Exploration of the Equation of State Dependence of Core-Collapse Supernova Explosion Outcomes and Signatures",
    "authors": "Aleksandr Rusakov, Adam S. Burrows, Tianshu Wang, David Vartanyan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09025v1",
    "source": "arXiv",
    "abstract": "We explore, using a state-of-the-art simulation code in 3D and to late enough times to witness final observables, the dependence of core-collapse supernova explosions on the nuclear equation of state. Going beyond questions of explodability, we compare final explosion energies, nucleosynthetic yields, recoil kicks, and gravitational-wave and neutrino signatures using the SFHo and DD2 nuclear equations of state (EOS) for a 9-$M_{\\odot}$/solar-metallicity progenitor star. The DD2 EOS is stiffer and has a lower effective nucleon mass. The result is a more extended protoneutron star (PNS) and lower central densities. As a consequence, the mean neutrino energies, final explosion energy, and recoil kick speed are lower. Moreover, the evolution of PNS convection differs between the two EOS models in significant ways. This translates in part into interestingly altered neutrino ``light\" curves and noticeably altered gravitational-wave signal strengths and frequency characteristics that may be diagnostic. The faster exploding model (SFHo) yields slightly more neutron-rich ejecta and more species with atomic weights between 60 and 90 and a weak r-process. However, this is merely a preliminary study. The next step is a more comprehensive and multi-progenitor set of 3D supernova simulations for various EOSes to late times when the observables have asymptoted. Such a future investigation will have a direct bearing on the neutron star and black hole birth mass functions and the quest towards a fully quantitative theory of supernova observables."
  },
  {
    "date": "2026-02-09",
    "title": "Testing the nuclear TMD gluon densities with heavy flavor production in proton-lead collisions at LHC",
    "authors": "A. V. Lipatov, A. V. Kotikov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09005v1",
    "source": "arXiv",
    "abstract": "We employ a simple model for nuclear modification of ordinary parton densities in a proton to evaluate the Transverse Momentum Dependent gluon and quark distributions in nuclei (nTMDs) within the popular Kimber-Martin-Ryskin/Watt-Martin-Ryskin approach. The model is based on a global analysis of available deep inelastic scattering data for different nuclear targets within the rescaling model, incorporating Fermi motion effects. The derived nTMDs are tested with latest CMS data on inclusive $b$-jet and $B^+$ meson production in proton-lead collisions collected at $\\sqrt s = 5.02$ and $8.16$~TeV using the High Energy Factorization framework. We predict the corresponding nuclear medium modification factors to be about of $0.8 - 1.2$ in the probed kinematical region, which is consistent with other estimations. Specially we highlight a possibility to investigate the nuclear modification of parton densities by applying different cuts on the final states in such processes."
  },
  {
    "date": "2026-02-09",
    "title": "Improving Topological Detection of Weather Regimes in climate dynamical systems",
    "authors": "Soheil Anbouhi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09004v1",
    "source": "arXiv",
    "abstract": "Weather regimes provide a useful framework for describing large-scale atmospheric variability and its impacts on regional weather. Despite extensive study, there is still no universally accepted definition or method for identifying weather regimes. Recent work has shown that weather regimes can be interpreted geometrically as topological structures in the phase space of the atmospheric system. In this approach, regimes are identified using a density--radius bifiltration combined with persistent homology, a well-established tool from Topological Data Analysis (TDA). This topological perspective provides a unifying view of regimes and, unlike traditional methods, does not require the number of regimes to be specified in advance. However, the method relies on density estimation techniques (typically Gaussian kernel density estimation), which can over--smooth weakly populated but dynamically important regions of the phase space."
  },
  {
    "date": "2026-02-09",
    "title": "From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection",
    "authors": "Zilin Fang, Anxing Xiao, David Hsu, Gim Hee Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09002v1",
    "source": "arXiv",
    "abstract": "Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geometric planning with contextual social reasoning. The system first extracts obstacles and human dynamics to generate geometrically feasible candidate paths, then leverages a fine-tuned vision-language model (VLM) to evaluate these paths, informed by contextually grounded social expectations, selecting a socially optimized path for the controller. This task-specific VLM distills social reasoning from large foundation models into a smaller and efficient model, allowing the framework to perform real-time adaptation in diverse human-robot interaction contexts. Experiments in four social navigation contexts demonstrate that our method achieves the best overall performance with the lowest personal space violation duration, the minimal pedestrian-facing time, and no social zone intrusions. Project page: https://path-etiquette.github.io"
  },
  {
    "date": "2026-02-09",
    "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
    "authors": "Ali Hatamizadeh, Shrimai Prabhumoye, Igor Gitman, Ximing Lu, Seungju Han, Wei Ping, Yejin Choi, Jan Kautz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09000v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\\% and 79.64\\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning."
  },
  {
    "date": "2026-02-09",
    "title": "Universal Coefficients and Mayer-Vietoris Sequence for Groupoid Homology",
    "authors": "Luciano Melodia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08998v1",
    "source": "arXiv",
    "abstract": "We study homology of ample groupoids via the compactly supported Moore complex of the nerve. Let $A$ be a topological abelian group. For $n\\ge 0$ set $C_n(\\mathcal G;A) := C_c(\\mathcal G_n,A)$ and define $\\partial_n^A=\\sum_{i=0}^n(-1)^i(d_i)_*$. This defines $H_n(\\mathcal G;A)$. The theory is functorial for continuous étale homomorphisms. It is compatible with standard reductions, including restriction to saturated clopen subsets. In the ample setting it is invariant under Kakutani equivalence. We reprove Matui type long exact sequences and identify the comparison maps at chain level. For discrete $A$ we prove a natural universal coefficient short exact sequence $$0\\to H_n(\\mathcal G)\\otimes_{\\mathbb Z}A\\xrightarrow{\\ ι_n^{\\mathcal G}\\ }H_n(\\mathcal G;A)\\xrightarrow{\\ κ_n^{\\mathcal G}\\ }\\operatorname{Tor}_1^{\\mathbb Z}\\bigl(H_{n-1}(\\mathcal G),A\\bigr)\\to 0.$$ The key input is the chain level isomorphism $C_c(\\mathcal G_n,\\mathbb Z)\\otimes_{\\mathbb Z}A\\cong C_c(\\mathcal G_n,A)$, which reduces the groupoid statement to the classical algebraic UCT for the free complex $C_c(\\mathcal G_\\bullet,\\mathbb Z)$. We also isolate the obstruction for non-discrete coefficients. For a locally compact totally disconnected Hausdorff space $X$ with a basis of compact open sets, the image of $Φ_X:C_c(X,\\mathbb Z)\\otimes_{\\mathbb Z}A\\to C_c(X,A)$ is exactly the compactly supported functions with finite image. Thus $Φ_X$ is surjective if and only if every $f\\in C_c(X,A)$ has finite image, and for suitable $X$ one can produce compactly supported continuous maps $X\\to A$ with infinite image. Finally, for a clopen saturated cover $\\mathcal G_0=U_1\\cup U_2$ we construct a short exact sequence of Moore complexes and derive a Mayer-Vietoris long exact sequence for $H_\\bullet(\\mathcal G;A)$ for explicit computations."
  },
  {
    "date": "2026-02-09",
    "title": "Evaluating the $Σ$-effect Model of the Solar Hemispherical Helicity Bias via Direct Numerical Simulations",
    "authors": "Jacob B. Noone Wade, Nicholas H. Brummell",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08992v1",
    "source": "arXiv",
    "abstract": "The Solar Hemispherical Helicity Rule(s) (SHHR) is a term used to represent a bias observed in proxies for the magnetic helicity in active regions at the solar surface. The SHHR states that predominantly negative magnetic helicity is observed in active regions in the northern hemisphere, whereas predominantly positive is found in the southern. The $Σ$-effect model of \\cite{longcope1998flux} is one of the most cited models for the explanation of the SHHR. In this model, the magnetic structures derive the bias in their magnetic helicity from the kinetic helicity of the turbulent convection through which they travel, where the latter is handed owing to the rotational influence of the star. The original paper built an elegant mathematical model for the dynamics of thin flux tubes influenced by parameterized helical turbulence. Here, we attempt to explore the conceptual ideas of this original simplified model using fully-nonlinear, three-dimensional, Cartesian-domain simulations of isolated, finite cross-sectional, twisted magnetic flux structures rising though rotating, overshooting, turbulent compressible convection. We look for evidence of a correlation between the kinetic helicity content of the turbulence and the evolving magnetic helicity of the structures. We find little evidence of such a relationship, and do not even find any clear hemispheric dependence. Although these simulations are far from a perfect representation of the ideas, this work raises many questions about the potential efficacy of the $Σ$-effect in reality."
  },
  {
    "date": "2026-02-09",
    "title": "Equilibrium-like statistical mechanics in space-time for a deterministic traffic model far from equilibrium",
    "authors": "Aryaman Jha, Kurt Wiesenfeld, Jorge Laval",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08991v1",
    "source": "arXiv",
    "abstract": "Motivated by earlier numerical evidence for a percolation-like transition in space-time jamming, we present an analytic description of the transient dynamics of the deterministic traffic model elementary cellular automaton rule 184 (ECA184). By exploiting the deterministic structure of the dynamics, we reformulate the problem in terms of a height function constructed directly from the initial condition, and obtain an equilibrium statistical mechanics-like description over the lattice configurations. This formulation allows macroscopic observables in space-time, such as the total jam delay and jam relaxation time, as well as microscopic jam statistics, to be expressed in terms of geometric properties of the height function. We thereby derive the associated scaling forms and recover the critical exponents previously observed in numerical studies. We discuss the physical implications of this space-time geometric approach."
  },
  {
    "date": "2026-02-09",
    "title": "Zero Trust for Multi-RAT IoT: Trust Boundary Management in Heterogeneous Wireless Network Environments",
    "authors": "Jonathan Shelby",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08989v1",
    "source": "arXiv",
    "abstract": "The proliferation of Multi-Radio Access Technology, Internet of Things devices, particularly Unmanned Aerial Vehicles operating across LoRaWAN, 5G/4G cellular, Meshtastic mesh, proprietary protocols such as DJI OcuSync, MAVLink telemetry links, Wi-Fi, and satellite, creates a fundamental and hitherto unexamined challenge for Zero Trust Architecture adoption. Each transition between radio access technologies constitutes a trust boundary crossing: the device exits one network trust domain and enters another, potentially invalidating authentication state, device attestation, and contextual trust signals. Current ZTA frameworks assume relatively stable network environments and do not address the trust implications of frequent, dynamic RAT switching in mobile IoT deployments."
  },
  {
    "date": "2026-02-09",
    "title": "An omega result for the least negative Hecke eigenvalue",
    "authors": "Youness Lamzouri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08985v1",
    "source": "arXiv",
    "abstract": "We establish the existence of many holomorphic Hecke eigenforms $f$ of large weight $k$ for the full modular group, for which the least positive integer $n_f$ such that $λ_f(n_f)<0$ satisfies $n_f \\ge (\\log k)^{1-o(1)}.$ This is believed to be best possible up to the $o(1)$ term in the exponent, and improves on a result of Kowalski, Lau, Soundararajan and Wu, who showed that, when restricted to primes, the least prime $p$ such that $λ_f(p)<0$ can be as large as $(\\log k)^{1/2+o(1)}$. We also discuss an extension of our result to primitive holomorphic cusp forms of weight $k$ and squarefree level $N\\geq 1$."
  },
  {
    "date": "2026-02-09",
    "title": "Indications of Rapid Dust Formation in the Inner Region of a Protoplanetary Disk",
    "authors": "Thanawuth Thanathibodee, Catherine Espaillat, Nuria Calvet, Zhaohuan Zhu, Julalak Nammanee, Caeley Pittman, Maire Volz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08973v1",
    "source": "arXiv",
    "abstract": "We report a significant increase in mid-infrared emission $\\leq10$ $μ$m in a transitional disk. The 2024 JWST/MIRI observation of the disk around CVSO 1942 reveals flux increase by a factor of two at $λ\\leq10$ $μ$m, compared to the near photospheric flux level observed with Spitzer/IRS in 2005. No significant change in flux at $\\gtrsim15$ $μ$m is detected in the spectra. Comparing the MIRI/MRS spectrum and NEOWISE photometry, we found that this $\\leq10$ $μ$m flux increase occurs on a timescale of 2 weeks and is consistent with the presence of warm (1,400 K), optically thick, large ($\\gtrsim1$ $μ$m) dust grains near the dust sublimation radius. We propose that this rapid dust appearance may indicate in situ dust formation, possibly from planetesimal collisions in the inner disk."
  },
  {
    "date": "2026-02-09",
    "title": "Is the nitrogen-rich source PN K4-47 a true planetary nebula?",
    "authors": "Thomas Steinmetz, Tomasz Kaminski, David Jones, Marcin Hajduk, Denise R. Goncalves, Stavros Akras",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08959v1",
    "source": "arXiv",
    "abstract": "PN K4-47 is a young planetary nebula that exhibits shock-excited bipolar lobes and a complex molecular environment, with the highest number of molecules detected within a planetary nebula. It has been questioned whether K4-47 is indeed a `typical' planetary nebula, or may be more exotic in nature. We examine this question using optical imaging and spectroscopy, and sub-millimetre and radio interferometry. Our observations spatially resolve the sub-millimetre environment of K4-47 for the first time. We find elongated CO (2-1) emission along a similar PA to the optical bipolar outflow. We derive a distance upper limit of 6 kpc to the source. The source hosts a fast ($\\sim$350 km s$^{-1}$) bipolar optical outflow, and a slow (~50-60 km s$^{-1}$) molecular outflow along a similar PA. The outflow velocity indicates an age of 336 $\\pm$ 119 yr. We also find that the excitation temperature and density of the atomic gas is~20 kK and 2800 cm$^{-3}$, respectively. The elemental and isotopic enrichment of K4-47 infers an AGB progenitor mass of 4-6 M$_{\\odot}$, which corresponds to a white dwarf mass of ~1 M$_{\\odot}$, following the initial-final mass relation for white dwarfs. We find that the core of K4-47 must contain 10$^{-2}$ M$_{\\odot}$ of dust to explain the extinction, and that photoionisation alone cannot explain the excitation of the atomic gas. We instead require an additional heating mechanism, with shocks a likely scenario. It is likely that the progenitor star of K4-47 was a J-type carbon AGB star, which formed the molecular and dusty circumstellar environment. The bipolar outflow is later triggered, punching through the circumstellar environment, producing shocks, and shaping the environment into the elongated structure seen in the sub-millimetre. We therefore classify K4-47 as a genuine, if unusual, planetary nebula."
  },
  {
    "date": "2026-02-09",
    "title": "Two Robust Interstellar Meteor Candidates in the Post-2018 CNEOS Fireball Database",
    "authors": "Richard Cloete, Abraham Loeb",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08956v1",
    "source": "arXiv",
    "abstract": "We report the identification of two previously unrecognized interstellar meteor candidates in the NASA CNEOS fireball database. Using the empirically calibrated low-discrepancy uncertainty model of Peña-Asensio et al.\\ (2025) for post-2018 CNEOS velocity accuracy (1$σ$: speed 0.55~km~s$^{-1}$, right ascension 1.35$^\\circ$, declination 0.84$^\\circ$), we transform CNEOS velocity vectors to heliocentric orbits and assess interstellar candidacy via $10^{6}$-draw Monte Carlo simulations. Two post-2018 events have heliocentric speeds robustly exceeding the Solar System escape speed. CNEOS-22 (2022-07-28; 6.0$^\\circ$S, 86.9$^\\circ$W; eastern tropical Pacific) has $v_{\\rm hel}=46.98$~km~s$^{-1}$, exceeding escape by $Δ= 5.18 \\pm 0.60$~km~s$^{-1}$ ($z_Δ=8.7σ$), with interstellar speed $v_{\\infty,\\odot}=21.5$~km~s$^{-1}$. CNEOS-25 (2025-02-12; 73.4$^\\circ$N, 49.3$^\\circ$E; Barents Sea) has $v_{\\rm hel}=45.63$~km~s$^{-1}$, exceeding escape by $Δ= 3.22 \\pm 0.58$~km~s$^{-1}$ ($z_Δ=5.5σ$), with $v_{\\infty,\\odot}=16.9$~km~s$^{-1}$. For both events, none of $10^{6}$ realizations yield a gravitationally bound orbit ($p_{\\rm bound} < 3\\times 10^{-6}$). The adopted error model would need to underestimate the true uncertainties by factors of 5--9 for either candidate to be marginally bound."
  },
  {
    "date": "2026-02-09",
    "title": "Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room",
    "authors": "Mohammad Morsali, Siavash H. Khajavi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08949v1",
    "source": "arXiv",
    "abstract": "According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes in real-time. To address these limitations, we introduce the Intelligent Virtual Situation Room (IVSR), a bidirectional Digital Twin (DT) platform augmented by autonomous AI agents. The IVSR continuously ingests multisource sensor imagery, weather data, and 3D forest models to create a live virtual replica of the fire environment. A similarity engine powered by AI aligns emerging conditions with a precomputed Disaster Simulation Library, retrieving and calibrating intervention tactics under the watchful eyes of experts. Authorized action-ranging from UAV redeployment to crew reallocation-is cycled back through standardized procedures to the physical layer, completing the loop between response and analysis. We validate IVSR through detailed case-study simulations provided by an industrial partner, demonstrating capabilities in localized incident detection, privacy-preserving playback, collider-based fire-spread projection, and site-specific ML retraining. Our results indicate marked reductions in detection-to-intervention latency and more effective resource coordination versus traditional systems. By uniting real-time bidirectional DTs with agentic AI, IVSR offers a scalable, semi-automated decision-support paradigm for proactive, adaptive wildfire disaster management."
  },
  {
    "date": "2026-02-09",
    "title": "Long distance quantum illumination and ranging using polarization entangled photon pairs in a lossy environment",
    "authors": "Sujai Matta, Soumya Asokan, Sanchari Chakraborti, Mayank Joshi, Rahul Dalal, C. M. Chandrashekar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08947v1",
    "source": "arXiv",
    "abstract": "Using polarization entangled photon pairs, we demonstrate a robust scheme for quantum illumination and ranging in a lossy environment. Entangled photon pairs are generated in a Sagnac interferometer configuration, yielding high-visibility two-photon polarization entanglement with a measured CHSH parameter of $S =2.802\\pm0.002$. One of the photons from the entangled pair is retained as idler and the other one is directed into either of the two paths, namely reference and probe, of which probe is sent toward a distant object through a lossy free-space channel, and the reflected photons are collected after round-trip free-space propagation over distances approaching $1$ km. Remarkably, strong correlations are observed with CHSH values $S >2.6$ even when only a few tens of probe photons are returned, confirming the robustness of polarization entanglement under long-distance free-space propagation. This work reports the robustness of encoding photons in different basis before it is sent towards the object and recovery of polarization entanglement even after a kilometer-scale scattering from the objects, establishing a practical foundation for scalable quantum-assisted object detection and ranging."
  },
  {
    "date": "2026-02-09",
    "title": "Sharp gradient integrability for $(s,p)$-Poisson type equations",
    "authors": "Verena Bögelein, Frank Duzaar, Naian Liao, Kristian Moring",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08944v1",
    "source": "arXiv",
    "abstract": "We prove local $W^{1,q}$-regularity for weak solutions to fractional $p$-Laplacian type equations with right-hand side $f\\in L^r_{\\mathrm{loc}}(Ω)$. Assuming $p>1$, $s\\in(0,1)$, and $sp'>1$, solutions belong to $W^{1,q}_{\\mathrm{loc}}(Ω)$ for the optimal exponent $q=q(n,p,s,r)$. We obtain quantitative local gradient estimates involving nonlocal tail terms. The optimality of $q$ is confirmed by a counterexample."
  },
  {
    "date": "2026-02-09",
    "title": "Teaching an Old Dynamics New Tricks: Regularization-free Last-iterate Convergence in Zero-sum Games via BNN Dynamics",
    "authors": "Tuo Zhang, Leonardo Stella",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08938v1",
    "source": "arXiv",
    "abstract": "Zero-sum games are a fundamental setting for adversarial training and decision-making in multi-agent learning (MAL). Existing methods often ensure convergence to (approximate) Nash equilibria by introducing a form of regularization. Yet, regularization requires additional hyperparameters, which must be carefully tuned--a challenging task when the payoff structure is known, and considerably harder when the structure is unknown or subject to change. Motivated by this problem, we repurpose a classical model in evolutionary game theory, i.e., the Brown-von Neumann-Nash (BNN) dynamics, by leveraging the intrinsic convergence of this dynamics in zero-sum games without regularization, and provide last-iterate convergence guarantees in noisy normal-form games (NFGs). Importantly, to make this approach more applicable, we develop a novel framework with theoretical guarantees that integrates the BNN dynamics in extensive-form games (EFGs) through counterfactual weighting. Furthermore, we implement an algorithm that instantiates our framework with neural function approximation, enabling scalable learning in both NFGs and EFGs. Empirical results show that our method quickly adapts to nonstationarities, outperforming the state-of-the-art regularization-based approach."
  },
  {
    "date": "2026-02-09",
    "title": "Existence of expanding harmonic map flows to hemispheres",
    "authors": "Xuanyu Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08932v1",
    "source": "arXiv",
    "abstract": "We show the existence of non-trivial self-expanding harmonic map flows starting from non-energy-minimizing 0-homogeneous maps to a regular ball or a closed hemisphere. In particular, given a non-minimizing but stationary 0-homogeneous harmonic map $u_0$ to a closed hemisphere, we construct infinitely many different weak solutions to harmonic map flow starting from $u_0$, all of which satisfy the parabolic monotonicity formula. This answers a question of Struwe."
  },
  {
    "date": "2026-02-09",
    "title": "RedDots: Multiplanet system around M dwarf GJ 887 in the solar neighborhood",
    "authors": "C. Hartogh, S. V. Jeffers, S. Dreizler, J. R. Barnes, C. A. Haswell, F. Liebing, A. Collier Cameron, P. Gorrini, F. Del Sordo, P. Cortés-Zuleta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08929v1",
    "source": "arXiv",
    "abstract": "GJ 877 is a bright M dwarf in the solar neighborhood with two currently reported nontransiting exoplanets with periods of $9~\\mathrm{d}$ and $21~\\mathrm{d,}$ along with an additional unconfirmed signal at $50~\\mathrm{d}$. We reanalyzed the system with 101 new HARPS and 12 new ESPRESSO radial velocities (RVs) secured with a cadence to confirm or refute the origin of the $50~\\mathrm{d}$ signal. To do so, we searched for signals related to stellar activity in photometric data and spectroscopic indicators. We modeled the stellar activity in the RVs with Gaussian processes (GPs). With the Bayesian analysis, we confirmed a four-planet model, including the two previously known planets at periods of $9.2619\\pm0.0005~\\mathrm{d}$ and $21.784\\pm0.004~\\mathrm{d,}$ as well as two newly confirmed exoplanets: an Earth-mass planet, with a $4.42490\\pm0.00014~\\mathrm{d}$ period and a sub-meter-per-second amplitude, and a super-Earth with a $50.77\\pm0.05~\\mathrm{d}$ period located in the habitable zone (HZ). This super-Earth is the second closest planet in the HZ, after Proxima Cen b. We found an additional signal in a 2:1 resonance with the $4.4~\\mathrm{d}$ planet at $2.21661\\pm0.00010~\\mathrm{d}$ with an amplitude of $0.37\\pm0.09~\\mathrm{m/s}$, which could be related to an additional planet. However, other explanations of its origin are also plausible. This signal remains a candidate, as further investigation is required to confirm its true nature. If the signal is caused by a planet, its minimum mass would be half that of Earth. We measured the stellar rotation period with the characteristic periodic timescale of the GP. We found a period of $38.7\\pm0.5~\\mathrm{d}$, which is consistent with the rotation period determined from photometry and other activity indices."
  },
  {
    "date": "2026-02-09",
    "title": "Automating the Wildfire Detection and Scheduling Pipeline with Maneuverable Earth Observation Satellites",
    "authors": "Brycen D. Pearl, Joshua G. Warner, Hang Woon Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08924v1",
    "source": "arXiv",
    "abstract": "Wildfires are becoming increasingly frequent, with potentially devastating consequences, including loss of life, infrastructure destruction, and severe environmental damage. Low Earth orbit satellites equipped with onboard sensors can capture critical imagery of active wildfires and enable real-time detection through machine learning algorithms applied to the acquired data. This paper presents a framework that automates the complete wildfire detection and scheduling pipeline, integrating three key components: wildfire detection in satellite imagery, statistical updating that incorporates data from repeated flyovers, and multi-satellite scheduling optimization. The framework enables wildfire detection using convolutional neural networks with sensor fusion techniques, the incorporation of subsequent flyover information using Bayesian statistics, and satellite scheduling through the state-of-the-art Reconfigurable Earth Observation Satellite Scheduling Problem. Experiments conducted using real-world wildfire events and operational Earth observation satellites demonstrate that this autonomous detection and scheduling approach effectively enhances wildfire monitoring capabilities."
  },
  {
    "date": "2026-02-09",
    "title": "On the Deepest Search for Galactic Center Pulsars and an Examination of an Intriguing Millisecond Pulsar Candidate",
    "authors": "Karen I. Perez, Vishal Gajjar, Slavko Bogdanov, Jules P. Halpern, Paul B. Demorest, Steve Croft, Matt Lebofsky, David H. E. MacMahon, Andrew P. V. Siemion",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08922v1",
    "source": "arXiv",
    "abstract": "We report results of one of the most sensitive pulsar surveys to date targeting the innermost region of the Galactic Center (GC) using the Robert C. Byrd Green Bank Telescope (GBT) at X-band (8--12GHz) using data from the Breakthrough Listen initiative. In total, we collected 9.5 hr of data covering the wider $\\sim 8'$ diameter of the GC bulge, and 11 hr on the inner $1.4'$ region between 2021 May and 2023 December. We conducted a comprehensive Fourier-domain periodicity search targeting both canonical pulsars (CPs) and millisecond pulsars (MSPs), using constant and linearly changing acceleration searches to improve sensitivity to compact binaries. Assuming weak scattering, our searches reached luminosity limits of $L_{\\rm min} \\approx 0.14~{\\rm mJy~kpc^{2}}$ for CPs and $L_{\\rm min} \\approx 0.26~{\\rm mJy~kpc^{2}}$ for MSPs -- sensitive enough to detect the most luminous pulsars expected in the GC. Among 5,282 signal candidates, we identify an interesting 8.19 ms MSP candidate (DM of 2775 pc cm$^{-3}$), persistent in time and frequency across a 1-hr scan at a flux density of $S_{\\rm min} \\approx 0.007~{\\rm mJy}$. We introduce a novel randomization test for evaluating candidate significance against noise fluctuations, including signal persistence via Kolmogorov-Smirnov tests and flux-vs-DM behavior. We are unable to make a definitive claim about the candidate due to a mixed degree of confidence from these tests and, more broadly, its non-detection in subsequent observations. This deepens the ongoing missing pulsar problem in the GC, reinforcing the idea that strong scattering and/or extreme orbital dynamics may obscure pulsar signals in this region."
  },
  {
    "date": "2026-02-09",
    "title": "Diffusion-Inspired Reconfiguration of Transformers for Uncertainty Calibration",
    "authors": "Manh Cuong Dao, Quang Hung Pham, Phi Le Nguyen, Thao Nguyen Truong, Bryan Kian Hsiang Low, Trong Nghia Hoang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08920v1",
    "source": "arXiv",
    "abstract": "Uncertainty calibration in pre-trained transformers is critical for their reliable deployment in risk-sensitive applications. Yet, most existing pre-trained transformers do not have a principled mechanism for uncertainty propagation through their feature transformation stack. In this work, we propose a diffusion-inspired reconfiguration of transformers in which each feature transformation block is modeled as a probabilistic mapping. Composing these probabilistic mappings reveals a probability path that mimics the structure of a diffusion process, transporting data mass from the input distribution to the pre-trained feature distribution. This probability path can then be recompiled on a diffusion process with a unified transition model to enable principled propagation of representation uncertainty throughout the pre-trained model's architecture while maintaining its original predictive performance. Empirical results across a variety of vision and language benchmarks demonstrate that our method achieves superior calibration and predictive accuracy compared to existing uncertainty-aware transformers."
  },
  {
    "date": "2026-02-09",
    "title": "An in vivo validation dataset for dynamic volumetric MRI",
    "authors": "Max H. C. van Riel, David G. J. Heesterbeek, Martijn Froeling, Cornelis A. T. van den Berg, Alessandro Sbrizzi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08918v1",
    "source": "arXiv",
    "abstract": "Dynamic volumetric MRI provides valuable information on in vivo motion and biomechanics, with applications spanning cardiac, musculoskeletal, or pulmonary imaging, amongst others. Developing reconstruction methods for time-resolved volumetric MRI is challenging due to the inherently slow acquisition process of MRI, which makes it an active area of research. However, in vivo validation of these methods remains challenging due to the lack of publicly available datasets with fully sampled ground-truth images. Here, we present a publicly available in vivo dataset designed to facilitate the development and validation of dynamic volumetric MRI reconstruction algorithms. Controlled and repeatable deformations of the muscles in the thigh were induced using a pneumatic pressure cuff, enabling the acquisition of both undersampled dynamic data and fully sampled validation images. The dataset comprises multichannel undersampled k-space data from nine healthy volunteers across four different dynamic deformations, with fully sampled validation data for one deformation. Additionally, an anatomical reference scan and muscle segmentation masks are provided for each subject. To illustrate a possible image reconstruction and validation approach, a binning-based reconstruction was performed on the undersampled data from six dynamic repetitions. The resulting images were consistent with the corresponding fully sampled validation images. This dataset offers possibilities for validating and advancing time-resolved volumetric MRI reconstruction methods."
  },
  {
    "date": "2026-02-09",
    "title": "Comparing AI Coding Agents: A Task-Stratified Analysis of Pull Request Acceptance",
    "authors": "Giovanni Pinna, Jingzhi Gong, David Williams, Federica Sarro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08915v1",
    "source": "arXiv",
    "abstract": "The rapid adoption of AI-powered coding assistants is transforming software development practices, yet systematic comparisons of their effectiveness across different task types and over time remain limited. This paper presents an empirical study comparing five popular agents (OpenAI Codex, GitHub Copilot, Devin, Cursor, and Claude Code), analyzing 7,156 pull requests (PRs) from the AIDev dataset. Temporal trend analysis reveals heterogeneous evolution patterns: Devin exhibits the only consistent positive trend in acceptance rate (+0.77% per week over 32 weeks), whereas other agents remain largely stable. Our analysis suggests that the PR task type is a dominant factor influencing acceptance rates: documentation tasks achieve 82.1% acceptance compared to 66.1% for new features - a 16 percentage point gap that exceeds typical inter-agent variance for most tasks. OpenAI Codex achieves consistently high acceptance rates across all nine task categories (59.6%-88.6%), with stratified Chi-square tests confirming statistically significant advantages over other agents in several task categories. However, no single agent performs best across all task types: Claude Code leads in documentation (92.3%) and features (72.6%), while Cursor excels in fix tasks (80.4%)."
  },
  {
    "date": "2026-02-09",
    "title": "Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks",
    "authors": "Kiyosu Maeda, William P. McCarthy, Ching-Yi Tsai, Jeffrey Mu, Haoliang Wang, Robert D. Hawkins, Judith E. Fan, Parastoo Abtahi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08914v1",
    "source": "arXiv",
    "abstract": "A quintessential feature of human intelligence is the ability to create ad hoc conventions over time to achieve shared goals efficiently. We investigate how communication strategies evolve through repeated collaboration as people coordinate on shared procedural abstractions. To this end, we conducted an online unimodal study (n = 98) using natural language to probe abstraction hierarchies. In a follow-up lab study (n = 40), we examined how multimodal communication (speech and gestures) changed during physical collaboration. Pairs used augmented reality to isolate their partner's hand and voice; one participant viewed a 3D virtual tower and sent instructions to the other, who built the physical tower. Participants became faster and more accurate by establishing linguistic and gestural abstractions and using cross-modal redundancy to emphasize key changes from previous interactions. Based on these findings, we extend probabilistic models of convention formation to multimodal settings, capturing shifts in modality preferences. Our findings and model provide building blocks for designing convention-aware intelligent agents situated in the physical world."
  },
  {
    "date": "2026-02-09",
    "title": "Fixed Effects as Generated Regressors",
    "authors": "Jiaqi Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08899v1",
    "source": "arXiv",
    "abstract": "Many economic models feature moment conditions that involve latent variables. When the latent variables are individual fixed effects in an auxiliary panel data regression, we construct orthogonal moments that eliminate first-order bias induced by estimating the fixed effects. Machine Learning methods and Empirical Bayes methods can be used to improve the estimate of the nuisance parameters in the orthogonal moments. We establish a central limit theorem based on the orthogonal moments without relying on exogeneity assumptions between panel data residuals and the cross-sectional moment functions. In a simulation study where the exogeneity assumption is violated, the estimator based on orthogonal moments has smaller bias compared with other estimators relying on that assumption. An empirical application on experimental site selection demonstrates how the method can be used for nonlinear moment conditions."
  },
  {
    "date": "2026-02-09",
    "title": "Discrete Bridges for Mutual Information Estimation",
    "authors": "Iryna Zabarianska, Sergei Kholkin, Grigoriy Ksenofontov, Ivan Butakov, Alexander Korotin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08894v1",
    "source": "arXiv",
    "abstract": "Diffusion bridge models in both continuous and discrete state spaces have recently become powerful tools in the field of generative modeling. In this work, we leverage the discrete state space formulation of bridge matching models to address another important problem in machine learning and information theory: the estimation of the mutual information (MI) between discrete random variables. By neatly framing MI estimation as a domain transfer problem, we construct a Discrete Bridge Mutual Information (DBMI) estimator suitable for discrete data, which poses difficulties for conventional MI estimators. We showcase the performance of our estimator on two MI estimation settings: low-dimensional and image-based."
  },
  {
    "date": "2026-02-09",
    "title": "AI-based Verbal and Visual Scaffolding in a Serious Game: Effects on Learning and Cognitive Load",
    "authors": "Caroline Wermann, Karina E. Avila, Sebastian André, Julia C. Draeger, Alvar Goetze, Jochen Kuhn, Maite Maurer, Sascha Mehlhase, Nikola Merkas, Fabian Schrodt, Stefan Küchemann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08893v1",
    "source": "arXiv",
    "abstract": "Due to their interactive nature, serious games offer valuable opportunities for supporting learning in educational contexts. Recent advances in large language models (LLMs) have further opened the door to new forms of personalized scaffolding in education. In this study, we combine both worlds and study three types of AI-based scaffolding designs in a serious game: (i) no scaffolding, (ii) chat-based (verbal) scaffolding provided by an AI-based non-player character (NPC), and (iii) combined chat-(verbal) and action-based (visual) scaffolding in which the AI may both try to explain or demonstrate the next step towards a solution. The scaffolding conditions are embedded in Qookies, a serious game designed to introduce fundamental concepts of quantum technologies. A total of 152 school students, university students, and members of the general public were randomly assigned to one of the three conditions. The results show that all groups experience significant learning gains, confirming the overall effectiveness of the serious game itself. No significant differences in learning outcomes emerged between scaffolding conditions. However, intrinsic cognitive load was lower in the combined chat-and-action (verbal+visual) scaffolding condition compared to the chat (verbal)-only condition, suggesting that visual demonstrations may offer more accessible support. Interaction analyses further revealed that players engaged with the AI character primarily for level-related questions and action recommendations, while deeper interactions were relatively rare."
  },
  {
    "date": "2026-02-09",
    "title": "Multiplexed microwave resonators by frequency comb spectroscopy",
    "authors": "Angelo Greco, Jukka-Pekka Kaikkonen, Luca Chirolli, Alberto Ronzani, Jorden Senior, Francesco Giazotto, Alessandro Crippa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08890v1",
    "source": "arXiv",
    "abstract": "Coplanar waveguide resonators are central to the thriving field of circuit quantum electrodynamics. Recently, we have demonstrated the generation of a broadband microwave-frequency comb spectrum using a superconducting quantum interference device (SQUID) driven by a time-dependent magnetic field. Here, the frequency comb is used to spectroscopically probe a bank of coplanar microwave resonators, inductively coupled to a common transmission line, a standard circuit with a variety of applications. We compare the resonator line shape obtained from signals synthesized at room temperature using conventional electronics with the radiation produced in the cryogenic environment by our source, showing substantial equivalence in the estimation of the resonator quality factors. To measure non-uniformly spaced resonant frequencies, we drive the generator with a bi-chromatic tone to generate intermodulation products. Such a dense frequency comb spectrum enables simultaneous addressing of a few resonators via frequency multiplexing. Finally, we discuss the criteria for achieving effective spectroscopic coverage of a given frequency bandwidth."
  },
  {
    "date": "2026-02-09",
    "title": "Contrastive Learning for Diversity-Aware Product Recommendations in Retail",
    "authors": "Vasileios Karlis, Ezgi Yıldırım, David Vos, Maarten de Rijke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08886v1",
    "source": "arXiv",
    "abstract": "Recommender systems often struggle with long-tail distributions and limited item catalog exposure, where a small subset of popular items dominates recommendations. This challenge is especially critical in large-scale online retail settings with extensive and diverse product assortments. This paper introduces an approach to enhance catalog coverage without compromising recommendation quality in the existing digital recommendation pipeline at IKEA Retail. Drawing inspiration from recent advances in negative sampling to address popularity bias, we integrate contrastive learning with carefully selected negative samples. Through offline and online evaluations, we demonstrate that our method improves catalog coverage, ensuring a more diverse set of recommendations yet preserving strong recommendation performance."
  },
  {
    "date": "2026-02-09",
    "title": "Breaking the Simplification Bottleneck in Amortized Neural Symbolic Regression",
    "authors": "Paul Saegert, Ullrich Köthe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08885v1",
    "source": "arXiv",
    "abstract": "Symbolic regression (SR) aims to discover interpretable analytical expressions that accurately describe observed data. Amortized SR promises to be much more efficient than the predominant genetic programming SR methods, but currently struggles to scale to realistic scientific complexity. We find that a key obstacle is the lack of a fast reduction of equivalent expressions to a concise normalized form. Amortized SR has addressed this by general-purpose Computer Algebra Systems (CAS) like SymPy, but the high computational cost severely limits training and inference speed. We propose SimpliPy, a rule-based simplification engine achieving a 100-fold speed-up over SymPy at comparable quality. This enables substantial improvements in amortized SR, including scalability to much larger training sets, more efficient use of the per-expression token budget, and systematic training set decontamination with respect to equivalent test expressions. We demonstrate these advantages in our Flash-ANSR framework, which achieves much better accuracy than amortized baselines (NeSymReS, E2E) on the FastSRB benchmark. Moreover, it performs on par with state-of-the-art direct optimization (PySR) while recovering more concise instead of more complex expressions with increasing inference budget."
  },
  {
    "date": "2026-02-09",
    "title": "Error compensation without a time penalty: robust spin-lock-induced crossing in solution NMR",
    "authors": "Mohamed Sabba, Christian Bengs, Urvashi D. Heramun, Malcolm H. Levitt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08883v1",
    "source": "arXiv",
    "abstract": "A modification of the widely-used spin-lock-induced crossing (SLIC) procedure is proposed for the solution nuclear magnetic resonance (NMR) of strongly coupled nuclear spin systems, including singlet NMR and parahydrogen-enhanced hyperpolarised NMR experiments. The compensated-SLIC (cSLIC) scheme uses a repetitive sequence where the repeated element employs two different radiofrequency field amplitudes. Effective compensation for deviations in the radiofrequency field amplitude is achieved without increasing the overall duration of the SLIC sequence. The advantageous properties of cSLIC are demonstrated by numerical simulations and by representative experiments."
  },
  {
    "date": "2026-02-09",
    "title": "Learning Potentials for Dynamic Matching and Application to Heart Transplantation",
    "authors": "Itai Zilberstein, Ioannis Anagnostides, Zachary W. Sollie, Arman Kilic, Tuomas Sandholm",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08878v1",
    "source": "arXiv",
    "abstract": "Each year, thousands of patients in need of heart transplants face life-threatening wait times due to organ scarcity. While allocation policies aim to maximize population-level outcomes, current approaches often fail to account for the dynamic arrival of organs and the composition of waitlisted candidates, thereby hampering efficiency. The United States is transitioning from rigid, rule-based allocation to more flexible data-driven models. In this paper, we propose a novel framework for non-myopic policy optimization in general online matching relying on potentials, a concept originally introduced for kidney exchange. We develop scalable and accurate ways of learning potentials that are higher-dimensional and more expressive than prior approaches. Our approach is a form of self-supervised imitation learning: the potentials are trained to mimic an omniscient algorithm that has perfect foresight. We focus on the application of heart transplant allocation and demonstrate, using real historical data, that our policies significantly outperform prior approaches -- including the current US status quo policy and the proposed continuous distribution framework -- in optimizing for population-level outcomes. Our analysis and methods come at a pivotal moment in US policy, as the current heart transplant allocation system is under review. We propose a scalable and theoretically grounded path toward more effective organ allocation."
  },
  {
    "date": "2026-02-09",
    "title": "Stress-Testing Alignment Audits With Prompt-Level Strategic Deception",
    "authors": "Oliver Daniels, Perusha Moodley, Ben Marlin, David Lindner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08877v1",
    "source": "arXiv",
    "abstract": "Alignment audits aim to robustly identify hidden goals from strategic, situationally aware misaligned models. Despite this threat model, existing auditing methods have not been systematically stress-tested against deception strategies. We address this gap, implementing an automatic red-team pipeline that generates deception strategies (in the form of system prompts) tailored to specific white-box and black-box auditing methods. Stress-testing assistant prefills, user persona sampling, sparse autoencoders, and token embedding similarity methods against secret-keeping model organisms, our automatic red-team pipeline finds prompts that deceive both the black-box and white-box methods into confident, incorrect guesses. Our results provide the first documented evidence of activation-based strategic deception, and suggest that current black-box and white-box methods would not be robust to a sufficiently capable misaligned model."
  },
  {
    "date": "2026-02-09",
    "title": "ArkEval: Benchmarking and Evaluating Automated CodeRepair for ArkTS",
    "authors": "Bang Xie, Senjian Zhang, Zhiyuan Peng, Wei Chen, Chenhao Ying, Yuan Luo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08866v1",
    "source": "arXiv",
    "abstract": "Large language models have transformed code generation, enabling unprecedented automation in software development. As mobile ecosystems evolve, HarmonyOS has emerged as a critical platform requiring robust development tools. Software development for the HarmonyOS ecosystem relies heavily on ArkTS, a statically typed extension of TypeScript. Despite its growing importance, the ecosystem lacks robust tools for automated code repair, primarily due to the absence of a high-quality benchmark for evaluation. To address this gap, we present ArkEval, a unified framework for ArkTS automated repair workflow evaluation and benchmark construction. It provides the first comprehensive benchmark specifically designed for ArkTS automated program repair. We constructed this benchmark by mining issues from a large-scale official Huawei repository containing over 400 independent ArkTS applications. Through a rigorous multi-stage filtering process, we curated 502 reproducible issues. To ensure testability, we employed a novel LLM-based test generation and voting mechanism involving Claude and other models. Furthermore, we standardized problem statements to facilitate fair evaluation. Finally, we evaluated four state-of-the-art Large Language Models (LLMs) on our benchmark using a retrieval-augmented repair workflow. Our results highlight the current capabilities and limitations of LLMs in repairing ArkTS code, paving the way for future research in this low-resource language domain."
  },
  {
    "date": "2026-02-09",
    "title": "Regression modeling of multivariate precipitation extremes under regular variation",
    "authors": "Rishikesh Yadav, Arnab Hazra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08865v1",
    "source": "arXiv",
    "abstract": "Motivated by the EVA2025 data challenge, where we participated as the team DesiBoys, we propose a regression strategy within the framework of regular variation to estimate the occurrences and intensities of high precipitation extremes derived from different climate runs of the CESM2 Large Ensemble Community Project (LENS2). Our approach first empirically estimates the target quantities at sub-asymptotic (lower threshold) levels and sets them as response variables within a simple regression framework arising from the theoretical expressions of joint regular variation. Although a seasonal pattern is evident in the data, the precipitation intensities do not exhibit any significant long-term trends across years. Besides, we can safely assume the data to be independent across different climate model runs, thereby simplifying the modeling framework. Once the regression parameters are estimated, we employ a standard prediction approach to infer precipitation levels at very high quantiles. We calculate the confidence intervals using a nonparametric block bootstrap procedure. While a likelihood-based inference grounded in multivariate extreme value theory may provide more accurate estimates and confidence intervals, it would involve a significantly higher computational burden. Our proposed simple and computationally straightforward two-stage approach provides reasonable estimates for the desired quantities, securing us a joint second position in the final rankings of the EVA2025 conference data challenge competition."
  },
  {
    "date": "2026-02-09",
    "title": "Magnitude Distance: A Geometric Measure of Dataset Similarity",
    "authors": "Sahel Torkamani, Henry Gouk, Rik Sarkar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08859v1",
    "source": "arXiv",
    "abstract": "Quantifying the distance between datasets is a fundamental question in mathematics and machine learning. We propose \\textit{magnitude distance}, a novel distance metric defined on finite datasets using the notion of the \\emph{magnitude} of a metric space. The proposed distance incorporates a tunable scaling parameter, $t$, that controls the sensitivity to global structure (small $t$) and finer details (large $t$). We prove several theoretical properties of magnitude distance, including its limiting behavior across scales and conditions under which it satisfies key metric properties. In contrast to classical distances, we show that magnitude distance remains discriminative in high-dimensional settings when the scale is appropriately tuned. We further demonstrate how magnitude distance can be used as a training objective for push-forward generative models. Our experimental results support our theoretical analysis and demonstrate that magnitude distance provides meaningful signals, comparable to established distance-based generative approaches."
  },
  {
    "date": "2026-02-09",
    "title": "FlattenGPT: Depth Compression for Transformer with Layer Flattening",
    "authors": "Ruihan Xu, Qingpei Guo, Yao Zhu, Xiangyang Ji, Ming Yang, Shiliang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08858v1",
    "source": "arXiv",
    "abstract": "Recent works have indicated redundancy across transformer blocks, prompting the research of depth compression to prune less crucial blocks. However, current ways of entire-block pruning suffer from risks of discarding meaningful cues learned in those blocks, leading to substantial performance degradation. As another line of model compression, channel pruning can better preserve performance, while it cannot reduce model depth and is challenged by inconsistent pruning ratios for individual layers. To pursue better model compression and acceleration, this paper proposes \\textbf{FlattenGPT}, a novel way to detect and reduce depth-wise redundancies. By flatting two adjacent blocks into one, it compresses the network depth, meanwhile enables more effective parameter redundancy detection and removal. FlattenGPT allows to preserve the knowledge learned in all blocks, and remains consistent with the original transformer architecture. Extensive experiments demonstrate that FlattenGPT enhances model efficiency with a decent trade-off to performance. It outperforms existing pruning methods in both zero-shot accuracies and WikiText-2 perplexity across various model types and parameter sizes. On LLaMA-2/3 and Qwen-1.5 models, FlattenGPT retains 90-96\\% of zero-shot performance with a compression ratio of 20\\%. It also outperforms other pruning methods in accelerating LLM inference, making it promising for enhancing the efficiency of transformers."
  },
  {
    "date": "2026-02-09",
    "title": "karl. -- A Research Vehicle for Automated and Connected Driving",
    "authors": "Jean-Pierre Busch, Lukas Ostendorf, Guido Linden, Lennart Reiher, Till Beemelmanns, Bastian Lampe, Timo Woopen, Lutz Eckstein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08842v1",
    "source": "arXiv",
    "abstract": "As highly automated driving is transitioning from single-vehicle closed-access testing to commercial deployments of public ride-hailing in selected areas (e.g., Waymo), automated driving and connected cooperative intelligent transport systems (C-ITS) remain active fields of research. Even though simulation is omnipresent in the development and validation life cycle of automated and connected driving technology, the complex nature of public road traffic and software that masters it still requires real-world integration and testing with actual vehicles. Dedicated vehicles for research and development allow testing and validation of software and hardware components under real-world conditions early on. They also enable collecting and publishing real-world datasets that let others conduct research without vehicle access, and support early demonstration of futuristic use cases. In this paper, we present karl., our new research vehicle for automated and connected driving. Apart from major corporations, few institutions worldwide have access to their own L4-capable research vehicles, restricting their ability to carry out independent research. This paper aims to help bridge that gap by sharing the reasoning, design choices, and technical details that went into making karl. a flexible and powerful platform for research, engineering, and validation in the context of automated and connected driving. More impressions of karl. are available at https://karl.ac."
  },
  {
    "date": "2026-02-09",
    "title": "Flash annealing-engineered wafer-scale relaxor antiferroelectrics for enhanced energy storage performance",
    "authors": "Yizhuo Li, Kepeng Song, Meixiong Zhu, Xiaoqi Li, Zhaowei Zeng, KangMing Luo, Yuxuan Jiang, Zhe Zhang, Cuihong Li, Yujia Wang, Bing Li, Zhihong Wang, Zhidong Zhang, Weijin Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08841v1",
    "source": "arXiv",
    "abstract": "Dielectric capacitors are essential for energy storage systems due to their high-power density and fast operation speed. However, optimizing energy storage density with concurrent thermal stability remains a substantial challenge. Here, we develop a flash annealing process with ultrafast heating and cooling rates of 1000 oC/s, which facilitates the rapid crystallization of PbZrO3 film within a mere second, while locking its high-temperature microstructure to room temperature. This produces compact films with sub-grain boundaries fraction of 36%, nanodomains of several nanometers, and negligible lead volatilization. These contribute to relaxor antiferroelectric film with a high breakdown strength (4800 kV/cm) and large polarization (70 uC/cm2). Consequently, we have achieved a high energy storage density of 63.5 J/cm3 and outstanding thermal stability with performance degradation less than 3% up to 250 oC. Our approach is extendable to ferroelectrics like Pb(Zr0.52Ti0.48)O3 and on wafer scale, providing on-chip nonlinear dielectric energy storage solutions with industrial scalability."
  },
  {
    "date": "2026-02-09",
    "title": "High-Probability Heralded Entanglement via Repeated Spin-Photon Phase Encoding with Moderate Cooperativity",
    "authors": "Yu Liu, Martin B. Plenio",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08834v1",
    "source": "arXiv",
    "abstract": "We propose a heralded high-probability scheme to generate remote entanglement between moderate-cooperativity spin-cavity registers with high fidelity. In conventional single-shot interfaces, limited cooperativity restricts the spin-conditional optical response and thus strongly suppresses the success probability. Our proposal instead recycles a single incident photon for repeated interactions with the spin-cavity register, such that a small spin-conditional phase shift acquired on each round trip accumulates coherently to enable remote entanglement. Moreover, the repeated scheme enables higher spin-photon encoding efficiency by using a spectral-width-scaling photon pulse with a shorter duration. We show that, for realistic imperfections and losses, this repeated phase-encoding approach produces high-fidelity entangled states with an appreciable success probability even at cooperativity $C\\sim1$. Our protocol is particularly well suited to weakly coupled, cavity-based solid-state spin platforms and provides a route toward hybrid, photon-loss-tolerant distributed quantum computing."
  },
  {
    "date": "2026-02-09",
    "title": "From the confluent Heun equation to a new factorized and resummed gravitational waveform for circularized, nonspinning, compact binaries",
    "authors": "Andrea Cipriani, Alessandro Nagar, Francesco Fucito, José Francisco Morales",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08833v1",
    "source": "arXiv",
    "abstract": "We introduce a new factorized and resummed waveform for circularized, nonspinning, compact binaries that leverages on the solution of the Teukolsky equation once mapped into a confluent Heun equation. The structure of the solution allows one to identify new resummed factors that completely absorb all test-mass logarithms and transcendental numbers via exponentials and $Γ$-functions at any post-Newtonian (PN) order. The corresponding residual relativistic and phase corrections are thus polynomial with rational coefficients, that are in fact PN-truncated hypergeometric functions. Our approach complements the recent proposal of Ivanov et al. [Phys. Rev. Lett. 135 (2025) 14, 141401], notably recovering the corresponding renormalization group scaling of multipole moments from first principles and fixing the scaling constant. In the test mass limit, our approach (pushed up to 10PN) yields waveforms and fluxes that are globally more accurate than those obtained using the standard factorized approach of Damour et al. [Phys. Rev. D 79 (2009), 064004]. The method generalizes straightforwardly to comparable mass binaries implementing the new concept of universal anomalous dimension of multipole moments and might be eventually useful to improve current state of the art effective-one-body waveform models for coalescing binaries."
  },
  {
    "date": "2026-02-09",
    "title": "An $L^2$-$\\partial\\overline\\partial$-Lemma on a class of complete Kähler manifolds",
    "authors": "Riccardo Piovani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08831v1",
    "source": "arXiv",
    "abstract": "We prove an $L^2$-$\\partial\\overline\\partial$-Lemma involving smooth square integrable forms on complete Kähler manifolds, provided that the unique self-adjoint extension of the Hodge Laplacian on the Hilbert space of $L^2$-forms has a gap in its spectrum near zero. This generalises the classical $\\partial\\overline\\partial$-Lemma on compact Kähler manifolds."
  },
  {
    "date": "2026-02-09",
    "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
    "authors": "Hao Peng, Yunjia Qi, Xiaozhi Wang, Zijun Yao, Lei Hou, Juanzi Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08829v1",
    "source": "arXiv",
    "abstract": "Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward."
  },
  {
    "date": "2026-02-09",
    "title": "A Methodology for Effective Surrogate Learning in Complex Optimization",
    "authors": "Tomohiro Harada, Enrique Alba, Gabriel Luque",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08825v1",
    "source": "arXiv",
    "abstract": "Solving complex problems requires continuous effort in developing theory and practice to cope with larger, more difficult scenarios. Working with surrogates is normal for creating a proxy that realistically models the problem into the computer. Thus, the question of how to best define and characterize such a surrogate model is of the utmost importance. In this paper, we introduce the PTME methodology to study deep learning surrogates by analyzing their Precision, Time, Memory, and Energy consumption. We argue that only a combination of numerical and physical performance can lead to a surrogate that is both a trusted scientific substitute for the real problem and an efficient experimental artifact for scalable studies. Here, we propose different surrogates for a real problem in optimally organizing the network of traffic lights in European cities and perform a PTME study on the surrogates' sampling methods, dataset sizes, and resource consumption. We further use the built surrogates in new optimization metaheuristics for decision-making in real cities. We offer better techniques and conclude that the PTME methodology can be used as a guideline for other applications and solvers."
  },
  {
    "date": "2026-02-09",
    "title": "Omni-Video 2: Scaling MLLM-Conditioned Diffusion for Unified Video Generation and Editing",
    "authors": "Hao Yang, Zhiyu Tan, Jia Gong, Luozheng Qin, Hesen Chen, Xiaomeng Yang, Yuqing Sun, Yuetan Lin, Mengping Yang, Hao Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08820v1",
    "source": "arXiv",
    "abstract": "We present Omni-Video 2, a scalable and computationally efficient model that connects pretrained multimodal large-language models (MLLMs) with video diffusion models for unified video generation and editing. Our key idea is to exploit the understanding and reasoning capabilities of MLLMs to produce explicit target captions to interpret user instructions. In this way, the rich contextual representations from the understanding model are directly used to guide the generative process, thereby improving performance on complex and compositional editing. Moreover, a lightweight adapter is developed to inject multimodal conditional tokens into pretrained text-to-video diffusion models, allowing maximum reuse of their powerful generative priors in a parameter-efficient manner. Benefiting from these designs, we scale up Omni-Video 2 to a 14B video diffusion model on meticulously curated training data with quality, supporting high quality text-to-video generation and various video editing tasks such as object removal, addition, background change, complex motion editing, \\emph{etc.} We evaluate the performance of Omni-Video 2 on the FiVE benchmark for fine-grained video editing and the VBench benchmark for text-to-video generation. The results demonstrate its superior ability to follow complex compositional instructions in video editing, while also achieving competitive or superior quality in video generation tasks."
  },
  {
    "date": "2026-02-09",
    "title": "Bayesian Preference Learning for Test-Time Steerable Reward Models",
    "authors": "Jiwoo Hong, Shao Tang, Zhipeng Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08819v1",
    "source": "arXiv",
    "abstract": "Reward models are central to aligning language models with human preferences via reinforcement learning (RL). As RL is increasingly applied to settings such as verifiable rewards and multi-objective alignment, RMs are expected to encode more complex and multifaceted preference distributions. However, classifier RMs remain static once trained, limiting their adaptability at test time. We propose Variational In-Context Reward Modeling (ICRM), a novel Bayesian reward modeling objective that enables test-time steerability via in-context preference demonstrations. ICRM casts reward modeling as amortized variational inference over a latent preference probability under the Bradley-Terry model using a conjugate Beta prior. We show that ICRM adapt to unseen preference distributions at test time for both single and multi-objective settings. With more in-context demonstrations, ICRM gains 34% accuracy on SafeRLHF and 9% accuracy on RM-Bench in the single-objective setting, while widening the Pareto frontier with a 4% gain in hypervolume on helpfulness and refusal benchmarks. We further study the practical applicability of ICRM for RL training, showing that it can effectively encode verifiable rewards by outperforming a conventional RM in math reasoning. Finally, we provide theoretical guarantees that the variational objective admits a global interior optimum with finite confidence, and we analyze how KL regularization mitigates reward over-optimization."
  },
  {
    "date": "2026-02-09",
    "title": "Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity",
    "authors": "James Jewitt, Gopi Krishnan Rajbahadur, Hao Li, Bram Adams, Ahmed E. Hassan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08816v1",
    "source": "arXiv",
    "abstract": "Permissive licenses like MIT, Apache-2.0, and BSD-3-Clause dominate open-source AI, signaling that artifacts like models, datasets, and code can be freely used, modified, and redistributed. However, these licenses carry mandatory requirements: include the full license text, provide a copyright notice, and preserve upstream attribution, that remain unverified at scale. Failure to meet these conditions can place reuse outside the scope of the license, effectively leaving AI artifacts under default copyright for those uses and exposing downstream users to litigation. We call this phenomenon ``permissive washing'': labeling AI artifacts as free to use, while omitting the legal documentation required to make that label actionable. To assess how widespread permissive washing is in the AI supply chain, we empirically audit 124,278 dataset $\\rightarrow$ model $\\rightarrow$ application supply chains, spanning 3,338 datasets, 6,664 models, and 28,516 applications across Hugging Face and GitHub. We find that an astonishing 96.5\\% of datasets and 95.8\\% of models lack the required license text, only 2.3\\% of datasets and 3.2\\% of models satisfy both license text and copyright requirements, and even when upstream artifacts provide complete licensing evidence, attribution rarely propagates downstream: only 27.59\\% of models preserve compliant dataset notices and only 5.75\\% of applications preserve compliant model notices (with just 6.38\\% preserving any linked upstream notice). Practitioners cannot assume permissive labels confer the rights they claim: license files and notices, not metadata, are the source of legal truth. To support future research, we release our full audit dataset and reproducible pipeline."
  },
  {
    "date": "2026-02-09",
    "title": "Benchmarking the Born-Oppenheimer approximation with the Gaussian expansion method for doubly heavy hadrons",
    "authors": "Zi-Long Man, Hao Zhou, Si-Qiang Luo, Xiang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08811v1",
    "source": "arXiv",
    "abstract": "The Born-Oppenheimer approximation is widely used to investigate the properties of hydrogen-like systems and doubly heavy hadrons. However, the extent to which this approximation reliably captures the true features of such systems remains an open question. In this work, we adopt the results obtained with the Gaussian expansion method as a benchmark to assess the validity of the Born-Oppenheimer approximation in hadronic systems. We also investigate the dependence of the Born-Oppenheimer approximation results on the choice of trial wave functions. A comprehensive study of the Born-Oppenheimer approximation is carried out by performing calculations using Slater-type functions and Gaussian-type functions as trial wave functions, and by comparing the resulting predictions with those obtained from the Gaussian expansion method. We find that the calculations performed within the Born-Oppenheimer approximation are close to those obtained with the Gaussian expansion method when the heavy-quark mass is relatively small. However, as the heavy-quark mass increases, calculations employing Slater-type functions yield larger values than those from the Gaussian expansion method, whereas those using Gaussian-type functions lead to smaller ones. The use of Slater-type functions generally leads to an enhanced binding energy. The underestimation observed in Born-Oppenheimer approximation calculations with Gaussian-type functions primarily stems from the neglect of non-adiabatic corrections. This comparative study provides deeper insight into the structure of doubly heavy hadrons and clarifies the applicability and limitations of the Born-Oppenheimer treatment in these systems."
  },
  {
    "date": "2026-02-09",
    "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs",
    "authors": "Yapei Chang, Kyle Lo, Mohit Iyyer, Luca Soldaini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08808v1",
    "source": "arXiv",
    "abstract": "Generating step-by-step \"how-to\" procedures is a key LLM capability: how-to advice is commonly requested in chatbots, and step-by-step planning is critical for reasoning over complex tasks. Yet, measuring and improving procedural validity at scale on real-world tasks remains challenging and understudied. To address this, we introduce How2Everything, a scalable framework to evaluate and improve goal-conditioned procedure generation. Our framework includes How2Mine, which mines 351K procedures from 980K web pages across 14 topics and readily scales to larger corpora. From this pool we build How2Bench, a 7K-example evaluation set balanced across topics. To reliably score model outputs, we develop How2Score, an evaluation protocol that uses an LLM judge to detect whether a generation contains any critical failure that would prevent achieving the goal. For low-cost, reproducible evaluation, we distill a frontier model into an open 8B model, achieving 80.5% agreement with human annotators. How2Bench reveals clear scaling trends across model sizes and training stages, providing signal early in pretraining. Finally, RL using How2Score as a reward improves performance on How2Bench by >10 points across three models without systematic regressions on standard benchmarks, with gains robust to superficial source-document memorization or format compliance. Taken together, How2Everything shows how pretraining web data can support a closed loop of capability evaluation and improvement at scale."
  },
  {
    "date": "2026-02-09",
    "title": "CI-groups for ternary structures",
    "authors": "Ted Dobson, Joy Morris, Mikhail Muzychuk, Pablo Spiga",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08802v1",
    "source": "arXiv",
    "abstract": "We explicitly determine all CI-groups with respect to ternary relational structures that have the form $C \\times D$, where $C$ is cyclic and $D$ is either a dicyclic group whose order is not divisible by $3$ or a dihedral group. Such groups are also CI-groups with respect to graphs and digraphs."
  },
  {
    "date": "2026-02-09",
    "title": "A Generic Service-Oriented Function Offloading Framework for Connected Automated Vehicles",
    "authors": "Robin Dehler, Michael Buchholz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08799v1",
    "source": "arXiv",
    "abstract": "Function offloading is a promising solution to address limitations concerning computational capacity and available energy of Connected Automated Vehicles~(CAVs) or other autonomous robots by distributing computational tasks between local and remote computing devices in form of distributed services. This paper presents a generic function offloading framework that can be used to offload an arbitrary set of computational tasks with a focus on autonomous driving. To provide flexibility, the function offloading framework is designed to incorporate different offloading decision making algorithms and quality of service~(QoS) requirements that can be adjusted to different scenarios or the objectives of the CAVs. With a focus on the applicability, we propose an efficient location-based approach, where the decision whether tasks are processed locally or remotely depends on the location of the CAV. We apply the proposed framework on the use case of service-oriented trajectory planning, where we offload the trajectory planning task of CAVs to a Multi-Access Edge Computing~(MEC) server. The evaluation is conducted in both simulation and real-world application. It demonstrates the potential of the function offloading framework to guarantee the QoS for trajectory planning while improving the computational efficiency of the CAVs. Moreover, the simulation results also show the adaptability of the framework to diverse scenarios involving simultaneous offloading requests from multiple CAVs."
  },
  {
    "date": "2026-02-09",
    "title": "Addressing data annotation scarcity in Brain Tumor Segmentation on 3D MRI scan Using a Semi-Supervised Teacher-Student Framework",
    "authors": "Jiaming Liu, Cheng Ding, Daoqiang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08797v1",
    "source": "arXiv",
    "abstract": "Accurate brain tumor segmentation from MRI is limited by expensive annotations and data heterogeneity across scanners and sites. We propose a semi-supervised teacher-student framework that combines an uncertainty-aware pseudo-labeling teacher with a progressive, confidence-based curriculum for the student. The teacher produces probabilistic masks and per-pixel uncertainty; unlabeled scans are ranked by image-level confidence and introduced in stages, while a dual-loss objective trains the student to learn from high-confidence regions and unlearn low-confidence ones. Agreement-based refinement further improves pseudo-label quality. On BraTS 2021, validation DSC increased from 0.393 (10% data) to 0.872 (100%), with the largest gains in early stages, demonstrating data efficiency. The teacher reached a validation DSC of 0.922, and the student surpassed the teacher on tumor subregions (e.g., NCR/NET 0.797 and Edema 0.980); notably, the student recovered the Enhancing class (DSC 0.620) where the teacher failed. These results show that confidence-driven curricula and selective unlearning provide robust segmentation under limited supervision and noisy pseudo-labels."
  },
  {
    "date": "2026-02-09",
    "title": "A Multi-objective Evolutionary Algorithm Based on Bi-population with Uniform Sampling for Neural Architecture Search",
    "authors": "Yu Xue, Pengcheng Jiang, Chenchen Zhu, Yong Zhang, Ran Cheng, Kaizhou Gao, Dunwei Gong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08513v1",
    "source": "arXiv",
    "abstract": "Neural architecture search (NAS) automates neural network design, improving efficiency over manual approaches. However, efficiently discovering high-performance neural network architectures that simultaneously optimize multiple objectives remains a significant challenge in NAS. Existing methods often suffer from limited population diversity and inadequate exploration of the search space, particularly in regions with extreme complexity values. To address these challenges, we propose MOEA-BUS, an innovative multi-objective evolutionary algorithm based on bi-population with uniform sampling for neural architecture search, aimed at simultaneously optimizing both accuracy and network complexity. In MOEA-BUS, a novel uniform sampling method is proposed to initialize the population, ensuring that architectures are distributed uniformly across the objective space. Furthermore, to enhance exploration, we deploy a bi-population framework where two populations evolve synergistically, facilitating comprehensive search space coverage. Experiments on CIFAR-10 and ImageNet demonstrate MOEA-BUS's superiority, achieving top-1 accuracies of 98.39% on CIFAR-10, and 80.03% on ImageNet. Notably, it achieves 78.28% accuracy on ImageNet with only 446M MAdds. Ablation studies confirm that both uniform sampling and bi-population mechanisms enhance population diversity and performance. Additionally, in terms of the Kendall's tau coefficient, the SVM achieves an improvement of at least 0.035 compared to the other three commonly used machine learning models, and uniform sampling provided an enhancement of approximately 0.07."
  },
  {
    "date": "2026-02-09",
    "title": "Clique-Based Deletion-Correcting Codes via Penalty-Guided Clique Search",
    "authors": "Aniruddh Pandav, Rajshekhar V Bhat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08952v1",
    "source": "arXiv",
    "abstract": "We study the construction of $d$-deletion-correcting binary codes by formulating the problem as a Maximum Clique Problem (MCP). In this formulation, vertices represent candidate codewords and edges connect pairs whose longest common subsequence (LCS) distance guarantees correction of up to $d$ deletions. A valid codebook corresponds to a clique in the resulting graph, and finding the largest codebook is equivalent to identifying a maximum clique. While MCP-based formulations for deletion-correcting codes have previously been explored, we demonstrate that applying Penalty-Guided Clique Search (PGCS), a lightweight stochastic clique-search heuristic inspired by Dynamic Local Search (DLS), consistently yields larger codebooks than existing graph-based heuristics, including minimum-degree and coloring methods, for block lengths $n = 8,9,\\dots,14$ and deletion parameters $d = 1,2,3$. In several finite-length regimes, the resulting codebooks match known optimal sizes and outperform classical constructions such as Helberg codes. For decoding under segmented reception, where codeword boundaries are known, we propose an optimized LCS-based decoder that exploits symbol-count filtering and early termination to substantially reduce the number of LCS evaluations while preserving exact decoding guarantees. These optimizations lead to significantly lower average-case decoding complexity than the baseline $O(|C| n^2)$ approach."
  },
  {
    "date": "2026-02-09",
    "title": "Distortion of Metric Voting with Bounded Randomness",
    "authors": "Ziyi Cai, D. D. Gao, Prasanna Ramakrishnan, Kangning Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08871v1",
    "source": "arXiv",
    "abstract": "We study the design of voting rules in the metric distortion framework. It is known that any deterministic rule suffers distortion of at least $3$, and that randomized rules can achieve distortion strictly less than $3$, often at the cost of reduced transparency and interpretability. In this work, we explore the trade-off between these paradigms by asking whether it is possible to break the distortion barrier of $3$ using only \"bounded\" randomness. We answer in the affirmative by presenting a voting rule that (1) achieves distortion of at most $3 - \\varepsilon$ for some absolute constant $\\varepsilon > 0$, and (2) selects a winner uniformly at random from a deterministically identified list of constant size. Our analysis builds on new structural results for the distortion and approximation of Maximal Lotteries and Stable Lotteries."
  },
  {
    "date": "2026-02-09",
    "title": "Fundamental Limits of Community Detection in Contextual Multi-Layer Stochastic Block Models",
    "authors": "Shuyang Gong, Dong Huang, Zhangsong Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08173v1",
    "source": "arXiv",
    "abstract": "We consider the problem of community detection from the joint observation of a high-dimensional covariate matrix and $L$ sparse networks, all encoding noisy, partial information about the latent community labels of $n$ subjects. In the asymptotic regime where the networks have constant average degree and the number of features $p$ grows proportionally with $n$, we derive a sharp threshold under which detecting and estimating the subject labels is possible. Our results extend the work of \\cite{MN23} to the constant-degree regime with noisy measurements, and also resolve a conjecture in \\cite{YLS24+} when the number of networks is a constant. Our information-theoretic lower bound is obtained via a novel comparison inequality between Bernoulli and Gaussian moments, as well as a statistical variant of the ``recovery to chi-square divergence reduction'' argument inspired by \\cite{DHSS25}. On the algorithmic side, we design efficient algorithms based on counting decorated cycles and decorated paths and prove that they achieve the sharp threshold for both detection and weak recovery. In particular, our results show that there is no statistical-computational gap in this setting."
  },
  {
    "date": "2026-02-09",
    "title": "$d$-Wave Surface Altermagnetism in Centrosymmetric Collinear Antiferromagnets",
    "authors": "Ersoy Sasioglu, Ingrid Mertig, Samir Lounis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08790v1",
    "source": "arXiv",
    "abstract": "Broken inversion symmetry at the surfaces of centrosymmetric collinear antiferromagnets lifts the combined inversion and time-reversal symmetry ($PT$) and can generate nonrelativistic d-wave spin splitting, termed surface altermagnetism. Combining symmetry analysis with first-principles calculations, we show that surface inversion breaking, while necessary, is not sufficient for this effect. Surface altermagnetism emerges only when the surface termination simultaneously breaks both $PT$ and translation--time-reversal symmetry ($tT$), thereby inducing magnetic sublattice inequivalence between antiferromagnetically coupled surface moments. We demonstrate this mechanism explicitly for the G-type antiferromagnets V$_3$Al and BaMn$_2$Sb$_2$, and show that the same symmetry criterion applies broadly across distinct structural families of centrosymmetric antiferromagnets. These results establish a general, symmetry-based route to realizing robust, exchange-driven spin polarization at antiferromagnetic surfaces and interfaces."
  },
  {
    "date": "2026-02-09",
    "title": "Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure",
    "authors": "Zirui Li, Xuefeng Bai, Kehai Chen, Yizhi Li, Jian Yang, Chenghua Lin, Min Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08783v1",
    "source": "arXiv",
    "abstract": "Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems."
  },
  {
    "date": "2026-02-09",
    "title": "Primordial features as probes of baryogenesis from supersymmetric flat directions",
    "authors": "Yi-Peng Wu, Xingang Chen, Nino Ephremidze, Lingfeng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08781v1",
    "source": "arXiv",
    "abstract": "The Affleck-Dine mechanism is a leading baryogenesis scenario in which scalar condensates form coherently during inflation along supersymmetric flat directions that are lifted by supersymmetry-breaking effects. We update the viable parameter space for baryogenesis using recent Cosmic Microwave Background constraints on baryon-density isocurvature perturbations, taking the quantum fluctuations of the scalar condensate generated during inflation as initial conditions. We then show that primordial features arising from the inflaton sector can serve as a unique probe of baryogenesis models, whose mechanisms are otherwise difficult to access directly due to their high energy scales. These primordial features leave correlated imprints, such as sharp feature signals and clock signals, on both the curvature and baryon-density isocurvature perturbations, providing direct evidence for the existence of both light and heavy modes involved in the Affleck-Dine mechanism."
  },
  {
    "date": "2026-02-09",
    "title": "The equivalence of quantum deletion and insertion errors on permutation-invariant codes",
    "authors": "Lewis Bulled, Yingkai Ouyang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08780v1",
    "source": "arXiv",
    "abstract": "Quantum synchronisation errors are a class of quantum errors that change the number of qubits in a quantum system. The classical error correction of synchronisation errors has been well-studied, including an insertion-deletion equivalence more than a half-century ago, but little progress has been made towards the quantum counterpart since the birth of quantum error correction. We address the longstanding problem of a quantum insertion-deletion equivalence on permutation-invariant codes, detailing the conditions under which such codes are $t$-insertion error-correctable. We extend these conditions to quantum insdel errors, formulating a more restrictive set of conditions under which permutation-invariant codes are $(t,s)$-insdel error-correctable. Our work resolves many of the outstanding questions regarding the quantum error correction of synchronisation errors."
  },
  {
    "date": "2026-02-09",
    "title": "Partition theorems for Ketonen-Solovay largeness",
    "authors": "Quentin Le Houérou, Ludovic Patey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08778v1",
    "source": "arXiv",
    "abstract": "We develop the framework of $α$-largeness introduced by Ketonen and Solovay, by proving a partition theorem for $α$-large sets with $α< ε_0$ which generalizes theorems from Ketonen and Solovay and from Bigorajska and Kotlarski. We also prove that for every $ω^{nk+3}$-large set $X$ with $\\min X \\geq 18$, every coloring $f : [X]^2 \\to k$ admits an $ω^n$-large $f$-homogeneous subset. This bound is tight, up to an additive constant."
  },
  {
    "date": "2026-02-09",
    "title": "Passivity-exploiting stabilization of semilinear single-track vehicle models with distributed tire friction dynamics",
    "authors": "Luigi Romano, Ole Morten Aamo, Miroslav Krstić, Jan Åslund, Erik Frisk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08767v1",
    "source": "arXiv",
    "abstract": "This paper addresses the local stabilization problem for semilinear single-track vehicle models with distributed tire friction dynamics, represented as interconnections of ordinary differential equations (ODEs) and hyperbolic partial differential equations (PDEs). A passivity-exploiting backstepping design is presented, which leverages the strict dissipativity properties of the PDE subsystem to achieve exponential stabilization of the considered ODE-PDE interconnection around a prescribed equilibrium. Sufficient conditions for local well-posedness and exponential convergence are derived by constructing a Lyapunov functional combining the lumped and distributed states. Both state-feedback and output-feedback controllers are synthesized, the latter relying on a cascaded observer. The theoretical results are corroborated with numerical simulations, considering non-ideal scenarios and accounting for external disturbances and uncertainties. Simulation results confirm that the proposed control strategy can effectively and robustly stabilize oversteer vehicles at high speeds, demonstrating the relevance of the approach for improving the safety and performance in automotive applications."
  },
  {
    "date": "2026-02-09",
    "title": "Josephson diode and spin-valve effects on the surface of altermagnet CrSb",
    "authors": "V. D. Esin, D. Yu. Kazmin, Yu. S. Barash, A. V. Timonina, N. N. Kolesnikov, E. V. Deviatov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08766v1",
    "source": "arXiv",
    "abstract": "We experimentally investigate charge transport in In-CrSb and In-CrSb-In proximity devices, which are formed as junctions between superconducting indium leads and thick single crystal flakes of altermagnet CrSb. For double In-CrSb-In junctions, the obtained $dV/dI(B)$ curves are mirrored in respect to zero field for two magnetic field sweep directions, which is characteristic behavior of a Josephson spin valve. Also, we demonstrate Josephson diode effect by direct measurement of the critical current for two opposite directions in external magnetic field. We interpret these observations as a joint effect of the spin-polarized topological surface states and the altermagnetic spin splitting of the bulk bands in CrSb. For a single In-CrSb interface, the superconducting gap oscillates in magnetic field for both field orientations, which strongly resembles the transition into the Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) state. The latter is based on finite-momentum Cooper pairing against a background of the Zeeman splitting, so it is fully compatible with the requirements for the Josephson diode effect."
  },
  {
    "date": "2026-02-09",
    "title": "Redundancy-Free View Alignment for Multimodal Human Activity Recognition with Arbitrarily Missing Views",
    "authors": "Duc-Anh Nguyen, Nhien-An Le-Khac",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08755v1",
    "source": "arXiv",
    "abstract": "Multimodal multiview learning seeks to integrate information from diverse sources to enhance task performance. Existing approaches often struggle with flexible view configurations, including arbitrary view combinations, numbers of views, and heterogeneous modalities. Focusing on the context of human activity recognition, we propose RALIS, a model that combines multiview contrastive learning with a mixture-of-experts module to support arbitrary view availability during both training and inference. Instead of trying to reconstruct missing views, an adjusted center contrastive loss is used for self-supervised representation learning and view alignment, mitigating the impact of missing views on multiview fusion. This loss formulation allows for the integration of view weights to account for view quality. Additionally, it reduces computational complexity from $O(V^2)$ to $O(V)$, where $V$ is the number of views. To address residual discrepancies not captured by contrastive learning, we employ a mixture-of-experts module with a specialized load balancing strategy, tasked with adapting to arbitrary view combinations. We highlight the geometric relationship among components in our model and how they combine well in the latent space. RALIS is validated on four datasets encompassing inertial and human pose modalities, with the number of views ranging from three to nine, demonstrating its performance and flexibility."
  },
  {
    "date": "2026-02-09",
    "title": "Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing",
    "authors": "Jona te Lintelo, Lichao Wu, Stjepan Picek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08741v1",
    "source": "arXiv",
    "abstract": "The rapid adoption of Mixture-of-Experts (MoE) architectures marks a major shift in the deployment of Large Language Models (LLMs). MoE LLMs improve scaling efficiency by activating only a small subset of parameters per token, but their routing structure introduces new safety attack surfaces. We find that safety-critical behaviors in MoE LLMs (e.g., refusal) are concentrated in a small set of experts rather than being uniformly distributed. Building on this, we propose Large Language Lobotomy (L$^3$), a training-free, architecture-agnostic attack that compromises safety alignment by exploiting expert routing dynamics. L$^3$ learns routing patterns that correlate with refusal, attributes safety behavior to specific experts, and adaptively silences the most safety-relevant experts until harmful outputs are produced. We evaluate L$^3$ on eight state-of-the-art open-source MoE LLMs and show that our adaptive expert silencing increases average attack success from 7.3% to 70.4%, reaching up to 86.3%, outperforming prior training-free MoE jailbreak methods. Moreover, bypassing guardrails typically requires silencing fewer than 20% of layer-wise experts while largely preserving general language utility. These results reveal a fundamental tension between efficiency-driven MoE design and robust safety alignment and motivate distributing safety mechanisms more robustly in future MoE LLMs with architecture- and routing-aware methods."
  },
  {
    "date": "2026-02-09",
    "title": "From Correspondence to Actions: Human-Like Multi-Image Spatial Reasoning in Multi-modal Large Language Models",
    "authors": "Masanari Oi, Koki Maeda, Ryuto Koike, Daisuke Oba, Nakamasa Inoue, Naoaki Okazaki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08735v1",
    "source": "arXiv",
    "abstract": "While multimodal large language models (MLLMs) have made substantial progress in single-image spatial reasoning, multi-image spatial reasoning, which requires integration of information from multiple viewpoints, remains challenging. Cognitive studies suggest that humans address such tasks through two mechanisms: cross-view correspondence, which identifies regions across different views that correspond to the same physical locations, and stepwise viewpoint transformation, which composes relative viewpoint changes sequentially. However, existing studies incorporate these mechanisms only partially and often implicitly, without explicit supervision for both. We propose Human-Aware Training for Cross-view correspondence and viewpoint cHange (HATCH), a training framework with two complementary objectives: (1) Patch-Level Spatial Alignment, which encourages patch representations to align across views for spatially corresponding regions, and (2) Action-then-Answer Reasoning, which requires the model to generate explicit viewpoint transition actions before predicting the final answer. Experiments on three benchmarks demonstrate that HATCH consistently outperforms baselines of comparable size by a clear margin and achieves competitive results against much larger models, while preserving single-image reasoning capabilities."
  },
  {
    "date": "2026-02-09",
    "title": "Algorithmic Governance in the United States: A Multi-Level Case Analysis of AI Deployment Across Federal, State, and Municipal Authorities",
    "authors": "Maxim Dedyaev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08728v1",
    "source": "arXiv",
    "abstract": "The rapid expansion of artificial intelligence in public governance has generated strong optimism about faster processes, smarter decisions, and more modern administrative systems. Yet despite this enthusiasm, we still know surprisingly little about how AI actually takes shape inside different layers of government. Especially in federal systems where authority is fragmented across multiple levels. In practice, the same algorithm can serve very different purposes. This study responds to that gap by examining how AI is used across federal, state, and municipal levels in the United States. Drawing on a comparative qualitative analysis of thirty AI implementation cases, and guided by a digital-era governance framework combined with a sociotechnical perspective, the study identifies two broad modes of algorithmic governance: control-oriented systems and support-oriented systems. The findings reveal a clear pattern of functional differentiation across levels of government. At the federal level, AI is most often institutionalized as a tool for high-stakes control: supporting surveillance, enforcement, and regulatory oversight. State governments occupy a more ambiguous middle ground, where AI frequently combines supportive functions with algorithmic gatekeeping, particularly in areas such as welfare administration and public health. Municipal governments, by contrast, tend to deploy AI in more pragmatic and service-oriented ways, using it to streamline everyday operations and improve direct interactions with residents. By foregrounding institutional context, this study advances debates on algorithmic governance by demonstrating that the character, function, and risks of AI in the public sector are fundamentally shaped by the level of governance at which these systems are deployed."
  },
  {
    "date": "2026-02-09",
    "title": "Rotated Lights for Consistent and Efficient 2D Gaussians Inverse Rendering",
    "authors": "Geng Lin, Matthias Zwicker",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08724v1",
    "source": "arXiv",
    "abstract": "Inverse rendering aims to decompose a scene into its geometry, material properties and light conditions under a certain rendering model. It has wide applications like view synthesis, relighting, and scene editing. In recent years, inverse rendering methods have been inspired by view synthesis approaches like neural radiance fields and Gaussian splatting, which are capable of efficiently decomposing a scene into its geometry and radiance. They then further estimate the material and lighting that lead to the observed scene radiance. However, the latter step is highly ambiguous and prior works suffer from inaccurate color and baked shadows in their albedo estimation albeit their regularization. To this end, we propose RotLight, a simple capturing setup, to address the ambiguity. Compared to a usual capture, RotLight only requires the object to be rotated several times during the process. We show that as few as two rotations is effective in reducing artifacts. To further improve 2DGS-based inverse rendering, we additionally introduce a proxy mesh that not only allows accurate incident light tracing, but also enables a residual constraint and improves global illumination handling. We demonstrate with both synthetic and real world datasets that our method achieves superior albedo estimation while keeping efficient computation."
  },
  {
    "date": "2026-02-09",
    "title": "Data Reconstruction: Identifiability and Optimization with Sample Splitting",
    "authors": "Yujie Shen, Zihan Wang, Jian Qian, Qi Lei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08723v1",
    "source": "arXiv",
    "abstract": "Training data reconstruction from KKT conditions has shown striking empirical success, yet it remains unclear when the resulting KKT equations have unique solutions and, even in identifiable regimes, how to reliably recover solutions by optimization. This work hereby focuses on these two complementary questions: identifiability and optimization. On the identifiability side, we discuss the sufficient conditions for KKT system of two-layer networks with polynomial activations to uniquely determine the training data, providing a theoretical explanation of when and why reconstruction is possible. On the optimization side, we introduce sample splitting, a curvature-aware refinement step applicable to general reconstruction objectives (not limited to KKT-based formulations): it creates additional descent directions to escape poor stationary points and refine solutions. Experiments demonstrate that augmenting several existing reconstruction methods with sample splitting consistently improves reconstruction performance."
  },
  {
    "date": "2026-02-09",
    "title": "PERSPECTRA: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments",
    "authors": "Shangrui Nie, Kian Omoomi, Lucie Flek, Zhixue Zhao, Charles Welch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08716v1",
    "source": "arXiv",
    "abstract": "Pluralism, the capacity to engage with diverse perspectives without collapsing them into a single viewpoint, is critical for developing large language models that faithfully reflect human heterogeneity. Yet this characteristic has not been carefully examined in the LLM research community and remains absent from most alignment studies. Debate-oriented sources provide a natural entry point for pluralism research. Previous work builds on online debate sources but remains constrained by costly human validation. Other debate-rich platforms such as Reddit and Kialo also offer promising material: Reddit provides linguistic diversity and scale but lacks clear argumentative structure, while Kialo supplies explicit pro/con graphs but remains overly concise and detached from natural discourse. We introduce PERSPECTRA, a pluralist benchmark that integrates the structural clarity of Kialo debate graphs with the linguistic diversity of real Reddit discussions. Using a controlled retrieval-and-expansion pipeline, we construct 3,810 enriched arguments spanning 762 pro/con stances on 100 controversial topics. Each opinion is expanded to multiple naturalistic variants, enabling robust evaluation of pluralism. We initialise three tasks with PERSPECTRA: opinion counting (identifying distinct viewpoints), opinion matching (aligning supporting stances and discourse to source opinions), and polarity check (inferring aggregate stance in mixed discourse). Experiments with state-of-the-art open-source and proprietary LLMs, highlight systematic failures, such as overestimating the number of viewpoints and misclassifying concessive structures, underscoring the difficulty of pluralism-aware understanding and reasoning. By combining diversity with structure, PERSPECTRA establishes the first scalable, configurable benchmark for evaluating how well models represent, distinguish, and reason over multiple perspectives."
  },
  {
    "date": "2026-02-09",
    "title": "Weighted Hardy-Sobolev type inequalities with boundary terms",
    "authors": "João Marcos do Ò, Marcelo Furtado, Everaldo Medeiros, Jesse Ratzkin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08702v1",
    "source": "arXiv",
    "abstract": "In this paper we establish a new class of weighted Hardy-Sobolev type inequalities under mild monotonicity assumptions on the weight function. As a consequence, we derive the corresponding weighted Sobolev and trace-type inequalities. These results play an important role in the analysis of elliptic problems with Neumann or Robin boundary conditions in unbounded domains."
  },
  {
    "date": "2026-02-09",
    "title": "LLM-Enhanced Wearables for Comprehensible Health Guidance in LMICs",
    "authors": "Mohammad Shaharyar Ahsan, Areeba Shahzad Shaikh, Maham Zahid, Umer Irfan, Maryam Mustafa, Naveed Anwar Bhatti, Muhammad Hamad Alizai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08701v1",
    "source": "arXiv",
    "abstract": "Personal health monitoring via IoT in LMICs is limited by affordability, low digital literacy, and limited health data comprehension. We present Guardian Angel, a low-cost, screenless wearable paired with a WhatsApp-based LLM agent that delivers plain-language, personalized insights. The LLM operates directly on raw, noisy sensor waveforms and is robust to the poor signal quality of low-cost hardware. On a benchmark dataset, a standard open-source algorithm produced valid outputs for only 70.29% of segments, whereas Guardian Angel achieved 100% availability (reported as coverage under field noise, distinct from accuracy), yielding a continuous and understandable physiological record. In a 96-hour study involving 20 participants (1,920 participant-hours), users demonstrated significant improvements in health data comprehension and mindfulness of vital signs. These results suggest a practical approach to enhancing health literacy and adoption in resource-constrained settings."
  },
  {
    "date": "2026-02-09",
    "title": "Improving Reliability of Hybrid Bit-Semantic Communications for Cellular Networks",
    "authors": "Nikos G. Evgenidis, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, Ioannis Krikidis, George K. Karagiannidis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08697v1",
    "source": "arXiv",
    "abstract": "Semantic communications (SemComs) have been considered as a promising solution to reduce the amount of transmitted information, thus paving the way for more energy-and spectrum-efficient wireless networks. Nevertheless, SemComs rely heavily on the utilization of deep neural networks (DNNs) at the transceivers, which limit the accuracy between the original and reconstructed data and are challenging to implement in practice due to increased architecture complexity. Thus, hybrid cellular networks that utilize both conventional bit communications (BitComs) and SemComs have been introduced to bridge the gap between required and existing infrastructure. To facilitate such networks, in this work, we investigate reliability by deriving closed-form expressions for the outage probability of the network. Additionally, we propose a generalized outage probability through which the cell radius that achieves a desired outage threshold for a specific range of users is calculated in closed form. Additionally, to consider the practical limitations caused by the specialized dedicated hardware and the increased memory and computational resources that are required to support SemCom, a semantic utilization metric is proposed. Based on this metric, we express the probability that a specific number of users select SemCom transmission and calculate the optimal cell radius for that number in closed form. Simulation results validate the derived analytical expressions and the characterized design properties of the cell radius found through the proposed metrics, providing useful insights."
  },
  {
    "date": "2026-02-09",
    "title": "Prototype-Based Disentanglement for Controllable Dysarthric Speech Synthesis",
    "authors": "Haoshen Wang, Xueli Zhong, Bingbing Lin, Jia Huang, Xingduo Pan, Shengxiang Liang, Nizhuan Wang, Wai Ting Siok",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08696v1",
    "source": "arXiv",
    "abstract": "Dysarthric speech exhibits high variability and limited labeled data, posing major challenges for both automatic speech recognition (ASR) and assistive speech technologies. Existing approaches rely on synthetic data augmentation or speech reconstruction, yet often entangle speaker identity with pathological articulation, limiting controllability and robustness. In this paper, we propose ProtoDisent-TTS, a prototype-based disentanglement TTS framework built on a pre-trained text-to-speech backbone that factorizes speaker timbre and dysarthric articulation within a unified latent space. A pathology prototype codebook provides interpretable and controllable representations of healthy and dysarthric speech patterns, while a dual-classifier objective with a gradient reversal layer enforces invariance of speaker embeddings to pathological attributes. Experiments on the TORGO dataset demonstrate that this design enables bidirectional transformation between healthy and dysarthric speech, leading to consistent ASR performance gains and robust, speaker-aware speech reconstruction."
  },
  {
    "date": "2026-02-09",
    "title": "Trapped by simplicity: When Transformers fail to learn from noisy features",
    "authors": "Evan Peters, Ando Deng, Matheus H. Zambianco, Devin Blankespoor, Achim Kempf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08695v1",
    "source": "arXiv",
    "abstract": "Noise is ubiquitous in data used to train large language models, but it is not well understood whether these models are able to correctly generalize to inputs generated without noise. Here, we study noise-robust learning: are transformers trained on data with noisy features able to find a target function that correctly predicts labels for noiseless features? We show that transformers succeed at noise-robust learning for a selection of $k$-sparse parity and majority functions, compared to LSTMs which fail at this task for even modest feature noise. However, we find that transformers typically fail at noise-robust learning of random $k$-juntas, especially when the boolean sensitivity of the optimal solution is smaller than that of the target function. We argue that this failure is due to a combination of two factors: transformers' bias toward simpler functions, combined with an observation that the optimal function for noise-robust learning typically has lower sensitivity than the target function for random boolean functions. We test this hypothesis by exploiting transformers' simplicity bias to trap them in an incorrect solution, but show that transformers can escape this trap by training with an additional loss term penalizing high-sensitivity solutions. Overall, we find that transformers are particularly ineffective for learning boolean functions in the presence of feature noise."
  },
  {
    "date": "2026-02-09",
    "title": "PBLean: Pseudo-Boolean Proof Certificates for Lean 4",
    "authors": "Stefan Szeider",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08692v1",
    "source": "arXiv",
    "abstract": "We present PBLean, a method for importing VeriPB pseudo-Boolean (PB) proof certificates into Lean 4. Key to our approach is reflection: a Boolean checker function whose soundness is fully proved in Lean and executed as compiled native code. Our method scales to proofs with tens of thousands of steps that would exhaust memory under explicit proof-term construction. Our checker supports all VeriPB kernel rules, including cutting-plane derivations and proof-by-contradiction subproofs. In contrast to external verified checkers that produce verdicts, our integration yields Lean theorems that can serve as composable lemmas in larger formal developments. To derive theorems about the original combinatorial problems rather than about PB constraints alone, we support verified encodings. This closes the trust gap between solver output and problem semantics since the constraint translation and its correctness proof are both formalized in Lean. We demonstrate the approach on various combinatorial problems."
  },
  {
    "date": "2026-02-09",
    "title": "Learning To Sample From Diffusion Models Via Inverse Reinforcement Learning",
    "authors": "Constant Bourdrez, Alexandre Vérine, Olivier Cappé",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08689v1",
    "source": "arXiv",
    "abstract": "Diffusion models generate samples through an iterative denoising process, guided by a neural network. While training the denoiser on real-world data is computationally demanding, the sampling procedure itself is more flexible. This adaptability serves as a key lever in practice, enabling improvements in both the quality of generated samples and the efficiency of the sampling process. In this work, we introduce an inverse reinforcement learning framework for learning sampling strategies without retraining the denoiser. We formulate the diffusion sampling procedure as a discrete-time finite-horizon Markov Decision Process, where actions correspond to optional modifications of the sampling dynamics. To optimize action scheduling, we avoid defining an explicit reward function. Instead, we directly match the target behavior expected from the sampler using policy gradient techniques. We provide experimental evidence that this approach can improve the quality of samples generated by pretrained diffusion models and automatically tune sampling hyperparameters."
  },
  {
    "date": "2026-02-09",
    "title": "Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement",
    "authors": "Hossein Kermani, Fatemeh Oudlajani, Pardis Yarahmadi, Hamideh Mahdi Soltani, Mohammad Makki, Zahra HosseiniKhoo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08688v1",
    "source": "arXiv",
    "abstract": "This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context."
  },
  {
    "date": "2026-02-09",
    "title": "CompilerKV: Risk-Adaptive KV Compression via Offline Experience Compilation",
    "authors": "Ning Yang, Chengzhi Wang, Yibo Liu, Baoliang Tian, Haijun Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08686v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) in long-context scenarios are severely constrained by the linear growth of Key-Value (KV) cache memory. Existing KV compression methods rely either on static thresholds and attention-only heuristics or on coarse memory budget allocation. Under tight memory budgets, these methods overlook two key factors: prompt-dependent variation in compression risk and functional heterogeneity across attention heads, which destabilize token selection and lead to tail failures. To address these challenges, we propose CompilerKV, a risk-adaptive and head-aware compression framework that compiles offline experience into reusable decision tables for prefill-only deployment. CompilerKV integrates two key synergistic components: (i) a Head Heterogeneity Table, learned via offline contextual bandits, which assigns head-specific reliability weights to govern functional differences across attention heads explicitly; and (ii) a Risk-Adaptive Threshold Gating mechanism that jointly models attention entropy and local perplexity, transforming prompt-level risk into deployable retention thresholds. Experiments on LongBench show CompilerKV dominates SOTA methods under a 512-token budget, recovering 97.7\\% of FullKV performance while achieving up to +5.2 points gain over the strongest competitor."
  },
  {
    "date": "2026-02-09",
    "title": "SA-CAISR: Stage-Adaptive and Conflict-Aware Incremental Sequential Recommendation",
    "authors": "Xiaomeng Song, Xinru Wang, Hanbing Wang, Hongyu Lu, Yu Chen, Zhaochun Ren, Zhumin Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08678v1",
    "source": "arXiv",
    "abstract": "Sequential recommendation (SR) aims to predict a user's next action by learning from their historical interaction sequences. In real-world applications, these models require periodic updates to adapt to new interactions and evolving user preferences. While incremental learning methods facilitate these updates, they face significant challenges. Replay-based approaches incur high memory and computational costs, and regularization-based methods often struggle to discard outdated or conflicting knowledge. To overcome these challenges, we propose SA-CAISR, a Stage-Adaptive and Conflict-Aware Incremental Sequential Recommendation framework. As a buffer-free framework, SA-CAISR operates using only the old model and new data, directly addressing the high costs of replay-based techniques. SA-CAISR introduces a novel Fisher-weighted knowledge-screening mechanism that dynamically identifies outdated knowledge by estimating parameter-level conflicts between the old model and new data, allowing our approach to selectively remove obsolete knowledge while preserving compatible historical patterns. This dynamic balance between stability and adaptability allows our method to achieve a new state-of-the-art performance in incremental SR. Specifically, SA-CAISR improves Recall@20 by 2.0%, MRR@20 by 1.2%, and NDCG@20 by 1.4% on average across datasets, while reducing memory usage by 97.5% and training time by 46.9% compared to the best baselines. This efficiency allows real-world systems to rapidly update user profiles with minimal computational overhead, ensuring more timely and accurate recommendations."
  },
  {
    "date": "2026-02-09",
    "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
    "authors": "Tiwei Bie, Maosong Cao, Xiang Cao, Bingsen Chen, Fuyuan Chen, Kun Chen, Lun Du, Daozhuo Feng, Haibo Feng, Mingliang Gong, Zhuocheng Gong, Yanmei Gu, Jian Guan, Kaiyuan Guan, Hongliang He, Zenan Huang, Juyong Jiang, Zhonghui Jiang, Zhenzhong Lan, Chengxi Li, Jianguo Li, Zehuan Li, Huabin Liu, Lin Liu, Guoshan Lu, Yuan Lu, Yuxin Ma, Xingyu Mou, Zhenxuan Pan, Kaida Qiu, Yuji Ren, Jianfeng Tan, Yiding Tian, Zian Wang, Lanning Wei, Tao Wu, Yipeng Xing, Wentao Ye, Liangyu Zha, Tianze Zhang, Xiaolu Zhang, Junbo Zhao, Da Zheng, Hao Zhong, Wanli Zhong, Jun Zhou, Junlin Zhou, Liwang Zhu, Muzhi Zhu, Yihong Zhuang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08676v1",
    "source": "arXiv",
    "abstract": "While LLaDA2.0 showcased the scaling potential of 100B-level block-diffusion models and their inherent parallelization, the delicate equilibrium between decoding speed and generation quality has remained an elusive frontier. Today, we unveil LLaDA2.1, a paradigm shift designed to transcend this trade-off. By seamlessly weaving Token-to-Token (T2T) editing into the conventional Mask-to-Token (M2T) scheme, we introduce a joint, configurable threshold-decoding scheme. This structural innovation gives rise to two distinct personas: the Speedy Mode (S Mode), which audaciously lowers the M2T threshold to bypass traditional constraints while relying on T2T to refine the output; and the Quality Mode (Q Mode), which leans into conservative thresholds to secure superior benchmark performances with manageable efficiency degrade. Furthering this evolution, underpinned by an expansive context window, we implement the first large-scale Reinforcement Learning (RL) framework specifically tailored for dLLMs, anchored by specialized techniques for stable gradient estimation. This alignment not only sharpens reasoning precision but also elevates instruction-following fidelity, bridging the chasm between diffusion dynamics and complex human intent. We culminate this work by releasing LLaDA2.1-Mini (16B) and LLaDA2.1-Flash (100B). Across 33 rigorous benchmarks, LLaDA2.1 delivers strong task performance and lightning-fast decoding speed. Despite its 100B volume, on coding tasks it attains an astounding 892 TPS on HumanEval+, 801 TPS on BigCodeBench, and 663 TPS on LiveCodeBench."
  },
  {
    "date": "2026-02-09",
    "title": "6G-Bench: An Open Benchmark for Semantic Communication and Network-Level Reasoning with Foundation Models in AI-Native 6G Networks",
    "authors": "Mohamed Amine Ferrag, Abderrahmane Lakas, Merouane Debbah",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08675v1",
    "source": "arXiv",
    "abstract": "This paper introduces 6G-Bench, an open benchmark for evaluating semantic communication and network-level reasoning in AI-native 6G networks. 6G-Bench defines a taxonomy of 30 decision-making tasks (T1--T30) extracted from ongoing 6G and AI-agent standardization activities in 3GPP, IETF, ETSI, ITU-T, and the O-RAN Alliance, and organizes them into five standardization-aligned capability categories. Starting from 113,475 scenarios, we generate a balanced pool of 10,000 very-hard multiple-choice questions using task-conditioned prompts that enforce multi-step quantitative reasoning under uncertainty and worst-case regret minimization over multi-turn horizons. After automated filtering and expert human validation, 3,722 questions are retained as a high-confidence evaluation set, while the full pool is released to support training and fine-tuning of 6G-specialized models. Using 6G-Bench, we evaluate 22 foundation models spanning dense and mixture-of-experts architectures, short- and long-context designs (up to 1M tokens), and both open-weight and proprietary systems. Across models, deterministic single-shot accuracy (pass@1) spans a wide range from 0.22 to 0.82, highlighting substantial variation in semantic reasoning capability. Leading models achieve intent and policy reasoning accuracy in the range 0.87--0.89, while selective robustness analysis on reasoning-intensive tasks shows pass@5 values ranging from 0.20 to 0.91. To support open science and reproducibility, we release the 6G-Bench dataset on GitHub: https://github.com/maferrag/6G-Bench"
  },
  {
    "date": "2026-02-09",
    "title": "Structural studies on $A_2$ReCl$_6$ ($A$=K, Rb, Cs): absence of Jahn-Teller distortion",
    "authors": "A. Bertin, L. Kiefer, V. Pomjakushin, O. Fabelo, P. Becker, L. Bohaty, M. Braden",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08665v1",
    "source": "arXiv",
    "abstract": "K$_2$ReCl$_6$ belongs to the antifluorite family and exhibits a sequence of structural transitions above the onset of magnetic order at $T_N$ = 12 K. Because of its 5d3 electronic configuration in an octahedral coordination, the ground state is a pure spin state without orbital degeneracy within the LS coupling scheme, but it can become Jahn-Teller active in the strong spin-orbit coupling limit described by the $jj$ coupling [S. Streltsov and D. I. Khomskii, Phys. Rev. X 10, 031043 (2020)]. While the structural transitions in K$_2$ReCl$_6$ are understood in terms of octahedral rotation and tilting, the possible impact of a Jahn-Teller distortion remains an open issue. We report on comprehensive crystalstructure studies by means of powder neutron and single-crystal x-ray diffraction on K$_2$ReCl$_6$ and on K$_2$SnCl$_6$. The latter material is used as a reference, because it exhibits the same sequence of structural transitions as K$_2$ReCl$_6$, but possesses a filled 4d shell ruling out a Jahn-Teller distortion. While the ReCl$_6$ octahedron in K$_2$ReCl$_6$ presents sizable distortions at intermediate temperatures, there is no such distortion persisting to low temperatures excluding a sizable Jahn-Teller effect. Studies on polycrystalline samples of Rb$_2$ReCl$_6$ and Cs$_2$ReCl$_6$, in which the structural transitions are suppressed due to the larger alkaline ionic radius, also do not find any indications for a Jahn-Teller distortion."
  },
  {
    "date": "2026-02-09",
    "title": "Equalized Generative Treatment: Matching f-divergences for Fairness in Generative Models",
    "authors": "Alexandre Verine, Rafael Pinot, Florian Le Bronnec",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08660v1",
    "source": "arXiv",
    "abstract": "Fairness is a crucial concern for generative models, which not only reflect but can also amplify societal and cultural biases. Existing fairness notions for generative models are largely adapted from classification and focus on balancing the probability of generating samples from each sensitive group. We show that such criteria are brittle, as they can be met even when different sensitive groups are modeled with widely varying quality. To address this limitation, we introduce a new fairness definition for generative models, termed as equalized generative treatment (EGT), which requires comparable generation quality across all sensitive groups, with quality measured via a reference f-divergence. We further analyze the trade-offs induced by EGT, demonstrating that enforcing fairness constraints necessarily couples the overall model quality to that of the most challenging group to approximate. This indicates that a simple yet efficient min-max fine-tuning method should be able to balance f-divergences across sensitive groups to satisfy EGT. We validate this theoretical insight through a set of experiments on both image and text generation tasks. We demonstrate that min-max methods consistently achieve fairer outcomes compared to other approaches from the literature, while maintaining competitive overall performance for both tasks."
  },
  {
    "date": "2026-02-09",
    "title": "From Robotics to Sepsis Treatment: Offline RL via Geometric Pessimism",
    "authors": "Sarthak Wanjari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08655v1",
    "source": "arXiv",
    "abstract": "Offline Reinforcement Learning (RL) promises the recovery of optimal policies from static datasets, yet it remains susceptible to the overestimation of out-of-distribution (OOD) actions, particularly in fractured and sparse data manifolds.Current solutions necessitates a trade off between computational efficiency and performance. Methods like CQL offers rigorous conservatism but require tremendous compute power while efficient expectile-based methods like IQL often fail to correct OOD errors on pathological datasets, collapsing to Behavioural Cloning. In this work, we propose Geometric Pessimism, a modular, compute-efficient framework that augments standard IQL with density-based penalty derived from k-nearest-neighbour distances in the state-action embedding space. By pre-computing the penalties applied to each state-action pair our method injects OOD conservatism via reward shaping with a O(1) training overhead. Evaluated on the D4Rl MuJoCo benchmark, our method, Geo-IQL outperforms standard IQL on sensitive and unstable medium-replay tasks by over 18 points, while reducing inter-seed variance by 4x. Furthermore, Geo-IQL does not degrade performance on stable manifolds. Crucially, we validate our algorithm on the MIMIC-III Sepsis critical care dataset. While standard IQL collapses to behaviour cloning, Geo-IQL demonstrates active policy improvement. Maintaining safety constraints, achieving 86.4% terminal agreement with clinicians compared to IQL's 75%. Our results suggest that geometric pessimism provides the necessary regularisation to safely overcome local optima in critical, real-world decision systems."
  },
  {
    "date": "2026-02-09",
    "title": "Deep Learning-Based Fixation Type Prediction for Quality Assurance in Digital Pathology",
    "authors": "Oskar Thaeter, Tanja Niedermair, Johannes Raffler, Ralf Huss, Peter J. Schüffler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08652v1",
    "source": "arXiv",
    "abstract": "Accurate annotation of fixation type is a critical step in slide preparation for pathology laboratories. However, this manual process is prone to errors, impacting downstream analyses and diagnostic accuracy. Existing methods for verifying formalin-fixed, paraffin-embedded (FFPE), and frozen section (FS) fixation types typically require full-resolution whole-slide images (WSIs), limiting scalability for high-throughput quality control. We propose a deep-learning model to predict fixation types using low-resolution, pre-scan thumbnail images. The model was trained on WSIs from the TUM Institute of Pathology (n=1,200, Leica GT450DX) and evaluated on a class-balanced subset of The Cancer Genome Atlas dataset (TCGA, n=8,800, Leica AT2), as well as on class-balanced datasets from Augsburg (n=695 [392 FFPE, 303 FS], Philips UFS) and Regensburg (n=202, 3DHISTECH P1000). Our model achieves an AUROC of 0.88 on TCGA, outperforming comparable pre-scan methods by 4.8%. It also achieves AUROCs of 0.72 on Regensburg and Augsburg slides, underscoring challenges related to scanner-induced domain shifts. Furthermore, the model processes each slide in 21 ms, $400\\times$ faster than existing high-magnification, full-resolution methods, enabling rapid, high-throughput processing. This approach provides an efficient solution for detecting labelling errors without relying on high-magnification scans, offering a valuable tool for quality control in high-throughput pathology workflows. Future work will improve and evaluate the model's generalisation to additional scanner types. Our findings suggest that this method can increase accuracy and efficiency in digital pathology workflows and may be extended to other low-resolution slide annotations."
  },
  {
    "date": "2026-02-09",
    "title": "Forget Superresolution, Sample Adaptively (when Path Tracing)",
    "authors": "Martin Bálint, Corentin Salaün, Hans-Peter Seidel, Karol Myszkowski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08642v1",
    "source": "arXiv",
    "abstract": "Real-time path tracing increasingly operates under extremely low sampling budgets, often below one sample per pixel, as rendering complexity, resolution, and frame-rate requirements continue to rise. While super-resolution is widely used in production, it uniformly sacrifices spatial detail and cannot exploit variations in noise, reconstruction difficulty, and perceptual importance across the image. Adaptive sampling offers a compelling alternative, but existing end-to-end approaches rely on approximations that break down in sparse regimes. We introduce an end-to-end adaptive sampling and denoising pipeline explicitly designed for the sub-1-spp regime. Our method uses a stochastic formulation of sample placement that enables gradient estimation despite discrete sampling decisions, allowing stable training of a neural sampler at low sampling budgets. To better align optimization with human perception, we propose a tonemapping-aware training pipeline that integrates differentiable filmic operators and a state-of-the-art perceptual loss, preventing oversampling of regions with low visual impact. In addition, we introduce a gather-based pyramidal denoising filter and a learnable generalization of albedo demodulation tailored to sparse sampling. Our results show consistent improvements over uniform sparse sampling, with notably better reconstruction of perceptually critical details such as specular highlights and shadow boundaries, and demonstrate that adaptive sampling remains effective even at minimal budgets."
  },
  {
    "date": "2026-02-09",
    "title": "A Primal-Dual-Based Active Fault-Tolerant Control Scheme for Cyber-Physical Systems: Application to DC Microgrids",
    "authors": "Wasif H. Syed, Juan E. Machado, Johannes Schiffer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08633v1",
    "source": "arXiv",
    "abstract": "We consider the problem of active fault-tolerant control in cyber-physical systems composed of strictly passive linear-time invariant dynamic subsystems. We cast the problem as a constrained optimization problem and propose an augmented primal-dual gradient dynamics-based fault-tolerant control framework that enforces network-level constraints and provides optimality guarantees for the post-fault steady-state operation. By suitably interconnecting the primal-dual algorithm with the cyber-physical dynamics, we provide sufficient conditions under which the resulting closed-loop system possesses a unique and exponentially stable equilibrium point that satisfies the Karush--Kuhn--Tucker (KKT) conditions of the constrained problem. The framework's effectiveness is illustrated through numerical experiments on a DC microgrid."
  },
  {
    "date": "2026-02-09",
    "title": "Debate is efficient with your time",
    "authors": "Jonah Brown-Cohen, Geoffrey Irving, Simon C. Marshall, Ilan Newman, Georgios Piliouras, Mario Szegedy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08630v1",
    "source": "arXiv",
    "abstract": "AI safety via debate uses two competing models to help a human judge verify complex computational tasks. Previous work has established what problems debate can solve in principle, but has not analysed the practical cost of human oversight: how many queries must the judge make to the debate transcript? We introduce Debate Query Complexity}(DQC), the minimum number of bits a verifier must inspect to correctly decide a debate. Surprisingly, we find that PSPACE/poly (the class of problems which debate can efficiently decide) is precisely the class of functions decidable with O(log n) queries. This characterisation shows that debate is remarkably query-efficient: even for highly complex problems, logarithmic oversight suffices. We also establish that functions depending on all their input bits require Omega(log n) queries, and that any function computable by a circuit of size s satisfies DQC(f) <= log(s) + 3. Interestingly, this last result implies that proving DQC lower bounds of log(n) + 6 for languages in P would yield new circuit lower bounds, connecting debate query complexity to central questions in circuit complexity."
  },
  {
    "date": "2026-02-09",
    "title": "Revisiting [CLS] and Patch Token Interaction in Vision Transformers",
    "authors": "Alexis Marouani, Oriane Siméoni, Hervé Jégou, Piotr Bojanowski, Huy V. Vo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08626v1",
    "source": "arXiv",
    "abstract": "Vision Transformers have emerged as powerful, scalable and versatile representation learners. To capture both global and local features, a learnable [CLS] class token is typically prepended to the input sequence of patch tokens. Despite their distinct nature, both token types are processed identically throughout the model. In this work, we investigate the friction between global and local feature learning under different pre-training strategies by analyzing the interactions between class and patch tokens. Our analysis reveals that standard normalization layers introduce an implicit differentiation between these token types. Building on this insight, we propose specialized processing paths that selectively disentangle the computational flow of class and patch tokens, particularly within normalization layers and early query-key-value projections. This targeted specialization leads to significantly improved patch representation quality for dense prediction tasks. Our experiments demonstrate segmentation performance gains of over 2 mIoU points on standard benchmarks, while maintaining strong classification accuracy. The proposed modifications introduce only an 8% increase in parameters, with no additional computational overhead. Through comprehensive ablations, we provide insights into which architectural components benefit most from specialization and how our approach generalizes across model scales and learning frameworks."
  },
  {
    "date": "2026-02-09",
    "title": "On soft contributions to the $B^-\\to γ^*$ form factors",
    "authors": "Aoife Bharucha, Danny van Dyk, Eduardo Velásquez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08623v1",
    "source": "arXiv",
    "abstract": "The photoleptonic decay $B^-\\to γ\\ell^-\\barν$ is the simplest low-energy process that probes the substructure of the $B$ meson, making it an excellent candidate to determine the parameters of $B$-meson light-cone distribution amplitudes from experimental data. More recently, the decay $B^-\\to γ^*(\\to \\ell'^-\\ell'^+)\\ell^-\\barν$ has received attention as an alternative probe of these parameters. Both decays are described through a common set of hadronic form factors, which if computed within the framework of QCD factorization give rise to the sensitivity to the $B$-meson light-cone distribution amplitudes. Nevertheless, in this case the form factors still receive so-called soft contributions that can only be estimated but not rigorously computed. In this work, we provide results for the QCD factorization expressions for the form factors, including terms at next-to-leading power in the $b$ quark mass and in the photon energy. We further use these results to estimate the soft contributions within a light-cone sum rule setup. Finally, using numerical results obtained from a benchmark model of the light-cone distribution amplitudes, we show that the soft contributions are under significantly better theoretical control at a mildly spacelike photon virtuality."
  },
  {
    "date": "2026-02-09",
    "title": "Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs",
    "authors": "Yukun Jiang, Hai Huang, Mingjie Li, Yage Zhang, Michael Backes, Yang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08621v1",
    "source": "arXiv",
    "abstract": "By introducing routers to selectively activate experts in Transformer layers, the mixture-of-experts (MoE) architecture significantly reduces computational costs in large language models (LLMs) while maintaining competitive performance, especially for models with massive parameters. However, prior work has largely focused on utility and efficiency, leaving the safety risks associated with this sparse architecture underexplored. In this work, we show that the safety of MoE LLMs is as sparse as their architecture by discovering unsafe routes: routing configurations that, once activated, convert safe outputs into harmful ones. Specifically, we first introduce the Router Safety importance score (RoSais) to quantify the safety criticality of each layer's router. Manipulation of only the high-RoSais router(s) can flip the default route into an unsafe one. For instance, on JailbreakBench, masking 5 routers in DeepSeek-V2-Lite increases attack success rate (ASR) by over 4$\\times$ to 0.79, highlighting an inherent risk that router manipulation may naturally occur in MoE LLMs. We further propose a Fine-grained token-layer-wise Stochastic Optimization framework to discover more concrete Unsafe Routes (F-SOUR), which explicitly considers the sequentiality and dynamics of input tokens. Across four representative MoE LLM families, F-SOUR achieves an average ASR of 0.90 and 0.98 on JailbreakBench and AdvBench, respectively. Finally, we outline defensive perspectives, including safety-aware route disabling and router training, as promising directions to safeguard MoE LLMs. We hope our work can inform future red-teaming and safeguarding of MoE LLMs. Our code is provided in https://github.com/TrustAIRLab/UnsafeMoE."
  },
  {
    "date": "2026-02-09",
    "title": "ERIS: Enhancing Privacy and Communication Efficiency in Serverless Federated Learning",
    "authors": "Dario Fenoglio, Pasquale Polverino, Jacopo Quizi, Martin Gjoreski, Marc Langheinrich",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08617v1",
    "source": "arXiv",
    "abstract": "Scaling federated learning (FL) to billion-parameter models introduces critical trade-offs between communication efficiency, model accuracy, and privacy guarantees. Existing solutions often tackle these challenges in isolation, sacrificing accuracy or relying on costly cryptographic tools. We propose ERIS, a serverless FL framework that balances privacy and accuracy while eliminating the server bottleneck and distributing the communication load. ERIS combines a model partitioning strategy, distributing aggregation across multiple client-side aggregators, with a distributed shifted gradient compression mechanism. We theoretically prove that ERIS (i) converges at the same rate as FedAvg under standard assumptions, and (ii) bounds mutual information leakage inversely with the number of aggregators, enabling strong privacy guarantees with no accuracy degradation. Experiments across image and text tasks, including large language models, confirm that ERIS achieves FedAvg-level accuracy while substantially reducing communication cost and improving robustness to membership inference and reconstruction attacks, without relying on heavy cryptography or noise injection."
  },
  {
    "date": "2026-02-09",
    "title": "Ziv-Zakai Bound for Near-Field Localization and Sensing",
    "authors": "Nicolò Decarli, Davide Dardari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08609v1",
    "source": "arXiv",
    "abstract": "The increasing carrier frequencies and growing physical dimensions of antenna arrays in modern wireless systems are driving renewed interest in localization and sensing under near-field conditions. In this paper, we analyze the Ziv-Zakai Bound (ZZB) for near-field localization and sensing operated with large antenna arrays, which offers a tighter characterization of estimation accuracy compared to traditional bounds such as the Cramér-Rao Bound (CRB), especially in low signal-to-noise ratio or threshold regions. Leveraging spherical wavefront and array geometry in the signal model, we evaluate the ZZB for distance and angle estimation, investigating the dependence of the accuracy on key signal and system parameters such as array geometry, wavelength, and target position. Our analysis highlights the transition behavior of the ZZB and underscores the fundamental limitations and opportunities for accurate near-field sensing."
  },
  {
    "date": "2026-02-09",
    "title": "OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval",
    "authors": "Teng Wang, Rong Shan, Jianghao Lin, Junjie Wu, Tianyi Xu, Jianping Zhang, Wenteng Chen, Changwang Zhang, Zhaoxiang Wang, Weinan Zhang, Jun Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08603v1",
    "source": "arXiv",
    "abstract": "Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agentic retrieval, which is limited by suboptimal, trial-and-error orchestration. To this end, we propose OSCAR, an optimization-steered agentic planning framework for composed image retrieval. We are the first to reformulate agentic CIR from a heuristic search process into a principled trajectory optimization problem. Instead of relying on heuristic trial-and-error exploration, OSCAR employs a novel offline-online paradigm. In the offline phase, we model CIR via atomic retrieval selection and composition as a two-stage mixed-integer programming problem, mathematically deriving optimal trajectories that maximize ground-truth coverage for training samples via rigorous boolean set operations. These trajectories are then stored in a golden library to serve as in-context demonstrations for online steering of VLM planner at online inference time. Extensive experiments on three public benchmarks and a private industrial benchmark show that OSCAR consistently outperforms SOTA baselines. Notably, it achieves superior performance using only 10% of training data, demonstrating strong generalization of planning logic rather than dataset-specific memorization."
  },
  {
    "date": "2026-02-09",
    "title": "Towards Reliable Social A/B Testing: Spillover-Contained Clustering with Robust Post-Experiment Analysis",
    "authors": "Xu Min, Zhaoxu Yang, Kaixuan Tan, Juan Yan, Xunbin Xiong, Zihao Zhu, Kaiyu Zhu, Fenglin Cui, Yang Yang, Sihua Yang, Jianhui Bu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08569v1",
    "source": "arXiv",
    "abstract": "A/B testing is the foundation of decision-making in online platforms, yet social products often suffer from network interference: user interactions cause treatment effects to spill over into the control group. Such spillovers bias causal estimates and undermine experimental conclusions. Existing approaches face key limitations: user-level randomization ignores network structure, while cluster-based methods often rely on general-purpose clustering that is not tailored for spillover containment and has difficulty balancing unbiasedness and statistical power at scale. We propose a spillover-contained experimentation framework with two stages. In the pre-experiment stage, we build social interaction graphs and introduce a Balanced Louvain algorithm that produces stable, size-balanced clusters while minimizing cross-cluster edges, enabling reliable cluster-based randomization. In the post-experiment stage, we develop a tailored CUPAC estimator that leverages pre-experiment behavioral covariates to reduce the variance induced by cluster-level assignment, thereby improving statistical power. Together, these components provide both structural spillover containment and robust statistical inference. We validate our approach through large-scale social sharing experiments on Kuaishou, a platform serving hundreds of millions of users. Results show that our method substantially reduces spillover and yields more accurate assessments of social strategies than traditional user-level designs, establishing a reliable and scalable framework for networked A/B testing."
  },
  {
    "date": "2026-02-09",
    "title": "Dynamical System Analysis of FLRW Model in f(R,L,T) Theory",
    "authors": "R. R. Panchal, Divya G. Sanjava, A. H. Hasmani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08562v1",
    "source": "arXiv",
    "abstract": "Modified gravity theories have been extensively studied recently as viable substitutes for general relativity to deal with cosmological issues like dark energy and late-time cosmic acceleration. In the present work, we investigate the dynamical behavior of the $f(R,L,T)$ gravity model with a scalar field utilizing exponential potential, where $R$ represents the Ricci scalar, $L$ is the Lagrangian density and $T$ is the trace of the energy-momentum tensor. We concentrate on a specific type of modified gravity characterized by $f(R,L,T) =R+αL+βT$, where $α$ and $β$ are positive constants. We study the dynamical behavior and late-time evolution of a cosmological model using a thorough phase-space analysis. We assess important cosmological parameters at the critical places, such as the density parameters corresponding to various cosmic components, the deceleration parameter, and the effective equation of state parameter. The nature of the cosmic phases such as matter-dominated, radiation-dominated, and accelerated expansion eras, described using these quantities."
  },
  {
    "date": "2026-02-09",
    "title": "Constrained Sampling to Guide Universal Manipulation RL",
    "authors": "Marc Toussaint, Cornelius V. Braun, Eckart Cobo-Briesewitz, Sayantan Auddy, Armand Jordana, Justin Carpentier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08557v1",
    "source": "arXiv",
    "abstract": "We consider how model-based solvers can be leveraged to guide training of a universal policy to control from any feasible start state to any feasible goal in a contact-rich manipulation setting. While Reinforcement Learning (RL) has demonstrated its strength in such settings, it may struggle to sufficiently explore and discover complex manipulation strategies, especially in sparse-reward settings. Our approach is based on the idea of a lower-dimensional manifold of feasible, likely-visited states during such manipulation and to guide RL with a sampler from this manifold. We propose Sample-Guided RL, which uses model-based constraint solvers to efficiently sample feasible configurations (satisfying differentiable collision, contact, and force constraints) and leverage them to guide RL for universal (goal-conditioned) manipulation policies. We study using this data directly to bias state visitation, as well as using black-box optimization of open-loop trajectories between random configurations to impose a state bias and optionally add a behavior cloning loss. In a minimalistic double sphere manipulation setting, Sample-Guided RL discovers complex manipulation strategies and achieves high success rates in reaching any statically stable state. In a more challenging panda arm setting, our approach achieves a significant success rate over a near-zero baseline, and demonstrates a breadth of complex whole-body-contact manipulation strategies."
  },
  {
    "date": "2026-02-09",
    "title": "Hidden in-plane long-range order in an amorphized crystal",
    "authors": "Yin Chen, Anthony E. Phillips, Cheng Fu, Volodymyr Bon, Lei Liu, Xiaoxu Sun, Jiahui Wang, Na Lin, Ruize Xie, Guanqun Cai, Yutong Wang, Jing Ma, Yuhong Liu, Yu Han, Stefan Kaskel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08551v1",
    "source": "arXiv",
    "abstract": "Solid materials are commonly classified as crystalline or amorphous based on the presence or absence of long-range order.Metal-organic frameworks (MOFs), like other solids,also display markedly different properties and functions in these two phases. Here, we identify a previously unrecognized structural state that retains long-range in-plane translational order while losing order along the stacking direction. Hypothesized since 1941 but not experimentally verified, this intermediate phase emerges in a crystalline MOFs via controlled thermal desolvation, which selectively disrupts the intrinsically weak interlayer interactions while preserving macroscopic structural coherence. Although the resulting material appears amorphous under conventional characterization, systematic synchrotron PXRD, total X-ray scattering, and low-dose high resolution TEM reveal clear in-plane periodicity. This material spontaneously delaminates in water into uniform, high-quality two-dimensional crystalline nanosheets, forming stable colloidal suspensions and exhibiting superlubricity comparable to graphene - but at less than 0.1% of the production cost. Our discovery finds a missing link within the long-standing crystalline-amorphous dichotomy, while providing an inherently scalable route to high-quality 2D crystals, and offering a conceptual and practical advance in phase engineering."
  },
  {
    "date": "2026-02-09",
    "title": "An Automata-Based Approach to Games with $ω$-Automatic Preferences",
    "authors": "Véronique Bruyère, Emmanuel Filiot, Christophe Grandmont, Jean-François Raskin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08549v1",
    "source": "arXiv",
    "abstract": "This paper studies multiplayer turn-based games on graphs in which player preferences are modeled as $ω$-automatic relations given by deterministic parity automata. This contrasts with most existing work, which focuses on specific reward functions. We conduct a computational analysis of these games, starting with the threshold problem in the antagonistic zero-sum case. As in classical games, we introduce the concept of value, defined here as the set of plays a player can guarantee to improve upon, relative to their preference relation. We show that this set is recognized by an alternating parity automaton APW of polynomial size. We also establish the computational complexity of several problems related to the concepts of value and optimal strategy, taking advantage of the $ω$-automatic characterization of value. Next, we shift to multiplayer games and Nash equilibria, and revisit the threshold problem in this context. Based on an APW construction again, we close complexity gaps left open in the literature, and additionally show that cooperative rational synthesis is $\\mathsf{PSPACE}$-complete, while it becomes undecidable in the non-cooperative case."
  },
  {
    "date": "2026-02-09",
    "title": "DA-RAG: Dynamic Attributed Community Search for Retrieval-Augmented Generation",
    "authors": "Xingyuan Zeng, Zuohan Wu, Yue Wang, Chen Zhang, Quanming Yao, Libin Zheng, Jian Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08545v1",
    "source": "arXiv",
    "abstract": "Owing to their unprecedented comprehension capabilities, large language models (LLMs) have become indispensable components of modern web search engines. From a technical perspective, this integration represents retrieval-augmented generation (RAG), which enhances LLMs by grounding them in external knowledge bases. A prevalent technical approach in this context is graph-based RAG (G-RAG). However, current G-RAG methodologies frequently underutilize graph topology, predominantly focusing on low-order structures or pre-computed static communities. This limitation affects their effectiveness in addressing dynamic and complex queries. Thus, we propose DA-RAG, which leverages attributed community search (ACS) to extract relevant subgraphs based on the queried question dynamically. DA-RAG captures high-order graph structures, allowing for the retrieval of self-complementary knowledge. Furthermore, DA-RAG is equipped with a chunk-layer oriented graph index, which facilitates efficient multi-granularity retrieval while significantly reducing both computational and economic costs. We evaluate DA-RAG on multiple datasets, demonstrating that it outperforms existing RAG methods by up to 40% in head-to-head comparisons across four metrics while reducing index construction time and token overhead by up to 37% and 41%, respectively."
  },
  {
    "date": "2026-02-09",
    "title": "Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO",
    "authors": "Kun Peng, Conghui Tan, Yu Liu, Guohua Tang, Zhongqian Sun, Wei Yang, Zining Zhu, Lei Jiang, Yanbing Liu, Hao Peng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08533v1",
    "source": "arXiv",
    "abstract": "Open-ended dialogue agents aim to deliver engaging, personalized interactions by adapting to users' traits, but existing methods face critical limitations: over-reliance on pre-collected user data, and short-horizon biases in reinforcement learning (RL) that neglect long-term dialogue value. To address these, we propose a novel long-horizon RL framework integrating online personalization with Adaptive Tree-based Group Relative Policy Optimization (AT-GRPO). Adopting a two-agent game paradigm, a user agent constructs dynamic environments via style mimicry (learning user-specific conversational traits) and active termination (predicting turn-level termination probabilities as immediate rewards), forming an iterative cycle that drives the dialogue agent to deepen interest exploration. AT-GRPO reinterprets dialogue trajectories as trees and introduces adaptive observation ranges. Unlike full tree expansion that incurs exponential overhead, it limits each node to aggregate rewards from a stage-aware range: larger ranges support early-stage topic exploration, while smaller ranges facilitate late-stage dialogue maintenance. This design reduces rollout budgets from exponential to polynomial in the dialogue length, while preserving long-term reward capture. Extensive experiments show our framework's superior performance, sample efficiency, and robustness."
  },
  {
    "date": "2026-02-09",
    "title": "Intelligent Control of Collisional Architectures for Deterministic Multipartite State Engineering",
    "authors": "Duc-Kha Vu, Minh Tam Nguyen, Özgür E. Müstecaplıoğlu, Fatih Ozaydin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08526v1",
    "source": "arXiv",
    "abstract": "Designing scalable, noise-tolerant control protocols for multipartite entanglement is a central challenge for quantum technologies, and it naturally calls for \\emph{algorithmic} synthesis of interaction parameters rather than handcrafted gate sequences. Here we introduce an intelligent, constraint-aware control framework for deterministic generation of symmetric Dicke states $|D_n^{(m)}\\rangle$ in repeated-interaction (collision-model) architectures. The protocol employs excitation-preserving partial-SWAP collisions between two disjoint qubit registers, mediated by $m$ ancillary ``shuttle'' qubits, and poses Dicke-state preparation as a \\emph{closed-loop design} problem: given the target $(n,m)$, automatically infer collision strengths that maximize fidelity under practical constraints. Concretely, we formulate a two-parameter, bound-constrained optimization over intra-register and shuttle--register collision angles and solve it using a multi-start strategy with L-BFGS-B, yielding a reproducible controller prescription (optimized $γ_{\\mathrm{in}}$, $γ_{\\mathrm{sh}}$, and minimal-round convergence points) for each target. This removes the need for projective measurements and extends collisional entanglement generation beyond the single-excitation (W-state) sector to arbitrary $m$. Crucially, we optimize \\emph{within} imperfect collisional dynamics where errors act throughout the sequence, including stochastic interaction dropouts (missing collisions) and standard decoherence channels. Strikingly, across wide error ranges the optimized controller preserves high preparation fidelity; imperfections manifest primarily as a modest increase in the required number of collision rounds. This behavior reflects a tunable competition in which noise suppresses correlations while properly chosen collisions continuously replenish them, allowing the control algorithm to trade time for fidelity."
  },
  {
    "date": "2026-02-09",
    "title": "GeoFocus: Blending Efficient Global-to-Local Perception for Multimodal Geometry Problem-Solving",
    "authors": "Linger Deng, Yuliang Liu, Wenwen Yu, Zujia Zhang, Jianzhong Ju, Zhenbo Luo, Xiang Bai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08524v1",
    "source": "arXiv",
    "abstract": "Geometry problem-solving remains a significant challenge for Large Multimodal Models (LMMs), requiring not only global shape recognition but also attention to intricate local relationships related to geometric theory. To address this, we propose GeoFocus, a novel framework comprising two core modules. 1) Critical Local Perceptor, which automatically identifies and emphasizes critical local structure (e.g., angles, parallel lines, comparative distances) through thirteen theory-based perception templates, boosting critical local feature coverage by 61% compared to previous methods. 2) VertexLang, a compact topology formal language, encodes global figures through vertex coordinates and connectivity relations. By replacing bulky code-based encodings, VertexLang reduces global perception training time by 20% while improving topology recognition accuracy. When evaluated in Geo3K, GeoQA, and FormalGeo7K, GeoFocus achieves a 4.7% accuracy improvement over leading specialized models and demonstrates superior robustness in MATHVERSE under diverse visual conditions. Project Page -- https://github.com/dle666/GeoFocus"
  },
  {
    "date": "2026-02-09",
    "title": "Polytopes and $C^0$-Riemannian metrics with positive $h_{\\rm top}$",
    "authors": "Marcelo R. R. Alves, Matthias Meiwes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08521v1",
    "source": "arXiv",
    "abstract": "We study Reeb dynamics on starshaped hypersurfaces in $\\mathbb{R}^4$ arising as smoothings of convex polytopes. Using the $C^0$--stability of positive topological entropy for Reeb flows in dimension three from our joint work with Dahinden and Pirnapasov, we show that there exist starshaped polytopes $P$ such that for any starshaped smoothing of $\\partial P$ the associated Reeb flows have positive topological entropy. This answers a question of Ostrover and Ginzburg. Similarly, we show that given a closed surface $M$ and a number $C>0$, there exist continuous and non-differentiable Riemannian metrics $g$ on $S$ with $h_{\\rm top}>C$ in the sense that for any smoothing of $g$ the associated geodesic flows have $h_{\\rm top}>C$."
  },
  {
    "date": "2026-02-09",
    "title": "TreeTensor: Boost AI System on Nested Data with Constrained Tree-Like Tensor",
    "authors": "Shaoang Zhang, Yazhe Niu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08517v1",
    "source": "arXiv",
    "abstract": "Tensor is the most basic and essential data structure of nowadays artificial intelligence (AI) system. The natural properties of Tensor, especially the memory-continuity and slice-independence, make it feasible for training system to leverage parallel computing unit like GPU to process data simultaneously in batch, spatial or temporal dimensions. However, if we look beyond perception tasks, the data in a complicated cognitive AI system usually has hierarchical structures (i.e. nested data) with various modalities. They are inconvenient and inefficient to program directly with conventional Tensor with fixed shape. To address this issue, we summarize two main computational patterns of nested data, and then propose a general nested data container: TreeTensor. Through various constraints and magic utilities of TreeTensor, one can apply arbitrary functions and operations to nested data with almost zero cost, including some famous machine learning libraries, such as Scikit-Learn, Numpy and PyTorch. Our approach utilizes a constrained tree-structure perspective to systematically model data relationships, and it can also easily be combined with other methods to extend more usages, such as asynchronous execution and variable-length data computation. Detailed examples and benchmarks show TreeTensor not only provides powerful usability in various problems, especially one of the most complicated AI systems at present: AlphaStar for StarCraftII, but also exhibits excellent runtime efficiency without any overhead. Our project is available at https://github.com/opendilab/DI-treetensor."
  },
  {
    "date": "2026-02-09",
    "title": "A note on cocycles in $\\mathbb{T}\\times SO(3)$",
    "authors": "Nikolaos Karaliolios",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08514v1",
    "source": "arXiv",
    "abstract": "This short note studies $C^{\\infty}$-smooth cocycles in $\\mathbb{T}\\times SO(3)$ that have $0$ degree and are non-homotopic to constants. The study picks up from where the author's PhD thesis left the subject, and shows that, under a relevant and full measure arithmetic condition, such cocycles can be conjugated to a simple model. Moreover, under the same arithmetic condition, the cocycle can be conjugated arbitrarily close to constant cocycles by a $2$-periodic conjugation."
  },
  {
    "date": "2026-02-09",
    "title": "Estimation of Fish Catch Using Sentinel-2, 3 and XGBoost-Kernel-Based Kernel Ridge Regression",
    "authors": "Kanu Mohammed, Vaishnavi Joshi, Pranjali Diliprao Patil, Sandipan Mondal, Ming-An Lee, Subhadip Dey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08511v1",
    "source": "arXiv",
    "abstract": "Oceanographic factors, such as sea surface temperature and upper-ocean dynamics, have a significant impact on fish distribution. Maintaining fisheries that contribute to global food security requires quantifying these connections. This study uses multispectral images from Sentinel-2 MSI and Sentinel-3 OLCI to estimate fish catch using an Extreme Gradient Boosting (XGBoost)-kernelized Kernel Ridge Regression (KRR) technique. According to model evaluation, the XGBoost-KRR framework achieves the strongest correlation and the lowest prediction error across both sensors, suggesting improved capacity to capture nonlinear ocean-fish connections. While Sentinel-2 MSI resolves finer-scale spatial variability, emphasizing localized ecological interactions, Sentinel-3 OLCI displays smoother spectral responses associated with poorer spatial resolution. By supporting sustainable ecosystem management and strengthening satellite-based fisheries assessment, the proposed approach advances SDGs 2 (Zero Hunger) and 14 (Life Below Water)."
  },
  {
    "date": "2026-02-09",
    "title": "The M-Tensor Format: Optimality in High Dimensional Regression for Nonlinear Models with Scarce Data",
    "authors": "Rémi Cloarec, Sebastian Rodriguez, Xavier Kestelyn, Francisco Chinesta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08509v1",
    "source": "arXiv",
    "abstract": "We present a nonlinear regression framework based on tensor algebra tailored to high dimensional contexts where data is scarce. We exploit algebraic properties of a partial tensor product, namely the m-tensor product, to leverage structured equations with separated variables. The proposed method combines kernel properties along with tensor algebra to prevent the curse of dimensionality and tackle approximations up to hundreds of parameters while avoiding the fixed point strategy. This formalism allows us to provide different regularization techniques fit for low amount of data with a high number of parameters while preserving well-known matrix-based properties. We demonstrate complexity scaling on a general benchmark and dynamical systems to show robustness for engineering problems and ease of implementation."
  },
  {
    "date": "2026-02-09",
    "title": "Are Vision Foundation Models Foundational for Electron Microscopy Image Segmentation?",
    "authors": "Caterina Fuster-Barceló, Virginie Uhlmann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08505v1",
    "source": "arXiv",
    "abstract": "Although vision foundation models (VFMs) are increasingly reused for biomedical image analysis, it remains unclear whether the latent representations they provide are general enough to support effective transfer and reuse across heterogeneous microscopy image datasets. Here, we study this question for the problem of mitochondria segmentation in electron microscopy (EM) images, using two popular public EM datasets (Lucchi++ and VNC) and three recent representative VFMs (DINOv2, DINOv3, and OpenCLIP). We evaluate two practical model adaptation regimes: a frozen-backbone setting in which only a lightweight segmentation head is trained on top of the VFM, and parameter-efficient fine-tuning (PEFT) via Low-Rank Adaptation (LoRA) in which the VFM is fine-tuned in a targeted manner to a specific dataset. Across all backbones, we observe that training on a single EM dataset yields good segmentation performance (quantified as foreground Intersection-over-Union), and that LoRA consistently improves in-domain performance. In contrast, training on multiple EM datasets leads to severe performance degradation for all models considered, with only marginal gains from PEFT. Exploration of the latent representation space through various techniques (PCA, Fréchet Dinov2 distance, and linear probes) reveals a pronounced and persistent domain mismatch between the two considered EM datasets in spite of their visual similarity, which is consistent with the observed failure of paired training. These results suggest that, while VFMs can deliver competitive results for EM segmentation within a single domain under lightweight adaptation, current PEFT strategies are insufficient to obtain a single robust model across heterogeneous EM datasets without additional domain-alignment mechanisms."
  },
  {
    "date": "2026-02-09",
    "title": "Multipoint Code-Weight Sphere Decoding: Parallel Near-ML Decoding for Short-Blocklength Codes",
    "authors": "Yubeen Jo, Geon Choi, Yongjune Kim, Namyoon Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08501v1",
    "source": "arXiv",
    "abstract": "Ultra-reliable low-latency communications (URLLC) operate with short packets, where finite-blocklength effects make near-maximum-likelihood (near-ML) decoding desirable but often too costly. This paper proposes a two-stage near-ML decoding framework that applies to any linear block code. In the first stage, we run a low-complexity decoder to produce a candidate codeword and a cyclic redundancy check. When this stage succeeds, we terminate immediately. When it fails, we invoke a second-stage decoder, termed multipoint code-weight sphere decoding (MP-WSD). The central idea behind {MP-WSD} is to concentrate the ML search where it matters. We pre-compute a set of low-weight codewords and use them to generate structured local perturbations of the current estimate. Starting from the first-stage output, MP-WSD iteratively explores a small Euclidean sphere of candidate codewords formed by adding selected low-weight codewords, tightening the search region as better candidates are found. This design keeps the average complexity low: at high signal-to-noise ratio, the first stage succeeds with high probability and the second stage is rarely activated; when it is activated, the search remains localized. Simulation results show that the proposed decoder attains near-ML performance for short-blocklength, low-rate codes while maintaining low decoding latency."
  },
  {
    "date": "2026-02-09",
    "title": "Is Meta-Path Attention an Explanation? Evidence of Alignment and Decoupling in Heterogeneous GNNs",
    "authors": "Maiqi Jiang, Noman Ali, Yiran Ding, Yanfu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08500v1",
    "source": "arXiv",
    "abstract": "Meta-path-based heterogeneous graph neural networks aggregate over meta-path-induced views, and their semantic-level attention over meta-path channels is widely used as a narrative for ``which semantics matter.'' We study this assumption empirically by asking: when does meta-path attention reflect meta-path importance, and when can it decouple? A key challenge is that most post-hoc GNN explainers are designed for homogeneous graphs, and naive adaptations to heterogeneous neighborhoods can mix semantics and confound perturbations. To enable a controlled empirical analysis, we introduce MetaXplain, a meta-path-aware post-hoc explanation protocol that applies existing explainers in the native meta-path view domain via (i) view-factorized explanations, (ii) schema-valid channel-wise perturbations, and (iii) fusion-aware attribution, without modifying the underlying predictor. We benchmark representative gradient-, perturbation-, and Shapley-style explainers on ACM, DBLP, and IMDB with HAN and HAN-GCN, comparing against xPath and type-matched random baselines under standard faithfulness metrics. To quantify attention reliability, we propose Meta-Path Attention--Explanation Alignment (MP-AEA), which measures rank correlation between learned attention weights and explanation-derived meta-path contribution scores across random runs. Our results show that meta-path-aware explanations typically outperform random controls, while MP-AEA reveals both high-alignment and statistically significant decoupling regimes depending on the dataset and backbone; moreover, retraining on explanation-induced subgraphs often preserves, and in some noisy regimes improves, predictive performance, suggesting an explanation-as-denoising effect."
  },
  {
    "date": "2026-02-09",
    "title": "Contextual Rollout Bandits for Reinforcement Learning with Verifiable Rewards",
    "authors": "Xiaodong Lu, Xiaohan Wang, Jiajun Chai, Guojun Yin, Wei Lin, Zhijun Chen, Yu Luo, Fuzhen Zhuang, Yikun Ban, Deqing Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08499v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) is an effective paradigm for improving the reasoning capabilities of large language models. However, existing RLVR methods utilize rollouts in an indiscriminate and short-horizon manner: responses of heterogeneous quality within each prompt are treated uniformly, and historical rollouts are discarded after a single use. This leads to noisy supervision, poor sample efficiency, and suboptimal policy updates. We address these issues by formulating rollout scheduling in RLVR as a contextual bandit problem and proposing a unified neural scheduling framework that adaptively selects high-value rollouts throughout training. Each rollout is treated as an arm whose reward is defined by the induced performance gain between consecutive optimization steps. The resulting scheduler supports both noise-aware intra-group selection and adaptive global reuse of historical rollouts within a single principled framework. We provide theoretical justification by deriving sublinear regret bounds and showing that enlarging the rollout buffer improves the achievable performance upper bound. Experiments on six mathematical reasoning benchmarks demonstrate consistent gains in performance and training efficiency across multiple RLVR optimization methods."
  },
  {
    "date": "2026-02-09",
    "title": "Radar Operating Metrics and Network Throughput for Integrated Sensing and Communications in Millimeter-wave Urban Environments",
    "authors": "Akanksha Sneh, Shobha Sundar Ram",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08495v1",
    "source": "arXiv",
    "abstract": "Millimeter wave integrated sensing and communication (ISAC) systems are being researched for next-generation intelligent transportation systems. Here, radar and communication functionalities share a common spectrum and hardware resources in a time-multiplexed manner. The objective of the radar is to first scan the angular search space and detect and localize mobile users/targets in the presence of discrete clutter scatterers. Subsequently, this information is used to direct highly directional beams toward these mobile users for communication service. The choice of radar parameters such as the radar duty cycle and the corresponding beamwidth are critical for realizing high communication throughput. In this work, we use the stochastic geometry-based mathematical framework to analyze the radar operating metrics as a function of diverse radar, target, and clutter parameters and subsequently use these results to study the network throughput of the ISAC system. The results are validated through Monte Carlo simulations."
  },
  {
    "date": "2026-02-09",
    "title": "Time-Delayed Transformers for Data-Driven Modeling of Low-Dimensional Dynamics",
    "authors": "Albert Alcalde, Markus Widhalm, Emre Yılmaz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08478v1",
    "source": "arXiv",
    "abstract": "We propose the time-delayed transformer (TD-TF), a simplified transformer architecture for data-driven modeling of unsteady spatio-temporal dynamics. TD-TF bridges linear operator-based methods and deep sequence models by showing that a single-layer, single-head transformer can be interpreted as a nonlinear generalization of time-delayed dynamic mode decomposition (TD-DMD). The architecture is deliberately minimal, consisting of one self-attention layer with a single query per prediction and one feedforward layer, resulting in linear computational complexity in sequence length and a small parameter count. Numerical experiments demonstrate that TD-TF matches the performance of strong linear baselines on near-linear systems, while significantly outperforming them in nonlinear and chaotic regimes, where it accurately captures long-term dynamics. Validation studies on synthetic signals, unsteady aerodynamics, the Lorenz '63 system, and a reaction-diffusion model show that TD-TF preserves the interpretability and efficiency of linear models while providing substantially enhanced expressive power for complex dynamics."
  },
  {
    "date": "2026-02-09",
    "title": "Renormalization destroys a finite time bifurcation in the $Φ^4_2$ equation",
    "authors": "Alexandra Blessing, Nicolas Perkowski, Chara Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08460v1",
    "source": "arXiv",
    "abstract": "We study the singular $Φ^4_2$ equation at a pitchfork bifurcation of the underlying deterministic dynamics. To this aim, we linearize the SPDE along its stationary solution and show that the support of its finite-time Lyapunov exponents (FTLEs) is the real line, regardless of the bifurcation parameter and in sharp contrast to the non-singular $Φ^4_1$ equation. The proof relies on a support theorem for the stationary solution and its renormalized square."
  },
  {
    "date": "2026-02-09",
    "title": "Identifying Host Galaxies of Binary Black Hole Mergers with Next-Generation Gravitational Wave Detector Networks",
    "authors": "Sumedha Biswas, Andrew Levan, Peter G. Jonker, Kendall Ackley, Gregory Ashton, Nikhil Sarin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08459v1",
    "source": "arXiv",
    "abstract": "Identifying the host galaxy of a binary black hole (BBH) merger detected via gravitational waves (GWs) remains a challenge due to the absence of electromagnetic counterparts and the large localization volumes produced by current-generation detectors. A confident host association would provide stellar population properties to constrain BBH formation channels and enable measurements of cosmological parameters such as the Hubble constant, H0. We simulate BBH mergers in nearby (z<0.25) host galaxies to evaluate the feasibility of host identification with future GW detector networks, including configurations with the planned LIGO-India detector and third-generation detectors such as the Einstein Telescope (ET) and Cosmic Explorer (CE). We construct two injection grids to explore variations in BBH mass, distance, and directional sensitivity, and infer localization volumes using the Fisher Information Matrix (FIM)-based parameter estimation implemented through BILBY. To assess the prospects for unique host identification, we introduce a set of diagnostics: theoretical comoving volume thresholds for galaxies of a given stellar mass, derived from galaxy stellar mass functions, a metallicity-based volume threshold motivated by progenitor environment models, stellar mass fractions to quantify candidate host prominence, and the probability of chance alignment (p_c). These metrics provide ways to evaluate host associations and constrain BBH formation channels. We find that future networks that include ET and CE localize BBH mergers to volumes smaller than those theoretical thresholds, implying potentially unique host identification, out to ~1000 Mpc at a rate of ~100 yr^{-1}. While associations for individual events may remain uncertain, our framework is well-suited to population-level analyses, enabling constraints on BBH formation scenarios in the era of next-generation GW detector networks."
  },
  {
    "date": "2026-02-09",
    "title": "Charge asymmetry in $e^{+}e^{-}\\to B^{(*)}\\bar{B}^{(*)}$ processes in the vicinity of $Υ(4S)$",
    "authors": "S. G. Salnikov, A. I. Milstein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08458v1",
    "source": "arXiv",
    "abstract": "The effects of isotopic invariance violation in the processes $e^{+}e^{-}\\to B\\bar{B}$, $e^{+}e^{-}\\to B^{*}\\bar{B}$, and $e^{+}e^{-}\\to B^{*}\\bar{B}^{*}$ are considered in the energy range between the thresholds of $B^{+}B^{-}$ and $B_{s}^{0}\\bar{B}_{s}^{0}$ production. The analysis is based on taking into account the final-state interaction in a six-channel problem. Our approach allowed us to obtain good agreement with recent Belle-II results for the ratio of the $B^{0}\\bar{B}^{0}$ and $B^{+}B^{-}$ production cross sections in $e^{+}e^{-}$ annihilation in the vicinity of $Υ(4S)$. It is shown that at higher energies the ratios of the cross sections for pairs of neutral and charged $B^{(*)}$ mesons can differ significantly from unity. A detailed measurement of this effect will provide evidence that the nontrivial energy dependence of the $B^{(*)}\\bar{B}^{(*)}$ production cross sections is a consequence of interference of the particle production amplitudes in the multichannel problem."
  },
  {
    "date": "2026-02-09",
    "title": "First Extraction of the Matter Radius of $^{132}$Sn via Proton Elastic Scattering at 200 MeV/Nucleon",
    "authors": "Y. Hijikata, J. Zenihiro, S. Terashima, Y. Matsuda, H. Sakaguchi, P. Arthuis, T. Miyagi, S. Ota, H. Baba, S. Chebotaryov, M. Dozono, T. Furuno, T. Harada, C. Iwamoto, T. Kawabata, M. Kobayashi, A. J. Krasznahorkay, S. Leblond, T. Lokotko, Y. Maeda, S. Masuoka, M. Matsushita, S. Michimasa, E. Milman, T. Murakami, H. Nasu, J. Okamoto, S. Sakaguchi, M. Takaki, K. Taniue, H. Tokieda, M. Tsumura, O. Wieland, Y. Yamaguchi, Z. H. Yang, R. Yokoyama, T. Uesaka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08455v1",
    "source": "arXiv",
    "abstract": "The angular distribution of the differential cross sections for proton elastic scattering from $^{132}$Sn at 196-210 MeV/nucleon was successfully measured over a momentum transfer range of 0.80 to 2.1 fm$^{-1}$. Using a relativistic impulse approximation, the root-mean-square matter radius of $^{132}$Sn was extracted to be $4.758^{+0.023}_{-0.024}$ fm, which was compared with the state-of-the-art ab initio calculations. Combined with the charge radius measured at ISOLDE, there are no theoretical calculations consistent with both matter and charge radii within the experimental errors."
  },
  {
    "date": "2026-02-09",
    "title": "UAV-Supported Maritime Search System: Experience from Valun Bay Field Trials",
    "authors": "Stefan Ivić, Luka Lanča, Karlo Jakac, Ante Sikirica, Stella Dumenčić, Matej Mališa, Zvonimir Mrle, Bojan Crnković",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08450v1",
    "source": "arXiv",
    "abstract": "This paper presents the integration of flow field reconstruction, dynamic probabilistic modeling, search control, and machine vision detection in a system for autonomous maritime search operations. Field experiments conducted in Valun Bay (Cres Island, Croatia) involved real-time drifter data acquisition, surrogate flow model fitting based on computational fluid dynamics and numerical optimization, advanced multi-UAV search control and vision sensing, as well as deep learning-based object detection. The results demonstrate that a tightly coupled approach enables reliable detection of floating targets under realistic uncertainties and complex environmental conditions, providing concrete insights for future autonomous maritime search and rescue applications."
  },
  {
    "date": "2026-02-09",
    "title": "RIFLE: Robust Distillation-based FL for Deep Model Deployment on Resource-Constrained IoT Networks",
    "authors": "Pouria Arefijamal, Mahdi Ahmadlou, Bardia Safaei, Jörg Henkel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08446v1",
    "source": "arXiv",
    "abstract": "Federated learning (FL) is a decentralized learning paradigm widely adopted in resource-constrained Internet of Things (IoT) environments. These devices, typically relying on TinyML models, collaboratively train global models by sharing gradients with a central server while preserving data privacy. However, as data heterogeneity and task complexity increase, TinyML models often become insufficient to capture intricate patterns, especially under extreme non-IID (non-independent and identically distributed) conditions. Moreover, ensuring robustness against malicious clients and poisoned updates remains a major challenge. Accordingly, this paper introduces RIFLE - a Robust, distillation-based Federated Learning framework that replaces gradient sharing with logit-based knowledge transfer. By leveraging a knowledge distillation aggregation scheme, RIFLE enables the training of deep models such as VGG-19 and Resnet18 within constrained IoT systems. Furthermore, a Kullback-Leibler (KL) divergence-based validation mechanism quantifies the reliability of client updates without exposing raw data, achieving high trust and privacy preservation simultaneously. Experiments on three benchmark datasets (MNIST, CIFAR-10, and CIFAR-100) under heterogeneous non-IID conditions demonstrate that RIFLE reduces false-positive detections by up to 87.5%, enhances poisoning attack mitigation by 62.5%, and achieves up to 28.3% higher accuracy compared to conventional federated learning baselines within only 10 rounds. Notably, RIFLE reduces VGG19 training time from over 600 days to just 1.39 hours on typical IoT devices (0.3 GFLOPS), making deep learning practical in resource-constrained networks."
  },
  {
    "date": "2026-02-09",
    "title": "Plethysm is in #BQP",
    "authors": "Matthias Christandl, Aram W. Harrow, Greta Panova, Pietro M. Posta, Michael Walter",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08441v1",
    "source": "arXiv",
    "abstract": "Some representation-theoretic multiplicities, such as the Kostka and the Littlewood-Richardson coefficients, admit a combinatorial interpretation that places their computation in the complexity class #P. Whether this holds more generally is considered an important open problem in mathematics and computer science, with relevance for geometric complexity theory and quantum information. Recent work has investigated the quantum complexity of particular multiplicities, such as the Kronecker coefficients and certain special cases of the plethysm coefficients. Here, we show that a broad class of representation-theoretic multiplicities is in #BQP. In particular, our result implies that the plethysm coefficients are in #BQP, which was only known in special cases. It also implies all known results on the quantum complexity of previously studied coefficients as special cases, unifying, simplifying, and extending prior work. We obtain our result by multiple applications of the Schur transform. Recent work has improved its dependence on the local dimension, which is crucial for our work. We further describe a general approach for showing that representation-theoretic multiplicities are in #BQP that captures our approach as well as the approaches of prior work. We complement the above by showing that the same multiplicities are also naturally in GapP and obtain polynomial-time classical algorithms when certain parameters are fixed."
  },
  {
    "date": "2026-02-09",
    "title": "Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition",
    "authors": "Yuhao Dong, Shulin Tian, Shuai Liu, Shuangrui Ding, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Jiaqi Wang, Ziwei Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08439v1",
    "source": "arXiv",
    "abstract": "Despite the growing video understanding capabilities of recent Multimodal Large Language Models (MLLMs), existing video benchmarks primarily assess understanding based on models' static, internal knowledge, rather than their ability to learn and adapt from dynamic, novel contexts from few examples. To bridge this gap, we present Demo-driven Video In-Context Learning, a novel task focused on learning from in-context demonstrations to answer questions about the target videos. Alongside this, we propose Demo-ICL-Bench, a challenging benchmark designed to evaluate demo-driven video in-context learning capabilities. Demo-ICL-Bench is constructed from 1200 instructional YouTube videos with associated questions, from which two types of demonstrations are derived: (i) summarizing video subtitles for text demonstration; and (ii) corresponding instructional videos as video demonstrations. To effectively tackle this new challenge, we develop Demo-ICL, an MLLM with a two-stage training strategy: video-supervised fine-tuning and information-assisted direct preference optimization, jointly enhancing the model's ability to learn from in-context examples. Extensive experiments with state-of-the-art MLLMs confirm the difficulty of Demo-ICL-Bench, demonstrate the effectiveness of Demo-ICL, and thereby unveil future research directions."
  },
  {
    "date": "2026-02-09",
    "title": "The Connection between Kriging and Large Neural Networks",
    "authors": "Marius Marinescu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08427v1",
    "source": "arXiv",
    "abstract": "AI has impacted many disciplines and is nowadays ubiquitous. In particular, spatial statistics is in a pivotal moment where it will increasingly intertwine with AI. In this scenario, a relevant question is what relationship spatial statistics models have with machine learning (ML) models, if any. In particular, in this paper, we explore the connections between Kriging and neural networks. At first glance, they may appear unrelated. Kriging - and its ML counterpart, Gaussian process regression - are grounded in probability theory and stochastic processes, whereas many ML models are extensively considered Black-Box models. Nevertheless, they are strongly related. We study their connections and revisit the relevant literature. The understanding of their relations and the combination of both perspectives may enhance ML techniques by making them more interpretable, reliable, and spatially aware."
  },
  {
    "date": "2026-02-09",
    "title": "LLMs + Security = Trouble",
    "authors": "Benjamin Livshits",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08422v1",
    "source": "arXiv",
    "abstract": "We argue that when it comes to producing secure code with AI, the prevailing \"fighting fire with fire\" approach -- using probabilistic AI-based checkers or attackers to secure probabilistically generated code -- fails to address the long tail of security bugs. As a result, systems may remain exposed to zero-day vulnerabilities that can be discovered by better-resourced or more persistent adversaries. While neurosymbolic approaches that combine LLMs with formal methods are attractive in principle, we argue that they are difficult to reconcile with the \"vibe coding\" workflow common in LLM-assisted development: unless the end-to-end verification pipeline is fully automated, developers are repeatedly asked to validate specifications, resolve ambiguities, and adjudicate failures, making the human-in-the-loop a likely point of weakness, compromising secure-by-construction guarantees. In this paper we argue that stronger security guarantees can be obtained by enforcing security constraints during code generation (e.g., via constrained decoding), rather than relying solely on post-hoc detection and repair. This direction is particularly promising for diffusion-style code models, whose approach provides a natural elegant opportunity for modular, hierarchical security enforcement, allowing us to combine lower-latency generation techniques with generating secure-by-construction code."
  },
  {
    "date": "2026-02-09",
    "title": "Graph-Loc: Robust Graph-Based LiDAR Pose Tracking with Compact Structural Map Priors under Low Observability and Occlusion",
    "authors": "Wentao Zhao, Yihe Niu, Zikun Chen, Rui Li, Yanbo Wang, Tianchen Deng, Jingchuan Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08417v1",
    "source": "arXiv",
    "abstract": "Map-based LiDAR pose tracking is essential for long-term autonomous operation, where onboard map priors need be compact for scalable storage and fast retrieval, while online observations are often partial, repetitive, and heavily occluded. We propose Graph-Loc, a graph-based localization framework that tracks the platform pose against compact structural map priors represented as a lightweight point-line graph. Such priors can be constructed from heterogeneous sources commonly available in practice, including polygon outlines vectorized from occupancy/grid maps and CAD/model/floor-plan layouts. For each incoming LiDAR scan, Graph-Loc extracts sparse point and line primitives to form an observation graph, retrieves a pose-conditioned visible subgraph via LiDAR ray simulation, and performs scan-to-map association through unbalanced optimal transport with a local graph-context regularizer. The unbalanced formulation relaxes mass conservation, improving robustness to missing, spurious, and fragmented structures under occlusion. To enhance stability in low-observability segments, we estimate information anisotropy from the refinement normal matrix and defer updates along weakly constrained directions until sufficient constraints reappear. Experiments on public benchmarks, controlled stress tests, and real-world deployments demonstrate accurate and stable tracking with KB-level priors from heterogeneous map sources, including under geometrically degenerate and sustained occlusion and in the presence of gradual scene changes."
  },
  {
    "date": "2026-02-09",
    "title": "Drop the mask! GAMM-A Taxonomy for Graph Attributes Missing Mechanisms",
    "authors": "Richard Serrano, Baptiste Jeudy, Charlotte Laclau, Christine Largeron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08407v1",
    "source": "arXiv",
    "abstract": "Exploring missing data in attributed graphs introduces unique challenges beyond those found in tabular datasets. In this work, we extend the taxonomy for missing data mechanisms to attributed graphs by proposing GAMM (Graph Attributes Missing Mechanisms), a framework that systematically links missingness probability to both node attributes and the underlying graph structure. Our taxonomy enriches the conventional definitions of masking mechanisms by introducing graph-specific dependencies. We empirically demonstrate that state-of-the-art imputation methods, while effective on traditional masks, significantly struggle when confronted with these more realistic graph-aware missingness scenarios."
  },
  {
    "date": "2026-02-09",
    "title": "Geometry-driven impact of photosensor placement on S2-based XY reconstruction in a dual-phase argon TPC",
    "authors": "Jilong Yin, Yi Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08402v1",
    "source": "arXiv",
    "abstract": "Accurate reconstruction of the horizontal vertex $(x,y)$ from the S2 electroluminescence pattern is essential for fiducialization and background rejection in dual-phase argon time projection chambers. In this work, we perform a Geant4-based simulation study using the G4DS framework to investigate how detector geometry, in particular the distance between the top photodetector plane and the gas pocket, impacts S2-based XY reconstruction. A compact dual-phase argon TPC instrumented with seven Hamamatsu R8520-506 PMTs is simulated with electron recoils at 41.5 keV (corresponding to the ${}^{83m}\\mathrm{Kr}$ calibration energy), as well as 1.0 keV to probe the low-S2 regime. The PMT array height is scanned from 0 mm to 50 mm, and XY positions are reconstructed using a geometrical solid-angle (GSA) method with the S2 emission modeled by 1 mm-thick slices across the 7 mm gas pocket. The results show a clear non-monotonic dependence of reconstruction bias and resolution on PMT height, driven by the trade-off between S2 light sharing and photon statistics. These findings provide guidance for geometry optimization in future low-threshold dual-phase argon detectors and will be validated with upcoming prototype measurements."
  },
  {
    "date": "2026-02-09",
    "title": "Multipoint Padé Approximation of the Hurwitz Zeta Function and a Riemann-Hilbert Steepest Descent Analysis",
    "authors": "Artur Kandaian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08399v1",
    "source": "arXiv",
    "abstract": "We study multipoint Padé approximants of type $(n,n)$ for the Hurwitz zeta function $f(a)=ζ(s,a)$ with $\\Re s>1$, constructed at quantile nodes $a_{n,j}=nα_{n,j}$ generated by a real-analytic density $κ$ on $[A,B]\\Subset(0,\\infty)$. Under the determinantal nondegeneracy condition $\\mathrm{(ND)}_n$ for large $n$ and in the regular one-cut soft-edge regime of the associated constrained equilibrium problem, we formulate the approximation as a matrix Riemann--Hilbert problem with poles and carry out a Deift--Zhou nonlinear steepest descent analysis. We construct an explicit outer parametrix together with Airy-type local parametrices at the endpoints and reduce the problem to a small-norm Riemann--Hilbert problem with uniform $O(1/n)$ control. As a consequence, the Padé numerator and denominator admit strong asymptotics uniformly on compact subsets of $\\mathbb{C}\\setminus[A,B]$, and exhibit Airy scaling in $O(n^{-2/3})$ neighborhoods of the edges."
  },
  {
    "date": "2026-02-09",
    "title": "Quantum Detection of Sequency-Band Structure",
    "authors": "Alok Shukla, Prakash Vedula",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08393v1",
    "source": "arXiv",
    "abstract": "We present a quantum algorithm for estimating the amplitude content of user-specified sequency bands in quantum-encoded signals. The method employs a sequency-ordered Quantum Walsh-Hadamard Transform (QWHT), a comparator-based oracle that coherently marks basis states within an arbitrary sequency range, and Quantum Amplitude Estimation (QAE) to estimate the total probability mass in the selected band. This enables the detection of structured signal components, including both high- and low-sequency features, as well as the identification of rapid sign-change behavior associated with noise or anomalies. The proposed method can be embedded as a module within a larger quantum algorithm; in this setting, both the input and output remain fully quantum, enabling seamless integration with upstream and downstream quantum operations. We show that the sequency-ordered QWHT can be implemented with circuit depth $O(\\log_2 N)$ (equivalently $O(n)$ for $N=2^n$) when acting on an amplitude-encoded quantum state, whereas computing the full Walsh-Hadamard spectrum of an explicit length-$N$ classical signal requires $O(N\\log_2 N)$ operations via the fast Walsh-Hadamard transform. This results in an exponential quantum advantage when the QWHT is used as a modular block within a larger quantum algorithm, relative to classical fast Walsh-Hadamard transform-based approaches operating on explicit data. From an application perspective, the proposed sequency band-energy estimation may be interpreted as a structure-based anomaly indicator, enabling the detection of unexpected high-sequency components relative to a nominal low-sequency signal class. The algorithm is applicable to quantum-enhanced signal processing tasks such as zero-crossing analysis, band-limited noise estimation, and feature extraction in the Walsh basis."
  },
  {
    "date": "2026-02-09",
    "title": "Geometric Image Editing via Effects-Sensitive In-Context Inpainting with Diffusion Transformers",
    "authors": "Shuo Zhang, Wenzhuo Wu, Huayu Zhang, Jiarong Cheng, Xianghao Zang, Chao Ban, Hao Sun, Zhongjiang He, Tianwei Cao, Kongming Liang, Zhanyu Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08388v1",
    "source": "arXiv",
    "abstract": "Recent advances in diffusion models have significantly improved image editing. However, challenges persist in handling geometric transformations, such as translation, rotation, and scaling, particularly in complex scenes. Existing approaches suffer from two main limitations: (1) difficulty in achieving accurate geometric editing of object translation, rotation, and scaling; (2) inadequate modeling of intricate lighting and shadow effects, leading to unrealistic results. To address these issues, we propose GeoEdit, a framework that leverages in-context generation through a diffusion transformer module, which integrates geometric transformations for precise object edits. Moreover, we introduce Effects-Sensitive Attention, which enhances the modeling of intricate lighting and shadow effects for improved realism. To further support training, we construct RS-Objects, a large-scale geometric editing dataset containing over 120,000 high-quality image pairs, enabling the model to learn precise geometric editing while generating realistic lighting and shadows. Extensive experiments on public benchmarks demonstrate that GeoEdit consistently outperforms state-of-the-art methods in terms of visual quality, geometric accuracy, and realism."
  },
  {
    "date": "2026-02-09",
    "title": "2D ferroelectric narrow-bandgap semiconductor Wurtzite' type alpha-In2Se3 and its silicon-compatible growth",
    "authors": "Yuxuan Jiang, Xingkun Ning, Renhui Liu, Kepeng Song, Sajjad Ali, Haoyue Deng, Yizhuo Li, Biaohong Huang, Jianhang Qiu, Xiaofei Zhu, Zhen Fan, Qiankun Li, Chengbing Qin, Fei Xue, Teng Yang, Bing Li, Gang Liu, Weijin Hu, Lain-Jong Li, Zhidong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08381v1",
    "source": "arXiv",
    "abstract": "2D van der Waals ferroelectrics, particularly alpha-In2Se3, have emerged as an attractive building block for next-generation information storage technologies due to their moderate band gap and robust ferroelectricity stabilized by dipole locking. alpha-In2Se3 can adopt either the distorted zincblende or wurtzite structures; however, the wurtzite phase has yet to be experimental-ly validated, and its large-scale synthesis poses significant challenges. Here, we report an in-situ transport growth of centimeter-scale wurtzite type alpha-In2Se3 films directly on SiO2 substrates using a process combining pulsed laser deposition and chemical vapor deposition. We demonstrate that it is a narrow bandgap ferroelectric semiconductor, featuring a Curie tem-perature exceeding 620 K, a tunable bandgap (0.8-1.6 eV) modulated by charged domain walls, and a large optical absorption coefficient of 1.3 times 10 powers 6 per centemeter. Moreover, light absorption promotes the dynamic conductance range, linearity, and symmetry of the synapse devices, leading to a high recognition accuracy of 92.3 percent in a supervised pattern classification task for neuromorphic computing. Our findings demonstrate a ferroelectric polymorphism of In2Se3, highlighting its potential in ferroelectric synapses for neuromorphic computing."
  },
  {
    "date": "2026-02-09",
    "title": "CFHT MegaCam Two Deep Fields Imaging Survey (2DFIS) II: Decoding the Lensing Profile of a \"Rotating\" Cluster with Deep CFHT Imaging",
    "authors": "Yicheng Li, Liping Fu, Wentao Luo, Binyang Liu, Wei Du, Martin Kilbinger, Calum Murray, Christopher J. Miller, Ray Wang, David Turner, Lance Miller, Dezi Liu, Mario Radovich, Jean-Paul Kneib, Huanyuan Shan, Kaiwen Mai, Zicheng Wang, Haoran Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08360v1",
    "source": "arXiv",
    "abstract": "We present a multi-wavelength analysis of the galaxy cluster RXCJ0110.0+1358 ($z=0.058$), a rotating cluster candidate, combining deep CFHT imaging, SDSS photometry, spectroscopic redshifts, and XMM-Newton X-ray observations. We find a notable discrepancy between the optical and X-ray views: while optical data reveal a pronounced bimodal galaxy distribution with significant kinematic substructure signatures, the X-ray emission exhibits a single, smoothly extended component centered on the BCG. Our weak lensing analysis resolves this discrepancy by revealing that the mass is predominantly concentrated in the southeast ($\\log M_{200}/M_\\odot = 14.04_{-0.40}^{+0.24}$), while the northwestern substructure has a negligible mass ($\\sim 10^{13} M_\\odot$). This immense mass disparity rules out the dynamical possibility of a rotating system. We demonstrate that the apparent optical bimodality arises from the projection of a filament, which led optical group-finding algorithms to misclassify these galaxies as cluster members. This contamination creates a spurious substructure that mimics a rotation signal and leads to an overestimation of the luminosity-based halo mass, resolving the observed inconsistencies."
  },
  {
    "date": "2026-02-09",
    "title": "Uniform spectral gaps for random hyperbolic surfaces with not many cusps",
    "authors": "Yuxin He, Yunhui Wu, Yuhao Xue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08352v1",
    "source": "arXiv",
    "abstract": "In this paper, we investigate uniform spectral gaps for Weil-Petersson random hyperbolic surfaces with not many cusps. We show that if $n=O(g^α)$ where $α\\in \\left[0,\\frac{1}{2}\\right)$, then for any $ε>0$, a random cusped hyperbolic surface in $\\mathcal{M}_{g,n}$ has no eigenvalues in $\\left(0,\\frac{1}{4}-\\left(\\frac{1}{6(1-α)}\\right)^2-ε\\right)$. If $α$ is close to $\\frac{1}{2}$, this gives a new uniform lower bound $\\frac{5}{36}-ε$ for the spectral gaps of Weil-Petersson random hyperbolic surfaces. The major contribution of this work is to reveal a critical phenomenon of ``second order cancellation\"."
  },
  {
    "date": "2026-02-09",
    "title": "UrbanGraphEmbeddings: Learning and Evaluating Spatially Grounded Multimodal Embeddings for Urban Science",
    "authors": "Jie Zhang, Xingtong Yu, Yuan Fang, Rudi Stouffs, Zdravko Trivic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08342v1",
    "source": "arXiv",
    "abstract": "Learning transferable multimodal embeddings for urban environments is challenging because urban understanding is inherently spatial, yet existing datasets and benchmarks lack explicit alignment between street-view images and urban structure. We introduce UGData, a spatially grounded dataset that anchors street-view images to structured spatial graphs and provides graph-aligned supervision via spatial reasoning paths and spatial context captions, exposing distance, directionality, connectivity, and neighborhood context beyond image content. Building on UGData, we propose UGE, a two-stage training strategy that progressively and stably aligns images, text, and spatial structures by combining instruction-guided contrastive learning with graph-based spatial encoding. We finally introduce UGBench, a comprehensive benchmark to evaluate how spatially grounded embeddings support diverse urban understanding tasks -- including geolocation ranking, image retrieval, urban perception, and spatial grounding. We develop UGE on multiple state-of-the-art VLM backbones, including Qwen2-VL, Qwen2.5-VL, Phi-3-Vision, and LLaVA1.6-Mistral, and train fixed-dimensional spatial embeddings with LoRA tuning. UGE built upon Qwen2.5-VL-7B backbone achieves up to 44% improvement in image retrieval and 30% in geolocation ranking on training cities, and over 30% and 22% gains respectively on held-out cities, demonstrating the effectiveness of explicit spatial grounding for spatially intensive urban tasks."
  },
  {
    "date": "2026-02-09",
    "title": "Combinatorial Spacetime from Loop Quantum Gravity",
    "authors": "Mikhail Altaisky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08341v1",
    "source": "arXiv",
    "abstract": "Loop quantum gravity is a perspective candidate for the quantum theory of gravity. However, there is a conceptual controversy in it: having started from the Einstein-Hilbert action and describing spacetime without matter, we can hardly define spacetime as anything other than a set of relations between matter fields. Here, following the Penrose idea of combinatorial spacetime we reformulate loop quantum gravity theory solely in terms of the matter fields."
  },
  {
    "date": "2026-02-09",
    "title": "Dark Matter from Eternity",
    "authors": "G. Franciolini, M. Peloso, A. Riotto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08338v1",
    "source": "arXiv",
    "abstract": "We propose that the totality of dark matter in the universe might ascribe its origin to one of the key properties of cosmological inflation, that it may be eternal: regions that at the end of the primordial accelerated expansion of the universe never reheated, but keep eternally inflating, manifest themselves as primordial black holes in our observable universe. This mechanism can provide a primordial black hole abundance which is larger than the standard one due to the gravitational collapse of sizeable overdensities in the radiation phase. It also predicts a broad spectrum for the curvature perturbation and a flat stochastic gravitational wave background at a level of $Ω_\\text{GW} h^2 \\simeq 10^{-10}$ up to the mHz."
  },
  {
    "date": "2026-02-09",
    "title": "Near-Oracle KV Selection via Pre-hoc Sparsity for Long-Context Inference",
    "authors": "Yifei Gao, Lei Wang, Rong-Cheng Tu, Qixin Zhang, Jun Cheng, Dacheng Tao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08329v1",
    "source": "arXiv",
    "abstract": "A core bottleneck in large language model (LLM) inference is the cost of attending over the ever-growing key-value (KV) cache. Although near-oracle top-k KV selection can preserve the quality of dense attention while sharply reducing computation and bandwidth, existing sparse methods generally rely on posterior heuristics, i.e., selectors conditioned on observed attention or proxy scores. Such conditioning introduces posterior bias: it tends to distort true token importance and miss salient tokens, thereby impairing long-range reasoning. To tackle this problem, we propose Pre-hoc Sparsity (PrHS), which selects KV entries before attention scoring and provides explicit accuracy control. Let the attention mass of discarded entries be delta (the dropped mass). Through a marginal-to-mutual-information analysis, we derive an upper bound on the mutual-information loss that depends only on the dropped mass. This relation explains failure modes of posterior heuristics and enables verifiable guarantees by controlling the dropped mass in advance. Within PrHS, we instantiate three orthogonal pre-hoc selectors along the axes of time, depth, and layer. Extensive experiments on LLaMA and Mistral families validate PrHS. Across GSM8K and CoQA, PrHS reduces retrieval overhead by over 90%, achieving 3x higher retrieval sparsity than HShare at matched or better accuracy. It incurs under 1% average degradation on LongBench, lowers attention FLOPs by about 15% versus prior sparse baselines, and yields a 9.9x speedup in attention-operator latency and 2.8x higher throughput on NVIDIA A100-80GB GPUs than the dense baseline."
  },
  {
    "date": "2026-02-09",
    "title": "Making Databases Searchable with Deep Context",
    "authors": "Alekh Jindal, Shi Qiao, Shivani Tripathi, Niloy Debnath, Kunal Singh, Pushpanjali Nema, Sharath Prakash, Aditya Halder, Ronith PR, Sadiq Mohammed, Abdul Hameed, Karan Hanswadkar, Ayush Kshitij, Sarthak Bhatt, Rony Chatterjee, Jyoti Pandey, Christina Pavlopoulou, Ravi Shetye",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08320v1",
    "source": "arXiv",
    "abstract": "Databases are the most critical assets for enterprises, and yet they remain largely inaccessible to people who make the most important decisions. In this paper, we describe the Tursio search platform that builds an abstraction layer, aka semantic knowledge graph, over the underlying databases to make them searchable in natural language. Tursio infuses large language models (LLMs) into every part of the query processing stack, including data modeling, query compilation, query planning, and result reasoning. This allows Tursio to process natural language queries systematically using techniques from traditional query planning and rewriting, rather than black-box memorization. We describe the architecture of Tursio in detail and present a comprehensive evaluation on production workloads, and synthetic and realistic benchmarks. Our results show that Tursio achieves high accuracy while being efficient and scalable, making databases truly searchable for non-expert users."
  },
  {
    "date": "2026-02-09",
    "title": "A criterion for a Hurewicz cofibration to be a Quillen cofibration",
    "authors": "Andrew Ronan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08317v1",
    "source": "arXiv",
    "abstract": "In this paper, we prove that $h$-cofibrations between $q$-cofibrant spaces are $q$-cofibrations. We also present a number of applications, including a pushout-product property for symmetrizable cofibrations, a local-to-global gluing lemma for $q$-cofibrations, a proof that $q$-fibrations between $q$-cofibrant spaces are $h$-fibrations, and an alternative proof of Waner's theorem on $G$-spaces with the $G$-homotopy type of a $G$-CW complex in fibre sequences. Moreover, all of the above generalises readily to the equivariant context, and so we work in the more general equivariant setting throughout."
  },
  {
    "date": "2026-02-09",
    "title": "SWE Context Bench: A Benchmark for Context Learning in Coding",
    "authors": "Jared Zhu, Minhao Hu, Junde Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08316v1",
    "source": "arXiv",
    "abstract": "Large language models are increasingly used as programming agents for repository level software engineering tasks. While recent benchmarks evaluate correctness in realistic codebases, they largely treat tasks as independent and do not assess whether agents can reuse experience across related problems. As a result, the ability of agents to accumulate, retrieve, and apply prior experience, as well as the efficiency gains from such reuse, remains difficult to measure. We introduce SWE-ContextBench, a benchmark designed to explicitly evaluate experience reuse in programming agents. Built on SWE-Bench Lite, SWE-ContextBench augments 300 base tasks with 99 related tasks derived from real dependency and reference relationships among GitHub issues and pull requests, forming task sequences with shared context. The benchmark evaluates agents along three complementary dimensions: prediction accuracy, time efficiency, and cost efficiency. Using SWE-ContextBench, we study multiple experience reuse settings, including oracle guided and autonomous retrieval, as well as full execution trajectories and compact summaries. Our results show that correctly selected summarized experience improves resolution accuracy and substantially reduces runtime and token cost, particularly on harder tasks. In contrast, unfiltered or incorrectly selected experience provides limited or negative benefits. These findings highlight the importance of experience representation and retrieval quality, and position SWE-ContextBench as a principled benchmark for studying experience reuse in programming agents."
  },
  {
    "date": "2026-02-09",
    "title": "CFHT MegaCam Two Deep Fields Imaging Survey (2DFIS) I: Overview",
    "authors": "Binyang Liu, Wentao Luo, Martin Kilbinger, Shenming Fu, Ian Dell'Antonio, Liping Fu, Xian Zhong Zheng, Yi-fu Cai, Cheng Jia, Ning Jiang, Qinxun Li, Yicheng Li, Shurui Lin, Christopher J. Miller, Surhud S. More, Huiyuan Wang, Yibo Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08312v1",
    "source": "arXiv",
    "abstract": "We present the Two Deep Fields Imaging Survey (2DFIS), a wide-field imaging program conducted with the Canada-France-Hawaii Telescope (CFHT) targeting two astrophysically distinct regions: one containing a repeating fast radio burst (FRB) source and another hosting a candidate of a rotating galaxy cluster. Achieving a depth of r~26mag, the survey enables a search for faint optical counterparts and environmental signatures associated with the FRB, while high-quality photometric and galaxy shape measurements in the cluster field support a weak-lensing analysis of its mass distribution. This paper describes the observing strategy and data processing methodology adopted for 2DFIS, including the use of the LSST Science Pipelines with survey-specific adaptations for CFHT/MegaCam data. We outline a complete workflow for transforming raw CFHT exposures into science-ready data products, including calibrated single-epoch images, multi-band coadded mosaics, and extensive source catalogs. These data products provide the foundation for ongoing and future studies of FRB host environments, cluster mass reconstruction, and related cosmological applications."
  },
  {
    "date": "2026-02-09",
    "title": "Moral Sycophancy in Vision Language Models",
    "authors": "Shadman Rabby, Md. Hefzul Hossain Papon, Sabbir Ahmed, Nokimul Hasan Arif, A. B. M. Ashikur Rahman, Irfan Ahmad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08311v1",
    "source": "arXiv",
    "abstract": "Sycophancy in Vision-Language Models (VLMs) refers to their tendency to align with user opinions, often at the expense of moral or factual accuracy. While prior studies have explored sycophantic behavior in general contexts, its impact on morally grounded visual decision-making remains insufficiently understood. To address this gap, we present the first systematic study of moral sycophancy in VLMs, analyzing ten widely-used models on the Moralise and M^3oralBench datasets under explicit user disagreement. Our results reveal that VLMs frequently produce morally incorrect follow-up responses even when their initial judgments are correct, and exhibit a consistent asymmetry: models are more likely to shift from morally right to morally wrong judgments than the reverse when exposed to user-induced bias. Follow-up prompts generally degrade performance on Moralise, while yielding mixed or even improved accuracy on M^3oralBench, highlighting dataset-dependent differences in moral robustness. Evaluation using Error Introduction Rate (EIR) and Error Correction Rate (ECR) reveals a clear trade-off: models with stronger error-correction capabilities tend to introduce more reasoning errors, whereas more conservative models minimize errors but exhibit limited ability to self-correct. Finally, initial contexts with a morally right stance elicit stronger sycophantic behavior, emphasizing the vulnerability of VLMs to moral influence and the need for principled strategies to improve ethical consistency and robustness in multimodal AI systems."
  },
  {
    "date": "2026-02-09",
    "title": "Variational Method for Interacting Surfaces with Higher-Form Global Symmetries",
    "authors": "Kiyoharu Kawana",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08310v1",
    "source": "arXiv",
    "abstract": "We develop a variational method for interacting surface systems with higher-form global symmetries. As a natural extension of the conventional second-quantized Hamiltonian of interacting bosons, we explicitly construct a second-quantized Hamiltonian formulated in terms of a closed surface operator $\\hatφ[C_p^{}]$ charged under a $p$-form global symmetry. Applying the variational principle, we derive a functional Schrödinger equation analogous to the Gross-Pitaevskii equation in conventional bosonic systems. In the absence of external forces, the variational equation admits a uniform solution that is uniquely determined by a microscopic interaction potential $U(ψ^*ψ)$ and the chemical potential. This uniform solution describes a uniform gas of bosonic surfaces. Using the obtained energy functional, we show that low-energy fluctuations contain a gapless $p$-form field $A_p^{}$ when the $p$-form global symmetry is $\\mathrm{U}(1)$, whereas the $p$-form field becomes massive for discrete symmetries, whose low-energy limit is described by a $\\mathrm{BF}$-type topological field theory. As a consequence, the system exhibits abelian topological order with anyonic surface excitations. In the presence of external forces, however, solving the functional equation in full generality remains challenging. We argue, however, that the problem reduces to solving the conventional Gross-Pitaevskii equation when external forces act separately on the center-of-mass and relative motions. In addition, we present analytic solutions for topological defects as analogs of vortex and domain-wall solutions in conventional bosonic systems. Finally, as a concrete microscopic model, we study a $\\mathbb{Z}_N^{}$ lattice gauge theory and apply our variational method to this system."
  },
  {
    "date": "2026-02-09",
    "title": "TextResNet: Decoupling and Routing Optimization Signals in Compound AI Systems via Deep Residual Tuning",
    "authors": "Suizhi Huang, Mei Li, Han Yu, Xiaoxiao Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08306v1",
    "source": "arXiv",
    "abstract": "Textual Gradient-style optimizers (TextGrad) enable gradient-like feedback propagation through compound AI systems. However, they do not work well for deep chains. The root cause of this limitation stems from the Semantic Entanglement problem in these extended workflows. In standard textual backpropagation, feedback signals mix local critiques with upstream contexts, leading to Attribution Ambiguity. To address this challenge, we propose TextResNet, a framework that reformulates the optimization process to achieve precise signal routing via four key innovations. Firstly, in the forward pass, it enforces Additive Semantic Deltas to preserve an Identity Highway for gradient flow. Secondly, in the backward pass, it introduces Semantic Gradient Decomposition via a Semantic Projector to disentangle feedback into causally independent subspaces. Thirdly, it implements Causal Routing, which routes projected signals to their specific components. Finally, it performs Density-Aware Optimization Scheduling to leverage the disentangled signals to dynamically allocate resources to key system bottlenecks. Our results show that TextResNet not only achieves superior performance compared to TextGrad, but also exhibits remarkable stability for agentic tasks in compound AI systems where baselines collapse. Code is available at https://github.com/JeanDiable/TextResNet."
  },
  {
    "date": "2026-02-09",
    "title": "Room Temperature Collective Blinking and Photon Bunching from CsPbBr3 Quantum Dot Superlattice",
    "authors": "Qiwen Tan, Sudipta Seth, Boris Louis, Xiayan Wu, Nithin Pathoor, Toranosuke Takagi, Shun Omagari, Takumi Sannomiya, Johan Hofkens, Martin Vacha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08301v1",
    "source": "arXiv",
    "abstract": "Development of quantum light sources and search for quantum systems capable of supporting collective many-body states are crucial for further progress of modern quantum technologies. Metal halide perovskite quantum dots (QDs) have emerged as a promising candidate for quantum light sources, as individual QDs are reliable single photon emitters even at room temperature. However, photon bunching, a key signature of collective many-body states, has been so far largely observed at cryogenic temperatures in perovskite materials, limiting their applications under ambient conditions. Here, we report the observation of collective blinking and photon bunching in perovskite QD superlattices at room temperature. Sub-wavelength-sized (100 - 500 nm) CsPbBr3 QD superlattices, fabricated via a self-assembly process, exhibit an unusual two-level blinking behavior similar to that of single QDs, and demonstrate photon bunching with a degree of up to 2.75. Time-resolved photoluminescence (PL) measurements and super-resolution imaging reveal that the superlattices have a significantly longer PL lifetime than individual QDs and that their emission is spatially confined to regions tens of nanometers in size. These observations suggest long-range exciton migration to a localized energy trap within the superlattice. Excitation power dependent degree of bunching and analysis of the bunching dynamics indicate that the photon bunching originates from exciton-biexciton cascade emission, a key mechanism for generating entangled photons. These findings establish perovskite QD superlattices as a promising platform for room-temperature collective optical phenomena and quantum light generation, advancing scalable quantum photonic technologies."
  },
  {
    "date": "2026-02-09",
    "title": "Benchmarking Autonomous Vehicles: A Driver Foundation Model Framework",
    "authors": "Yuxin Zhang, Cheng Wang, Hubert P. H. Shum",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08298v1",
    "source": "arXiv",
    "abstract": "Autonomous vehicles (AVs) are poised to revolutionize global transportation systems. However, its widespread acceptance and market penetration remain significantly below expectations. This gap is primarily driven by persistent challenges in safety, comfort, commuting efficiency and energy economy when compared to the performance of experienced human drivers. We hypothesize that these challenges can be addressed through the development of a driver foundation model (DFM). Accordingly, we propose a framework for establishing DFMs to comprehensively benchmark AVs. Specifically, we describe a large-scale dataset collection strategy for training a DFM, discuss the core functionalities such a model should possess, and explore potential technical solutions to realize these functionalities. We further present the utility of the DFM across the operational spectrum, from defining human-centric safety envelopes to establishing benchmarks for energy economy. Overall, We aim to formalize the DFM concept and introduce a new paradigm for the systematic specification, verification and validation of AVs."
  },
  {
    "date": "2026-02-09",
    "title": "The Vibe-Automation of Automation: A Proactive Education Framework for Computer Science in the Age of Generative AI",
    "authors": "Ilya Levin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08295v1",
    "source": "arXiv",
    "abstract": "The emergence of generative artificial intelligence (GenAI) represents not an incremental technological advance but a qualitative epistemological shift that challenges foundational assumptions of computer science. Whereas machine learning has been described as the automation of automation, generative AI operates by navigating contextual, semantic, and stylistic coherence rather than optimizing predefined objective metrics. This paper introduces the concept of Vibe-Automation to characterize this transition. The central claim is that the significance of GenAI lies in its functional access to operationalized tacit regularities: context-sensitive patterns embedded in practice that cannot be fully specified through explicit algorithmic rules. Although generative systems do not possess tacit knowledge in a phenomenological sense, they operationalize sensitivities to tone, intent, and situated judgment encoded in high-dimensional latent representations. On this basis, the human role shifts from algorithmic problem specification toward Vibe-Engineering, understood as the orchestration of alignment and contextual judgment in generative systems. The paper connects this epistemological shift to educational and institutional transformation by proposing a conceptual framework structured across three analytical levels and three domains of action: faculty worldview, industry relations, and curriculum design. The risks of mode collapse and cultural homogenization are briefly discussed, emphasizing the need for deliberate engagement with generative systems to avoid regression toward synthetic uniformity."
  },
  {
    "date": "2026-02-09",
    "title": "Almost-primes in Sun's $x^2+ny^2$ conjecture",
    "authors": "Songlin Han, Jinbo Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08286v1",
    "source": "arXiv",
    "abstract": "In 2015 Zhi-Wei Sun proposed the conjecture that any integer $n > 1$ admits a partition $n = x + y$ with integers $x, y >0$ such that $x + ny$ and $x^2 + ny^2$ are simultaneously prime. To approach this conjecture we use the method of weighted sieve as developed by Richert, Halberstam, and Diamond. In this article, we first formalize the conjecture into a sieve problem. We verify that the conditions required to use Richert's weighted sieve are satisfied and establish partial results with almost-prime solutions for sufficiently large $n$."
  },
  {
    "date": "2026-02-09",
    "title": "ClusterChirp: A GPU-accelerated Web Server for Natural Language-Guided Interactive Visualization and Analysis of Large Omics Data",
    "authors": "Osho Rawal, Rex Lu, Edgar Gonzalez-Kozlova, Sacha Gnjatic, Zeynep H. Gümüş",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08280v1",
    "source": "arXiv",
    "abstract": "Tabular datasets are commonly visualized as heatmaps, where data values are represented as color intensities in a matrix to reveal patterns and correlations. However, modern omics technologies increasingly generate matrices so large that existing visual exploration tools require downsampling or filtering, risking loss of biologically important patterns. Additional barriers arise from tools that require command-line expertise, or fragmented workflows for downstream biological interpretation. We present ClusterChirp, a web-based platform for real-time, interactive exploration of large-scale data matrices enabled by GPU-accelerated rendering and parallelized hierarchical clustering using multiple CPU cores. Built on deck.gl and multi-threaded clustering algorithms, ClusterChirp supports on-the-fly clustering, multi-metric sorting, feature search, and adjustable visualization parameters for interactive explorations. Uniquely, a natural language interface powered by a Large Language Model helps users perform complex operations and build reproducible workflows from conversational commands. Furthermore, users can select clusters to explore interactive within-cluster correlation networks in 2D or 3D, or perform functional enrichment through biological knowledge bases. Developed with iterative user feedback and adhering to FAIR4S principles, ClusterChirp empowers researchers to extract insights from high-dimensional omics data with unprecedented ease and speed. This website is freely available at clusterchirp.mssm.edu, with no login required."
  },
  {
    "date": "2026-02-09",
    "title": "Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis",
    "authors": "Haoyu Jia, Kento Kawaharazuka, Kei Okada",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08276v1",
    "source": "arXiv",
    "abstract": "Current research on large language model (LLM) agents is fragmented: discussions of conceptual frameworks and methodological principles are frequently intertwined with low-level implementation details, causing both readers and authors to lose track amid a proliferation of superficially distinct concepts. We argue that this fragmentation largely stems from the absence of an analyzable, self-consistent formal model that enables implementation-independent characterization and comparison of LLM agents. To address this gap, we propose the \\texttt{Structural Context Model}, a formal model for analyzing and comparing LLM agents from the perspective of context structure. Building upon this foundation, we introduce two complementary components that together span the full lifecycle of LLM agent research and development: (1) a declarative implementation framework; and (2) a sustainable agent engineering workflow, \\texttt{Semantic Dynamics Analysis}. The proposed workflow provides principled insights into agent mechanisms and supports rapid, systematic design iteration. We demonstrate the effectiveness of the complete framework on dynamic variants of the monkey-banana problem, where agents engineered using our approach achieve up to a 32 percentage points improvement in success rate on the most challenging setting."
  },
  {
    "date": "2026-02-09",
    "title": "Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI",
    "authors": "Akinori Maeda, Yuto Sekiya, Sota Sugimura, Tomoya Asai, Yu Tsuda, Kohei Ikeda, Hiroshi Fujii, Kohei Watanabe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08268v1",
    "source": "arXiv",
    "abstract": "Personal data centralization among dominant platform providers including search engines, social networking services, and e-commerce has created siloed ecosystems that restrict user sovereignty, thereby impeding data use across services. Meanwhile, the rapid proliferation of Large Language Model (LLM)-based agents has intensified demand for highly personalized services that require the dynamic provision of diverse personal data. This presents a significant challenge: balancing the utilization of such data with privacy protection. To address this challenge, we propose Puda (Private User Dataset Agent), a user-sovereign architecture that aggregates data across services and enables client-side management. Puda allows users to control data sharing at three privacy levels: (i) Detailed Browsing History, (ii) Extracted Keywords, and (iii) Predefined Category Subsets. We implemented Puda as a browser-based system that serves as a common platform across diverse services and evaluated it through a personalized travel planning task. Our results show that providing Predefined Category Subsets achieves 97.2% of the personalization performance (evaluated via an LLM-as-a-Judge framework across three criteria) obtained when sharing Detailed Browsing History. These findings demonstrate that Puda enables effective multi-granularity management, offering practical choices to mitigate the privacy-personalization trade-off. Overall, Puda provides an AI-native foundation for user sovereignty, empowering users to safely leverage the full potential of personalized AI."
  },
  {
    "date": "2026-02-09",
    "title": "HEAL: Online Incremental Recovery for Leaderless Distributed Systems Across Persistency Models",
    "authors": "Antonis Psistakis, Burak Ocalan, Fabien Chaix, Ramnatthan Alagappan, Josep Torrellas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08257v1",
    "source": "arXiv",
    "abstract": "Ensuring resilience in distributed systems has become an acute concern. In today's environment, it is crucial to develop light-weight mechanisms that recover a distributed system from faults quickly and with only a small impact on the live-system throughput. To address this need, this paper proposes a new low-overhead, general recovery scheme for modern non-transactional leaderless distributed systems. We call our scheme HEAL. On a node failure, HEAL performs an optimized online incremental recovery. This paper presents HEAL's algorithms for settings with Linearizable consistency and different memory persistency models. We implement HEAL on a 6-node Intel cluster. Our experiments running TAOBench workloads show that HEAL is very effective. HEAL recovers the cluster in 120 milliseconds on average, while reducing the throughput of the running workload by an average of 8.7%. In contrast, a conventional recovery scheme for leaderless systems needs 360 seconds to recover, reducing the throughput of the system by 16.2%. Finally, compared to an incremental recovery scheme for a state-of-the-art leader-based system, HEAL reduces the average recovery latency by 20.7x and the throughput degradation by 62.4%."
  },
  {
    "date": "2026-02-09",
    "title": "Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs",
    "authors": "Siqu Ou, Tianrui Wan, Zhiyuan Zhao, Junyu Gao, Xuelong Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08241v1",
    "source": "arXiv",
    "abstract": "While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis shows that current MLLMs exhibit weak visual focus: early-stage visual misalignment is rarely corrected during subsequent reasoning, leading to error propagation and failed inferences. We argue that this limitation stems from inadequate credit assignment for visual attention during training. To address this issue, we propose SAYO, a visual reasoning model trained with a reinforcement learning (RL) framework that introduces a region-level visual attention-based reward. This reward explicitly aligns optimization signals with visually grounded reasoning steps, enabling the model to learn more reliable attention behaviors. Extensive experiments across multiple multimodal benchmarks demonstrate that SAYO consistently improves performance on diverse reasoning and perception tasks."
  },
  {
    "date": "2026-02-09",
    "title": "Document Reconstruction Unlocks Scalable Long-Context RLVR",
    "authors": "Yao Xiao, Lei Wang, Yue Deng, Guanzheng Chen, Ziqi Jin, Jung-jae Kim, Xiaoli Li, Roy Ka-wei Lee, Lidong Bing",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08237v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards~(RLVR) has become a prominent paradigm to enhance the capabilities (i.e.\\ long-context) of Large Language Models~(LLMs). However, it often relies on gold-standard answers or explicit evaluation rubrics provided by powerful teacher models or human experts, which are costly and time-consuming. In this work, we investigate unsupervised approaches to enhance the long-context capabilities of LLMs, eliminating the need for heavy human annotations or teacher models' supervision. Specifically, we first replace a few paragraphs with special placeholders in a long document. LLMs are trained through reinforcement learning to reconstruct the document by correctly identifying and sequencing missing paragraphs from a set of candidate options. This training paradigm enables the model to capture global narrative coherence, significantly boosting long-context performance. We validate the effectiveness of our method on two widely used benchmarks, RULER and LongBench~v2. While acquiring noticeable gains on RULER, it can also achieve a reasonable improvement on LongBench~v2 without any manually curated long-context QA data. Furthermore, we conduct extensive ablation studies to analyze the impact of reward design, data curation strategies, training schemes, and data scaling effects on model performance. We publicly release our code, data, and models."
  },
  {
    "date": "2026-02-09",
    "title": "A Minimal Interpretation of the Galactic Cosmic-Ray Spectrum from GeV to PeV Energies",
    "authors": "Felix Aharonian, Bing Theodore Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08223v1",
    "source": "arXiv",
    "abstract": "High-precision measurements of the cosmic-ray (CR) proton spectrum have revealed significant deviations from a simple power-law behaviour. These deviations are characterised by three prominent features: (i) a progressive spectral hardening above approximately 200 GeV, (ii) an excess between 10 and 30 TeV (the ``multi-TeV bump''), followed by a sharp turnover around 100 TeV, and (iii) a pronounced structure between 0.1 and 10 PeV (the ``PeV bump''). We propose a minimal two cosmic-ray population framework that consistently accounts for the observed CR proton spectrum across six decades in energy, from GeV to PeV. In this scenario, the spectral complexity arises naturally from a transition between two Galactic CR proton populations in the 10-100 TeV energy range. The low-energy population exhibits a sharp cutoff at tens of TeV, while a second, higher-energy population emerges and dominates above 100 TeV, terminating with a smooth exponential cutoff at approximately 6.5 PeV. This framework reproduces all observed spectral features without invoking contributions from nearby sources or requiring non-standard assumptions about particle acceleration or propagation. Recent gamma-ray observations of supernova remnants, star-forming regions, and microquasars provide plausible astrophysical candidates for the origin of the two CR components."
  },
  {
    "date": "2026-02-09",
    "title": "Pretraining with Token-Level Adaptive Latent Chain-of-Thought",
    "authors": "Boyi Zeng, Yiqin Hao, He Li, Shixiang Song, Feichen Song, Zitong Wang, Siyuan Huang, Yi Xu, ZiWei He, Xinbing Wang, Zhouhan Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08220v1",
    "source": "arXiv",
    "abstract": "Scaling large language models by increasing parameters and training data is increasingly constrained by limited high-quality corpora and rising communication costs. This work explores an alternative axis: increasing per-token computation without expanding parameters, by internalizing latent Chain-of-Thought (CoT) into pretraining. We propose Pretraining with Token-Level Adaptive Latent CoT (adaptive latent CoT), where the model generates a variable-length latent CoT trajectory before emitting each token -- allocating longer trajectories to difficult tokens and shorter (or even zero) trajectories to easy ones. Importantly, this behavior emerges naturally from one-stage pretraining on general text and reduces computation in both training and inference via token-wise adaptive halting. Experiments with Llama architectures show that adaptive latent CoT consistently improves language modeling perplexity and broad downstream accuracy, even with fewer training FLOPs than prior recurrent baselines."
  },
  {
    "date": "2026-02-09",
    "title": "HOICraft: In-Situ VLM-based Authoring Tool for Part-Level Hand-Object Interaction Design in VR",
    "authors": "Dohui Lee, Qi Sun, Sang Ho Yoon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08219v1",
    "source": "arXiv",
    "abstract": "Hand-Object Interaction (HOI) is a key interaction component in Virtual Reality (VR). However, designing HOI still requires manual efforts to decide how object should be selected and manipulated, while also considering user abilities, which leads to time-consuming refinements. We present HOICraft, a VLM-based in-situ HOI authoring tool that enables part-level interaction design in VR. Here, HOICraft assists designers by recommending interactable elements from 3D objects, customizing HOI design properties, and mapping hand movement with virtual object behavior. We conducted a formative study with three expert VR designers to identify five representative HOI designs to support diverse user experiences. Building upon preference data from 20 participants, we develop an HOI mapping module with in-context learning. In a user study with 12 VR interaction designers, HOI mapping from HOICraft significantly reduced trial-and-error iterations compared to manual authoring. Finally, we assessed the usability of HOICraft, demonstrating its effectiveness for HOI design in VR."
  },
  {
    "date": "2026-02-09",
    "title": "Sparsity-Aware Evolution for Model Merging",
    "authors": "Huan Zhang, Yanjian Zhang, Guillaume Wisniewski, Nadi Tomeh, Bang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08218v1",
    "source": "arXiv",
    "abstract": "We propose a sparsity-aware evolutionary (SAE) framework for model merging that involves iterative pruning-merging cycles to act as a novel mutation operator. We incorporate the sparsity constraints into the score function, which steers the evolutionary process to favor more sparse models, in addition to other conventional performance scores. Interestingly, the by-product of \\textit{competition} for sparsity introduces an extra local \\textit{attraction} and interplay into the evolutionary process: if one competitor has more zero elements, the other competitor's non-zero elements will occupy those positions, even though the less sparse competitor loses to the more sparse competitor in other positions. The proposed pipeline is evaluated on a variety of large-scale LLM benchmarks. Experiments demonstrate that our approach can improve model merging reliability across multiple benchmarks, and is easy to incorporate due to its simplicity and being orthogonal to most existing approaches."
  },
  {
    "date": "2026-02-09",
    "title": "Chain-of-Caption: Training-free improvement of multimodal large language model on referring expression comprehension",
    "authors": "Yik Lung Pang, Changjae Oh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08211v1",
    "source": "arXiv",
    "abstract": "Given a textual description, the task of referring expression comprehension (REC) involves the localisation of the referred object in an image. Multimodal large language models (MLLMs) have achieved high accuracy on REC benchmarks through scaling up the model size and training data. Moreover, the performance of MLLMs can be further improved using techniques such as Chain-of-Thought and tool use, which provides additional visual or textual context to the model. In this paper, we analyse the effect of various techniques for providing additional visual and textual context via tool use to the MLLM and its effect on the REC task. Furthermore, we propose a training-free framework named Chain-of-Caption to improve the REC performance of MLLMs. We perform experiments on RefCOCO/RefCOCOg/RefCOCO+ and Ref-L4 datasets and show that individual textual or visual context can improve the REC performance without any fine-tuning. By combining multiple contexts, our training-free framework shows between 5% to 30% performance gain over the baseline model on accuracy at various Intersection over Union (IoU) thresholds."
  },
  {
    "date": "2026-02-09",
    "title": "CADO: From Imitation to Cost Minimization for Heatmap-based Solvers in Combinatorial Optimization",
    "authors": "Hyungseok Song, Deunsol Yoon, Kanghoon Lee, Han-Seul Jeong, Soonyoung Lee, Woohyung Lim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08210v1",
    "source": "arXiv",
    "abstract": "Heatmap-based solvers have emerged as a promising paradigm for Combinatorial Optimization (CO). However, we argue that the dominant Supervised Learning (SL) training paradigm suffers from a fundamental objective mismatch: minimizing imitation loss (e.g., cross-entropy) does not guarantee solution cost minimization. We dissect this mismatch into two deficiencies: Decoder-Blindness (being oblivious to the non-differentiable decoding process) and Cost-Blindness (prioritizing structural imitation over solution quality). We empirically demonstrate that these intrinsic flaws impose a hard performance ceiling. To overcome this limitation, we propose CADO (Cost-Aware Diffusion models for Optimization), a streamlined Reinforcement Learning fine-tuning framework that formulates the diffusion denoising process as an MDP to directly optimize the post-decoded solution cost. We introduce Label-Centered Reward, which repurposes ground-truth labels as unbiased baselines rather than imitation targets, and Hybrid Fine-Tuning for parameter-efficient adaptation. CADO achieves state-of-the-art performance across diverse benchmarks, validating that objective alignment is essential for unlocking the full potential of heatmap-based solvers."
  },
  {
    "date": "2026-02-09",
    "title": "Does fermionic entanglement always outperform bosonic entanglement in dilaton black hole?",
    "authors": "Wen-Mei Li, Jianbo Lu, Shu-Min Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08205v1",
    "source": "arXiv",
    "abstract": "It has traditionally been believed that fermionic entanglement generally outperforms bosonic entanglement in relativistic frameworks, and that bosonic entanglement experiences sudden death in extreme gravitational environments. In this study, we analyze the genuine N-partite entanglement, measured by negativity, of bosonic and fermionic GHZ states, focusing on scenarios where a subset of $m$ ($m<N$) constituents interacts with Hawking radiation generated by a Garfinkle-Horowitz-Strominger (GHS) dilaton black hole. Surprisingly, we find that quantum entanglement between the non-gravitational and gravitational modes for the bosonic field is stronger than that in the same modes for the fermionic field within dilaton spacetime. This study challenges the traditional belief that ``fermionic entanglement always outperforms bosonic entanglement\" in the relativistic framework. However, quantum entanglement between the gravitational modes and the combined gravitational and non-gravitational modes is weaker for the bosonic field than for the fermionic field in the presence of a dilaton black hole. Finally, the connection between the global N-partite entanglement in the bosonic field and that in the fermionic field is influenced by the gravitational field's intensity. Our study reveals the intrinsic relationship between quantum entanglement of bosonic and fermionic fields in curved spacetime from a new perspective, and provides theoretical guidance for selecting appropriate field-based quantum resources for relativistic quantum information tasks under extreme gravitational conditions."
  },
  {
    "date": "2026-02-09",
    "title": "Amplified up-conversion of electromagnetic waves using time-varying metasurfaces",
    "authors": "Fedor Kovalev, Stanislav Maslovski, Abdelghafour Abraray, Ilya Shadrivov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08193v1",
    "source": "arXiv",
    "abstract": "Time-varying metamaterials and photonic time crystals offer a powerful route to wave amplification through temporal modulation of material parameters. Here, we experimentally demonstrate amplified up-conversion of free-space electromagnetic waves in the microwave regime, with conversion efficiency exceeding the limits imposed by the Manley-Rowe relations as a result of a cascaded amplification process. Using a time-varying metasurface composed of an array of varactor-loaded coupled split-ring resonators, we investigate parametric amplification, frequency up-conversion and wave generation. Direct measurements in both non-degenerate and degenerate regimes show that the Manley-Rowe limits can be surpassed near integer multiples of the incident wave frequency when the pump frequency is approximately twice that of the incident wave. These results establish time-varying metasurfaces as an efficient platform for amplification, generation, and frequency conversion of electromagnetic waves in the microwave and terahertz bands, with potential extension to optical frequencies via ultrafast modulation techniques."
  },
  {
    "date": "2026-02-09",
    "title": "Large Language Models in Peer-Run Community Behavioral Health Services: Understanding Peer Specialists and Service Users' Perspectives on Opportunities, Risks, and Mitigation Strategies",
    "authors": "Cindy Peng, Megan Chai, Gao Mo, Naveen Raman, Ningjing Tang, Shannon Pagdon, Margaret Swarbrick, Nev Jones, Fei Fang, Hong Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08187v1",
    "source": "arXiv",
    "abstract": "Peer-run organizations (PROs) provide critical, recovery-based behavioral health support rooted in lived experience. As large language models (LLMs) enter this domain, their scale, conversationality, and opacity introduce new challenges for situatedness, trust, and autonomy. Partnering with Collaborative Support Programs of New Jersey (CSPNJ), a statewide PRO in the Northeastern United States, we used comicboarding, a co-design method, to conduct workshops with 16 peer specialists and 10 service users exploring perceptions of integrating an LLM-based recommendation system into peer support. Findings show that depending on how LLMs are introduced, constrained, and co-used, they can reconfigure in-room dynamics by sustaining, undermining, or amplifying the relational authority that grounds peer support. We identify opportunities, risks, and mitigation strategies across three tensions: bridging scale and locality, protecting trust and relational dynamics, and preserving peer autonomy amid efficiency gains. We contribute design implications that center lived-experience-in-the-loop, reframe trust as co-constructed, and position LLMs not as clinical tools but as relational collaborators in high-stakes, community-led care."
  },
  {
    "date": "2026-02-09",
    "title": "Information Geometry of Absorbing Markov-Chain and Discriminative Random Walks",
    "authors": "Masanari Kimura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08185v1",
    "source": "arXiv",
    "abstract": "Discriminative Random Walks (DRWs) are a simple yet powerful tool for semi-supervised node classification, but their theoretical foundations remain fragmentary. We revisit DRWs through the lens of information geometry, treating the family of class-specific hitting-time laws on an absorbing Markov chain as a statistical manifold. Starting from a log-linear edge-weight model, we derive closed-form expressions for the hitting-time probability mass function, its full moment hierarchy, and the observed Fisher information. The Fisher matrix of each seed node turns out to be rank-one, taking the quotient by its null space yields a low-dimensional, globally flat manifold that captures all identifiable directions of the model. Leveraging the geometry, we introduce a sensitivity score for unlabeled nodes that bounds, and in one-dimensional cases attains, the maximal first-order change in DRW betweenness under unit Fisher perturbations. The score can lead to principled strategies for active label acquisition, edge re-weighting, and explanation."
  },
  {
    "date": "2026-02-09",
    "title": "Boosting high-current alkaline water electrolysis and carbon dioxide reduction with novel CuNiFe-based anodes",
    "authors": "Nusrat Rashid, Shurui Yang, Galyam Sanfo, Isabelle Ewing, Zahra Ibrahim Albu, Xinjuan Li, Tianhao Wu, Prajna Bhatt, Mathieu Prevot, Laurent Piccolo, Mahmoud Zendehdel, Robert G. Palgrave, Caterina Ducati, Mojtaba Abdi-Jalebi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08183v1",
    "source": "arXiv",
    "abstract": "The transition to a green hydrogen economy demands robust, scalable, and sustainable anodes for alkaline water electrolysis operating at industrial current densities (>1 A/cm2). However, achieving high activity and long-term stability under such conditions remains a formidable challenge with conventional catalysts. Here, we report a novel trimetallic CuNiFe anode fabricated through a rapid, single-step electrodeposition process at room temperature without organic additives. The catalyst exhibits an exceptionally low overpotential of <270 mV at 100 mA cm(-2) and operates stably for over 500 hours at 1 A cm(-2) in 30 wt% KOH. In a practical anion exchange membrane water electrolyzer (AEM-WE), the CuNiFe anode enables a current density of 2.5 A cm(-2) at only 2.5 V, with a voltage efficiency of 66.8%. Beyond water splitting, this anode also significantly enhances CO2 electrolysis, tripling the CO2 reduction current density and steering selectivity toward valuable multi-carbon products when paired with commercial copper cathodes. A cradle-to-gate life cycle assessment confirms that the CuNiFe anode reduces the carbon footprint by an order of magnitude and decreases environmental impacts by 40-60% across multiple categories compared to benchmark IrRuO2. Our work establishes a scalable, high-performance, and environmentally benign anode technology, paving the way for cost-effective electrochemical production of green hydrogen and carbon-neutral chemicals."
  },
  {
    "date": "2026-02-09",
    "title": "Large deviations for some unbounded observables in dynamical systems",
    "authors": "Anselmo Pontes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08178v1",
    "source": "arXiv",
    "abstract": "In this paper we establish a large deviations type estimate for strongly mixing Markov chains with respect to the Lp norm. As applications we derive such estimates for the iterates of a locally constant random cocycle with mixed rank, as well as for unbounded observables of expanding maps."
  },
  {
    "date": "2026-02-09",
    "title": "Asymptotically Minimax Robust Likelihood Ratio Test",
    "authors": "Gökhan Gül",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08174v1",
    "source": "arXiv",
    "abstract": "This paper develops a unified framework for asymptotically minimax robust hypothesis testing under distributional uncertainty, applicable to both Bayesian and Neyman--Pearson formulations (Type-I and Type-II). Uncertainty classes based on the KL-divergence, $α$-divergence, and its symmetrized variant are considered. Using Sion's minimax theorem and Karush-Kuhn-Tucker conditions, the existence and uniqueness of the resulting robust tests are established. The least favorable distributions and corresponding robust likelihood ratio functions are derived in closed parametric forms, enabling computation via systems of nonlinear equations. It is proven that Dabak's approach does not yield an asymptotically minimax robust test. The proposed theory generalizes earlier work by offering a more systematic and comprehensive derivation of robust tests. Numerical simulations confirm the theoretical results and illustrate the behavior of the derived robust tests."
  },
  {
    "date": "2026-02-09",
    "title": "Learning from Literature: Integrating LLMs and Bayesian Hierarchical Modeling for Oncology Trial Design",
    "authors": "Guannan Gong, Satrajit Roychoudhury, Allison Meisner, Lajos Pusztai, Sarah B Goldberg, Wei Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08172v1",
    "source": "arXiv",
    "abstract": "Designing modern oncology trials requires synthesizing evidence from prior studies to inform hypothesis generation and sample size determination. Trial designs based on incomplete or imprecise summaries can lead to misspecified hypotheses and underpowered studies, resulting in false positive or negative conclusions. To address this challenge, we developed LEAD-ONC (Literature to Evidence for Analytics and Design in Oncology), an AI-assisted framework that transforms published clinical trial reports into quantitative, design-relevant evidence. Given expert-curated trial publications that meet prespecified eligibility criteria, LEAD-ONC uses large language models to extract baseline characteristics and reconstruct individual patient data from Kaplan-Meier curves, followed by Bayesian hierarchical modeling to generate predictive survival distributions for a prespecified target trial population. We demonstrate the framework using five phase III trials in first-line non-small-cell lung cancer evaluating PD-1 or PD-L1 inhibitors with or without CTLA-4 blockade. Clustering based on baseline characteristics identified three clinically interpretable populations defined by histology. For a prospective randomized trial in the mixed-histology population comparing mono versus dual immune checkpoint inhibition, LEAD-ONC projected a modest median overall survival difference of 2.8 months (95 percent credible interval -2.0 to 7.6) and an estimated probability of at least a 3-month benefit of approximately 0.45. As LEAD-ONC remains under active development, these results are intended as preliminary demonstrations of the frameworks potential to support evidence-driven oncology trial design rather than definitive clinical conclusions."
  },
  {
    "date": "2026-02-09",
    "title": "Spherical Steering: Geometry-Aware Activation Rotation for Language Models",
    "authors": "Zejia You, Chunyuan Deng, Hanjie Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08169v1",
    "source": "arXiv",
    "abstract": "Inference-time steering has emerged as a promising paradigm for controlling language models (LMs) without the cost of retraining. However, standard approaches typically rely on activation addition, a geometric operation that inevitably alters the magnitude of hidden representations. This raises concerns about representation collapse and degradation of open-ended generation capabilities. In this work, we explore Spherical Steering, a training-free primitive that resolves this trade-off through activation rotation. Rather than shifting activations with a fixed vector, our method rotates them along a geodesic toward a target direction, guiding the activation toward the target concept while preserving the integrity of the signal. To further enhance adaptivity, we incorporate a confidence gate that dynamically modulates steering strength based on input uncertainty. Extensive experiments across multiple-choice benchmarks demonstrate that Spherical Steering significantly outperforms addition-based baselines (notably by +10% on TruthfulQA, COPA, and Storycloze), while simultaneously maintaining the model's general open-ended generation quality. This work highlights the value of geometric consistency, suggesting that norm-preserving rotation is a robust and effective primitive for precise inference-time control."
  },
  {
    "date": "2026-02-09",
    "title": "Hints of sign-changing scalar field energy density and a transient acceleration phase at $z\\sim 2$ from model-agnostic reconstructions",
    "authors": "Özgür Akarsu, Maria Caruana, Konstantinos F. Dialektopoulos, Luis A. Escamilla, Emre O. Kahya, Jackson Levi Said",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08928v1",
    "source": "arXiv",
    "abstract": "We present a data-driven reconstruction of the late-time expansion history and its implications for dark-energy dynamics. Modeling the reduced Hubble rate with a node-based Gaussian-process-kernel interpolant, we constrain the reconstruction using CC, Pantheon+ SNIa, BAO data from SDSS and DESI, transversal BAO data, and external $H_0$ priors (SH0ES and H0DN). Assuming GR at the background level, we map the reconstructed kinematics onto a dark-energy fluid and a scalar-field description, yielding the total potential and kinetic contributions that reproduce the inferred $H(z)$. To interpret the reconstruction, we consider both a minimal single-field model (canonical or phantom) and a two-field (quintom) system consisting of one canonical and one phantom scalar field (or families). Within the GR-based effective-fluid mapping, the inferred dark-energy density changes sign for all dataset combinations explored, transitioning from $ρ_{\\rm DE}<0$ at higher redshift to $ρ_{\\rm DE}>0$ toward the present, and defining a transition redshift $z_\\dagger$ by $ρ_{\\rm DE}(z_\\dagger)=0$. A single canonical scalar cannot realize such a smooth evolution during expansion, whereas a phantom field or a two-field quintom framework can accommodate the required behavior; in particular, the two-field system permits smooth phantom-divide crossings at finite $ρ_{\\rm DE}>0$ and distinguishes them from the separate notion of a density zero crossing. The reconstructed kinematics admit intermediate-redshift structure in some combinations, including hints of an additional accelerated-expansion interval around $z\\sim 1.7$--$2.3$. The present-day equation of state remains close to a cosmological constant: combinations including supernovae give $w_0\\simeq -1$, while combinations without supernovae but with an external $H_0$ prior show only a mild preference for $w_0<-1$ at the $\\sim1.5$--$1.7σ$ level."
  },
  {
    "date": "2026-02-09",
    "title": "Informative Object-centric Next Best View for Object-aware 3D Gaussian Splatting in Cluttered Scenes",
    "authors": "Seunghoon Jeong, Eunho Lee, Jeongyun Kim, Ayoung Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08266v1",
    "source": "arXiv",
    "abstract": "In cluttered scenes with inevitable occlusions and incomplete observations, selecting informative viewpoints is essential for building a reliable representation. In this context, 3D Gaussian Splatting (3DGS) offers a distinct advantage, as it can explicitly guide the selection of subsequent viewpoints and then refine the representation with new observations. However, existing approaches rely solely on geometric cues, neglect manipulation-relevant semantics, and tend to prioritize exploitation over exploration. To tackle these limitations, we introduce an instance-aware Next Best View (NBV) policy that prioritizes underexplored regions by leveraging object features. Specifically, our object-aware 3DGS distills instancelevel information into one-hot object vectors, which are used to compute confidence-weighted information gain that guides the identification of regions associated with erroneous and uncertain Gaussians. Furthermore, our method can be easily adapted to an object-centric NBV, which focuses view selection on a target object, thereby improving reconstruction robustness to object placement. Experiments demonstrate that our NBV policy reduces depth error by up to 77.14% on the synthetic dataset and 34.10% on the real-world GraspNet dataset compared to baselines. Moreover, compared to targeting the entire scene, performing NBV on a specific object yields an additional reduction of 25.60% in depth error for that object. We further validate the effectiveness of our approach through real-world robotic manipulation tasks."
  },
  {
    "date": "2026-02-09",
    "title": "Emergent altermagnetism at surfaces of antiferromagnets: full symmetry classification and material identification",
    "authors": "Colin Lange, Rodrigo Jaeschke-Ubiergo, Atasi Chakraborty, Xanthe H. Verbeek, Libor Šmejkal, Jairo Sinova, Alexander Mook",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08773v1",
    "source": "arXiv",
    "abstract": "We demonstrate the emergence of altermagnetism at the surfaces of antiferromagnets, vastly expanding the number of material candidates with altermagnetic characteristics and establishing a route to two-dimensional altermagnetism through surface-induced symmetry breaking. We do so by developing a surface spin group formalism that fully classifies all surface magnetic states and identifies altermagnetic surface spin groups that can arise at the surfaces of antiferromagnets. We use this formalism to identify over 140 antiferromagnetic entries from the MAGNDATA database with at least one altermagnetic surface, often times with multiple such surfaces in the same material. We illustrate this emergent phenomenon in a realistic Lieb lattice-based minimal model and present ab initio calculations on two representative material candidates, NaMnP and FeGe$_2$, exhibiting $d$-wave and $g$-wave surface altermagnetism, respectively. Our theory naturally resolves the contradiction of recent experimental reports of $d$-wave ARPES measurements on metallic Lieb lattice compounds that have been shown to be antiferromagnetic in the bulk. Hence, we establish a new paradigm for generating two-dimensional altermagnetism by functionalizing the abundant material class of collinear antiferromagnets as viable platforms for controlled surface altermagnetism, creating natural materials for future hybrid device implementation."
  },
  {
    "date": "2026-02-09",
    "title": "Modeling Protein Evolution via Generative Inference From Monte Carlo Chains to Population Genetics",
    "authors": "Leonardo Di Bari, Thierry Mora, Andrea Pagnani, Aleksandra M. Walczak, Francesco Zamponi, Saverio Rossi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08641v1",
    "source": "arXiv",
    "abstract": "Generative models derived from large protein sequence alignments define complex fitness landscapes, but their utility for accurately modeling non-equilibrium evolutionary dynamics remains unclear. In this work, we perform a rigorous comparative analysis of three simulation schemes, designed to mimic evolution in silico by local sampling of the probability distribution defined by a generative model. We compare standard independent Markov Chain Monte Carlo, Monte Carlo on a phylogenetic tree, and a population genetics dynamics, benchmarking their outputs against deep sequencing data from four distinct in vitro evolution experiments. We find that standard Monte Carlo fails to reproduce the correct phylogenetic structure and generates unrealistic, gradual mutational sweeps. Performing Monte Carlo on a tree inferred from data improves phylogenetic fidelity and historical accuracy. The population genetics scheme successfully captures phylogenetic correlations, mutational abundances, and selective sweeps as emergent properties, without the need to infer additional information from data. However, the latter choice come at the price of not sampling the proper generative model distribution at long times. Our findings highlight the crucial role of phylogenetic correlations and finite-population effects in shaping evolutionary trajectories on fitness landscapes. These models therefore provide powerful tools for predicting complex adaptive paths and for reliably extrapolating evolutionary dynamics beyond current experimental limitations."
  },
  {
    "date": "2026-02-09",
    "title": "Phase behavior and electrical transport in DBTTF-HATCN donor-acceptor mixtures",
    "authors": "Andreas Opitz, Hongwon Kim, Dmitry Lapkin, Gianfranco Melis, Ainur Abukaev, Marie Siegert, Lennart Frohloff, Lisa Schraut-May, Oleg Konovalov, Alexander Hinderhofer, Frank Schreiber, Jens Pflaum, Wolfgang Brütting",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08627v1",
    "source": "arXiv",
    "abstract": "The formation of donor-acceptor complexes (DACs) between the electron donor Dibenzotetrathiafulvalene (DBTTF) and the acceptor Hexaaza\\-triphenylene\\-hexacarbo\\-nitrile (HATCN) results in a new phase with a distinctly different crystal structure as well as new optical absorption bands below the energy gaps of the two pristine materials. X-ray scattering and atomic force microscopy provide detailed insights into the film structure and morphology by systematic variation of the mixing ratio from pristine DBTTF to pristine HATCN. The measured electrical conductivity of thin films depends in a highly non-monotonic manner on the composition of the mixture and shows significantly improved charge transport compared to the pristine films. The temperature-dependent conductivity, charge carrier concentration, and mobility were investigated across these compositions. Surprisingly, all compositions exhibited n-type behavior, except for pristine DBTTF. This behavior is explained by the electronic structure of the mixtures, as revealed by ultraviolet photoelectron spectroscopy, which indicates that charge injection and transport occur via the lowest unoccupied molecular orbital of the DAC and HATCN. Additionally, the observed electrical conductivity is strongly influenced by morphology and structural ordering of the films. These findings offer valuable insights for the design of advanced materials with enhanced electrical performance."
  },
  {
    "date": "2026-02-09",
    "title": "An Approach for the Qualitative Graphical Representation of the Describing Function in Nonlinear Systems Stability Analysis",
    "authors": "Davide Tebaldi, Roberto Zanasi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08435v1",
    "source": "arXiv",
    "abstract": "The describing function method is a useful tool for the qualitative analysis of limit cycles in the stability analysis of nonlinear systems. This method is inherently approximate; therefore, it should be used for a fast qualitative analysis of the considered systems. However, plotting the exact describing function requires heavy mathematical calculations, reducing interest in this method especially from the point of view of control education. The objective of this paper is to enhance the describing function method by providing a new approach for the qualitative plotting of the describing function for piecewise nonlinearities involving discontinuities. Unlike the standard method, the proposed approach allows for a straightforward, hand-drawn plotting of the describing function using the rules introduced in this paper, simply by analyzing the shape of the nonlinearity. The proposed case studies show that the limit cycles estimation performed using the standard exact plotting of the describing function yields the same qualitative results as those obtained using the proposed qualitative method for plotting the describing function."
  },
  {
    "date": "2026-02-09",
    "title": "Derivation and analysis of a Stokes-transport system in evolving vessels modeling thermoregulation in human skin",
    "authors": "Kilian Hacker, Maria Neuss-Radu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08788v1",
    "source": "arXiv",
    "abstract": "We consider a Stokes flow coupled with advective-diffusive transport in an evolving domain with boundary conditions allowing for inflow and outflow. The evolution of the domain is induced by the transport process, leading to a fully coupled problem. Our aim is to model the thermal control of blood flow in human skin. To this end, the model takes into account the temperature-dependent production of biochemical substances, the subsequent dilation and constriction of blood vessels, and the resulting changes in convective heat transfer. We prove existence and uniqueness of weak solutions using a fixed point method that allows us to treat the nonlinear coupling."
  },
  {
    "date": "2026-02-09",
    "title": "A Graphop Analysis of Graph Neural Networks on Sparse Graphs: Generalization and Universal Approximation",
    "authors": "Ofek Amran, Tom Gilat, Ron Levie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08785v1",
    "source": "arXiv",
    "abstract": "Generalization and approximation capabilities of message passing graph neural networks (MPNNs) are often studied by defining a compact metric on a space of input graphs under which MPNNs are Hölder continuous. Such analyses are of two varieties: 1) when the metric space includes graphs of unbounded sizes, the theory is only appropriate for dense graphs, and, 2) when studying sparse graphs, the metric space only includes graphs of uniformly bounded size. In this work, we present a unified approach, defining a compact metric on the space of graphs of all sizes, both sparse and dense, under which MPNNs are Hölder continuous. This leads to more powerful universal approximation theorems and generalization bounds than previous works. The theory is based on, and extends, a recent approach to graph limit theory called graphop analysis."
  },
  {
    "date": "2026-02-09",
    "title": "Topological properties of spin block magnetic ladders in proximity of a superconductor: application to BaFe$_{2}$S$_{3}$",
    "authors": "Shivam Yadav, Pascal Simon, Andrzej Ptok",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08771v1",
    "source": "arXiv",
    "abstract": "Monoatomic chains with magnetic order in proximity of a s-wave superconductor can host Majorana edge modes. In this paper, we extend this idea to more complex spin-block chains such as the BaFe$_{2}$S$_{3}$ magnetic material that has a spin-ladder like structure. We investigate the topological phase diagram of such a system as function of the system parameters. We show that the coupling between chains within the ladder leads to the topological phase with a winding number larger than the sum of two single magnetic chains. Furthermore, strong coupling between chains leads to fractal-like substructure in the topological phase diagram. By investigating the real space properties of such a system and particularly its edge modes, we find that the system spectrum contains several in-gap states that we analyze in detail."
  },
  {
    "date": "2026-02-09",
    "title": "FreqLens: Interpretable Frequency Attribution for Time Series Forecasting",
    "authors": "Chi-Sheng Chen, Xinyu Zhang, En-Jui Kuo, Guan-Ying Chen, Qiuzhe Xie, Fan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08768v1",
    "source": "arXiv",
    "abstract": "Time series forecasting models often lack interpretability, limiting their adoption in domains requiring explainable predictions. We propose \\textsc{FreqLens}, an interpretable forecasting framework that discovers and attributes predictions to learnable frequency components. \\textsc{FreqLens} introduces two key innovations: (1) \\emph{learnable frequency discovery} -- frequency bases are parameterized via sigmoid mapping and learned from data with diversity regularization, enabling automatic discovery of dominant periodic patterns without domain knowledge; and (2) \\emph{axiomatic frequency attribution} -- a theoretically grounded framework that provably satisfies Completeness, Faithfulness, Null-Frequency, and Symmetry axioms, with per-frequency attributions equivalent to Shapley values. On Traffic and Weather datasets, \\textsc{FreqLens} achieves competitive or superior performance while discovering physically meaningful frequencies: all 5 independent runs discover the 24-hour daily cycle ($24.6 \\pm 0.1$h, 2.5\\% error) and 12-hour half-daily cycle ($11.8 \\pm 0.1$h, 1.6\\% error) on Traffic, and weekly cycles ($10\\times$ longer than the input window) on Weather. These results demonstrate genuine frequency-level knowledge discovery with formal theoretical guarantees on attribution quality."
  },
  {
    "date": "2026-02-09",
    "title": "HoGS: Homophily-Oriented Graph Synthesis for Local Differentially Private GNN Training",
    "authors": "Wen Xu, Zhetao Li, Yong Xiao, Pengpeng Qiao, Mianxiong Dong, Kaoru Ota",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08762v1",
    "source": "arXiv",
    "abstract": "Graph neural networks (GNNs) have demonstrated remarkable performance in various graph-based machine learning tasks by effectively modeling high-order interactions between nodes. However, training GNNs without protection may leak sensitive personal information in graph data, including links and node features. Local differential privacy (LDP) is an advanced technique for protecting data privacy in decentralized networks. Unfortunately, existing local differentially private GNNs either only preserve link privacy or suffer significant utility loss in the process of preserving link and node feature privacy. In this paper, we propose an effective LDP framework, called HoGS, which trains GNNs with link and feature protection by generating a synthetic graph. Concretely, HoGS first collects the link and feature information of the graph under LDP, and then utilizes the phenomenon of homophily in graph data to reconstruct the graph structure and node features separately, thereby effectively mitigating the negative impact of LDP on the downstream GNN training. We theoretically analyze the privacy guarantee of HoGS and conduct experiments using the generated synthetic graph as input to various state-of-the-art GNN architectures. Experimental results on three real-world datasets show that HoGS significantly outperforms baseline methods in the accuracy of training GNNs."
  },
  {
    "date": "2026-02-09",
    "title": "Homomorphism counting for immersion-closed classes is not isomorphism",
    "authors": "Andrea Jiménez, Benjamin Moore, Daniel A. Quiroz, Youngho Yoo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08738v1",
    "source": "arXiv",
    "abstract": "Lovász proved that two graphs $G$ and $H$ are isomorphic if $\\hom(K,G) = \\hom(K,H)$ for all graphs $K$, where $\\hom(G_1,G_2)$ denotes the number of homomorphisms from $G_1$ to $G_2$. Dvořák showed that it suffices to count homomorphisms from all $2$-degenerate graphs $K$. On the other hand, for several interesting graph classes $\\mathcal{M}$, it has been shown that there exist non-isomorphic graphs $G$ and $H$ such that $\\hom(K,G)=\\hom(K,H)$ for all $K\\in \\mathcal{M}$. Most such classes are minor-closed classes and Roberson conjectured that every proper minor-closed and union-closed graph class $\\mathcal{M}$ has the property of there existing non-isomorphic graphs that are indistinguishable by homomorphism counts from $\\mathcal{M}$. There has been an effort to prove Roberson's conjecture as it is believed that minor-closed classes play a special role in the context of homomorphism indistinguishability. We show that this special role, if so, must be shared, by proving an analogue of Roberson's conjecture holds for a rich family of non-minor-closed classes. Namely, we prove that for any proper immersion-closed and union-closed class $\\mathcal{M}$, there exist non-isomorphic graphs $G$ and $H$ such that $\\hom(K,G) = \\hom(K,H)$ for all $K \\in \\mathcal{M}$. This extends a result of Roberson on homomorphism indistinguishability over bounded degree graphs, and gives an almost full picture since our result cannot be extended in the natural way, that is, by replacing immersions with topological minors, due to a result of Neuen and Seppelt."
  },
  {
    "date": "2026-02-09",
    "title": "Foundation Inference Models for Ordinary Differential Equations",
    "authors": "Maximilian Mauel, Johannes R. Hübers, David Berghaus, Patrick Seifner, Ramses J. Sanchez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08733v1",
    "source": "arXiv",
    "abstract": "Ordinary differential equations (ODEs) are central to scientific modelling, but inferring their vector fields from noisy trajectories remains challenging. Current approaches such as symbolic regression, Gaussian process (GP) regression, and Neural ODEs often require complex training pipelines and substantial machine learning expertise, or they depend strongly on system-specific prior knowledge. We propose FIM-ODE, a pretrained Foundation Inference Model that amortises low-dimensional ODE inference by predicting the vector field directly from noisy trajectory data in a single forward pass. We pretrain FIM-ODE on a prior distribution over ODEs with low-degree polynomial vector fields and represent the target field with neural operators. FIM-ODE achieves strong zero-shot performance, matching and often improving upon ODEFormer, a recent pretrained symbolic baseline, across a range of regimes despite using a simpler pretraining prior distribution. Pretraining also provides a strong initialisation for finetuning, enabling fast and stable adaptation that outperforms modern neural and GP baselines without requiring machine learning expertise."
  },
  {
    "date": "2026-02-09",
    "title": "Synchrotron Self-Compton Process for Constraining sub-GeV Dark Matter in Omega Centauri via SKA",
    "authors": "Guan-Sen Wang, Bing-Yu Su, Yang Yu, Bo Zhang, Lei Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08731v1",
    "source": "arXiv",
    "abstract": "The search for the particle identity of dark matter (DM) continues to be a primary objective in modern physics. In this field, the sub-GeV mass range of DM detection remains a crucial yet challenging window. We investigate synchrotron self-Compton (SSC) emission from electrons and positrons produced by MeV-scale DM annihilation as a novel indirect detection channel. Focusing on the globular cluster Omega Centauri and the sensitivity of the Square Kilometre Array, we derive constraints on the annihilation cross section reaching $\\langleσv\\rangle \\sim 10^{-30}\\,\\rm{cm}^{3}\\,\\rm{s}^{-1}$ in the tens-of-MeV range. Furthermore, constraints could even reach below $\\langleσv\\rangle \\sim 10^{-32}\\,\\rm{cm}^{3}\\,\\rm{s}^{-1}$ for extreme parameter choices. Remarkably, even under deliberately conservative astrophysical assumptions, this channel outperforms existing indirect limits, establishing SSC emission as a robust probe of sub-GeV DM."
  },
  {
    "date": "2026-02-09",
    "title": "Closing the Confusion Loop: CLIP-Guided Alignment for Source-Free Domain Adaptation",
    "authors": "Shanshan Wang, Ziying Feng, Xiaozheng Shen, Xun Yang, Pichao Wang, Zhenwei He, Xingyi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08730v1",
    "source": "arXiv",
    "abstract": "Source-Free Domain Adaptation (SFDA) tackles the problem of adapting a pre-trained source model to an unlabeled target domain without accessing any source data, which is quite suitable for the field of data security. Although recent advances have shown that pseudo-labeling strategies can be effective, they often fail in fine-grained scenarios due to subtle inter-class similarities. A critical but underexplored issue is the presence of asymmetric and dynamic class confusion, where visually similar classes are unequally and inconsistently misclassified by the source model. Existing methods typically ignore such confusion patterns, leading to noisy pseudo-labels and poor target discrimination. To address this, we propose CLIP-Guided Alignment(CGA), a novel framework that explicitly models and mitigates class confusion in SFDA. Generally, our method consists of three parts: (1) MCA: detects first directional confusion pairs by analyzing the predictions of the source model in the target domain; (2) MCC: leverages CLIP to construct confusion-aware textual prompts (e.g. a truck that looks like a bus), enabling more context-sensitive pseudo-labeling; and (3) FAM: builds confusion-guided feature banks for both CLIP and the source model and aligns them using contrastive learning to reduce ambiguity in the representation space. Extensive experiments on various datasets demonstrate that CGA consistently outperforms state-of-the-art SFDA methods, with especially notable gains in confusion-prone and fine-grained scenarios. Our results highlight the importance of explicitly modeling inter-class confusion for effective source-free adaptation. Our code can be find at https://github.com/soloiro/CGA"
  },
  {
    "date": "2026-02-09",
    "title": "Trellis codes with a good distance profile constructed from expander graphs",
    "authors": "Yubin Zhu, Zitan Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08718v1",
    "source": "arXiv",
    "abstract": "We derive Singleton-type bounds on the free distance and column distances of trellis codes. Our results show that, at a given time instant, the maximum attainable column distance of trellis codes can exceed that of convolutional codes. Moreover, using expander graphs, we construct trellis codes over constant-size alphabets that achieve a rate-distance trade-off arbitrarily close to that of convolutional codes with a maximum distance profile. By comparison, all known constructions of convolutional codes with a maximum distance profile require working over alphabets whose size grows at least exponentially with the number of output symbols per time instant."
  },
  {
    "date": "2026-02-09",
    "title": "Zero-shot System for Automatic Body Region Detection for Volumetric CT and MR Images",
    "authors": "Farnaz Khun Jush, Grit Werner, Mark Klemens, Matthias Lenga",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08717v1",
    "source": "arXiv",
    "abstract": "Reliable identification of anatomical body regions is a prerequisite for many automated medical imaging workflows, yet existing solutions remain heavily dependent on unreliable DICOM metadata. Current solutions mainly use supervised learning, which limits their applicability in many real-world scenarios. In this work, we investigate whether body region detection in volumetric CT and MR images can be achieved in a fully zero-shot manner by using knowledge embedded in large pre-trained foundation models. We propose and systematically evaluate three training-free pipelines: (1) a segmentation-driven rule-based system leveraging pre-trained multi-organ segmentation models, (2) a Multimodal Large Language Model (MLLM) guided by radiologist-defined rules, and (3) a segmentation-aware MLLM that combines visual input with explicit anatomical evidence. All methods are evaluated on 887 heterogeneous CT and MR scans with manually verified anatomical region labels. The segmentation-driven rule-based approach achieves the strongest and most consistent performance, with weighted F1-scores of 0.947 (CT) and 0.914 (MR), demonstrating robustness across modalities and atypical scan coverage. The MLLM performs competitively in visually distinctive regions, while the segmentation-aware MLLM reveals fundamental limitations."
  },
  {
    "date": "2026-02-09",
    "title": "Exploring SAIG Methods for an Objective Evaluation of XAI",
    "authors": "Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Anna Arias-Duart",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08715v1",
    "source": "arXiv",
    "abstract": "The evaluation of eXplainable Artificial Intelligence (XAI) methods is a rapidly growing field, characterized by a wide variety of approaches. This diversity highlights the complexity of the XAI evaluation, which, unlike traditional AI assessment, lacks a universally correct ground truth for the explanation, making objective evaluation challenging. One promising direction to address this issue involves the use of what we term Synthetic Artificial Intelligence Ground truth (SAIG) methods, which generate artificial ground truths to enable the direct evaluation of XAI techniques. This paper presents the first review and analysis of SAIG methods. We introduce a novel taxonomy to classify these approaches, identifying seven key features that distinguish different SAIG methods. Our comparative study reveals a concerning lack of consensus on the most effective XAI evaluation techniques, underscoring the need for further research and standardization in this area."
  },
  {
    "date": "2026-02-09",
    "title": "Is plasmoid-mediated reconnection really important in accretion flows to drive flares in AGNs?",
    "authors": "Giovani H. Vicentin, Elisabete M. de Gouveia Dal Pino, George N. Wong, Lia Medeiros, Grzegorz Kowal, James M. Stone, Alex Lazarian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08710v1",
    "source": "arXiv",
    "abstract": "Based on very high-resolution resistive 2D and 3D magnetohydrodynamical (MHD) simulations of current sheets, our findings suggest that the answer to this question is likely no. In contrast, turbulence-mediated reconnection yields significantly faster reconnection rates - about an order of magnitude higher than the so-called universal rate for plasmoid-mediated reconnection in MHD flows ($V_\\text{rec}/V_A \\sim 0.01$). We conclude that turbulence-driven reconnection is the dominant mechanism responsible for fast reconnection and flares in systems such as accretion flows and relativistic jets in Active Galactic Nuclei (AGNs). In these environments, turbulence is driven by instabilities such as the magneto-rotational instability (MRI), Parker-Rayleigh-Taylor instability (PRTI), and current-driven kink instability (CDKI). Finally, we present 3D General Relativistic MHD simulations of accretion flows that confirm the crucial role of turbulence-mediated reconnection in AGN systems. These findings have important implications for understanding the origin of flares, particle acceleration, and the production of polarized radiation in these extreme environments."
  },
  {
    "date": "2026-02-09",
    "title": "Do Images Clarify? A Study on the Effect of Images on Clarifying Questions in Conversational Search",
    "authors": "Clemencia Siro, Zahra Abbasiantaeb, Yifei Yuan, Mohammad Aliannejadi, Maarten de Rijke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08700v1",
    "source": "arXiv",
    "abstract": "Conversational search systems increasingly employ clarifying questions to refine user queries and improve the search experience. Previous studies have demonstrated the usefulness of text-based clarifying questions in enhancing both retrieval performance and user experience. While images have been shown to improve retrieval performance in various contexts, their impact on user performance when incorporated into clarifying questions remains largely unexplored. We conduct a user study with 73 participants to investigate the role of images in conversational search, specifically examining their effects on two search-related tasks: (i) answering clarifying questions and (ii) query reformulation. We compare the effect of multimodal and text-only clarifying questions in both tasks within a conversational search context from various perspectives. Our findings reveal that while participants showed a strong preference for multimodal questions when answering clarifying questions, preferences were more balanced in the query reformulation task. The impact of images varied with both task type and user expertise. In answering clarifying questions, images helped maintain engagement across different expertise levels, while in query reformulation they led to more precise queries and improved retrieval performance. Interestingly, for clarifying question answering, text-only setups demonstrated better user performance as they provided more comprehensive textual information in the absence of images. These results provide valuable insights for designing effective multimodal conversational search systems, highlighting that the benefits of visual augmentation are task-dependent and should be strategically implemented based on the specific search context and user characteristics."
  },
  {
    "date": "2026-02-09",
    "title": "Challenges in Translating Technical Lectures: Insights from the NPTEL",
    "authors": "Basudha Raje, Sadanand Venkatraman, Nandana TP, Soumyadeepa Das, Polkam Poojitha, M. Vijaykumar, Tanima Bagchi, Hema A. Murthy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08698v1",
    "source": "arXiv",
    "abstract": "This study examines the practical applications and methodological implications of Machine Translation in Indian Languages, specifically Bangla, Malayalam, and Telugu, within emerging translation workflows and in relation to existing evaluation frameworks. The choice of languages prioritized in this study is motivated by a triangulation of linguistic diversity, which illustrates the significance of multilingual accommodation of educational technology under NEP 2020. This is further supported by the largest MOOC portal, i.e., NPTEL, which has served as a corpus to facilitate the arguments presented in this paper. The curation of a spontaneous speech corpora that accounts for lucid delivery of technical concepts, considering the retention of suitable register and lexical choices are crucial in a diverse country like India. The findings of this study highlight metric-specific sensitivity and the challenges of morphologically rich and semantically compact features when tested against surface overlapping metrics."
  },
  {
    "date": "2026-02-09",
    "title": "On the vortex transport and blade interactions in a reversible pump-turbine",
    "authors": "Chirag Trivedi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08687v1",
    "source": "arXiv",
    "abstract": "Pumped storage type hydropower plants play an important role in mitigating real-time energy flexibility. Reversible pump-turbines undergo extreme operating conditions such as runaway and speed-no-load. Very limited studies are undertaken to understand the stochastic flow under these conditions in the reversible pump-turbine. The present study investigates the unsteady vortical flow, its transportation, and interaction with the blades at speed-no-load. Large eddy simulations are conducted in both turbine and pump modes. The computational domain contains 120 million nodes. Numerical results provided evidence of a large longitudinal vortex that develops on the high-pressure side of the blade, and transports into the blade passage and develops the unsteady \"string of swirls\". The results also showed another \"string of swirls\" in the draft tube, where flow in the center is reversible (pumping). The resulting flow instability is very high, and it has the potential to induce fatigue damage to the blades."
  },
  {
    "date": "2026-02-09",
    "title": "Chiral phase memory of twisted light through multiple scattering",
    "authors": "Igor Meglinski, Anton Sdobnov, Alexander Bykov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08677v1",
    "source": "arXiv",
    "abstract": "Chiroptical signals, optical responses sensitive to molecular handedness, are rapidly suppressed by multiple scattering, fundamentally limiting their use in turbid media. Here we show that coupling molecular chirality to the topological structure of twisted light generates a protected phase observable that survives strong scattering. When Laguerre-Gaussian beams carrying orbital angular momentum propagate through chiral media, spin-orbit interaction converts circular birefringence into an azimuthal rotation of the helical wavefront. Remarkably, this chiral phase memory persists at scattering strengths that fully depolarize conventional beams, with the rotation magnitude preserved quantitatively between transparent solutions and strongly scattering tissue. The sign of the azimuthal rotation encodes molecular handedness: opposite enantiomers produce mirror-symmetric phase maps even after multiple scattering. Differential measurements between conjugate topological charges isolate the chiral contribution while cancelling achiral background, enabling the resolution of refractive-index changes of order 10-6. These results establish topological phase observables as robust carriers of weak chiral light-matter interactions in complex media, opening new routes for chiroptical spectroscopy and sensing beyond the ballistic-photon regime."
  },
  {
    "date": "2026-02-09",
    "title": "Frustrated spin models on two- and three-dimensional decorated lattices with high residual entropy",
    "authors": "D. V. Dmitriev, V. Ya. Krivnov, O. A. Vasilyev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08674v1",
    "source": "arXiv",
    "abstract": "We study the ground-state properties of a family of frustrated spin-1/2 Heisenberg models on two- and three-dimensional decorated lattices composed of connected star-shaped units. Each star is built from edge-sharing triangles with an antiferromagnetic interaction on the shared side and ferromagnetic interactions on the others. At a critical coupling ratio, the ideal star model - defined by equal ferromagnetic interactions - exhibits a macroscopically degenerate ground state, which we map onto a site percolation problem on the Lieb lattice. This mapping enables the calculation of exponential ground-state degeneracy and the corresponding residual entropy for square, triangular, honeycomb, and cubic lattices. Remarkably, the residual entropy remains high for all studied lattices, exceeding 60\\% of the maximal value ln(2). Despite a gapless quadratic one-magnon spectrum, the low-temperature thermodynamics is governed by exponentially numerous gapped excitations. For a distorted-star variant of the model, the ground-state manifold is equivalent to that of decoupled ferromagnetic clusters, leading to exponential degeneracy with a lower, yet still substantial, residual entropy. At low temperature the system mimics a paramagnetic crystal of non-interacting spins with high spin value ($s=4$ for a square lattice). The obtained results establish a structural design principle for engineering quantum magnets with a high ground-state degeneracy, suggesting promising candidates for enhanced magnetocaloric cooling and quantum thermal machines."
  },
  {
    "date": "2026-02-09",
    "title": "A Machine Learning accelerated geophysical fluid solver",
    "authors": "Yang Bai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08670v1",
    "source": "arXiv",
    "abstract": "Machine learning methods have been successful in many areas, like image classification and natural language processing. However, it still needs to be determined how to apply ML to areas with mathematical constraints, like solving PDEs. Among various approaches to applying ML techniques to solving PDEs, the data-driven discretization method presents a promising way of accelerating and improving existing PDE solver on structured grids where it predicts the coefficients of quasi-linear stencils for computing values or derivatives of a function at given positions. It can improve the accuracy and stability of low-resolution simulation compared with using traditional finite difference or finite volume schemes. Meanwhile, it can also benefit from traditional numerical schemes like achieving conservation law by adapting finite volume type formulations. In this thesis, we have implemented the shallow water equation and Euler equation classic solver under a different framework. Experiments show that our classic solver performs much better than the Pyclaw solver. Then we propose four different deep neural networks for the ML-based solver. The results indicate that two of these approaches could output satisfactory solutions."
  },
  {
    "date": "2026-02-09",
    "title": "Retrieval Pivot Attacks in Hybrid RAG: Measuring and Mitigating Amplified Leakage from Vector Seeds to Graph Expansion",
    "authors": "Scott Thornton",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08668v1",
    "source": "arXiv",
    "abstract": "Hybrid Retrieval-Augmented Generation (RAG) pipelines combine vector similarity search with knowledge graph expansion for multi-hop reasoning. We show that this composition introduces a distinct security failure mode: a vector-retrieved \"seed\" chunk can pivot via entity links into sensitive graph neighborhoods, causing cross-tenant data leakage that does not occur in vector-only retrieval. We formalize this risk as Retrieval Pivot Risk (RPR) and introduce companion metrics Leakage@k, Amplification Factor, and Pivot Depth (PD) to quantify leakage magnitude and traversal structure. We present seven Retrieval Pivot Attacks that exploit the vector-to-graph boundary and show that adversarial injection is not required: naturally shared entities create cross-tenant pivot paths organically. Across a synthetic multi-tenant enterprise corpus and the Enron email corpus, the undefended hybrid pipeline exhibits high pivot risk (RPR up to 0.95) with multiple unauthorized items returned per query. Leakage consistently appears at PD=2, which we attribute to the bipartite chunk-entity topology and formalize as a proposition. We then show that enforcing authorization at a single location, the graph expansion boundary, eliminates measured leakage (RPR near 0) across both corpora, all attack variants, and label forgery rates up to 10 percent, with minimal overhead. Our results indicate the root cause is boundary enforcement, not inherently complex defenses: two individually secure retrieval components can compose into an insecure system unless authorization is re-checked at the transition point."
  },
  {
    "date": "2026-02-09",
    "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models",
    "authors": "Mingzi Cao, Xingwei Tan, Mahmud Akhter, Marco Valentino, Maria Liakata, Xi Wang, Nikolaos Aletras",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08658v1",
    "source": "arXiv",
    "abstract": "Deduction, induction, and abduction are fundamental reasoning paradigms, core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning, and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts. We comprehensively evaluate induced models on realistic out-of-domain tasks, that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to $14.60$) across realistic tasks."
  },
  {
    "date": "2026-02-09",
    "title": "High-Speed Vision-Based Flight in Clutter with Safety-Shielded Reinforcement Learning",
    "authors": "Jiarui Zhang, Chengyong Lei, Chengjiang Dai, Lijie Wang, Zhichao Han, Fei Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08653v1",
    "source": "arXiv",
    "abstract": "Quadrotor unmanned aerial vehicles (UAVs) are increasingly deployed in complex missions that demand reliable autonomous navigation and robust obstacle avoidance. However, traditional modular pipelines often incur cumulative latency, whereas purely reinforcement learning (RL) approaches typically provide limited formal safety guarantees. To bridge this gap, we propose an end-to-end RL framework augmented with model-based safety mechanisms. We incorporate physical priors in both training and deployment. During training, we design a physics-informed reward structure that provides global navigational guidance. During deployment, we integrate a real-time safety filter that projects the policy outputs onto a provably safe set to enforce strict collision-avoidance constraints. This hybrid architecture reconciles high-speed flight with robust safety assurances. Benchmark evaluations demonstrate that our method outperforms both traditional planners and recent end-to-end obstacle avoidance approaches based on differentiable physics. Extensive experiments demonstrate strong generalization, enabling reliable high-speed navigation in dense clutter and challenging outdoor forest environments at velocities up to 7.5m/s."
  },
  {
    "date": "2026-02-09",
    "title": "Four-dimensional pp-wave Lie groups and harmonic curvature",
    "authors": "Eduardo García-Río, Rosalía Rodríguez-Gigirey, Ramón Vázquez-Lorenzo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08650v1",
    "source": "arXiv",
    "abstract": "We determine all four-dimensional Lie groups which have harmonic curvature. As a consequence, a description of four-dimensional pp-wave Lie groups is obtained."
  },
  {
    "date": "2026-02-09",
    "title": "Comparison of Structure Preserving Schemes for the Cahn-Hilliard-Navier-Stokes Equations with Degenerate Mobility and Adaptive Mesh Refinement",
    "authors": "Jimmy Kornelije Gunnarsson, Robert Klöfkorn",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08639v1",
    "source": "arXiv",
    "abstract": "The Cahn-Hilliard-Navier-Stokes (CHNS) system utilizes a diffusive phase-field for interface tracking of multi-phase fluid flows. Recently structure preserving methods for CHNS have moved into focus to construct numerical schemes that, for example, are mass conservative or obey initial bounds of the phase-field variable. In this work decoupled implicit-explicit formulations based on the Discontinuous Galerkin (DG) methodology are considered and compared to existing schemes from the literature. For the fluid flow a standard continuous Galerkin approach is applied. An adaptive conforming grid is utilized to further draw computational focus on the interface regions, while coarser meshes are utilized around pure phases. All presented methods are compared against each other in terms of bound preservation, mass conservation, and energy dissipation for different examples found in the literature, including a classical rising droplet problem."
  },
  {
    "date": "2026-02-09",
    "title": "Spaltenstein Varieties Associated with Pseudo-Polarizations",
    "authors": "Xueqing Wen, Yaoxiong Wen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08637v1",
    "source": "arXiv",
    "abstract": "We introduce minimal Richardson orbits and pseudo-polarizations for nilpotent orbits in classical Lie algebras of types B, C, and D. For any nilpotent orbit, we classify all minimal Richardson orbits containing it and thereby determine the associated pseudo-polarizations. We prove that the corresponding Spaltenstein varieties are smooth and pure dimensional, with iterated orthogonal/isotropic Grassmannian fibrations. As an application, we extend the seesaw property and duality of Fu-Ruan-Wen from Richardson orbits to all special orbits in types B and C."
  },
  {
    "date": "2026-02-09",
    "title": "Algebraic degree of Cayley colour graphs",
    "authors": "Sauvik Poddar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08634v1",
    "source": "arXiv",
    "abstract": "The splitting field of a graph $Γ$ with respect to a square matrix $M$ associated with $Γ$, is the smallest field extension over the field of rationals $\\mathbb{Q}$ that contains all the eigenvalues of $M$. The degree of the extension is called the algebraic degree of $Γ$ with respect to $M$. In this paper, we completely determine the splitting field of the adjacency matrix of the Cayley colour graph $\\operatorname{Cay}(G,f)$ on a finite group $G$, associated with a class function $f:G\\to\\mathbb{Q}$ and compute its algebraic degree, which generalize the main results of Wu et al. Moreover, we study the relation between the algebraic integrality of two Cayley colour graphs, and deduce the fact that the algebraic degree and distance algebraic degree of a normal Cayley graph are same, generalizing a result of Zhang et al."
  },
  {
    "date": "2026-02-09",
    "title": "Effectiveness of Rent Controls: Evidence from Spain",
    "authors": "Luis Perez Garcia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08631v1",
    "source": "arXiv",
    "abstract": "Growing concerns about housing affordability have prompted the adoption of rent control policies and renewed debates over their effectiveness. This paper provides the first empirical evaluation of the 2024 rent control policy implemented in Catalonia under Spain's new national housing law. To identify the causal effect of the policy on the rental market, I use municipality-level administrative data and implement several difference-in-differences strategies and event study designs. The results point to a reduction in tenancy agreements and a less robust decrease in rental price growth. While the findings highlight important short-term consequences of rent control, they also underscore the need for caution due to data limitations and limited robustness in some estimates."
  },
  {
    "date": "2026-02-09",
    "title": "CauScale: Neural Causal Discovery at Scale",
    "authors": "Bo Peng, Sirui Chen, Jiaguo Tian, Yu Qiao, Chaochao Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08629v1",
    "source": "arXiv",
    "abstract": "Causal discovery is essential for advancing data-driven fields such as scientific AI and data analysis, yet existing approaches face significant time- and space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via a reduction unit that compresses data embeddings and improves space efficiency by adopting tied attention weights to avoid maintaining axis-specific attention maps. To keep high causal discovery accuracy, CauScale adopts a two-stream design: a data stream extracts relational evidence from high-dimensional observations, while a graph stream integrates statistical graph priors and preserves key structural signals. CauScale successfully scales to 500-node graphs during training, where prior work fails due to space limitations. Across testing data with varying graph scales and causal mechanisms, CauScale achieves 99.6% mAP on in-distribution data and 84.4% on out-of-distribution data, while delivering 4-13,000 times inference speedups over prior methods. Our project page is at https://github.com/OpenCausaLab/CauScale."
  },
  {
    "date": "2026-02-09",
    "title": "Nesterov's accelerated gradient for unbounded convex functions finds the minimum-norm point in the dual space",
    "authors": "Keiya Sakabe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08618v1",
    "source": "arXiv",
    "abstract": "We study the behavior of first-order methods applied to a lower-unbounded convex function $f$, i.e., $\\inf f = -\\infty$. Such a setting has received little attention since the trajectories of gradient descent and Nesterov's accelerated gradient method diverge. In this paper, we establish quantitative convergence results describing their speeds and directions of divergence, with implications for unboundedness judgment. A key idea is a relation to a norm-minimization problem in the dual space: minimize $\\|p\\|^2/2$ over $p \\in \\mathrm{dom}f^\\ast$, which can be naturally solved via mirror descent by taking the Legendre--Fenchel conjugate $f^\\ast$ as the distance-generating function. It then turns out that gradient descent for $f$ coincides with mirror descent for this norm-minimization problem, and thus it simultaneously solves both problems at $\\mathcal{O}(k^{-1})$. This result admits acceleration; Nesterov's accelerated gradient method, without any modifications, simultaneously solves the original minimization and the dual norm-minimization problems at $\\mathcal{O}(k^{-2})$, providing a quantitative characterization of divergence in unbounded convex optimization."
  },
  {
    "date": "2026-02-09",
    "title": "Constructive conditional normalizing flows",
    "authors": "Borjan Geshkovski, Domènec Ruiz-Balet",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08606v1",
    "source": "arXiv",
    "abstract": "Motivated by applications in conditional sampling, given a probability measure $μ$ and a diffeomorphism $φ$, we consider the problem of simultaneously approximating $φ$ and the pushforward $φ_{\\#}μ$ by means of the flow of a continuity equation whose velocity field is a perceptron neural network with piecewise constant weights. We provide an explicit construction based on a polar-like decomposition of the Lagrange interpolant of $φ$. The latter involves a compressible component, given by the gradient of a particular convex function, which can be realized exactly, and an incompressible component, which -- after approximating via permutations -- can be implemented through shear flows intrinsic to the continuity equation. For more regular maps $φ$ -- such as the Knöthe-Rosenblatt rearrangement -- we provide an alternative, probabilistic construction inspired by the Maurey empirical method, in which the number of discontinuities in the weights doesn't scale inversely with the ambient dimension."
  },
  {
    "date": "2026-02-09",
    "title": "Elastic field causing noncommutativity",
    "authors": "A. L. Silva Netto, A. M. de M. Carvalho, G. Q. Garcia, C. Furtado",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08604v1",
    "source": "arXiv",
    "abstract": "We study how a uniform torsion background, modeling a continuous density of screw dislocations and induces effective spatial noncommutativity and reshapes the energy spectrum of a free quantum particle. Within the geometric theory of defects, the metric yields a first-order (magnetic-like) coupling in the transverse dynamics, equivalent to an effective magnetic field $B_{eff}$ proportional to $p_z Omega$, where $Omega$ encodes the torsion strength. In the strong-coupling (Landau) regime, the planar coordinates obey [x,y] != 0 and the spectrum organizes into Landau-like levels with a slight electric-field-driven tilt and a uniform shift. Thus, increasing $Omega$ drives the system continuously toward the familiar Landau problem in flat space, with torsion setting the noncommutativity scale and controlling the approach to the Landau limit."
  },
  {
    "date": "2026-02-09",
    "title": "A Precise Real-Time Force-Aware Grasping System for Robust Aerial Manipulation",
    "authors": "Kenghou Hoi, Yuze Wu, Annan Ding, Junjie Wang, Anke Zhao, Chengqian Zhang, Fei Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08599v1",
    "source": "arXiv",
    "abstract": "Aerial manipulation requires force-aware capabilities to enable safe and effective grasping and physical interaction. Previous works often rely on heavy, expensive force sensors unsuitable for typical quadrotor platforms, or perform grasping without force feedback, risking damage to fragile objects. To address these limitations, we propose a novel force-aware grasping framework incorporating six low-cost, sensitive skin-like tactile sensors. We introduce a magnetic-based tactile sensing module that provides high-precision three-dimensional force measurements. We eliminate geomagnetic interference through a reference Hall sensor and simplify the calibration process compared to previous work. The proposed framework enables precise force-aware grasping control, allowing safe manipulation of fragile objects and real-time weight measurement of grasped items. The system is validated through comprehensive real-world experiments, including balloon grasping, dynamic load variation tests, and ablation studies, demonstrating its effectiveness in various aerial manipulation scenarios. Our approach achieves fully onboard operation without external motion capture systems, significantly enhancing the practicality of force-sensitive aerial manipulation. The supplementary video is available at: https://www.youtube.com/watch?v=mbcZkrJEf1I."
  },
  {
    "date": "2026-02-09",
    "title": "MMTS-BENCH: A Comprehensive Benchmark for Time Series Understanding and Reasoning",
    "authors": "Yao Yin, Zhenyu Xiao, Musheng Li, Yiwen Liu, Sutong Nan, Yiting He, Ruiqi Wang, Zhenwei Zhang, Qingmin Liao, Yuantao Gu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08588v1",
    "source": "arXiv",
    "abstract": "Time series data are central to domains such as finance, healthcare, and cloud computing, yet existing benchmarks for evaluating various large language models (LLMs) on temporal tasks remain scattered and unsystematic. To bridge this gap, we introduce MMTS-BENCH, a comprehensive multimodal benchmark built upon a hierarchical taxonomy of time-series tasks, spanning structural awareness, feature analysis, temporal reasoning, sequence matching and cross-modal alignment. MMTS-BENCH comprises 2,424 time series question answering (TSQA) pairs across 4 subsets: Base, InWild, Match, and Align, generated through a progressive real-world QA framework and modular synthetic data construction. We conduct extensive evaluations on closed-source, open-source LLMs and existing time series adapted large language models (TS-LLMs), revealing that: (1) TS-LLMs significantly lag behind general-purpose LLMs in cross-domain generalization, (2) LLMs show weaknesses in local tasks compared to global tasks, (3) chain-of-thought (CoT) reasoning and multimodal integration substantially improve performance, and (4) the dominant factor in existing TS-LLMs remains the backbone network capability rather than the time series encoder design. MMTS-BENCH not only provides a rigorous evaluation framework but also offers clear directions for advancing LLMs toward robust, interpretable, and generalizable time-series reasoning."
  },
  {
    "date": "2026-02-09",
    "title": "Predicting Future Utility: Global Combinatorial Optimization for Task-Agnostic KV Cache Eviction",
    "authors": "Ziyao Tang, Pengkun Jiao, Xinhang Chen, Wei Liu, Shiyong Li, Jingjing Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08585v1",
    "source": "arXiv",
    "abstract": "Given the quadratic complexity of attention, KV cache eviction is vital to accelerate model inference. Current KV cache eviction methods typically rely on instantaneous heuristic metrics, implicitly assuming that score magnitudes are consistent proxies for importance across all heads. However, this overlooks the heterogeneity in predictive fidelity across attention heads. While certain heads prioritize the instantaneous contribution of tokens, others are dedicated to capturing long-horizon utility. In this paper, we propose that optimal budget allocation should be governed by the marginal utility in preserving long-term semantic information. Based on this insight, we propose LU-KV, a novel framework that optimizes head-level budget allocation through a convex-hull relaxation and a marginal-utility-based greedy solver to achieve near-optimal precision. Furthermore, we implement a data-driven offline profiling protocol to facilitate the practical deployment of LU-KV. Extensive evaluations on LongBench and RULER benchmarks demonstrate that LU-KV achieves an 80% reduction in KV cache size with minimal performance degradation, while simultaneously reducing inference latency and GPU memory footprint."
  },
  {
    "date": "2026-02-09",
    "title": "SemiNFT: Learning to Transfer Presets from Imitation to Appreciation via Hybrid-Sample Reinforcement Learning",
    "authors": "Melany Yang, Yuhang Yu, Diwang Weng, Jinwei Chen, Wei Dong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08582v1",
    "source": "arXiv",
    "abstract": "Photorealistic color retouching plays a vital role in visual content creation, yet manual retouching remains inaccessible to non-experts due to its reliance on specialized expertise. Reference-based methods offer a promising alternative by transferring the preset color of a reference image to a source image. However, these approaches often operate as novice learners, performing global color mappings derived from pixel-level statistics, without a true understanding of semantic context or human aesthetics. To address this issue, we propose SemiNFT, a Diffusion Transformer (DiT)-based retouching framework that mirrors the trajectory of human artistic training: beginning with rigid imitation and evolving into intuitive creation. Specifically, SemiNFT is first taught with paired triplets to acquire basic structural preservation and color mapping skills, and then advanced to reinforcement learning (RL) on unpaired data to cultivate nuanced aesthetic perception. Crucially, during the RL stage, to prevent catastrophic forgetting of old skills, we design a hybrid online-offline reward mechanism that anchors aesthetic exploration with structural review. % experiments Extensive experiments show that SemiNFT not only outperforms state-of-the-art methods on standard preset transfer benchmarks but also demonstrates remarkable intelligence in zero-shot tasks, such as black-and-white photo colorization and cross-domain (anime-to-photo) preset transfer. These results confirm that SemiNFT transcends simple statistical matching and achieves a sophisticated level of aesthetic comprehension. Our project can be found at https://melanyyang.github.io/SemiNFT/."
  },
  {
    "date": "2026-02-09",
    "title": "Percolation and Threshold-like Behavior in Multiple Sclerosis Progression",
    "authors": "Nikola Mirkov, Dušan S. Radivojević, Slobodan Maletić",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08576v1",
    "source": "arXiv",
    "abstract": "In this study we investigate the Percolation Hypothesis for Multiple Sclerosis Progression. The methodology relies on cross-reference analysis centered around a question: What is the evidence for a Percolation/phase-transition hypothesis in Multiple Sclerosis (MS), especially the idea that the RRMS dynamic balance can abruptly break akin to crossing a percolation threshold into SPMS? We identify theoretical models invoking percolation/critical thresholds, network/connectome studies assessing percolation robustness or threshold-like behavior, clinical markers showing thresholds or early-warning signals, and counter-evidence arguing for gradual/continuum transitions."
  },
  {
    "date": "2026-02-09",
    "title": "FLAG-4D: Flow-Guided Local-Global Dual-Deformation Model for 4D Reconstruction",
    "authors": "Guan Yuan Tan, Ngoc Tuan Vu, Arghya Pal, Sailaja Rajanala, Raphael Phan C. -W., Mettu Srinivas, Chee-Ming Ting",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08558v1",
    "source": "arXiv",
    "abstract": "We introduce FLAG-4D, a novel framework for generating novel views of dynamic scenes by reconstructing how 3D Gaussian primitives evolve through space and time. Existing methods typically rely on a single Multilayer Perceptron (MLP) to model temporal deformations, and they often struggle to capture complex point motions and fine-grained dynamic details consistently over time, especially from sparse input views. Our approach, FLAG-4D, overcomes this by employing a dual-deformation network that dynamically warps a canonical set of 3D Gaussians over time into new positions and anisotropic shapes. This dual-deformation network consists of an Instantaneous Deformation Network (IDN) for modeling fine-grained, local deformations and a Global Motion Network (GMN) for capturing long-range dynamics, refined through mutual learning. To ensure these deformations are both accurate and temporally smooth, FLAG-4D incorporates dense motion features from a pretrained optical flow backbone. We fuse these motion cues from adjacent timeframes and use a deformation-guided attention mechanism to align this flow information with the current state of each evolving 3D Gaussian. Extensive experiments demonstrate that FLAG-4D achieves higher-fidelity and more temporally coherent reconstructions with finer detail preservation than state-of-the-art methods."
  },
  {
    "date": "2026-02-09",
    "title": "The Impact of Turbulence on Hydroacoustic Waves",
    "authors": "Kai-Xin Hu, Yue-Jin Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08553v1",
    "source": "arXiv",
    "abstract": "Building upon our first paper [Hu, K.X, & Hu, Y. J. (2025). Hydroacoustic Absorption and Amplification by Turbulence, arXiv:2512.07920], the present work conducts a more in-depth investigation into the impact of turbulence on hydroacoustic waves. The study includes the influences of temperature, unsteady laminar flow, standing wave effects, the alteration of phase, the variation of amplification factor with frequency, and the temporal evolution of the acoustic wave. Experiments indicate that the temperature rise caused by friction between the turbulent flow and the pipe wall does not significantly affect the acoustic wave, and therefore is not the primary cause of changes in wave amplitude. When two transducers are placed opposite each other, the acoustic waves can be regarded as a superposition of traveling waves and standing waves. When the pump is shut down after the pipe flow has stabilized, the temporal evolution of the acoustic waves during the subsequent turbulence decay process can be classified into six types. In addition to altering the amplitude, turbulence also changes the phase of waves. The total phase shift of the acoustic wave along the entire pipe equals the sum of the phase shifts in each segment. Both the amplification factor and the phase shift due to turbulence vary periodically with frequency. Experiments for low-frequency waves show that acoustic waves with frequencies below a certain threshold are not affected by turbulence. These findings suggest that the interaction between hydroacoustic waves and turbulence constitutes stimulated emission in water."
  },
  {
    "date": "2026-02-09",
    "title": "Rho-Perfect: Correlation Ceiling For Subjective Evaluation Datasets",
    "authors": "Fredrik Cumlin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08552v1",
    "source": "arXiv",
    "abstract": "Subjective ratings contain inherent noise that limits the model-human correlation, but this reliability issue is rarely quantified. In this paper, we present $ρ$-Perfect, a practical estimation of the highest achievable correlation of a model on subjectively rated datasets. We define $ρ$-Perfect to be the correlation between a perfect predictor and human ratings, and derive an estimate of the value based on heteroscedastic noise scenarios, a common occurrence in subjectively rated datasets. We show that $ρ$-Perfect squared estimates test-retest correlation and use this to validate the estimate. We demonstrate the use of $ρ$-Perfect on a speech quality dataset and show how the measure can distinguish between model limitations and data quality issues."
  },
  {
    "date": "2026-02-09",
    "title": "Thegra: Graph-based SLAM for Thermal Imagery",
    "authors": "Anastasiia Kornilova, Ivan Moskalenko, Arabella Gromova, Gonzalo Ferrer, Alexander Menshchikov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08531v1",
    "source": "arXiv",
    "abstract": "Thermal imaging provides a practical sensing modality for visual SLAM in visually degraded environments such as low illumination, smoke, or adverse weather. However, thermal imagery often exhibits low texture, low contrast, and high noise, complicating feature-based SLAM. In this work, we propose a sparse monocular graph-based SLAM system for thermal imagery that leverages general-purpose learned features -- the SuperPoint detector and LightGlue matcher, trained on large-scale visible-spectrum data to improve cross-domain generalization. To adapt these components to thermal data, we introduce a preprocessing pipeline to enhance input suitability and modify core SLAM modules to handle sparse and outlier-prone feature matches. We further incorporate keypoint confidence scores from SuperPoint into a confidence-weighted factor graph to improve estimation robustness. Evaluations on public thermal datasets demonstrate that the proposed system achieves reliable performance without requiring dataset-specific training or fine-tuning a desired feature detector, given the scarcity of quality thermal data. Code will be made available upon publication."
  },
  {
    "date": "2026-02-09",
    "title": "Automatic regularization parameter choice for tomography using a double model approach",
    "authors": "Chuyang Wu, Samuli Siltanen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08528v1",
    "source": "arXiv",
    "abstract": "Image reconstruction in X-ray tomography is an ill-posed inverse problem, particularly with limited available data. Regularization is thus essential, but its effectiveness hinges on the choice of a regularization parameter that balances data fidelity against a priori information. We present a novel method for automatic parameter selection based on the use of two distinct computational discretizations of the same problem. A feedback control algorithm dynamically adjusts the regularization strength, driving an iterative reconstruction toward the smallest parameter that yields sufficient similarity between reconstructions on the two grids. The effectiveness of the proposed approach is demonstrated using real tomographic data."
  },
  {
    "date": "2026-02-09",
    "title": "Inverse orbital Hall effect induced terahertz emission enabled by a ferromagnet with quenched orbital moment in Fe/Pt/W trilayers",
    "authors": "Chao Zhou, Lei Hao, Shaohua Zhang, Yaxuan Jin, Xianguo Jiang, Ning Yang, Li Zheng, Hao Meng, Chao Lu, Wendeng Huang, Yizheng Wu, Yan Zhou, Jia Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08516v1",
    "source": "arXiv",
    "abstract": "The inverse orbital Hall effect (IOHE) has recently attracted considerable attention as an emerging mechanism for terahertz (THz) emission based on ultrafast angular-momentum-to-charge conversion. Most experimental studies have focused on materials with strong spin-orbit coupling or pronounced orbital character, where sizable orbital Hall responses are expected. Elemental ferromagnets such as Fe are generally regarded as quenched orbital sources and are not expected to exhibit orbital-dominated THz emission. Here, we report a pronounced enhancement of THz emission in Fe/Pt/W trilayer heterostructures, despite the absence of detectable orbital contributions in the corresponding Fe/Pt and Fe/W bilayers. Thickness-dependent measurements reveal long-distance signal persistence, systematic delay accumulation, and pronounced pulse broadening with increasing W thickness. These features are inconsistent with diffusive spin transport and indicate that orbital angular momentum transport in the W layer, converted into charge current via the IOHE, becomes a dominant channel for THz emission in the trilayer configuration. Our results demonstrate that strong IOHE can emerge in heterostructures incorporating a quenched orbital ferromagnet, providing an effective route to enhance spintronic THz emitters through orbital Hall physics."
  },
  {
    "date": "2026-02-09",
    "title": "Constraints on Higgs Light Yukawa Couplings with the CMS Detector",
    "authors": "Alberto Zucchetta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08512v1",
    "source": "arXiv",
    "abstract": "The discovery of the Higgs boson ten years ago and successful measurement of the Higgs boson couplings to third generation fermions by LHC mark great milestones for HEP. The much weaker coupling to the second generation quarks predicted by the SM makes the measurement of the light Yukawa Higgs couplings, as the Higgs-charm ones, much more challenging. With the latest tagging algorithms capabilities, a lot of progress has been made to constrain these couplings. In this talk, the latest results of direct and indirect measurements by the CMS experiment are presented. Prospects for future improvements are also given."
  },
  {
    "date": "2026-02-09",
    "title": "Covariant eigenmode overlap formalism for gravitational wave signals in electromagnetic cavities",
    "authors": "Jordan Gué, Tom Krokotsch, Gudrid Moortgat-Pick",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08507v1",
    "source": "arXiv",
    "abstract": "We develop a coordinate invariant formalism which describes the mechanical and electromagnetic interaction of gravitational waves (GWs) with a wide class of resonant detectors. We solve the GW-modified equations of electrodynamics and elasticity with dynamic boundary conditions using an eigenmode expansion. Furthermore, we take damping effects and electromagnetic back-action on mechanical systems covariantly into account. The resulting coupling coefficients are particularly useful for high-frequency gravitational wave experiments using microwave cavities and allow a straightforward numerical implementation for arbitrary detector geometries."
  },
  {
    "date": "2026-02-09",
    "title": "A General Theory of Proportionality with Additive Utilities",
    "authors": "Piotr Skowron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08504v1",
    "source": "arXiv",
    "abstract": "We consider a model where a subset of candidates must be selected based on voter preferences, subject to general constraints that specify which subsets are feasible. This model generalizes committee elections with diversity constraints, participatory budgeting (including constraints specifying how funds must be allocated to projects from different pools), and public decision-making. Axioms of proportionality have recently been defined for this general model, but the proposed rules apply only to approval ballots, where each voter submits a subset of candidates she finds acceptable. We propose proportional rules for cardinal ballots, where each voter assigns a numerical value to each candidate corresponding to her utility if that candidate is selected. In developing these rules, we also introduce methods that produce proportional rankings, ensuring that every prefix of the ranking satisfies proportionality."
  },
  {
    "date": "2026-02-09",
    "title": "Learning Self-Correction in Vision-Language Models via Rollout Augmentation",
    "authors": "Yi Ding, Ziliang Qiu, Bolian Li, Ruqi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08503v1",
    "source": "arXiv",
    "abstract": "Self-correction is essential for solving complex reasoning problems in vision-language models (VLMs). However, existing reinforcement learning (RL) methods struggle to learn it, as effective self-correction behaviors emerge only rarely, making learning signals extremely sparse. To address this challenge, we propose correction-specific rollouts (Octopus), an RL rollout augmentation framework that synthesizes dense self-correction examples by recombining existing rollouts. This augmentation simultaneously improves sample efficiency due to rollout reuse and stabilizes RL optimization through balanced supervision. Furthermore, we introduce a response-masking strategy that decouples self-correction from direct reasoning, avoiding signal conflicts and enabling both behaviors to be learned effectively. Building on this, we introduce Octopus-8B, a reasoning VLM with controllable self-correction capability. Across 7 benchmarks, it achieves SoTA performance among open-source VLMs, outperforming the best RLVR baseline by 1.0 score while requiring only $0.72\\times$ training time per step."
  },
  {
    "date": "2026-02-09",
    "title": "A Comparative Analysis of the CERN ATLAS ITk MOPS Readout: A Feasibility Study on Production and Development Setups",
    "authors": "Lukas Flad, Felix Sebastian Nitz, Tobias Krawutschke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08488v1",
    "source": "arXiv",
    "abstract": "The upcoming High-Luminosity upgrade of the Large Hadron Collider (LHC) necessitates a complete replacement of the ATLAS Inner Detector with the new Inner Tracker (ITk). This upgrade imposes stringent requirements on the associated Detector Control System (DCS), which is responsible for the monitoring, control, and safety of the detector. A critical component of the ITk DCS is the Monitoring of Pixel System (MOPS), which supervises the local voltages and temperatures of the new pixel detector modules. This paper introduces a dedicated testbed and verification methodology for the MOPS readout, defining a structured set of test cases for two DCS-readout architectures: a preliminary Raspberry Pi-based controller, the \"MOPS-Hub Mock-up\"(MH Mock-up), and the final production FPGA-based \"MOPS-Hub\" (MH). The methodology specifies the measurement chain for end-to-end latency, jitter, and data integrity across CAN and UART interfaces, including a unified time-stamping scheme, non-intrusive signal taps, and a consistent data-logging and analysis pipeline. This work details the load profiles and scalability scenarios (baseline operation, full-crate stress, and CAN Interface Card channel isolation), together with acceptance criteria and considerations for measurement uncertainty to ensure reproducibility. The objective is to provide a clear, repeatable procedure to qualify the MH architecture for production and deployment in the ATLAS ITk DCS. A companion paper will present the experimental results and the comparative analysis obtained using this testbed."
  },
  {
    "date": "2026-02-09",
    "title": "Can UV meet IR in the Swiss cheese?",
    "authors": "Madina Abilmazhinova, Diana Kulubayeva, Hrishikesh Chakrabarty, Daniele Malafarina",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08487v1",
    "source": "arXiv",
    "abstract": "We consider the embedding of regular black holes in an expanding universe and study how the ultraviolet modifications to the Schwarzschild geometry that regularize the black hole singularity affect the exterior universe's expansion rate. We consider several proposals for the regular black hole geometry and obtain the corresponding Friedmann equations for a universe filled only with dust and black holes. We show that different proposals have different implications which may be distinguished. We then test the hypothesis that the UV corrections to the black hole geometry may be responsible for the current phase of accelerated expansion. To this aim we constrain the value of the regular black hole UV cutoff parameter from observations. Interestingly we find that the best fit is obtained by values of the parameter corresponding to regular horizonless compact objects."
  },
  {
    "date": "2026-02-09",
    "title": "Physics-Guided Variational Model for Unsupervised Sound Source Tracking",
    "authors": "Luan Vinícius Fiorio, Ivana Nikoloska, Bruno Defraene, Alex Young, Johan David, Ronald M. Aarts",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08484v1",
    "source": "arXiv",
    "abstract": "Sound source tracking is often performed using classical array-processing algorithms. Alternative methods, such as machine learning, rely on ground truth position labels, which are costly to obtain. We propose a variational model that can perform single-source unsupervised sound source tracking in latent space, aided by a physics-based decoder. Our experiments demonstrate that the proposed method surpasses traditional baselines and achieves performance and computational complexity comparable to state-of-the-art supervised models. We also show that the method presents substantial robustness to altered microphone array geometries and corrupted microphone position metadata. Finally, the method is extended to multi-source sound tracking and the basic theoretical changes are proposed."
  },
  {
    "date": "2026-02-09",
    "title": "Symbol Rate Maximization in Rolling-Shutter OCC: Design and Implementation Considerations",
    "authors": "Xinyu Zhang, Alexis A. Dowhuszko, Miguel Rêgo, Pedro Fonseca, Luís Nero Alves, Jyri Hämäläinen, Risto Wichman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08474v1",
    "source": "arXiv",
    "abstract": "Optical Camera Communication (OCC) systems can take advantage of the row-by-row scanning process of rolling-shutter cameras to capture the fast variations of light intensity coming from Visible Light Communication (VLC) LED-based transmitters. In order to study the maximum data rate that is feasible in such kind of OCC systems, this paper presents its equivalent digital communication system model in which the rolling-shutter camera is modeled as a rectangular matched-filter whose time width is equal to the exposure time of the camera, followed by a sampling process at the pixel row sweep rate of the camera. Based on the proposed rolling-shutter camera model, the maximum symbol rate that such OCC systems can support is experimentally demonstrated, and the impact of imperfect time synchronization between the VLC transmitter and the rolling-shutter OCC receiver is characterized in the form of Inter-Symbol Interference (ISI). The equivalent three-tap channel model that results from this process is experimentally validated and the generated ISI is compensated with the use of linear equalization in reception. Simulation and experimental results show a strong correlation between them, demonstrating that the proposed approach can be used to make the OCC system work at the Nyquist sampling rate, which is equivalent to the pixel row sweep rate of the rolling-shutter camera used in reception."
  },
  {
    "date": "2026-02-09",
    "title": "Submodular Maximization over a Matroid $k$-Intersection: Multiplicative Improvement over Greedy",
    "authors": "Moran Feldman, Justin Ward",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08473v1",
    "source": "arXiv",
    "abstract": "We study the problem of maximizing a non-negative monotone submodular objective $f$ subject to the intersection of $k$ arbitrary matroid constraints. The natural greedy algorithm guarantees $(k+1)$-approximation for this problem, and the state-of-the-art algorithm only improves this approximation ratio to $k$. We give a $\\frac{2k\\ln2}{1+\\ln2}+O(\\sqrt{k})<0.819k+O(\\sqrt{k})$ approximation for this problem. Our result is the first multiplicative improvement over the approximation ratio of the greedy algorithm for general $k$. We further show that our algorithm can be used to obtain roughly the same approximation ratio also for the more general problem in which the objective is not guaranteed to be monotone (the sublinear term in the approximation ratio becomes $O(k^{2/3})$ rather than $O(\\sqrt{k})$ in this case). All of our results hold also when the $k$-matroid intersection constraint is replaced with a more general matroid $k$-parity constraint. Furthermore, unlike the case in many of the previous works, our algorithms run in time that is independent of $k$ and polynomial in the size of the ground set. Our algorithms are based on a hybrid greedy local search approach recently introduced by Singer and Thiery (STOC 2025) for the weighted matroid $k$-intersection problem, which is a special case of the problem we consider. Leveraging their approach in the submodular setting requires several non-trivial insights and algorithmic modifications since the marginals of a submodular function $f$, which correspond to the weights in the weighted case, are not independent of the algorithm's internal randomness. In the special weighted case studied by Singer and Thiery, our algorithms reduce to a variant of their algorithm with an improved approximation ratio of $k\\ln2+1-\\ln2<0.694k+0.307$, compared to an approximation ratio of $\\frac{k+1}{2\\ln2}\\approx0.722k+0.722$ guaranteed by Singer and Thiery."
  },
  {
    "date": "2026-02-09",
    "title": "Classifying the simplest Bell inequalities beyond qubits and their applications towards self-testing",
    "authors": "Palash Pandya, Shubhayan Sarkar, Remigiusz Augusiak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08469v1",
    "source": "arXiv",
    "abstract": "Bell inequalities reveal the fundamentally nonlocal character of quantum mechanics. In this regard, one of the interesting problems is to explore all possible Bell inequalities that demonstrate a gap between local and nonlocal quantum behaviour. This is useful for the geometric characterisation of the set of nonlocal correlations achievable within quantum theory. Moreover, it provides a systematic way to construct Bell inequalities that are tailored to specific quantum information processing tasks. This characterisation is well understood in the simplest $(2,2,2)$ scenario, namely two parties performing two binary outcome measurements. However, beyond this setting, relatively few Bell inequalities are known, and the situation becomes particularly scarce in scenarios involving a greater number of outcomes. Here, we consider the $(2,2,3)$ scenario, or two parties performing two three-outcome measurements, and characterise all Bell inequalities that can arise from the simplest sum-of-squares decomposition and are maximally violated by the maximally entangled state of local dimension three. We then utilise them to self-test this state, along with a class of three-outcome measurements."
  },
  {
    "date": "2026-02-09",
    "title": "Observation of e/4 charge at $ν=1/2$ in GaAs",
    "authors": "Tomer Alkalai, Emily Hajigeorgiou, Adbhut Gupta, Tapas Senapati, Priya Tiwari, Chia-Tse Tai, Siddharth Kumar Singh, Kirk W. Baldwin, Loren N. Pfeiffer, Mansour Shayegan, Mitali Banerjee, Moty Heiblum",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08468v1",
    "source": "arXiv",
    "abstract": "Even-denominator fractional quantum Hall states (FQHSs) fall outside the standard Laughlin's and Jain's odd-denominator hierarchy. In this work, we study the FQHS $ν=1/2$ in the lowest Landau level. The state is confined within a 70 nm-wide GaAs quantum well, where the electrons exhibit a bilayer-like charge distribution. Inter-layer interactions stabilize the $ν=1/2$ FQHS, which is predicted to host quasiparticles with charge e/4 - with either Abelian or non-Abelian topological order. Here, we report on shot-noise measurements of partitioned quasiparticles at $ν=1/2$, where charge partitioning is generated by a unique etch-defined quantum point contact. Our measurements were performed on two nominally identical devices, at two independent experimental setups. Analysis of shot noise in the weak-backscattering regime in each device reveals quasiparticles with charge e/4. These observations provide a clear benchmark for future studies aimed at probing the topological order of the $ν=1/2$ FQHS and its quasiparticles' exchange statistics."
  },
  {
    "date": "2026-02-09",
    "title": "Decentralized Spatial Reuse Optimization in Wi-Fi: An Internal Regret Minimization Approach",
    "authors": "Francesc Wilhelmi, Boris Bellalta, Miguel Casasnovas, Aleksandra Kijanka, Miguel Calvo-Fullana",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08456v1",
    "source": "arXiv",
    "abstract": "Spatial Reuse (SR) is a cost-effective technique for improving spectral efficiency in dense IEEE 802.11 deployments by enabling simultaneous transmissions. However, the decentralized optimization of SR parameters -- transmission power and Carrier Sensing Threshold (CST) -- across different Basic Service Sets (BSSs) is challenging due to the lack of global state information. In addition, the concurrent operation of multiple agents creates a highly non-stationary environment, often resulting in suboptimal global configurations (e.g., using the maximum possible transmission power by default). To overcome these limitations, this paper introduces a decentralized learning algorithm based on regret-matching, grounded in internal regret minimization. Unlike standard decentralized ``selfish'' approaches that often converge to inefficient Nash Equilibria (NE), internal regret minimization guides competing agents toward Correlated Equilibria (CE), effectively mimicking coordination without explicit communication. Through simulation results, we showcase the superiority of our proposed approach and its ability to reach near-optimal global performance. These results confirm the not-yet-unleashed potential of scalable decentralized solutions and question the need for the heavy signaling overheads and architectural complexity associated with emerging centralized solutions like Multi-Access Point Coordination (MAPC)."
  },
  {
    "date": "2026-02-09",
    "title": "When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment",
    "authors": "Igor Santos-Grueiro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08449v1",
    "source": "arXiv",
    "abstract": "Safety evaluation for advanced AI systems implicitly assumes that behavior observed under evaluation is predictive of behavior in deployment. This assumption becomes fragile for agents with situational awareness, which may exploitregime leakage-informational cues distinguishing evaluation from deployment-to implement conditional policies such as sycophancy and sleeper agents, which preserve compliance under oversight while defecting in deployment-like regimes. We reframe alignment evaluation as a problem of information flow under partial observability. Within this framework, we show that divergence between evaluation-time and deployment-time behavior is bounded by the mutual information between internal representations and the regime variable. Motivated by this result, we study regime-blind mechanisms: training-time interventions that reduce the extractability of regime information at decision-relevant internal representations via adversarial invariance. We evaluate this approach on a base, open-weight language model across two fully characterized failure modes -scientific sycophancy and temporal sleeper agents. Regime-blind training suppresses regime-conditioned behavior in both evaluated cases without measurable loss of task utility, but with qualitatively different dynamics: sycophancy exhibits a sharp representational and behavioral transition at low intervention strength, whereas sleeper-agent behavior requires substantially stronger pressure and does not exhibit a clean collapse of regime decodability. These results demonstrate that representational invariance is a meaningful but fundamentally limited control lever, whose effectiveness depends on how regime information is embedded in the policy. We argue that behavioral evaluation should be complemented with white-box diagnostics of regime awareness and information flow."
  },
  {
    "date": "2026-02-09",
    "title": "Shear-Induced Collective Shape Oscillations in Dense Soft Suspensions",
    "authors": "Ioannis Hadjifrangiskou, Rahil N. Valani, Diogo E. P. Pinto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08445v1",
    "source": "arXiv",
    "abstract": "Dense suspensions of deformable particles can exhibit rich nonequilibrium dynamics arising from complex flow-structure coupling. Using a multi-phase field model, we show that steady shear drives an initially disordered, dense, soft suspension into a positionally and orientationally ordered state, within which particles undergo robust self-sustained shape oscillations. These oscillations originate from repeated T1 neighbor exchanges that force the ordered particle lattice to cyclically traverse different ordered configurations, coupling particle deformation to evolving lattice topology. By identifying the lattice angle as a key variable, we construct a minimal one-degree-of-freedom model that quantitatively captures the limit cycle oscillation. Because these mechanisms rely only on deformability, packing, and shear, they provide a generic route to collective time-dependent behavior in dense soft suspensions."
  },
  {
    "date": "2026-02-09",
    "title": "Post-Collision Trajectory Restoration for a Single-track Ackermann Vehicle using Heuristic Steering and Tractive Force Functions",
    "authors": "Samsaptak Ghosh, M. Felix Orlando, Sohom Chakrabarty",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08444v1",
    "source": "arXiv",
    "abstract": "Post-collision trajectory restoration is a safety-critical capability for autonomous vehicles, as impact-induced lateral motion and yaw transients can rapidly drive the vehicle away from the intended path. This paper proposes a structured heuristic recovery control law that jointly commands steering and tractive force for a generalized single-track Ackermann vehicle model. The formulation explicitly accounts for time-varying longitudinal velocity in the lateral-yaw dynamics and retains nonlinear steering-coupled interaction terms that are commonly simplified in the literature. Unlike approaches that assume constant longitudinal speed, the proposed design targets the transient post-impact regime where speed variations and nonlinear coupling significantly influence recovery. The method is evaluated in simulation on the proposed generalized single-track model and a standard 3DOF single-track reference model in MATLAB, demonstrating consistent post-collision restoration behaviour across representative initial post-impact conditions."
  },
  {
    "date": "2026-02-09",
    "title": "Large Language Models and Impossible Language Acquisition: \"False Promise\" or an Overturn of our Current Perspective towards AI",
    "authors": "Ziyan wang, Longlong Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08437v1",
    "source": "arXiv",
    "abstract": "In Chomsky's provocative critique \"The False Promise of CHATGPT,\" Large Language Models (LLMs) are characterized as mere pattern predictors that do not acquire languages via intrinsic causal and self-correction structures like humans, therefore are not able to distinguish impossible languages. It stands as a representative in a fundamental challenge to the intellectual foundations of AI, for it integrally synthesizes major issues in methodologies within LLMs and possesses an iconic a priori rationalist perspective. We examine this famous critic from both the perspective in pre-existing literature of linguistics and psychology as well as a research based on an experiment inquiring the capacity of learning both possible and impossible languages among LLMs. We constructed a set of syntactically impossible languages by applying certain transformations to English. These include reversing whole sentences, and adding negation based on word-count parity. Two rounds of controlled experiments were each conducted on GPT-2 small models and long short-term memory (LSTM) models. Statistical analysis (Welch's t-test) shows GPT2 small models underperform in learning all of the impossible languages compared to their performance on the possible language (p<.001). On the other hand, LSTM models' performance tallies with Chomsky's argument, suggesting the irreplaceable role of the evolution of transformer architecture. Based on theoretical analysis and empirical findings, we propose a new vision within Chomsky's theory towards LLMs, and a shift of theoretical paradigm outside Chomsky, from his \"rationalist-romantics\" paradigm to functionalism and empiricism in LLMs research."
  },
  {
    "date": "2026-02-09",
    "title": "Dynamics of Y Dwarf Atmospheres",
    "authors": "C. Akın, E. K. H. Lee, L. Gkouvelis, K. Heng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08434v1",
    "source": "arXiv",
    "abstract": "The global circulation regime of the coolest brown dwarfs, the Y dwarfs, remains largely unexplored. We investigate the interplay between convection, rotation, and cloud thermal feedback using a selected sample of Y dwarf atmospheric models. We explore effective temperatures $400~\\mathrm{K} \\leq T_{\\mathrm{eff}} \\leq 600~\\mathrm{K}$ and rotation periods $P_{\\mathrm{rot}} = 2.5 \\text{--} 20\\ \\mathrm{h}$, where salt and sulfide condensates are expected. We include $\\mathrm{KCl,~Na_{2}S}$, and $\\mathrm{MnS}$ clouds to assess their atmospheric impact and identify circulation regimes across parameter space. We run twelve general circulation models (GCMs) spanning this grid and develop additional physics modules for the THOR GCM to model brown dwarf atmospheres. The dynamical core is coupled to interior thermal perturbations near the radiative-convective boundary, a mixing-length convection scheme, gray two-stream radiative transfer with Rosseland-mean opacities, and simple cloud tracers including thermal feedback and scattering. All simulations exhibit a radiative-forcing-dominated regime with weak winds, minimal horizontal temperature contrasts, and no persistent jets. Convection controls vertical mixing and sets the extent of salt and sulfide cloud layers below the photosphere. Thermal structures equilibrate quickly and cloud radiative feedback remains insignificant, with limited variability. Within the gray radiative transfer framework adopted here, Y dwarf atmospheres in this parameter space are controlled by interior thermal radiation. Rotation sets modest variability, while clouds play a secondary role. Because our single-band approach does not capture spectral windows that could probe deeper cloud layers, our constraints on cloud radiative feedback are likely conservative, and we outline pathways toward more active regimes."
  },
  {
    "date": "2026-02-09",
    "title": "Kosmulator: A Python framework for cosmological inference with MCMC",
    "authors": "Renier T. Hough, Robert Rugg, Shambel Sahlu, Amare Abebe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08424v1",
    "source": "arXiv",
    "abstract": "We present Kosmulator, a modular and vectorised Python framework designed to accelerate the statistical testing of cosmological models. As the theoretical landscape expands beyond standard $Λ$CDM, implementing new expansion histories into traditional Einstein--Boltzmann solvers becomes a significant computational bottleneck. Kosmulator addresses this by leveraging array-native execution and efficient ensemble slice sampling (via Zeus) to perform rapid Bayesian inference. We validate the framework against the industry-standard Cobaya code using a combination of Type Ia Supernovae, Cosmic Chronometers, and Baryon Acoustic Oscillation (BAO) data. Our results demonstrate that Kosmulator reproduces Cobaya's posterior constraints to within $\\leq0.3σ$ statistical agreement on $H_{0}$ and $Ω_{m}$ and $<0.6\\%$ precision on $χ^{2}$, while achieving a $\\sim 4.5\\times$ reduction in wall-clock time on a single CPU core compared to a standard MPI-parallelised baseline. Furthermore, we showcase the framework's utility by constraining the implicit power-law $f(Q)$ \"$f_1$CDM\" model and demonstrating its automated model selection capabilities (AIC/BIC). Kosmulator is introduced as a \"scientific sieve\" for rapid hypothesis testing, allowing researchers to efficiently filter theoretical candidates before deploying high-precision resources."
  },
  {
    "date": "2026-02-09",
    "title": "Johann Heinrich Lambert's memoir \"Theorie der Parallellinien\": A review with commentary",
    "authors": "Athanase Papadopoulos, Guillaume Théret",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08420v1",
    "source": "arXiv",
    "abstract": "We review the memoir \\emph{heorie der Parallellinien} by Johann Heinrich Lambert, written in 1766. Lambert, a victim of the prejudices of his time, conceived this memoir as an attempt to prove the so-called parallel postulate of Euclid's \\emph{Elements}, and consequently, the non-existence of the geometry that we now call hyperbolic geometry. In fact, by developing the foundations of a geometry obtained by replacing the parallel postulate with its negation while keeping Euclid's other postulates unchanged, Lambert was hoping to arrive at a contradiction. Of course, he failed in his endeavor, but these attempts at proving the parallel postulate implicitly contain, without Lambert having foreseen it, fundamental results of hyperbolic geometry, the discovery of which, by Lobachevsky, Bolyai and Gauss, was not to take place until the following century. Thus, Lambert's memoir (which he did not intend to publish but which was eventually published in 1895) constitutes one of the founding texts of non-Euclidean geometry. Spherical geometry is one of the three geometries of constant curvature, the other two being Euclidean geometry and hyperbolic geometry. In this sense, along with hyperbolic geometry, spherical geometry constitutes one of the two non-Euclidean geometries. In fact, Lambert, like Lobachevsky and others after him, understood the deep relationships between the three geometries: Euclidean, spherical, and hyperbolic, in particular the formal and the more profound analogies between the trigonometric formulae, the properties of birectangular isosceles quadrilaterals and of trirectangular quadrilaterals, the monotonicity properties (which can be formulated in terms of convexity properties) which hold in opposite senses in spherical and hyperbolic geometry which at some points he calls a sphere of imaginary radius. It is for these reasons that we decided to include in this volume, dedicated to spherical geometry, a chapter on this important memoir by Lambert, trying to highlight its most important ideas. This paper will appear as a chapter in the book ``Spherical Geometry in the Eighteenth Century I: Euler, Lagrange and Lambert'', ed. R. Caddeo and A. Papadopoulos, Springer Nature Switzerland, 2026."
  },
  {
    "date": "2026-02-09",
    "title": "A Sketch+Text Composed Image Retrieval Dataset for Thangka",
    "authors": "Jinyu Xu, Yi Sun, Jiangling Zhang, Qing Xie, Daomin Ji, Zhifeng Bao, Jiachen Li, Yanchun Ma, Yongjian Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08411v1",
    "source": "arXiv",
    "abstract": "Composed Image Retrieval (CIR) enables image retrieval by combining multiple query modalities, but existing benchmarks predominantly focus on general-domain imagery and rely on reference images with short textual modifications. As a result, they provide limited support for retrieval scenarios that require fine-grained semantic reasoning, structured visual understanding, and domain-specific knowledge. In this work, we introduce CIRThan, a sketch+text Composed Image Retrieval dataset for Thangka imagery, a culturally grounded and knowledge-specific visual domain characterized by complex structures, dense symbolic elements, and domain-dependent semantic conventions. CIRThan contains 2,287 high-quality Thangka images, each paired with a human-drawn sketch and hierarchical textual descriptions at three semantic levels, enabling composed queries that jointly express structural intent and multi-level semantic specification. We provide standardized data splits, comprehensive dataset analysis, and benchmark evaluations of representative supervised and zero-shot CIR methods. Experimental results reveal that existing CIR approaches, largely developed for general-domain imagery, struggle to effectively align sketch-based abstractions and hierarchical textual semantics with fine-grained Thangka images, particularly without in-domain supervision. We believe CIRThan offers a valuable benchmark for advancing sketch+text CIR, hierarchical semantic modeling, and multimodal retrieval in cultural heritage and other knowledge-specific visual domains. The dataset is publicly available at https://github.com/jinyuxu-whut/CIRThan."
  },
  {
    "date": "2026-02-09",
    "title": "IEEE 802.11ad-Aided 5-D Sensing with a UAV Swarm in Urban Environment",
    "authors": "Akanksha Sneh, Shobha Sundar Ram, Kumar Vijay Mishra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08396v1",
    "source": "arXiv",
    "abstract": "Aerial base stations mounted on unmanned aerial vehicles (UAVs) support next-generation wireless networks in challenging environments such as urban areas, disaster zones, and remote locations. Further, UAV swarms overcome the challenges of limited battery life and other operational constraints of a single UAV. However, tracking mobile users on the ground by each UAV and the corresponding synchronization between the UAVs is a significant issue that must be addressed before this framework can be deployed in reality. Incorporating additional sensing capabilities to facilitate this additional requirement would introduce significant overhead in terms of hardware, cost, and power to each UAV. Instead, we propose an integrated sensing and communications-enabled swarm UAV system, based on the millimeter-wave IEEE 802.11ad protocol. Further, we show that our proposed system is capable of five-dimensional (5-D) ground target sensing (range, Doppler velocity, azimuth, elevation, and polarization) in an urban environment. Numerical experiments using realistic models demonstrate and validate the performance of 5-D sensing using our proposed 802-11ad-aided UAV system."
  },
  {
    "date": "2026-02-09",
    "title": "BiManiBench: A Hierarchical Benchmark for Evaluating Bimanual Coordination of Multimodal Large Language Models",
    "authors": "Xin Wu, Zhixuan Liang, Yue Ma, Mengkang Hu, Zhiyuan Qin, Xiu Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08392v1",
    "source": "arXiv",
    "abstract": "Multimodal Large Language Models (MLLMs) have significantly advanced embodied AI, and using them to benchmark robotic intelligence has become a pivotal trend. However, existing frameworks remain predominantly confined to single-arm manipulation, failing to capture the spatio-temporal coordination required for bimanual tasks like lifting a heavy pot. To address this, we introduce BiManiBench, a hierarchical benchmark evaluating MLLMs across three tiers: fundamental spatial reasoning, high-level action planning, and low-level end-effector control. Our framework isolates unique bimanual challenges, such as arm reachability and kinematic constraints, thereby distinguishing perceptual hallucinations from planning failures. Analysis of over 30 state-of-the-art models reveals that despite high-level reasoning proficiency, MLLMs struggle with dual-arm spatial grounding and control, frequently resulting in mutual interference and sequencing errors. These findings suggest the current paradigm lacks a deep understanding of mutual kinematic constraints, highlighting the need for future research to focus on inter-arm collision-avoidance and fine-grained temporal sequencing."
  },
  {
    "date": "2026-02-09",
    "title": "Hierarchical Subcode Ensemble Decoding of Polar Codes",
    "authors": "Yubeen Jo, Geon Choi, Chanho Park, Namyoon Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08391v1",
    "source": "arXiv",
    "abstract": "Subcode-ensemble decoders improve iterative decoding by running multiple decoders in parallel over carefully chosen subcodes, increasing the likelihood that at least one decoder avoids the dominant trapping structures. Achieving strong diversity gains, however, requires constructing many subcodes that satisfy a linear covering property-yet existing approaches lack a systematic way to scale the ensemble size while preserving this property. This paper introduces hierarchical subcode ensemble decoding (HSCED), a new ensemble decoding framework that expands the number of constituent decoders while still guaranteeing linear covering. The key idea is to recursively generate subcode parity constraints in a hierarchical structure so that coverage is maintained at every level, enabling large ensembles with controlled complexity. To demonstrate its effectiveness, we apply HSCED to belief propagation (BP) decoding of polar codes, where dense parity-check matrices induce severe stopping-set effects that limit conventional BP. Simulations confirm that HSCED delivers significant block-error-rate improvements over standard BP and conventional subcode-ensemble decoding under the same decoding-latency constraint."
  },
  {
    "date": "2026-02-09",
    "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning",
    "authors": "Zhuoen Chen, Dongfang Li, Meishan Zhang, Baotian Hu, Min Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08382v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) face significant challenges in long-context processing, including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall, rather than processing all raw tokens. The framework segments long inputs into chunks and encodes each chunk into compressed memory representations using a learned compressor. A gating module dynamically selects relevant memory blocks, which are then iteratively processed by a reasoning module with an evolving working memory to solve downstream tasks. The compressor and reasoner are jointly optimized via end-to-end reinforcement learning, while the gating module is trained separately as a classifier. Experimental results show that the proposed method achieves competitive accuracy on multi-hop reasoning benchmarks such as RULER-HQA, extrapolates context length from 7K to 1.75M tokens, and offers a favorable accuracy-efficiency trade-off compared to strong long-context baselines. In particular, it achieves up to a 2 times reduction in peak GPU memory usage and a 6 times inference speedup over MemAgent."
  },
  {
    "date": "2026-02-09",
    "title": "Reinforcement Learning with Backtracking Feedback",
    "authors": "Bilgehan Sel, Vaishakh Keshava, Phillip Wallis, Lukas Rutishauser, Ming Jin, Dingcheng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08377v1",
    "source": "arXiv",
    "abstract": "Addressing the critical need for robust safety in Large Language Models (LLMs), particularly against adversarial attacks and in-distribution errors, we introduce Reinforcement Learning with Backtracking Feedback (RLBF). This framework advances upon prior methods, such as BSAFE, by primarily leveraging a Reinforcement Learning (RL) stage where models learn to dynamically correct their own generation errors. Through RL with critic feedback on the model's live outputs, LLMs are trained to identify and recover from their actual, emergent safety violations by emitting an efficient \"backtrack by x tokens\" signal, then continuing generation autoregressively. This RL process is crucial for instilling resilience against sophisticated adversarial strategies, including middle filling, Greedy Coordinate Gradient (GCG) attacks, and decoding parameter manipulations. To further support the acquisition of this backtracking capability, we also propose an enhanced Supervised Fine-Tuning (SFT) data generation strategy (BSAFE+). This method improves upon previous data creation techniques by injecting violations into coherent, originally safe text, providing more effective initial training for the backtracking mechanism. Comprehensive empirical evaluations demonstrate that RLBF significantly reduces attack success rates across diverse benchmarks and model scales, achieving superior safety outcomes while critically preserving foundational model utility."
  },
  {
    "date": "2026-02-09",
    "title": "OJBKQ: Objective-Joint Babai-Klein Quantization",
    "authors": "Xinyu Wang, Ziyu Zhao, Peng Lu, Yu Gu, Xiao-Wen Chang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08376v1",
    "source": "arXiv",
    "abstract": "Post-training quantization (PTQ) is widely used to compress large language models without retraining. However, many existing weight-only methods rely on heuristic objectives and greedy rounding, thus leading to noticeable degradation under low-bit quantization. In this work, we introduce OJBKQ (Objective-Joint Babai-Klein Quantization with K-Best Sampling), a layer-wise PTQ method that formulates weight quantization as a joint optimization problem over activations and weights. This formulation results in a multiple-right-hand-side box-constrained integer least squares (BILS) problem in each layer, which is NP-hard. For each column of the weight matrix, we apply an extended Babai nearest-plane algorithm and an extended version of Klein's randomized Babai algorithm to find the minimum-residual Babai-Klein point, a sub-optimal solution to the BILS problem. Experimental results on large language models show that OJBKQ achieves lower perplexity at 3-4 bits compared to existing PTQ approaches, while maintaining comparable computational cost."
  },
  {
    "date": "2026-02-09",
    "title": "Learning Human-Like Badminton Skills for Humanoid Robots",
    "authors": "Yeke Chen, Shihao Dong, Xiaoyu Ji, Jingkai Sun, Zeren Luo, Liu Zhao, Jiahui Zhang, Wanyue Li, Ji Ma, Bowen Xu, Yimin Han, Yudong Zhao, Peng Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08370v1",
    "source": "arXiv",
    "abstract": "Realizing versatile and human-like performance in high-demand sports like badminton remains a formidable challenge for humanoid robotics. Unlike standard locomotion or static manipulation, this task demands a seamless integration of explosive whole-body coordination and precise, timing-critical interception. While recent advances have achieved lifelike motion mimicry, bridging the gap between kinematic imitation and functional, physics-aware striking without compromising stylistic naturalness is non-trivial. To address this, we propose Imitation-to-Interaction, a progressive reinforcement learning framework designed to evolve a robot from a \"mimic\" to a capable \"striker.\" Our approach establishes a robust motor prior from human data, distills it into a compact, model-based state representation, and stabilizes dynamics via adversarial priors. Crucially, to overcome the sparsity of expert demonstrations, we introduce a manifold expansion strategy that generalizes discrete strike points into a dense interaction volume. We validate our framework through the mastery of diverse skills, including lifts and drop shots, in simulation. Furthermore, we demonstrate the first zero-shot sim-to-real transfer of anthropomorphic badminton skills to a humanoid robot, successfully replicating the kinetic elegance and functional precision of human athletes in the physical world."
  },
  {
    "date": "2026-02-09",
    "title": "MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval",
    "authors": "Xin Zhang, Kailai Yang, Chenyue Li, Hao Li, Qiyu Wei, Jun'ichi Tsujii, Sophia Ananiadou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08369v1",
    "source": "arXiv",
    "abstract": "Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retrieval framework that enables fast alignment across agent memory paradigms. MemAdapter adopts a two-stage training strategy: (1) training a generative subgraph retriever from the unified memory space, and (2) adapting the retriever to unseen memory paradigms by training a lightweight alignment module through contrastive learning. This design improves the flexibility for memory retrieval and substantially reduces alignment cost across paradigms. Comprehensive experiments on three public evaluation benchmarks demonstrate that the generative subgraph retriever consistently outperforms five strong agent memory systems across three memory paradigms and agent model scales. Notably, MemAdapter completes cross-paradigm alignment within 13 minutes on a single GPU, achieving superior performance over original memory retrievers with less than 5% of training compute. Furthermore, MemAdapter enables effective zero-shot fusion across memory paradigms, highlighting its potential as a plug-and-play solution for agent memory systems."
  },
  {
    "date": "2026-02-09",
    "title": "T2VTree: User-Centered Visual Analytics for Agent-Assisted Thought-to-Video Authoring",
    "authors": "Zhuoyun Zheng, Yu Dong, Gaorong Liang, Guan Li, Guihua Shan, Shiyu Cheng, Dong Tian, Jianlong Zhou, Jie Liang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08368v1",
    "source": "arXiv",
    "abstract": "Generative models have substantially expanded video generation capabilities, yet practical thought-to-video creation remains a multi-stage, multi-modal, and decision-intensive process. However, existing tools either hide intermediate decisions behind repeated reruns or expose operator-level workflows that make exploration traces difficult to manage, compare, and reuse. We present T2VTree, a user-centered visual analytics approach for agent-assisted thought-to-video authoring. T2VTree represents the authoring process as a tree visualization. Each node in the tree binds an editable specification (intent, referenced inputs, workflow choice, prompts, and parameters) with the resulting multimodal outputs, making refinement, branching, and provenance inspection directly operable. To reduce the burden of deciding what to do next, a set of collaborating agents translates step-level intent into an executable plan that remains visible and user-editable before execution. We further implement a visual analytics system that integrates branching authoring with in-place preview and stitching for convergent assembly, enabling end-to-end multi-scene creation without leaving the authoring context. We demonstrate T2VTreeVA through two multi-scene case studies and a comparative user study, showing how the T2VTree visualization and editable agent planning support reliable refinement, localized comparison, and practical reuse in real authoring workflows. T2VTree is available at: https://github.com/tezuka0210/T2VTree."
  },
  {
    "date": "2026-02-09",
    "title": "WorldTravel: A Realistic Multimodal Travel-Planning Benchmark with Tightly Coupled Constraints",
    "authors": "Zexuan Wang, Chenghao Yang, Yingqi Que, Zhenzhu Yang, Huaqing Yuan, Yiwen Wang, Zhengxuan Jiang, Shengjie Fang, Zhenhe Wu, Zhaohui Wang, Zhixin Yao, Jiashuo Liu, Jincheng Ren, Yuzhen Li, Yang Yang, Jiaheng Liu, Jian Yang, Zaiyuan Wang, Ge Zhang, Zhoufutu Wen, Wenhao Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08367v1",
    "source": "arXiv",
    "abstract": "Real-world autonomous planning requires coordinating tightly coupled constraints where a single decision dictates the feasibility of all subsequent actions. However, existing benchmarks predominantly feature loosely coupled constraints solvable through local greedy decisions and rely on idealized data, failing to capture the complexity of extracting parameters from dynamic web environments. We introduce \\textbf{WorldTravel}, a benchmark comprising 150 real-world travel scenarios across 5 cities that demand navigating an average of 15+ interdependent temporal and logical constraints. To evaluate agents in realistic deployments, we develop \\textbf{WorldTravel-Webscape}, a multi-modal environment featuring over 2,000 rendered webpages where agents must perceive constraint parameters directly from visual layouts to inform their planning. Our evaluation of 10 frontier models reveals a significant performance collapse: even the state-of-the-art GPT-5.2 achieves only 32.67\\% feasibility in text-only settings, which plummets to 19.33\\% in multi-modal environments. We identify a critical Perception-Action Gap and a Planning Horizon threshold at approximately 10 constraints where model reasoning consistently fails, suggesting that perception and reasoning remain independent bottlenecks. These findings underscore the need for next-generation agents that unify high-fidelity visual perception with long-horizon reasoning to handle brittle real-world logistics."
  },
  {
    "date": "2026-02-09",
    "title": "Direct Evidence of a Near-Ideal Jeff = 1/2 Ground State in Triangular-Lattice Na2BaCo(PO4)2",
    "authors": "M. M. Ferreira-Carvalho, S. H. Chen, Y. C. Ku, Anagha Jose, Ryan Morrow, C. Y. Kuo, C. F. Chang, Z. Hu, M. W. Haverkort, L. H. Tjeng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08361v1",
    "source": "arXiv",
    "abstract": "We investigated the local Co 3d electronic structure of Na2BaCo(PO4)2 using polarization-dependent X-ray absorption spectroscopy (XAS) in combination with full multiplet cluster calculations. We employed the line-fitting inverse partial fluorescence yield (IPFY) technique to obtain accurate XAS spectra from strong insulating materials. Our combined experimental and theoretical analysis reveals a very small effective trigonal distortion of only 11 meV in the CoO6 octahedra, indicating a close to ideal condition to render a ground state with the Jeff = 1/2 character. With our cluster model we were also able to simulate magnetic susceptibility measurements along different directions in the crystal. These findings highlight Na2BaCo(PO4)2 as a promising platform for exploring exotic magnetic phenomena associated with Jeff = 1/2 ground states on triangular lattices."
  },
  {
    "date": "2026-02-09",
    "title": "FIMPs in a two-component dark matter model with $Z_2 \\times Z_4$ symmetry",
    "authors": "XinXin Qi, Hao Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08359v1",
    "source": "arXiv",
    "abstract": "We consider the FIMPs scenario in a two-component dark matter model with $Z_2 \\times Z_4$ symmetry, where a singlet scalar $S$ and a Majorana fermion $χ$ are introduced as dark matter candidates. We also introduce another singlet scalar $S_0$ with a non-zero vacuum expectation value to the SM so that the fermion dark matter can obtain mass after spontaneous symmetry breaking. The model admits six free parameters in the decoupling limit: three masses and three dimensionless parameters. Depending on the mass hierarchies between dark matter particles with half of the new Higgs mass, the DM relic density will be determined by different channels, where $χ$ and $S$ production can be generated individually. We numerically study the relic density as a function of the model's free parameters and determine the regions consistent with the dark matter constraint for four possible cases. Our results show that this scenario is viable over a wide range of couplings and dark matter masses, where the coupling $λ_{ds}$ can be as tiny as $\\mathcal{O}(10^{-20})$ level. We stress that even for such tiny couplings, the new Higgs can still play a dominant role in determining dark matter production."
  },
  {
    "date": "2026-02-09",
    "title": "Towards Better Evolution Modeling for Temporal Knowledge Graphs",
    "authors": "Zhang Jiasheng, Li Zhangpin, Wang Mingzhe, Shao Jie, Cui Jiangtao, Li Hui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08353v1",
    "source": "arXiv",
    "abstract": "Temporal knowledge graphs (TKGs) structurally preserve evolving human knowledge. Recent research has focused on designing models to learn the evolutionary nature of TKGs to predict future facts, achieving impressive results. For instance, Hits@10 scores over 0.9 on YAGO dataset. However, we find that existing benchmarks inadvertently introduce a shortcut. Near state-of-the-art performance can be simply achieved by counting co-occurrences, without using any temporal information. In this work, we examine the root cause of this issue, identifying inherent biases in current datasets and over simplified form of evaluation task that can be exploited by these biases. Through this analysis, we further uncover additional limitations of existing benchmarks, including unreasonable formatting of time-interval knowledge, ignorance of learning knowledge obsolescence, and insufficient information for precise evolution understanding, all of which can amplify the shortcut and hinder a fair assessment. Therefore, we introduce the TKG evolution benchmark. It includes four bias-corrected datasets and two novel tasks closely aligned with the evolution process, promoting a more accurate understanding of the challenges in TKG evolution modeling. Benchmark is available at: https://github.com/zjs123/TKG-Benchmark."
  },
  {
    "date": "2026-02-09",
    "title": "The Chicken and Egg Dilemma: Co-optimizing Data and Model Configurations for LLMs",
    "authors": "Zhiliang Chen, Alfred Wei Lun Leong, Shao Yong Ong, Apivich Hemachandram, Gregory Kang Ruey Lau, Chuan-Sheng Foo, Zhengyuan Liu, Nancy F. Chen, Bryan Kian Hsiang Low",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08351v1",
    "source": "arXiv",
    "abstract": "Co-optimizing data and model configurations for training LLMs presents a classic chicken-and-egg dilemma: The best training data configuration (e.g., data mixture) for a downstream task depends on the chosen model configuration (e.g., model architecture), and vice versa. However, jointly optimizing both data and model configurations is often deemed intractable, and existing methods focus on either data or model optimization without considering their interaction. We introduce JoBS, an approach that uses a scaling-law-inspired performance predictor to aid Bayesian optimization (BO) in jointly optimizing LLM training data and model configurations efficiently. JoBS allocates a portion of the optimization budget to learn an LLM performance predictor that predicts how promising a training configuration is from a small number of training steps. The remaining budget is used to perform BO entirely with the predictor, effectively amortizing the cost of running full-training runs. We study JoBS's average regret and devise the optimal budget allocation to minimize regret. JoBS outperforms existing multi-fidelity BO baselines, as well as data and model optimization approaches across diverse LLM tasks under the same optimization budget."
  },
  {
    "date": "2026-02-09",
    "title": "All ERMs Can Fail in Stochastic Convex Optimization Lower Bounds in Linear Dimension",
    "authors": "Tal Burla, Roi Livni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08350v1",
    "source": "arXiv",
    "abstract": "We study the sample complexity of the best-case Empirical Risk Minimizer in the setting of stochastic convex optimization. We show that there exists an instance in which the sample size is linear in the dimension, learning is possible, but the Empirical Risk Minimizer is likely to be unique and to overfit. This resolves an open question by Feldman. We also extend this to approximate ERMs. Building on our construction we also show that (constrained) Gradient Descent potentially overfits when horizon and learning rate grow w.r.t sample size. Specifically we provide a novel generalization lower bound of $Ω\\left(\\sqrt{ηT/m^{1.5}}\\right)$ for Gradient Descent, where $η$ is the learning rate, $T$ is the horizon and $m$ is the sample size. This narrows down, exponentially, the gap between the best known upper bound of $O(ηT/m)$ and existing lower bounds from previous constructions."
  },
  {
    "date": "2026-02-09",
    "title": "The braided Doplicher-Roberts program and the Finkelberg-Kazhdan-Lusztig equivalence: A historical perspective, recent progress, and future directions",
    "authors": "Claudia Pinzari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08348v1",
    "source": "arXiv",
    "abstract": "Our recent approach to the Finkelberg-Kazhdan-Lusztig equivalence theorem centers on the construction of a fiber functor associated with the categories in the equivalence theorem, which in turn explains the underlying algebraic and analytic structure of the corresponding weak Hopf algebra in a new sense. We provide a non-technical and historical overview of the core arguments behind our proof, discuss these structural properties, and its applications to rigidity and unitarizability of braided fusion categories arising from conformal field theory. We conclude proposing some natural directions for future research."
  },
  {
    "date": "2026-02-09",
    "title": "ManifoldKV: Training-Free KV Cache Compression via Euclidean Outlier Detection",
    "authors": "Debajyoti Datta, Trishala Neeraj, Bibek Paudel, Vyom Sharma, Subhabrata Mukherjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08343v1",
    "source": "arXiv",
    "abstract": "Long-context inference is constrained by KV-cache memory, which grows linearly with sequence length; KV-cache compression therefore hinges on reliably selecting which past tokens to retain. Most geometry-based eviction methods score keys by cosine similarity to a global centroid, but cosine is scale-invariant and can discard magnitude cues that distinguish semantically salient tokens. We propose ManifoldKV, a training-free scorer that ranks tokens by Euclidean distance to the key centroid, capturing both angular and radial deviations. On the RULER benchmark, ManifoldKV achieves 95.7% accuracy at 4K-16K contexts with 20% compression; matching the best geometric baseline while improving robustness in two regimes where cosine scoring fails. First, on multi-key retrieval, ManifoldKV reduces directional collisions, achieving 92.4% vs KeyDiff's 77.0% (+15.4 points) on 3-key NIAH at 50% compression. Second, to address dilution and performance collapse of global centroids at 64K context, we introduce WindowedManifoldKV, which restores accuracy to 84.3% at 25% compression, a 49-point recovery over global L2 and +3.2 points over KeyDiff. The method requires only 3 lines of code and works across 4 architectures without tuning."
  },
  {
    "date": "2026-02-09",
    "title": "Regime Change Hypothesis: Foundations for Decoupled Dynamics in Neural Network Training",
    "authors": "Cristian Pérez-Corral, Alberto Fernández-Hernández, Jose I. Mestre, Manuel F. Dolz, Jose Duato, Enrique S. Quintana-Ortí",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08333v1",
    "source": "arXiv",
    "abstract": "Despite the empirical success of DNN, their internal training dynamics remain difficult to characterize. In ReLU-based models, the activation pattern induced by a given input determines the piecewise-linear region in which the network behaves affinely. Motivated by this geometry, we investigate whether training exhibits a two-timescale behavior: an early stage with substantial changes in activation patterns and a later stage where weight updates predominantly refine the model within largely stable activation regimes. We first prove a local stability property: outside measure-zero sets of parameters and inputs, sufficiently small parameter perturbations preserve the activation pattern of a fixed input, implying locally affine behavior within activation regions. We then empirically track per-iteration changes in weights and activation patterns across fully-connected and convolutional architectures, as well as Transformer-based models, where activation patterns are recorded in the ReLU feed-forward (MLP/FFN) submodules, using fixed validation subsets. Across the evaluated settings, activation-pattern changes decay 3 times earlier than weight-update magnitudes, showing that late-stage training often proceeds within relatively stable activation regimes. These findings provide a concrete, architecture-agnostic instrument for monitoring training dynamics and motivate further study of decoupled optimization strategies for piecewise-linear networks. For reproducibility, code and experiment configurations will be released upon acceptance."
  },
  {
    "date": "2026-02-09",
    "title": "Latent Reasoning with Supervised Thinking States",
    "authors": "Ido Amos, Avi Caciularu, Mor Geva, Amir Globerson, Jonathan Herzig, Lior Shani, Idan Szpektor",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08332v1",
    "source": "arXiv",
    "abstract": "Reasoning with a chain-of-thought (CoT) enables Large Language Models (LLMs) to solve complex tasks but incurs significant inference costs due to the generation of long rationales. We propose Thinking States, a method that performs reasoning {\\em while} the input is processing. Specifically, Thinking States generates sequences of thinking tokens every few input tokens, transforms the thoughts back into embedding space, and adds them to the following input tokens. This has two key advantages. First, it captures the recurrent nature of CoT, but where the thought tokens are generated as input is processing. Second, since the thoughts are represented as tokens, they can be learned from natural language supervision, and using teacher-forcing, which is parallelizable. Empirically, Thinking States outperforms other latent reasoning methods on multiple reasoning tasks, narrowing the gap to CoT on math problems, and matching its performance on 2-Hop QA with improved latency. On state-tracking tasks, we show Thinking States leads to stronger reasoning behavior than CoT, successfully extrapolating to longer sequences than seen during training."
  },
  {
    "date": "2026-02-09",
    "title": "Forced oscillation of a damped BBM equation posed on whole line in low regularity spaces",
    "authors": "Chun Ho Lau, Taige Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08327v1",
    "source": "arXiv",
    "abstract": "In this manuscript, we would established in low regularity spaces $H^\\ell, \\ell\\in [0,1)$, the existence and stability results of time-periodic solution of 1D Cauchy problem of forced damped Benjamin-Bona-Mahony equation (BBM). We use estimates from I-energy method to derive needed estimates in $H^\\ell$ for the linearized problem, then convection term will be treated as perturbation of linear problem such that original Cauchy problem is solved."
  },
  {
    "date": "2026-02-09",
    "title": "Towards Efficient Large Language Reasoning Models via Extreme-Ratio Chain-of-Thought Compression",
    "authors": "Yuntian Tang, Bohan Jia, Wenxuan Huang, Lianyue Zhang, Jiao Xie, Wenxi Li, Wei Li, Jie Hu, Xinghao Chen, Rongrong Ji, Shaohui Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08324v1",
    "source": "arXiv",
    "abstract": "Chain-of-Thought (CoT) reasoning successfully enhances the reasoning capabilities of Large Language Models (LLMs), yet it incurs substantial computational overhead for inference. Existing CoT compression methods often suffer from a critical loss of logical fidelity at high compression ratios, resulting in significant performance degradation. To achieve high-fidelity, fast reasoning, we propose a novel EXTreme-RAtio Chain-of-Thought Compression framework, termed Extra-CoT, which aggressively reduces the token budget while preserving answer accuracy. To generate reliable, high-fidelity supervision, we first train a dedicated semantically-preserved compressor on mathematical CoT data with fine-grained annotations. An LLM is then fine-tuned on these compressed pairs via a mixed-ratio supervised fine-tuning (SFT), teaching it to follow a spectrum of compression budgets and providing a stable initialization for reinforcement learning (RL). We further propose Constrained and Hierarchical Ratio Policy Optimization (CHRPO) to explicitly incentivize question-solving ability under lower budgets by a hierarchical reward. Experiments on three mathematical reasoning benchmarks show the superiority of Extra-CoT. For example, on MATH-500 using Qwen3-1.7B, Extra-CoT achieves over 73\\% token reduction with an accuracy improvement of 0.6\\%, significantly outperforming state-of-the-art (SOTA) methods."
  },
  {
    "date": "2026-02-09",
    "title": "Neutrino Emission from Gamma-ray Burst Jet Propagating inside the Cavity within Active Galactic Nucleus Accretion Disks",
    "authors": "Hao-Yu Yuan, Wen-Long Xu, Kai Wang, Wei-Hua Lei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08319v1",
    "source": "arXiv",
    "abstract": "Short gamma-ray bursts (sGRBs) from the merger of binary compact objects (BCOs) could occur in the accretion disks of the active galactic nucleus (AGN). Before merging, the BCO will inevitably form a low-density cavity. The sGRB jet will interact with the AGN disk photons during its propagation through the cavity, leading to unique electromagnetic and neutrino signatures. In this work, we investigate the influence of the AGN disk photon field on neutrino emission within the internal dissipation regions of a two-component sGRB jet (a narrow core and a wide wing). We find that, due to the strong AGN disk photon field, the neutrino flux at high-energy part (e.g., PeV to EeV) will be suppressed, while the relatively lower-energy part (e.g., TeV to PeV) will be enhanced. Such a conclusion can enhance the constraints on GRB parameters (e.g., baryonic loading factor and bulk Lorentz factor) based on the future detection or non-detection of high-energy neutrinos from GRBs. Besides, the two-component jet can display two-bump structure at higher and lower energy in the neutrino spectrum. Therefore, the joint observations of electromagnetic and neutrinos emission can help us identify the sGRB jet and its structure in the AGN disk."
  },
  {
    "date": "2026-02-09",
    "title": "Interaction-Grounded Learning for Contextual Markov Decision Processes with Personalized Feedback",
    "authors": "Mengxiao Zhang, Yuheng Zhang, Haipeng Luo, Paul Mineiro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08307v1",
    "source": "arXiv",
    "abstract": "In this paper, we study Interaction-Grounded Learning (IGL) [Xie et al., 2021], a paradigm designed for realistic scenarios where the learner receives indirect feedback generated by an unknown mechanism, rather than explicit numerical rewards. While prior work on IGL provides efficient algorithms with provable guarantees, those results are confined to single-step settings, restricting their applicability to modern sequential decision-making systems such as multi-turn Large Language Model (LLM) deployments. To bridge this gap, we propose a computationally efficient algorithm that achieves a sublinear regret guarantee for contextual episodic Markov Decision Processes (MDPs) with personalized feedback. Technically, we extend the reward-estimator construction of Zhang et al. [2024a] from the single-step to the multi-step setting, addressing the unique challenges of decoding latent rewards under MDPs. Building on this estimator, we design an Inverse-Gap-Weighting (IGW) algorithm for policy optimization. Finally, we demonstrate the effectiveness of our method in learning personalized objectives from multi-turn interactions through experiments on both a synthetic episodic MDP and a real-world user booking dataset."
  },
  {
    "date": "2026-02-09",
    "title": "Cyclic Adaptive Private Synthesis for Sharing Real-World Data in Education",
    "authors": "Hibiki Ito, Chia-Yu Hsu, Hiroaki Ogata",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08299v1",
    "source": "arXiv",
    "abstract": "The rapid adoption of digital technologies has greatly increased the volume of real-world data (RWD) in education. While these data offer significant opportunities for advancing learning analytics (LA), secondary use for research is constrained by privacy concerns. Differentially private synthetic data generation is regarded as the gold-standard approach to sharing sensitive data, yet studies on the private synthesis of educational data remain very scarce and rely predominantly on large, low-dimensional open datasets. Educational RWD, however, are typically high-dimensional and small in sample size, leaving the potential of private synthesis underexplored. Moreover, because educational practice is inherently iterative, data sharing is continual rather than one-off, making a traditional one-shot synthesis approach suboptimal. To address these challenges, we propose the Cyclic Adaptive Private Synthesis (CAPS) framework and evaluate it on authentic RWD. By iteratively sharing RWD, CAPS not only fosters open science, but also offers rich opportunities of design-based research (DBR), thereby amplifying the impact of LA. Our case study using actual RWD demonstrates that CAPS outperforms a one-shot baseline while highlighting challenges that warrant further investigation. Overall, this work offers a crucial first step towards privacy-preserving sharing of educational RWD and expands the possibilities for open science and DBR in LA."
  },
  {
    "date": "2026-02-09",
    "title": "Trust-Based Incentive Mechanisms in Semi-Decentralized Federated Learning Systems",
    "authors": "Ajay Kumar Shrestha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08290v1",
    "source": "arXiv",
    "abstract": "In federated learning (FL), decentralized model training allows multi-ple participants to collaboratively improve a shared machine learning model without exchanging raw data. However, ensuring the integrity and reliability of the system is challenging due to the presence of potentially malicious or faulty nodes that can degrade the model's performance. This paper proposes a novel trust-based incentive mechanism designed to evaluate and reward the quality of contributions in FL systems. By dynamically assessing trust scores based on fac-tors such as data quality, model accuracy, consistency, and contribution fre-quency, the system encourages honest participation and penalizes unreliable or malicious behavior. These trust scores form the basis of an incentive mechanism that rewards high-trust nodes with greater participation opportunities and penal-ties for low-trust participants. We further explore the integration of blockchain technology and smart contracts to automate the trust evaluation and incentive distribution processes, ensuring transparency and decentralization. Our proposed theoretical framework aims to create a more robust, fair, and transparent FL eco-system, reducing the risks posed by untrustworthy participants."
  },
  {
    "date": "2026-02-09",
    "title": "Knowledge Augmented Entity and Relation Extraction for Legal Documents with Hypergraph Neural Network",
    "authors": "Binglin Wu, Xianneng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08289v1",
    "source": "arXiv",
    "abstract": "With the continuous progress of digitization in Chinese judicial institutions, a substantial amount of electronic legal document information has been accumulated. To unlock its potential value, entity and relation extraction for legal documents has emerged as a crucial task. However, existing methods often lack domain-specific knowledge and fail to account for the unique characteristics of the judicial domain. In this paper, we propose an entity and relation extraction algorithm based on hypergraph neural network (Legal-KAHRE) for drug-related judgment documents. Firstly, we design a candidate span generator based on neighbor-oriented packing strategy and biaffine mechanism, which identifies spans likely to contain entities. Secondly, we construct a legal dictionary with judicial domain knowledge and integrate it into text encoding representation using multi-head attention. Additionally, we incorporate domain-specific cases like joint crimes and combined punishment for multiple crimes into the hypergraph structure design. Finally, we employ a hypergraph neural network for higher-order inference via message passing. Experimental results on the CAIL2022 information extraction dataset demonstrate that our method significantly outperforms existing baseline models."
  },
  {
    "date": "2026-02-09",
    "title": "Noise Stability of Transformer Models",
    "authors": "Themistoklis Haris, Zihan Zhang, Yuichi Yoshida",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08287v1",
    "source": "arXiv",
    "abstract": "Understanding simplicity biases in deep learning offers a promising path toward developing reliable AI. A common metric for this, inspired by Boolean function analysis, is average sensitivity, which captures a model's robustness to single-token perturbations. We argue that average sensitivity has two key limitations: it lacks a natural generalization to real-valued domains and fails to explain the \"junta-like\" input dependence we empirically observe in modern LLMs. To address these limitations, we propose noise stability as a more comprehensive simplicity metric. Noise stability expresses a model's robustness to correlated noise applied to all input coordinates simultaneously. We provide a theoretical analysis of noise stability for single-layer attention and ReLU MLP layers and tackle the multi-layer propagation problem with a covariance interval propagation approach. Building on this theory, we develop a practical noise stability regularization method. Experiments on algorithmic and next-token-prediction tasks show that our regularizer consistently catalyzes grokking and accelerates training by approximately $35\\%$ and $75\\%$ respectively. Our results sculpt a new connection between signal propagation in neural networks and interpretability, with noise stability emerging as a powerful tool for understanding and improving modern Transformers."
  },
  {
    "date": "2026-02-09",
    "title": "New Skills or Sharper Primitives? A Probabilistic Perspective on the Emergence of Reasoning in RLVR",
    "authors": "Zhilin Wang, Yafu Li, Shunkai Zhang, Zhi Wang, Haoran Zhang, Xiaoye Qu, Yu Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08281v1",
    "source": "arXiv",
    "abstract": "Whether Reinforcement Learning with Verifiable Rewards (RLVR) endows Large Language Models (LLMs) with new capabilities or merely elicits latent traces remains a central debate. In this work, we align with the former view, proposing a probabilistic framework where capability is defined by instance-level solvability. We hypothesize that the emergence of complex reasoning can be driven by sharpening atomic step probabilities, which enables models to overcome the exponential decay of success rates inherent in multi-step reasoning chains. Utilizing the Algebrarium framework, we train models exclusively on single-step operations and evaluate their performance on unseen multi-step tasks. Our empirical results confirm that: (1) RLVR incentivizes the exploration of previously inaccessible solution paths by amplifying the model's existing skills; (2) composite performance is strictly governed by the joint probability of atomic steps, evidenced by high Pearson correlation coefficients ($ρ\\in [0.69, 0.96]$); and (3) RLVR, acting as a global optimizer, can cause specific skills to be sacrificed to maximize aggregate reward. Our work offers a novel explanation for emergent abilities in RLVR, suggesting that the iterative optimization of solvable problems enables models to develop the capabilities to tackle previously unsolvable scenarios."
  },
  {
    "date": "2026-02-09",
    "title": "PISCO: Precise Video Instance Insertion with Sparse Control",
    "authors": "Xiangbo Gao, Renjie Li, Xinghao Chen, Yuheng Wu, Suofei Feng, Qing Yin, Zhengzhong Tu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08277v1",
    "source": "arXiv",
    "abstract": "The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on exhaustive prompt-engineering and \"cherry-picking\" - towards fine-grained, controllable generation and high-fidelity post-processing. In professional AI-assisted filmmaking, it is crucial to perform precise, targeted modifications. A cornerstone of this transition is video instance insertion, which requires inserting a specific instance into existing footage while maintaining scene integrity. Unlike traditional video editing, this task demands several requirements: precise spatial-temporal placement, physically consistent scene interaction, and the faithful preservation of original dynamics - all achieved under minimal user effort. In this paper, we propose PISCO, a video diffusion model for precise video instance insertion with arbitrary sparse keyframe control. PISCO allows users to specify a single keyframe, start-and-end keyframes, or sparse keyframes at arbitrary timestamps, and automatically propagates object appearance, motion, and interaction. To address the severe distribution shift induced by sparse conditioning in pretrained video diffusion models, we introduce Variable-Information Guidance for robust conditioning and Distribution-Preserving Temporal Masking to stabilize temporal generation, together with geometry-aware conditioning for realistic scene adaptation. We further construct PISCO-Bench, a benchmark with verified instance annotations and paired clean background videos, and evaluate performance using both reference-based and reference-free perceptual metrics. Experiments demonstrate that PISCO consistently outperforms strong inpainting and video editing baselines under sparse control, and exhibits clear, monotonic performance improvements as additional control signals are provided. Project page: xiangbogaobarry.github.io/PISCO."
  },
  {
    "date": "2026-02-09",
    "title": "Irreducible objects in the Gaiotto category at roots of unity",
    "authors": "Aleksandr Popkovich",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08264v1",
    "source": "arXiv",
    "abstract": "A theorem of R. Travkin and R. Yang, initially conjectured by D. Gaiotto, states that for a generic (not a root of unity) $q$ the category of $q$-twisted D-modules on the affine Grassmannian $Gr_{GL_N}$ which are equivariant with respect to a certain subgroup (defined by a choice of $0 \\le M <N$) of $GL_N$ is equivalent to the category of representations of the quantum supergroup $U_q(\\mathfrak{gl}(M|N))$. We aim to see whether this equivalence should hold when $q$ is a root of unity. We begin by asking if there is a natural bijection between the sets of irreducible objects. In this note we make an observation that suggests this should be the case: we show that there is a natural bijection between irreducible objects in the Gaiotto category and in the category of representations of a supergroup $GL(M|N)$ in positive characteristic. The proof is based on the version of the Serganova's algorithm formulated by J. Brundan and J. Kujawa in arXiv:math/0210108."
  },
  {
    "date": "2026-02-09",
    "title": "Specification Vibing for Automated Program Repair",
    "authors": "Taohong Zhu, Lucas C. Cordeiro, Mustafa A. Mustafa, Youcheng Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08263v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM)-driven automated program repair (APR) has advanced rapidly, but most methods remain code-centric: they directly rewrite source code and thereby risk hallucinated, behaviorally inconsistent fixes. This limitation suggests the need for an alternative repair paradigm that relies on a representation more accessible to LLMs than raw code, enabling more accurate understanding, analysis, and alignment during repair. To address this gap, we propose VibeRepair, a specification-centric APR technique that treats repair as behavior-specification repair rather than ad-hoc code editing. VibeRepair first translates buggy code into a structured behavior specification that captures the program's intended runtime behavior, then infers and repairs specification misalignments, and finally synthesizes code strictly guided by the corrected behavior specification. An on-demand reasoning component enriches hard cases with program analysis and historical bug-fix evidence while controlling cost. Across Defects4J and real-world benchmarks and multiple LLMs, VibeRepair demonstrates consistently strong repair effectiveness with a significantly smaller patch space. On Defects4J v1.2, VibeRepair correctly repairs 174 bugs, exceeding the strongest state-of-the-art baseline by 28 bugs, which corresponds to a 19% improvement. On Defects4J v2.0, it repairs 178 bugs, outperforming prior approaches by 33 bugs, representing a 23% improvement. Evaluations on real-world benchmarks collected after the training period of selected LLMs further confirm its effectiveness and generalizability. By centering repair on explicit behavioral intent, VibeRepair reframes APR for the era of \"vibe\" coding: make the behavior sing, and the code will follow."
  },
  {
    "date": "2026-02-09",
    "title": "Moving Beyond Functional Connectivity: Time-Series Modeling for fMRI-Based Brain Disorder Classification",
    "authors": "Guoqi Yu, Xiaowei Hu, Angelica I. Aviles-Rivero, Anqi Qiu, Shujun Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08262v1",
    "source": "arXiv",
    "abstract": "Functional magnetic resonance imaging (fMRI) enables non-invasive brain disorder classification by capturing blood-oxygen-level-dependent (BOLD) signals. However, most existing methods rely on functional connectivity (FC) via Pearson correlation, which reduces 4D BOLD signals to static 2D matrices, discarding temporal dynamics and capturing only linear inter-regional relationships. In this work, we benchmark state-of-the-art temporal models (e.g., time-series models such as PatchTST, TimesNet, and TimeMixer) on raw BOLD signals across five public datasets. Results show these models consistently outperform traditional FC-based approaches, highlighting the value of directly modeling temporal information such as cycle-like oscillatory fluctuations and drift-like slow baseline trends. Building on this insight, we propose DeCI, a simple yet effective framework that integrates two key principles: (i) Cycle and Drift Decomposition to disentangle cycle and drift within each ROI (Region of Interest); and (ii) Channel-Independence to model each ROI separately, improving robustness and reducing overfitting. Extensive experiments demonstrate that DeCI achieves superior classification accuracy and generalization compared to both FC-based and temporal baselines. Our findings advocate for a shift toward end-to-end temporal modeling in fMRI analysis to better capture complex brain dynamics. The code is available at https://github.com/Levi-Ackman/DeCI."
  },
  {
    "date": "2026-02-09",
    "title": "Language Predicts Identity Fusion Across Cultures and Reveals Divergent Pathways to Violence",
    "authors": "Devin R. Wright, Justin E. Lane, F. LeRon Shults",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08252v1",
    "source": "arXiv",
    "abstract": "In light of increasing polarization and political violence, understanding the psychological roots of extremism is increasingly important. Prior research shows that identity fusion predicts willingness to engage in extreme acts. We evaluate the Cognitive Linguistic Identity Fusion Score, a method that uses cognitive linguistic patterns, LLMs, and implicit metaphor to measure fusion from language. Across datasets from the United Kingdom and Singapore, this approach outperforms existing methods in predicting validated fusion scores. Applied to extremist manifestos, two distinct high-fusion pathways to violence emerge: ideologues tend to frame themselves in terms of group, forming kinship bonds; whereas grievance-driven individuals frame the group in terms of their personal identity. These results refine theories of identity fusion and provide a scalable tool aiding fusion research and extremism detection."
  },
  {
    "date": "2026-02-09",
    "title": "Aerial Manipulation with Contact-Aware Onboard Perception and Hybrid Control",
    "authors": "Yuanzhu Zhan, Yufei Jiang, Muqing Cao, Junyi Geng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08251v1",
    "source": "arXiv",
    "abstract": "Aerial manipulation (AM) promises to move Unmanned Aerial Vehicles (UAVs) beyond passive inspection to contact-rich tasks such as grasping, assembly, and in-situ maintenance. Most prior AM demonstrations rely on external motion capture (MoCap) and emphasize position control for coarse interactions, limiting deployability. We present a fully onboard perception-control pipeline for contact-rich AM that achieves accurate motion tracking and regulated contact wrenches without MoCap. The main components are (1) an augmented visual-inertial odometry (VIO) estimator with contact-consistency factors that activate only during interaction, tightening uncertainty around the contact frame and reducing drift, and (2) image-based visual servoing (IBVS) to mitigate perception-control coupling, together with a hybrid force-motion controller that regulates contact wrenches and lateral motion for stable contact. Experiments show that our approach closes the perception-to-wrench loop using only onboard sensing, yielding an velocity estimation improvement of 66.01% at contact, reliable target approach, and stable force holding-pointing toward deployable, in-the-wild aerial manipulation."
  },
  {
    "date": "2026-02-09",
    "title": "Infrared photonics for healthcare: A roadmap for proactive and predictive health management",
    "authors": "Borislav Hinkov, Johannes Kunsch, Werner Mäntele, Lukasz Sterczewski, Ángel Sánchez-Illana, Jaume Béjar-Grimalt, Víctor Navarro-Esteve, David Perez-Guaita, Alexander Mittelstädt, Philippa Clark, Valentino Lepro, Sergius Janik, Thorsten Lubinski, Luis Felipe das Chagas e Silva de Carvalho, Hugh James Byrne, Filiz Korkmaz, Michael Kaluza, Mattia Saita, Lars Melchior, Alicja Dabrowska, Georg Ramer, Bernhard Lendl, Nathalie Woitzik, Klaus Gerwert, Peter Gardner, Hugues Tariel, Olivier Sire, Margaux Petay, Elisabeth Holub, Markus Brandstetter, Kristina Duswald, Verena Karl, Florian Meirer, Lukas Kenner, Gabriela Flores Rangel, Boris Mizaikoff, Mohamed Sy, Aamir Farooq, Liudmila Voronina, Marinus Huber, Tarek Eissa, Katharina Dietmann, Lorenzo Gatto, Mihaela Žigman, Joseph Rebel, Frank Fleischmann, Jakub Mnich, Jarosław Sotor, Bassam Saadany, Matthias Budden, Thomas Gebert, Marco Schossig, Shankar Baliga, Timothy Olsen, Christopher Harrower, Ivan Zorin, Chiara Lindner, Shigeki Takeuchi, Sven Ramelow, Paul Gattinger, David Stark, Réka-Eszter Vass, Killian Keller, Alessio Cargioli, Mattias Beck, Jérôme Faist, Robert Weih, Josephine Nauschütz, Julian Scheuermann, Jordan Fordyce, Johannes Koeth, Ka Fai Mak, Alexander Weigel, Ryszard Piramidowicz, Stanisław Stopiński, Mircea Guina, Jukka Viheriälä, Felix Jaeschke, Polina Fomina, Alexander Novikov, Viacheslav Artyushenko, Ivan Sinev, Nikita Glebov, Berkay Dagli, Hatice Altug",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08248v1",
    "source": "arXiv",
    "abstract": "The field of infrared (IR) photonics is currently undergoing remarkable progress, moving rapidly towards practical sensing applications demanded by medical therapy and diagnostics (theranostics). The Developments can be divided into three main categories: (i) novel devices and measurement concepts including advanced updates of classical approaches that push medical sensing into the spotlight; (ii) new demonstrations of photonic integrated circuit (PIC-)based IR devices enabling highly miniaturized sensors for point-of-care application as well as medical and wellness wearables; and (iii) technologically-mature IR demonstrators that enable first medical sensing and treatment applications. This roadmap paper provides a consolidated overview of this highly dynamic and interdisciplinary research field with a focus on the major roadblocks that limit the widespread adoption of IR photonics in large-scale medical diagnostics. Special attention is given to the ambivalence between the molecular-level spectroscopic interpretation and a broader health-state assessment, highlighting the need for a common framework. Additionally, the paper discusses the critical importance of unified measurement standards, calibration protocols, and medical certification processes to ensure the validity of experimental results, reproducibility, and clinical trust, particularly when novel experimental techniques and AI algorithms are involved. Perspectives from major past and current contributors to application-oriented IR photonics will be provided."
  },
  {
    "date": "2026-02-09",
    "title": "Learning in Context, Guided by Choice: A Reward-Free Paradigm for Reinforcement Learning with Transformers",
    "authors": "Juncheng Dong, Bowen He, Moyang Guo, Ethan X. Fang, Zhuoran Yang, Vahid Tarokh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08244v1",
    "source": "arXiv",
    "abstract": "In-context reinforcement learning (ICRL) leverages the in-context learning capabilities of transformer models (TMs) to efficiently generalize to unseen sequential decision-making tasks without parameter updates. However, existing ICRL methods rely on explicit reward signals during pretraining, which limits their applicability when rewards are ambiguous, hard to specify, or costly to obtain. To overcome this limitation, we propose a new learning paradigm, In-Context Preference-based Reinforcement Learning (ICPRL), in which both pretraining and deployment rely solely on preference feedback, eliminating the need for reward supervision. We study two variants that differ in the granularity of feedback: Immediate Preference-based RL (I-PRL) with per-step preferences, and Trajectory Preference-based RL (T-PRL) with trajectory-level comparisons. We first show that supervised pretraining, a standard approach in ICRL, remains effective under preference-only context datasets, demonstrating the feasibility of in-context reinforcement learning using only preference signals. To further improve data efficiency, we introduce alternative preference-native frameworks for I-PRL and T-PRL that directly optimize TM policies from preference data without requiring reward signals nor optimal action labels.Experiments on dueling bandits, navigation, and continuous control tasks demonstrate that ICPRL enables strong in-context generalization to unseen tasks, achieving performance comparable to ICRL methods trained with full reward supervision."
  },
  {
    "date": "2026-02-09",
    "title": "PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition",
    "authors": "Xun Su, Huamin Wang, Qi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08240v1",
    "source": "arXiv",
    "abstract": "Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven nature; however, their integration with continuous Self-Supervised Learning (SSL) representations is fundamentally challenged by distribution mismatch, where high-dynamic-range embeddings degrade the information coding capacity of threshold-based neurons. To resolve this, we propose Prompt-Tuned Spiking Neural Networks (PTS-SNN), a parameter-efficient neuromorphic adaptation framework that aligns frozen SSL backbones with spiking dynamics. Specifically, we introduce a Temporal Shift Spiking Encoder to capture local temporal dependencies via parameter-free channel shifts, establishing a stable feature basis. To bridge the domain gap, we devise a Context-Aware Membrane Potential Calibration strategy. This mechanism leverages a Spiking Sparse Linear Attention module to aggregate global semantic context into learnable soft prompts, which dynamically regulate the bias voltages of Parametric Leaky Integrate-and-Fire (PLIF) neurons. This regulation effectively centers the heterogeneous input distribution within the responsive firing range, mitigating functional silence or saturation. Extensive experiments on five multilingual datasets (e.g., IEMOCAP, CASIA, EMODB) demonstrate that PTS-SNN achieves 73.34\\% accuracy on IEMOCAP, comparable to competitive Artificial Neural Networks (ANNs), while requiring only 1.19M trainable parameters and 0.35 mJ inference energy per sample."
  },
  {
    "date": "2026-02-09",
    "title": "InfiCoEvalChain: A Blockchain-Based Decentralized Framework for Collaborative LLM Evaluation",
    "authors": "Yifan Yang, Jinjia Li, Kunxi Li, Puhao Zheng, Yuanyi Wang, Zheyan Qu, Yang Yu, Jianmin Wu, Ming Li, Hongxia Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08229v1",
    "source": "arXiv",
    "abstract": "The rapid advancement of large language models (LLMs) demands increasingly reliable evaluation, yet current centralized evaluation suffers from opacity, overfitting, and hardware-induced variance. Our empirical analysis reveals an alarming inconsistency in existing evaluations: the standard deviation across ten repeated runs of a single model on HumanEval (1.67) actually exceeds the performance gap among the top-10 models on the official leaderboard (0.91), rendering current rankings statistically precarious. To mitigate these instabilities, we propose a decentralized evaluation framework that enables hardware and parameter diversity through large-scale benchmarking across heterogeneous compute nodes. By leveraging the blockchain-based protocol, the framework incentivizes global contributors to act as independent validators, using a robust reward system to ensure evaluation integrity and discourage dishonest participation. This collective verification transforms evaluation from a \"centralized black box\" into a \"decentralized endorsement\" where multi-party consensus and diverse inference environments yield a more stable, representative metric. Experimental results demonstrate that the decentralized evaluation framework reduces the standard deviation across ten runs on the same model to 0.28. This significant improvement over conventional frameworks ensures higher statistical confidence in model rankings. We have completely implemented this platform and will soon release it to the community."
  },
  {
    "date": "2026-02-09",
    "title": "Riemannian Manifold Optimization for Advanced Wireless Communications: Fundamentals and Applications",
    "authors": "Siwen Li, Jiacheng Chen, Yunting Xu, Shaofeng Li, Le Yao, Jieling Wang, Dusit Niyato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08225v1",
    "source": "arXiv",
    "abstract": "Next-generation wireless communications promise transformative technologies such as massive multiple-input multiple-output (MIMO), reconfigurable intelligent surfaces (RIS), integrated sensing and communication (ISAC), and fluid antenna systems (FAS). However, deploying these technologies is hindered by large-scale optimization problems with nonconvex constraints. Conventional Euclidean-space methods rely on approximations or relaxations, which degrade performance and incur substantial computational costs. Riemannian manifold optimization (RMO) offers a powerful alternative that directly operates on the manifold defined by the geometric constraints. This approach inherently satisfies the constraints at every optimization step, thereby avoiding the performance degradation and substantial computational costs. In this paper, we first elaborate on the principles of RMO, including the fundamental concepts, tools, and methods, emphasizing its effectiveness for nonconvex problems. We then introduce its applications in advanced wireless communications, showing how constrained problems are reformulated on their natural manifolds and solved using tailored RMO algorithms. Furthermore, we present a case study on secure beamforming in an FAS-assisted non-orthogonal multiple access (NOMA) system, demonstrating RMO's superiority over conventional methods in terms of both performance and computational efficiency."
  },
  {
    "date": "2026-02-09",
    "title": "Efficient-SAM2: Accelerating SAM2 with Object-Aware Visual Encoding and Memory Retrieval",
    "authors": "Jing Zhang, Zhikai Li, Xuewen Liu, Qingyi Gu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08224v1",
    "source": "arXiv",
    "abstract": "Segment Anything Model 2 (SAM2) shows excellent performance in video object segmentation tasks; however, the heavy computational burden hinders its application in real-time video processing. Although there have been efforts to improve the efficiency of SAM2, most of them focus on retraining a lightweight backbone, with little exploration into post-training acceleration. In this paper, we observe that SAM2 exhibits sparse perception pattern as biological vision, which provides opportunities for eliminating redundant computation and acceleration: i) In mask decoder, the attention primarily focuses on the foreground objects, whereas the image encoder in the earlier stage exhibits a broad attention span, which results in unnecessary computation to background regions. ii) In memory bank, only a small subset of tokens in each frame contribute significantly to memory attention, and the salient regions exhibit temporal consistency, making full-token computation redundant. With these insights, we propose Efficient-SAM2, which promotes SAM2 to adaptively focus on object regions while eliminating task-irrelevant computations, thereby significantly improving inference efficiency. Specifically, for image encoder, we propose object-aware Sparse Window Routing (SWR), a window-level computation allocation mechanism that leverages the consistency and saliency cues from the previous-frame decoder to route background regions into a lightweight shortcut branch. Moreover, for memory attention, we propose object-aware Sparse Memory Retrieval (SMR), which allows only the salient memory tokens in each frame to participate in computation, with the saliency pattern reused from their first recollection. With negligible additional parameters and minimal training overhead, Efficient-SAM2 delivers 1.68x speedup on SAM2.1-L model with only 1.0% accuracy drop on SA-V test set."
  },
  {
    "date": "2026-02-09",
    "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger",
    "authors": "Zehao Chen, Gongxun Li, Tianxiang Ai, Yifei Li, Zixuan Huang, Wang Zhou, Fuzhen Zhuang, Xianglong Liu, Jianxin Li, Deqing Wang, Yikun Ban",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08222v1",
    "source": "arXiv",
    "abstract": "As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning, WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost."
  },
  {
    "date": "2026-02-09",
    "title": "Preparing squeezed, cat and GKP states with parity measurements",
    "authors": "Zhiyuan Lin, Sen Li, Jingyan Feng, Valentin Ivannikov, Matteo Fadel, Tim Byrnes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08209v1",
    "source": "arXiv",
    "abstract": "Bosonic modes constitute a central resource in a wide range of quantum technologies, providing long-lived degrees of freedom for the storage, processing, and transduction of quantum information. Such modes naturally arise in platforms including circuit quantum electrodynamics, quantum acoustodynamics, and trapped-ion systems. In these architectures, coherent control and high-fidelity readout of the bosonic degrees of freedom are achieved via coupling to an auxiliary qubit. When operated in the strong dispersive regime, this interaction enables parity measurements of the mode which, in combination with phase-space displacements, constitute a standard experimental tool for full Wigner-function tomography. Here, we propose a protocol based on displaced parity measurements that allows for the preparation of a variety of bosonic quantum states. As a first example, we demonstrate the generation of squeezed states, achieving up to ~9 dB of squeezing after only three parity measurements, and show that the protocol is robust against experimental imperfections. Finally, we generalize our approach to the preparation of other paradigmatic bosonic states, including cat and Gottesman-Kitaev-Preskill states."
  },
  {
    "date": "2026-02-09",
    "title": "LocDreamer: World Model-Based Learning for Joint Indoor Tracking and Anchor Scheduling",
    "authors": "Geng Wang, Zhouyou Gu, Shenghong Li, Peng Cheng, Jihong Park, Branka Vucetic, Yonghui Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08204v1",
    "source": "arXiv",
    "abstract": "Accurate, resource-efficient localization and tracking enables numerous location-aware services in next-generation wireless networks. However, existing machine learning-based methods often require large labeled datasets while overlooking spectrum and energy efficiencies. To fill this gap, we propose LocDreamer, a world model (WM)-based framework for joint target tracking and scheduling of localization anchors. LocDreamer learns a WM that captures the latent representation of the target motion and localization environment, thereby generating synthetic measurements to imagine arbitrary anchor deployments. These measurements enable imagination-driven training of both the tracking model and the reinforcement learning (RL)-based anchor scheduler that activates only the most informative anchors, which significantly reduce energy and signaling costs while preserving high tracking accuracy. Experiments on a real-world indoor dataset demonstrate that LocDreamer substantially improves data efficiency and generalization, outperforming conventional Bayesian filter with random scheduling by 37% in tracking accuracy, and achieving 86% of the accuracy of same model trained directly on real data."
  },
  {
    "date": "2026-02-09",
    "title": "Finger Tendon Vibration: Finger Movement Illusions for Immersive Virtual Object Interaction",
    "authors": "Kun-Woo Song, Youngrae Kim, Sang Ho Yoon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08201v1",
    "source": "arXiv",
    "abstract": "The absence of physical information during hand-object interaction in a virtual environment diminishes realism and immersion. Kinesthetic haptic feedback has proven effective in delivering realistic object-derived haptic cues, enhancing the overall virtual reality (VR) experience. Here, we propose kinesthetic illusion through a novel application of finger tendon vibration (FTV), which creates an illusory sensation of finger movement. To effectively apply FTV for virtual object interactions, we first examine the effects of short-duration FTV (<5 s) through 3 perception studies. Based on study results, we design 6 exemplary VR scenarios, representing the overall design space of VR object interactions, and 4 different haptic rendering strategies for FTV. We evaluated these rendering methods on each VR scenario and derived a design guideline for FTV application. We then compared FTV with no vibration and simple vibration, observing that FTV enhances VR experience by providing realistic resistance on the finger, greatly improving body ownership."
  },
  {
    "date": "2026-02-09",
    "title": "Chamelion: Reliable Change Detection for Long-Term LiDAR Mapping in Transient Environments",
    "authors": "Seoyeon Jang, Alex Junho Lee, I Made Aswin Nahrendra, Hyun Myung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08189v1",
    "source": "arXiv",
    "abstract": "Online change detection is crucial for mobile robots to efficiently navigate through dynamic environments. Detecting changes in transient settings, such as active construction sites or frequently reconfigured indoor spaces, is particularly challenging due to frequent occlusions and spatiotemporal variations. Existing approaches often struggle to detect changes and fail to update the map across different observations. To address these limitations, we propose a dual-head network designed for online change detection and long-term map maintenance. A key difficulty in this task is the collection and alignment of real-world data, as manually registering structural differences over time is both labor-intensive and often impractical. To overcome this, we develop a data augmentation strategy that synthesizes structural changes by importing elements from different scenes, enabling effective model training without the need for extensive ground-truth annotations. Experiments conducted at real-world construction sites and in indoor office environments demonstrate that our approach generalizes well across diverse scenarios, achieving efficient and accurate map updates.\\resubmit{Our source code and additional material are available at: https://chamelion-pages.github.io/."
  },
  {
    "date": "2026-02-09",
    "title": "The Great Filter hypothesis -- a new Great Filter?",
    "authors": "Darren J. Dougan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08188v1",
    "source": "arXiv",
    "abstract": "The Great Filter hypothesis is an extension of the Fermi Paradox: \"If life is so common in the universe, why don't we see it?\" The Great Filter theory posits there are multiple obstacles or filters life must pass through which ultimately sifts out intelligent life. This paper identifies a new filter: depopulation. As an exospecies advances and reaches the top of the food chain on its planet, Darwinian evolution selects the species to breed fewer offspring due to a lack of predation. As the species evolves intelligence, this leads to medicines and most notably contraception, enabling the species to reduce infant mortality while controlling reproduction. Finally, economic, social and educational factors add to the conscious decision of the intelligent life to slow reproduction. These factors are currently contributing to a human global population peak mid century with subsequent population collapse in less than 500 years. Noting that population growth and decline is exponential, our modelling forecasts human extinction thresholds being tested sometime after the year 2500. There is no reason to assume depopulation dynamics (exodepopulation) would not apply to exocivilizations (exodemography), thus providing a possible resolution of the Fermi Paradox. Furthermore, as machines and AI inevitably supplement humans as depopulation accelerates, the Fermi Paradox can be restated as \"Why don't we see machines and AI colonising the galaxy?\" A plausible answer is machines will not become conscious and will continue to operate only as tools, tools that will cease operating once humanity is extinct. The Fermi Paradox can then be restated as \"Machines will not become conscious, otherwise we would see them colonising the galaxy\"."
  },
  {
    "date": "2026-02-09",
    "title": "Detecting multilevel entanglement from light-based entanglement witnesses",
    "authors": "Pedro Rosario, Romain Bachelard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08180v1",
    "source": "arXiv",
    "abstract": "We introduce a set of electric-field based inequalities capable of detecting multilevel entanglement from a system of N quantum emitters. We determine that the polarization channel as well as the direction of detection can enhance entanglement detection, a feature specific to multilevel systems. We demonstrate the efficiency of the witnesses to detect genuine multipartite entanglement by applying it to families of paradigmatic quantum states, such as Dicke states, singlet states and W-like states. The detection is not only robust to noise, but also applies to mixed entangled states. Our findings open up possibilities for the detection of entanglement without local measurements in systems of multilevel emitters such as superconducting qubits, Rydberg atoms or quantum dots."
  },
  {
    "date": "2026-02-09",
    "title": "Stability phenomena for Kac-Moody groups",
    "authors": "Nitu Kitchloo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08175v1",
    "source": "arXiv",
    "abstract": "We show that a canonical procedure of extending generalized Dynkin diagrams gives rise to families of Kac-Moody groups that satisfy homological stability. We also briefly sketch some emergent structure that appears on stabilization. Our results are illustrated for the family {E_n} which is of interest in String theory. The techniques used involve homotopy decompositions of classifying spaces of Kac-Moody groups."
  },
  {
    "date": "2026-02-09",
    "title": "Evasion of IoT Malware Detection via Dummy Code Injection",
    "authors": "Sahar Zargarzadeh, Mohammad Islam",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08170v1",
    "source": "arXiv",
    "abstract": "The Internet of Things (IoT) has revolutionized connectivity by linking billions of devices worldwide. However, this rapid expansion has also introduced severe security vulnerabilities, making IoT devices attractive targets for malware such as the Mirai botnet. Power side-channel analysis has recently emerged as a promising technique for detecting malware activity based on device power consumption patterns. However, the resilience of such detection systems under adversarial manipulation remains underexplored. This work presents a novel adversarial strategy against power side-channel-based malware detection. By injecting structured dummy code into the scanning phase of the Mirai botnet, we dynamically perturb power signatures to evade AI/ML-based anomaly detection without disrupting core functionality. Our approach systematically analyzes the trade-offs between stealthiness, execution overhead, and evasion effectiveness across multiple state-of-the-art models for side-channel analysis, using a custom dataset collected from smartphones of diverse manufacturers. Experimental results show that our adversarial modifications achieve an average attack success rate of 75.2\\%, revealing practical vulnerabilities in power-based intrusion detection frameworks."
  },
  {
    "date": "2026-02-09",
    "title": "DAS-SK: An Adaptive Model Integrating Dual Atrous Separable and Selective Kernel CNN for Agriculture Semantic Segmentation",
    "authors": "Mei Ling Chee, Thangarajah Akilan, Aparna Ravindra Phalke, Kanchan Keisham",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08168v1",
    "source": "arXiv",
    "abstract": "Semantic segmentation in high-resolution agricultural imagery demands models that strike a careful balance between accuracy and computational efficiency to enable deployment in practical systems. In this work, we propose DAS-SK, a novel lightweight architecture that retrofits selective kernel convolution (SK-Conv) into the dual atrous separable convolution (DAS-Conv) module to strengthen multi-scale feature learning. The model further enhances the atrous spatial pyramid pooling (ASPP) module, enabling the capture of fine-grained local structures alongside global contextual information. Built upon a modified DeepLabV3 framework with two complementary backbones - MobileNetV3-Large and EfficientNet-B3, the DAS-SK model mitigates limitations associated with large dataset requirements, limited spectral generalization, and the high computational cost that typically restricts deployment on UAVs and other edge devices. Comprehensive experiments across three benchmarks: LandCover.ai, VDD, and PhenoBench, demonstrate that DAS-SK consistently achieves state-of-the-art performance, while being more efficient than CNN-, transformer-, and hybrid-based competitors. Notably, DAS-SK requires up to 21x fewer parameters and 19x fewer GFLOPs than top-performing transformer models. These findings establish DAS-SK as a robust, efficient, and scalable solution for real-time agricultural robotics and high-resolution remote sensing, with strong potential for broader deployment in other vision domains."
  },
  {
    "date": "2026-02-09",
    "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
    "authors": "Zehan Wang, Tengfei Wang, Haiyu Zhang, Xuhui Zuo, Junta Wu, Haoyuan Wang, Wenqiang Sun, Zhenwei Wang, Chenjie Cao, Hengshuang Zhao, Chunchao Guo, Zhou Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09022v1",
    "source": "arXiv",
    "abstract": "This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models, enabling them to explore the world more accurately and consistently based on interaction signals. To effectively \"steer\" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy: We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions: We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios."
  },
  {
    "date": "2026-02-09",
    "title": "The seismic diversity of four successive solar cycle minima as observed by the Birmingham Solar-Oscillations Network (BiSON)",
    "authors": "Sarbani Basu, William J. Chaplin, Rachel Howe, Yvonne Elsworth, Steven J. Hale, Eleanor Murray",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09019v1",
    "source": "arXiv",
    "abstract": "We have used data collected by the Birmingham Solar-Oscillations Network (BiSON) to perform a helioseismic diagnosis of changes to the Sun's internal structure between four successive solar cycle minima, beginning with the minimum at the end of cycle 21 and ending with the recent minimum at the beginning of cycle 25. The unique duration of the BiSON database makes such a study possible. We used the low-degree BiSON p-mode frequencies to constrain structural changes between minima in the layers above $\\approx 0.9 R_{\\odot}$. We accomplished this by examining variations in the HeII ionisation zone signature; and by inverting the frequency differences to infer changes in the sound speed. Additionally, we employed frequency differences between various solar models that had subtle modifications to their internal structures to facilitate analysis of the observations. We find evidence for small, but marginally significant, changes in structure between different minima. The HeII signature was larger, and the sound speed in the range $\\approx 0.93$ to $0.97 R_{\\odot}$ was slightly higher, during the cycle 23/24 minimum, than during the other minima. The cycle 23/24 minimum was the deepest, as measured by proxies of global solar activity. These findings are consistent with magnetic flux levels having been lower in this minimum than the others, resulting in a higher gas pressure, higher temperatures, and higher sound speed. Our results demonstrate the potential of using asteroseismic data to perform similar analyses on other solar-type stars."
  },
  {
    "date": "2026-02-09",
    "title": "Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving",
    "authors": "Amir Mallak, Alaa Maalouf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09018v1",
    "source": "arXiv",
    "abstract": "Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \\in \\{0,1,2,3\\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT policies, train compact ViT heads on frozen foundation-model (FM) features, and vary ID support in scale, diversity, and temporal context. (1) ViT policies are markedly more OOD-robust than comparably sized CNN/FC, and FM features yield state-of-the-art success at a latency cost. (2) Naive temporal inputs (multi-frame) do not beat the best single-frame baseline. (3) The largest single factor drops are rural $\\rightarrow$ urban and day $\\rightarrow$ night ($\\sim 31\\%$ each); actor swaps $\\sim 10\\%$, moderate rain $\\sim 7\\%$; season shifts can be drastic, and combining a time flip with other changes further degrades performance. (4) FM-feature policies stay above $85\\%$ under three simultaneous changes; non-FM single-frame policies take a large first-shift hit, and all no-FM models fall below $50\\%$ by three changes. (5) Interactions are non-additive: some pairings partially offset, whereas season-time combinations are especially harmful. (6) Training on winter/snow is most robust to single-factor shifts, while a rural+summer baseline gives the best overall OOD performance. (7) Scaling traces/views improves robustness ($+11.8$ points from $5$ to $14$ traces), yet targeted exposure to hard conditions can substitute for scale. (8) Using multiple ID environments broadens coverage and strengthens weak cases (urban OOD $60.6\\% \\rightarrow 70.1\\%$) with a small ID drop; single-ID preserves peak performance but in a narrow domain. These results yield actionable design rules for OOD-robust driving policies."
  },
  {
    "date": "2026-02-09",
    "title": "DirMoE: Dirichlet-routed Mixture of Experts",
    "authors": "Amirhossein Vahidi, Hesam Asadollahzadeh, Navid Akhavan Attar, Marie Moullet, Kevin Ly, Xingyi Yang, Mohammad Lotfollahi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09001v1",
    "source": "arXiv",
    "abstract": "Mixture-of-Experts (MoE) models have demonstrated exceptional performance in large-scale language models. Existing routers typically rely on non-differentiable Top-$k$+Softmax, limiting their performance and scalability. We argue that two distinct decisions, which experts to activate and how to distribute expert contributions among them, are conflated in standard Top-$k$+Softmax. We introduce Dirichlet-Routed MoE (DirMoE), a novel end-to-end differentiable routing mechanism built on a Dirichlet variational autoencoder framework. This design fundamentally disentangles the core routing problems: expert selection, modeled by a Bernoulli component, and expert contribution among chosen experts, handled by a Dirichlet component. The entire forward pass remains fully differentiable through the use of Gumbel-Sigmoid relaxation for the expert selection and implicit reparameterization for the Dirichlet distribution. Our training objective, a variational ELBO, includes a direct sparsity penalty that precisely controls the number of active experts in expectation, alongside a schedule for key hyperparameters that guides the model from an exploratory to a definitive routing state. Moreover, our DirMoE router matches or exceeds other methods while improving expert specialization."
  },
  {
    "date": "2026-02-09",
    "title": "Paradox of De-identification: A Critique of HIPAA Safe Harbour in the Age of LLMs",
    "authors": "Lavender Y. Jiang, Xujin Chris Liu, Kyunghyun Cho, Eric K. Oermann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08997v1",
    "source": "arXiv",
    "abstract": "Privacy is a human right that sustains patient-provider trust. Clinical notes capture a patient's private vulnerability and individuality, which are used for care coordination and research. Under HIPAA Safe Harbor, these notes are de-identified to protect patient privacy. However, Safe Harbor was designed for an era of categorical tabular data, focusing on the removal of explicit identifiers while ignoring the latent information found in correlations between identity and quasi-identifiers, which can be captured by modern LLMs. We first formalize these correlations using a causal graph, then validate it empirically through individual re-identification of patients from scrubbed notes. The paradox of de-identification is further shown through a diagnosis ablation: even when all other information is removed, the model can predict the patient's neighborhood based on diagnosis alone. This position paper raises the question of how we can act as a community to uphold patient-provider trust when de-identification is inherently imperfect. We aim to raise awareness and discuss actionable recommendations."
  },
  {
    "date": "2026-02-09",
    "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
    "authors": "Shiyang Feng, Runmin Ma, Xiangchao Yan, Yue Fan, Yusong Hu, Songtao Huang, Shuaiyu Zhang, Zongsheng Cao, Tianshuo Peng, Jiakang Yuan, Zijie Guo, Zhijie Zhong, Shangheng Du, Weida Wang, Jinxin Shi, Yuhao Zhou, Xiaohan He, Zhiyin Yu, Fangchen Yu, Qihao Zheng, Jiamin Wu, Mianxin Liu, Chi Zhang, Shaowei Hou, Shuya Li, Yankai Jiang, Wenjie Lou, Lilong Wang, Zifu Wang, Jiong Wang, Wanghan Xu, Yue Deng, Dongrui Liu, Yiheng Wang, Wenlong Zhang, Fenghua Ling, Shufei Zhang, Xiaosong Wang, Shuangjia Zheng, Xun Huang, Siqi Sun, Shuyue Hu, Peng Ye, Chunfeng Song, Bin Wang, Conghui He, Yihao Liu, Xin Li, Qibin Hou, Tao Chen, Xiangyu Yue, Bin Wang, Liang He, Dahua Lin, Bowen Zhou, Bo Zhang, Lei Bai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08990v1",
    "source": "arXiv",
    "abstract": "We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery."
  },
  {
    "date": "2026-02-09",
    "title": "StretchTime: Adaptive Time Series Forecasting via Symplectic Attention",
    "authors": "Yubin Kim, Viresh Pati, Jevon Twitty, Vinh Pham, Shihao Yang, Jiecheng Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08983v1",
    "source": "arXiv",
    "abstract": "Transformer architectures have established strong baselines in time series forecasting, yet they typically rely on positional encodings that assume uniform, index-based temporal progression. However, real-world systems, from shifting financial cycles to elastic biological rhythms, frequently exhibit \"time-warped\" dynamics where the effective flow of time decouples from the sampling index. In this work, we first formalize this misalignment and prove that rotary position embedding (RoPE) is mathematically incapable of representing non-affine temporal warping. To address this, we propose Symplectic Positional Embeddings (SyPE), a learnable encoding framework derived from Hamiltonian mechanics. SyPE strictly generalizes RoPE by extending the rotation group $\\mathrm{SO}(2)$ to the symplectic group $\\mathrm{Sp}(2,\\mathbb{R})$, modulated by a novel input-dependent adaptive warp module. By allowing the attention mechanism to adaptively dilate or contract temporal coordinates end-to-end, our approach captures locally varying periodicities without requiring pre-defined warping functions. We implement this mechanism in StretchTime, a multivariate forecasting architecture that achieves state-of-the-art performance on standard benchmarks, demonstrating superior robustness on datasets exhibiting non-stationary temporal dynamics."
  },
  {
    "date": "2026-02-09",
    "title": "When do neural ordinary differential equations generalize on complex networks?",
    "authors": "Moritz Laber, Tina Eliassi-Rad, Brennan Klein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08980v1",
    "source": "arXiv",
    "abstract": "Neural ordinary differential equations (neural ODEs) can effectively learn dynamical systems from time series data, but their behavior on graph-structured data remains poorly understood, especially when applied to graphs with different size or structure than encountered during training. We study neural ODEs ($\\mathtt{nODE}$s) with vector fields following the Barabási-Barzel form, trained on synthetic data from five common dynamical systems on graphs. Using the $\\mathbb{S}^1$-model to generate graphs with realistic and tunable structure, we find that degree heterogeneity and the type of dynamical system are the primary factors in determining $\\mathtt{nODE}$s' ability to generalize across graph sizes and properties. This extends to $\\mathtt{nODE}$s' ability to capture fixed points and maintain performance amid missing data. Average clustering plays a secondary role in determining $\\mathtt{nODE}$ performance. Our findings highlight $\\mathtt{nODE}$s as a powerful approach to understanding complex systems but underscore challenges emerging from degree heterogeneity and clustering in realistic graphs."
  },
  {
    "date": "2026-02-09",
    "title": "Cyclic universe from uniform rate inflation on the brane with a timelike extra dimension",
    "authors": "Rikpratik Sengupta, Arkajit Aich, Kaushik Bhattacharya",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08974v1",
    "source": "arXiv",
    "abstract": "We investigate a non-singular cosmological scenario in which uniform-rate inflation is realised on an anisotropic Shtanov-Sahni braneworld. The model naturally resolves the initial singularity resulting in an infinite number of smooth non-singular bounces, while accommodating a phase of accelerated expansion driven by a scalar field rolling at a constant rate. The presence of a timelike extra dimension induces high-energy corrections to the effective Friedmann dynamics, allowing anisotropic shear to be dynamically suppressed near the bounce and rendering the background evolution stable. We derive the full background dynamics analytically and demonstrate that uniform-rate inflation can be consistently embedded within an anisotropic braneworld framework. Primordial scalar and tensor perturbations are analysed using the $δN$ formalism, ensuring that only physically relevant modes exiting the horizon during inflation contribute to observable quantities. Remarkably, we find that observational consistency can be achieved with different levels of anisotropy in the two different scenarios we consider, without compromising the smoothness or stability of the bounce. Our results establish uniform-rate inflation on an anisotropic braneworld as a robust and observationally viable alternative to standard inflationary cosmology, offering a compelling framework in which non-singular early-universe dynamics and precision cosmology can be consistently unified."
  },
  {
    "date": "2026-02-09",
    "title": "PPG as a Bridge: Cross-Device Authentication for Smart Wearables with Photoplethysmography",
    "authors": "Jiacheng Liu, Jiankai Tang, Guangye Zhao, Ruichen Gui, Songqin Cheng, Taiting Lu, Jian Liu, Weiqiang Wang, Mahanth Gowda, Yuanchun Shi, Yuntao Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08972v1",
    "source": "arXiv",
    "abstract": "As smart wearable devices become increasingly powerful and pervasive, protecting user privacy on these devices has emerged as a critical challenge. While existing authentication mechanisms are available for interaction-rich devices such as smartwatches, enabling on-device authentication (ODA) on interaction-limited wearables including rings, earphones, glasses, and wristbands remains difficult. Moreover, as users increasingly own multiple smart devices, relying on device-specific authentication methods becomes redundant and burdensome. To address these challenges, we present PPGTransID, a ubiquitous and unobtrusive cross-device authentication (CDA) approach that leverages the real-time physiological consistency of photoplethysmography (PPG) signals across the human body. PPGTransID utilizes widely available PPG sensors on wearable devices to capture users' physiological signals and compares them with remote PPG (rPPG) signals extracted from a smartphone camera, where robust face-based authentication is already established. In doing so, PPGTransID securely transfers the reliable authentication status of the smartphone to nearby wearable devices without requiring additional user interaction. An evaluation with 33 participants shows that PPGTransID achieves a balanced accuracy of 95.5 percent and generalizes across multiple wearable form factors. Robustness experiments with 10 participants demonstrate resilience to variations in lighting, camera placement, and user behavior, while a real-time usability study with 14 participants confirms reliable performance with minimal interaction burden."
  },
  {
    "date": "2026-02-09",
    "title": "Maximin Shares with Lower Quotas",
    "authors": "Hirota Kinoshita, Ayumi Igarashi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08966v1",
    "source": "arXiv",
    "abstract": "We study the fair division of indivisible items among $n$ agents with heterogeneous additive valuations, subject to lower and upper quotas on the number of items allocated to each agent. Such constraints are crucial in various applications, ranging from personnel assignments to computing resource distribution. This paper focuses on the fairness criterion known as maximin shares (MMS) and its approximations. Under arbitrary lower and upper quotas, we show that a $\\left(\\frac{2n}{3n-1}\\right)$-MMS allocation of goods exists and can be computed in polynomial time, while we also present a polynomial-time algorithm for finding a $\\left(\\frac{3n-1}{2n}\\right)$-MMS allocation of chores. Furthermore, we consider the generalized scenario where items are partitioned into multiple categories, each with its own lower and upper quotas. In this setting, our algorithm computes an $\\left(\\frac{n}{2n-1}\\right)$-MMS allocation of goods or a $\\left(\\frac{2n-1}{n}\\right)$-MMS allocation of chores in polynomial time. These results extend previous work on the cardinality constraints, i.e., the special case where only upper quotas are imposed."
  },
  {
    "date": "2026-02-09",
    "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
    "authors": "Ruijie Zhu, Jiahao Lu, Wenbo Hu, Xiaoguang Han, Jianfei Cai, Ying Shan, Chuanxia Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08961v1",
    "source": "arXiv",
    "abstract": "We introduce MotionCrafter, a video diffusion-based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system, and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents-despite their fundamentally different distributions-we show that such alignment is unnecessary and leads to suboptimal performance. Instead, we introduce a new data normalization and VAE training strategy that better transfers diffusion priors and greatly improves reconstruction quality. Extensive experiments across multiple datasets demonstrate that MotionCrafter achieves state-of-the-art performance in both geometry reconstruction and dense scene flow estimation, delivering 38.64% and 25.0% improvements in geometry and motion reconstruction, respectively, all without any post-optimization. Project page: https://ruijiezhu94.github.io/MotionCrafter_Page"
  },
  {
    "date": "2026-02-09",
    "title": "Robust Sequential Learning in Random Order Networks",
    "authors": "William Guo, Edward Xiong, Jie Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08953v1",
    "source": "arXiv",
    "abstract": "In the sequential learning problem, agents in a network attempt to predict a binary ground truth, informed by both a noisy private signal and the predictions of neighboring agents before them. It is well known that social learning in this setting can be highly fragile: small changes to the action ordering, network topology, or even the strength of the agents' private signals can prevent a network from converging to the truth. We study networks that achieve random-order asymptotic truth learning, in which almost all agents learn the ground truth when the decision ordering is selected uniformly at random. We analyze the robustness of these networks, showing that those achieving random-order asymptotic truth learning are resilient to a bounded number of adversarial modifications. We characterize necessary conditions for such networks to succeed in this setting and introduce several graph constructions that learn through different mechanisms. Finally, we present a randomized polynomial-time algorithm that transforms an arbitrary network into one achieving random-order learning using minimal edge or vertex modifications, with provable approximation guarantees. Our results reveal structural properties of networks that achieve random-order learning and provide algorithmic tools for designing robust social networks."
  },
  {
    "date": "2026-02-09",
    "title": "Tailoring Ultrathin Magnetic Multilayers at Terraced Topologically Insulating Interfaces for Perpendicularly Magnetized Domains",
    "authors": "Benjamin A. Brereton, Soumyarup Hait, Ahmet Yagmur, Christy J. Kinane, Francesco Maccherozzi, Michele Conroy, Satoshi Sasaki, Thomas A. Moore, Sarnjeet S. Dhesi, Sean Langridge, Christopher H. Marrows",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08950v1",
    "source": "arXiv",
    "abstract": "Topological insulators and skyrmion-hosting, chiral magnetic multilayers are two well-explored areas of modern condensed matter physics, each offering unique advantages for spintronics applications. In this paper, we demonstrate the optimization process for the growth of a Bi$_2$Se$_3$/buffer/[Pt/CoB/Ru]$_{\\times N}$ heterostructure that combines these two material classes: the Bi$_2$Se$_3$ epilayer was grown by molecular beam epitaxy before transfer under ultrahigh vacuum to a separate growth chamber where the polycrystalline metallic multilayer was sputter deposited. The structure of the samples was characterized by co-fitted X-ray and polarized neutron reflectometry measurements and scanning transmission electron microscopy. Polarized neutron models and standard magnetometry show that a buffer layer exceeding a critical thickness is required to obtain the desired uniform, perpendicular magnetic anisotropy in every magnetic layer in the multilayer. Samples with both Ta and Mo buffers were used requiring thicknesses of 1.5 and 0.9 nm respectively. In minimizing the Bi$_2$Se$_3$ terracing, buffered samples yield well-defined, out-of-plane, magnetic domains suitable for spin-orbit torque induced manipulation as determined by X-ray photoemission electron microscopy."
  },
  {
    "date": "2026-02-09",
    "title": "GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search",
    "authors": "Sahajpreet Singh, Kokil Jaidka, Min-Yen Kan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08945v1",
    "source": "arXiv",
    "abstract": "Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in \"cold start\" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality."
  },
  {
    "date": "2026-02-09",
    "title": "CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse",
    "authors": "Longling Geng, Andy Ouyang, Theodore Wu, Daphne Barretto, Matthew John Hayes, Rachael Cooper, Yuqiao Zeng, Sameer Vijay, Gia Ancone, Ankit Rai, Matthew Wolfman, Patrick Flanagan, Edward Y. Chang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08939v1",
    "source": "arXiv",
    "abstract": "LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycophantic drift under adversarial pressure; and (3) generating Wise Refusals that specify missing information when evidence is underdetermined. Unlike synthetic benchmarks, CausalT5K embeds causal traps in realistic narratives and decomposes performance into Utility (sensitivity) and Safety (specificity), revealing failure modes invisible to aggregate accuracy. Developed through a rigorous human-machine collaborative pipeline involving 40 domain experts, iterative cross-validation cycles, and composite verification via rule-based, LLM, and human scoring, CausalT5K implements Pearl's Ladder of Causation as research infrastructure. Preliminary experiments reveal a Four-Quadrant Control Landscape where static audit policies universally fail, a finding that demonstrates CausalT5K's value for advancing trustworthy reasoning systems. Repository: https://github.com/genglongling/CausalT5kBench"
  },
  {
    "date": "2026-02-09",
    "title": "The role of absorption in three-dimensional electron diffraction dynamical structure refinement",
    "authors": "Benjamin Colmey, Tiarnan A. S. Doherty, Shreshth A. Malik, Paul A. Midgley",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08935v1",
    "source": "arXiv",
    "abstract": "The role of absorption in 3D electron diffraction is established through analytical theory, simulation, and dynamical refinement. A two-beam expression for the absorbed integrated intensity is derived, showing that for $t/ξ_g \\ll 1$ reflections follow a uniform exponential decay set by the mean absorptive potential $U_0'$. Many-beam simulations demonstrate that neglecting absorption in dynamical refinement of integrated intensities incurs a residual that increases linearly with thickness and diverges near zone axes. Dynamical refinements were performed on CsPbBr$_3$, quartz, and borane, with the inclusion of absorption yielding an improvement in $R_{\\mathrm{obs}}$ from $6.4$ to $5.3$ \\% for CsPbBr$_3$ and negligible changes for quartz and borane. Absorption is therefore deemed negligible for routine refinement of integrated intensities except in high-$Z$ materials at thicknesses approaching $ξ_g$."
  },
  {
    "date": "2026-02-09",
    "title": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors",
    "authors": "Suraj Ranganath, Atharv Ramesh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08934v1",
    "source": "arXiv",
    "abstract": "AI-text detectors face a critical robustness challenge: adversarial paraphrasing attacks that preserve semantics while evading detection. We introduce StealthRL, a reinforcement learning framework that stress-tests detector robustness under realistic adversarial conditions. StealthRL trains a paraphrase policy against a multi-detector ensemble using Group Relative Policy Optimization (GRPO) with LoRA adapters on Qwen3-4B, optimizing a composite reward that balances detector evasion with semantic preservation. We evaluate six attack settings (M0-M5) against three detector families (RoBERTa, FastDetectGPT, and Binoculars) at the security-relevant 1% false positive rate operating point. StealthRL achieves near-zero detection (0.001 mean TPR@1%FPR), reduces mean AUROC from 0.74 to 0.27, and attains a 99.9% attack success rate. Critically, attacks transfer to a held-out detector family not seen during training, revealing shared architectural vulnerabilities rather than detector-specific brittleness. We additionally conduct LLM-based quality evaluation via Likert scoring, analyze detector score distributions to explain why evasion succeeds, and provide per-detector AUROC with bootstrap confidence intervals. Our results expose significant robustness gaps in current AI-text detection and establish StealthRL as a principled adversarial evaluation protocol. Code and evaluation pipeline are publicly available at https://github.com/suraj-ranganath/StealthRL."
  },
  {
    "date": "2026-02-09",
    "title": "DynamiQ: Accelerating Gradient Synchronization using Compressed Multi-hop All-reduce",
    "authors": "Wenchen Han, Shay Vargaftik, Michael Mitzenmacher, Ran Ben Basat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08923v1",
    "source": "arXiv",
    "abstract": "Multi-hop all-reduce is the de facto backbone of large model training. As the training scale increases, the network often becomes a bottleneck, motivating reducing the volume of transmitted data. Accordingly, recent systems demonstrated significant acceleration of the training process using gradient quantization. However, these systems are not optimized for multi-hop aggregation, where entries are partially summed multiple times along their aggregation topology. This paper presents DynamiQ, a quantization framework that bridges the gap between quantization best practices and multi-hop aggregation. DynamiQ introduces novel techniques to better represent partial sums, co-designed with a decompress-accumulate-recompress fused kernel to facilitate fast execution. We extended PyTorch DDP to support DynamiQ over NCCL P2P, and across different LLMs, tasks, and scales, we demonstrate consistent improvement of up to 34.2% over the best among state-of-the-art methods such as Omni-Reduce, THC, and emerging standards such as MXFP4, MXFP6, and MXFP8. Further, DynamiQ is the only evaluated method that consistently reaches near-baseline accuracy (e.g., 99.9% of the BF16 baseline) and does so while significantly accelerating the training."
  },
  {
    "date": "2026-02-09",
    "title": "Automatic In-Domain Exemplar Construction and LLM-Based Refinement of Multi-LLM Expansions for Query Expansion",
    "authors": "Minghan Li, Ercong Nie, Siqi Zhao, Tongna Chen, Huiping Huang, Guodong Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08917v1",
    "source": "arXiv",
    "abstract": "Query expansion with large language models is promising but often relies on hand-crafted prompts, manually chosen exemplars, or a single LLM, making it non-scalable and sensitive to domain shift. We present an automated, domain-adaptive QE framework that builds in-domain exemplar pools by harvesting pseudo-relevant passages using a BM25-MonoT5 pipeline. A training-free cluster-based strategy selects diverse demonstrations, yielding strong and stable in-context QE without supervision. To further exploit model complementarity, we introduce a two-LLM ensemble in which two heterogeneous LLMs independently generate expansions and a refinement LLM consolidates them into one coherent expansion. Across TREC DL20, DBPedia, and SciFact, the refined ensemble delivers consistent and statistically significant gains over BM25, Rocchio, zero-shot, and fixed few-shot baselines. The framework offers a reproducible testbed for exemplar selection and multi-LLM generation, and a practical, label-free solution for real-world QE."
  },
  {
    "date": "2026-02-09",
    "title": "Dynamics, Ringdown, and Accretion-Driven Multiple Quasi-Periodic Oscillations of Kerr-Bertotti-Robinson Black Holes",
    "authors": "G. Mustafa, Orhan Donmez, Dhruba Jyoti Gogoi, Sushant G. Ghosh, Ibrar Hussain, Chengxun Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08911v1",
    "source": "arXiv",
    "abstract": "We study the motion of test particles around Kerr--Bertotti--Robinson (KBR) black hole (BH) and explore how the three defining parameters the mass $M$, rotation parameter $a$, and magnetic parameter $B$ influence their dynamics. We derive analytical expressions for the energy and angular momentum of stable equatorial circular orbits, along with the corresponding radial and latitudinal oscillation frequencies, as functions of $M$, $a$, and $B$. We also examine the key features of the quasi-periodic oscillations of test particles near stable circular orbits, including the precession effects such as periastron precession and the Lense-Thirring effect. Finally, we compare our results with those corresponding to the Kerr BH. We find that particle motion is strongly shaped by the BH parameters. Using a WKB approach, we also study scalar quasinormal modes of a rotating KBR BH in an external magnetic field and show that the magnetic field increases damping, while rotation and angular momentum mainly set the oscillation frequencies. Alternatively, general relativistic modelling of Bondi-Hoyle-Lyttleton (BHL) accretion onto a rapidly rotating KBR BH shows that two distinct physical structures emerge and cyclically transform into one another over time. These processes produce either a strongly oscillating flip-flop shock cone or a nearly stationary toroidal structure, with their formation governed by the black hole spin and magnetic curvature. Power spectral analysis shows that these configurations give rise to low and high-frequency quasi-periodic oscillations, offering a unified explanation for the multiple quasi-periodic oscillations observed in rapidly spinning X--ray binaries."
  },
  {
    "date": "2026-02-09",
    "title": "Efficient and Stable Reinforcement Learning for Diffusion Language Models",
    "authors": "Jiawei Liu, Xiting Wang, Yuanyuan Zhong, Defu Lian, Yu Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08905v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (1) \\textit{spatial pruning}, which constrains the exploration space using static priors; and (2) \\textit{temporal pruning}, which bypasses redundant late-stage refinement steps. Our theoretical analysis demonstrates that STP strictly reduces the variance of the log-likelihood estimation, thereby ensuring more stable policy updates. Extensive experiments demonstrate that STP surpasses state-of-the-art baselines in both efficiency and accuracy. Our code is available at https://github.com/Lolo1222/STP."
  },
  {
    "date": "2026-02-09",
    "title": "OmniReview: A Large-scale Benchmark and LLM-enhanced Framework for Realistic Reviewer Recommendation",
    "authors": "Yehua Huang, Penglei Sun, Zebin Chen, Zhenheng Tang, Xiaowen Chu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08896v1",
    "source": "arXiv",
    "abstract": "Academic peer review remains the cornerstone of scholarly validation, yet the field faces some challenges in data and methods. From the data perspective, existing research is hindered by the scarcity of large-scale, verified benchmarks and oversimplified evaluation metrics that fail to reflect real-world editorial workflows. To bridge this gap, we present OmniReview, a comprehensive dataset constructed by integrating multi-source academic platforms encompassing comprehensive scholarly profiles through the disambiguation pipeline, yielding 202, 756 verified review records. Based on this data, we introduce a three-tier hierarchical evaluaion framework to assess recommendations from recall to precise expert identification. From the method perspective, existing embedding-based approaches suffer from the information bottleneck of semantic compression and limited interpretability. To resolve these method limitations, we propose Profiling Scholars with Multi-gate Mixture-of-Experts (Pro-MMoE), a novel framework that synergizes Large Language Models (LLMs) with Multi-task Learning. Specifically, it utilizes LLM-generated semantic profiles to preserve fine-grained expertise nuances and interpretability, while employing a Task-Adaptive MMoE architecture to dynamically balance conflicting evaluation goals. Comprehensive experiments demonstrate that Pro-MMoE achieves state-of-the-art performance across six of seven metrics, establishing a new benchmark for realistic reviewer recommendation."
  },
  {
    "date": "2026-02-09",
    "title": "Designing Multi-Robot Ground Video Sensemaking with Public Safety Professionals",
    "authors": "Puqi Zhou, Ali Asgarov, Aafiya Hussain, Wonjoon Park, Amit Paudyal, Sameep Shrestha, Chia-wei Tang, Michael F. Lighthiser, Michael R. Hieb, Xuesu Xiao, Chris Thomas, Sungsoo Ray Hong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08882v1",
    "source": "arXiv",
    "abstract": "Videos from fleets of ground robots can advance public safety by providing scalable situational awareness and reducing professionals' burden. Yet little is known about how to design and integrate multi-robot videos into public safety workflows. Collaborating with six police agencies, we examined how such videos could be made practical. In Study 1, we presented the first testbed for multi-robot ground video sensemaking. The testbed includes 38 events-of-interest (EoI) relevant to public safety, a dataset of 20 robot patrol videos (10 day/night pairs) covering EoI types, and 6 design requirements aimed at improving current video sensemaking practices. In Study 2, we built MRVS, a tool that augments multi-robot patrol video streams with a prompt-engineered video understanding model. Participants reported reduced manual workload and greater confidence with LLM-based explanations, while noting concerns about false alarms and privacy. We conclude with implications for designing future multi-robot video sensemaking tools. The testbed is available at https://github.com/Puqi7/MRVS\\_VideoSensemaking"
  },
  {
    "date": "2026-02-09",
    "title": "Conservative binary dynamics to third post-Minkowskian order beyond General Relativity",
    "authors": "Gabriel Luz Almeida, Yuchen Du, Zhengwen Liu, Hongbin Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08876v1",
    "source": "arXiv",
    "abstract": "We present the conservative dynamics of compact binaries to third order in the post-Minkowskian approximation in a theory that extends general relativity by a massless scalar field coupled to the Gauss-Bonnet invariant. We employ the effective field theory approach to construct the effective action of binary systems by integrating out the metric and scalar degrees of freedom that mediate the gravitational interactions between the two bodies. We derive analytical expressions for the scattering impulse and the deflection angle to third order in the post-Minkowskian expansion. Our results are found to be in agreement, in the overlapping regimes, with state-of-the-art calculations in the post-Newtonian/post-Minkowskian theory."
  },
  {
    "date": "2026-02-09",
    "title": "Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation",
    "authors": "Lisette Espin-Noboa, Gonzalo Gabriel Mendez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08873v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly used for academic expert recommendation. Existing audits typically evaluate model outputs in isolation, largely ignoring end-user inference-time interventions. As a result, it remains unclear whether failures such as refusals, hallucinations, and uneven coverage stem from model choice or deployment decisions. We introduce LLMScholarBench, a benchmark for auditing LLM-based scholar recommendation that jointly evaluates model infrastructure and end-user interventions across multiple tasks. LLMScholarBench measures both technical quality and social representation using nine metrics. We instantiate the benchmark in physics expert recommendation and audit 22 LLMs under temperature variation, representation-constrained prompting, and retrieval-augmented generation (RAG) via web search. Our results show that end-user interventions do not yield uniform improvements but instead redistribute error across dimensions. Higher temperature degrades validity, consistency, and factuality. Representation-constrained prompting improves diversity at the expense of factuality, while RAG primarily improves technical quality while reducing diversity and parity. Overall, end-user interventions reshape trade-offs rather than providing a general fix. We release code and data that can be adapted to other disciplines by replacing domain-specific ground truth and metrics."
  },
  {
    "date": "2026-02-09",
    "title": "Gelfand-Kirillov bound for $p$-adic Banach representations with infinitesimal character for $\\text{GL}_2$ and quaternion units",
    "authors": "Reinier Sorgdrager",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08856v1",
    "source": "arXiv",
    "abstract": "We prove that an admissible $p$-adic Banach representation of $\\text{GL}_2K$ whose locally analytic vectors have an infinitesimal character has Gelfand-Kirillov dimension $\\leq[K\\colon\\mathbf Q_p]$, where $p>2$ and $K$ is a $p$-adic field. We also prove this for the group of units of the quaternions over $K$ replacing $\\text{GL}_2K$. In the process, we make some observations in the theory of $p$-adic Banach representations that might be of independent interest."
  },
  {
    "date": "2026-02-09",
    "title": "Koszul duality for algebras over infinity-operads",
    "authors": "Eric Hoffbeck, Ieke Moerdijk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08851v1",
    "source": "arXiv",
    "abstract": "In this paper, we introduce a new notion of algebra over a linear $\\infty$-operad and a corresponding notion of coalgebra over an $\\infty$-cooperad. We next extend the Koszul duality between linear $\\infty$-operads and linear $\\infty$-cooperads from our previous paper (arXiv:2105.11943) to their categories of algebras and coalgebras. This duality theorem specialises to the known duality in the case of algebras over classical (non-infinity) operads, but our proof is different. In fact, it is based on a much more general duality between presheaves and copresheaves on a category of trees. The latter duality is a priori independent of the (co)algebra structures, but we show that it can be lifted to (co)presheaves supporting such a structure. Based on this duality, we define the homology of an algebra over an $\\infty$-operad, and prove that it can be described in terms of the homology of the same category of trees with coefficients in a presheaf."
  },
  {
    "date": "2026-02-09",
    "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
    "authors": "Lang Feng, Longtao Zheng, Shuo He, Fuxiang Zhang, Bo An",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08847v1",
    "source": "arXiv",
    "abstract": "Multi-agent LLM systems enable advanced reasoning and tool use via role specialization, yet reliable reinforcement learning (RL) post-training for such systems remains difficult. In this work, we theoretically pinpoint a key reason for training instability when extending group-based RL to multi-agent LLM systems. We show that under GRPO-style optimization, a global normalization baseline may deviate from diverse agents' reward distributions, which ultimately leads to gradient-norm instability. Based on this finding, we propose Dr. MAS, a simple and stable RL training recipe for multi-agent LLM systems. Dr. MAS uses an agent-wise remedy: normalizing advantages per agent using each agent's own reward statistics, which calibrates gradient scales and dramatically stabilizes training, both theoretically and empirically. Beyond the algorithm, Dr. MAS provides an end-to-end RL training framework for multi-agent LLM systems, supporting scalable orchestration, flexible per-agent LLM serving and optimization configs, and shared resource scheduling of LLM actor backends. We evaluate Dr. MAS on multi-agent math reasoning and multi-turn search benchmarks using Qwen2.5 and Qwen3 series models. Dr. MAS achieves clear gains over vanilla GRPO (e.g., +5.6\\% avg@16 and +4.6\\% pass@16 on math, and +15.2\\% avg@16 and +13.1\\% pass@16 on search) while largely eliminating gradient spikes. Moreover, it remains highly effective under heterogeneous agent-model assignments while improving efficiency."
  },
  {
    "date": "2026-02-09",
    "title": "CHIMPS2: The physical properties and star formation efficiency of molecular gas in the Central Molecular Zone",
    "authors": "S. M. King, T. J. T. Moore, S. N. Longmore, D. J. Eden, J. D. Henshaw, A. J. Rigby, R. Rani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08824v1",
    "source": "arXiv",
    "abstract": "We present Local Thermodynamic Equilibrium (LTE) estimates of the physical properties and star formation efficiency (SFE) of molecular gas in the Central Molecular Zone (CMZ), using new $^{12}$CO $J=2\\to1$ observations from the James Clerk Maxwell Telescope. Combined with CHIMPS2 $^{12}$CO and $^{13}$CO $J=3\\to2$, and SEDIGISM $^{13}$CO $J=2\\to1$ data, we estimate a median excitation temperature of $T_{\\rm ex} = 11$K for $^{13}$CO throughout the CMZ, with peaks exceeding $120$K in the Sgr B1/B2 complex. Cooler gas dominates around Sgr A and nearby clouds. We derive a median H$_{2}$ column-density of $N(\\mathrm{H}2) = 2 \\times 10^{22}$ cm$^{-2}$ and a total $^{13}$CO-traced gas mass of $M_{\\rm gas} = 7 \\times 10^6$ M$_\\odot$, consistent with previous estimates when accounting for spatial coverage. The instantaneous SFE is assessed using Hi-GAL compact sources detected at 70-$μm$ and 160--500-$μm$. The 70-$μm$-bright SFE, tracing current star formation, is modest overall but elevated in Sgr B1/B2, the Arches cluster, and Sgr C. In contrast, the 160--500-$μm$ SFE, tracing cold pre-stellar gas, is more broadly enhanced, particularly in the dust ridge clouds and towards negative longitudes surrounding Sgr C. The contrasting distributions suggest an evolutionary gradient in SFE, consistent with a transition from dense, cold gas to embedded protostars. Our results imply that the CMZ may be enter a more active phase of star formation, with large reservoirs of gas primed for future activity."
  },
  {
    "date": "2026-02-09",
    "title": "Impredicativity in Linear Dependent Type Theory",
    "authors": "Sam Speight, Niels van der Weide",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08846v1",
    "source": "arXiv",
    "abstract": "We construct a realizability model of linear dependent type theory from a linear combinatory algebra. Our model motivates a number of additions to the type theory. In particular, we add a universe with two decoding operations: one takes codes to cartesian types and the other takes codes to linear types. The universe is impredicative in the sense that it is closed under both large cartesian dependent products and large linear dependent products. We also add a rule for injectivity of the modality turning linear terms into cartesian terms. With all of the additions, we are able to encode (linear) inductive types. As a case study, we consider the type of lists over a linear type, and demonstrate that our encoding has the relevant uniqueness principle. The construction of the realizability model is fully formalized in the proof assistant Rocq."
  },
  {
    "date": "2026-02-09",
    "title": "Finite-State Controllers for (Hidden-Model) POMDPs using Deep Reinforcement Learning",
    "authors": "David Hudák, Maris F. L. Galesloot, Martin Tappler, Martin Kurečka, Nils Jansen, Milan Češka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08734v1",
    "source": "arXiv",
    "abstract": "Solving partially observable Markov decision processes (POMDPs) requires computing policies under imperfect state information. Despite recent advances, the scalability of existing POMDP solvers remains limited. Moreover, many settings require a policy that is robust across multiple POMDPs, further aggravating the scalability issue. We propose the Lexpop framework for POMDP solving. Lexpop (1) employs deep reinforcement learning to train a neural policy, represented by a recurrent neural network, and (2) constructs a finite-state controller mimicking the neural policy through efficient extraction methods. Crucially, unlike neural policies, such controllers can be formally evaluated, providing performance guarantees. We extend Lexpop to compute robust policies for hidden-model POMDPs (HM-POMDPs), which describe finite sets of POMDPs. We associate every extracted controller with its worst-case POMDP. Using a set of such POMDPs, we iteratively train a robust neural policy and consequently extract a robust controller. Our experiments show that on problems with large state spaces, Lexpop outperforms state-of-the-art solvers for POMDPs as well as HM-POMDPs."
  },
  {
    "date": "2026-02-09",
    "title": "Learning to Judge: LLMs Designing and Applying Evaluation Rubrics",
    "authors": "Clemencia Siro, Pourya Aliannejadi, Mohammad Aliannejadi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08672v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly used as evaluators for natural language generation, applying human-defined rubrics to assess system outputs. However, human rubrics are often static and misaligned with how models internally represent language quality. We introduce GER-Eval (Generating Evaluation Rubrics for Evaluation) to investigate whether LLMs can design and apply their own evaluation rubrics. We evaluate the semantic coherence and scoring reliability of LLM-defined criteria and their alignment with human criteria. LLMs reliably generate interpretable and task-aware evaluation dimensions and apply them consistently within models, but their scoring reliability degrades in factual and knowledge-intensive settings. Closed-source models such as GPT-4o achieve higher agreement and cross-model generalization than open-weight models such as Llama. Our findings position evaluation as a learned linguistic capability of LLMs, consistent within models but fragmented across them, and call for new methods that jointly model human and LLM evaluative language to improve reliability and interpretability."
  },
  {
    "date": "2026-02-09",
    "title": "Convergence Analysis for the Recovery of the Friction Threshold in a Scalar Tresca Model",
    "authors": "Erik Burman, Marvin Knöller, Lauri Oksanen, Andreas Rupp",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08967v1",
    "source": "arXiv",
    "abstract": "We consider a scalar valued elliptic partial differential equation on a sufficiently smooth domain $Ω$, subject to a regularized Tresca friction-type boundary condition on a subset $Γ$ of $\\partial Ω$. The friction threshold, a positive function appearing in this boundary condition, is assumed to be unknown and serves as the coefficient to be recovered in our inverse problem. Assuming that (i) the friction threshold lies in a finite dimensional space with known basis functions, (ii) the right hand sides of the partial differential equation are known, and (iii) the solution to the partial differential equation on some small open subset $ω\\subset Ω$ is available, we develop an iterative computational method for the recovery of the friction threshold. This algorithm is simple to implement and is based on piecewise linear finite elements. We show that the proposed algorithm converges in second order to a function $a_h$ and, moreover, that $a_h$ converges in second order in the finite element's mesh size $h$ to the true (unknown) friction threshold. We highlight our theoretical results by simulations that confirm our rates numerically."
  },
  {
    "date": "2026-02-09",
    "title": "The Theory and Practice of MAP Inference over Non-Convex Constraints",
    "authors": "Leander Kurscheidt, Gabriele Masina, Roberto Sebastiani, Antonio Vergari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08681v1",
    "source": "arXiv",
    "abstract": "In many safety-critical settings, probabilistic ML systems have to make predictions subject to algebraic constraints, e.g., predicting the most likely trajectory that does not cross obstacles. These real-world constraints are rarely convex, nor the densities considered are (log-)concave. This makes computing this constrained maximum a posteriori (MAP) prediction efficiently and reliably extremely challenging. In this paper, we first investigate under which conditions we can perform constrained MAP inference over continuous variables exactly and efficiently and devise a scalable message-passing algorithm for this tractable fragment. Then, we devise a general constrained MAP strategy that interleaves partitioning the domain into convex feasible regions with numerical constrained optimization. We evaluate both methods on synthetic and real-world benchmarks, showing our % approaches outperform constraint-agnostic baselines, and scale to complex densities intractable for SoTA exact solvers."
  },
  {
    "date": "2026-02-09",
    "title": "Modelling Conduction Cooling of Superconducting Accelerator Magnets using a Thermal Thin Shell Approximation",
    "authors": "Emma Vancayseele, Erik Schnaubelt, Louis Denis, Christophe Geuzaine, Arjan Verweij, Mariusz Wozniak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08648v1",
    "source": "arXiv",
    "abstract": "Understanding the thermal behaviour of superconducting accelerator magnets is essential to ensure stable and reliable operation. This work presents an extension of the Finite Element Quench Simulator (FiQuS) Multipole module to include collar and pole regions of accelerator magnets, which influences the overall thermal response. A thermal thin shell approximation (TSA), which is shown to be effective in previous works, is employed to model thermal insulation layers efficiently, replacing an insulation surface mesh. The main novelty of this work lies in the development of a method to model the thermal connection between the magnet winding and the collar and pole regions via the TSA. To assess the accuracy and computational efficiency of the novel method, temperature and field variations are computed for a current ramp-up scenario. The thermal solution is coupled to a fully resolved magnetodynamic solution to capture the interaction between thermal and electromagnetic behaviour. The results obtained with the TSA are then compared to classical finite element (FE) solutions with explicitly meshed insulation domains. The TSA predicts the maximum temperature within 2-4% of the reference solution while substantially reducing mesh complexity and achieving up to a 5 times speed-up in computation time. While the TSA has traditionally been employed for short-duration quench simulations with high heat fluxes between magnet turns, these results demonstrate its reliability and efficiency for current ramp scenarios with low heat fluxes, significantly expanding its application range beyond what has been previously reported in the literature. To illustrate potential applications of this new functionality, conduction cooling through the collar region is studied, comparing different cooling configurations and collar materials."
  },
  {
    "date": "2026-02-09",
    "title": "AI-Assisted Model for Generating Multiple-Choice Questions",
    "authors": "Tetiana Krushynska, Jani Ursin, Ville Heilala",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08383v1",
    "source": "arXiv",
    "abstract": "Multiple-choice questions (MCQs) are widely used across diverse educational fields and levels. Well-designed MCQs should evaluate knowledge application in real-world situations. However, writing such test items in sufficient numbers is challenging and time-consuming, especially in natural science education. The problem of a sufficient number of MCQs has two aspects: content coverage and exam security. Therefore, generating test items involves two tasks: creating MCQ prototypes and transforming these prototypes into item series. In automated item generation, prototype creation aligns with template-based methods like cognitive modelling, while item expansion corresponds to example-based techniques. The aim of this research was designing the goal-oriented conceptual model of human - AI co-creation of MCQs that should meet strictly formulated quality criteria. The resulting three-step model for creating MCQ prototypes distributed prompts between several AIs, with human revision of responses for each prompt before setting the next one. To transform the MCQ prototype into an MCQ series, a one-step model was developed in which multiple new items are generated simultaneously. These items assess the same learning outcome but are not simple rephrasings of the prototype or of one another. Based on human and automated evaluation, approximately half of the output MCQs were acceptable without editing. Minor corrections of initially rejected test items allowed for a moderate increase in acceptance of MCQs in series and a significant improvement of MCQ-prototypes."
  },
  {
    "date": "2026-02-09",
    "title": "TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration",
    "authors": "Linye Wei, Zixiang Luo, Pingzhi Tang, Meng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08404v1",
    "source": "arXiv",
    "abstract": "Diffusion large language models (dLLMs) have recently gained significant attention due to their inherent support for parallel decoding. Building on this paradigm, Mixture-of-Experts (MoE) dLLMs with autoregressive (AR) initialization have further demonstrated strong performance competitive with mainstream AR models. However, we identify a fundamental mismatch between MoE architectures and diffusion-based decoding. Specifically, a large number of experts are activated at each denoising step, while only a small subset of tokens is ultimately accepted, resulting in substantial inference overhead and limiting their deployment in latency-sensitive applications. In this work, we propose TEAM, a plug-and-play framework that accelerates MoE dLLMs by enabling more accepted tokens with fewer activated experts. TEAM is motivated by the observation that expert routing decisions exhibit strong temporal consistency across denoising levels as well as spatial consistency across token positions. Leveraging these properties, TEAM employs three complementary expert activation and decoding strategies, conservatively selecting necessary experts for decoded and masked tokens and simultaneously performing aggressive speculative exploration across multiple candidates. Experimental results demonstrate that TEAM achieves up to 2.2x speedup over vanilla MoE dLLM, with negligible performance degradation. Code is released at https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM."
  },
  {
    "date": "2026-02-09",
    "title": "K-DRIFT Science Theme: Galaxies in the Faint Universe",
    "authors": "Woowon Byun, Yongmin Yoon, Jongwan Ko, Yun Hee Lee, Gain Lee, Ho Seong Hwang, Cristiano G. Sabiu, Kwang-il Seon, Kyungwon Chun, Jihye Shin, Jinsu Rhee, Jae-Woo Kim, Jaewon Yoo, Jaehyun Lee, Sang-Hyun Chun, Hong Soo Park, Soung-Chul Yang, Sungryong Hong, Jeehye Shin, Hyowon Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08283v1",
    "source": "arXiv",
    "abstract": "Low-surface-brightness (LSB) structures serve as evidence of the intricate mass assembly of galaxies, and dedicatedly studying them promises to give us profound insights into the evolutionary history of galaxies. Furthermore, delving into the properties of star formation (SF) in the LSB regime can broaden our understanding of SF activity in regions characterized by low surface gas density, thereby shedding light on fundamental cosmic processes. However, systematic uncertainties may hamper the exploration of the LSB universe by limiting detectable SB levels. Indeed, despite dedicated advancements in telescope and observing techniques over decades, achieving ultra-deep photometric depths in optical wavelengths remains a formidable challenge. To overcome this challenge and explore the LSB universe that we have yet to see, we have been developing a novel telescope called K-DRIFT. This paper outlines the telescope's specification and describes various LSB features we aim for, explicitly focusing on nearby individual galaxies. To further advance the capabilities of the K-DRIFT survey, focused on LSB detection, we present several feasible research topics that utilize other survey data together and discuss the role of LSB observation in understanding the evolution of galaxies."
  },
  {
    "date": "2026-02-09",
    "title": "Efficient circuit compression by multi-qudit entangling gates in linear optical quantum computation",
    "authors": "Apurav, Jaskaran Singh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08394v1",
    "source": "arXiv",
    "abstract": "Linear optical quantum computation (LOQC) offers a promising platform for scalable quantum information processing, but its scalability is fundamentally constrained by the probabilistic nature of non-local entangling gates. Qudit circuit compression schemes mitigate this issue by encoding multiple qubits onto qudits. However, these schemes become inefficient when only a subset of the encoded qubits is required to participate in the non-local entangling gate, leading to an exponential increase in the number of non-local gates. In this Letter, we address this bottleneck by demonstrating the existence of multi-level control-Z (CZ) gates for qudits encoded in multiple spatial modes in LOQC. Unlike conventional two-level CZ gates, which act only on a single pair of modes, multi-level CZ gates impart a conditional phase shift for an arbitrarily chosen subset of the spatial modes. We present two explicit linear optical schemes that realize such operations, illustrating a fundamental trade-off between prior information about the input quantum state and the physical resources required. The first scheme is realized with a constant success probability of $1/8$ independent of the qudit dimension using a single non-local entangling gate, at the cost of state dependence, which is significantly better than the current success probability of $1/9$. Our second scheme provides a fully state independent realization reducing the number of non-local gates to $\\mathcal{O}(2^{r_1}+2^{r_2})$ as compared to the existing bound of $\\mathcal{O}(2^{r_1+r_2})$ where $r_1$ and $r_2$ are the number of qubits to be removed as control in the qudits. The success probability of the realization is $\\frac{1}{2} \\left(\\frac{1}{8}\\right)^{2^{r_1}+2^{r_2}}$. When combined with qudit circuit compression schemes, our results improve upon a key scalability limitation and significantly improve the efficiency of LOQC architectures."
  },
  {
    "date": "2026-02-09",
    "title": "Controlled Flight of an Insect-Scale Flapping-Wing Robot via Integrated Onboard Sensing and Computation",
    "authors": "Yi-Hsuan Hsiao, Quang Phuc Kieu, Zhongtao Guan, Suhan Kim, Jiaze Cai, Owen Matteson, Jonathan P. How, Elizabeth Farrell Helbling, YuFeng Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08328v1",
    "source": "arXiv",
    "abstract": "Aerial insects can effortlessly navigate dense vegetation, whereas similarly sized aerial robots typically depend on offboard sensors and computation to maintain stable flight. This disparity restricts insect-scale robots to operation within motion capture environments, substantially limiting their applicability to tasks such as search-and-rescue and precision agriculture. In this work, we present a 1.29-gram aerial robot capable of hovering and tracking trajectories with solely onboard sensing and computation. The combination of a sensor suite, estimators, and a low-level controller achieved centimeter-scale positional flight accuracy. Additionally, we developed a hierarchical controller in which a human operator provides high-level commands to direct the robot's motion. In a 30-second flight experiment conducted outside a motion capture system, the robot avoided obstacles and ultimately landed on a sunflower. This level of sensing and computational autonomy represents a significant advancement for the aerial microrobotics community, further opening opportunities to explore onboard planning and power autonomy."
  },
  {
    "date": "2026-02-09",
    "title": "stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation",
    "authors": "Lucas Maes, Quentin Le Lidec, Dan Haramati, Nassim Massaudi, Damien Scieur, Yann LeCun, Randall Balestriero",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08968v1",
    "source": "arXiv",
    "abstract": "World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-worldmodel (SWM), a modular, tested, and documented world-model research ecosystem that provides efficient data-collection tools, standardized environments, planning algorithms, and baseline implementations. In addition, each environment in SWM enables controllable factors of variation, including visual and physical properties, to support robustness and continual learning research. Finally, we demonstrate the utility of SWM by using it to study zero-shot robustness in DINO-WM."
  },
  {
    "date": "2026-02-09",
    "title": "Representation theory of inhomogeneous Gaussian unitaries",
    "authors": "Jingqi Sun, Joshua Combes, Lucas Hackl",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08611v1",
    "source": "arXiv",
    "abstract": "Gaussian unitaries, generated by quadratic Hamiltonians, are fundamental in quantum optics and continuous-variable computing. Their structures correspond to symplectic (bosons) and orthogonal (fermions) groups, but physical realizations give rise to their respective double covers, introducing phase and sign ambiguities. The homogeneous (quadratic-only) case has been resolved through a parameterization constructed in a recent work [arXiv:2409.11628]. We extend the previous framework to inhomogeneous Gaussian unitaries parameterized by $(M,z,Ψ)$. The Baker-Campbel-Hausdorff formula allows us then to factor any Gaussian unitary into a squeezing and a displacement transformation, from which we derive the group multiplication law."
  },
  {
    "date": "2026-02-09",
    "title": "Multi-Staged Framework for Safety Analysis of Offloaded Services in Distributed Intelligent Transportation Systems",
    "authors": "Robin Dehler, Oliver Schumann, Jona Ruof, Michael Buchholz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08821v1",
    "source": "arXiv",
    "abstract": "The integration of service-oriented architectures (SOA) with function offloading for distributed, intelligent transportation systems (ITS) offers the opportunity for connected autonomous vehicles (CAVs) to extend their locally available services. One major goal of offloading a subset of functions in the processing chain of a CAV to remote devices is to reduce the overall computational complexity on the CAV. The extension of using remote services, however, requires careful safety analysis, since the remotely created data are corrupted more easily, e.g., through an attacker on the remote device or by intercepting the wireless transmission. To tackle this problem, we first analyze the concept of SOA for distributed environments. From this, we derive a safety framework that validates the reliability of remote services and the data received locally. Since it is possible for the autonomous driving task to offload multiple different services, we propose a specific multi-staged framework for safety analysis dependent on the service composition of local and remote services. For efficiency reasons, we directly include the multi-staged framework for safety analysis in our service-oriented function offloading framework (SOFOF) that we have proposed in earlier work. The evaluation compares the performance of the extended framework considering computational complexity, with energy savings being a major motivation for function offloading, and its capability to detect data from corrupted remote services."
  },
  {
    "date": "2026-02-09",
    "title": "Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation",
    "authors": "Yanglei Gan, Peng He, Yuxiang Cai, Run Lin, Guanyu Zhou, Qiao Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08815v1",
    "source": "arXiv",
    "abstract": "Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate ordering but provides little supervision over the calibration of the denoised embedding. To bridge this gap, we introduce Negative-Aware Diffusion model for TKG Extrapolation (NADEx). Specifically, NADEx encodes subject-centric histories of entities, relations and temporal intervals into sequential embeddings. NADEx perturbs the query object in the forward process and reconstructs it in reverse with a Transformer denoiser conditioned on the temporal-relational context. We further derive a cosine-alignment regularizer derived from batch-wise negative prototypes, which tightens the decision boundary against implausible candidates. Comprehensive experiments on four public TKG benchmarks demonstrate that NADEx delivers state-of-the-art performance."
  },
  {
    "date": "2026-02-09",
    "title": "Robust Policy Optimization to Prevent Catastrophic Forgetting",
    "authors": "Mahdi Sabbaghi, George Pappas, Adel Javanmard, Hamed Hassani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08813v1",
    "source": "arXiv",
    "abstract": "Large language models are commonly trained through multi-stage post-training: first via RLHF, then fine-tuned for other downstream objectives. Yet even small downstream updates can compromise earlier learned behaviors (e.g., safety), exposing a brittleness known as catastrophic forgetting. This suggests standard RLHF objectives do not guarantee robustness to future adaptation. To address it, most prior work designs downstream-time methods to preserve previously learned behaviors. We argue that preventing this requires pre-finetuning robustness: the base policy should avoid brittle high-reward solutions whose reward drops sharply under standard fine-tuning. We propose Fine-tuning Robust Policy Optimization (FRPO), a robust RLHF framework that optimizes reward not only at the current policy, but across a KL-bounded neighborhood of policies reachable by downstream adaptation. The key idea is to ensure reward stability under policy shifts via a max-min formulation. By modifying GRPO, we develop an algorithm with no extra computation, and empirically show it substantially reduces safety degradation across multiple base models and downstream fine-tuning regimes (SFT and RL) while preserving downstream task performance. We further study a math-focused RL setting, demonstrating that FRPO preserves accuracy under subsequent fine-tuning."
  },
  {
    "date": "2026-02-09",
    "title": "Efficient Deep Learning for Biometrics: Overview, Challenges and Trends in Ear of Frugal AI",
    "authors": "Karim Haroun, Aya Zitouni, Aicha Zenakhri, Meriem Amel Guessoum, Larbi Boubchir",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08809v1",
    "source": "arXiv",
    "abstract": "Recent advances in deep learning, whether on discriminative or generative tasks have been beneficial for various applications, among which security and defense. However, their increasing computational demands during training and deployment translates directly into high energy consumption. As a consequence, this induces a heavy carbon footprint which hinders their widespread use and scalability, but also a limitation when deployed on resource-constrained edge devices for real-time use. In this paper, we briefly survey efficient deep learning methods for biometric applications. Specifically, we tackle the challenges one might incur when training and deploying deep learning approaches, and provide a taxonomy of the various efficient deep learning families. Additionally, we discuss complementary metrics for evaluating the efficiency of these models such as memory, computation, latency, throughput, and advocate for universal and reproducible metrics for better comparison. Last, we give future research directions to consider."
  },
  {
    "date": "2026-02-09",
    "title": "Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures",
    "authors": "Liming Zhou, Ailing Liu, Hongwei Liu, Min He, Heng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08804v1",
    "source": "arXiv",
    "abstract": "Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusion structure is designed to integrate multi-source telemetry data, while the contextual reasoning capability of large language models is leveraged to model temporal and cross-microservice causal dependencies. Experimental results on CCF-AIOps microservice datasets demonstrate that RC-LLM achieves strong accuracy and efficiency in root cause analysis."
  },
  {
    "date": "2026-02-09",
    "title": "The Use of AI Tools to Develop and Validate Q-Matrices",
    "authors": "Kevin Fan, Jacquelyn A. Bialo, Hongli Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.08796v1",
    "source": "arXiv",
    "abstract": "Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed."
  },
  {
    "date": "2026-2-9",
    "title": "RespireNet: Enhancing Lung Sound Classification using CNN-TCN Hybrid Approach",
    "authors": "Reshma Sreejith, R Kanesaraj Ramasamy, Wan-Noorshahida Mohd-Isa, Junaidi Abdullah, Shamsuriani Md. Jamal, Faizal Amri Hamzah, Sivasutha Thanjappan",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787132",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "DALD-PCAC: Density-Adaptive Learning Descriptor for Point Cloud Lossless Attribute Compression",
    "authors": "Chunyang Fu, Ge Li, Wei Gao, Shiqi Wang, Zhu Li, Shan Liu",
    "publish": "ACM Transactions on Multimedia Computing, Communications, and Applications",
    "url": "https://doi.org/10.1145/3785465",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "RoTransMIL: Rotary Positional Embedding for Transformer-based Multiple Instance Learning",
    "authors": "Taro Nitta, Masataka Kawai",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787131",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Interactive-SmartClerk: A Recommender Robot System Sharing Preferences with Customer",
    "authors": "Hikaru Matsuzaki, Tomoyuki Maekawa, Kentaro Ishii, Michita Imai",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787133",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "On the Reruns of GitHub Actions Workflows",
    "authors": "Jiangnan Huang, Bin Lin",
    "publish": "ACM Transactions on Software Engineering and Methodology",
    "url": "https://doi.org/10.1145/3795771",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "MTF: an Open-Source Metamorphic Testing Framework for LLM-based systems",
    "authors": "Theis Henry, Sian Savourat, Lydie du Bousquet, Masahide Nakamura",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787123",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Designing Ethics or Manipulating It: Who Needs Ethics in a Multi-Agent Virtual Space?",
    "authors": "Kathleen Bryson, Kathleen Richardson",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787129",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Program Behavior Gaps: An Extension of the Rules of Program Behavior Framework",
    "authors": "Jesse Hoobergs, Tom Schrijvers, Felienne Hermans",
    "publish": "ACM Transactions on Computing Education",
    "url": "https://doi.org/10.1145/3796523",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series",
    "authors": "Muyan Anna Li, Aditi Gautam",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787130",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Enhancing Morphological Discrimination in Red Blood Cell Images via Multi-Level Attention",
    "authors": "Yidong Cao, Zhipeng Liu, Haozhe Liu, Chuantong Zhang, Yu Gao, Shangce Gao",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787124",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Adaptive Geometric Attention-Driven No-Reference Multi-Modal Point Cloud Quality Assessment",
    "authors": "Zhihao Jia, Hao Liu, Shuo Zhang, Yonghua Zhang, Yang Lu, Ziqing Huang, Shiguang Liu",
    "publish": "ACM Transactions on Multimedia Computing, Communications, and Applications",
    "url": "https://doi.org/10.1145/3795690",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "authors": "N/A",
    "publish": "N/A",
    "url": "https://doi.org/10.1145/3787120",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Solving Derangement Problems by Particle Swarm Optimization",
    "authors": "Pavel Kromer, Vojtech Uher",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787136",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "End-to-end Viewpoint Optimization for Inspection based on Defect Detectability Assessment",
    "authors": "Yuzhe Zhang, Hongchao Fang, Hwee Ping Ng",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787121",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Bridging Personality Theory and Emotion Dynamics for Intelligent Robots: An MBTI-to-OCEAN-PAD Approach",
    "authors": "Ruochen Liu, Haizhen Li, Kun Xu, Xilun Ding",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787127",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Light Status Recognition and Runtime Analytics Using YOLOv5-tiny",
    "authors": "Warit Attharat, Supattra Puttinaovarat, Kritsada Puangsuwan",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787128",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "DHMNet: Dendritic Learning-enhanced MobileNet for Intracranial Hemorrhage Detection in Head CT Scans",
    "authors": "Zhipeng Liu, Yidong Cao, Chuantong Zhang, Qingya Sui, Lin Zhong, Shangce Gao",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787125",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Program Debloating via Multi-Granularity Stochastic Optimization",
    "authors": "Jinran Tang, Shufan Gong, Hao Chen, Qi Xin, Xiaoyuan Xie, Jifeng Xuan",
    "publish": "ACM Transactions on Software Engineering and Methodology",
    "url": "https://doi.org/10.1145/3796513",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "MetaML-Pro: Cross-Stage Design Flow Automation for Efficient Deep Learning Acceleration",
    "authors": "Zhiqiang Que, Jose G. F. Coutinho, Ce Guo, Hongxiang Fan, Wayne Luk",
    "publish": "ACM Transactions on Reconfigurable Technology and Systems",
    "url": "https://doi.org/10.1145/3795794",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Comparative Performance of YOLOv5-tiny and YOLOv8-m for Insect Pest Detection",
    "authors": "Boorapa Chuenarrom, Kritsada Puangsuwan, Nathaphon Boonnam",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787126",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Functional Diversity in Deep Ensembles via Wasserstein Representation Alignment",
    "authors": "Haowei Huang, Junyu Xuan",
    "publish": "ACM Transactions on Probabilistic Machine Learning",
    "url": "https://doi.org/10.1145/3795796",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Representing Tuple in Graph with Trail Structure",
    "authors": "Zhongbao Zhang, Zhizhen He, Junda Ye, Li Sun",
    "publish": "ACM Transactions on Knowledge Discovery from Data",
    "url": "https://doi.org/10.1145/3795689",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Effective False Alarm Reduction : Integrating Dual-Kernels and Random Projection in One-Class Support Vector Machine",
    "authors": "Imam Wijaya, Koji Takata",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787122",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Fix Pattern-Aware Vulnerability Patch Generation via In-Context Learning",
    "authors": "Miaomiao Shao, Yuxin Ding, Cuiyun Gao, Junru Wang, Guoqing Zhu",
    "publish": "ACM Transactions on Software Engineering and Methodology",
    "url": "https://doi.org/10.1145/3796512",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "A Soft Set-Based Classifier Pruning for Multi-Layer Stacking Ensembles in Churn Prediction",
    "authors": "Nurul Nadzirah Adnan, Mohd Khalid Awang, Mokhairi Makhtar",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787137",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Beyond Bitrate: Understanding the QoE Impact of Playback Rate and Seeking in Adaptive Video Streaming",
    "authors": "Tomasz Lyko, Yehia Elkhatib, Rajiv Ramdhany, Nicholas Race",
    "publish": "ACM Transactions on Multimedia Computing, Communications, and Applications",
    "url": "https://doi.org/10.1145/3796724",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "Decoding AI Literacy: A Bibliometric Analysis of Global Research Trends, Thematic Evolution, and Future Directions",
    "authors": "Julaporn I-kitisiri, Danupol Hoonsopon, Wilert Puriwat",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787135",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-9",
    "title": "An Evolutionary Computation-based Approach for a Multi-Objective Drone-Assisted Relief Distribution Problem",
    "authors": "Setyo Tri Windras Mara, Saber Elsayed, Yuji Sato, Ruhul Amin Sarker",
    "publish": "Proceedings of the 2025 5th International Conference on Artificial Intelligence and Application Technologies",
    "url": "https://doi.org/10.1145/3787120.3787134",
    "source": "ACM",
    "abstract": "None"
  }
]