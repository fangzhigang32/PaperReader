[
  {
    "date": "2026-2-13",
    "title": "A Verification-First, Self-Healing Framework for LLM-Enabled Generation of CS1 Exercises",
    "authors": "Aneesh Durai, Anirudh Chaudhary, Naveen Nathan, Gireeja Ranade, Narges Norouzi",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777364",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "一种验证优先、自我修复的框架，用于支持大语言模型生成计算机科学导论课程练习题",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Can LLMs Be Effective Sensor Processing Copilots?",
    "authors": "Pengrui Quan, Xiaomin Ouyang, Jeya Vikranth Jeyakumar, Ziqi Wang, Yang Xing, Mani Srivastava",
    "publish": "IEEE Internet of Things Journal",
    "url": "https://doi.org/10.1109/jiot.2026.3664751",
    "source": "IEEE",
    "abstract": "Effective sensor data processing is critical for cyber-physical and IoT systems but often requires specialized expertise. While Large Language Models (LLMs) show promise as autonomous <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">copilots</i> for sensor processing, their capabilities remain underexplored. We introduce SensorBench, the first comprehensive benchmark for evaluating LLMs across diverse real-world sensor datasets and tasks. SensorBench evaluates three paradigms for leveraging LLMs in sensing tasks: Tool-Augmented Coding (TAC), Standalone Coding (SAC), and Direct Answer (DA). We evaluate 8 leading LLM variants, including 2 Large Reasoning Models (LRMs) and 2 domain-specific LLMs, providing a structured reference for absolute performance, latency, and resource requirements. Our analysis reveals that: (1) TAC significantly outperforms SAC and DA; (2) LLMs excel at simple tasks but consistently underperform domain experts on compositional tasks requiring parameter tuning and multi-step reasoning. (3) The reasoning mechanism introduced in LRMs does not yield substantial performance gains. To improve the performance, we explore four prompting strategies and fine-tuning approaches (using our newly released sensor-processing corpus). The results show that self-verification prompting proves most effective, outperforming other methods simultaneously in 48% of tasks, while fine-tuning yields marginal gains. Our analysis suggests that more sophisticated interaction frameworks, such as signal-level self-verification, may bridge the gap to human expert-level performance. This benchmark provides a foundation for evaluating and improving LLMs in sensing applications<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>.",
    "title_zh": "大型语言模型能否成为有效的传感器处理协作者？",
    "abstract_zh": "有效的传感器数据处理对于网络物理系统和物联网系统至关重要，但通常需要专门的技术专长。尽管大型语言模型（LLMs）作为传感器处理的自主“副驾驶”展现出巨大潜力，但其能力仍处于探索阶段。为此，我们提出了SensorBench——首个全面评估LLMs在多样化真实世界传感器数据集和任务上表现的基准测试平台。SensorBench评估了三种利用LLMs进行传感任务的范式：工具增强编码（TAC）、独立编码（SAC）和直接回答（DA）。我们对8种主流LLM变体进行了评估，包括2种大型推理模型（LRMs）和2种领域专用LLM，为绝对性能、延迟和资源需求提供了结构化参考。我们的分析揭示了以下发现：（1）TAC显著优于SAC和DA；（2）LLMs在简单任务中表现优异，但在需要参数调优和多步推理的复合任务上，始终无法达到领域专家的水平；（3）LRMs中引入的推理机制并未带来显著的性能提升。为提升性能，我们探索了四种提示策略和微调方法（基于我们新发布的传感器处理语料库）。结果表明，自我验证提示策略在48%的任务中同时优于其他方法，而微调带来的收益则十分有限。我们的分析表明，更复杂的交互框架（如信号级自我验证）可能有助于缩小与人类专家水平之间的差距。该基准测试为评估和提升LLMs在传感应用中的表现奠定了基础<sup>1</sup>。"
  },
  {
    "date": "2026-2-13",
    "title": "Intelligent Document Query System using Retrieval-Augmented Generation (RAG)",
    "authors": "Rosario Gilmary, B. Pradeepa, N. Manvizhi, D. Nivedha",
    "publish": "2025 5th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS)",
    "url": "https://doi.org/10.1109/icuis67429.2025.11380714",
    "source": "IEEE",
    "abstract": "The RAG Chatbot can be considered an AI document-interactive system that integrates Retrieval-Augmented Generation (RAG) technology, thus allowing the owner to interact with their archival documents. It uses Streamlit for its user interface with the backend employing Ollama for the local running of the Large Language Model (LLM) and FAISS for fast vector-based similarity search. The users can upload their documents in formats such as PDF, DOCX, and TXT which are then directly subjected to the text extraction, chunking, and embedding generation process. The embeddings that are produced are indexed by FAISS which allows the chatbot to retrieve the document parts relevant to its answer. The system architecture assures that the response generated by the LLM is always tied to the user's document improving precision and enabling the customer to identify the information source. Besides, the chatbot has features such as document management in real-time, debug mode for response tracing, and local data persistence that not only augment its functionalities but also guarantee privacy. This project illustrates a complete end-to-end realization of a local RAG pipeline integrating language comprehension, retrieval speed, and user engagement in a seamless conversational interface.",
    "title_zh": "基于检索增强生成（RAG）的智能文档查询系统",
    "abstract_zh": "该RAG聊天机器人可被视为一种集成检索增强生成（RAG）技术的AI文档交互系统，使用户能够与其归档文档进行互动。其前端采用Streamlit构建用户界面，后端则利用Ollama在本地运行大型语言模型（LLM），并使用FAISS实现基于向量的快速相似性搜索。用户可上传PDF、DOCX和TXT等格式的文档，系统会立即对文档进行文本提取、分块处理及嵌入向量生成。生成的嵌入向量由FAISS进行索引，使聊天机器人能够检索与回答相关联的文档内容片段。该系统架构确保LLM生成的回应始终基于用户文档，从而提升回答的准确性，并使用户能够追溯信息来源。此外，该聊天机器人还具备实时文档管理、响应追踪的调试模式以及本地数据持久化等特性，不仅增强了系统功能，也保障了数据隐私。本项目完整实现了本地RAG流程的端到端构建，将语言理解、检索速度与用户交互无缝融合于一个流畅的对话界面中。"
  },
  {
    "date": "2026-2-13",
    "title": "CodeFlow: LLM-Generated Flowchart Feedback for Programming Students",
    "authors": "Kehao Zheng, Yang Shi",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777175",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "CodeFlow：基于大模型生成的流程图反馈系统，用于编程学习者",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Fine-Tuning Open-Source Models as a Viable Alternative to Proprietary LLMs for Explaining Compiler Messages",
    "authors": "Lorenzo Lee Solano, Charles Koutcheme, Juho Leinonen, Alexandra Vassar, Jake Renzella",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.1",
    "url": "https://doi.org/10.1145/3770762.3772576",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "微调开源模型作为解释编译器消息的专有大语言模型的可行替代方案",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Exploring LLMs for Generating Erroneous Examples in CS1",
    "authors": "Yuxuan Chen, Chenyan Zhao, Kangyu Feng, Junyu Zhang, Vedan Malhotra, Mariana Silva",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777210",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "探索大型语言模型在计算机科学导论课程中生成错误示例的应用",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Evolutionary Generative Optimization: Towards Fully Data-Driven Evolutionary Optimization via Generative Learning",
    "authors": "Tao Jiang, Kebin Sun, Zhenyu Liang, Ran Cheng, Yaochu Jin, Kay Chen Tan",
    "publish": "IEEE Transactions on Evolutionary Computation",
    "url": "https://doi.org/10.1109/tevc.2026.3664432",
    "source": "IEEE",
    "abstract": "Recent advances in data-driven evolutionary algorithms (EAs) have demonstrated the potential of leveraging historical data to improve optimization accuracy and adaptability. Despite these advancements, existing methods remain reliant on handcrafted process-level operators. In contrast, Evolutionary Generative Optimization (EvoGO) is a fully data-driven framework designed from the objective level, enabling autonomous learning of the entire search process. EvoGO streamlines the evolutionary optimization process into three stages: data preparation, model training, and population generation. The data preparation stage constructs a pairwise dataset to enrich training diversity without incurring additional evaluation costs. During model training, a tailored generative model learns to transform inferior solutions into superior ones. In the population generation stage, EvoGO replaces traditional reproduction operators with a scalable and parallelizable generative mechanism. Extensive experiments on numerical benchmarks, classical control problems, and high-dimensional robotic tasks demonstrate that EvoGO consistently converges within merely 10 generations and substantially outperforms a wide spectrum of optimization approaches, including traditional EAs, Bayesian optimization, and reinforcement learning based methods. Code is available at: https://github.com/EMI-Group/evogo.",
    "title_zh": "进化生成优化：通过生成学习迈向完全数据驱动的进化优化",
    "abstract_zh": "近年来，数据驱动的进化算法（EAs）取得了显著进展，展示了利用历史数据提升优化精度与适应性的巨大潜力。尽管如此，现有方法仍依赖于人工设计的过程级算子。相比之下，进化生成优化（EvoGO）是一种完全数据驱动的框架，从目标层面出发设计，能够自主学习整个搜索过程。EvoGO将进化优化过程简化为三个阶段：数据准备、模型训练和种群生成。在数据准备阶段，构建成对数据集以丰富训练多样性，且无需额外的评估成本。在模型训练阶段，采用定制化的生成模型学习将劣质解转化为优质解。在种群生成阶段，EvoGO用可扩展且可并行化的生成机制替代传统繁殖算子。在数值基准测试、经典控制问题以及高维机器人任务上的大量实验表明，EvoGO仅需约10代即可稳定收敛，并显著优于多种优化方法，包括传统进化算法、贝叶斯优化以及基于强化学习的方法。代码已开源，地址为：https://github.com/EMI-Group/evogo。"
  },
  {
    "date": "2026-2-13",
    "title": "AI Agent based SaaS Platform (AIBSP)",
    "authors": "MsAnju, Abhimannew Vinuroy Smitha, Arya.J, Madhav K, Bachu Skanda",
    "publish": "2025 5th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS)",
    "url": "https://doi.org/10.1109/icuis67429.2025.11380629",
    "source": "IEEE",
    "abstract": "This work presents a web-based AI-powered platform named AI SAP Tools, designed to deliver intelligent SaaS-based utilities such as research paper summarization, subtitle generation, PDF-based question answering, and data analysis. The system integrates multiple AI models, including large language models (LLMs) and speech-to-text engines, to power and improve user output in academic, professional, and enterprise contexts. Each tool acts as an independent AI agent, interacting via a combined interface that allows users to select and use tools as needed. The platform works on coin-based subscription model using Coins, allowing micro-payments for tool usage instead of traditional fixed plans. System performance is evaluated in terms of response accuracy, processing time, and user efficiency. Results indicate improved task automation and accessibility when compared to conventional manual processes. This approach aims to democratize AI access for a wider user base and establish a scalable framework for deploying AI utilities in SaaS environments. Future improvements includes adding performance analyzer and increasing multilingual support.",
    "title_zh": "基于AI代理的SaaS平台（AIBSP）",
    "abstract_zh": "本研究提出了一种基于Web的AI驱动平台——AI SAP Tools，旨在提供智能化的SaaS工具服务，包括论文摘要生成、字幕自动生成、基于PDF的问答系统以及数据分析等功能。该系统整合了多种人工智能模型，如大语言模型（LLMs）和语音转文字引擎，以在学术、职场及企业应用场景中提升用户输出的质量与效率。每个工具均作为独立的AI代理运行，通过统一的交互界面供用户按需选择和使用。平台采用基于“积分”（Coins）的订阅模式，支持按使用量进行微支付，取代传统的固定套餐模式。系统性能通过响应准确性、处理时间及用户效率等指标进行评估，结果表明，相较于传统人工操作，该平台显著提升了任务自动化水平与使用便捷性。该方法致力于降低AI技术的使用门槛，使更广泛的用户群体能够平等获取AI能力，并为SaaS环境中AI工具的部署建立可扩展的框架。未来改进方向包括增加性能分析功能以及进一步增强多语言支持能力。"
  },
  {
    "date": "2026-2-13",
    "title": "Lifecycle-Wide AI Security Enhancement using Generative AI: A Unified Framework for Robustness, Privacy, and Self-Healing",
    "authors": "V.V.A.S.Lakshmi, U.Usha Rani, P. V.Sateesh Kumar, A.Pavithra, Ch.Sudharshan Reddy, Bala Veeravatnam",
    "publish": "2025 5th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS)",
    "url": "https://doi.org/10.1109/icuis67429.2025.11380238",
    "source": "IEEE",
    "abstract": "The rapid rise of artificial intelligence (AI) in key industries has created significant security challenges that affect the entire AI process. This includes collecting data, training models, deploying systems, and maintaining them over time. While Generative AI (GAI) provides useful tools like synthetic data generation and adversarial scenario modeling, most current methods focus only on protecting individual stages instead of the entire lifecycle. To fill this gap, this paper presents a unified, end- to-end GAI-enabled security framework aimed at providing ongoing, flexible protection at every stage of AI development. The framework combines high-quality synthetic data generation, realistic adversarial threat simulation, and automated self-healing features to build AI systems that are both resilient and safeguard privacy. Evaluations on a large healthcare dataset show significant improvements, including a 14.7% boost in adversarial strength, under 3.5% difference between real and synthetic data, and a 96% success rate in recovering from performance issues. These results demonstrate the practical benefits and technical importance of incorporating GAI throughout the security lifecycle, providing a scalable and flexible foundation for protecting next-generation AI systems in sensitive and high-risk areas.",
    "title_zh": "基于生成式人工智能的全生命周期AI安全增强：一种统一的鲁棒性、隐私保护与自愈框架",
    "abstract_zh": "人工智能（AI）在关键行业的迅速崛起，给整个AI流程带来了重大的安全挑战。这些挑战贯穿于数据收集、模型训练、系统部署以及长期维护等各个环节。尽管生成式人工智能（GAI）提供了诸如合成数据生成和对抗性场景建模等实用工具，但目前大多数方法仅关注保护单一环节，而未能覆盖整个生命周期。为弥补这一空白，本文提出了一种统一的、端到端的GAI赋能安全框架，旨在为AI开发的每个阶段提供持续且灵活的安全防护。该框架融合了高质量的合成数据生成、逼真的对抗性威胁模拟以及自动化的自我修复功能，构建出既具备韧性又保障隐私的AI系统。在大规模医疗数据集上的评估结果显示，系统性能显著提升：对抗攻击强度提高14.7%，真实数据与合成数据之间的差异低于3.5%，且在应对性能问题时恢复成功率高达96%。这些结果充分展示了将GAI贯穿于安全生命周期所带来的实际效益和技术价值，为保护敏感和高风险领域中的下一代AI系统提供了可扩展、灵活的基础支撑。"
  },
  {
    "date": "2026-2-13",
    "title": "Individualized Quizzes From Student Code with LLMs",
    "authors": "Ed Novak, Bradley McDanel",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777181",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "基于学生代码的个性化测验生成：利用大语言模型",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Design and Simulation of Core Image Processing Techniques Using MATLAB and Verilog",
    "authors": "Bala Sindhuri Kandula, G. Challa Ram, Sangeeta Singh, Subhashini Tata, R. Prameela Devi, M. Aravind Kumar",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11383195",
    "source": "IEEE",
    "abstract": "Image processing enhances visual information for effective analysis in domains such as medical imaging, satellite observation, and digital media. This work presents the fundamental pre-processing operations such as Posterize, Red Channel Extraction, Red Tint, and Warm Red Tint—on test images using a MATLAB–Verilog co-design approach.. MATLAB is used for file conversion while Verilog models the algorithms for functional verification. Simulation results confirm the correctness of the operations and highlight the framework’s potential as a scalable foundation for real-time image enhancement applications.",
    "title_zh": "基于MATLAB与Verilog的核心图像处理技术设计与仿真",
    "abstract_zh": "图像处理通过增强视觉信息，为医学影像、卫星观测和数字媒体等领域提供有效的分析支持。本文采用MATLAB与Verilog协同设计方法，对测试图像实施了若干基本预处理操作，包括图像海报化（Posterize）、红色通道提取、红色滤镜以及暖红色滤镜。其中，MATLAB用于文件格式转换，而Verilog则用于算法建模以实现功能验证。仿真结果验证了各项操作的正确性，并凸显了该框架在实时图像增强应用中作为可扩展基础的巨大潜力。"
  },
  {
    "date": "2026-2-13",
    "title": "Toward Automated Validation of Language Model Synthesized Test Cases using Semantic Entropy",
    "authors": "Hamed Taherkhani, Jiho Shin, Muhammad Ammar Tahir, Md Rakib Hossain Misu, Vineet Sunil Gattani, Hadi Hemmati",
    "publish": "IEEE Transactions on Software Engineering",
    "url": "https://doi.org/10.1109/tse.2026.3664287",
    "source": "IEEE",
    "abstract": "Modern Large Language Model (LLM)-based programming agents often rely on test execution feedback to refine their generated code. These tests are synthetically generated by LLMs. However, LLMs may produce invalid or hallucinated test cases, which can mislead feedback loops and degrade the performance of agents in refining and improving code. This paper introduces <monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">VALTEST</monospace>, a novel framework that leverages semantic entropy to automatically validate test cases generated by LLMs. By analyzing the semantic structure of test cases and computing entropy-based uncertainty measures, <monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">VALTEST</monospace> trains a machine learning model to classify test cases as valid or invalid and filters out invalid test cases. Experiments on multiple benchmark datasets and various LLMs show that <monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">VALTEST</monospace> not only boosts test validity by up to 29% but also improves code generation performance, as evidenced by significant increases in pass@1 scores. Our extensive experiments also reveal that semantic entropy is a reliable indicator to distinguish between valid and invalid test cases and provides a robust solution for improving the correctness of LLM-generated test cases used in software testing and code generation.",
    "title_zh": "基于语义熵的自动化验证语言模型生成的测试用例",
    "abstract_zh": "基于现代大型语言模型（LLM）的编程代理通常依赖于测试执行反馈来优化其生成的代码。这些测试用例由LLM自动生成，但LLM可能产生无效或虚构的测试用例，从而误导反馈循环，降低代理在代码优化与改进方面的性能。本文提出了一种名为<monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">VALTEST</monospace>的新框架，该框架利用语义熵自动验证LLM生成的测试用例。通过分析测试用例的语义结构并计算基于熵的不确定性度量，<monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">VALTEST</monospace>训练一个机器学习模型，以区分测试用例的有效性，并过滤掉无效的测试用例。在多个基准数据集和不同LLM上的实验表明，<monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">VALTEST</monospace>不仅将测试有效性提升了高达29%，还显著提高了代码生成性能，表现为pass@1得分的显著增长。大量实验进一步揭示，语义熵是一种可靠的指标，能够有效区分有效与无效的测试用例，为提升LLM生成测试用例在软件测试与代码生成中的正确性提供了稳健的解决方案。"
  },
  {
    "date": "2026-2-13",
    "title": "Generative AI for ETL Automation: Revolutionizing Data Flow Management",
    "authors": "Naveen Kolli, Milan Parikh, Veeravenkata Maruthi Lakshmi Ganesh Nerella, Kathiresan Jayabalan, Shivaranjani Sankara Krishnan, R.Maruthi",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11382614",
    "source": "IEEE",
    "abstract": "The diversity of heterogeneous data sources in pervasive modern enterprises requires scalable and adaptable Extract-Transform-Load (ETL) pipelines. Established rule-based ETL approaches and template-driven ETL frameworks suffer from rigid structures and are not suited to deal with schema drift resulting in increased maintenance and higher development costs compared to auto-generated ETL pipelines. This paper describes GenETL based on leveraging generative-AI large language models and semantic embeddings for automated schema inference, automated transformation rule generation, and dynamic pipeline orchestration. The generative methodology is supported by a feedback reinforcement loop and generative test cases to improve performance with every run. Benchmark tests, against four existing ETL methods demonstrate an overall 97% transformation accuracy, 85% automation rate, and 6-hour adaptation to the changes in the source schema for provided data flows. This positive result demonstrates a significant reduction in the time to create an ETL pipeline and overall improvement in data quality. Future work plans extend GenETL to support near real-time streaming generation requirements, further domain-specific tuning, and data privacy-preserving automation of the pipeline generation process.",
    "title_zh": "生成式AI赋能ETL自动化：革新数据流管理",
    "abstract_zh": "现代企业中异构数据源的多样性要求ETL（抽取-转换-加载）流程具备可扩展性和适应性。传统的基于规则的ETL方法和模板驱动的ETL框架由于结构僵化，难以应对模式漂移问题，导致维护成本增加、开发成本上升，相较于自动生成的ETL流程效率更低。本文提出GenETL，利用生成式AI大型语言模型与语义嵌入技术，实现自动模式推断、自动化转换规则生成以及动态管道编排。该生成式方法通过反馈强化循环和生成式测试用例，在每次运行中持续优化性能。与四种现有ETL方法的基准测试结果表明，GenETL在整体转换准确率上达到97%，自动化率达85%，对源模式变更的适应时间仅需6小时。这一积极成果显著缩短了ETL管道的构建时间，并整体提升了数据质量。未来工作计划将扩展GenETL以支持近实时流式数据生成需求，进一步进行领域特定优化，并实现数据隐私保护下的管道生成自动化。"
  },
  {
    "date": "2026-2-13",
    "title": "Improving LLM-Generated Educational Content: A Case Study on Prototyping, Prompt Engineering, and Evaluating a Tool for Generating Programming Problems for Data Science",
    "authors": "Jiaen Yu, Ylesia Wu, Gabriel Cha, Ayush Shah, Samuel Lau",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.1",
    "url": "https://doi.org/10.1145/3770762.3772619",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "提升大语言模型生成的教育内容：以生成数据科学编程题的工具原型设计、提示工程与评估为例的案例研究",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Detecting AI-Generated Code in Introductory Programming Courses",
    "authors": "Aryan Ramachandra, Suhani Chaudhary, Justin Tran, Riti Desai, Ashley Pang, Mariam Salloum",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.1",
    "url": "https://doi.org/10.1145/3770762.3772522",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "在入门编程课程中检测人工智能生成的代码",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "State Transition Graph-Based Pipelined Sequential Multiplier",
    "authors": "Basavaraj, M. Vinodhini, C. Paramasivam",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11383082",
    "source": "IEEE",
    "abstract": "This paper presents a State Transition Graph (STG)-based Pipelined Sequential Multiplier designed for high-throughput and efficient multiplication operations in VLSI systems. The proposed architecture extends a conventional STG-based multiplier by introducing a five-stage pipeline, where each stage performs progressive partial product accumulation based on the bits of the multiplier input. This pipelining significantly reduces latency and enhances throughput by enabling stage-wise computation overlap, while preserving the area and control simplicity of traditional sequential designs. The design is implemented in Verilog HDL, functionally verified using Xilinx Vivado, and synthesized for ASIC deployment using Cadence Genus in 45 nm technology node. Additionally, Static Timing Analysis (STA), including setup and hold checks, was performed using Cadence Tempus, confirming improved timing closure and enabling higher clock frequencies. Compared with the previous STG design, the proposed multiplier achieves significantly higher throughput, along with reduced critical path delay and improved operating speed. These improvements make it highly suitable for high-speed VLSI applications.",
    "title_zh": "基于状态转移图的流水线顺序乘法器",
    "abstract_zh": "本文提出了一种基于状态转移图（STG）的流水线化顺序乘法器，专为VLSI系统中的高吞吐量和高效乘法运算而设计。所提出的架构在传统STG乘法器的基础上进行了扩展，引入了五级流水线结构，每一级根据乘数输入的位进行逐步的部分积累加。该流水线设计显著降低了延迟，通过各阶段计算的重叠提升了吞吐量，同时保持了传统顺序设计在面积和控制逻辑上的简洁性。该设计采用Verilog HDL实现，使用Xilinx Vivado进行功能验证，并通过Cadence Genus工具在45 nm工艺节点上完成ASIC综合。此外，利用Cadence Tempus工具进行了静态时序分析（STA），包括建立时间和保持时间检查，验证了时序收敛性提升，支持更高的时钟频率。与先前的STG设计相比，所提出的乘法器在吞吐量、关键路径延迟和工作速度方面均实现了显著改进，使其特别适用于高速VLSI应用场景。"
  },
  {
    "date": "2026-2-13",
    "title": "PromptFixer: An AI-based System for Improving and Structuring User Prompts for Language Model",
    "authors": "Medamanoori Dhanush, Briso Becky Bell",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11382812",
    "source": "IEEE",
    "abstract": "The rise in the use of large language models (LLMs) such as ChatGPT, Claude, and Gemini has highlighted the need for well-designed prompts to achieve meaningful and effective responses. Nonetheless, the users frequently fail to devise effective prompts, which results in ambiguous, insufficient, or grammatically incorrect instructions. The current paper presents PromptFixer, an AI-powered interface that will be deployable to analyze, improve, and streamline a user input so that it can be used and interacted with by an LLM in the best way possible. PromptFixer understands intent and grammatical structure in prompts by figuring out how to implement natural language processing techniques--part-of-speech tagging, dependency parsing, and named entity recognition--in the context of prompts. The system sorts through prompts, which are categorized as informational requests, commands, or programmatic calls, and optimizes them through the state of the art transformer models like FLAN-T5 and GPT-2. A safety module also identifies poisonous or unethical inputs by means of zero-shot classifiers and toxicity APIs. Sentence-Bert used during similarity testing is to retain semantic completeness whereas the quality of the output is measured against metrics such as BERTScore and readability indices. The given system improves timely comprehensibility, security, and adequacy, and will lead to better interaction possibilities between humans and AI in various sectors, including content creation, programming, and online learning.",
    "title_zh": "PromptFixer：一种基于人工智能的用户提示优化与结构化系统",
    "abstract_zh": "大型语言模型（LLMs）如ChatGPT、Claude和Gemini的广泛应用，凸显了设计优质提示（prompt）以获得有意义且高效响应的重要性。然而，用户常常无法制定出有效的提示，导致指令模糊、信息不足或语法错误。本文提出了一种名为PromptFixer的人工智能驱动界面，该系统可部署用于分析、优化和简化用户输入，使其能够以最佳方式被LLM理解和交互。PromptFixer通过运用自然语言处理技术——词性标注、依存句法分析和命名实体识别——来理解提示中的意图与语法结构。系统能够识别提示的类型，如信息查询、指令或程序调用，并利用先进的Transformer模型（如FLAN-T5和GPT-2）对其进行优化。此外，系统还配备安全模块，通过零样本分类器和毒性检测API识别有害或不道德的输入内容。在相似性测试中，采用Sentence-BERT以保持语义完整性，同时通过BERTScore和可读性指数等指标评估输出质量。该系统显著提升了提示的及时可理解性、安全性与准确性，将推动人类与人工智能在内容创作、编程及在线学习等多个领域实现更高效、更可靠的交互。"
  },
  {
    "date": "2026-2-13",
    "title": "ReasonLite: A Unified Framework for Distilling Reasoning into Small Language Models",
    "authors": "Karun Thankachan",
    "publish": "2025 5th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS)",
    "url": "https://doi.org/10.1109/icuis67429.2025.11380787",
    "source": "IEEE",
    "abstract": "Small language models (SLMs) offer advantages in cost, latency, and deployment control but often underperform on multi-step reasoning tasks without large-model guidance or costly supervision. While techniques like chain-of-thought prompting, self-consistent decoding, and rationale distillation improve reasoning, fragmented tooling, unclear evaluation practices, and high token costs hinder progress. ReasonLite addresses these gaps with a modular Python library for reasoning-centric distillation in SLMs. It unifies answer and rationale supervision, multi-sample agreement, and program-aided distillation for verified intermediate reasoning. The library also provides discrete and continuous compression to reduce token budgets while retaining reasoning quality. To promote reproducibility, ReasonLite includes standardized diagnostics, curriculum scheduling, tracebudget control, and configurable policies for safe reasoning trace storage and emission. This paper offers a functional overview of ReasonLite, presenting it as a cohesive and reproducible framework for advancing reasoning efficiency in small models.",
    "title_zh": "ReasonLite：一种将推理能力提炼至小型语言模型的统一框架",
    "abstract_zh": "小型语言模型（SLMs）在成本、延迟和部署控制方面具有优势，但在缺乏大模型指导或高昂监督成本的情况下，往往在多步推理任务上表现不佳。尽管链式思维提示（chain-of-thought prompting）、自一致解码和推理过程蒸馏等技术能够提升推理能力，但工具碎片化、评估标准不明确以及高昂的令牌开销仍阻碍了进一步发展。ReasonLite 通过一个模块化的 Python 库，解决了这些痛点，专注于以推理为核心的蒸馏方法。该库统一了答案与推理过程的监督机制，支持多样本一致性判断，并引入程序辅助蒸馏，以验证中间推理步骤的正确性。此外，ReasonLite 提供离散与连续压缩技术，在保持推理质量的同时显著降低令牌预算。为促进可复现性，ReasonLite 还集成了标准化诊断工具、课程调度机制、追踪预算控制，以及可配置的策略，用于安全地存储和输出推理轨迹。本文对 ReasonLite 进行了功能概述，将其呈现为一个统一且可复现的框架，旨在推动小型模型在推理效率方面的持续进步。"
  },
  {
    "date": "2026-2-13",
    "title": "Critique Connect: Augmenting Human Creativity through AI-Driven Semantic Analysis and Adaptive Feedback Synthesis-A Review",
    "authors": "Mohd Anas, Shelly Gupta, Nikhil Raikwar, Gaurav Verma, Hritik Roushan, Mukesh Kumar Tripathi",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11382628",
    "source": "IEEE",
    "abstract": "Feedback is essential to creative growth, even if it’s haphazard, inconsistent and hardly ever easy to act on. Critique Connect solves this opportunity gap with an AI-based model that decodes raw peer feedback and structures it into usable insights. The system has two levels. first, where the system pre-processes feedback using a BERT based model and cluster it to avoid redundancy as well as measure sentiment and tone, whilst extracting the underlying semantics. And then if author use a generation model like GPT, the author can generate clear and concise advice that the creators are able to follow. To encourage activity, Critique Connect \"gamifies\" the site and promises badges, experience points and a leader’s board to those leaving considered critiques. In our preliminary analysis, auhtro found that Critique Connect improves feedback on three aspects, i.e. clarity, depth, and useful-ness improvement. This results in higher user satisfaction and higher creativity novelty. It’s perfect for schools, arts organizations and events like hackathons. Their vision is Visions Critique Connect show how AI can revolutionize feedback culture by taking a set of vague loose-comments and aggregating them into a coherent, constructive comment about author work that will inspire human creativity and innovation, things which machines are not very good at.",
    "title_zh": "批判性连接：通过AI驱动的语义分析与自适应反馈合成增强人类创造力——综述",
    "abstract_zh": "反馈对于创意成长至关重要，即使它常常杂乱无章、前后不一，且几乎难以付诸实践。Critique Connect 通过基于人工智能的模型，解决了这一关键缺口：它能够解析原始的同行反馈，并将其转化为可操作的洞察。该系统分为两个层级：首先，系统利用基于 BERT 的模型对反馈进行预处理，通过聚类消除冗余信息，同时分析情感倾向与语气，并提取其深层语义；其次，创作者若使用生成模型（如 GPT），便可生成清晰、简洁的建议，便于实际执行。为激发用户参与，Critique Connect 还“游戏化”了平台设计，通过发放徽章、经验值以及排行榜等方式，奖励那些提供深入、有见地的批评。在初步分析中，我们发现 Critique Connect 在反馈的清晰度、深度和实用性三个方面均有显著提升，从而带来了更高的用户满意度和更强的创意新颖性。该平台非常适合学校、艺术机构以及黑客马拉松等创意活动。其愿景是：通过 AI 技术，彻底革新反馈文化——将零散、模糊的评论整合为条理清晰、富有建设性的反馈，真正激发人类的创造力与创新力，而这正是机器所难以企及的领域。"
  },
  {
    "date": "2026-2-13",
    "title": "Large Language Model Tools for Enhancing Student Learning Processes in Computing Education",
    "authors": "Opetunde Oluwadolapo Ibitoye",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3779183",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "用于提升计算教育中学生学习过程的大型语言模型工具",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "How Retrieval Augmented Generation Can Assist Secondary Computer Science Educators - Research Description",
    "authors": "Christopher D Watson",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777063",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "检索增强生成在辅助中学计算机科学教师方面的研究描述",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Coding Twice: Integrating Independent and AI-Assisted Programming Assignments in CS Education",
    "authors": "Jingsai Liang, Xi Chen",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777222",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "编程两次：在计算机科学教育中融合独立编程与AI辅助编程任务",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "A Hardware-Efficient Approximate Booth Multiplier for Error-Tolerant Applications",
    "authors": "Bavisetty Sai Swaroop, Paramasivam C",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11382738",
    "source": "IEEE",
    "abstract": "Multiplication is a low-level operation in digital circuits, especially in signal processing, machine learning, and embedded computing. High-performance, low-power, area, and delay multiplier design is important to the low-power VLSI systems of today. For most applications, high-precision computation is not required, and thus there is space for approximate computing as an acceptable design option. In this paper, an approximate Booth multiplier architecture is proposed for applications where a minimal computation error is acceptable. The design starts with a traditional radix-4 Booth encoder and Wallace tree reduction for the base case multiplier. Three directed approximation methods are used to make it more efficient. 1. Wire-based partial product generation, which reduces the logic routing overhead and complexity. 2. Truncation of the least significant bit (LSB) to reduce the operations during the last summation stage. 3. Utilization of a custom approximate 4:2 compressor, which optimizes the usage of gates in the reduction tree. The architecture is synthesized in Verilog HDL and functionally verified. Synthesis is performed using a 90nm standard cell library to estimate the important parameters such as area, timing, power, and error rate. The results show that the approximate multiplier saves considerable area and power with a minor loss in timing and output accuracy. The characteristics make it suitable for use in image processing and machine learning inference, where energy efficiency is of greater concern than exact computation. The solution suggested highlights the merits of approximating at the structural level to obtain a good tradeoff between performance and efficiency.",
    "title_zh": "面向容错应用的硬件高效近似Booth乘法器",
    "abstract_zh": "乘法是数字电路中的一个底层操作，尤其在信号处理、机器学习和嵌入式计算领域中具有重要意义。对于当今的低功耗VLSI系统而言，设计高性能、低功耗、小面积且延迟低的乘法器至关重要。在大多数应用中，并不需要高精度计算，因此采用近似计算作为一种可接受的设计方案具有广阔空间。本文提出了一种适用于允许极小计算误差的应用场景的近似Booth乘法器架构。该设计以传统的radix-4 Booth编码器和Wallace树压缩作为基础乘法器。通过三种定向近似方法进一步提升其效率：1）基于导线的局部积生成方式，有效降低逻辑布线开销与复杂度；2）截断最低有效位（LSB），减少最后求和阶段的操作量；3）采用自定义的近似4:2压缩器，优化压缩树中门电路的使用效率。该架构使用Verilog HDL进行综合并完成功能验证。利用90nm标准单元库进行综合，以评估面积、时序、功耗和误差率等关键参数。结果表明，该近似乘法器在仅带来轻微时序和输出精度损失的情况下，显著节省了面积与功耗。这些特性使其特别适用于图像处理和机器学习推理等对能效要求高于精确计算的应用场景。本方案凸显了在结构层面进行近似设计的优势，能够在性能与效率之间实现良好的权衡。"
  },
  {
    "date": "2026-2-13",
    "title": "Automated Program Repair of Uncompilable Student Code",
    "authors": "Griffin Pitts, Aum Pandya, Darsh Rank, Muntasir Hoq, Tirth Bhatt, Bita Akram",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777323",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "自动修复无法编译的学生代码",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "VLSI Design based Smart Traffic Signal Control",
    "authors": "Naveenkumar R, Karuppasamy Karthikshun A, Oliver Rexton A",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11382739",
    "source": "IEEE",
    "abstract": "This study introduces the design and implementation of a VLSI-based Smart Traffic Signal Controller with Pedestrian Crossing for transportation systems. To improve hardware efficiency, Verilog synthesized on FPGA is used in the development of this study. In traditional controllers which is static, but this system adapts signal timing dynamically based on real-time vehicle density and pedestrian demand, ensuring smooth traffic flow while maintaining road safety. Operating modes such as normal mode and pedestrian-priority mode are embedded to handle different traffic scenarios. Sensor-based detection enables accurate green cycle allocation and safe pedestrian intervals, reducing traffic, and fuel consumption. Experimental evaluation indicates accuracy between 81% and 91% in improving traffic control and pedestrian crossing management. Experimental simulation using ModelSim validate the system’s low power consumption. This study ensures low power consumption, and minimal delay, making it a cost-effective and adaptable framework for urban traffic management. With its adaptability, the controller offers significant advantages in terms of safety, efficiency, and reliability over traditional systems.",
    "title_zh": "基于VLSI设计的智能交通信号控制",
    "abstract_zh": "本研究介绍了基于VLSI的智能交通信号控制器（含行人过街功能）的设计与实现，应用于交通系统。为提高硬件效率，本研究采用在FPGA上综合的Verilog语言进行开发。与传统静态控制器不同，本系统可根据实时车流量和行人需求动态调整信号灯时序，确保交通流畅的同时保障道路安全。系统内置正常模式与行人优先模式，以应对不同的交通状况。基于传感器的检测技术可实现绿灯周期的精准分配和行人过街的安全间隔，有效减少交通拥堵和燃油消耗。实验评估表明，该系统在交通控制与行人过街管理方面，准确率可达81%至91%。利用ModelSim进行的仿真验证了系统具有低功耗特性。本研究实现了低功耗与极小延迟，为城市交通管理提供了一种成本低廉且高度可适应的解决方案。凭借其出色的适应性，该控制器在安全性、效率和可靠性方面显著优于传统系统。"
  },
  {
    "date": "2026-2-13",
    "title": "Design of Electronic Circuits for Electrical Ground Support Equipment of Spacecraft Propulsion System",
    "authors": "Muthuselvi K, Saurabh Agrawal, V Abarna, Krishna Mohan Shanbhogue K, Shambayya K",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11383313",
    "source": "IEEE",
    "abstract": "The Assembly, Integration and Testing (AIT) phase is critical in spacecraft development, particularly for the Spacecraft Propulsion System (SPS). Electrical Ground Support Equipment (EGSE) plays a pivotal role during this phase by facilitating comprehensive verification and validation of the SPS. EGSE encompasses specialized electronic circuits and systems designed to interface with spacecraft components during ground testing. Its primary functions include pressure and temperature monitoring, latch valve control and status monitoring, and redundant data monitoring. These circuits are typically implemented on two-layer Printed Circuit Boards (PCBs) using carefully selected Commercial Off-The-Shelf (COTS) components to balance performance and reliability. During the AIT phase, EGSE supports various testing stages, including module-level functional checks, system-level simulations, environmental testing, and launch site operations. By facilitating these tests, EGSE helps identify design and manufacturing defects in spacecraft propulsion system early, reducing rework and improving the first-pass yield of the SPS.",
    "title_zh": "航天器推进系统电气地面支持设备的电子电路设计",
    "abstract_zh": "装配、集成与测试（AIT）阶段在航天器研发中至关重要，尤其对于航天器推进系统（SPS）而言。地面电气支持设备（EGSE）在该阶段发挥着关键作用，能够全面验证和确认SPS的功能。EGSE包括专为航天器组件地面测试设计的电子电路与系统，其主要功能涵盖压力与温度监测、锁闭阀控制与状态监控，以及冗余数据监控。这些电路通常采用精心挑选的商用现成（COTS）元器件，实现于双层印刷电路板（PCB）上，以在性能与可靠性之间取得平衡。在AIT阶段，EGSE支持多个测试环节，包括模块级功能检查、系统级仿真、环境测试以及发射场操作。通过支持这些测试，EGSE有助于在早期发现航天器推进系统的设计与制造缺陷，减少返工，提升SPS的一次通过率。"
  },
  {
    "date": "2026-2-13",
    "title": "Power-Efficient Instruction-Aware Clock Gating for RISC-V Based PicoSoC Design",
    "authors": "Paramasivam C, Sunkavalli Vinay Kumar",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11383520",
    "source": "IEEE",
    "abstract": "This paper presents an instruction-aware clock gating approach to reduce dynamic power consumption in RISC-V-based PicoSoC architectures. As energy efficiency becomes a critical constraint in modern SoC systems, especially for IoT and embedded domains, we propose a hardware-level gating mechanism that activates peripheral clocks based on decoded instruction types. Unlike conventional designs where modules such as UART, SPI, and SRAM remain clocked regardless of operation, our architecture introduces decode-driven control logic that identifies instruction classes (e.g., R-type, LW, SW, I/O operations) and asserts corresponding clock enables. Through selective activation, only the CPU and relevant peripherals remain active per cycle, minimizing unnecessary toggling. This technique is seamlessly integrated with the PicoRV32 core and validated via waveform analysis. The implementation achieves significant power reduction without compromising performance or area, demonstrating an effective methodology for low-power SoC design.",
    "title_zh": "面向RISC-V的PicoSoC设计的低功耗指令感知时钟门控技术",
    "abstract_zh": "本文提出了一种面向指令感知的时钟门控方法，用于降低基于RISC-V的PicoSoC架构中的动态功耗。随着能效成为现代片上系统（SoC）设计中的关键约束，尤其是在物联网（IoT）和嵌入式领域，我们提出了一种硬件级的时钟门控机制，该机制根据解码后的指令类型来激活外设时钟。与传统设计中UART、SPI和SRAM等模块始终处于时钟驱动状态不同，本架构引入了基于指令解码的控制逻辑，能够识别指令类别（如R型指令、LW、SW及I/O操作），并相应地发出时钟使能信号。通过选择性地激活，每个时钟周期内仅CPU及相关外设处于工作状态，从而最大限度地减少了不必要的信号翻转。该技术已无缝集成至PicoRV32核心，并通过波形分析进行了验证。实现结果表明，该方法在不牺牲性能和面积的前提下，显著降低了功耗，为低功耗SoC设计提供了一种高效可行的解决方案。"
  },
  {
    "date": "2026-2-13",
    "title": "ML-based Fuzzing for Vulnerability Detection: Methods, Benchmarks, and Open Challenges-A Review",
    "authors": "Kiran Narang, Amolkumar N. Jadhav, Vikas Nivrutti Dhakane, Mukesh Kumar Tripathi, Sajid Mansur Momin, Nilesh A. Thorat",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11382854",
    "source": "IEEE",
    "abstract": "Modern society depends heavily on software Modern society depends heavily on software and network systems, yet the author is still able to identify flaws in these systems more quickly than conventional protective strategies can be created. Automation will be necessary to scale these efforts, allowing defenders to frequently identify and resolve problems on a broad scale in realistic time frames that differ based on the application. Fuzzing Technique-Based Testing was a crucial preemptive test; yet, traditional fizzers are still challenged with deep bug hunting, slow crash triage, input validity, and suboptimal seed scheduling. Recent work integrates Machine Learning (ML) into the fuzzing pipeline to mitigate these issues through sophisticated feature engineering, smart seed selection, predictive/fitness models, and gradient-based optimization. Networks such as Long Short-Term Memory (LSTM), Generative Adversarial Networks (GANs), Sequence-to-Sequence, and Gated Recurrent Units (GRUs) architectures have demonstrated significant potential. In this paper, the author conducts a systematic review of ML-Augmented Fuzzing, targeting four strands: Traditional ML (TML), Deep Learning (DL), Reinforcement Learning (RL), and Deep Reinforcement Learning (DRL). The author explicitly examines how each class facilitates basic fuzzing tasks, distilling their respective advantages and disadvantages, as well as class-specific tradeoffs. The author provides a comprehensive view of the existing situation and a development goal by connecting techniques to fuzzing phases and analytic targets. The author aims to assist researchers and practitioners in developing ML-guided solutions that are more efficient, scalable, and reproducible.",
    "title_zh": "基于机器学习的模糊测试在漏洞检测中的应用：方法、基准测试与开放挑战——综述",
    "abstract_zh": "现代社会高度依赖软件和网络系统，然而作者仍能比传统防护策略的构建速度更快地发现这些系统中的缺陷。为了实现规模化的应对，自动化将成为必要手段，使防御者能够在不同应用场景下以现实的时间框架内频繁识别并解决广泛存在的问题。基于模糊测试（Fuzzing Technique-Based Testing）的预判性检测至关重要，但传统的模糊测试工具在深度漏洞挖掘、崩溃分析缓慢、输入有效性验证以及种子调度效率低下等方面仍面临挑战。近期的研究通过将机器学习（ML）引入模糊测试流程，利用复杂的特征工程、智能种子选择、预测/适应度模型以及基于梯度的优化方法，有效缓解了上述问题。诸如长短期记忆网络（LSTM）、生成对抗网络（GANs）、序列到序列模型（Sequence-to-Sequence）以及门控循环单元（GRUs）等网络架构已展现出巨大潜力。本文对机器学习增强型模糊测试进行了系统性综述，聚焦于四大方向：传统机器学习（TML）、深度学习（DL）、强化学习（RL）以及深度强化学习（DRL）。作者明确分析了每一类技术如何支持基础的模糊测试任务，提炼出各自的优缺点及特定类别之间的权衡取舍。通过将各类技术与模糊测试阶段及分析目标相联系，作者全面呈现了当前研究现状，并提出了未来发展的目标。本文旨在帮助研究人员和实践者开发出更高效、可扩展且可复现的机器学习引导型解决方案。"
  },
  {
    "date": "2026-2-13",
    "title": "Aligning Small Language Models for Programming Feedback: Towards Scalable Coding Support in a Massive Global Course",
    "authors": "Charles Koutcheme, Juliette Woodrow, Chris Piech",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.1",
    "url": "https://doi.org/10.1145/3770762.3772539",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "面向编程反馈的小型语言模型对齐：迈向大规模全球课程中的可扩展编程支持",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Scaling Engagement: Leveraging Social Annotation and AI for Collaborative Code Review in Large CS Courses",
    "authors": "Raymond Klefstad, Susan Anderson Klefstad, Vincent Tran, Michael Shindler",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.1",
    "url": "https://doi.org/10.1145/3770762.3772652",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "扩大参与度：利用社交标注与人工智能促进大规模计算机科学课程中的协作代码审查",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Instructors' Perspectives on LLM-Generated Programming Formative Feedback",
    "authors": "Rose Niosuha, Samantha Boatright Smith, Abigail O'Neill, J.D. Zamfirescu-Pereira, John DeNero, Narges Norouzi",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777293",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "教师对大语言模型生成的编程形成性反馈的看法",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Low Power Reconfigurable PRBS Checker",
    "authors": "Pragna Vedi, Paramasivam C, Ganapathi Hegde",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11383175",
    "source": "IEEE",
    "abstract": "The fully reconfigurable pipelined architecture for FPGA based parallel pseudorandom binary sequence (PRBS) test pattern creation is demonstrated and simulated in this work. PRBS parameters such as order, polynomial, seed, and output width are dynamically reconfigurable at runtime without resynthesis. The architecture enables great timing performance and scalability through the use of pipelined data paths with scalable XOR networks. Implemented and verified in Verilog HDL, the architecture includes a self synchronizing PRBS checker, a clock gating controller, and an error estimator for efficient performance evaluation. Reversible logic gates Toffoli and Feynman were introduced, resulting in approximately 41.58 power reductions and 40.54 area reductions. Timing performance was also enhanced with reduced delays. The architecture is suitable for low power, area efficient, and high speed VLSI communication system testing.",
    "title_zh": "低功耗可重构PRBS校验器",
    "abstract_zh": "本文展示并仿真了一种基于FPGA的全可重构流水线架构，用于并行伪随机二进制序列（PRBS）测试模式的生成。该架构支持在运行时动态重构PRBS参数，包括阶数、多项式、初始种子和输出宽度，且无需重新综合。通过采用可扩展的异或（XOR）网络和流水线数据通路，该架构实现了优异的时序性能与可扩展性。该架构使用Verilog HDL实现并验证，包含自同步PRBS校验器、时钟门控控制器以及误差估计算法，以实现高效的性能评估。引入可逆逻辑门Toffoli和Feynman后，功耗降低了约41.58%，面积减少了约40.54%，同时时序延迟也得到显著降低。该架构适用于低功耗、面积高效且高速的VLSI通信系统测试。"
  },
  {
    "date": "2026-2-13",
    "title": "From Code Generation to Learning: Investigating AI-Assisted Programming in Computing Education",
    "authors": "Salma El Otmani",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777065",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "从代码生成到学习：探究人工智能辅助编程在计算机教育中的应用",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Bringing Interactive Learning to Industrial IDEs: Kotlin Notebook and LLM-Generated Exercises",
    "authors": "Daniil Karol, Ksenia Shneyveys, Roman Belov, Anastasiia Birillo",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777024",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "将互动式学习引入工业级IDE：Kotlin笔记本与大模型生成的练习题",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Prompting through Decomposition: Evaluating the Efficacy of Problem Decomposition Diagrams for Code Generation",
    "authors": "David H. Smith, S. Moonwara A. Monisha, Annapurna Vadaparty, Leo Porter, Daniel Zingaro",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777189",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "通过分解进行提示：评估问题分解图在代码生成中的有效性",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "WebTigerPython: A Low-Floor High-Ceiling Python IDE for the Browser",
    "authors": "Clemens Bachmann, Alexandra Maximova, Tobias Kohn, Dennis Komm",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.1",
    "url": "https://doi.org/10.1145/3770762.3772670",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "WebTigerPython：一款面向浏览器的低门槛、高扩展性Python集成开发环境",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Are CS1 Students More Creative than LLM in Solving a Problem? Preliminary Results on a Comparison of Code Diversity",
    "authors": "Lu Fang, Mengqian Wu, Xinying Hou, Mohsen Dorodchi, Peter Brusilovsky",
    "publish": "Proceedings of the 57th ACM Technical Symposium on Computer Science Education V.2",
    "url": "https://doi.org/10.1145/3770761.3777221",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "计算机科学专业一年级学生与大型语言模型在解决问题时的创造力比较：代码多样性初步研究结果",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-13",
    "title": "Semantic Kernel for Software Engineering: A Multi-Agent Framework for Autonomous Development Lifecycles",
    "authors": "Adithya B V, Raj Kumar.J.S., Nirmal Varghese Babu",
    "publish": "2025 9th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",
    "url": "https://doi.org/10.1109/iceca66444.2025.11383462",
    "source": "IEEE",
    "abstract": "Software engineering automation remains constrained, with existing AI tools typically focusing on isolated tasks such as code generation, while still relying heavily on human intervention for integration, testing, and deployment. This paper presents a multi-agent system that will autonomously manage the whole software development process-including natural language requirements to deployed systems. The system leverages a Semantic Kernel for dynamic task decomposition and orchestrates specialized, role-specific agents for code generation, testing, debugging, and deployment. A vector-based knowledge retention engine allows for ongoing learning and reuse of solutions across projects. This will ensure high-quality code and consistent architecture. The framework works with professional tools like Docker and GitHub Actions. It supports results that are ready for production. In experimental tests, the end-to-end task success rate reached 65 percent. The average development time dropped to 35 minutes. There was also a decrease in human intervention compared to baseline systems like ChatDev and GPT-4, which relied on manual tools. This work creates a new approach in autonomous software engineering. It uses coordinated multi-agent systems that can handle complex projects with minimal human involvement.",
    "title_zh": "软件工程中的语义核：用于自主开发生命周期的多智能体框架",
    "abstract_zh": "软件工程自动化仍受限制，现有AI工具通常仅专注于孤立的任务，如代码生成，而在集成、测试和部署等环节仍严重依赖人工干预。本文提出了一种多智能体系统，能够自主管理整个软件开发流程——从自然语言需求到系统部署。该系统利用语义内核实现动态任务分解，并协调具备特定角色的专用智能体，分别负责代码生成、测试、调试和部署。基于向量的知识保留引擎支持跨项目持续学习与解决方案复用，从而确保代码质量与架构一致性。该框架可与Docker、GitHub Actions等专业工具无缝集成，生成的结果可直接用于生产环境。实验测试表明，端到端任务的成功率达到65%，平均开发时间缩短至35分钟，且相比依赖手动工具的基线系统（如ChatDev和GPT-4），所需的人工干预显著减少。本研究开创了自主软件工程的新范式，通过协同的多智能体系统，实现对复杂项目在极小人工参与下的全流程自主管理。"
  }
]