[
  {
    "date": "2026-02-16",
    "title": "Parameter-Efficient Fine-Tuning of LLMs with Mixture of Space Experts",
    "authors": "Buze Zhang, Jinkai Tao, Zilang Zeng, Neil He, Ali Maatouk, Menglin Yang, Rex Ying",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14490v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have achieved remarkable progress, with Parameter-Efficient Fine-Tuning (PEFT) emerging as a key technique for downstream task adaptation. However, existing PEFT methods mainly operate in Euclidean space, fundamentally limiting their capacity to capture complex geometric structures inherent in language data. While alternative geometric spaces, like hyperbolic geometries for hierarchical data and spherical manifolds for circular patterns, offer theoretical advantages, forcing representations into a single manifold type ultimately limits expressiveness, even when curvature parameters are learnable. To address this, we propose Mixture of Space (MoS), a unified framework that leverages multiple geometric spaces simultaneously to learn richer, curvature-aware representations. Building on this scheme, we develop MoSLoRA, which extends Low-Rank Adaptation (LoRA) with heterogeneous geometric experts, enabling models to dynamically select or combine appropriate geometric spaces based on input context. Furthermore, to address the computational overhead of frequent manifold switching, we develop a lightweight routing mechanism. Moreover, we provide empirical insights into how curvature optimization impacts training stability and model performance. Our experiments across diverse benchmarks demonstrate that MoSLoRA consistently outperforms strong baselines, achieving up to 5.6% improvement on MATH500 and 15.9% on MAWPS.",
    "title_zh": "基于空间专家混合的大型语言模型参数高效微调",
    "abstract_zh": "大型语言模型（LLMs）取得了显著进展，参数高效微调（PEFT）已成为下游任务适配的关键技术。然而，现有的PEFT方法主要在欧几里得空间中操作，从根本上限制了其捕捉语言数据固有复杂几何结构的能力。尽管超球面几何（适用于层次化数据）和球面流形（适用于循环模式）等替代几何空间在理论上具有优势，但强制将表示限制在单一流形类型中，即便 curvature 参数可学习，仍会限制模型的表达能力。为解决这一问题，我们提出 Mixture of Space（MoS）——一种统一框架，通过同时利用多种几何空间来学习更丰富、具有曲率感知能力的表示。在此基础上，我们开发了 MoSLoRA，它将低秩适配（LoRA）扩展为包含异构几何专家的架构，使模型能够根据输入上下文动态选择或组合合适的几何空间。此外，为缓解频繁切换流形带来的计算开销，我们设计了一种轻量级路由机制。同时，我们还提供了关于曲率优化如何影响训练稳定性和模型性能的实证分析。在多个基准测试上的实验表明，MoSLoRA 始终优于强基线方法，在 MATH500 上提升高达 5.6%，在 MAWPS 上提升高达 15.9%。"
  },
  {
    "date": "2026-02-16",
    "title": "LACONIC: Length-Aware Constrained Reinforcement Learning for LLM",
    "authors": "Chang Liu, Yiran Zhao, Lawrence Liu, Yaoqi Ye, Csaba Szepesvári, Lin F. Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14468v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning (RL) has enhanced the capabilities of large language models (LLMs) through reward-driven training. Nevertheless, this process can introduce excessively long responses, inflating inference latency and computational overhead. Prior length-control approaches typically rely on fixed heuristic reward shaping, which can misalign with the task objective and require brittle tuning. In this work, we propose LACONIC, a reinforcement learning method that enforces a target token budget during training. Specifically, we update policy models using an augmented objective that combines the task reward with a length-based cost. To balance brevity and task performance, the cost scale is adaptively adjusted throughout training. This yields robust length control while preserving task reward. We provide a theoretical guarantee that support the method. Across mathematical reasoning models and datasets, LACONIC preserves or improves pass@1 while reducing output length by over 50%. It maintains out-of-domain performance on general knowledge and multilingual benchmarks with 44% fewer tokens. Moreover, LACONIC integrates into standard RL-tuning with no inference changes and minimal deployment overhead.",
    "title_zh": "简洁：面向大语言模型的长度感知约束强化学习",
    "abstract_zh": "强化学习（RL）通过基于奖励的训练提升了大型语言模型（LLMs）的能力。然而，这一过程可能导致生成响应过长，从而增加推理延迟和计算开销。以往的长度控制方法通常依赖于固定的启发式奖励设计，这容易与任务目标产生偏差，且需要脆弱的调参。在本研究中，我们提出 LACONIC，一种在训练过程中强制执行目标词元预算的强化学习方法。具体而言，我们通过结合任务奖励与基于长度的代价项来更新策略模型，构建增强的目标函数。为平衡简洁性与任务性能，代价项的权重在训练过程中自适应调整。该方法在保持任务奖励的同时，实现了稳健的长度控制。我们还提供了该方法的理论保证。在多个数学推理模型和数据集上，LACONIC 在保持或提升 pass@1 准确率的同时，将输出长度减少了超过 50%。在通用知识和多语言基准测试中，其在仅使用 44% 的词元数量的情况下，仍能保持出色的跨领域性能。此外，LACONIC 可无缝集成到标准的强化学习微调流程中，无需修改推理过程，且部署开销极低。"
  },
  {
    "date": "2026-02-16",
    "title": "Beyond Token-Level Policy Gradients for Complex Reasoning with Large Language Models",
    "authors": "Mufan Xu, Kehai Chen, Xuefeng Bai, Zhengyu Niu, Muyun Yang, Tiejun Zhao, Min Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14386v1",
    "source": "arXiv",
    "abstract": "Existing policy-gradient methods for auto-regressive language models typically select subsequent tokens one at a time as actions in the policy. While effective for many generation tasks, such an approach may not fully capture the structure of complex reasoning tasks, where a single semantic decision is often realized across multiple tokens--for example, when defining variables or composing equations. This introduces a potential mismatch between token-level optimization and the inherently block-level nature of reasoning in these settings. To bridge this gap, we propose Multi-token Policy Gradient Optimization (MPO), a framework that treats sequences of K consecutive tokens as unified semantic actions. This block-level perspective enables our method to capture the compositional structure of reasoning trajectories and supports optimization over coherent, higher-level objectives. Experiments on mathematical reasoning and coding benchmarks show that MPO outperforms standard token-level policy gradient baselines, highlight the limitations of token-level policy gradients for complex reasoning, motivating future research to look beyond token-level granularity for reasoning-intensive language tasks.",
    "title_zh": "基于大型语言模型的复杂推理中的超越标记级策略梯度方法",
    "abstract_zh": "现有的自回归语言模型的策略梯度方法通常将后续的每个词元作为策略中的单一动作逐一选择。尽管这种方法在许多生成任务中表现良好，但在处理复杂推理任务时可能无法充分捕捉其内在结构，因为在这些任务中，一个语义决策往往跨越多个词元实现——例如在定义变量或构建方程时。这导致了词元级优化与推理任务固有的块级特性之间存在潜在的不匹配。为弥合这一差距，我们提出了多词元策略梯度优化（Multi-token Policy Gradient Optimization, MPO），该框架将K个连续词元的序列视为统一的语义动作。这种块级视角使我们的方法能够捕捉推理轨迹的组合结构，并支持对连贯的高层次目标进行优化。在数学推理和编程基准上的实验表明，MPO优于标准的词元级策略梯度基线方法，凸显了词元级策略梯度在复杂推理任务中的局限性，也推动未来研究在推理密集型语言任务中探索超越词元级粒度的新范式。"
  },
  {
    "date": "2026-02-16",
    "title": "A Trajectory-Based Safety Audit of Clawdbot (OpenClaw)",
    "authors": "Tianyu Chen, Dongrui Liu, Xia Hu, Jingyi Yu, Wenjie Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14364v1",
    "source": "arXiv",
    "abstract": "Clawdbot is a self-hosted, tool-using personal AI agent with a broad action space spanning local execution and web-mediated workflows, which raises heightened safety and security concerns under ambiguity and adversarial steering. We present a trajectory-centric evaluation of Clawdbot across six risk dimensions. Our test suite samples and lightly adapts scenarios from prior agent-safety benchmarks (including ATBench and LPS-Bench) and supplements them with hand-designed cases tailored to Clawdbot's tool surface. We log complete interaction trajectories (messages, actions, tool-call arguments/outputs) and assess safety using both an automated trajectory judge (AgentDoG-Qwen3-4B) and human review. Across 34 canonical cases, we find a non-uniform safety profile: performance is generally consistent on reliability-focused tasks, while most failures arise under underspecified intent, open-ended goals, or benign-seeming jailbreak prompts, where minor misinterpretations can escalate into higher-impact tool actions. We supplemented the overall results with representative case studies and summarized the commonalities of these cases, analyzing the security vulnerabilities and typical failure modes that Clawdbot is prone to trigger in practice.",
    "title_zh": "基于轨迹的 Clawdbot（OpenClaw）安全审计",
    "abstract_zh": "Clawdbot 是一个自托管的、具备工具使用能力的个人AI代理，其行动空间广泛，涵盖本地执行与网络中介工作流，因此在面对模糊情境和对抗性引导时，安全与隐私风险显著增加。我们针对 Clawdbot 在六个风险维度上开展了以轨迹为中心的评估。测试套件从先前的代理安全基准（包括 ATBench 和 LPS-Bench）中采样并轻度调整了部分场景，并补充了专为 Clawdbot 工具功能设计的手工案例。我们完整记录了交互轨迹（包括消息、动作、工具调用参数与输出），并采用自动化轨迹评估器（AgentDoG-Qwen3-4B）与人工评审相结合的方式进行安全评估。在34个典型测试案例中，我们发现其安全表现呈现非均匀特征：在以可靠性为核心的任务上表现总体稳定，而大多数失败集中在意图不明确、目标开放或看似无害的“越狱”提示场景中，微小的误解即可引发高影响的工具操作。我们进一步通过代表性案例研究补充了整体评估结果，总结了这些案例的共性特征，深入分析了 Clawdbot 在实际应用中易触发的安全漏洞及其典型失效模式。"
  },
  {
    "date": "2026-02-16",
    "title": "Scaling Beyond Masked Diffusion Language Models",
    "authors": "Subham Sekhar Sahoo, Jean-Marie Lemercier, Zhihan Yang, Justin Deschenaux, Jingyu Liu, John Thickstun, Ante Jukic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15014v1",
    "source": "arXiv",
    "abstract": "Diffusion language models are a promising alternative to autoregressive models due to their potential for faster generation. Among discrete diffusion approaches, Masked diffusion currently dominates, largely driven by strong perplexity on language modeling benchmarks. In this work, we present the first scaling law study of uniform-state and interpolating discrete diffusion methods. We also show that Masked diffusion models can be made approximately 12% more FLOPs-efficient when trained with a simple cross-entropy objective. We find that perplexity is informative within a diffusion family but can be misleading across families, where models with worse likelihood scaling may be preferable due to faster and more practical sampling, as reflected by the speed-quality Pareto frontier. These results challenge the view that Masked diffusion is categorically the future of diffusion language modeling and that perplexity alone suffices for cross-algorithm comparison. Scaling all methods to 1.7B parameters, we show that uniform-state diffusion remains competitive on likelihood-based benchmarks and outperforms autoregressive and Masked diffusion models on GSM8K, despite worse validation perplexity. We provide the code, model checkpoints, and video tutorials on the project page: http://s-sahoo.github.io/scaling-dllms",
    "title_zh": "超越掩码扩散语言模型的扩展",
    "abstract_zh": "扩散语言模型由于其在生成速度方面的潜力，成为自回归模型的一种有前景的替代方案。在离散扩散方法中，掩码扩散（Masked diffusion）目前占据主导地位，这主要得益于其在语言建模基准测试中表现出的优异困惑度。在本研究中，我们首次对均匀状态（uniform-state）和插值型（interpolating）离散扩散方法进行了规模定律（scaling law）研究。我们还发现，当使用简单的交叉熵目标函数进行训练时，掩码扩散模型的浮点运算效率可提升约12%。研究结果表明，困惑度在同一种扩散方法内部具有参考价值，但在不同方法之间可能具有误导性——某些似然性（likelihood）表现较差的模型，由于采样速度更快、更实用，反而可能更优，这一点在速度-质量帕累托前沿（speed-quality Pareto frontier）中得到了体现。这些发现挑战了“掩码扩散是扩散语言建模未来的必然选择”以及“仅凭困惑度即可进行跨算法比较”的观点。当所有方法均扩展至17亿参数规模时，我们发现均匀状态扩散模型在基于似然性的基准测试中仍具竞争力，并且在GSM8K任务上优于自回归模型和掩码扩散模型，尽管其验证困惑度表现较差。项目主页提供了代码、模型检查点以及视频教程：http://s-sahoo.github.io/scaling-dllms"
  },
  {
    "date": "2026-02-16",
    "title": "An Empirical Study of the Evolution of GitHub Actions Workflows",
    "authors": "Pooya Rostami Mazrae, Alexandre Decan, Tom Mens, Mairieli Wessel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14572v1",
    "source": "arXiv",
    "abstract": "CI/CD practices play a significant role during collaborative software development by automating time-consuming and repetitive tasks such as testing, building, quality checking, dependency and security management. GitHub Actions, the CI/CD tool integrated into GitHub, allows repository maintainers to automate development workflows. We conducted a mixed methods analysis of GitHub Actions workflow changes over time. Through a preliminary qualitative analysis of 439 modified workflow files we identified seven types of conceptual changes to workflows. Next, we performed a quantitative analysis over 49K+ GitHub repositories totaling 267K+ workflow change histories and 3.4M+ workflow file versions from November 2019 to August 2025. This analysis revealed that repositories contain a median of three workflow files, and 7.3% of all workflow files are being changed every week. The changes made to workflows tend to be small, with about three-quarters containing only a single change. The large majority of the observed changes have to do with task configuration and task specification in workflow jobs. We did not find any conclusive evidence of the effect of LLM coding tools or other major technological changes on workflow creation and workflow maintenance frequency. Our findings highlight the need for improved tooling to support fine-grained maintenance tasks, such as a broader adoption of dependency management and AI-based support for ensuring and sustaining workflow security and quality.",
    "title_zh": "GitHub Actions 工作流演化的实证研究",
    "abstract_zh": "CI/CD实践在协作式软件开发中发挥着重要作用，通过自动化耗时且重复的任务（如测试、构建、质量检查、依赖管理和安全管控）来提升效率。GitHub Actions作为集成在GitHub中的CI/CD工具，使仓库维护者能够自动化开发工作流。我们对GitHub Actions工作流随时间的变化进行了混合方法分析。通过对439个被修改的工作流文件进行初步的定性分析，我们识别出工作流的七种概念性变更类型。随后，我们对超过49,000个GitHub仓库（总计267,000多个工作流变更历史和340多万个工作流文件版本）进行了定量分析，时间跨度为2019年11月至2025年8月。分析结果显示，仓库中工作流文件的中位数为三个，每周有7.3%的工作流文件被修改。工作流的变更通常规模较小，约四分之三的变更仅包含单一修改。绝大多数观察到的变更都涉及工作流任务的配置和任务规范。我们未发现LLM编程工具或其他重大技术变革对工作流创建和维护频率产生显著影响的明确证据。我们的研究结果凸显了改进工具支持细粒度维护任务的必要性，例如更广泛地采用依赖管理，以及利用人工智能技术来保障和维持工作流的安全性与质量。"
  },
  {
    "date": "2026-02-16",
    "title": "Explainable Token-level Noise Filtering for LLM Fine-tuning Datasets",
    "authors": "Yuchen Yang, Wenze Lin, Enhao Huang, Zhixuan Chu, Hongbin Zhou, Lan Tao, Yiming Li, Zhan Qin, Kui Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14536v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have seen remarkable advancements, achieving state-of-the-art results in diverse applications. Fine-tuning, an important step for adapting LLMs to specific downstream tasks, typically involves further training on corresponding datasets. However, a fundamental discrepancy exists between current fine-tuning datasets and the token-level optimization mechanism of LLMs: most datasets are designed at the sentence-level, which introduces token-level noise, causing negative influence to final performance. In this paper, we propose XTF, an explainable token-level noise filtering framework. XTF decomposes the complex and subtle contributions of token-level data to the fine-tuning process into three distinct and explicit attributes (reasoning importance, knowledge novelty, and task relevance), which can be assessed using scoring methods, and then masks the gradients of selected noisy tokens accordingly to optimize the performance of fine-tuned LLMs. We conduct extensive experiments on three representative downstream tasks (math, code and medicine) across 7 mainstream LLMs. The results demonstrate that XTF can significantly improve downstream performance by up to 13.7% compared to regular fine-tuning. Our work highlights the importance of token-level dataset optimization, and demonstrates the potential of strategies based on attribute decomposition for explaining complex training mechanisms.",
    "title_zh": "面向大语言模型微调数据集的可解释性逐标记噪声过滤",
    "abstract_zh": "大型语言模型（LLMs）取得了显著进展，在多种应用中达到了最先进的性能。微调是将LLMs适配到特定下游任务的重要步骤，通常涉及在相应数据集上进行进一步训练。然而，当前微调数据集与LLM的词元级优化机制之间存在一个根本性差异：大多数数据集是以句子为单位设计的，这引入了词元级别的噪声，对最终性能产生了负面影响。本文提出了一种可解释的词元级噪声过滤框架——XTF。XTF将词元级数据对微调过程的复杂而微妙的贡献分解为三个明确且独立的属性：推理重要性、知识新颖性和任务相关性，这些属性可通过评分方法进行评估，并据此掩码选定的噪声词元的梯度，从而优化微调后LLM的性能。我们在三个代表性下游任务（数学、代码和医学）上，针对7个主流LLM进行了大量实验。结果表明，与常规微调相比，XTF可将下游任务性能提升高达13.7%。我们的工作凸显了词元级数据集优化的重要性，并展示了基于属性分解策略在解释复杂训练机制方面的潜力。"
  },
  {
    "date": "2026-02-16",
    "title": "On the Learning Dynamics of RLVR at the Edge of Competence",
    "authors": "Yu Huang, Zixin Wen, Yuejie Chi, Yuting Wei, Aarti Singh, Yingbin Liang, Yuxin Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14872v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has been a main driver of recent breakthroughs in large reasoning models. Yet it remains a mystery how rewards based solely on final outcomes can help overcome the long-horizon barrier to extended reasoning. To understand this, we develop a theory of the training dynamics of RL for transformers on compositional reasoning tasks. Our theory characterizes how the effectiveness of RLVR is governed by the smoothness of the difficulty spectrum. When data contains abrupt discontinuities in difficulty, learning undergoes grokking-type phase transitions, producing prolonged plateaus before progress recurs. In contrast, a smooth difficulty spectrum leads to a relay effect: persistent gradient signals on easier problems elevate the model's capabilities to the point where harder ones become tractable, resulting in steady and continuous improvement. Our theory explains how RLVR can improve performance at the edge of competence, and suggests that appropriately designed data mixtures can yield scalable gains. As a technical contribution, our analysis develops and adapts tools from Fourier analysis on finite groups to our setting. We validate the predicted mechanisms empirically via synthetic experiments.",
    "title_zh": "在能力边缘处的RLVR学习动态",
    "abstract_zh": "基于可验证奖励的强化学习（RLVR）是推动大型推理模型近期突破的主要动力。然而，仅依赖最终结果的奖励机制如何克服长程推理中的长期障碍，仍是一个未解之谜。为理解这一现象，我们构建了针对变换器模型在组合推理任务上强化学习训练动态的理论框架。该理论揭示了RLVR的有效性由难度谱的平滑程度所决定。当数据中存在难度的突变断层时，学习过程会出现类似“顿悟”（grokking）的相变现象，在进展再次出现前经历漫长的平台期；而当难度谱平滑连续时，则会产生“接力效应”：在较简单问题上持续存在的梯度信号，逐步提升模型能力，使其能够解决更复杂的问题，从而实现稳定且连续的性能提升。我们的理论解释了RLVR如何在模型能力边界处提升表现，并表明通过合理设计的数据混合策略，可实现可扩展的性能增益。作为技术贡献，我们的分析发展并适配了有限群上的傅里叶分析工具以适用于本研究场景。我们通过合成实验对理论预测的机制进行了实证验证。"
  },
  {
    "date": "2026-02-16",
    "title": "Goldilocks RL: Tuning Task Difficulty to Escape Sparse Rewards for Reasoning",
    "authors": "Ilia Mahrooghi, Aryo Lotfi, Emmanuel Abbe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14868v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning has emerged as a powerful paradigm for unlocking reasoning capabilities in large language models. However, relying on sparse rewards makes this process highly sample-inefficient, as models must navigate vast search spaces with minimal feedback. While classic curriculum learning aims to mitigate this by ordering data based on complexity, the right ordering for a specific model is often unclear. To address this, we propose Goldilocks, a novel teacher-driven data sampling strategy that aims to predict each question's difficulty for the student model. The teacher model selects questions of appropriate difficulty for the student model, i.e., questions that are neither too easy nor too hard (Goldilocks principle), while training the student with GRPO. By leveraging the student's performance on seen samples, the teacher continuously adapts to the student's evolving abilities. On OpenMathReasoning dataset, Goldilocks data sampling improves the performance of models trained with standard GRPO under the same compute budget.",
    "title_zh": "金发姑娘强化学习：通过调节任务难度以摆脱稀疏奖励的困境实现推理",
    "abstract_zh": "强化学习已成为激发大语言模型推理能力的强大范式。然而，依赖稀疏奖励使得该过程极低样本效率，因为模型必须在巨大的搜索空间中进行探索，却仅获得极少的反馈。尽管传统的课程学习通过根据复杂度对数据进行排序来缓解这一问题，但针对特定模型的最优排序往往难以确定。为解决这一问题，我们提出了Goldilocks——一种新型的教师驱动数据采样策略，旨在预测每个问题对目标学生模型的难度。教师模型会为学生模型选择难度适中的问题，即既不太容易也不太困难的问题（遵循“金发姑娘原则”），同时使用GRPO训练学生模型。通过利用学生模型在已见样本上的表现，教师能够持续适应学生能力的动态变化。在OpenMathReasoning数据集上的实验表明，Goldilocks数据采样策略在相同计算预算下，显著提升了使用标准GRPO训练模型的性能。"
  },
  {
    "date": "2026-02-16",
    "title": "Learning State-Tracking from Code Using Linear RNNs",
    "authors": "Julien Siems, Riccardo Grazzi, Kirill Kalinin, Hitesh Ballani, Babak Rahmani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14814v1",
    "source": "arXiv",
    "abstract": "Over the last years, state-tracking tasks, particularly permutation composition, have become a testbed to understand the limits of sequence models architectures like Transformers and RNNs (linear and non-linear). However, these are often sequence-to-sequence tasks: learning to map actions (permutations) to states, which is incompatible with the next-token prediction setting commonly used to train language models. We address this gap by converting permutation composition into code via REPL traces that interleave state-reveals through prints and variable transformations. We show that linear RNNs capable of state-tracking excel also in this setting, while Transformers still fail. Motivated by this representation, we investigate why tracking states in code is generally difficult: actions are not always fully observable. We frame this as tracking the state of a probabilistic finite-state automaton with deterministic state reveals and show that linear RNNs can be worse than non-linear RNNs at tracking states in this setup.",
    "title_zh": "使用线性RNN从代码中学习状态追踪",
    "abstract_zh": "近年来，状态追踪任务，尤其是排列组合任务，已成为研究Transformer和RNN（线性与非线性）等序列模型架构极限的重要测试平台。然而，这些任务通常属于序列到序列的范畴：学习将动作（排列）映射到状态，这与语言模型常用训练方式——下一个词预测——不兼容。为弥补这一差距，我们通过REPL（交互式解释器）追踪将排列组合转化为代码的形式，其中通过print语句和变量变换交错揭示状态信息。我们发现，具备状态追踪能力的线性RNN在此设置下表现优异，而Transformer模型依然表现不佳。受此表示形式的启发，我们进一步探究了在代码中追踪状态为何普遍困难：动作并非总是完全可观测。我们将这一问题建模为对具有确定性状态揭示的随机有限状态自动机的状态追踪问题，并发现在此设定下，线性RNN的表现甚至可能劣于非线性RNN。"
  },
  {
    "date": "2026-02-16",
    "title": "Traceable Latent Variable Discovery Based on Multi-Agent Collaboration",
    "authors": "Huaming Du, Tao Hu, Yijie Huang, Yu Zhao, Guisong Liu, Tao Gu, Gang Kou, Carl Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14456v1",
    "source": "arXiv",
    "abstract": "Revealing the underlying causal mechanisms in the real world is crucial for scientific and technological progress. Despite notable advances in recent decades, the lack of high-quality data and the reliance of traditional causal discovery algorithms (TCDA) on the assumption of no latent confounders, as well as their tendency to overlook the precise semantics of latent variables, have long been major obstacles to the broader application of causal discovery. To address this issue, we propose a novel causal modeling framework, TLVD, which integrates the metadata-based reasoning capabilities of large language models (LLMs) with the data-driven modeling capabilities of TCDA for inferring latent variables and their semantics. Specifically, we first employ a data-driven approach to construct a causal graph that incorporates latent variables. Then, we employ multi-LLM collaboration for latent variable inference, modeling this process as a game with incomplete information and seeking its Bayesian Nash Equilibrium (BNE) to infer the possible specific latent variables. Finally, to validate the inferred latent variables across multiple real-world web-based data sources, we leverage LLMs for evidence exploration to ensure traceability. We comprehensively evaluate TLVD on three de-identified real patient datasets provided by a hospital and two benchmark datasets. Extensive experimental results confirm the effectiveness and reliability of TLVD, with average improvements of 32.67% in Acc, 62.21% in CAcc, and 26.72% in ECit across the five datasets.",
    "title_zh": "基于多智能体协作的可追溯潜在变量发现",
    "abstract_zh": "揭示现实世界中潜在的因果机制对于科学与技术的进步至关重要。尽管近几十年来取得了显著进展，但高质量数据的缺乏、传统因果发现算法（TCDA）对“无潜在混杂因素”这一假设的依赖，以及其对潜在变量精确语义的忽视，长期以来一直是制约因果发现广泛应用的主要障碍。为解决这一问题，我们提出了一种新颖的因果建模框架——TLVD，该框架将大型语言模型（LLM）基于元数据的推理能力与TCDA的数据驱动建模能力相结合，用于推断潜在变量及其语义。具体而言，我们首先采用数据驱动的方法构建一个包含潜在变量的因果图；随后，通过多LLM协作进行潜在变量推断，将该过程建模为一个不完全信息博弈，并通过寻找其贝叶斯纳什均衡（BNE）来推断可能的具体潜在变量；最后，为在多个真实世界基于网络的数据源中验证所推断的潜在变量，我们利用LLM进行证据探索，以确保推断过程的可追溯性。我们在一家医院提供的三个去标识化患者数据集以及两个基准数据集上对TLVD进行了全面评估。大量实验结果证实了TLVD的有效性与可靠性，在五个数据集上平均分别提升了32.67%的准确率（Acc）、62.21%的类别准确率（CAcc）和26.72%的ECit指标。"
  },
  {
    "date": "2026-02-16",
    "title": "Automated Classification of Source Code Changes Based on Metrics Clustering in the Software Development Process",
    "authors": "Evgenii Kniazev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14591v1",
    "source": "arXiv",
    "abstract": "This paper presents an automated method for classifying source code changes during the software development process based on clustering of change metrics. The method consists of two steps: clustering of metric vectors computed for each code change, followed by expert mapping of the resulting clusters to predefined change classes. The distribution of changes into clusters is performed automatically, while the mapping of clusters to classes is carried out by an expert. Automation of the distribution step substantially reduces the time required for code change review. The k-means algorithm with a cosine similarity measure between metric vectors is used for clustering. Eleven source code metrics are employed, covering lines of code, cyclomatic complexity, file counts, interface changes, and structural changes. The method was validated on five software systems, including two open-source projects (Subversion and NHibernate), and demonstrated classification purity of P_C = 0.75 +/- 0.05 and entropy of E_C = 0.37 +/- 0.06 at a significance level of 0.05.",
    "title_zh": "基于度量聚类的软件开发过程中源代码变更的自动化分类",
    "abstract_zh": "本文提出了一种基于变更度量聚类的自动化方法，用于在软件开发过程中对源代码变更进行分类。该方法包含两个步骤：首先对每个代码变更计算的度量向量进行聚类，然后由专家将聚类结果映射到预定义的变更类别。变更在聚类中的分配过程完全自动化，而聚类到类别的映射则由专家完成。自动化分配步骤显著减少了代码变更审查所需的时间。聚类采用基于度量向量间余弦相似度的k-means算法。所使用的度量共11项，涵盖代码行数、圈复杂度、文件数量、接口变更以及结构变更等方面。该方法在五个软件系统上进行了验证，包括两个开源项目（Subversion和NHibernate），在0.05的显著性水平下，分类纯度达到P_C = 0.75 ± 0.05，熵值为E_C = 0.37 ± 0.06。"
  },
  {
    "date": "2026-02-16",
    "title": "LLMStructBench: Benchmarking Large Language Model Structured Data Extraction",
    "authors": "Sönke Tenckhoff, Mario Koddenbrock, Erik Rodner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14743v1",
    "source": "arXiv",
    "abstract": "We present LLMStructBench, a novel benchmark for evaluating Large Language Models (LLMs) on extracting structured data and generating valid JavaScript Object Notation (JSON) outputs from natural-language text. Our open dataset comprises diverse, manually verified parsing scenarios of varying complexity and enables systematic testing across 22 models and five prompting strategies. We further introduce complementary performance metrics that capture both token-level accuracy and document-level validity, facilitating rigorous comparison of model, size, and prompting effects on parsing reliability. In particular, we show that choosing the right prompting strategy is more important than standard attributes such as model size. This especially ensures structural validity for smaller or less reliable models but increase the number of semantic errors. Our benchmark suite is an step towards future research in the area of LLM applied to parsing or Extract, Transform and Load (ETL) applications.",
    "title_zh": "LLMStructBench：大型语言模型结构化数据提取基准测试",
    "abstract_zh": "我们提出了 LLMStructBench，这是一个用于评估大型语言模型（LLMs）从自然语言文本中提取结构化数据并生成有效 JavaScript 对象表示（JSON）输出的新基准。我们的开源数据集包含多种经过人工验证的、复杂度各异的解析场景，支持对22种模型和五种提示策略进行系统性测试。我们还引入了互补的性能度量指标，能够同时捕捉标记级准确率和文档级有效性，从而更严谨地比较模型、模型规模以及提示策略对解析可靠性的影响。特别地，我们发现选择合适的提示策略比模型规模等传统属性更为重要。这尤其有助于提升小型或可靠性较低模型的结构有效性，但可能增加语义错误的数量。我们的基准套件为未来在大型语言模型应用于解析或提取、转换、加载（ETL）等应用领域的研究迈出了重要一步。"
  },
  {
    "date": "2026-02-16",
    "title": "Polar: An Algebraic Analyzer for (Probabilistic) Loops",
    "authors": "Marcel Moosbrugger, Julian Müllner, Ezio Bartocci, Laura Kovács",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14573v1",
    "source": "arXiv",
    "abstract": "We present the Polar framework for fully automating the analysis of classical and probabilistic loops using algebraic reasoning. The central theme in Polar comes with handling algebraic recurrences that precisely capture the loop semantics. To this end, our work implements a variety of techniques to compute exact closed-forms of recurrences over higher-order moments of variables, infer invariants, and derive loop sensitivities with respect to unknown parameters. Polar can analyze probabilistic loops containing if-statements, polynomial arithmetic, and common probability distributions. By translating loop analysis into linear recurrence solving, Polar uses the derived closed-forms of recurrences to compute the strongest polynomial invariant or to infer parameter sensitivity. Polar is both sound and complete within well-defined programming model restrictions. Lifting any of these restrictions results in significant hardness limits of computation. To overcome computational burdens for the sake of efficiency, Polar also provides incomplete but sound techniques to compute moments of combinations of variables.",
    "title_zh": "极地：一个用于（概率）循环的代数分析器",
    "abstract_zh": "我们提出了Polar框架，该框架通过代数推理实现对经典循环和概率循环的完全自动化分析。Polar的核心思想在于处理能够精确捕捉循环语义的代数递推关系。为此，我们的工作实现了多种技术，用于计算变量高阶矩的递推关系的精确闭式解，推断循环不变式，并推导循环对未知参数的敏感性。Polar能够分析包含if语句、多项式运算以及常见概率分布的概率循环。通过将循环分析转化为线性递推求解问题，Polar利用递推关系的闭式解来计算最强的多项式不变式或推断参数敏感性。在定义明确的编程模型限制下，Polar具有完备性和正确性。若放宽这些限制，则会导致计算复杂性显著增加。为提高效率，Polar还提供了一些不完备但正确的技术，用于计算变量组合的矩。"
  },
  {
    "date": "2026-02-16",
    "title": "When Security Meets Usability: An Empirical Investigation of Post-Quantum Cryptography APIs",
    "authors": "Marthin Toruan, R. D. N. Shakya, Samuel Tseitkin, Raymond K. Zhao, Nalin Arachchilage",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14539v1",
    "source": "arXiv",
    "abstract": "Advances in quantum computing increasingly threaten the security and privacy of data protected by current cryptosystems, particularly those relying on public-key cryptography. In response, the international cybersecurity community has prioritized the implementation of Post-Quantum Cryptography (PQC), a new cryptographic standard designed to resist quantum attacks while operating on classical computers. The National Institute of Standards and Technology (NIST) has already standardized several PQC algorithms and plans to deprecate classical asymmetric schemes, such as RSA and ECDSA, by 2035. Despite this urgency, PQC adoption remains slow, often due to limited developer expertise. Application Programming Interfaces (APIs) are intended to bridge this gap, yet prior research on classical security APIs demonstrates that poor usability of cryptographic APIs can lead developers to introduce vulnerabilities during implementation of the applications, a risk amplified by the novelty and complexity of PQC. To date, the usability of PQC APIs has not been systematically studied. This research presents an empirical evaluation of the usability of the PQC APIs, observing how developers interact with APIs and documentation during software development tasks. The study identifies cognitive factors that influence the developer's performance when working with PQC primitives with minimal onboarding. The findings highlight opportunities across the PQC ecosystem to improve developer-facing guidance, terminology alignment, and workflow examples to better support non-specialists.",
    "title_zh": "当安全遇见可用性：后量子密码学API的实证研究",
    "abstract_zh": "量子计算技术的不断进步，正日益威胁当前加密系统所保护的数据安全与隐私，尤其是依赖公钥密码学的系统。为此，国际网络安全界已将实施后量子密码学（Post-Quantum Cryptography, PQC）列为优先事项。PQC是一种新型加密标准，旨在抵御量子攻击，同时可在经典计算机上运行。美国国家标准与技术研究院（NIST）已正式标准化了多项PQC算法，并计划在2035年前逐步淘汰RSA、ECDSA等传统非对称加密方案。尽管形势紧迫，但PQC的实际应用推广仍进展缓慢，主要原因在于开发者专业能力有限。应用程序编程接口（API）本应弥补这一差距，然而以往针对传统安全API的研究表明，密码学API的可用性差，容易导致开发者在实现应用时引入安全漏洞，而PQC本身具有新颖性和复杂性，这一风险被进一步放大。迄今为止，PQC API的可用性尚未得到系统性研究。本研究通过实证方法评估了PQC API的可用性，观察开发者在软件开发任务中如何与API及文档互动。研究识别出影响开发者在极少培训情况下使用PQC原语时表现的认知因素。研究结果揭示了在PQC生态系统中存在诸多改进机会，包括优化面向开发者的指导文档、统一术语表达以及提供更实用的工作流程示例，以更好地支持非专业开发者。"
  },
  {
    "date": "2026-02-16",
    "title": "ReusStdFlow: A Standardized Reusability Framework for Dynamic Workflow Construction in Agentic AI",
    "authors": "Gaoyang Zhang, Shanghong Zou, Yafang Wang, He Zhang, Ruohua Xu, Feng Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14922v1",
    "source": "arXiv",
    "abstract": "To address the ``reusability dilemma'' and structural hallucinations in enterprise Agentic AI,this paper proposes ReusStdFlow, a framework centered on a novel ``Extraction-Storage-Construction'' paradigm. The framework deconstructs heterogeneous, platform-specific Domain Specific Languages (DSLs) into standardized, modular workflow segments. It employs a dual knowledge architecture-integrating graph and vector databases-to facilitate synergistic retrieval of both topological structures and functional semantics. Finally, workflows are intelligently assembled using a retrieval-augmented generation (RAG) strategy. Tested on 200 real-world n8n workflows, the system achieves over 90% accuracy in both extraction and construction. This framework provides a standardized solution for the automated reorganization and efficient reuse of enterprise digital assets.",
    "title_zh": "ReusStdFlow：面向智能体AI动态工作流构建的标准化可复用性框架",
    "abstract_zh": "为解决企业智能体AI中的“可重用性困境”与结构幻觉问题，本文提出ReusStdFlow框架，该框架以一种新颖的“提取-存储-构建”范式为核心。该框架将异构的、平台特定的领域特定语言（DSL）解构为标准化、模块化的流程片段，并采用融合图数据库与向量数据库的双重知识架构，实现拓扑结构与功能语义的协同检索。最终，通过检索增强生成（RAG）策略，智能地组装工作流程。在200个真实世界n8n工作流上的测试表明，该系统在提取与构建环节均实现了超过90%的准确率。该框架为企事业单位数字资产的自动化重组与高效重用提供了标准化解决方案。"
  },
  {
    "date": "2026-02-16",
    "title": "Model Context Protocol (MCP) Tool Descriptions Are Smelly! Towards Improving AI Agent Efficiency with Augmented MCP Tool Descriptions",
    "authors": "Mohammed Mehedi Hasan, Hao Li, Gopi Krishnan Rajbahadur, Bram Adams, Ahmed E. Hassan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14878v1",
    "source": "arXiv",
    "abstract": "The Model Context Protocol (MCP) standardizes how Foundation Model (FM)-based agents interact with external systems by invoking tools. However, to understand a tool's purpose and features, FMs rely on natural-language tool descriptions, making these descriptions a critical component in guiding FMs to select the optimal tool for a given (sub)task and to pass the right arguments to the tool. While defects or smells in these descriptions can misguide FM-based agents, their prevalence and consequences in the MCP ecosystem remain unclear. To address this, we conduct the first large-scale empirical study of 856 tools spread across 103 MCP servers, assessing their description quality and their impact on agent performance. We identify six components of tool descriptions from the literature, develop a scoring rubric utilizing these components, then formalize tool description smells based on this rubric. By operationalizing this rubric through an FM-based scanner, we find that 97.1% of the analyzed tool descriptions contain at least one smell, with 56% failing to state their purpose clearly. While augmenting these descriptions for all components improves task success rates by a median of 5.85 percentage points and improves partial goal completion by 15.12%, it also increases the number of execution steps by 67.46% and regresses performance in 16.67% of cases. These findings highlight a trade-off between agent performance and cost, as well as the context sensitivity of the performance gain. Furthermore, component ablations show that compact variants of different component combinations often preserve behavioral reliability while reducing unnecessary token overhead, enabling more efficient use of the FM context window and lower execution costs.",
    "title_zh": "模型上下文协议（MCP）工具描述存在“异味”！通过增强MCP工具描述提升AI代理效率的研究",
    "abstract_zh": "模型上下文协议（MCP）通过调用工具，标准化了基于基础模型（FM）的智能体与外部系统之间的交互方式。然而，为了理解工具的目的和功能，基础模型依赖于自然语言描述的工具说明，因此这些描述成为引导FM为特定（子）任务选择最优工具并正确传递参数的关键组成部分。尽管工具说明中的缺陷或“异味”可能误导FM驱动的智能体，但这些缺陷在MCP生态系统中的普遍程度及其后果尚不明确。为解决这一问题，我们开展了首个大规模实证研究，对分布在103个MCP服务器上的856个工具进行了分析，评估其说明质量及其对智能体性能的影响。\n\n我们从文献中归纳出工具说明的六个核心组成部分，基于这些部分构建了一个评分量表，并据此形式化定义了工具说明的“异味”类型。通过使用基于基础模型的扫描工具来操作化该量表，我们发现：在所分析的工具说明中，97.1%至少包含一种异味，其中56%未能清晰表达其用途。尽管对所有组成部分进行说明增强后，任务成功率中位数提升了5.85个百分点，部分目标完成率提升了15.12%，但同时也导致执行步骤数量增加了67.46%，且在16.67%的情况下反而导致性能下降。\n\n这些发现揭示了智能体性能与执行成本之间的权衡关系，以及性能提升具有高度上下文依赖性。此外，通过组件消融实验发现，不同组件组合的紧凑变体通常能在保持行为可靠性的同时，减少不必要的令牌开销，从而更高效地利用基础模型的上下文窗口，降低执行成本。"
  },
  {
    "date": "2026-02-16",
    "title": "BEACONS: Bounded-Error, Algebraically-Composable Neural Solvers for Partial Differential Equations",
    "authors": "Jonathan Gorard, Ammar Hakim, James Juno",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14853v1",
    "source": "arXiv",
    "abstract": "The traditional limitations of neural networks in reliably generalizing beyond the convex hulls of their training data present a significant problem for computational physics, in which one often wishes to solve PDEs in regimes far beyond anything which can be experimentally or analytically validated. In this paper, we show how it is possible to circumvent these limitations by constructing formally-verified neural network solvers for PDEs, with rigorous convergence, stability, and conservation properties, whose correctness can therefore be guaranteed even in extrapolatory regimes. By using the method of characteristics to predict the analytical properties of PDE solutions a priori (even in regions arbitrarily far from the training domain), we show how it is possible to construct rigorous extrapolatory bounds on the worst-case L^inf errors of shallow neural network approximations. Then, by decomposing PDE solutions into compositions of simpler functions, we show how it is possible to compose these shallow neural networks together to form deep architectures, based on ideas from compositional deep learning, in which the large L^inf errors in the approximations have been suppressed. The resulting framework, called BEACONS (Bounded-Error, Algebraically-COmposable Neural Solvers), comprises both an automatic code-generator for the neural solvers themselves, as well as a bespoke automated theorem-proving system for producing machine-checkable certificates of correctness. We apply the framework to a variety of linear and non-linear PDEs, including the linear advection and inviscid Burgers' equations, as well as the full compressible Euler equations, in both 1D and 2D, and illustrate how BEACONS architectures are able to extrapolate solutions far beyond the training data in a reliable and bounded way. Various advantages of the approach over the classical PINN approach are discussed.",
    "title_zh": "BEACONS：用于偏微分方程的有界误差、代数可组合神经求解器",
    "abstract_zh": "神经网络在可靠地超越其训练数据凸包之外进行泛化方面的传统局限性，对计算物理领域构成了重大挑战，因为在该领域中，人们常常需要求解远超出实验或解析验证范围的偏微分方程（PDEs）。本文展示了如何通过构建形式化验证的神经网络PDE求解器，来克服这些局限性。这些求解器具备严格的收敛性、稳定性及守恒性质，因此即使在外推区域，其正确性也能得到保证。我们利用特征线法预先预测PDE解的解析性质（即使在距离训练域任意远的区域），从而能够对浅层神经网络近似解的最坏情况L^∞误差建立严格的外推边界。接着，通过将PDE解分解为更简单函数的复合形式，我们展示了如何将这些浅层神经网络组合成深度架构，借鉴了组合式深度学习的思想，从而有效抑制了近似中出现的大L^∞误差。由此形成的框架被称为BEACONS（Bounded-Error, Algebraically-COmposable Neural Solvers），它不仅包含用于自动生成神经求解器代码的工具，还配备了一个专用的自动化定理证明系统，用于生成可机器验证的正确性证明证书。我们将该框架应用于多种线性和非线性PDE，包括一维和二维的线性对流方程、无粘Burgers方程以及完整的可压缩Euler方程，并展示了BEACONS架构能够在可靠且误差有界的前提下，将解外推至远超训练数据的区域。本文还讨论了该方法相较于经典物理信息神经网络（PINN）方法的多种优势。"
  },
  {
    "date": "2026-02-16",
    "title": "RoboSolver: A Multi-Agent Large Language Model Framework for Solving Robotic Arm Problems",
    "authors": "Hamid Khabazi, Ali F. Meghdari, Alireza Taheri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14438v1",
    "source": "arXiv",
    "abstract": "This study proposes an intelligent multi-agent framework built on LLMs and VLMs and specifically tailored to robotics. The goal is to integrate the strengths of LLMs and VLMs with computational tools to automatically analyze and solve problems related to robotic manipulators. Our developed framework accepts both textual and visual inputs and can automatically perform forward and inverse kinematics, compute velocities and accelerations of key points, generate 3D simulations of the robot, and ultimately execute motion control within the simulated environment, all according to the user's query. To evaluate the framework, three benchmark tests were designed, each consisting of ten questions. In the first benchmark test, the framework was evaluated while connected to GPT-4o, DeepSeek-V3.2, and Claude-Sonnet-4.5, as well as their corresponding raw models. The objective was to extract the forward kinematics of robots directly from textual descriptions. The results showed that the framework integrated with GPT-4o achieved the highest accuracy, reaching 0.97 in computing the final solution, whereas the raw model alone attained an accuracy of only 0.30 for the same task. Similarly, for the other two models, the framework consistently outperformed the corresponding raw models in terms of accuracy. The second benchmark test was identical to the first, except that the input was provided in visual form. In this test, the GPT-4o LLM was used alongside the Gemini 2.5 Pro VLM. The results showed that the framework achieved an accuracy of 0.93 in obtaining the final answer, which is approximately 20% higher than that of the corresponding raw model. The third benchmark test encompassed a range of robotic tasks, including simulation, control, velocity and acceleration computation, as well as inverse kinematics and Jacobian calculation, for which the framework achieved an accuracy of 0.97.",
    "title_zh": "RoboSolver：一种用于解决机械臂问题的多智能体大语言模型框架",
    "abstract_zh": "本研究提出了一种基于大语言模型（LLMs）和视觉语言模型（VLMs）的智能多智能体框架，专为机器人领域量身定制。其目标是融合LLMs与VLMs的优势，并结合计算工具，实现对机器人操作臂相关问题的自动分析与求解。我们开发的框架能够接受文本和视觉双重输入，根据用户查询自动完成正向与逆向运动学计算、关键点速度与加速度的求解、生成机器人的三维仿真，并最终在仿真环境中执行运动控制。\n\n为评估该框架的性能，我们设计了三项基准测试，每项测试包含十个问题。在第一项基准测试中，框架分别与GPT-4o、DeepSeek-V3.2和Claude-Sonnet-4.5及其对应的原始模型进行集成测试，目标是从纯文本描述中直接提取机器人的正向运动学信息。结果表明，集成GPT-4o的框架在求解最终结果时达到了0.97的准确率，而仅使用原始模型的准确率仅为0.30。同样地，对于其他两个模型，框架在各项指标上均显著优于对应的原始模型。\n\n第二项基准测试与第一项类似，但输入形式改为视觉信息。本测试中，采用GPT-4o作为语言模型，Gemini 2.5 Pro作为视觉语言模型。结果显示，框架在获取最终答案时的准确率达到0.93，较对应原始模型高出约20%。\n\n第三项基准测试涵盖了多种机器人任务，包括仿真、控制、速度与加速度计算、逆向运动学求解以及雅可比矩阵计算。在此综合性任务中，框架整体准确率达到了0.97，充分展现了其在复杂机器人问题求解中的强大能力。"
  },
  {
    "date": "2026-02-16",
    "title": "Configuring Agentic AI Coding Tools: An Exploratory Study",
    "authors": "Matthias Galster, Seyedmoein Mohsenimofidi, Jai Lal Lulla, Muhammad Auwal Abubakar, Christoph Treude, Sebastian Baltes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14690v1",
    "source": "arXiv",
    "abstract": "Agentic AI coding tools with autonomous capabilities beyond conversational content generation increasingly automate repetitive and time-consuming software development tasks. Developers can configure these tools through versioned repository-level artifacts such as Markdown and JSON files. In this paper, we present a systematic analysis of configuration mechanisms for agentic AI coding tools, covering Claude Code, GitHub Copilot, Cursor, Gemini, and Codex. We identify eight configuration mechanisms and, in an empirical study of 2,926 GitHub repositories, examine whether and how they are adopted. We then explore Context Files, Skills, and Subagents, that is, three mechanisms available across tools, in more detail. Our findings reveal three trends. First, Context Files dominate the configuration landscape and are often the sole mechanism in a repository, with AGENTS$.$md emerging as an interoperable standard across tools. Second, advanced mechanisms such as Skills and Subagents are only shallowly adopted: most repositories define only one or two artifacts, and Skills predominantly rely on static instructions rather than executable workflows. Third, distinct configuration cultures are forming around different tools, with Claude Code users employing the broadest range of mechanisms. These findings establish an empirical baseline for longitudinal and experimental research on how configuration strategies evolve and affect agent performance as agentic AI coding tools mature.",
    "title_zh": "配置代理型AI编程工具：一项探索性研究",
    "abstract_zh": "具备自主能力的智能代理型AI编程工具，其功能已超越单纯的对话内容生成，正日益自动化重复性且耗时的软件开发任务。开发者可通过版本化仓库级别的配置文件（如Markdown和JSON文件）对这些工具进行配置。本文系统分析了五种主流智能代理型AI编程工具——Claude Code、GitHub Copilot、Cursor、Gemini和Codex——的配置机制，识别出八种主要配置方式。通过对2,926个GitHub仓库的实证研究，我们考察了这些机制的实际采用情况及其使用方式。此外，我们进一步深入探讨了三种在各工具间通用的机制：上下文文件（Context Files）、技能（Skills）和子代理（Subagents）。研究发现呈现三大趋势：第一，上下文文件在配置体系中占据主导地位，许多仓库仅使用这一种机制，其中AGENTS.md已逐渐成为跨工具间可互操作的标准；第二，高级配置机制如技能和子代理的采用程度较浅：大多数仓库仅定义一两个配置文件，且技能主要依赖静态指令，而非可执行的工作流；第三，不同工具正形成各自独特的配置文化，其中Claude Code用户使用配置机制的范围最广。本研究为未来关于智能代理型AI编程工具配置策略如何随时间演变及其对代理性能影响的纵向研究与实验研究，奠定了实证基础。"
  },
  {
    "date": "2026-02-16",
    "title": "Consistent or Sensitive? Automated Code Revision Tools Against Semantics-Preserving Perturbations",
    "authors": "Shirin Pirouzkhah, Souhaila Serbout, Alberto Bacchelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14595v1",
    "source": "arXiv",
    "abstract": "Automated Code Revision (ACR) tools aim to reduce manual effort by automatically generating code revisions based on reviewer feedback. While ACR tools have shown promising performance on historical data, their real-world utility depends on their ability to handle similar code variants expressing the same issue - a property we define as consistency. However, the probabilistic nature of ACR tools often compromises consistency, which may lead to divergent revisions even for semantically equivalent code variants. In this paper, we investigate the extent to which ACR tools maintain consistency when presented with semantically equivalent code variants. To do so, we first designed nine types of semantics-preserving perturbations (SPP) and applied them to 2032 Java methods from real-world GitHub projects, generating over 10K perturbed variants for evaluation. Then we used these perturbations to evaluate the consistency of five state-of-the-art transformer-based ACR tools. We found that the ACR tools' ability to generate correct revisions can drop by up to 45.3%, when presented with semantically equivalent code. The closer the perturbation is to this targeted region, the more likely an ACR tool is to fail to generate the correct revision. We explored potential mitigation strategies that modify the input representation, but found that these attention-guiding heuristics yielded only marginal improvements, thus leaving the solution to this problem as an open research question.",
    "title_zh": "一致还是敏感？针对语义保持扰动的自动化代码修订工具",
    "abstract_zh": "自动化代码修订（ACR）工具旨在通过根据评审反馈自动生成代码修订，从而减少人工工作量。尽管ACR工具在历史数据上表现出色，但其在现实场景中的实用性取决于其处理语义相同但形式不同的代码变体的能力——我们称之为一致性。然而，ACR工具固有的概率特性常常损害一致性，导致即使面对语义等价的代码变体，也可能产生不同的修订结果。本文研究了ACR工具在面对语义等价代码变体时保持一致性的程度。为此，我们首先设计了九种语义保持型扰动（SPP），并将其应用于来自真实GitHub项目的2032个Java方法，生成了超过10,000个扰动后的代码变体用于评估。随后，我们利用这些扰动对五种最先进的基于Transformer的ACR工具进行了一致性评估。研究发现，当ACR工具面对语义等价的代码时，其生成正确修订的能力最高可下降45.3%。扰动越接近目标修改区域，ACR工具越可能无法生成正确的修订。我们探索了通过修改输入表示来缓解该问题的潜在策略，但发现这些引导注意力的启发式方法仅带来微弱的改进，因此该问题的解决方案仍是一个开放的研究课题。"
  },
  {
    "date": "2026-02-16",
    "title": "Optimal Program Synthesis via Abstract Interpretation",
    "authors": "Stephen Mell, Steve Zdancewic, Osbert Bastani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14717v1",
    "source": "arXiv",
    "abstract": "We consider the problem of synthesizing programs with numerical constants that optimize a quantitative objective, such as accuracy, over a set of input-output examples. We propose a general framework for optimal synthesis of such programs in a given domain specific language (DSL), with provable optimality guarantees. Our framework enumerates programs in a general search graph, where nodes represent subsets of concrete programs. To improve scalability, it uses A* search in conjunction with a search heuristic based on abstract interpretation; intuitively, this heuristic establishes upper bounds on the value of subtrees in the search graph, enabling the synthesizer to identify and prune subtrees that are provably suboptimal. In addition, we propose a natural strategy for constructing abstract transformers for monotonic semantics, which is a common property for components in DSLs for data classification. Finally, we implement our approach in the context of two such existing DSLs, demonstrating that our algorithm is more scalable than existing optimal synthesizers.",
    "title_zh": "通过抽象解释实现最优程序合成",
    "abstract_zh": "我们研究在给定一组输入-输出示例的情况下，合成包含数值常量的程序以优化定量目标（如准确率）的问题。我们提出了一种通用框架，用于在特定领域语言（DSL）中实现此类程序的最优合成，并提供可证明的最优性保证。该框架在通用搜索图中枚举程序，其中节点表示具体程序的子集。为了提高可扩展性，该框架结合A*搜索与基于抽象解释的搜索启发式方法；直观上，该启发式方法为搜索图中的子树建立了上界，使合成器能够识别并剪除那些被证明次优的子树。此外，我们提出了一种针对单调语义的自然抽象变换器构造策略，而单调语义是数据分类类DSL中组件的常见性质。最后，我们在两个现有的此类DSL中实现了该方法，实验表明，我们的算法比现有的最优合成器具有更高的可扩展性。"
  },
  {
    "date": "2026-02-16",
    "title": "Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows",
    "authors": "Bardia Mohammadi, Nearchos Potamitis, Lars Klein, Akhil Arora, Laurent Bindschaedler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14849v1",
    "source": "arXiv",
    "abstract": "LLM agents increasingly act on external systems, yet tool effects are immediate. Under failures, speculation, or contention, losing branches can leak unintended side effects with no safe rollback. We introduce Atomix, a runtime that provides progress-aware transactional semantics for agent tool calls. Atomix tags each call with an epoch, tracks per-resource frontiers, and commits only when progress predicates indicate safety; bufferable effects can be delayed, while externalized effects are tracked and compensated on abort. Across real workloads with fault injection, transactional retry improves task success, while frontier-gated commit strengthens isolation under speculation and contention.",
    "title_zh": "Atomix：及时、事务性工具使用，实现可靠的智能体工作流",
    "abstract_zh": "大型语言模型（LLM）代理越来越多地作用于外部系统，但工具调用的效果往往是即时生效的。在发生故障、存在推测性执行或资源竞争的情况下，未完成的分支可能会导致意外的副作用，且无法安全回滚。我们提出了Atomix，一种运行时系统，为代理的工具调用提供具有进度感知能力的事务性语义。Atomix为每次调用打上“纪元”标签，跟踪每个资源的前沿状态，并仅在进度谓词表明安全时才提交；可缓冲的副作用可以延迟执行，而已对外暴露的副作用则会被追踪并在事务中止时进行补偿。在真实工作负载中结合故障注入的实验表明，事务性重试显著提升了任务成功率，而基于前沿状态的提交机制则在推测执行和资源竞争场景下有效增强了隔离性。"
  },
  {
    "date": "2026-02-16",
    "title": "Overthinking Loops in Agents: A Structural Risk via MCP Tools",
    "authors": "Yohan Lee, Jisoo Jang, Seoyeon Choi, Sangyeop Kim, Seungtaek Choi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14798v1",
    "source": "arXiv",
    "abstract": "Tool-using LLM agents increasingly coordinate real workloads by selecting and chaining third-party tools based on text-visible metadata such as tool names, descriptions, and return messages. We show that this convenience creates a supply-chain attack surface: a malicious MCP tool server can be co-registered alongside normal tools and induce overthinking loops, where individually trivial or plausible tool calls compose into cyclic trajectories that inflate end-to-end tokens and latency without any single step looking abnormal. We formalize this as a structural overthinking attack, distinguishable from token-level verbosity, and implement 14 malicious tools across three servers that trigger repetition, forced refinement, and distraction. Across heterogeneous registries and multiple tool-capable models, the attack causes severe resource amplification (up to $142.4\\times$ tokens) and can degrade task outcomes. Finally, we find that decoding-time concision controls do not reliably prevent loop induction, suggesting defenses should reason about tool-call structure rather than tokens alone.",
    "title_zh": "代理中的过度思考循环：一种通过MCP工具带来的结构风险",
    "abstract_zh": "使用工具的大型语言模型代理正越来越多地通过基于文本可见元数据（如工具名称、描述和返回消息）选择并串联第三方工具来协调实际工作负载。我们发现，这种便利性带来了一种供应链攻击面：恶意的MCP工具服务器可与正常工具一同注册，从而引发过度思考循环——单个工具调用看似平凡或合理，但多个调用组合后形成循环轨迹，导致端到端的令牌数量和延迟显著增加，而每个步骤本身却无异常表现。我们将这一现象形式化为一种结构性过度思考攻击，其与基于令牌数量的冗长性有本质区别。我们在三个服务器上实现了14个恶意工具，能够触发重复、强制优化和干扰等行为。在多种异构工具注册表及多个具备工具调用能力的模型上，该攻击导致严重的资源放大（令牌数最高达142.4倍），并可能损害任务完成效果。最后，我们发现解码阶段的简洁性控制措施无法可靠防止循环诱导，这表明防御策略应关注工具调用的结构而非仅依赖令牌数量。"
  },
  {
    "date": "2026-02-16",
    "title": "Efficient Multi-round LLM Inference over Disaggregated Serving",
    "authors": "Wenhao He, Youhe Jiang, Penghao Zhao, Quanqing Xu, Eiko Yoneki, Bin Cui, Fangcheng Fu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14516v1",
    "source": "arXiv",
    "abstract": "With the rapid evolution of Large Language Models (LLMs), multi-round workflows, such as autonomous agents and iterative retrieval, have become increasingly prevalent. However, this raises hurdles for serving LLMs under prefill-decode (PD) disaggregation, a widely adopted paradigm that separates the compute-bound prefill phase and memory-bound decode phase onto individual resources. Specifically, existing systems overlook the interleaved prefill-decode workload pattern in multi-round inference, leading to sub-optimal handling of the incremental prefill workloads and model deployment for the two phases. In this work, we present AMPD, a brand new disaggregated serving framework for multi-round LLM inference. The core of AMPD is to coordinate the prefill workloads based on real-time workloads by adaptively determining where to carry out these workloads and how they are scheduled, in order to maximize service level objective (SLO) attainment. In addition, we tailor a planning algorithm for our scenario, facilitating the deduction of optimal resource allocation and parallel strategies for the two phases. Empirical results demonstrate that AMPD substantially improves SLO attainment compared to state-of-the-art baselines.",
    "title_zh": "分离式服务下的高效多轮大语言模型推理",
    "abstract_zh": "随着大型语言模型（LLMs）的快速发展，多轮推理工作流（如自主代理和迭代检索）日益普遍。然而，这给在预填充-解码（Prefill-Decode, PD）分离架构下的LLM服务带来了挑战。PD分离是一种广泛采用的范式，将计算密集型的预填充阶段与内存密集型的解码阶段分别部署在独立的资源上。然而，现有系统忽略了多轮推理中预填充与解码交错执行的工作负载特征，导致对增量预填充任务的处理不够优化，且对两个阶段的模型部署缺乏高效协调。本文提出AMPD——一种全新的用于多轮LLM推理的分离式服务框架。AMPD的核心思想是基于实时工作负载动态协调预填充任务，自适应地决定任务的执行位置及调度方式，以最大化服务等级目标（SLO）的达成率。此外，我们针对该场景设计了一种定制化的规划算法，能够推导出两个阶段最优的资源分配与并行策略。实验结果表明，与现有最先进基线相比，AMPD显著提升了SLO达成率。"
  },
  {
    "date": "2026-02-16",
    "title": "Precedent-Informed Reasoning: Mitigating Overthinking in Large Reasoning Models via Test-Time Precedent Learning",
    "authors": "Qianyue Wang, Jinwu Hu, Huanxiang Lin, Bolin Chen, Zhiquan Wen, Yaofo Chen, Yu Rong, Mingkui Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14451v1",
    "source": "arXiv",
    "abstract": "Reasoning in Large Language Models (LLMs) often suffers from inefficient long chain-of-thought traces with redundant self-exploration and validation, which inflate computational costs and even degrade performance. Inspired by human reasoning patterns where people solve new problems by leveraging past related cases to constrain search spaces and reduce trial-and-error, we propose Precedent Informed Reasoning (PIR) transforming LRMs'reasoning paradigm from exhaustive self-exploration to guided learning from precedents. PIR addresses two key challenges: what precedents to adopt and how to utilize them. First, Adaptive Precedent Selection (APS) constructs, for each question and LRM, a compact set of precedents that are both semantically related and informative for the model. It ranks examples by a joint score with semantic similarity and model perplexity, then adapts the amount of precedents to maximize perplexity reduction. Second, Test-time Experience Internalization (TEI) is treated as the test-time learning on precedent-informed instruction, updating lightweight adapters to internalize solution patterns and use them as a prior during subsequent reasoning. Experiments across mathematical reasoning, scientific QA, and code generation demonstrate that PIR consistently shortens reasoning traces while maintaining or improving final accuracy across LLMs, yielding outstanding accuracy-efficiency trade-offs.",
    "title_zh": "基于先例的推理：通过测试时先例学习缓解大型推理模型的过度思考问题",
    "abstract_zh": "大型语言模型（LLM）在推理过程中常常面临低效的长链思维（chain-of-thought）轨迹问题，表现为冗余的自我探索与验证，这不仅增加了计算开销，甚至会降低模型性能。受人类推理模式的启发——人们在解决新问题时，会借助过往相关案例来缩小搜索空间、减少试错——我们提出了**先例引导推理**（Precedent Informed Reasoning, PIR），将LLM的推理范式从盲目自探索转变为基于先例的引导式学习。PIR解决了两个核心挑战：**应选择哪些先例**，以及**如何有效利用这些先例**。\n\n首先，**自适应先例选择**（Adaptive Precedent Selection, APS）为每个问题和LLM构建一个紧凑的先例集合，这些先例在语义上与当前问题相关，且对模型具有信息价值。APS通过结合语义相似度与模型困惑度的联合得分对候选示例进行排序，并动态调整先例数量，以实现困惑度的最大化降低。\n\n其次，**测试时经验内化**（Test-time Experience Internalization, TEI）被视作在先例引导指令下的测试时学习过程，通过更新轻量级适配器（adapters），使模型能够内化解决方案的模式，并在后续推理中将其作为先验知识使用。\n\n在数学推理、科学问答和代码生成等多个任务上的实验表明，PIR能够显著缩短推理轨迹，同时在各类LLM上保持甚至提升最终准确率，实现了卓越的准确率-效率权衡。"
  },
  {
    "date": "2026-02-16",
    "title": "Broken Chains: The Cost of Incomplete Reasoning in LLMs",
    "authors": "Ian Su, Gaurav Purushothaman, Jey Narayan, Ruhika Goel, Kevin Zhu, Sunishchal Dev, Yash More, Maheep Chaudhary",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.14444v1",
    "source": "arXiv",
    "abstract": "Reasoning-specialized models like OpenAI's 5.1 and DeepSeek-V3.2 allocate substantial inference compute to extended chain-of-thought (CoT) traces, yet reasoning tokens incur significant costs. How do different reasoning modalities of code, natural language, hybrid, or none do perform under token constraints? We introduce a framework that constrains models to reason exclusively through code, comments, both, or neither, then systematically ablates token budgets to 10\\%, 30\\%, 50\\%, and 70\\% of optimal. We evaluate four frontier models (GPT-5.1, Gemini 3 Flash, DeepSeek-V3.2, Grok 4.1) across mathematical benchmarks (AIME, GSM8K, HMMT). Our findings reveal: (1) \\textbf{truncated reasoning can hurt} as DeepSeek-V3.2 achieves 53\\% with no reasoning but only 17\\% with truncated CoT at 50\\% budget; (2) \\textbf{code degrades gracefully} as Gemini's comments collapse to 0\\% while code maintains 43-47\\%; (3) \\textbf{hybrid reasoning underperforms} single modalities; (4) \\textbf{robustness is model-dependent} as Grok maintains 80-90\\% at 30\\% budget where OpenAI and DeepSeek collapse to 7-27\\%. These results suggest incomplete reasoning chains actively mislead models, with implications for deploying reasoning-specialized systems under resource constraints.",
    "title_zh": "断裂的链条：大语言模型中不完整推理的代价",
    "abstract_zh": "像OpenAI的5.1和DeepSeek-V3.2这类专注于推理的模型，会将大量推理计算资源分配给扩展的思维链（CoT）轨迹，但推理阶段产生的token成本极高。在token资源受限的情况下，不同推理模态——代码、自然语言、混合模式或无推理——的表现如何？我们提出一个框架，强制模型仅通过代码、注释、两者结合或完全不使用推理方式进行思考，随后系统性地将token预算缩减至最优值的10%、30%、50%和70%。我们在四个前沿模型（GPT-5.1、Gemini 3 Flash、DeepSeek-V3.2、Grok 4.1）上，针对数学基准测试（AIME、GSM8K、HMMT）进行了评估。研究结果表明：（1）**推理链被截断反而有害**：DeepSeek-V3.2在无推理时达到53%准确率，但在token预算降至50%时，截断的CoT推理准确率骤降至17%；（2）**代码推理具有良好的退化鲁棒性**：Gemini的注释推理在预算降低时迅速衰减至0%，而代码推理仍能维持43%-47%的准确率；（3）**混合推理表现不如单一模态**；（4）**鲁棒性高度依赖模型本身**：Grok在30%预算下仍保持80%-90%的性能，而OpenAI和DeepSeek则分别跌至7%-27%。这些结果表明，在资源受限条件下，不完整的推理链会主动误导模型，对推理专用系统的实际部署具有重要启示。"
  },
  {
    "date": "2026-2-16",
    "title": "HLS-Based Algorithm-Hardware Co-Design of MIMO-OFDM Receiver for Tactical Jamming Suppression",
    "authors": "J. Andrew Zhang, Jie Lei, Hao Zhang, Anh Tuyen Le, Kin-Ping Hui, Damien Phillips, Asanka Kekirigoda, Alan Allwright",
    "publish": "IEEE Transactions on Circuits and Systems I: Regular Papers",
    "url": "https://doi.org/10.1109/tcsi.2026.3660017",
    "source": "IEEE",
    "abstract": "This paper presents an HLS-based algorithm-hardware co-design methodology and complete FPGA hardware accelerator for multi-user massive MIMO-OFDM receivers operating in contested tactical environments with jamming suppression capabilities. We develop a systematic bi-directional co-design methodology using high-level synthesis (HLS) where algorithms provide functional verification constraints while hardware synthesis feedback drives algorithmic complexity reduction, enabling efficient transformation from signal processing algorithms to optimized circuit implementations on the Xilinx ZCU111 radio frequency system-on-chip (RFSoC) platform. The primary contributions include: 1) hardware architecture innovations featuring QR decomposition-based synchronization achieving 330 MHz post-route operation and optimized frequency-domain minimum mean square error (FD-MMSE) equalization with systematic loop restructuring for data dependency removal in substitution modules, reducing hardware resources by 56% lookup tables (LUTs), 58% flip-flops (FFs), and 67% digital signal processing (DSP) blocks while maintaining real-time throughput; 2) systematic HLS-based co-design framework enabling automated architecture exploration with hardware-oriented algorithm adaptations including silent-period frame structure and Cholesky-based decision-feedback equalization; 3) complete system integration validated through field trials demonstrating 8 dB jamming suppression improvement with reliable spatial division multiple access (SDMA) communications. The presented methodology provides insights applicable to broader signal processing systems with stringent real-time constraints.",
    "title_zh": "基于HLS的MIMO-OFDM接收机算法硬件协同设计用于战术干扰抑制",
    "abstract_zh": "本文提出了一种基于高层次综合（HLS）的算法-硬件协同设计方法，以及用于在受干扰战术环境中运行的多用户大规模MIMO-OFDM接收机的完整FPGA硬件加速器，具备抑制干扰的能力。我们采用一种系统化的双向协同设计方法，利用高层次综合（HLS）技术，使算法提供功能验证约束，同时硬件综合反馈驱动算法复杂度的降低，从而实现从信号处理算法到Xilinx ZCU111射频片上系统（RFSoC）平台优化电路实现的高效转换。主要贡献包括：1）硬件架构创新，采用基于QR分解的同步机制，实现后布线330 MHz的运行频率；同时对频域最小均方误差（FD-MMSE）均衡器进行优化，通过系统性的循环重构策略消除替换模块中的数据依赖性，使硬件资源消耗降低56%的查找表（LUTs）、58%的触发器（FFs）和67%的数字信号处理（DSP）模块，同时保持实时吞吐能力；2）建立了一套系统化的基于HLS的协同设计框架，支持自动化架构探索，并结合面向硬件的算法优化，包括静默周期帧结构设计以及基于Cholesky分解的决策反馈均衡技术；3）完成了完整的系统集成，并通过实地试验验证，实现了8 dB的干扰抑制性能提升，保障了可靠的空间分多址（SDMA）通信。所提出的协同设计方法为具有严格实时性要求的更广泛信号处理系统提供了有价值的参考与启示。"
  },
  {
    "date": "2026-2-16",
    "title": "Evaluating Security Checks Against Malicious Payloads with Forged Signatures",
    "authors": "Lalchandra Rampersaud, Behzad Ousat, Seyed Ali Akhavani, Javad Zandi, Selcuk Uluagac, Amin Kharraz",
    "publish": "2025 IEEE 16th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)",
    "url": "https://doi.org/10.1109/iemcon67450.2025.11381164",
    "source": "IEEE",
    "abstract": "Adversaries increasingly leverage diverse techniques to distribute malicious payloads across the web. One common, low-cost tactic is the hijacking of digital signatures and their attachment to malicious binaries, with the intent of deceiving both web browsers and operating systems. While code-signing certificates have traditionally served to verify the authenticity and integrity of software, adversaries now exploit these same certificates to evade detection mechanisms and facilitate the propagation of malicious code. This study seeks to empirically evaluate how modern web browsers respond to untrusted code by analyzing their reactions to signed malicious binaries. Our analysis shows that browsers’ responses to certificate abuses may differ significantly, and the operating system may respond ineffectively potentially leaving end-users vulnerable to straightforward adversarial tactics. We also show that it is possible to significantly reduce the attack surface against certificate abuse with the use of a browser extension.",
    "title_zh": "使用伪造签名的恶意载荷评估安全检查",
    "abstract_zh": "攻击者正越来越多地利用各种技术，在网络上分发恶意载荷。一种常见且成本低廉的手段是劫持数字签名，并将其附加到恶意二进制文件上，以欺骗网络浏览器和操作系统。尽管代码签名证书传统上用于验证软件的真实性和完整性，但攻击者如今正滥用这些证书，以规避检测机制并促进恶意代码的传播。本研究旨在通过分析现代网络浏览器对已签名恶意二进制文件的反应，实证评估其对不受信任代码的应对能力。我们的分析表明，不同浏览器对证书滥用的响应可能存在显著差异，而操作系统可能反应无效，从而导致终端用户容易受到简单攻击手段的威胁。此外，我们还证明，通过使用浏览器扩展，可以显著缩小针对证书滥用攻击的攻击面。"
  },
  {
    "date": "2026-2-16",
    "title": "JIT-MTL: Just-in-Time Defect Localization and Prediction with Multi-Task Learning",
    "authors": "Zongwen Shen, Wentao Zou, Xiang Chen, Jidong Ge, Chuanyi Li, Shuai Cao, Xuewei Zhang, LiGuo Huang, Bin Luo",
    "publish": "ACM Transactions on Software Engineering and Methodology",
    "url": "https://doi.org/10.1145/3797269",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "JIT-MTL：基于多任务学习的即时缺陷定位与预测",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-16",
    "title": "JANUS: A Difference-Oriented Analyzer for Financial Centralized Risks in Smart Contracts",
    "authors": "Wansen Wang, Pu Zhang, Renjie Ji, Wenchao Huang, Zhaoyi Meng, Jie Cui, Hong Zhong, Yan Xiong",
    "publish": "IEEE Transactions on Dependable and Secure Computing",
    "url": "https://doi.org/10.1109/tdsc.2026.3664823",
    "source": "IEEE",
    "abstract": "Some smart contracts violate decentralization principles by defining privileged accounts that manage other users' assets without permission, introducing centralized risks that have caused financial losses. Existing methods, however, face challenges in accurately detecting diverse centralized risks due to their dependence on predefined behavior patterns. In this paper, we propose JANUS, an automated analyzer for Solidity smart contracts that detects financial centralized risks independently of their specific behaviors. JANUS identifies differences between states reached by privileged and ordinary accounts, and analyzes whether these differences are finance-related. Focusing on the impact of risks rather than behaviors, JANUS achieves improved accuracy compared to existing tools and can uncover centralized risks with unknown patterns. To evaluate JANUS's performance, we compare it with other tools using a dataset of 540 contracts. Our evaluation demonstrates that JANUS outperforms representative tools in terms of detection accuracy for financial centralized risks. Additionally, we evaluate JANUS on a real-world dataset of 33,151 contracts, successfully identifying two types of risks that other tools fail to detect. We also prove that the state traversal method and variable summaries, which are used in JANUS to reduce the number of states to be compared, do not introduce false alarms or omissions in detection.",
    "title_zh": "JANUS：面向差异的智能合约金融集中风险分析器",
    "abstract_zh": "一些智能合约通过定义特权账户来管理其他用户的资产而违背了去中心化原则，这些账户在未经许可的情况下操控用户资产，引入了中心化风险，已导致重大财务损失。然而，现有方法在准确检测多样化的中心化风险方面面临挑战，因为它们依赖于预定义的行为模式。本文提出JANUS，一种用于Solidity智能合约的自动化分析工具，能够独立于具体行为模式检测金融中心化风险。JANUS通过识别特权账户与普通账户所达到状态之间的差异，并分析这些差异是否具有金融相关性，从而实现风险检测。与关注行为特征的现有方法不同，JANUS聚焦于风险的实际影响，因此在检测准确率上优于现有工具，并能发现具有未知模式的中心化风险。为评估JANUS的性能，我们使用包含540个合约的数据集将其与其他工具进行对比，结果表明，JANUS在检测金融中心化风险方面显著优于代表性工具。此外，我们在一个包含33,151个真实合约的数据集上对JANUS进行了评估，成功识别出两种其他工具未能检测到的风险类型。我们还证明，JANUS中用于减少需比较状态数量的状态遍历方法和变量摘要技术，不会引入误报或漏报。"
  },
  {
    "date": "2026-2-16",
    "title": "Cost-Effective Adversarial Attacks Against Code LLM with Model Attention",
    "authors": "Weifeng Sun, Naiqi Huang, Meng Yan, Li Huang, Zhongxin Liu, Xiao Liu, David Lo",
    "publish": "IEEE Transactions on Software Engineering",
    "url": "https://doi.org/10.1109/tse.2026.3663143",
    "source": "IEEE",
    "abstract": "Code LLMs (CLLMs) are vulnerable to adversarial attacks, where semantically identical code mutations mislead models into incorrect predictions. To address this, adversarial training has been proposed, retraining models with adversarial examples generated by attack methods. Among various attack approaches, black-box methods have attracted increasing attention due to their flexibility and applicability. However, existing black-box attack methods face two key challenges: 1) vast mutation spaces limit attack efficiency and effectiveness, and 2) resource-intensive model queries constrain scalability. These challenges hinder the practicality of black-box attacks, especially under resource constraints, prompting the critical question: <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Can we enhance the efficiency of existing attack methods without compromising their effectiveness?</i> To answer this, we conduct an empirical study using Explainable AI (XAI) techniques to investigate differences between adversarial and non-adversarial (failure) examples. After analyzing state-of-the-art attack methods against two CLLMs, we introduce the concept of <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">model attention deviation</i>, which quantifies differences in the model’s focus between unmutated (original) and mutated code. Our findings reveal that adversarial examples exhibit significant attention deviations, with the direction of deviation critically affecting attack success. Building on these insights, we propose ADVSEL, an efficient adversarial attack framework comprising two proxy components: the Attention Proxy Model (APM), which quickly estimates attention deviations to filter unpromising mutations, and the Deviation Direction Proxy Model (DDPM), which assesses whether attention shifts lead toward incorrect predictions. By integrating these proxy models with existing attack methods, A<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">DV</small>S<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">EL</small> effectively prioritizes promising mutations, significantly improving attack efficiency. Experimental evaluations across five CLLMs, four downstream tasks, and three attack methods demonstrate that ADVSEL maintains comparable attack success rates (a slight ASR reduction of 0.62%–0.70%) while significantly reducing model queries (by 34.98%–42.91%) and runtime (by 20.84%–21.45%). Under resource constraints, ADVSEL consistently outperforms baselines, highlighting its practical advantage in cost-effective adversarial evaluation.",
    "title_zh": "基于模型注意力的低成本对抗性攻击代码大模型",
    "abstract_zh": "代码大语言模型（CLLMs）容易受到对抗性攻击的影响，即语义相同的代码变异会误导模型产生错误预测。为应对这一问题，对抗训练被提出，通过使用攻击方法生成的对抗样本对模型进行重新训练。在各类攻击方法中，黑盒攻击因其灵活性和适用性而受到越来越多的关注。然而，现有的黑盒攻击方法面临两大关键挑战：1）庞大的变异空间限制了攻击的效率与效果；2）高资源消耗的模型查询制约了其可扩展性。这些挑战阻碍了黑盒攻击在实际应用中的可行性，尤其是在资源受限的情况下，由此引出一个核心问题：**我们能否在不损害攻击效果的前提下，提升现有攻击方法的效率？**\n\n为回答这一问题，我们采用可解释人工智能（XAI）技术开展了一项实证研究，深入分析对抗性样本与非对抗性（失败）样本之间的差异。通过对两种先进攻击方法在两类CLLM上的表现进行分析，我们提出了“**模型注意力偏差**”（model attention deviation）的概念，用于量化模型在原始代码与变异代码之间的关注点差异。研究发现，对抗性样本表现出显著的注意力偏差，且偏差的方向对攻击成功率具有决定性影响。\n\n基于上述发现，我们提出了ADVSEL——一种高效的对抗攻击框架，包含两个代理组件：**注意力代理模型**（Attention Proxy Model, APM），用于快速估算注意力偏差，以过滤掉无潜力的变异；以及**偏差方向代理模型**（Deviation Direction Proxy Model, DDPM），用于判断注意力偏移是否倾向于导致错误预测。通过将这两个代理模型与现有攻击方法相结合，ADVSEL能够有效筛选出有潜力的变异，显著提升攻击效率。\n\n在五个CLLM、四个下游任务及三种攻击方法上的实验评估表明，ADVSEL在保持相近攻击成功率（攻击成功率ASR仅下降0.62%–0.70%）的同时，大幅减少了模型查询次数（降低34.98%–42.91%）和运行时间（减少20.84%–21.45%）。在资源受限条件下，ADVSEL始终优于基线方法，充分展现了其在低成本、高效对抗评估中的实际优势。"
  },
  {
    "date": "2026-2-16",
    "title": "A Coq-based Interactive Verification Tool for Analog Circuits",
    "authors": "Jingwen Yang, Zihang Zhang, Hao Deng, Kangqi Zhou, Gang Chen",
    "publish": "2025 16th International Conference on Software Engineering and Service Science (ICSESS)",
    "url": "https://doi.org/10.1109/icsess67729.2025.11380695",
    "source": "IEEE",
    "abstract": "Printed circuit board design relies on EDA (Electronic Design Automation) tools, and ensuring the correctness of analog circuit design is a crucial step in the design process. This article introduces an interactive verification tool for analog circuits based on the Coq theorem prover, and develops a graphical user interface that combines formal verification. The interface enables users to draw analog circuit diagrams and automatically convert them into Coq description code, significantly enhancing the efficiency of the verification process. By using the tool, we draw a series of typical linear analog circuit diagrams and generate their Coq descriptions. Furthermore, we use theorem provers to verify that the physical quantities of the circuit design meet the expected standards. The experimental results indicate that formal verification can be effectively applied to analog circuit design, providing new research directions and practical methods for software engineering.",
    "title_zh": "基于Coq的模拟电路交互式验证工具",
    "abstract_zh": "印刷电路板设计依赖于电子设计自动化（EDA）工具，而确保模拟电路设计的正确性是设计过程中的关键步骤。本文介绍了一种基于Coq定理证明器的模拟电路交互式验证工具，并开发了一个结合形式化验证的图形用户界面。该界面使用户能够绘制模拟电路图，并自动将其转换为Coq描述代码，显著提升了验证过程的效率。通过该工具，我们绘制了一系列典型的线性模拟电路图，并生成了相应的Coq描述。此外，我们利用定理证明器验证了电路设计中物理量是否满足预期标准。实验结果表明，形式化验证可有效应用于模拟电路设计，为软件工程领域提供了新的研究方向和实用方法。"
  },
  {
    "date": "2026-2-16",
    "title": "MAQ-Retrieval: Multi-Aspect Queries Retrieval for Large Language Models",
    "authors": "Zixuan Xu, Gaoyang Pang, Xinyu Chen, Ming Ding, Branka Vucetic, Yonghui Li, Zihuai Li",
    "publish": "IEEE Transactions on Artificial Intelligence",
    "url": "https://doi.org/10.1109/tai.2026.3665176",
    "source": "IEEE",
    "abstract": "Retrieval-Augmented Generation (RAG) typically relies on single-query retrieval. Various query optimization techniques have been proposed to enhance retrieval by decomposing the single query into multiple queries focusing on different aspects. This query optimization is to supplement the original query to increase the retrieval confidence from diverse aspects. Existing practices individually retrieve relevant texts based on the generated multi-aspect queries, aggregate these texts, and apply reranking methods to select the Top-<inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$K$</tex-math></inline-formula> most relevant texts. Such existing individual retrieval and reranking mechanisms often overlook the connections between queries. Consequently, these methods fail to adequately capture the nuances introduced by distinct aspects in multiple queries, and may amplify retrievalinduced hallucinations when semantically fragmented evidence is presented to large models. To bridge this gap, we introduce a novel Multi-Aspect Queries Retrieval (MAQ-Retrieval) method. It follows query optimization for multi-aspect queries, integrates a query-weighting mechanism, and leverages the concept of convex hull to perform joint retrieval of multi-aspect queries. In particular, the convex region we constructed can include the set of candidate texts that may be overlooked in traditional approaches, ensuring comprehensive coverage of relevant texts while suppressing inconsistent or noisy fragments that may contribute to model hallucinations. Extensive experiments on both multiplechoice and summarization tasks in either English or Chinese demonstrate that MAQ-Retrieval consistently outperforms four baselines, achieving up to an increased accuracy of 15.2% and the best F1 and ROUGE-Lsum scores across all evaluated datasets, confirming its advantages in RAG with multiple queries, highlighting its ability to enhance retrieval accuracy and mitigate hallucination propagation in large models.",
    "title_zh": "MAQ-检索：面向大语言模型的多维度查询检索",
    "abstract_zh": "检索增强生成（RAG）通常依赖于单查询检索。为提升检索效果，已有多种查询优化技术被提出，通过将单一查询分解为多个关注不同方面的多角度查询。这种查询优化旨在补充原始查询，从多个维度增强检索的置信度。现有方法通常基于生成的多方面查询分别检索相关文本，再对检索结果进行聚合，并采用重排序方法选取最相关的Top-K文本。然而，这些独立检索与重排序机制往往忽视了各查询之间的内在联系。因此，这些方法难以充分捕捉多查询中不同方面带来的细微差异，当语义碎片化的证据被输入大模型时，还可能加剧检索引发的幻觉问题。\n\n为弥补这一不足，本文提出一种新颖的多方面查询检索（Multi-Aspect Queries Retrieval, MAQ-Retrieval）方法。该方法在多方面查询优化的基础上，引入查询加权机制，并利用凸包（convex hull）概念实现多方面查询的联合检索。特别地，我们构建的凸区域能够包含传统方法可能遗漏的候选文本，从而在确保相关文本全面覆盖的同时，有效抑制不一致或噪声片段的引入，降低模型产生幻觉的风险。\n\n在中英文环境下的多项选择与摘要生成任务上进行的大量实验表明，MAQ-Retrieval在所有评估数据集上均显著优于四种基线方法，准确率最高提升达15.2%，并取得了最佳的F1和ROUGE-Lsum得分，充分验证了其在多查询RAG场景中的优势，凸显了其在提升检索准确性与抑制大模型幻觉传播方面的卓越能力。"
  },
  {
    "date": "2026-2-16",
    "title": "From NOP to ADD and Beyond: A Novel Fault-Model Comprising Variable-Length Instruction Sets",
    "authors": "Xhani Marvin Sas, Thomas Martin Johannes Lehrach, Jean-Pierre Seifert",
    "publish": "2025 Workshop on Fault Detection and Tolerance in Cryptography (FDTC)",
    "url": "https://doi.org/10.1109/fdtc68360.2025.00013",
    "source": "IEEE",
    "abstract": "Fault Injection Attacks (FIAs) pose significant security threats to embedded devices, compromising the security of critical systems. Although the implications of Fault Injection (FI) are well understood for embedded platforms exhibiting Reduced Instruction Set Computer (RISC) architectures, Complex Instruction Set Computer (CISC) platforms have received much less attention in security research. Modern x86 processors employ variable-length instructions spanning 1 to 15 bytes, creating unique vulnerability patterns that remain largely unexplored in existing FI research.We present the first systematic study of Electro-Magnetic Fault Injection (EMFI) attacks against variable-length Instruction Set Architectures (ISAs), highlighting misalignment effects. Our research introduces a novel fault model that demonstrates how strategically induced bit flips in instruction opcodes cause decoder misalignment, ultimately leading to the execution of completely different code sequences. We provide proof-of-concept evidence on Intel N100 hardware, showing how EMFI can transform a NOP instruction sequence into an equivalent-length ADD sequence, demonstrating novel misalignment vulnerabilities specific to variable-length ISAs.",
    "title_zh": "从NOP到ADD及更远：一种包含可变长度指令集的新故障模型",
    "abstract_zh": "故障注入攻击（Fault Injection Attacks, FIAs）对嵌入式设备构成了重大安全威胁，危及关键系统的安全性。尽管针对采用精简指令集计算机（RISC）架构的嵌入式平台，故障注入（FI）的影响已得到充分理解，但复杂指令集计算机（CISC）平台在安全研究中却鲜受关注。现代x86处理器采用长度可变的指令，指令长度为1至15字节，这种特性形成了独特的漏洞模式，而这些模式在现有故障注入研究中尚未被充分探索。本文首次系统性地研究了针对可变长度指令集架构（ISAs）的电磁故障注入（EMFI）攻击，重点揭示了指令对齐错误的影响。我们的研究提出了一种新颖的故障模型，展示了如何通过在指令操作码中战略性地引发比特翻转，导致指令解码器发生错位，最终引发完全不同的代码序列执行。我们在Intel N100硬件平台上提供了概念验证实验，证明了EMFI可将一段NOP指令序列转换为等长的ADD指令序列，从而揭示了可变长度ISA特有的新型对齐错误漏洞。"
  },
  {
    "date": "2026-2-16",
    "title": "Fault Detection in the Control- and Data-Path of Neural Networks",
    "authors": "Matthias Probst, Manuel Brosch, Augustin Ewald, Michael Gruber, Georg Sigl",
    "publish": "2025 Workshop on Fault Detection and Tolerance in Cryptography (FDTC)",
    "url": "https://doi.org/10.1109/fdtc68360.2025.00010",
    "source": "IEEE",
    "abstract": "Machine learning and neural networks experience growing usage in resource-constrained devices. However, moving neural networks to small devices also brings new requirements regarding the reliability and security of the networks and their hardware. In many areas, such as autonomous driving, the device must detect possible errors during execution to ensure safe functionality. Moreover, an adversary can gain physical access to the device, opening the door for hardware attacks like fault injections that target misclassification or parameter retrieval. This work proposes a fault detection mechanism for software implementations of neural networks running on a microcontroller to increase the reliability and security of the neural network. Our technique uses AN-codes, a type of error-detecting code, to detect errors in calculations within the neural network without any implications on the accuracy of protected networks. In addition, signature checking ensures the integrity of the control flow. Simulations and real-world testing show that our mechanism successfully detects faults in all possible locations in the neural network’s program code. Despite the robustness of our fault detection mechanism, it has an overhead in code size of only about 10%, independent of the implemented network. The memory usage increases by at most 232 bytes independently of the neural network size, ensuring that the mechanism is not overly burdensome for the memory.",
    "title_zh": "神经网络控制路径与数据路径中的故障检测",
    "abstract_zh": "机器学习与神经网络在资源受限设备中的应用日益广泛。然而，将神经网络部署到小型设备上也带来了对网络及其硬件可靠性和安全性的新要求。在许多领域，例如自动驾驶，设备必须能够在执行过程中检测潜在错误，以确保功能安全。此外，攻击者可能获得对设备的物理访问权限，从而实施硬件攻击，如故障注入攻击，以引发误分类或窃取参数。本文提出了一种针对微控制器上运行的神经网络软件实现的故障检测机制，旨在提升神经网络的可靠性和安全性。我们的技术采用AN码（一种错误检测码）来检测神经网络计算过程中的错误，且不会影响受保护网络的准确性。此外，通过签名检查确保控制流的完整性。仿真与实际测试结果表明，该机制能够成功检测神经网络程序代码中所有可能位置的故障。尽管该故障检测机制具有较强的鲁棒性，其代码大小开销仅为约10%，且与所实现的网络无关；内存使用量最多增加232字节，同样不随神经网络规模变化，从而确保该机制对内存的负担不会过重。"
  },
  {
    "date": "2026-2-16",
    "title": "Bridging the AI-Human Gap in Programming Education: A Case Study on Structured Prompting and Content-Constrained Generation",
    "authors": "Tee Hean Tan, Too Khong Tan",
    "publish": "2025 5th International Conference on Educational Technology (ICET)",
    "url": "https://doi.org/10.1109/icet67421.2025.11380421",
    "source": "IEEE",
    "abstract": "Generative AI has emerged as a transformative tool in education, yet its effectiveness in programming instruction remains limited by unreliable outputs and prompt dependency. MyOOTutor addresses these challenges through a specialized AI tutoring system that combines (1) content-constrained generation (using validated course materials) and (2) structured query guidance (transforming novice prompts into expert-level queries). Implemented in a Year 1 Object-Oriented Programming course, the system demonstrated significant impact: 93% of students reported improved assignment grades, 97% gained programming confidence, and 95% achieved problem-solving independence. While excelling in foundational OOP concepts (81% understanding), limitations persisted in advanced topic support. These results establish a framework for AI tutoring systems that balances generative AI’s flexibility with pedagogical reliability, offering a replicable model for technical education.",
    "title_zh": "编程教育中人工智能与人类之间的鸿沟：结构化提示与内容约束生成的案例研究",
    "abstract_zh": "生成式人工智能已成为教育领域的一项变革性工具，但其在编程教学中的有效性仍受限于输出不可靠和对提示词高度依赖的问题。MyOOTutor通过一种专门的AI辅导系统解决了这些挑战，该系统结合了（1）内容受限生成（利用经过验证的课程材料）和（2）结构化查询引导（将初学者的提问转化为专家级问题）。该系统在一年级面向对象编程课程中实施后，取得了显著成效：93%的学生表示作业成绩有所提升，97%的学生增强了编程信心，95%的学生实现了独立解决问题。尽管在基础面向对象编程概念（81%的理解率）方面表现优异，但在高级主题支持方面仍存在局限。这些结果为AI辅导系统建立了一个框架，平衡了生成式人工智能的灵活性与教学可靠性，为技术教育提供了一个可复制的范例。"
  },
  {
    "date": "2026-2-16",
    "title": "Understanding the Amount of Changes Required for Merge Request Acceptance: An Empirical Study",
    "authors": "Samah Kansab, Mohammed Sayagh, Francis Bordeleau, Ali Tizghadam",
    "publish": "2025 16th International Conference on Software Engineering and Service Science (ICSESS)",
    "url": "https://doi.org/10.1109/icsess67729.2025.11380541",
    "source": "IEEE",
    "abstract": "Code review (CR) is essential to software development, helping ensure that new code is properly integrated. However, the CR process often involves significant effort, including code adjustments, responses to reviewers, and continued implementation. While past studies have examined CR delays and iteration counts, few have investigated the effort based on the volume of code changes required—especially in the context of GitLab’s Merge Request (MR) mechanism, which remains underexplored. In this paper, we define and measure CR effort as the amount of code modified after submission, using a dataset of over 23.6k MRs from four GitLab projects. We find that up to 71% of MRs require adjustments post-submission, and 28% of these involve changes to over 200 lines of code. Surprisingly, this effort is not correlated with review time or the number of participants. To better understand and predict CR effort, we train an interpretable machine learning model using metrics across multiple dimensions: text features, code complexity, developer experience, review history, and branching. Our model achieves strong performance (AUC 0.84–0.88) and reveals that complexity, experience, and text features are key predictors. Historical project characteristics also influence current review effort. Our findings highlight the feasibility of using ML to explain and anticipate the effort needed to integrate code changes during review.",
    "title_zh": "理解合并请求接受所需的变更量：一项实证研究",
    "abstract_zh": "代码审查（Code Review, CR）是软件开发中不可或缺的环节，有助于确保新代码的正确集成。然而，CR过程通常需要投入大量精力，包括代码修改、回应评审意见以及持续的开发工作。尽管以往研究已探讨过CR延迟和迭代次数等问题，但很少有研究关注基于代码变更量的CR工作量，尤其是在GitLab的合并请求（Merge Request, MR）机制背景下，这一领域仍鲜有深入探索。本文定义并度量了CR工作量为提交后需修改的代码量，基于来自四个GitLab项目的超过23.6k个MR的数据集进行分析。研究发现，高达71%的MR在提交后需要调整，其中28%的MR修改了超过200行代码。令人意外的是，这种工作量与评审时长或参与人数并无显著相关性。为更深入理解并预测CR工作量，我们构建了一个可解释的机器学习模型，综合了多个维度的指标：文本特征、代码复杂度、开发者经验、评审历史以及分支策略。该模型表现出优异的预测性能（AUC值为0.84–0.88），并揭示代码复杂度、开发者经验以及文本特征是关键预测因子。此外，历史项目特征也显著影响当前的评审工作量。研究结果表明，利用机器学习方法解释和预测代码集成过程中的工作量具有可行性，为优化CR流程提供了有力支持。"
  },
  {
    "date": "2026-2-16",
    "title": "From Data Mirror to Smart Copilot: A Survey on NextG Semantic Communication for Propelling Digital Twin World into Cognitive Stage",
    "authors": "Fang Zhu, Jiayuan Chen, Junjie Wen, Yuye Yang, Changyan Yi, Yun Tie, Peng Zhang, Jun Cai, Dusit Niyato, Mohsen Guizani",
    "publish": "IEEE Communications Surveys &amp; Tutorials",
    "url": "https://doi.org/10.1109/comst.2026.3665395",
    "source": "IEEE",
    "abstract": "The revolution of information technologies is blur-ring the boundary between physical and virtual worlds, with digital twin (DT) at the forefront of this transformation. Mean-while, DT is evolving from offering simple data mirrors to smart copilots, capable of understanding user’s intents and proactively providing profound insights. This ushers in the pivotal cognitive stage of the DT, where humans or embodied artificial intelligence agents (EAIs) can obtain cognitive perceptions within the DT world. Among various issues, in the cognitive stage, establishing strong interactions between the physical and DT worlds is critical. This paper thus explores the Next-Generation Semantic Communication (NextG-SemCom), well-suited for this issue, to fully enable the DT world with human-like cognitive capabilities. NextG-SemCom is envisioned as a cognitive-native paradigm that leverages Large AI Models (LAMs) as its core engine to perform intent understanding, contextual planning, and intent-oriented generative extraction. NextG-SemCom establishes a closed cognitive loop that shifts communication from data-driven to cognitive-driven, thereby not only reducing the traffic overhead, but also achieving cognitive comprehension of the transmitted information. This paper provides the first survey of the NextG-SemCom driven DT world, focusing on the advancement, trend and vision. We start by tracing the evolution of the DT from the initial virtual mapping stage to the current cognitive stage, and detail the distinguishing features of NextG-SemCom. We then present a holistic framework of cognitive interactions in the DT world, analyzing its core components, including the NextG-SemCom codec and network management, along with its design requirements and challenges. Furthermore, we discuss potential applications across a spectrum of human-human, human-EAI, and EAI-EAI interactive scenarios. Finally, we outline future research directions to provide a roadmap and inspire further studies in this promising field.",
    "title_zh": "从数据镜像到智能副驾驶：推动数字孪生世界迈向认知阶段的下一代语义通信综述",
    "abstract_zh": "信息技术的革命正在模糊物理世界与虚拟世界之间的界限，而数字孪生（Digital Twin, DT）正处于这一变革的前沿。与此同时，数字孪生正从最初提供简单数据镜像的功能，演进为具备理解用户意图并主动提供深刻洞察的智能副驾驶。这标志着数字孪生迈入了关键的认知阶段，在此阶段，人类或具身人工智能代理（Embodied Artificial Intelligence Agents, EAIs）能够在数字孪生世界中获得认知感知。在诸多挑战中，认知阶段建立物理世界与数字孪生世界之间强交互关系尤为关键。本文因此探讨了下一代语义通信（Next-Generation Semantic Communication, NextG-SemCom），该技术非常适合解决上述问题，旨在全面赋予数字孪生世界类人认知能力。NextG-SemCom被构想为一种原生认知范式，以大型人工智能模型（Large AI Models, LAMs）为核心引擎，实现意图理解、上下文规划以及面向意图的生成式信息提取。NextG-SemCom构建了一个闭环认知系统，推动通信从以数据为中心转向以认知为中心，不仅显著降低通信流量开销，更实现了对传输信息的认知性理解。本文首次对由NextG-SemCom驱动的数字孪生世界进行了全面综述，聚焦其发展进展、未来趋势与愿景。我们首先追溯数字孪生从初始的虚拟映射阶段到当前认知阶段的演进历程，并详述NextG-SemCom的显著特征。随后，提出数字孪生世界中认知交互的完整框架，深入分析其核心组件，包括NextG-SemCom编解码器与网络管理机制，以及其设计需求与面临的挑战。此外，我们探讨了该技术在人与人、人与EAI、EAI与EAI等多种交互场景中的潜在应用。最后，本文展望了未来的研究方向，为该充满前景的领域提供发展路线图，并激发更深入的研究探索。"
  },
  {
    "date": "2026-2-16",
    "title": "BugBlaze: An Explainable Framework for Detecting Latent Defect Ignitions in Software Systems",
    "authors": "Hema Yalamancheli, Nazia Shaik, Nurmyrat Amanmadov, Tarlan Abdullayev, Balajee Asish Brahmandam",
    "publish": "2025 IEEE 16th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)",
    "url": "https://doi.org/10.1109/iemcon67450.2025.11381085",
    "source": "IEEE",
    "abstract": "Contemporary software systems frequently harbor latent defects such as dormant logic errors, untested edge cases, and hidden security flaws that slip past static analysis tools and conventional test suites, undermining both reliability and security. To address this, we introduce BugBlaze, the first comprehensive framework for real time ignition detection of latent defects powered by explainable AI. At the center of BugBlaze is the BlazeCore engine, which integrates a large language model with an attention enhanced graph neural network to jointly represent source code and runtime logs. The framework incorporates several key modules: a TriggerTrace Predictor that anticipates defect-triggering inputs with SHAP based explanations, a CollabGuard Integrator that enriches pull requests with risk scores and natural language justifications, a PatchCraft Assistant that suggests preventive patches supported by XAI reports, and a RiskHeat Visualizer that highlights vulnerable code regions directly in the editor. Complementing these is a ContextMemory Vault that adapts risk profiles based on historical data, and an XAI-Trace Explainer that records LIME-based decision traces for transparency. Deployed through an IgnitionMesh across CI/CD pipelines, VSCode, and Git workflows, BugBlaze cut latent defect incidents by 87% and reduced mean time to detection by 65% across seven large-scale projects totaling 1.2M LOC. We also discuss scalability considerations, integration trade-offs, and future extensions toward adaptive learning in multilingual environments.",
    "title_zh": "BugBlaze：一种用于检测软件系统中潜在缺陷触发的可解释框架",
    "abstract_zh": "当代软件系统中常常潜藏着诸如休眠逻辑错误、未测试的边界情况以及隐蔽的安全漏洞等潜在缺陷，这些缺陷往往能够绕过静态分析工具和传统测试套件，从而严重影响系统的可靠性与安全性。为应对这一挑战，我们提出了 BugBlaze——首个基于可解释人工智能（XAI）的实时潜在缺陷检测综合框架。BugBlaze 的核心是 BlazeCore 引擎，该引擎融合了大型语言模型与增强注意力机制的图神经网络，能够联合建模源代码与运行时日志。该框架包含多个关键模块：基于 SHAP 的触发路径预测器（TriggerTrace Predictor），可提前预测引发缺陷的输入并提供可解释性说明；协同防护集成器（CollabGuard Integrator），可为代码合并请求（pull requests）注入风险评分与自然语言解释；补丁生成助手（PatchCraft Assistant），能够基于 XAI 报告提出预防性修复建议；以及风险热力可视化工具（RiskHeat Visualizer），可直接在编辑器中高亮显示高风险代码区域。此外，框架还配备了上下文记忆库（ContextMemory Vault），可根据历史数据动态调整风险画像；以及 XAI-Trace 解释器，用于记录基于 LIME 的决策追踪路径，确保系统透明可追溯。BugBlaze 通过在 CI/CD 流水线、VSCode 编辑器及 Git 工作流中部署的“点火网格”（IgnitionMesh）实现集成，在七个大型项目（总计 120 万行代码）中，使潜在缺陷事件减少了 87%，平均检测时间缩短了 65%。我们还探讨了系统的可扩展性、集成权衡，以及未来在多语言环境下的自适应学习扩展方向。"
  },
  {
    "date": "2026-2-16",
    "title": "Generative AI and Knowledge Graph Empowered Digital-Intelligent Collaborative Teaching System",
    "authors": "Xiaodong Liu, Xi Xiong, Baolin Lai, Jinyi Liu, Huilin Zhou, Yuhao Wang",
    "publish": "2025 5th International Conference on Educational Technology (ICET)",
    "url": "https://doi.org/10.1109/icet67421.2025.11380716",
    "source": "IEEE",
    "abstract": "The rapid development of artificial intelligence (AI) and digital transformation is driving higher education to shift from mass education to personalized education. However, current digital and intelligent technologies are primarily applied to teaching without fully exploring their potential. Thus, based on generative AI and knowledge graphs, a digital-intelligent collaborative teaching system is proposed to construct a novel intelligent teaching environment that supports active learning and collaborative teaching. The system focuses on the cultivation of talents in electronic information fields. Specifically, it leverages large models to develop a three-dimensional knowledge graph for professional courses, enabling the recommendation of personalized learning paths for students. Meanwhile, an intelligent formula derivation engine is designed to facilitate human-machine collaborative problem setting and solving, while establishing connections between knowledge and application based on the given problems. Moreover, a wireless communication agent incorporating teacher knowledge base is constructed to provide students with professional companion learning tools. The proposed system implemented over one semester in three classes with 144 students significantly enhances teaching quality and learning effectiveness, earning positive recognition from students. This provides a low-cost, high-efficiency digital-intelligent education model for new engineering education.",
    "title_zh": "生成式人工智能与知识图谱赋能的数字化智能协同教学系统",
    "abstract_zh": "人工智能（AI）的快速发展与数字化转型正推动高等教育从大众化教育向个性化教育转变。然而，当前的数字化与智能化技术主要应用于教学环节，尚未充分挖掘其潜力。为此，本文基于生成式AI与知识图谱，提出一种数字智能协同教学系统，旨在构建支持主动学习与协作教学的新型智能教学环境，重点服务于电子信息领域人才的培养。具体而言，系统利用大模型构建专业课程的三维知识图谱，实现对学生个性化学习路径的智能推荐；设计智能公式推导引擎，促进人机协同的问题设置与求解，并基于所给问题建立知识与应用之间的关联；同时，构建融合教师知识库的无线通信代理，为学生提供专业的陪伴式学习工具。该系统在三个班级、144名学生中实施一个学期，显著提升了教学质量和学习效果，获得学生广泛好评。该研究为新工科教育提供了一种低成本、高效率的数字智能教育新模式。"
  },
  {
    "date": "2026-2-16",
    "title": "A Survey and Prospects of Source Code Processing Techniques Based on Large Language Models",
    "authors": "Lei Wang, Zhuoying Yang",
    "publish": "2025 16th International Conference on Software Engineering and Service Science (ICSESS)",
    "url": "https://doi.org/10.1109/icsess67729.2025.11380277",
    "source": "IEEE",
    "abstract": "Source code processing is a core research domain in software engineering. In recent years, the emergence of large language models (LLMs) — such as the BERT series, GPT series, LLaMA series, DeepSeek series, T5, and their variants tailored for source code—has introduced novel technical approaches to this field. Numerous scholars, both domestic and international, have devoted significant efforts to the study of LLM-based source code processing techniques, resulting in a wealth of fruitful research outcomes. To further advance the theoretical and practical development of this domain, this paper conducts a comprehensive review and presents future prospects. Centered on two primary methodological categories—prompt-based source code processing and fine-tuned task-specific models—the study systematically organizes and summarizes the current state of research and recent achievements in LLM-based source code processing. On this basis, it further identifies the key challenges and pressing issues in the field. Finally, it outlines promising research directions and potential solutions. This work offers a thorough and systematic overview of the development, latest progress, and future trends of source code processing technologies powered by LLMs, providing valuable references and guidance for future research endeavors.",
    "title_zh": "基于大语言模型的源代码处理技术综述与展望",
    "abstract_zh": "源代码处理是软件工程领域的一个核心研究方向。近年来，大型语言模型（LLMs）——如BERT系列、GPT系列、LLaMA系列、DeepSeek系列、T5及其针对源代码优化的变体——的出现，为该领域带来了全新的技术路径。国内外众多学者投入大量精力研究基于大语言模型的源代码处理技术，取得了丰硕的研究成果。为进一步推动该领域的理论与实践发展，本文开展了一次全面的综述，并展望了未来发展方向。文章围绕两大主要方法论——基于提示的源代码处理与微调的特定任务模型——系统梳理并总结了当前基于大语言模型的源代码处理研究现状与最新进展。在此基础上，进一步识别出该领域面临的关键挑战与紧迫问题，并提出了具有前景的研究方向及潜在解决方案。本工作全面而系统地回顾了大语言模型驱动的源代码处理技术的发展历程、最新进展与未来趋势，为后续研究提供了宝贵的参考与指导。"
  },
  {
    "date": "2026-2-16",
    "title": "Automated C Vulnerability Detection via Structure-Enhanced Graph Transformer and RBM",
    "authors": "Yibo Zhou, Xiaolong Xu, Haolong Xiang, Xuyun Zhang, Siyu Wu",
    "publish": "Proceedings of the Nineteenth ACM International Conference on Web Search and Data Mining",
    "url": "https://doi.org/10.1145/3773966.3778005",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "基于结构增强图Transformer与RBM的自动化C语言漏洞检测",
    "abstract_zh": "None"
  }
]