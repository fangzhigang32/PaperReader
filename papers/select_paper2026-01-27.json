[
  {
    "date": "2026-01-27",
    "title": "OSIRIS: Bridging Analog Circuit Design and Machine Learning with Scalable Dataset Generation",
    "authors": "Giuseppe Chiari, Michele Piccoli, Davide Zoni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19439v1",
    "source": "arXiv",
    "abstract": "The automation of analog integrated circuit (IC) design remains a longstanding challenge, primarily due to the intricate interdependencies among physical layout, parasitic effects, and circuit-level performance. These interactions impose complex constraints that are difficult to accurately capture and optimize using conventional design methodologies. Although recent advances in machine learning (ML) have shown promise in automating specific stages of the analog design flow, the development of holistic, end-to-end frameworks that integrate these stages and iteratively refine layouts using post-layout, parasitic-aware performance feedback is still in its early stages. Furthermore, progress in this direction is hindered by the limited availability of open, high-quality datasets tailored to the analog domain, restricting both the benchmarking and the generalizability of ML-based techniques. To address these limitations, we present OSIRIS, a scalable dataset generation pipeline for analog IC design. OSIRIS systematically explores the design space of analog circuits while producing comprehensive performance metrics and metadata, thereby enabling ML-driven research in electronic design automation (EDA). In addition, we release a dataset consisting of 87,100 circuit variations generated with OSIRIS, accompanied by a reinforcement learning (RL)-based baseline method that exploits OSIRIS for analog design optimization.",
    "title_zh": "OSIRIS：通过可扩展的数据集生成，连接模拟电路设计与机器学习",
    "abstract_zh": "模拟集成电路（IC）设计的自动化长期以来一直是一个重大挑战，主要原因是物理版图、寄生效应与电路级性能之间存在复杂的相互依赖关系。这些相互作用带来了难以通过传统设计方法准确捕捉和优化的复杂约束。尽管机器学习（ML）领域的最新进展在自动化模拟设计流程的特定阶段方面展现出潜力，但能够整合各设计环节并利用后版图、考虑寄生效应的性能反馈进行迭代优化的端到端整体框架仍处于初步发展阶段。此外，这一方向的进步还受到面向模拟领域、公开可用且高质量数据集稀缺的制约，这限制了基于机器学习技术的基准测试能力及其泛化性能。为解决上述局限性，我们提出了OSIRIS——一个可扩展的模拟IC设计数据集生成管道。OSIRIS系统地探索模拟电路的设计空间，同时生成全面的性能指标和元数据，从而推动电子设计自动化（EDA）领域中以机器学习驱动的研究。此外，我们发布了由OSIRIS生成的包含87,100个电路变体的数据集，并配套提供一种基于强化学习（RL）的基线方法，该方法利用OSIRIS实现模拟电路的优化设计。"
  },
  {
    "date": "2026-01-27",
    "title": "RPO:Reinforcement Fine-Tuning with Partial Reasoning Optimization",
    "authors": "Hongzhu Yi, Xinming Wang, Zhenghao zhang, Tianyu Zong, Yuanxiang Wang, Jun Xie, Tao Yu, Haopeng Jin, Zhepeng Wang, Kaixin Xu, Feng Chen, Jiahuan Chen, Yujia Yang, Zhenyu Guan, Bingkang Shi, Jungang Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19404v1",
    "source": "arXiv",
    "abstract": "Within the domain of large language models, reinforcement fine-tuning algorithms necessitate the generation of a complete reasoning trajectory beginning from the input query, which incurs significant computational overhead during the rollout phase of training. To address this issue, we analyze the impact of different segments of the reasoning path on the correctness of the final result and, based on these insights, propose Reinforcement Fine-Tuning with Partial Reasoning Optimization (RPO), a plug-and-play reinforcement fine-tuning algorithm. Unlike traditional reinforcement fine-tuning algorithms that generate full reasoning paths, RPO trains the model by generating suffixes of the reasoning path using experience cache. During the rollout phase of training, RPO reduces token generation in this phase by approximately 95%, greatly lowering the theoretical time overhead. Compared with full-path reinforcement fine-tuning algorithms, RPO reduces the training time of the 1.5B model by 90% and the 7B model by 72%. At the same time, it can be integrated with typical algorithms such as GRPO and DAPO, enabling them to achieve training acceleration while maintaining performance comparable to the original algorithms. Our code is open-sourced at https://github.com/yhz5613813/RPO.",
    "title_zh": "RPO：基于部分推理优化的强化微调",
    "abstract_zh": "在大型语言模型领域，强化学习微调算法需要从输入查询开始生成完整的推理轨迹，这在训练的 rollout 阶段带来了巨大的计算开销。为解决这一问题，我们分析了推理路径不同阶段对最终结果正确性的影响，并基于这些发现，提出了一种即插即用的强化学习微调算法——部分推理优化强化微调（Reinforcement Fine-Tuning with Partial Reasoning Optimization, RPO）。与传统强化微调算法需生成完整推理路径不同，RPO 通过使用经验缓存来生成推理路径的后缀进行模型训练。在训练的 rollout 阶段，RPO 将 token 生成量减少了约 95%，显著降低了理论上的时间开销。相较于全路径强化微调算法，RPO 使 1.5B 模型的训练时间减少 90%，7B 模型的训练时间减少 72%。同时，RPO 可与 GRPO、DAPO 等典型算法无缝集成，在保持与原算法相当性能的前提下实现训练加速。我们的代码已开源，地址为：https://github.com/yhz5613813/RPO。"
  },
  {
    "date": "2026-01-27",
    "title": "High-quality data augmentation for code comment classification",
    "authors": "Thomas Borsani, Andrea Rosani, Giuseppe Di Fatta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19383v1",
    "source": "arXiv",
    "abstract": "Code comments serve a crucial role in software development for documenting functionality, clarifying design choices, and assisting with issue tracking. They capture developers' insights about the surrounding source code, serving as an essential resource for both human comprehension and automated analysis. Nevertheless, since comments are in natural language, they present challenges for machine-based code understanding. To address this, recent studies have applied natural language processing (NLP) and deep learning techniques to classify comments according to developers' intentions. However, existing datasets for this task suffer from size limitations and class imbalance, as they rely on manual annotations and may not accurately represent the distribution of comments in real-world codebases. To overcome this issue, we introduce new synthetic oversampling and augmentation techniques based on high-quality data generation to enhance the NLBSE'26 challenge datasets. Our Synthetic Quality Oversampling Technique and Augmentation Technique (Q-SYNTH) yield promising results, improving the base classifier by $2.56\\%$.",
    "title_zh": "高质量的代码注释分类数据增强",
    "abstract_zh": "代码注释在软件开发中起着至关重要的作用，用于记录功能、阐明设计决策并协助问题追踪。它们捕捉了开发者对周围源代码的见解，是人类理解与自动化分析不可或缺的资源。然而，由于注释采用自然语言表达，给基于机器的代码理解带来了挑战。为应对这一问题，近期研究已应用自然语言处理（NLP）和深度学习技术，根据开发者的意图对注释进行分类。但现有相关数据集存在规模有限和类别不平衡的问题，因为这些数据依赖人工标注，可能无法准确反映真实代码库中注释的实际分布。为解决这一难题，我们提出了一种基于高质量数据生成的新型合成过采样与增强技术，以提升NLBSE'26挑战赛数据集的质量。我们的合成质量过采样与增强技术（Q-SYNTH）取得了令人瞩目的成果，使基础分类器的性能提升了2.56%。"
  },
  {
    "date": "2026-01-27",
    "title": "Understanding Dominant Themes in Reviewing Agentic AI-authored Code",
    "authors": "Md. Asif Haider, Thomas Zimmermann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19287v1",
    "source": "arXiv",
    "abstract": "While prior work has examined the generation capabilities of Agentic AI systems, little is known about how reviewers respond to AI-authored code in practice. In this paper, we present a large-scale empirical study of code review dynamics in agent-generated PRs. Using a curated subset of the AIDev dataset, we analyze 19,450 inline review comments spanning 3,177 agent-authored PRs from real-world GitHub repositories. We first derive a taxonomy of 12 review comment themes using topic modeling combined with large language model (LLM)-assisted semantic clustering and consolidation. According to this taxonomy, we then investigate whether zero-shot prompts to LLM can reliably annotate review comments. Our evaluation against human annotations shows that open-source LLM achieves reasonably high exact match (78.63%), macro F1 score (0.78), and substantial agreement with human annotators at the review comment level. At the PR level, the LLM also correctly identifies the dominant review theme with 78% Top-1 accuracy and achieves an average Jaccard similarity of 0.76, indicating strong alignment with human judgments. Applying this annotation pipeline at scale, we find that apart from functional correctness and logical changes, reviews of agent-authored PRs predominantly focus on documentation gaps, refactoring needs, styling and formatting issues, with testing and security-related concerns. These findings suggest that while AI agents can accelerate code production, there remain gaps requiring targeted human review oversight.",
    "title_zh": "理解代理型人工智能生成代码中的主导主题",
    "abstract_zh": "尽管先前的研究已探讨了智能体AI系统在代码生成方面的能力，但关于评审人员在实际中如何回应由AI撰写的代码，目前仍知之甚少。本文通过一项大规模的实证研究，分析了由AI代理生成的代码提交（PR）中的评审动态。我们基于经过筛选的AIDev数据集子集，对来自真实世界GitHub仓库的3,177个由AI生成的PR所包含的19,450条内联评审评论进行了分析。首先，我们结合主题建模与大语言模型（LLM）辅助的语义聚类和整合方法，构建了一个包含12个评审评论主题的分类体系。根据该分类体系，我们进一步评估了零样本提示（zero-shot prompts）能否可靠地对评审评论进行标注。与人工标注结果对比显示，开源大语言模型在精确匹配率（78.63%）、宏平均F1分数（0.78）以及评论级别的标注一致性方面均表现良好，达到了较高水平。在PR层面，该模型以78%的Top-1准确率正确识别出主导评审主题，并实现了平均0.76的Jaccard相似度，表明其判断与人类评审意见高度一致。通过大规模应用该标注流程，我们发现，除了功能正确性和逻辑变更外，针对AI生成PR的评审主要集中在文档缺失、重构需求、风格与格式问题，以及测试和安全相关的问题上。这些发现表明，尽管AI代理能够显著提升代码产出效率，但仍存在需要针对性的人工审查监督的差距。"
  },
  {
    "date": "2026-01-27",
    "title": "UniPCB: A Unified Vision-Language Benchmark for Open-Ended PCB Quality Inspection",
    "authors": "Fuxiang Sun, Xi Jiang, Jiansheng Wu, Haigang Zhang, Feng Zheng, Jinfeng Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19222v1",
    "source": "arXiv",
    "abstract": "Multimodal Large Language Models (MLLMs) show promise for general industrial quality inspection, but fall short in complex scenarios, such as Printed Circuit Board (PCB) inspection. PCB inspection poses unique challenges due to densely packed components, complex wiring structures, and subtle defect patterns that require specialized domain expertise. However, a high-quality, unified vision-language benchmark for quantitatively evaluating MLLMs across PCB inspection tasks remains absent, stemming not only from limited data availability but also from fragmented datasets and inconsistent standardization. To fill this gap, we propose UniPCB, the first unified vision-language benchmark for open-ended PCB quality inspection. UniPCB is built via a systematic pipeline that curates and standardizes data from disparate sources across three annotated scenarios. Furthermore, we introduce PCB-GPT, an MLLM trained on a new instruction dataset generated by this pipeline, utilizing a novel progressive curriculum that mimics the learning process of human experts. Evaluations on the UniPCB benchmark show that while existing MLLMs falter on domain-specific tasks, PCB-GPT establishes a new baseline. Notably, it more than doubles the performance on fine-grained defect localization compared to the strongest competitors, with significant advantages in localization and analysis. We will release the instruction data, benchmark, and model to facilitate future research.",
    "title_zh": "UniPCB：面向开放式PCB质量检测的统一视觉-语言基准",
    "abstract_zh": "多模态大语言模型（MLLMs）在通用工业质量检测方面展现出巨大潜力，但在复杂场景中仍显不足，例如印刷电路板（PCB）检测。由于元器件密集排列、布线结构复杂以及缺陷模式细微，PCB检测对领域专业知识要求极高，带来了独特挑战。然而，目前尚缺乏高质量、统一的视觉-语言基准来定量评估MLLMs在PCB检测任务中的表现，这不仅源于数据资源有限，也由于数据集分散且标准不一。为填补这一空白，我们提出了UniPCB——首个面向开放式PCB质量检测的统一视觉-语言基准。UniPCB通过一个系统化流程构建，从三个标注场景中整合并标准化来自不同来源的数据。此外，我们推出了PCB-GPT，一种基于该流程生成的新指令数据集训练而成的MLLM，采用了一种新颖的渐进式课程学习策略，模拟人类专家的学习过程。在UniPCB基准上的评估表明，尽管现有MLLMs在特定领域任务上表现不佳，但PCB-GPT已确立新的性能基准。尤为突出的是，其在细粒度缺陷定位任务上的表现超过最强竞争对手逾一倍，且在定位与分析方面均具有显著优势。我们将公开发布指令数据、基准测试集及模型，以推动后续研究发展。"
  },
  {
    "date": "2026-01-27",
    "title": "Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach",
    "authors": "Weiran Guo, Bing Bo, Shaoxiang Wu, Jingsheng Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19122v1",
    "source": "arXiv",
    "abstract": "Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generation by models, and use this data to finetune the LLMs. However, these methods often lack targeted design and are constrained by fixed patterns and data distributions, which limits their effectiveness in enhancing the generalization and robustness of function call LLMs. To address this limitation, we propose a novel adversarial data augmentation method that employs reinforcement learning to systematically identify and target the weaknesses of function call LLMs. Our training framework introduces a query model trained with reinforcement learning (RL) to generate adversarial queries that are specifically designed to challenge function call (FC) models. This approach adopts a zero sum game formulation, where the query model and the FC model engage in iterative alternating training. Overall, our method advances the development of more robust FC models and provides a systematic way to identify and correct weaknesses in the ability of LLMs to interact with external tools.",
    "title_zh": "通过强化学习探索函数调用模型的弱点：一种对抗性数据增强方法",
    "abstract_zh": "函数调用能力已成为大型语言模型（LLMs）的关键要素，使其能够更有效地与外部工具和API进行交互。目前提升LLM函数调用能力的方法主要依赖于通过人工标注或由模型自动生成的数据，并利用这些数据对LLM进行微调。然而，这些方法往往缺乏针对性设计，受限于固定的模式和数据分布，难以有效提升函数调用LLM的泛化能力和鲁棒性。为解决这一局限，我们提出一种新颖的对抗性数据增强方法，采用强化学习系统性地识别并针对函数调用LLM的薄弱环节。我们的训练框架引入了一个通过强化学习（RL）训练的查询模型，专门生成旨在挑战函数调用（FC）模型的对抗性查询。该方法采用零和博弈的建模方式，使查询模型与FC模型在训练过程中进行迭代交替优化。总体而言，我们的方法推动了更鲁棒的FC模型的发展，并提供了一种系统化的方法，用于发现并修正LLM与外部工具交互能力中的缺陷。"
  },
  {
    "date": "2026-01-27",
    "title": "TinyTorch: Building Machine Learning Systems from First Principles",
    "authors": "Vijay Janapa Reddi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19107v1",
    "source": "arXiv",
    "abstract": "Machine learning systems engineering requires a deep understanding of framework internals. Yet most current education separates algorithms from systems. Students learn gradient descent without measuring memory usage, and attention mechanisms without profiling computational cost. This split leaves graduates unprepared to debug real production failures and widens the gap between machine learning research and reliable deployment. We present TinyTorch, a 20 module curriculum in which students implement the core components of PyTorch, including tensors, autograd, optimizers, and neural networks, entirely in pure Python. The curriculum is built around three pedagogical principles. Progressive disclosure gradually introduces complexity as students build confidence. Systems first integration embeds memory and performance awareness from the very beginning. Historical milestone validation guides students to recreate key breakthroughs, from the Perceptron in 1958 to modern Transformers, using only code they have written themselves. TinyTorch requires only a laptop with 4GB of RAM and no GPU, making machine learning systems education accessible worldwide. Its goal is to prepare the next generation of AI engineers, practitioners who understand not only what machine learning systems do, but why they work and how to make them scale. The curriculum is available as open source at mlsysbook.ai slash tinytorch.",
    "title_zh": "TinyTorch：从基本原理构建机器学习系统",
    "abstract_zh": "机器学习系统工程需要对框架内部机制有深入理解。然而，当前大多数教育体系将算法与系统分离开来：学生学习梯度下降时从不测量内存使用情况，研究注意力机制时也从未分析其计算开销。这种割裂使得毕业生难以应对真实生产环境中的故障排查，进一步拉大了机器学习研究与可靠部署之间的差距。我们提出 TinyTorch——一个由20个模块组成的课程体系，学生将用纯 Python 完全实现 PyTorch 的核心组件，包括张量、自动微分（autograd）、优化器和神经网络。该课程围绕三大教学原则构建：渐进式揭示（progressive disclosure）——随着学生信心的建立逐步引入复杂性；系统优先整合（systems first integration）——从一开始就融入对内存和性能的关注；历史里程碑验证（historical milestone validation）——引导学生通过自己编写的代码重现关键突破，从1958年的感知机到现代 Transformer 模型。TinyTorch 仅需一台配备 4GB 内存的笔记本电脑，无需 GPU，使全球范围内的机器学习系统教育变得触手可及。其目标是培养下一代 AI 工程师，造就那些不仅知道机器学习系统“做什么”，更理解“为什么能工作”以及“如何实现规模化”的实践者。该课程已开源，访问地址为：mlsysbook.ai/slash/tinytorch。"
  },
  {
    "date": "2026-01-27",
    "title": "Detecting and Correcting Hallucinations in LLM-Generated Code via Deterministic AST Analysis",
    "authors": "Dipin Khati, Daniel Rodriguez-Cardenas, Paul Pantzer, Denys Poshyvanyk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19106v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) for code generation boost productivity but frequently introduce Knowledge Conflicting Hallucinations (KCHs), subtle, semantic errors, such as non-existent API parameters, that evade linters and cause runtime failures. Existing mitigations like constrained decoding or non-deterministic LLM-in-the-loop repair are often unreliable for these errors. This paper investigates whether a deterministic, static-analysis framework can reliably detect \\textit{and} auto-correct KCHs. We propose a post-processing framework that parses generated code into an Abstract Syntax Tree (AST) and validates it against a dynamically-generated Knowledge Base (KB) built via library introspection. This non-executing approach uses deterministic rules to find and fix both API and identifier-level conflicts. On a manually-curated dataset of 200 Python snippets, our framework detected KCHs with 100\\% precision and 87.6\\% recall (0.934 F1-score), and successfully auto-corrected 77.0\\% of all identified hallucinations. Our findings demonstrate that this deterministic post-processing approach is a viable and reliable alternative to probabilistic repair, offering a clear path toward trustworthy code generation.",
    "title_zh": "通过确定性抽象语法树分析检测并纠正大语言模型生成代码中的幻觉",
    "abstract_zh": "用于代码生成的大语言模型（LLMs）虽然显著提升了开发效率，但常常引入知识冲突型幻觉（Knowledge Conflicting Hallucinations, KCHs），即一些细微且语义层面的错误，例如不存在的API参数，这类错误难以被代码检查工具（linter）发现，却会导致运行时失败。现有的缓解方法，如受限解码或非确定性的“LLM在环”修复，对于此类错误往往不可靠。本文探讨了是否可以通过一种确定性的静态分析框架，可靠地检测并自动修正KCHs。我们提出了一种后处理框架：将生成的代码解析为抽象语法树（AST），并基于通过库内省动态构建的知识库（KB）进行验证。该非执行性方法利用确定性规则，能够发现并修复API级别和标识符级别的冲突。在人工精心整理的200个Python代码片段数据集上，我们的框架实现了100%的精确率和87.6%的召回率（F1分数为0.934），并成功自动修正了所有识别出的幻觉中的77.0%。研究结果表明，这种确定性的后处理方法是概率性修复的一种可行且可靠的替代方案，为实现可信代码生成提供了清晰路径。"
  },
  {
    "date": "2026-01-27",
    "title": "Dynamic Cogeneration of Bug Reproduction Test in Agentic Program Repair",
    "authors": "Runxiang Cheng, Michele Tufano, José Cambronero, Renyao Wei, Sherry Shi, Grant Uy, Pat Rondon, Franjo Ivančić",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19066v1",
    "source": "arXiv",
    "abstract": "Bug Reproduction Tests (BRTs) have been used in many agentic Automated Program Repair (APR) systems, primarily for validating promising fixes and aiding fix generation. In practice, when developers submit a patch, they often implement the BRT alongside the fix. Our experience deploying agentic APR reveals that developers similarly desire a BRT within AI-generated patches to increase their confidence. However, canonical APR systems tend to generate BRTs and fixes separately, or focus on producing only the fix in the final patch. In this paper, we study agentic APR in the context of cogeneration, where the APR agent is instructed to generate both a fix and a BRT in the same patch. We evaluate the effectiveness of different cogeneration strategies on 120 human-reported bugs at Google and characterize different cogeneration strategies by their influence on APR agent behavior. We develop and evaluate patch selectors that account for test change information to select patches with plausible fixes (and plausible BRTs). Finally, we analyze the root causes of failed cogeneration trajectories. Importantly, we show that cogeneration allows the APR agent to generate BRTs for at least as many bugs as a dedicated BRT agent, without compromising the generation rate of plausible fixes, thereby reducing engineering effort in maintaining and coordinating separate generation pipelines for fix and BRT at scale.",
    "title_zh": "智能程序修复中的动态虫害复现测试生成",
    "abstract_zh": "缺陷复现测试（BRTs）已被广泛应用于多种基于智能体的自动化程序修复（APR）系统中，主要用于验证有前景的修复方案并辅助生成修复代码。在实际开发中，当开发者提交补丁时，通常会同时提供相应的BRT。我们在部署基于智能体的APR系统过程中发现，开发者同样希望AI生成的补丁中包含BRT，以增强对修复结果的信心。然而，传统的APR系统往往将BRT与修复代码分开生成，或仅在最终补丁中聚焦于生成修复代码本身。本文研究了在“共生成”（cogeneration）情境下的智能体式APR，即指令APR智能体在同一补丁中同时生成修复代码和BRT。我们针对Google上120个由人工报告的缺陷，评估了不同共生成策略的有效性，并通过分析其对APR智能体行为的影响，对各类共生成策略进行了分类。我们设计并评估了能够考虑测试变更信息的补丁选择器，以筛选出具有合理修复逻辑（及合理BRT）的补丁。最后，我们深入分析了共生成失败轨迹的根本原因。重要的是，我们的研究表明，共生成机制能够在不降低合理修复生成率的前提下，使APR智能体为至少与专用BRT生成器相当数量的缺陷生成BRT，从而显著减少在大规模场景下维护和协调独立修复与BRT生成流水线所带来的工程负担。"
  },
  {
    "date": "2026-01-27",
    "title": "R^3: Replay, Reflection, and Ranking Rewards for LLM Reinforcement Learning",
    "authors": "Zhizheng Jiang, Kang Zhao, Weikai Xu, Xinkui Lin, Wei Liu, Jian Luan, Shuo Shang, Peng Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19620v1",
    "source": "arXiv",
    "abstract": "Large reasoning models (LRMs) aim to solve diverse and complex problems through structured reasoning. Recent advances in group-based policy optimization methods have shown promise in enabling stable advantage estimation without reliance on process-level annotations. However, these methods rely on advantage gaps induced by high-quality samples within the same batch, which makes the training process fragile and inefficient when intra-group advantages collapse under challenging tasks. To address these problems, we propose a reinforcement learning mechanism named \\emph{\\textbf{R^3}} that along three directions: (1) a \\emph{cross-context \\underline{\\textbf{R}}eplay} strategy that maintains the intra-group advantage by recalling valuable examples from historical trajectories of the same query, (2) an \\emph{in-context self-\\underline{\\textbf{R}}eflection} mechanism enabling models to refine outputs by leveraging past failures, and (3) a \\emph{structural entropy \\underline{\\textbf{R}}anking reward}, which assigns relative rewards to truncated or failed samples by ranking responses based on token-level entropy patterns, capturing both local exploration and global stability. We implement our method on Deepseek-R1-Distill-Qwen-1.5B and train it on the DeepscaleR-40k in the math domain. Experiments demonstrate our method achieves SoTA performance on several math benchmarks, representing significant improvements and fewer reasoning tokens over the base models. Code and model will be released.",
    "title_zh": "R^3：用于大语言模型强化学习的重放、反思与排序奖励",
    "abstract_zh": "大型推理模型（LRMs）旨在通过结构化推理解决多样且复杂的问题。近期基于群体的策略优化方法在无需过程级标注的情况下，展现出稳定优势估计的潜力。然而，这些方法依赖于同一批次内高质量样本所引发的优势差距，当面对具有挑战性的任务时，组内优势可能崩溃，导致训练过程变得脆弱且低效。为解决这些问题，我们提出了一种名为 \\emph{\\textbf{R^3}} 的强化学习机制，从三个方向进行改进：(1) 一种**跨上下文 \\underline{\\textbf{R}}eplay** 策略，通过从相同查询的历史轨迹中召回有价值的示例，维持组内优势；(2) 一种**上下文内自 \\underline{\\textbf{R}}eflection** 机制，使模型能够利用过往失败经验来优化输出；(3) 一种**结构熵 \\underline{\\textbf{R}}anking 奖励**，通过基于标记级熵模式对截断或失败样本进行排序，赋予相对奖励，从而同时捕捉局部探索与全局稳定性。我们在 Deepseek-R1-Distill-Qwen-1.5B 模型上实现了该方法，并在数学领域使用 DeepscaleR-40k 数据集进行训练。实验结果表明，我们的方法在多个数学基准测试中达到了当前最优性能（SoTA），相较于基线模型显著提升了表现，同时减少了推理所需的 token 数量。代码与模型将公开发布。"
  },
  {
    "date": "2026-01-27",
    "title": "Yunque DeepResearch Technical Report",
    "authors": "Yuxuan Cai, Xinyi Lai, Peng Yuan, Weiting Liu, Huajian Li, Mingda Li, Xinghua Wang, Shengxie Zheng, Yanchao Hao, Yuyang Yin, Zheng Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19578v1",
    "source": "arXiv",
    "abstract": "Deep research has emerged as a transformative capability for autonomous agents, empowering Large Language Models to navigate complex, open-ended tasks. However, realizing its full potential is hindered by critical limitations, including escalating contextual noise in long-horizon tasks, fragility leading to cascading errors, and a lack of modular extensibility. To address these challenges, we introduce Yunque DeepResearch, a hierarchical, modular, and robust framework. The architecture is characterized by three key components: (1) a centralized Multi-Agent Orchestration System that routes subtasks to an Atomic Capability Pool of tools and specialized sub-agents; (2) a Dynamic Context Management mechanism that structures completed sub-goals into semantic summaries to mitigate information overload; and (3) a proactive Supervisor Module that ensures resilience through active anomaly detection and context pruning. Yunque DeepResearch achieves state-of-the-art performance across a range of agentic deep research benchmarks, including GAIA, BrowseComp, BrowseComp-ZH, and Humanity's Last Exam. We open-source the framework, reproducible implementations, and application cases to empower the community.",
    "title_zh": "云阙深度研究技术报告",
    "abstract_zh": "深度研究已成为自主代理的一项变革性能力，使大型语言模型能够应对复杂且开放式的任务。然而，要充分发挥其潜力仍面临诸多关键挑战，包括长周期任务中不断加剧的上下文噪声、系统脆弱性导致的错误级联，以及缺乏模块化可扩展性。为解决这些问题，我们提出了Yunque DeepResearch——一种分层、模块化且具备鲁棒性的框架。该架构包含三个核心组件：(1) 中心化的多智能体编排系统，负责将子任务分配至工具与专用子代理组成的原子能力池；(2) 动态上下文管理机制，通过将已完成的子目标结构化为语义摘要，有效缓解信息过载；(3) 主动式监督模块，通过主动异常检测与上下文裁剪保障系统的韧性。Yunque DeepResearch在多项智能体深度研究基准测试中达到当前最优水平，涵盖GAIA、BrowseComp、BrowseComp-ZH以及Humanity's Last Exam。我们已开源该框架、可复现的实现代码及应用案例，以赋能更广泛的社区发展。"
  },
  {
    "date": "2026-01-27",
    "title": "Learning Adaptive Parallel Execution for Efficient Code Localization",
    "authors": "Ke Xu, Siyang Xiao, Ming Liang, Yichen Yu, Zhixiang Wang, Jingxuan Xu, Dajun Chen, Wei Jiang, Yong Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19568v1",
    "source": "arXiv",
    "abstract": "Code localization constitutes a key bottleneck in automated software development pipelines. While concurrent tool execution can enhance discovery speed, current agents demonstrate a 34.9\\% redundant invocation rate, which negates parallelism benefits. We propose \\textbf{FuseSearch}, reformulating parallel code localization as a \\textbf{joint quality-efficiency optimization} task. Through defining \\textbf{tool efficiency} -- the ratio of unique information gain to invocation count -- we utilize a two-phase SFT and RL training approach for learning adaptive parallel strategies. Different from fixed-breadth approaches, FuseSearch dynamically modulates search breadth according to task context, evolving from exploration phases to refinement stages. Evaluated on SWE-bench Verified, FuseSearch-4B achieves SOTA-level performance (84.7\\% file-level and 56.4\\% function-level $F_1$ scores) with 93.6\\% speedup, utilizing 67.7\\% fewer turns and 68.9\\% fewer tokens. Results indicate that efficiency-aware training naturally improves quality through eliminating noisy redundant signals, enabling high-performance cost-effective localization agents.",
    "title_zh": "用于高效代码定位的自适应并行执行学习",
    "abstract_zh": "代码定位是自动化软件开发流程中的一个关键瓶颈。尽管并行工具执行能够提升发现速度，但当前的智能体存在34.9%的冗余调用率，这抵消了并行带来的优势。我们提出 \\textbf{FuseSearch}，将并行代码定位重新建模为一项 \\textbf{质量与效率联合优化} 任务。通过定义 \\textbf{工具效率}——即单位调用次数所获得的独特信息量——我们采用两阶段的监督微调（SFT）与强化学习（RL）训练方法，以学习自适应的并行策略。与固定广度的方法不同，FuseSearch 能根据任务上下文动态调节搜索广度，从探索阶段平滑过渡到精炼阶段。在 SWE-bench Verified 数据集上的评估表明，FuseSearch-4B 达到了顶尖水平的表现（文件级 F₁ 得分为 84.7%，函数级 F₁ 得分为 56.4%），同时实现了 93.6% 的加速效果，仅使用了 67.7% 的对话轮次和 68.9% 的 token 数量。结果表明，注重效率的训练能够自然地通过消除噪声和冗余信号来提升质量，从而实现高性能且低成本的代码定位智能体。"
  },
  {
    "date": "2026-01-27",
    "title": "Identifying and Transferring Reasoning-Critical Neurons: Improving LLM Inference Reliability via Activation Steering",
    "authors": "Fangan Dong, Zuming Yan, Xuri Ge, Zhiwei Xu, Mengqi Zhang, Xuanang Chen, Ben He, Xin Xin, Zhumin Chen, Ying Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19847v1",
    "source": "arXiv",
    "abstract": "Despite the strong reasoning capabilities of recent large language models (LLMs), achieving reliable performance on challenging tasks often requires post-training or computationally expensive sampling strategies, limiting their practical efficiency. In this work, we first show that a small subset of neurons in LLMs exhibits strong predictive correlations with reasoning correctness. Based on this observation, we propose AdaRAS (Adaptive Reasoning Activation Steering), a lightweight test-time framework that improves reasoning reliability by selectively intervening on neuron activations. AdaRAS identifies Reasoning-Critical Neurons (RCNs) via a polarity-aware mean-difference criterion and adaptively steers their activations during inference, enhancing incorrect reasoning traces while avoiding degradation on already-correct cases. Experiments on 10 mathematics and coding benchmarks demonstrate consistent improvements, including over 13% gains on AIME-24 and AIME-25. Moreover, AdaRAS exhibits strong transferability across datasets and scalability to stronger models, outperforming post-training methods without additional training or sampling cost.",
    "title_zh": "识别并转移推理关键神经元：通过激活引导提升大语言模型推理的可靠性",
    "abstract_zh": "尽管近期大型语言模型（LLMs）具备强大的推理能力，但在复杂任务上实现可靠性能通常仍需依赖后训练或计算成本高昂的采样策略，这限制了其实际效率。在本工作中，我们首先发现，LLMs中一小部分神经元与推理正确性表现出显著的预测相关性。基于这一观察，我们提出了AdaRAS（自适应推理激活引导）——一种轻量级的测试时框架，通过有选择地干预神经元激活来提升推理的可靠性。AdaRAS利用一种考虑极性的均值差异准则识别出“推理关键神经元”（RCNs），并在推理过程中自适应地调整这些神经元的激活状态，从而增强错误推理路径的表现，同时避免对已正确的案例造成性能下降。在10个数学与编程基准上的实验表明，该方法实现了持续的性能提升，其中在AIME-24和AIME-25上取得了超过13%的增益。此外，AdaRAS展现出良好的跨数据集迁移能力，并可扩展至更强的模型，其性能优于后训练方法，且无需额外训练或采样开销。"
  },
  {
    "date": "2026-01-27",
    "title": "Agentic Design Patterns: A System-Theoretic Framework",
    "authors": "Minh-Dung Dao, Quy Minh Le, Hoang Thanh Lam, Duc-Trong Le, Quoc-Viet Pham, Barry O'Sullivan, Hoang D. Nguyen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19752v1",
    "source": "arXiv",
    "abstract": "With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.",
    "title_zh": "代理设计模式：一种系统理论框架",
    "abstract_zh": "随着基础模型（Foundation Model, FM）的发展，智能体式人工智能系统日益受到关注。然而，这些系统固有的问题，如幻觉现象和推理能力不足，加之系统设计常具有临时性和随意性，导致其应用往往不可靠且脆弱。现有对智能体设计模式的归纳工作通常缺乏严谨的系统理论基础，因而多为高层次或基于便利性的分类体系，难以实际落地。本文旨在填补这一空白，提出一种工程化构建稳健AI智能体的原理性方法。我们主要贡献如下：第一，提出一个新颖的系统理论框架，将智能体式AI系统分解为五个核心且相互作用的功能子系统：推理与世界模型、感知与具身化、行动执行、学习与自适应，以及智能体间通信。第二，基于该架构并直接映射到智能体挑战的全面分类体系，我们提炼出12种智能体设计模式。这些模式被划分为基础类、认知与决策类、执行与交互类，以及自适应与学习类，为智能体设计中反复出现的问题提供可复用的结构性解决方案。通过以ReAct框架为例的案例研究，本文展示了所提设计模式如何有效修复系统性架构缺陷。本研究为研究人员与工程师之间提供了标准化的交流语言和结构化的方法论，有助于推动智能体设计的模块化、可理解性与可靠性提升，为构建更稳健的自主系统奠定坚实基础。"
  },
  {
    "date": "2026-01-27",
    "title": "How Do Transformers Learn to Associate Tokens: Gradient Leading Terms Bring Mechanistic Interpretability",
    "authors": "Shawn Im, Changdae Oh, Zhen Fang, Sharon Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19208v1",
    "source": "arXiv",
    "abstract": "Semantic associations such as the link between \"bird\" and \"flew\" are foundational for language modeling as they enable models to go beyond memorization and instead generalize and generate coherent text. Understanding how these associations are learned and represented in language models is essential for connecting deep learning with linguistic theory and developing a mechanistic foundation for large language models. In this work, we analyze how these associations emerge from natural language data in attention-based language models through the lens of training dynamics. By leveraging a leading-term approximation of the gradients, we develop closed-form expressions for the weights at early stages of training that explain how semantic associations first take shape. Through our analysis, we reveal that each set of weights of the transformer has closed-form expressions as simple compositions of three basis functions (bigram, token-interchangeability, and context mappings), reflecting the statistics of the text corpus and uncovering how each component of the transformer captures semantic associations based on these compositions. Experiments on real-world LLMs demonstrate that our theoretical weight characterizations closely match the learned weights, and qualitative analyses further show how our theorem shines light on interpreting the learned associations in transformers.",
    "title_zh": "变压器如何学习关联标记：梯度主导项带来机制可解释性",
    "abstract_zh": "诸如“鸟”与“飞”之间的语义关联，是语言建模的基础，它们使模型能够超越简单的记忆，实现泛化并生成连贯的文本。理解这些关联在语言模型中如何被学习和表征，对于连接深度学习与语言学理论、建立大语言模型的机制基础至关重要。本文从训练动态的角度，分析了注意力机制语言模型如何从自然语言数据中涌现出这些语义关联。通过利用梯度的主导项近似，我们推导出训练初期权重的闭式表达式，解释了语义关联如何最初形成。我们的分析揭示，Transformer 的每一组权重均可表示为三个基本函数（二元组、词元可互换性、上下文映射）的简单组合，反映了语料库的统计特性，并揭示了 Transformer 各组成部分如何基于这些组合捕捉语义关联。对真实世界大语言模型的实验表明，我们的理论权重刻画与实际学习到的权重高度吻合；定性分析进一步展示了该理论如何为理解 Transformer 中学习到的语义关联提供洞见。"
  },
  {
    "date": "2026-01-27",
    "title": "MetaGen: Self-Evolving Roles and Topologies for Multi-Agent LLM Reasoning",
    "authors": "Yimeng Wang, Jiaxing Zhao, Hongbin Xie, Hexing Ma, Yuzhen Lei, Shuangxue Liu, Xuan Song, Zichen Zhang, Haoran Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19290v1",
    "source": "arXiv",
    "abstract": "Large language models are increasingly deployed as multi-agent systems, where specialized roles communicate and collaborate through structured interactions to solve complex tasks that often exceed the capacity of a single agent. However, most existing systems still rely on a fixed role library and an execution-frozen interaction topology, a rigid design choice that frequently leads to task mismatch, prevents timely adaptation when new evidence emerges during reasoning, and further inflates inference cost. We introduce MetaGen, a training-free framework that adapts both the role space and the collaboration topology at inference time, without updating base model weights. MetaGen generates and rewrites query-conditioned role specifications to maintain a controllable dynamic role pool, then instantiates a constrained execution graph around a minimal backbone. During execution, it iteratively updates role prompts and adjusts structural decisions using lightweight feedback signals. Experiments on code generation and multi-step reasoning benchmarks show that MetaGen improves the accuracy and cost tradeoff over strong multi-agent baselines.",
    "title_zh": "MetaGen：用于多智能体大语言模型推理的自演化角色与拓扑结构",
    "abstract_zh": "大型语言模型正越来越多地被部署为多智能体系统，通过结构化的交互协作，由各具专长的智能体共同解决复杂任务，这些任务往往超出单个智能体的能力范围。然而，现有大多数系统仍依赖固定的智能体角色库和执行冻结的交互拓扑，这种僵化的设计常常导致任务不匹配，无法在推理过程中及时响应新出现的证据，并进一步增加推理开销。我们提出MetaGen，一种无需训练的框架，在推理阶段动态调整角色空间与协作拓扑，且无需更新基础模型权重。MetaGen会生成并重写基于查询条件的角色规范，以维持一个可控的动态角色池，随后围绕最小化核心构建受约束的执行图。在执行过程中，它通过轻量级反馈信号迭代更新角色提示并调整结构决策。在代码生成和多步推理基准上的实验表明，MetaGen在准确率与成本权衡方面优于现有的强大多智能体基线方法。"
  },
  {
    "date": "2026-01-27",
    "title": "GLOVE: Global Verifier for LLM Memory-Environment Realignment",
    "authors": "Xingkun Yin, Hongyang Du",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19249v1",
    "source": "arXiv",
    "abstract": "Most existing memory-enhanced Large Language Model (LLM) approaches implicitly assume that memory validity can be established either through external evaluators that provide task-specific success signals or through internal model cognition, such as reflection, for editing memory entries. However, these assumptions often break down in practical environments with dynamic drifts. We propose the Global Verifier (GLOVE), a framework that introduces a new design dimension for LLM memory systems by establishing a relative notion of truth. Through active probing to detect inconsistencies between retrieved memories and fresh observations, GLOVE enables memory-environment realignment by verifying and updating memory without access to ground-truth supervision or strong reliance on model introspection. We evaluate GLOVE on diverse benchmarks spanning web navigation, planning, and control, augmented with controlled environmental drifts that introduce non-stationarity beyond the original benchmark settings. Our results show that GLOVE substantially improves agent success rates, suggesting a robust pathway to cognitive agents capable of self-evolving.",
    "title_zh": "GLOVE：大语言模型记忆-环境重对齐的全局验证器",
    "abstract_zh": "大多数现有的增强型记忆大型语言模型（LLM）方法隐含地假设，记忆的有效性可以通过外部评估者提供的任务特定成功信号，或通过模型内部的认知机制（如反思）来实现，从而对记忆条目进行编辑。然而，在存在动态漂移的实际环境中，这些假设往往失效。为此，我们提出了全局验证器（GLOVE），一种引入LLM记忆系统新设计维度的框架，通过建立相对真理的概念来应对这一挑战。GLOVE通过主动探测，识别检索到的记忆与最新观察之间的不一致性，从而在无需真实标签监督或强依赖模型内省的情况下，实现记忆与环境的重新对齐——即验证并更新记忆内容。我们在涵盖网页导航、规划和控制等多种基准任务上评估了GLOVE，这些任务均引入了受控的环境漂移，使非平稳性超出原始基准设置的范围。实验结果表明，GLOVE显著提升了智能体的成功率，揭示了一条通往具备自我演化能力的认知智能体的稳健路径。"
  },
  {
    "date": "2026-01-27",
    "title": "LLM-based Vulnerability Detection at Project Scale: An Empirical Study",
    "authors": "Fengjie Li, Jiajun Jiang, Dongchi Chen, Yingfei Xiong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19239v1",
    "source": "arXiv",
    "abstract": "In this paper, we present the first comprehensive empirical study of specialized LLM-based detectors and compare them with traditional static analyzers at the project scale. Specifically, our study evaluates five latest and representative LLM-based methods and two traditional tools using: 1) an in-house benchmark of 222 known real-world vulnerabilities (C/C++ and Java) to assess detection capability, and 2) 24 active open-source projects, where we manually inspected 385 warnings to assess their practical usability and underlying root causes of failures. Our evaluation yields three key findings: First, while LLM-based detectors exhibit low recall on the in-house benchmark, they still uncover more unique vulnerabilities than traditional tools. Second, in open-source projects, both LLM-based and traditional tools generate substantial warnings but suffer from very high false discovery rates, hindering practical use. Our manual analysis further reveals shallow interprocedural reasoning and misidentified source/sink pairs as primary failure causes, with LLM-based tools exhibiting additional unique failures. Finally, LLM-based methods incurs substantial computational costs-hundreds of thousands to hundreds of millions of tokens and multi-hour to multi-day runtimes. Overall, our findings underscore critical limitations in the robustness, reliability, and scalability of current LLM-based detectors. We ultimately summarize a set of implications for future research toward more effective and practical project-scale vulnerability detection.",
    "title_zh": "基于大语言模型的项目级漏洞检测：一项实证研究",
    "abstract_zh": "本文首次对基于大语言模型（LLM）的专用漏洞检测工具进行了全面的实证研究，并将其与传统的静态分析工具在项目规模上进行对比。具体而言，我们的研究评估了五种最新且具有代表性的LLM-based方法以及两种传统工具，采用以下两个维度：1）一个包含222个已知真实世界漏洞（涵盖C/C++和Java）的自建基准测试集，用于评估检测能力；2）24个活跃的开源项目，我们手动检查了385条警告，以评估其实际可用性及失败的根本原因。我们的评估得出三个关键发现：第一，尽管LLM-based检测工具在自建基准测试中的召回率较低，但它们仍发现了比传统工具更多的独特漏洞。第二，在开源项目中，LLM-based工具与传统工具均产生大量警告，但误报率极高，严重阻碍了实际应用。进一步的手动分析表明，浅层过程间推理能力不足以及源/汇点对识别错误是主要的失败原因，而LLM-based工具还表现出一些独特的失败模式。第三，LLM-based方法带来了巨大的计算开销——需要数十万至数亿个token的处理量，运行时间长达数小时甚至数天。总体而言，我们的研究揭示了当前LLM-based检测工具在鲁棒性、可靠性和可扩展性方面的关键局限。最后，我们总结了一系列对未来研究的启示，旨在推动更高效、更实用的项目级漏洞检测技术的发展。"
  },
  {
    "date": "2026-01-27",
    "title": "Refactoring and Equivalence in Rust: Expanding the REM Toolchain with a Novel Approach to Automated Equivalence Proofs",
    "authors": "Matthew Britton, Sasha Pak, Alex Potanin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19207v1",
    "source": "arXiv",
    "abstract": "Refactoring tools are central to modern development, with extract-function refactorings used heavily in day-to-day work. For Rust, however, ownership, borrowing, and advanced type features make automated extract-function refactoring challenging. Existing tools either rely on slow compiler-based analysis, support only restricted language fragments, or provide little assurance beyond \"it still compiles.\" This paper presents REM2.0, a new extract-function and verification toolchain for Rust. REM2.0 works atop rust-analyzer as a persistent daemon, providing low-latency refactorings with a VSCode front-end. It adds a repairer that automatically adjusts lifetimes and signatures when extraction exposes borrow-checker issues, and an optional verification pipeline connecting to CHARON and AENEAS to generate Coq equivalence proofs for a supported Rust subset. The architecture is evaluated on three benchmark suites. On the original REM artefact, REM2.0 achieves 100% compatibility while reducing latency from ~1000ms to single-digit milliseconds in the daemon. On 40 feature-focused extractions from 20 highly starred GitHub repositories, REM2.0 handles most examples involving async/await, const fn, non-local control flow, generics, and higher-ranked trait bounds. On twenty verification benchmarks, the CHARON/AENEAS pipeline constructs end-to-end equivalence proofs for cases within its current subset. Overall, results show that a rust-analyzer-based design can provide fast, feature-rich extract-function refactoring for real Rust programs, while opt-in verification delivers machine-checked behaviour preservation.",
    "title_zh": "Rust中的重构与等价性：通过一种新方法扩展REM工具链以实现自动等价性证明",
    "abstract_zh": "重构工具在现代软件开发中占据核心地位，其中提取函数（extract-function）重构在日常工作中被广泛使用。然而，对于 Rust 语言而言，所有权、借用机制以及高级类型特性使得自动化提取函数重构面临巨大挑战。现有的工具要么依赖于缓慢的编译器分析，要么仅支持受限的语言片段，或仅能提供“代码仍能编译”这类有限的保障。本文提出 REM2.0——一个面向 Rust 的新型提取函数与验证工具链。REM2.0 基于 rust-analyzer 作为持久化后台进程运行，通过 VSCode 前端提供低延迟的重构功能。它引入了一个修复器（repairer），可在提取操作暴露出借用检查器问题时自动调整生命周期和函数签名；同时，还提供可选的验证流水线，可与 CHARON 和 AENEAS 集成，为支持的 Rust 子集生成 Coq 等价性证明。该架构在三个基准测试套件上进行了评估：在原始 REM 工具的基准上，REM2.0 实现了 100% 兼容性，同时将延迟从约 1000 毫秒降低至个位数毫秒；在来自 20 个高星 GitHub 仓库的 40 个聚焦特性的提取案例中，REM2.0 成功处理了涉及 async/await、const fn、非局部控制流、泛型以及高阶特征边界等复杂场景；在二十个验证基准测试中，CHARON/AENEAS 流水线成功构建了针对其当前子集内案例的端到端等价性证明。总体而言，结果表明基于 rust-analyzer 的设计能够为真实的 Rust 程序提供快速且功能丰富的提取函数重构能力，而可选的验证机制则实现了机器可检查的行为保持。"
  },
  {
    "date": "2026-01-27",
    "title": "Using LLMs to Evaluate Architecture Documents: Results from a Digital Marketplace Environment",
    "authors": "Frank Elberzhager, Matthias Gerbershagen, Joshua Ginkel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19693v1",
    "source": "arXiv",
    "abstract": "Generative AI plays an increasing role during software engineering activities to make them, e.g., more efficient or provide better quality. However, it is often unclear how much benefit LLMs really provide. We concentrate on software architects and investigated how an LLM-supported evaluation of architecture documents can support software architects to improve such artefacts. In the context of a research project where a digital marketplace is developed and digital solutions should be analyzed, we used different LLMs to analyze the quality of architecture documents and compared the results with evaluations from software architects. We found out that the quality of the artifact has a strong influence on the quality of the LLM, i.e., the better the quality of the architecture document was, the more consistent were the LLM-based evaluation and the human expert evaluation. While using LLMs in this architecture task is promising, our results showed inconsistencies that need further analyses before generalizing them.",
    "title_zh": "使用大语言模型评估架构文档：来自数字市场环境的成果",
    "abstract_zh": "生成式人工智能在软件工程活动中正发挥着越来越重要的作用，有助于提升效率或提高质量。然而，大型语言模型（LLMs）实际带来的效益往往并不明确。本文聚焦于软件架构师，研究了在架构文档评估中使用LLM如何帮助架构师改进相关成果。在一项开发数字市场平台的研究项目中，需要对各类数字解决方案进行分析，我们采用多种LLM对架构文档的质量进行分析，并将结果与软件架构师的评估进行对比。研究发现，文档本身的质量对LLM评估结果有显著影响：架构文档质量越高，基于LLM的评估结果与人工专家评估结果的一致性也越高。尽管在该架构任务中使用LLM具有潜力，但我们的研究也揭示出一些不一致之处，这些现象仍需进一步分析，才能进行推广。"
  },
  {
    "date": "2026-01-27",
    "title": "ProToken: Token-Level Attribution for Federated Large Language Models",
    "authors": "Waris Gill, Ahmad Humayun, Ali Anwar, Muhammad Ali Gulzar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19672v1",
    "source": "arXiv",
    "abstract": "Federated Learning (FL) enables collaborative training of Large Language Models (LLMs) across distributed data sources while preserving privacy. However, when federated LLMs are deployed in critical applications, it remains unclear which client(s) contributed to specific generated responses, hindering debugging, malicious client identification, fair reward allocation, and trust verification. We present ProToken, a novel Provenance methodology for Token-level attribution in federated LLMs that addresses client attribution during autoregressive text generation while maintaining FL privacy constraints. ProToken leverages two key insights to enable provenance at each token: (1) transformer architectures concentrate task-specific signals in later blocks, enabling strategic layer selection for computational tractability, and (2) gradient-based relevance weighting filters out irrelevant neural activations, focusing attribution on neurons that directly influence token generation. We evaluate ProToken across 16 configurations spanning four LLM architectures (Gemma, Llama, Qwen, SmolLM) and four domains (medical, financial, mathematical, coding). ProToken achieves 98% average attribution accuracy in correctly localizing responsible client(s), and maintains high accuracy when the number of clients are scaled, validating its practical viability for real-world deployment settings.",
    "title_zh": "ProToken：面向联邦大语言模型的令牌级归因方法",
    "abstract_zh": "联邦学习（FL）能够在保护隐私的前提下，实现跨分布式数据源的大语言模型（LLM）协同训练。然而，当联邦大语言模型被部署于关键应用时，仍难以明确具体生成内容是由哪个客户端贡献的，这给故障排查、恶意客户端识别、公平奖励分配以及信任验证带来了挑战。为此，我们提出 ProToken——一种面向联邦大语言模型中 token 级别溯源的新型可证明性方法，可在保持联邦学习隐私约束的同时，实现自回归文本生成过程中的客户端归属追踪。ProToken 基于两个关键洞察，实现了每个 token 的溯源能力：（1）Transformer 架构中任务相关信号集中体现在较深层块，因此可通过战略性地选择网络层来保证计算可行性；（2）基于梯度的相关性加权机制能够过滤掉无关的神经激活，聚焦于直接影响 token 生成的神经元。我们在涵盖四种 LLM 架构（Gemma、Llama、Qwen、SmolLM）和四个领域（医疗、金融、数学、编程）共 16 种配置下对 ProToken 进行评估。结果表明，ProToken 在正确定位责任客户端方面平均达到了 98% 的溯源准确率，并且在客户端数量增加的情况下仍保持高精度，充分验证了其在真实世界部署场景中的实际可行性。"
  },
  {
    "date": "2026-01-27",
    "title": "LURE-RAG: Lightweight Utility-driven Reranking for Efficient RAG",
    "authors": "Manish Chandra, Debasis Ganguly, Iadh Ounis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19535v1",
    "source": "arXiv",
    "abstract": "Most conventional Retrieval-Augmented Generation (RAG) pipelines rely on relevance-based retrieval, which often misaligns with utility -- that is, whether the retrieved passages actually improve the quality of the generated text specific to a downstream task such as question answering or query-based summarization. The limitations of existing utility-driven retrieval approaches for RAG are that, firstly, they are resource-intensive typically requiring query encoding, and that secondly, they do not involve listwise ranking loss during training. The latter limitation is particularly critical, as the relative order between documents directly affects generation in RAG. To address this gap, we propose Lightweight Utility-driven Reranking for Efficient RAG (LURE-RAG), a framework that augments any black-box retriever with an efficient LambdaMART-based reranker. Unlike prior methods, LURE-RAG trains the reranker with a listwise ranking loss guided by LLM utility, thereby directly optimizing the ordering of retrieved documents. Experiments on two standard datasets demonstrate that LURE-RAG achieves competitive performance, reaching 97-98% of the state-of-the-art dense neural baseline, while remaining efficient in both training and inference. Moreover, its dense variant, UR-RAG, significantly outperforms the best existing baseline by up to 3%.",
    "title_zh": "LURE-RAG：轻量级实用驱动重排序以实现高效RAG",
    "abstract_zh": "大多数传统的检索增强生成（RAG）流程依赖于基于相关性的检索，这往往与实用性不一致——即所检索的文本片段是否真正提升了针对下游任务（如问答或基于查询的摘要）的生成质量。现有基于实用性的RAG检索方法存在两个局限：首先，它们通常资源消耗大，需要进行查询编码；其次，在训练过程中未采用列表级排序损失（listwise ranking loss）。后者尤为关键，因为文档之间的相对顺序直接影响RAG的生成效果。为弥补这一不足，我们提出了一种轻量级、以实用性为导向的重排序框架——高效RAG的LURE-RAG（Lightweight Utility-driven Reranking for Efficient RAG），该框架可为任意黑盒检索器添加一个基于LambdaMART的高效重排序模块。与以往方法不同，LURE-RAG利用大语言模型（LLM）的实用性作为指导，通过列表级排序损失来训练重排序器，从而直接优化检索文档的排序。在两个标准数据集上的实验表明，LURE-RAG取得了具有竞争力的性能，达到最先进的密集神经基线97%-98%的水平，同时在训练和推理阶段均保持高效。此外，其密集版本UR-RAG相比现有最佳基线，性能提升最高达3%。"
  },
  {
    "date": "2026-01-27",
    "title": "AACR-Bench: Evaluating Automatic Code Review with Holistic Repository-Level Context",
    "authors": "Lei Zhang, Yongda Yu, Minghui Yu, Xinxin Guo, Zhengqi Zhuang, Guoping Rong, Dong Shao, Haifeng Shen, Hongyu Kuang, Zhengfeng Li, Boge Wang, Guoan Zhang, Bangyu Xiang, Xiaobing Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19494v1",
    "source": "arXiv",
    "abstract": "High-quality evaluation benchmarks are pivotal for deploying Large Language Models (LLMs) in Automated Code Review (ACR). However, existing benchmarks suffer from two critical limitations: first, the lack of multi-language support in repository-level contexts, which restricts the generalizability of evaluation results; second, the reliance on noisy, incomplete ground truth derived from raw Pull Request (PR) comments, which constrains the scope of issue detection. To address these challenges, we introduce AACR-Bench a comprehensive benchmark that provides full cross-file context across multiple programming languages. Unlike traditional datasets, AACR-Bench employs an \"AI-assisted, Expert-verified\" annotation pipeline to uncover latent defects often overlooked in original PRs, resulting in a 285\\% increase in defect coverage. Extensive evaluations of mainstream LLMs on AACR-Bench reveal that previous assessments may have either misjudged or only partially captured model capabilities due to data limitations. Our work establishes a more rigorous standard for ACR evaluation and offers new insights on LLM based ACR, i.e., the granularity/level of context and the choice of retrieval methods significantly impact ACR performance, and this influence varies depending on the LLM, programming language, and the LLM usage paradigm e.g., whether an Agent architecture is employed. The code, data, and other artifacts of our evaluation set are available at https://github.com/alibaba/aacr-bench .",
    "title_zh": "AACR-Bench：基于全面仓库级上下文的自动代码审查评估",
    "abstract_zh": "高质量的评估基准对于在自动化代码审查（ACR）中部署大语言模型（LLMs）至关重要。然而，现有的基准存在两个关键局限：其一，缺乏对仓库级上下文中的多语言支持，限制了评估结果的泛化能力；其二，依赖于从原始Pull Request（PR）评论中提取的噪声大、不完整的真值数据，从而制约了问题检测的范围。为解决上述挑战，我们提出了AACR-Bench——一个全面的评估基准，能够提供跨多个编程语言的完整跨文件上下文信息。与传统数据集不同，AACR-Bench采用“AI辅助、专家验证”的标注流程，有效挖掘出原始PR中常被忽略的潜在缺陷，使缺陷覆盖率提升了285%。对主流LLMs在AACR-Bench上的广泛评估表明，由于数据本身的局限性，以往的评估可能错误判断或仅部分捕捉到模型的真实能力。我们的工作建立了一个更为严格的ACR评估标准，并为基于LLM的ACR提供了新的洞见：上下文的粒度/层级以及检索方法的选择显著影响ACR性能，且这种影响因LLM类型、编程语言及LLM使用范式（例如是否采用Agent架构）而异。我们评估集的代码、数据及其他相关资源已公开，可访问 https://github.com/alibaba/aacr-bench 。"
  },
  {
    "date": "2026-01-27",
    "title": "Hybrid Fault-Driven Mutation Testing for Python",
    "authors": "Saba Alimadadi, Golnaz Gharachorlu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19088v1",
    "source": "arXiv",
    "abstract": "Mutation testing is an effective technique for assessing the effectiveness of test suites by systematically injecting artificial faults into programs. However, existing mutation testing techniques fall short in capturing many types of common faults in dynamically typed languages like Python. In this paper, we introduce a novel set of seven mutation operators that are inspired by prevalent anti-patterns in Python programs, designed to complement the existing general-purpose operators and broaden the spectrum of simulated faults. We propose a mutation testing technique that utilizes a hybrid of static and dynamic analyses to mutate Python programs based on these operators while minimizing equivalent mutants. We implement our approach in a tool called PyTation and evaluate it on 13 open-source Python applications. Our results show that PyTation generates mutants that complement those from general-purpose tools, exhibiting distinct behaviour under test execution and uncovering inadequacies in high-coverage test suites. We further demonstrate that PyTation produces a high proportion of unique mutants, a low cross-kill rate, and a low test overlap ratio relative to baseline tools, highlighting its novel fault model. PyTation also incurs few equivalent mutants, aided by dynamic analysis heuristics.",
    "title_zh": "Python混合故障驱动变异测试",
    "abstract_zh": "变异测试是一种有效的技术，用于通过系统性地向程序中注入人工故障来评估测试套件的有效性。然而，现有的变异测试技术在捕捉动态类型语言（如Python）中常见的多种故障类型方面仍存在不足。本文提出了一组全新的七种变异操作符，这些操作符源自Python程序中普遍存在的反模式，旨在补充现有的通用操作符，并扩展所模拟故障的范围。我们提出了一种结合静态分析与动态分析的变异测试方法，基于这些操作符对Python程序进行变异，同时最大限度地减少等价变异体的产生。我们实现该方法为一个名为PyTation的工具，并在13个开源Python应用程序上进行了评估。结果表明，PyTation生成的变异体能够有效补充通用工具产生的变异体，在测试执行过程中表现出不同的行为，揭示了高覆盖率测试套件中的不足之处。此外，我们进一步证明，PyTation生成的变异体具有较高的唯一性比例，较低的交叉杀死率以及较低的测试重叠率，凸显了其新颖的故障模型。同时，得益于动态分析启发式方法，PyTation产生的等价变异体极少。"
  },
  {
    "date": "2026-01-27",
    "title": "Reward Engineering for Reinforcement Learning in Software Tasks",
    "authors": "Md Rayhanul Masud, Azmine Toushik Wasi, Salman Rahman, Md Rizwan Parvez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19100v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning is increasingly used for code-centric tasks. These tasks include code generation, summarization, understanding, repair, testing, and optimization. This trend is growing faster with large language models and autonomous agents. A key challenge is how to design reward signals that make sense for software. In many RL problems, the reward is a clear number. In software, this is often not possible. The goal is rarely a single numeric objective. Instead, rewards are usually proxies. Common proxies check if the code compiles, passes tests, or satisfies quality metrics. Many reward designs have been proposed for code-related tasks. However, the work is scattered across areas and papers. There is no single survey that brings these approaches together and shows the full landscape of reward design for RL in software. In this survey, we provide the first systematic and comprehensive review of reward engineering for RL in software tasks. We focus on existing methods and techniques. We structure the literature along three complementary dimensions, summarizing the reward-design choices within each. We conclude with challenges and recommendations in the reward design space for SE tasks.",
    "title_zh": "强化学习在软件任务中的奖励工程",
    "abstract_zh": "强化学习在以代码为中心的任务中正得到越来越广泛的应用。这些任务包括代码生成、摘要、理解、修复、测试和优化等。随着大型语言模型和自主代理的发展，这一趋势正在加速。一个关键挑战是如何设计对软件有意义的奖励信号。在许多强化学习问题中，奖励是一个明确的数值；但在软件领域，这种情况往往难以实现。软件任务的目标很少是单一的数值目标，因此奖励通常只能作为代理指标。常见的代理指标包括代码能否编译通过、是否通过测试用例，或是否满足质量度量标准。尽管已有大量针对代码相关任务的奖励设计被提出，但这些研究分散在不同领域和论文中，尚无系统性的综述能够整合这些方法，全面展示强化学习在软件领域的奖励设计全景。本文首次对软件任务中强化学习的奖励工程进行了系统且全面的回顾。我们聚焦于现有方法与技术，从三个互补维度对文献进行组织，并总结了每个维度中的奖励设计选择。最后，我们总结了软件工程任务中奖励设计面临的挑战，并提出了相应的建议。"
  },
  {
    "date": "2026-01-27",
    "title": "Who Said CVE? How Vulnerability Identifiers Are Mentioned by Humans, Bots, and Agents in Pull Requests",
    "authors": "Pien Rooijendijk, Christoph Treude, Mairieli Wessel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19636v1",
    "source": "arXiv",
    "abstract": "Vulnerability identifiers such as CVE, CWE, and GHSA are standardised references to known software security issues, yet their use in practice is not well understood. This paper compares vulnerability ID use in GitHub pull requests authored by autonomous agents, bots, and human developers. Using the AIDev pop dataset and an augmented set of pull requests from the same repositories, we analyse who mentions vulnerability identifiers and where they appear. Bots account for around 69.1% of all mentions, usually adding few identifiers in pull request descriptions, while human and agent mentions are rarer but span more locations. Qualitative analysis shows that bots mainly reference identifiers in automated dependency updates and audits, whereas humans and agents use them to support fixes, maintenance, and discussion.",
    "title_zh": "谁提到了CVE？漏洞标识符在拉取请求中的人类、机器人和代理的提及方式",
    "abstract_zh": "漏洞标识符（如CVE、CWE和GHSA）是针对已知软件安全问题的标准化引用，但在实际应用中其使用方式尚未被充分理解。本文对比了由自主代理、机器人和人类开发者撰写的GitHub拉取请求中对漏洞标识符的使用情况。基于AIDev pop数据集以及同一仓库中扩充的拉取请求集合，我们分析了哪些人提及漏洞标识符，以及这些标识符出现在何处。结果显示，机器人占所有提及的约69.1%，通常仅在拉取请求描述中添加少量标识符；而人类和代理的提及较少，但涉及的位置更广泛。定性分析表明，机器人主要在自动化依赖项更新和审计中引用标识符，而人类和代理则更多地利用标识符来支持修复、维护和讨论。"
  },
  {
    "date": "2026-01-27",
    "title": "The Competence Crisis: A Design Fiction on AI-Assisted Research in Software Engineering",
    "authors": "Mairieli Wessel, Daniel Feitosa, Sangeeth Kochanthara",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19628v1",
    "source": "arXiv",
    "abstract": "Rising publication pressure and the routine use of generative AI tools are reshaping how software engineering research is produced, assessed, and taught. While these developments promise efficiency, they also raise concerns about skill degradation, responsibility, and trust in scholarly outputs. This vision paper employs Design Fiction as a methodological lens to examine how such concerns might materialise if current practices persist. Drawing on themes reported in a recent community survey, we construct a speculative artifact situated in a near future research setting. The fiction is used as an analytical device rather than a forecast, enabling reflection on how automated assistance might impede domain knowledge competence, verification, and mentoring practices. By presenting an intentionally unsettling scenario, the paper invites discussion on how the software engineering research community in the future will define proficiency, allocate responsibility, and support learning.",
    "title_zh": "能力危机：关于人工智能辅助软件工程研究的科幻设计",
    "abstract_zh": "日益增长的发表压力以及生成式AI工具的常态化使用，正在重塑软件工程研究的产出、评估与教学方式。尽管这些发展带来了效率提升的前景，但也引发了人们对技能退化、责任归属以及学术成果可信度的担忧。本文采用设计虚构（Design Fiction）作为方法论视角，探讨若当前实践持续下去，这些担忧可能如何具体显现。基于近期社区调查中提出的关键议题，我们构建了一个设定在近未来研究环境中的假设性案例。该虚构作品并非对未来进行预测，而是一种分析工具，用以反思自动化辅助可能对领域知识掌握、验证过程及指导实践带来的阻碍。通过呈现一个令人不安的设想场景，本文旨在引发讨论：未来的软件工程研究共同体将如何界定专业能力、分配责任，并支持学习与发展。"
  },
  {
    "date": "2026-01-27",
    "title": "Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search",
    "authors": "Thomas Bömer, Nico Koltermann, Max Disselnmeyer, Bastian Amberg, Anne Meyer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19622v1",
    "source": "arXiv",
    "abstract": "Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.",
    "title_zh": "基于算法提示增强的高效LLM启发式设计用于A*搜索",
    "abstract_zh": "启发式函数对树搜索算法（如A*）的性能至关重要，其准确性和效率直接影响搜索结果。传统上，这些启发式函数需要人工精心设计，耗费大量专业知识。近年来，大型语言模型（LLMs）和进化框架的进展为启发式设计的自动化开辟了新途径。本文将启发式进化（EoH）框架进一步扩展，以研究A*搜索中引导启发式自动生成的问题。我们提出了一种新颖的领域无关提示增强策略，将A*算法代码引入提示中，以利用上下文学习能力，该方法称为算法-上下文启发式进化（A-CEoH）。为评估A-CEoH的有效性，我们选取了两个问题领域进行研究：仓库物流中的一个特定问题——单位载荷预整理问题（UPMP），以及经典的滑动拼图问题（SPP）。计算实验表明，A-CEoH能够显著提升生成启发式函数的质量，甚至超越专家设计的启发式函数。"
  },
  {
    "date": "2026-01-27",
    "title": "Whitespaces Don't Lie: Feature-Driven and Embedding-Based Approaches for Detecting Machine-Generated Code",
    "authors": "Syed Mehedi Hasan Nirob, Shamim Ehsan, Moqsadur Rahman, Summit Haque",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19264v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have made it remarkably easy to synthesize plausible source code from natural language prompts. While this accelerates software development and supports learning, it also raises new risks for academic integrity, authorship attribution, and responsible AI use. This paper investigates the problem of distinguishing human-written from machine-generated code by comparing two complementary approaches: feature-based detectors built from lightweight, interpretable stylometric and structural properties of code, and embedding-based detectors leveraging pretrained code encoders. Using a recent large-scale benchmark dataset of 600k human-written and AI-generated code samples, we find that feature-based models achieve strong performance (ROC-AUC 0.995, PR-AUC 0.995, F1 0.971), while embedding-based models with CodeBERT embeddings are also very competitive (ROC-AUC 0.994, PR-AUC 0.994, F1 0.965). Analysis shows that features tied to indentation and whitespace provide particularly discriminative cues, whereas embeddings capture deeper semantic patterns and yield slightly higher precision. These findings underscore the trade-offs between interpretability and generalization, offering practical guidance for deploying robust code-origin detection in academic and industrial contexts.",
    "title_zh": "空白字符不会说谎：基于特征驱动与嵌入的机器生成代码检测方法",
    "abstract_zh": "大型语言模型（LLMs）使得仅通过自然语言提示即可轻松生成看似合理的源代码，这虽然加速了软件开发并支持学习过程，但也带来了学术诚信、作者归属以及负责任使用人工智能等方面的新风险。本文研究了区分人类编写与机器生成代码的问题，比较了两种互补的方法：基于特征的检测器，利用轻量级、可解释的代码风格和结构特征；以及基于嵌入的检测器，借助预训练的代码编码器。基于一个包含60万份人类编写和AI生成代码样本的最新大规模基准数据集，我们发现基于特征的模型表现优异（ROC-AUC 0.995，PR-AUC 0.995，F1 0.971），而使用CodeBERT嵌入的基于嵌入的模型同样具有很强竞争力（ROC-AUC 0.994，PR-AUC 0.994，F1 0.965）。分析表明，与缩进和空白字符相关的特征提供了特别有判别力的线索，而嵌入则捕捉到更深层的语义模式，并表现出略高的精确率。这些发现凸显了可解释性与泛化能力之间的权衡，为在学术和工业场景中部署稳健的代码来源检测系统提供了实用指导。"
  },
  {
    "date": "2026-01-27",
    "title": "\"ENERGY STAR\" LLM-Enabled Software Engineering Tools",
    "authors": "Himon Thakur, Armin Moin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19260v1",
    "source": "arXiv",
    "abstract": "The discussion around AI-Engineering, that is, Software Engineering (SE) for AI-enabled Systems, cannot ignore a crucial class of software systems that are increasingly becoming AI-enhanced: Those used to enable or support the SE process, such as Computer-Aided SE (CASE) tools and Integrated Development Environments (IDEs). In this paper, we study the energy efficiency of these systems. As AI becomes seamlessly available in these tools and, in many cases, is active by default, we are entering a new era with significant implications for energy consumption patterns throughout the Software Development Lifecycle (SDLC). We focus on advanced Machine Learning (ML) capabilities provided by Large Language Models (LLMs). Our proposed approach combines Retrieval-Augmented Generation (RAG) with Prompt Engineering Techniques (PETs) to enhance both the quality and energy efficiency of LLM-based code generation. We present a comprehensive framework that measures real-time energy consumption and inference time across diverse model architectures ranging from 125M to 7B parameters, including GPT-2, CodeLlama, Qwen 2.5, and DeepSeek Coder. These LLMs, chosen for practical reasons, are sufficient to validate the core ideas and provide a proof of concept for more in-depth future analysis.",
    "title_zh": "“能源之星”LLM赋能的软件工程工具",
    "abstract_zh": "关于人工智能工程（AI-Engineering），即面向人工智能增强型系统的软件工程（SE），我们无法忽视一类日益被AI赋能的关键软件系统：那些用于支持或促进软件工程流程的工具，例如计算机辅助软件工程（CASE）工具和集成开发环境（IDE）。本文研究了这些系统在能源效率方面的表现。随着人工智能功能在这些工具中变得无缝可用，且在许多情况下默认处于激活状态，我们正步入一个新时代，这将对整个软件开发生命周期（SDLC）中的能耗模式产生深远影响。本文聚焦于大型语言模型（LLMs）所提供的先进机器学习（ML）能力。我们提出了一种结合检索增强生成（RAG）与提示工程技巧（PETs）的方法，以提升基于LLM的代码生成在质量和能源效率两方面的表现。本文构建了一个全面的框架，能够实时测量不同模型架构（参数量从1.25亿到70亿不等）下的能耗与推理时间，涵盖GPT-2、CodeLlama、Qwen 2.5以及DeepSeek Coder等模型。这些模型的选择基于实际应用考量，足以验证核心理念，并为未来更深入的分析提供概念验证。"
  },
  {
    "date": "2026-01-27",
    "title": "Evaluating Nova 2.0 Lite model under Amazon's Frontier Model Safety Framework",
    "authors": "Satyapriya Krishna, Matteo Memelli, Tong Wang, Abhinav Mohanty, Claire O'Brien Rajkumar, Payal Motwani, Rahul Gupta, Spyros Matsoukas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19134v1",
    "source": "arXiv",
    "abstract": "Amazon published its Frontier Model Safety Framework (FMSF) as part of the Paris AI summit, following which we presented a report on Amazon's Premier model. In this report, we present an evaluation of Nova 2.0 Lite. Nova 2.0 Lite was made generally available from amongst the Nova 2.0 series and is one of its most capable reasoning models. The model processes text, images, and video with a context length of up to 1M tokens, enabling analysis of large codebases, documents, and videos in a single prompt. We present a comprehensive evaluation of Nova 2.0 Lite's critical risk profile under the FMSF. Evaluations target three high-risk domains-Chemical, Biological, Radiological and Nuclear (CBRN), Offensive Cyber Operations, and Automated AI R&D-and combine automated benchmarks, expert red-teaming, and uplift studies to determine whether the model exceeds release thresholds. We summarize our methodology and report core findings. We will continue to enhance our safety evaluation and mitigation pipelines as new risks and capabilities associated with frontier models are identified.",
    "title_zh": "在亚马逊前沿模型安全框架下评估 Nova 2.0 Lite 模型",
    "abstract_zh": "亚马逊在巴黎人工智能峰会期间发布了其前沿模型安全框架（FMSF），随后我们提交了一份关于亚马逊领先模型的报告。在该报告中，我们对Nova 2.0 Lite进行了评估。Nova 2.0 Lite是Nova 2.0系列中率先面向公众推出的版本，也是该系列中推理能力最强的模型之一。该模型能够处理文本、图像和视频，支持高达100万token的上下文长度，从而可在单个提示中分析大型代码库、文档和视频内容。我们依据FMSF框架，对Nova 2.0 Lite的关键风险状况进行了全面评估。评估聚焦于三个高风险领域——化学、生物、辐射与核（CBRN）、进攻性网络行动，以及自动化人工智能研发，并结合自动化基准测试、专家红队测试及提升效果研究，判断该模型是否超过发布阈值。本文总结了我们的评估方法并报告了核心发现。随着对前沿模型所带来新风险与新能力的不断识别，我们将持续优化和完善安全评估与缓解流程。"
  },
  {
    "date": "2026-01-27",
    "title": "CASTER: Breaking the Cost-Performance Barrier in Multi-Agent Orchestration via Context-Aware Strategy for Task Efficient Routing",
    "authors": "Shanyv Liu, Xuyang Yuan, Tao Chen, Zijun Zhan, Zhu Han, Danyang Zheng, Weishan Zhang, Shaohua Cao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19793v1",
    "source": "arXiv",
    "abstract": "Graph-based Multi-Agent Systems (MAS) enable complex cyclic workflows but suffer from inefficient static model allocation, where deploying strong models uniformly wastes computation on trivial sub-tasks. We propose CASTER (Context-Aware Strategy for Task Efficient Routing), a lightweight router for dynamic model selection in graph-based MAS. CASTER employs a Dual-Signal Router that combines semantic embeddings with structural meta-features to estimate task difficulty. During training, the router self-optimizes through a Cold Start to Iterative Evolution paradigm, learning from its own routing failures via on-policy negative feedback. Experiments using LLM-as-a-Judge evaluation across Software Engineering, Data Analysis, Scientific Discovery, and Cybersecurity demonstrate that CASTER reduces inference cost by up to 72.4% compared to strong-model baselines while matching their success rates, and consistently outperforms both heuristic routing and FrugalGPT across all domains.",
    "title_zh": "CASTER：通过上下文感知策略打破多智能体编排中的成本-性能壁垒，实现任务高效路由",
    "abstract_zh": "基于图的多智能体系统（MAS）能够支持复杂的循环工作流，但其静态模型分配机制效率低下：在所有子任务上统一部署强模型，导致对简单任务的计算资源浪费。为此，我们提出 CASTER（上下文感知的任务高效路由策略），一种轻量级路由器，用于在基于图的多智能体系统中实现动态模型选择。CASTER采用双信号路由机制，结合语义嵌入与结构元特征，以估计任务难度。在训练过程中，该路由器通过“冷启动至迭代演化”范式自我优化，利用自身路由失败产生的在线策略负反馈进行学习。在软件工程、数据分析、科学发现和网络安全四个领域，基于大语言模型作为裁判的实验评估表明，与强模型基线相比，CASTER将推理成本降低了高达72.4%，同时保持了相当的成功率；并且在所有领域中，其表现均持续优于启发式路由方法和FrugalGPT。"
  },
  {
    "date": "2026-01-27",
    "title": "TokenSeek: Memory Efficient Fine Tuning via Instance-Aware Token Ditching",
    "authors": "Runjia Zeng, Qifan Wang, Qiang Guan, Ruixiang Tang, Lifu Huang, Zhenting Wang, Xueling Zhang, Cheng Han, Dongfang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19739v1",
    "source": "arXiv",
    "abstract": "Fine tuning has been regarded as a de facto approach for adapting large language models (LLMs) to downstream tasks, but the high training memory consumption inherited from LLMs makes this process inefficient. Among existing memory efficient approaches, activation-related optimization has proven particularly effective, as activations consistently dominate overall memory consumption. Although prior arts offer various activation optimization strategies, their data-agnostic nature ultimately results in ineffective and unstable fine tuning. In this paper, we propose TokenSeek, a universal plugin solution for various transformer-based models through instance-aware token seeking and ditching, achieving significant fine-tuning memory savings (e.g., requiring only 14.8% of the memory on Llama3.2 1B) with on-par or even better performance. Furthermore, our interpretable token seeking process reveals the underlying reasons for its effectiveness, offering valuable insights for future research on token efficiency. Homepage: https://runjia.tech/iclr_tokenseek/",
    "title_zh": "TokenSeek：通过实例感知的令牌舍弃实现高效内存微调",
    "abstract_zh": "微调已被视为将大型语言模型（LLMs）适配到下游任务的默认方法，但LLM固有的高训练内存消耗使得该过程效率低下。在现有的内存高效方法中，与激活相关的优化被证明尤为有效，因为激活始终占据整体内存消耗的主导地位。尽管先前的研究提出了多种激活优化策略，但其数据无关的特性最终导致微调效果不佳且不稳定。本文提出了一种名为TokenSeek的通用插件式解决方案，通过实例感知的token选择与舍弃机制，适用于各类基于Transformer的模型，在实现显著微调内存节省（例如，仅需Llama3.2 1B模型14.8%的内存）的同时，保持甚至超越原有性能。此外，我们提出的可解释性token选择过程揭示了其高效性的内在原因，为未来关于token效率的研究提供了宝贵洞见。主页：https://runjia.tech/iclr_tokenseek/"
  },
  {
    "date": "2026-01-27",
    "title": "RvB: Automating AI System Hardening via Iterative Red-Blue Games",
    "authors": "Lige Huang, Zicheng Liu, Jie Zhang, Lewen Yan, Dongrui Liu, Jing Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19726v1",
    "source": "arXiv",
    "abstract": "The dual offensive and defensive utility of Large Language Models (LLMs) highlights a critical gap in AI security: the lack of unified frameworks for dynamic, iterative adversarial adaptation hardening. To bridge this gap, we propose the Red Team vs. Blue Team (RvB) framework, formulated as a training-free, sequential, imperfect-information game. In this process, the Red Team exposes vulnerabilities, driving the Blue Team to learning effective solutions without parameter updates. We validate our framework across two challenging domains: dynamic code hardening against CVEs and guardrail optimization against jailbreaks. Our empirical results show that this interaction compels the Blue Team to learn fundamental defensive principles, leading to robust remediations that are not merely overfitted to specific exploits. RvB achieves Defense Success Rates of 90\\% and 45\\% across the respective tasks while maintaining near 0\\% False Positive Rates, significantly surpassing baselines. This work establishes the iterative adversarial interaction framework as a practical paradigm that automates the continuous hardening of AI systems.",
    "title_zh": "RvB：通过迭代红蓝对抗实现AI系统加固的自动化",
    "abstract_zh": "大型语言模型（LLMs）兼具攻击与防御双重能力，凸显了人工智能安全领域的一个关键短板：缺乏统一的、支持动态迭代式对抗适应强化的框架。为弥合这一差距，我们提出“红队 vs. 蓝队”（RvB）框架，该框架被建模为一种无需训练、顺序进行、信息不完全的博弈过程。在此过程中，红队负责暴露系统漏洞，推动蓝队在不更新参数的前提下学习有效的应对策略。我们在两个具有挑战性的领域验证了该框架的有效性：针对CVE漏洞的动态代码加固，以及针对越狱攻击的防护机制优化。实验结果表明，这种交互促使蓝队学习到根本性的防御原则，从而生成不仅针对特定攻击手段、而且具备广泛鲁棒性的修复方案。在两项任务中，RvB分别实现了90%和45%的防御成功率，同时保持接近0%的误报率，显著优于现有基线方法。本研究确立了迭代式对抗交互框架作为一种可实践的新范式，能够自动化实现AI系统的持续强化。"
  },
  {
    "date": "2026-01-27",
    "title": "GAVEL: Towards rule-based safety through activation monitoring",
    "authors": "Shir Rozenfeld, Rahul Pankajakshan, Itay Zloczower, Eyal Lenga, Gilad Gressel, Yisroel Mirsky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19768v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly paired with activation-based monitoring to detect and prevent harmful behaviors that may not be apparent at the surface-text level. However, existing activation safety approaches, trained on broad misuse datasets, struggle with poor precision, limited flexibility, and lack of interpretability. This paper introduces a new paradigm: rule-based activation safety, inspired by rule-sharing practices in cybersecurity. We propose modeling activations as cognitive elements (CEs), fine-grained, interpretable factors such as ''making a threat'' and ''payment processing'', that can be composed to capture nuanced, domain-specific behaviors with higher precision. Building on this representation, we present a practical framework that defines predicate rules over CEs and detects violations in real time. This enables practitioners to configure and update safeguards without retraining models or detectors, while supporting transparency and auditability. Our results show that compositional rule-based activation safety improves precision, supports domain customization, and lays the groundwork for scalable, interpretable, and auditable AI governance. We will release GAVEL as an open-source framework and provide an accompanying automated rule creation tool.",
    "title_zh": "GAVEL：通过激活监控实现基于规则的安全性",
    "abstract_zh": "大型语言模型（LLMs）正越来越多地与基于激活值的监控技术结合，以检测并预防那些在表面文本层面难以察觉的有害行为。然而，现有的激活安全方法大多基于广泛滥用数据集进行训练，存在精度低、灵活性差以及可解释性不足等问题。本文提出一种新范式：基于规则的激活安全，其灵感源自网络安全领域的规则共享实践。我们提出将激活值建模为认知元素（Cognitive Elements, CEs），即细粒度、可解释的因素，如“发出威胁”和“支付处理”等，这些元素可通过组合方式捕捉细微且领域特定的行为，从而实现更高的检测精度。在此基础上，我们构建了一个实用框架，通过在CE上定义谓词规则，并实现实时违规检测。该框架使从业者能够在不重新训练模型或检测器的情况下，灵活配置和更新安全防护机制，同时保障透明性与可审计性。实验结果表明，这种组合式的规则驱动激活安全方法显著提升了精度，支持领域定制化，并为可扩展、可解释、可审计的AI治理奠定了基础。我们将开源发布GAVEL框架，并配套提供自动化规则生成工具。"
  },
  {
    "date": "2026-01-27",
    "title": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
    "authors": "Tianyue Jiang, Yanli Wang, Yanlin Wang, Daya Guo, Ensheng Shi, Yuchi Ma, Jiachi Chen, Zibin Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19697v1",
    "source": "arXiv",
    "abstract": "Repository-level code completion remains a challenging task for existing code large language models (code LLMs) due to their limited understanding of repository-specific context and domain knowledge. While retrieval-augmented generation (RAG) approaches have shown promise by retrieving relevant code snippets as cross-file context, they suffer from two fundamental problems: misalignment between the query and the target code in the retrieval process, and the inability of existing retrieval methods to effectively utilize the inference information. To address these challenges, we propose AlignCoder, a repository-level code completion framework that introduces a query enhancement mechanism and a reinforcement learning based retriever training method. Our approach generates multiple candidate completions to construct an enhanced query that bridges the semantic gap between the initial query and the target code. Additionally, we employ reinforcement learning to train an AlignRetriever that learns to leverage inference information in the enhanced query for more accurate retrieval. We evaluate AlignCoder on two widely-used benchmarks (CrossCodeEval and RepoEval) across five backbone code LLMs, demonstrating an 18.1% improvement in EM score compared to baselines on the CrossCodeEval benchmark. The results show that our framework achieves superior performance and exhibits high generalizability across various code LLMs and programming languages.",
    "title_zh": "AlignCoder：面向仓库级代码补全的检索与目标意图对齐",
    "abstract_zh": "由于现有代码大语言模型（code LLMs）对项目级上下文和领域知识的理解有限，仓库级代码补全仍然是一个具有挑战性的任务。尽管检索增强生成（RAG）方法通过检索相关代码片段作为跨文件上下文展现出了潜力，但其仍存在两个根本性问题：检索过程中查询与目标代码之间的语义不匹配，以及现有检索方法无法有效利用推理信息。为解决这些挑战，我们提出了AlignCoder——一种仓库级代码补全框架，该框架引入了查询增强机制和基于强化学习的检索器训练方法。我们的方法生成多个候选补全结果，以构建一个增强后的查询，从而弥合初始查询与目标代码之间的语义鸿沟。此外，我们采用强化学习训练一个AlignRetriever，使其能够利用增强查询中的推理信息，实现更精准的检索。我们在两个广泛使用的基准测试（CrossCodeEval 和 RepoEval）上，针对五种不同的骨干代码LLM进行了评估，结果显示在CrossCodeEval基准上，相比基线模型，EM得分提升了18.1%。实验结果表明，我们的框架不仅性能优越，而且在多种代码LLM和编程语言之间表现出良好的泛化能力。"
  },
  {
    "date": "2026-01-27",
    "title": "From Scattered to Structured: A Vision for Automating Architectural Knowledge Management",
    "authors": "Jan Keim, Angelika Kaplan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19548v1",
    "source": "arXiv",
    "abstract": "Software architecture is inherently knowledge-centric. The architectural knowledge is distributed across heterogeneous software artifacts such as requirements documents, design diagrams, code, and documentation, making it difficult for developers to access and utilize this knowledge effectively. Moreover, as systems evolve, inconsistencies frequently emerge between these artifacts, leading to architectural erosion and impeding maintenance activities. We envision an automated pipeline that systematically extracts architectural knowledge from diverse artifacts, links them, identifies and resolves inconsistencies, and consolidates this knowledge into a structured knowledge base. This knowledge base enables critical activities such as architecture conformance checking and change impact analysis, while supporting natural language question-answering to improve access to architectural knowledge. To realize this vision, we plan to develop specialized extractors for different artifact types, design a unified knowledge representation schema, implement consistency checking mechanisms, and integrate retrieval-augmented generation techniques for conversational knowledge access.",
    "title_zh": "从零散到系统：自动化建筑知识管理的愿景",
    "abstract_zh": "软件架构本质上是知识驱动的。架构知识分散在各种异构的软件制品中，如需求文档、设计图、代码和文档等，这使得开发人员难以有效获取和利用这些知识。此外，随着系统不断演进，这些制品之间经常出现不一致，导致架构退化，进而阻碍维护工作。我们设想构建一个自动化的处理流程，能够系统地从多种制品中提取架构知识，建立它们之间的关联，识别并解决不一致性问题，最终将这些知识整合到一个结构化的知识库中。该知识库可支持诸如架构合规性检查、变更影响分析等关键活动，并通过自然语言问答方式提升对架构知识的访问效率。为实现这一愿景，我们计划开发针对不同制品类型的专用提取工具，设计统一的知识表示模式，实现一致性检查机制，并集成检索增强生成技术，以支持对话式知识访问。"
  },
  {
    "date": "2026-01-27",
    "title": "A Security Analysis of CheriBSD and Morello Linux",
    "authors": "Dariy Guzairov, Alex Potanin, Stephen Kell, Alwen Tiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19074v1",
    "source": "arXiv",
    "abstract": "Memory corruption attacks have been prevalent in software for a long time. Some mitigation strategies against these attacks do exist, but they are not as far-reaching or as efficient as the CHERI architecture. CHERI uses capabilities to restrict pointers to certain regions of memory and with certain access restrictions. These capabilities are also used to implement \"compartmentalisation\": dividing a binary into smaller components with limited privilege, while adhering to the principle of least privilege. However, while this architecture successfully mitigates memory corruption attacks, the compartmentalisation mechanisms in place are less effective in containing malicious code to a separate compartment. This paper details four ways to bypass compartmentalisation, with a focus on Linux and BSD operating systems ported to this architecture. We find that although compartmentalisation is implemented in these two operating systems, simple bugs and attacks can still allow malicious code to bypass it. We conclude with mitigation measures to prevent these attacks, a proof-of-concept demonstrating their use, and recommendations for further securing Linux and BSD against unknown attacks.",
    "title_zh": "CheriBSD与Morello Linux的安全性分析",
    "abstract_zh": "内存损坏攻击在软件中已存在很长时间。尽管已有一些缓解策略，但它们的覆盖范围和效率远不及CHERI架构。CHERI通过使用能力（capabilities）来限制指针只能访问特定内存区域并施加特定访问权限。这些能力还用于实现“隔离”：将二进制文件划分为多个权限受限的组件，遵循最小权限原则。然而，尽管该架构能有效缓解内存损坏攻击，其现有的隔离机制在将恶意代码限制在独立组件方面效果有限。本文详细介绍了四种绕过隔离机制的方法，重点针对移植到该架构上的Linux和BSD操作系统。我们发现，尽管这两个操作系统已实现隔离机制，但简单的漏洞和攻击仍可能使恶意代码成功绕过隔离。最后，本文提出了防范这些攻击的缓解措施，提供了一个概念验证实例，并对进一步加强Linux和BSD系统抵御未知攻击提出了建议。"
  },
  {
    "date": "2026-01-27",
    "title": "The Opaque Pointer Design Pattern in Python: Towards a Pythonic PIMPL for Modularity, Encapsulation, and Stability",
    "authors": "Antonios Saravanos, John Pazarzis, Stavros Zervoudakis, Dongnanzi Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19065v1",
    "source": "arXiv",
    "abstract": "Python libraries often need to maintain a stable public API even as internal implementations evolve, gain new backends, or depend on heavy optional libraries. In Python, where internal objects are easy to inspect and import, users can come to rely on \"reachable internals\" that were never intended to be public, making refactoring risky and slowing long-term maintenance. This paper revisits the pointer-to-implementation (PIMPL) idiom from C++ and reinterprets it as a Pythonic pattern of opaque delegation: a small public object (or module) that delegates its behavior to a separate implementation object treated as internal. We situate this pattern within a broader taxonomy of encapsulation techniques in Python, relate it to existing practices such as module-level indirection, facade objects, and backend dispatch, and identify PIMPL-like structures already used in the standard library and the scientific Python ecosystem. We then show how a Pythonic PIMPL can be used in existing codebases to isolate heavy dependencies, support lazy imports, and enable runtime selection of alternative backends without changing the public API. Finally, we discuss the benefits and trade-offs of the approach and offer practical guidance on when the pattern is appropriate and how to apply it in large, long-lived Python libraries.",
    "title_zh": "Python中的不透明指针设计模式：迈向模块化、封装性和稳定性的Python式PIMPL",
    "abstract_zh": "Python 库常常需要在内部实现不断演进、引入新后端或依赖大型可选库的同时，保持稳定的公共 API。在 Python 中，由于内部对象易于检查和导入，用户往往会依赖那些本意并非公开的“可访问内部组件”，这使得重构变得风险重重，并拖慢了长期维护的进程。本文重新审视了 C++ 中的指针到实现（PIMPL）设计模式，并将其重新诠释为一种符合 Python 风格的“不透明委托”模式：即一个小型的公共对象（或模块），其行为通过委托给一个被视作内部实现的独立对象来完成。我们将这一模式置于 Python 封装技术的更广泛分类体系中，将其与现有的实践（如模块级间接引用、外观对象、后端分发机制）相联系，并指出标准库及科学计算 Python 生态系统中已存在类似 PIMPL 的结构。接着，我们展示了如何在现有代码库中运用这种 Python 化的 PIMPL 模式，以隔离重型依赖、支持延迟导入，并在不改变公共 API 的前提下实现在运行时选择替代后端。最后，我们讨论了该方法的优势与权衡，并提供了关于何时适用此模式以及如何在大型、长期维护的 Python 库中应用它的实用建议。"
  },
  {
    "date": "2026-01-27",
    "title": "Proactive Hardening of LLM Defenses with HASTE",
    "authors": "Henry Chen, Victor Aranda, Samarth Keshari, Ryan Heartfield, Nicole Nichols",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19051v1",
    "source": "arXiv",
    "abstract": "Prompt-based attack techniques are one of the primary challenges in securely deploying and protecting LLM-based AI systems. LLM inputs are an unbounded, unstructured space. Consequently, effectively defending against these attacks requires proactive hardening strategies capable of continuously generating adaptive attack vectors to optimize LLM defense at runtime. We present HASTE (Hard-negative Attack Sample Training Engine): a systematic framework that iteratively engineers highly evasive prompts, within a modular optimization process, to continuously enhance detection efficacy for prompt-based attack techniques. The framework is agnostic to synthetic data generation methods, and can be generalized to evaluate prompt-injection detection efficacy, with and without fuzzing, for any hard-negative or hard-positive iteration strategy. Experimental evaluation of HASTE shows that hard negative mining successfully evades baseline detectors, reducing malicious prompt detection for baseline detectors by approximately 64%. However, when integrated with detection model re-training, it optimizes the efficacy of prompt detection models with significantly fewer iteration loops compared to relative baseline strategies. The HASTE framework supports both proactive and reactive hardening of LLM defenses and guardrails. Proactively, developers can leverage HASTE to dynamically stress-test prompt injection detection systems; efficiently identifying weaknesses and strengthening defensive posture. Reactively, HASTE can mimic newly observed attack types and rapidly bridge detection coverage by teaching HASTE-optimized detection models to identify them.",
    "title_zh": "通过HASTE实现大语言模型防御的主动强化",
    "abstract_zh": "基于提示的攻击技术是安全部署和保护基于大语言模型（LLM）的人工智能系统所面临的主要挑战之一。由于LLM的输入空间具有无限且非结构化的特性，因此有效防御此类攻击需要采用主动强化策略，能够持续生成自适应的攻击向量，以在运行时优化LLM的防御能力。我们提出了HASTE（Hard-negative Attack Sample Training Engine）：一种系统化框架，通过模块化的优化流程，迭代地设计出高度隐蔽的提示样本，持续提升对基于提示攻击技术的检测效能。该框架与合成数据生成方法无关，可广泛应用于评估任意硬负样本或硬正样本迭代策略下，是否存在模糊测试（fuzzing）时的提示注入检测效果。\n\n实验评估表明，通过硬负样本挖掘，攻击能够成功规避基线检测器，使基线检测器对恶意提示的识别率下降约64%。然而，当与检测模型的再训练相结合时，HASTE在远少于传统基线策略所需迭代次数的情况下，显著提升了提示检测模型的有效性。HASTE框架支持对LLM防御机制及安全护栏的主动与被动加固。主动方面，开发者可利用HASTE动态压力测试提示注入检测系统，高效发现潜在弱点并增强防御能力；被动方面，HASTE可模拟新出现的攻击类型，快速弥补检测覆盖盲区，通过HASTE优化后的检测模型迅速学习识别这些新型攻击。"
  },
  {
    "date": "2026-01-27",
    "title": "Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection",
    "authors": "Quy-Anh Dang, Chris Ngo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19375v1",
    "source": "arXiv",
    "abstract": "Despite significant progress in alignment, large language models (LLMs) remain vulnerable to adversarial attacks that elicit harmful behaviors. Activation steering techniques offer a promising inference-time intervention approach, but existing methods suffer from critical limitations: activation addition requires careful coefficient tuning and is sensitive to layer-specific norm variations, while directional ablation provides only binary control. Recent work on Angular Steering introduces continuous control via rotation in a 2D subspace, but its practical implementation violates norm preservation, causing distribution shift and generation collapse, particularly in models below 7B parameters. We propose Selective Steering, which addresses these limitations through two key innovations: (1) a mathematically rigorous norm-preserving rotation formulation that maintains activation distribution integrity, and (2) discriminative layer selection that applies steering only where feature representations exhibit opposite-signed class alignment. Experiments across nine models demonstrate that Selective Steering achieves 5.5x higher attack success rates than prior methods while maintaining zero perplexity violations and approximately 100\\% capability retention on standard benchmarks. Our approach provides a principled, efficient framework for controllable and stable LLM behavior modification. Code: https://github.com/knoveleng/steering",
    "title_zh": "选择性引导：通过判别层选择实现范数保持的控制",
    "abstract_zh": "尽管在对齐方面取得了显著进展，大型语言模型（LLMs）仍容易受到对抗性攻击的影响，从而诱发有害行为。激活引导技术提供了一种有前景的推理时干预方法，但现有方法存在关键局限：激活添加需要精细调节系数，且对各层的范数变化敏感；而方向性消融仅能提供二值控制。近期提出的角向引导（Angular Steering）通过在二维子空间中进行旋转实现了连续控制，但其实际实现违反了范数保持原则，导致分布偏移和生成崩溃，尤其在参数量低于70亿的模型中表现尤为明显。我们提出**选择性引导**（Selective Steering），通过两项关键创新解决了上述问题：（1）一种数学上严格保证范数不变的旋转公式，有效维持激活分布的完整性；（2）具有判别性的层选择机制，仅在特征表示呈现相反符号类别对齐的层上施加引导。在九个不同模型上的实验表明，选择性引导相比先前方法实现了5.5倍更高的攻击成功率，同时保持零困惑度违规，并在标准基准测试中实现约100%的能力保留。我们的方法为可控、稳定的大型语言模型行为调控提供了一个原理清晰且高效的框架。代码地址：https://github.com/knoveleng/steering"
  },
  {
    "date": "2026-01-27",
    "title": "Assessing Task-based Chatbots: Snapshot and Curated Datasets for Dialogflow",
    "authors": "Elena Masserini, Diego Clerissi, Daniela Micucci, Leonardo Mariani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19787v1",
    "source": "arXiv",
    "abstract": "In recent years, chatbots have gained widespread adoption thanks to their ability to assist users at any time and across diverse domains. However, the lack of large-scale curated datasets limits research on their quality and reliability. This paper presents TOFU-D, a snapshot of 1,788 Dialogflow chatbots from GitHub, and COD, a curated subset of TOFU-D including 185 validated chatbots. The two datasets capture a wide range of domains, languages, and implementation patterns, offering a sound basis for empirical studies on chatbot quality and security. A preliminary assessment using the Botium testing framework and the Bandit static analyzer revealed gaps in test coverage and frequent security vulnerabilities in several chatbots, highlighting the need for systematic, multi-Platform research on chatbot quality and security.",
    "title_zh": "评估基于任务的聊天机器人：Dialogflow 的快照与精选数据集",
    "abstract_zh": "近年来，聊天机器人因其能够在任何时间、跨多个领域为用户提供帮助而得到广泛应用。然而，由于缺乏大规模的高质量数据集，相关研究在聊天机器人质量与可靠性方面受到限制。本文提出了TOFU-D，一个来自GitHub的1,788个Dialogflow聊天机器人的快照数据集，以及COD，TOFU-D的一个经过筛选的子集，包含185个经过验证的聊天机器人。这两个数据集涵盖了广泛的领域、语言和实现模式，为聊天机器人质量与安全性的实证研究提供了坚实基础。通过Botium测试框架和Bandit静态分析工具进行的初步评估发现，部分聊天机器人存在测试覆盖率不足和频繁的安全漏洞，凸显了开展系统性、多平台的聊天机器人质量与安全研究的必要性。"
  },
  {
    "date": "2026-01-27",
    "title": "ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks",
    "authors": "Haoyun Li, Ming Xiao, Kezhi Wang, Robert Schober, Dong In Kim, Yong Liang Guan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19607v1",
    "source": "arXiv",
    "abstract": "Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck. While Large Language Models (LLMs) offer promise, monolithic approaches often lack sufficient domain grounding, constraint awareness, and verification capabilities. To address this, we present ComAgent, a multi-LLM agentic AI framework. ComAgent employs a closed-loop Perception-Planning-Action-Reflection cycle, coordinating specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations. By iteratively decomposing problems and self-correcting errors, the framework effectively bridges the gap between user intent and execution. Evaluations demonstrate that ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, highlighting its potential for automating design in emerging wireless networks.",
    "title_zh": "ComAgent：基于多大语言模型的代理式人工智能赋能智能无线网络",
    "abstract_zh": "6G网络的兴起依赖于复杂的跨层优化，然而将高层次意图手动转化为数学表达式仍是一个瓶颈。尽管大型语言模型（LLMs）展现出巨大潜力，但传统的单一模型方法往往缺乏足够的领域知识支撑、约束意识以及验证能力。为解决这一问题，我们提出了ComAgent——一种基于多LLM代理的智能AI框架。ComAgent采用闭环的“感知-规划-执行-反思”循环机制，通过协调专门负责文献检索、代码生成和评分的多个智能体，自主生成可求解的数学公式及可复现的仿真结果。通过迭代分解问题并自我修正错误，该框架有效弥合了用户意图与实际执行之间的鸿沟。评估结果表明，ComAgent在复杂的波束成形优化任务中达到了专家级表现，并在多种无线通信任务中优于单一的LLM模型，凸显其在新兴无线网络自动化设计中的巨大潜力。"
  },
  {
    "date": "2026-01-27",
    "title": "Toward Architecture-Aware Evaluation Metrics for LLM Agents",
    "authors": "Débora Souza, Patrícia Machado",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19583v1",
    "source": "arXiv",
    "abstract": "LLM-based agents are becoming central to software engineering tasks, yet evaluating them remains fragmented and largely model-centric. Existing studies overlook how architectural components, such as planners, memory, and tool routers, shape agent behavior, limiting diagnostic power. We propose a lightweight, architecture-informed approach that links agent components to their observable behaviors and to the metrics capable of evaluating them. Our method clarifies what to measure and why, and we illustrate its application through real world agents, enabling more targeted, transparent, and actionable evaluation of LLM-based agents.",
    "title_zh": "面向架构感知的大型语言模型代理评估指标",
    "abstract_zh": "基于大语言模型（LLM）的智能体正日益成为软件工程任务的核心，但其评估仍处于碎片化状态，且主要聚焦于模型本身。现有研究忽视了诸如规划器、记忆模块和工具路由等架构组件如何影响智能体行为，从而限制了诊断能力。为此，我们提出一种轻量级、以架构为导向的方法，将智能体的不同组件与其可观察行为以及相应的评估指标相联系。该方法明确了应测量什么以及为何要这样测量，并通过真实世界智能体的应用实例展示了其有效性，从而实现了对LLM智能体更精准、透明且可操作的评估。"
  },
  {
    "date": "2026-01-27",
    "title": "CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations",
    "authors": "Bilel Sefsaf, Abderraouf Dandani, Abdessamed Seddiki, Arab Mohammed, Eduardo Chielle, Michail Maniatakos, Riyadh Baghdadi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19367v1",
    "source": "arXiv",
    "abstract": "Fully Homomorphic Encryption (FHE) enables computations directly on encrypted data, but its high computational cost remains a significant barrier. Writing efficient FHE code is a complex task requiring cryptographic expertise, and finding the optimal sequence of program transformations is often intractable. In this paper, we propose CHEHAB RL, a novel framework that leverages deep reinforcement learning (RL) to automate FHE code optimization. Instead of relying on predefined heuristics or combinatorial search, our method trains an RL agent to learn an effective policy for applying a sequence of rewriting rules to automatically vectorize scalar FHE code while reducing instruction latency and noise growth. The proposed approach supports the optimization of both structured and unstructured code. To train the agent, we synthesize a diverse dataset of computations using a large language model (LLM). We integrate our proposed approach into the CHEHAB FHE compiler and evaluate it on a suite of benchmarks, comparing its performance against Coyote, a state-of-the-art vectorizing FHE compiler. The results show that our approach generates code that is $5.3\\times$ faster in execution, accumulates $2.54\\times$ less noise, while the compilation process itself is $27.9\\times$ faster than Coyote (geometric means).",
    "title_zh": "CHEHAB RL：学习优化全同态加密计算",
    "abstract_zh": "全同态加密（FHE）允许直接在加密数据上进行计算，但其高昂的计算开销仍然是一个重大障碍。编写高效的FHE代码是一项复杂任务，需要深厚的密码学专业知识，而寻找最优的程序变换序列往往难以实现。本文提出了一种名为CHEHAB RL的新框架，该框架利用深度强化学习（RL）来自动化FHE代码优化。与依赖预定义启发式规则或组合搜索的方法不同，我们的方法训练一个强化学习代理，使其学会一种有效的策略，通过应用一系列重写规则，自动将标量FHE代码向量化，同时降低指令延迟和噪声增长。所提出的方案支持对结构化和非结构化代码的优化。为训练该智能体，我们使用大型语言模型（LLM）生成了一个多样化的计算数据集。我们将该方法集成到CHEHAB FHE编译器中，并在一组基准测试上进行了评估，与当前最先进的向量化FHE编译器Coyote进行了性能对比。结果表明，我们的方法生成的代码执行速度提升了5.3倍，噪声积累减少至2.54倍，且编译过程本身比Coyote快27.9倍（几何平均值）。"
  },
  {
    "date": "2026-01-27",
    "title": "Curiosity Driven Knowledge Retrieval for Mobile Agents",
    "authors": "Sijia Li, Xiaoyu Tan, Shahir Ali, Niels Schmidt, Gengchen Ma, Xihe Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19306v1",
    "source": "arXiv",
    "abstract": "Mobile agents have made progress toward reliable smartphone automation, yet performance in complex applications remains limited by incomplete knowledge and weak generalization to unseen environments. We introduce a curiosity driven knowledge retrieval framework that formalizes uncertainty during execution as a curiosity score. When this score exceeds a threshold, the system retrieves external information from documentation, code repositories, and historical trajectories. Retrieved content is organized into structured AppCards, which encode functional semantics, parameter conventions, interface mappings, and interaction patterns. During execution, an enhanced agent selectively integrates relevant AppCards into its reasoning process, thereby compensating for knowledge blind spots and improving planning reliability. Evaluation on the AndroidWorld benchmark shows consistent improvements across backbones, with an average gain of six percentage points and a new state of the art success rate of 88.8\\% when combined with GPT-5. Analysis indicates that AppCards are particularly effective for multi step and cross application tasks, while improvements depend on the backbone model. Case studies further confirm that AppCards reduce ambiguity, shorten exploration, and support stable execution trajectories. Task trajectories are publicly available at https://lisalsj.github.io/Droidrun-appcard/.",
    "title_zh": "好奇心驱动的知识检索在移动代理中的应用",
    "abstract_zh": "移动代理在实现可靠的智能手机自动化方面已取得进展，但在复杂应用中的表现仍受限于知识不完整以及对未见环境的泛化能力较弱。我们提出了一种基于好奇心驱动的知识检索框架，将执行过程中的不确定性形式化为“好奇心分数”。当该分数超过阈值时，系统会从文档、代码仓库和历史轨迹中检索外部信息。检索到的内容被组织成结构化的AppCards，其中编码了功能语义、参数规范、界面映射关系以及交互模式。在执行过程中，增强型代理会根据需要选择性地将相关AppCards融入其推理过程，从而弥补知识盲区，提升规划的可靠性。在AndroidWorld基准上的评估表明，该方法在不同主干模型上均表现出一致的性能提升，结合GPT-5时平均提升6个百分点，并达到88.8%的新一代最优成功率。分析显示，AppCards在多步骤及跨应用任务中尤为有效，而性能提升程度依赖于所采用的主干模型。案例研究进一步证实，AppCards能够降低歧义性、缩短探索时间，并支持更稳定的执行轨迹。相关任务轨迹已公开，可访问：https://lisalsj.github.io/Droidrun-appcard/。"
  },
  {
    "date": "2026-01-27",
    "title": "Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement",
    "authors": "Wangyang Ying, Yanchi Liu, Xujiang Zhao, Wei Cheng, Zhengzhang Chen, Wenchao Yu, Yanjie Fu, Haifeng Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19170v1",
    "source": "arXiv",
    "abstract": "Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \\model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \\model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.",
    "title_zh": "具有结构与逻辑优化的多智能体过程图提取",
    "abstract_zh": "从自然语言中自动提取工作流为过程图具有广阔前景但研究尚不充分，需要同时保证结构有效性与逻辑一致性。尽管近期的大规模语言模型（LLMs）在过程图提取方面展现出潜力，但其常生成结构不规范的图或误解逻辑流程。我们提出 \\model{}，一种多智能体框架，将过程图提取建模为多轮推理过程，并通过专门的结构与逻辑优化阶段实现逐步改进。该框架迭代经历三个阶段：(1) 由图构建智能体完成的图提取阶段；(2) 由仿真智能体执行的结构反馈阶段，用于诊断并解释结构缺陷；(3) 由语义智能体执行的逻辑反馈阶段，用于对齐流程逻辑与源文本中的语言线索。重要反馈以自然语言形式优先表达，并注入后续提示中，从而实现可解释且可控的迭代优化。这种模块化设计使各智能体能够针对不同类型的错误进行精准修正，无需监督信号或参数更新。实验表明，\\model{} 在结构正确性和逻辑一致性方面均显著优于现有强基线方法。"
  },
  {
    "date": "2026-01-27",
    "title": "AgenticSCR: An Autonomous Agentic Secure Code Review for Immature Vulnerabilities Detection",
    "authors": "Wachiraphan Charoenwet, Kla Tantithamthavorn, Patanamon Thongtanunam, Hong Yi Lin, Minwoo Jeong, Ming Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19138v1",
    "source": "arXiv",
    "abstract": "Secure code review is critical at the pre-commit stage, where vulnerabilities must be caught early under tight latency and limited-context constraints. Existing SAST-based checks are noisy and often miss immature, context-dependent vulnerabilities, while standalone Large Language Models (LLMs) are constrained by context windows and lack explicit tool use. Agentic AI, which combine LLMs with autonomous decision-making, tool invocation, and code navigation, offer a promising alternative, but their effectiveness for pre-commit secure code review is not yet well understood. In this work, we introduce AgenticSCR, an agentic AI for secure code review for detecting immature vulnerabilities during the pre-commit stage, augmented by security-focused semantic memories. Using our own curated benchmark of immature vulnerabilities, tailored to the pre-commit secure code review, we empirically evaluate how accurate is our AgenticSCR for localizing, detecting, and explaining immature vulnerabilities. Our results show that AgenticSCR achieves at least 153% relatively higher percentage of correct code review comments than the static LLM-based baseline, and also substantially surpasses SAST tools. Moreover, AgenticSCR generates more correct comments in four out of five vulnerability types, consistently and significantly outperforming all other baselines. These findings highlight the importance of Agentic Secure Code Review, paving the way towards an emerging research area of immature vulnerability detection.",
    "title_zh": "AgenticSCR：一种用于检测不成熟漏洞的自主代理式安全代码审查",
    "abstract_zh": "安全代码审查在提交前阶段至关重要，此时必须在严格的延迟和有限上下文约束下尽早发现漏洞。现有的基于SAST的检查方法噪声大，常常遗漏那些不成熟且依赖上下文的漏洞；而独立运行的大语言模型（LLMs）则受限于上下文窗口长度，并缺乏显式的工具调用能力。代理型人工智能（Agentic AI）结合了大语言模型、自主决策、工具调用与代码导航能力，为这一问题提供了有前景的解决方案，但其在提交前安全代码审查中的实际效果尚不明确。本文提出AgenticSCR——一种面向提交前阶段的安全代码审查代理型AI系统，用于检测不成熟漏洞，并引入聚焦安全的语义记忆机制进行增强。我们构建了一个专为提交前安全代码审查设计的、经过精心筛选的不成熟漏洞基准数据集，对AgenticSCR在定位、检测和解释不成熟漏洞方面的准确性进行了实证评估。结果表明，AgenticSCR相较于静态LLM基线，正确代码审查评论的比例至少提升了153%，同时显著优于传统SAST工具。此外，在五类漏洞中的四类中，AgenticSCR生成的正确评论数量均超过其他所有基线，表现持续且显著更优。这些发现凸显了代理型安全代码审查的重要性，为不成熟漏洞检测这一新兴研究领域的发展铺平了道路。"
  },
  {
    "date": "2026-01-27",
    "title": "HalluJudge: A Reference-Free Hallucination Detection for Context Misalignment in Code Review Automation",
    "authors": "Kla Tantithamthavorn, Hong Yi Lin, Patanamon Thongtanunam, Wachiraphan Charoenwet, Minwoo Jeong, Ming Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19072v1",
    "source": "arXiv",
    "abstract": "Large Language models (LLMs) have shown strong capabilities in code review automation, such as review comment generation, yet they suffer from hallucinations -- where the generated review comments are ungrounded in the actual code -- poses a significant challenge to the adoption of LLMs in code review workflows. To address this, we explore effective and scalable methods for a hallucination detection in LLM-generated code review comments without the reference. In this work, we design HalluJudge that aims to assess the grounding of generated review comments based on the context alignment. HalluJudge includes four key strategies ranging from direct assessment to structured multi-branch reasoning (e.g., Tree-of-Thoughts). We conduct a comprehensive evaluation of these assessment strategies across Atlassian's enterprise-scale software projects to examine the effectiveness and cost-efficiency of HalluJudge. Furthermore, we analyze the alignment between HalluJudge's judgment and developer preference of the actual LLM-generated code review comments in the real-world production. Our results show that the hallucination assessment in HalluJudge is cost-effective with an F1 score of 0.85 and an average cost of $0.009. On average, 67% of the HalluJudge assessments are aligned with the developer preference of the actual LLM-generated review comments in the online production. Our results suggest that HalluJudge can serve as a practical safeguard to reduce developers' exposure to hallucinated comments, fostering trust in AI-assisted code reviews.",
    "title_zh": "HalluJudge：一种用于代码审查自动化中上下文错位幻觉检测的无参考方法",
    "abstract_zh": "大型语言模型（LLMs）在代码审查自动化方面展现出强大的能力，例如自动生成审查评论。然而，它们存在幻觉问题——生成的审查评论缺乏对实际代码的依据——这给LLMs在代码审查工作流中的应用带来了重大挑战。为应对这一问题，我们探索了无需参考即可有效且可扩展地检测LLM生成代码审查评论中幻觉的方法。本文设计了HalluJudge，旨在基于上下文一致性来评估生成评论的合理性。HalluJudge包含四种关键策略，从直接评估到结构化的多分支推理（如思维树，Tree-of-Thoughts）。我们在Atlassian的企业级软件项目上对这些评估策略进行了全面评估，以检验HalluJudge的有效性与成本效益。此外，我们还分析了HalluJudge的判断结果与真实生产环境中开发者对LLM生成审查评论偏好的一致性。实验结果表明，HalluJudge的幻觉检测具有良好的成本效益，F1得分为0.85，平均成本仅为0.009美元。平均而言，67%的HalluJudge评估结果与线上生产环境中开发者的实际偏好一致。研究结果表明，HalluJudge可作为一项实用的保障机制，有效减少开发者接触幻觉评论的风险，从而增强对AI辅助代码审查的信任。"
  },
  {
    "date": "2026-01-27",
    "title": "Principled Fine-tuning of LLMs from User-Edits: A Medley of Preference, Supervision, and Reward",
    "authors": "Dipendra Misra, Aldo Pacchiano, Ta-Chung Chi, Ge Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19055v1",
    "source": "arXiv",
    "abstract": "We study how to fine-tune LLMs using user-edit deployment data consisting of a set of context, an agent's response, and user edits. This deployment data is naturally generated by users in applications such as LLMs-based writing assistants and coding agents. The _natural_ origin of user edits makes it a desired source for adapting and personalizing LLMs. In this setup, there emerges a unification of various feedback types namely preferences, supervised labels, and cost that are typically studied separately in the literature. In this paper, we initiate the theoretical investigation of learning from user edits. We first derive bounds for learning algorithms that learn from each of these feedback types. We prove that these algorithms have different trade-offs depending upon the user, data distribution, and model class. We then propose a simple ensembling procedure to jointly learn from these feedback types. On two domains adapted from Gao et al. 2024, we show our ensembling procedure outperforms these methods that learn from individual feedback. Further, we show that our proposed procedure can robustly adapt to different user-edit distributions at test time.",
    "title_zh": "基于用户编辑的大型语言模型原则性微调：偏好、监督与奖励的综合方法",
    "abstract_zh": "我们研究如何利用用户编辑的部署数据对大语言模型（LLMs）进行微调，这些数据包含一组上下文、代理的响应以及用户的编辑。这类部署数据在基于大语言模型的写作助手和编程代理等应用中自然生成。用户编辑的“自然”来源使其成为适应和个性化大语言模型的理想数据源。在此设置下，各种通常在文献中被分别研究的反馈类型——如偏好、监督标签和代价——得以统一。本文首次对从用户编辑中学习进行了理论探讨。我们首先推导出针对每种反馈类型的训练算法的学习界。我们证明了这些算法在不同用户、数据分布和模型类别下的表现存在不同的权衡。随后，我们提出了一种简单的集成方法，以联合利用这些反馈类型。在两个源自 Gao 等人（2024）研究的领域上，我们展示了该集成方法优于仅依赖单一反馈类型的方法。此外，我们还证明了所提出的集成方法能够在测试时稳健地适应不同的用户编辑分布。"
  },
  {
    "date": "2026-01-27",
    "title": "From Answer Givers to Design Mentors: Guiding LLMs with the Cognitive Apprenticeship Model",
    "authors": "Yongsu Ahn, Lejun R Liao, Benjamin Bach, Nam Wook Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19053v1",
    "source": "arXiv",
    "abstract": "Design feedback helps practitioners improve their artifacts while also fostering reflection and design reasoning. Large Language Models (LLMs) such as ChatGPT can support design work, but often provide generic, one-off suggestions that limit reflective engagement. We investigate how to guide LLMs to act as design mentors by applying the Cognitive Apprenticeship Model, which emphasizes demonstrating reasoning through six methods: modeling, coaching, scaffolding, articulation, reflection, and exploration. We operationalize these instructional methods through structured prompting and evaluate them in a within-subjects study with data visualization practitioners. Participants interacted with both a baseline LLM and an instructional LLM designed with cognitive apprenticeship prompts. Surveys, interviews, and conversational log analyses compared experiences across conditions. Our findings show that cognitively informed prompts elicit deeper design reasoning and more reflective feedback exchanges, though the baseline is sometimes preferred depending on task types or experience levels. We distill design considerations for AI-assisted feedback systems that foster reflective practice.",
    "title_zh": "从答案提供者到设计导师：基于认知学徒制模型引导大语言模型",
    "abstract_zh": "设计反馈有助于从业者改进其作品，同时促进反思与设计思维的深化。大型语言模型（LLMs）如ChatGPT能够辅助设计工作，但往往提供泛化且一次性建议，限制了反思性互动的深度。本文探讨如何通过应用认知师徒模型（Cognitive Apprenticeship Model），引导LLM扮演设计导师的角色。该模型强调通过六种方法展现思维过程：示范（modeling）、指导（coaching）、支架（scaffolding）、表达（articulation）、反思（reflection）和探索（exploration）。我们通过结构化提示（structured prompting）将这些教学方法具体化，并在一项针对数据可视化从业者的组内对照研究中进行评估。参与者分别与基线LLM及采用认知师徒提示设计的指令型LLM进行交互。通过问卷调查、访谈以及对话日志分析，比较不同条件下的使用体验。研究结果表明，基于认知理念的提示能激发更深入的设计推理和更具反思性的反馈交流；然而，在某些任务类型或不同经验水平下，基线LLM仍可能更受青睐。本文提炼出若干面向AI辅助反馈系统的设设计考量，以支持反思性实践的发展。"
  },
  {
    "date": "2026-01-27",
    "title": "Veri-Sure: A Contract-Aware Multi-Agent Framework with Temporal Tracing and Formal Verification for Correct RTL Code Generation",
    "authors": "Jiale Liu, Taiyu Zhou, Tianqi Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.19747v1",
    "source": "arXiv",
    "abstract": "In the rapidly evolving field of Electronic Design Automation (EDA), the deployment of Large Language Models (LLMs) for Register-Transfer Level (RTL) design has emerged as a promising direction. However, silicon-grade correctness remains bottlenecked by: (i) limited test coverage and reliability of simulation-centric evaluation, (ii) regressions and repair hallucinations introduced by iterative debugging, and (iii) semantic drift as intent is reinterpreted across agent handoffs. In this work, we propose Veri-Sure, a multi-agent framework that establishes a design contract to align agents' intent and uses a patching mechanism guided by static dependency slicing to perform precise, localized repairs. By integrating a multi-branch verification pipeline that combines trace-driven temporal analysis with formal verification consisting of assertion-based checking and boolean equivalence proofs, Veri-Sure enables functional correctness beyond pure simulations. We also introduce VerilogEval-v2-EXT, extending the original benchmark with 53 more industrial-grade design tasks and stratified difficulty levels, and show that Veri-Sure achieves state-of-the-art verified-correct RTL code generation performance, surpassing standalone LLMs and prior agentic systems.",
    "title_zh": "Veri-Sure：一种具备合约感知能力的多智能体框架，支持时序追溯与形式化验证，确保正确RTL代码生成",
    "abstract_zh": "在电子设计自动化（EDA）快速发展的领域中，将大语言模型（LLMs）应用于寄存器传输级（RTL）设计已成为一个极具前景的研究方向。然而，芯片级正确性仍面临诸多挑战：（i）以仿真为核心的评估方法存在测试覆盖率有限且可靠性不足的问题；（ii）迭代调试过程中引入的回归错误与修复幻觉；（iii）在多智能体协作过程中因意图传递而产生的语义漂移。针对上述问题，本文提出Veri-Sure——一种多智能体框架，通过建立设计契约来对齐各智能体的意图，并采用基于静态依赖切片的修补机制，实现精准、局部化的修复。Veri-Sure集成了多分支验证流程，融合了基于追踪的时序分析与形式化验证技术（包括断言检查和布尔等价性证明），从而在功能正确性方面超越了纯仿真手段。此外，我们还推出了VerilogEval-v2-EXT，该基准在原有基础上扩展了53个工业级设计任务，并设置了分层难度等级。实验结果表明，Veri-Sure在生成经验证正确的RTL代码方面达到当前最优水平，显著优于独立的大语言模型及以往的智能体系统。"
  },
  {
    "date": "2026-1-27",
    "title": "Penetration Testing of a Merchant Payment Platform; Systemic Vulnerabilities and Compliance-Centric Mitigation",
    "authors": "Ahmad H. Al-Omari",
    "publish": "2025 12th International Conference on Information Technology (ICIT)",
    "url": "https://doi.org/10.1109/icit64950.2025.11049241",
    "source": "IEEE",
    "abstract": "Merchant Payment Platform (MPPs) are vital systems in today’s financial world, handling payments, transactions, and customer support all in one place. However, their complexity, especially when serving multiple businesses on the same platform makes them a magnet for cyberattacks. In this study, we rigorously tested an MPP and uncovered eleven exploitable weaknesses, including critical flaws like price manipulation, unauthorized access to sensitive data, and tampered transactions. Using a mix of automated tools (like Nessus and Burp Suite) and hands-on hacking techniques, we identified these issues while aligning our work with top security standards such as the OWASP Top 10 2023 and PCI DSS v4.0. Our findings highlight how vulnerabilities in one part of the system can cascade into others, emphasize the importance of compliance with regulations like General Data Protection Regulation (GDPR) and Payment Card Industry Data Security Standard (PCI DSS), and offer practical fixes, such as tightening access controls, validating data server-side, and embedding security into development processes to help businesses safeguard these critical platforms against evolving threats",
    "title_zh": "商户支付平台的渗透测试；系统性漏洞及以合规为中心的缓解措施",
    "abstract_zh": "商户支付平台（MPPs）是当今金融体系中至关重要的系统，集支付处理、交易管理及客户支持等功能于一体。然而，由于其复杂性，尤其是在同一平台上服务多个企业的情况下，这些系统极易成为网络攻击的目标。在本研究中，我们对某MPP进行了严格测试，共发现十一处可被利用的漏洞，其中包括若干严重问题，如价格篡改、未经授权访问敏感数据以及交易数据被篡改等。通过结合自动化工具（如Nessus和Burp Suite）与手动渗透技术，并遵循OWASP 2023年十大安全风险及PCI DSS v4.0等顶级安全标准，我们成功识别出上述问题。\n\n研究结果揭示了系统中某一环节的漏洞可能引发连锁反应，导致整个平台面临严重威胁。同时，研究强调了遵守《通用数据保护条例》（GDPR）和《支付卡行业数据安全标准》（PCI DSS）等法规的重要性。为此，我们提出了切实可行的修复建议，包括强化访问控制机制、在服务器端实施数据验证，以及将安全措施融入开发流程（即“安全左移”），以帮助企业在面对不断演化的网络威胁时，有效保护这一关键基础设施的安全。"
  },
  {
    "date": "2026-1-27",
    "title": "A Survey of Domain-specific Fine-tuned Large Language Models",
    "authors": "Paria Sarzaeim, Akramul Azim, Gary Bauer, Masoud Makrehchi",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3658096",
    "source": "IEEE",
    "abstract": "The advancement of large language models (LLMs), such as GPT-3, BERT, and Llama, has introduced a new era in natural language processing (NLP) as they have demonstrated exceptional capabilities across diverse tasks. Fine-tuning these LLMs with domain-specific data has become a popular practice, particularly in domains like education, law, medicine, and software development. This process not only empowers LLMs with domain knowledge but also enhances their capabilities by addressing issues such as reliability and reducing the chance of hallucination. This survey examines a range of domain-specific fine-tuned models by highlighting their unique characteristics, enhancements in performance, and the challenges they address, including the demand for extensive computational resources. Furthermore, we explore the fine-tuning methodologies, including instruction tuning used in the development of these models, and ultimately, inform future research on the existing gaps and how to enhance the effective application of LLMs across diverse domains.",
    "title_zh": "领域特定微调的大语言模型综述",
    "abstract_zh": "大型语言模型（LLMs）如GPT-3、BERT和Llama的快速发展，为自然语言处理（NLP）开启了新的时代，这些模型在多种任务中展现出卓越的能力。通过使用特定领域的数据对这些大模型进行微调，已成为一种流行的做法，尤其在教育、法律、医疗和软件开发等领域尤为突出。这一过程不仅使LLMs获得了领域专业知识，还通过解决可靠性问题和降低幻觉现象的发生率，进一步提升了其性能。本综述系统地考察了一系列特定领域的微调模型，重点分析了它们的独特特征、性能提升以及所应对的挑战，包括对大量计算资源的需求。此外，我们深入探讨了微调方法，包括在模型开发中广泛应用的指令微调技术，并最终指出现有研究中的空白，为未来如何更有效地将LLMs应用于多样化领域提供指导。"
  },
  {
    "date": "2026-1-27",
    "title": "Machine learning-driven prediction of optimal design parameters for ripple carry adder",
    "authors": "Samriddh Kumar Singh, Shobhit Mittra, Neha Singh, Shilpi Birla",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3658174",
    "source": "IEEE",
    "abstract": "Adder circuits are fundamental building blocks in digital electronics and computing systems with applications in basic arithmetic operations to complex computational tasks. Their performance is often limited by propagation delay, area, and power trade-offs. This paper focuses on exploring a machine learning (ML) driven multi-target regression approach for optimizing key design parameters of adders, specifically a ripple carry adder (RCA). Using artificial intelligence (AI) methodologies for automated very large scale integration (VLSI) design optimization will contribute to saving design time for energy efficient sustainable innovations to widen the horizons of computing and communication technologies in the observable future. A dataset containing 8000 datapoints for delay and power consumption of RCA design with different transistor sizes and supply voltages is generated using simulation program with integrated circuit emphasis (SPICE) circuit simulation at 32nm technology node. Multi-target based regression is then used to predict optimal device dimensions and supply voltage, for delay and power constraints. Experimental results demonstrate R<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> score of 0.984, root mean square error (RMSE) of 20.96 and a mean square error (MAE) of 11.37 between the predicted and actual design parameters. This approach provides efficient parameter exploration for optimized and efficient design and operation of digital and analog circuits with different features.",
    "title_zh": "基于机器学习的行波进位加法器最优设计参数预测",
    "abstract_zh": "加法器电路是数字电子与计算系统中的基本构建模块，广泛应用于从基础算术运算到复杂计算任务的各种场景。其性能通常受限于传播延迟、面积和功耗之间的权衡。本文聚焦于一种基于机器学习（ML）的多目标回归方法，用于优化加法器的关键设计参数，特别是行波进位加法器（RCA）。利用人工智能（AI）方法实现超大规模集成电路（VLSI）设计的自动化优化，将有助于节省设计时间，推动能效更高的可持续创新，从而拓展未来计算与通信技术的发展前景。\n\n本研究采用SPICE电路仿真工具，在32纳米工艺节点下，针对不同晶体管尺寸和供电电压组合，生成了包含8000个数据点的RCA设计延迟与功耗数据集。随后，采用多目标回归方法，预测在满足特定延迟与功耗约束条件下的最优器件尺寸与供电电压。实验结果表明，预测值与实际设计参数之间的决定系数（R²）达到0.984，均方根误差（RMSE）为20.96，平均绝对误差（MAE）为11.37。该方法能够高效地进行参数探索，为具有不同特性的数字与模拟电路提供优化且高效的设与运行方案。"
  },
  {
    "date": "2026-1-27",
    "title": "When Voice Meets Touch: Conflict Analysis in Mobile Applications",
    "authors": "Suwan Li, Lei Bu, Shangqing Liu, Guangdong Bai, Fuman Xie, Kai Chen, Chang Yue",
    "publish": "IEEE Transactions on Software Engineering",
    "url": "https://doi.org/10.1109/tse.2026.3656691",
    "source": "IEEE",
    "abstract": "The recent advancement of the automatic speech recognition (ASR) contributes to the voice user interface (VUI), which is broadly embedded into mobile apps. The VUI implemented on modern mobile operating systems like Android naturally involves multiple threads, and brings new race issues and challenges in defining and identifying them. Specifically, when the GUI and VUI (GV) actions both access to the same resource simultanously, the data race named GV-race may occur. GV-race can lead to wrong behavior and even crashes. However, to the best of our knowledge, this problem has not been adequately studied. In this paper, we present the first study of GV-race on Android apps. However, the involvement of the VUI complicates the concurrency model, affects the temporal relationship and brings state space explosion in global analysis. To tackle these challenges, we firstly define <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">primitives</i> and their <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">happen-before</i> rules to abstract GV interaction patterns. Using these primitives, we are able to characterize and formally define GV-race. We then develop <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Roma</i> (GV-<underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">r</u>ace detector <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">o</u>n <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">m</u>obile <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">a</u>pps) to detect both app-level and system-level GV-race automatically. Through static program analysis, Roma extracts GV related call graphs for each pair of conflicting GV actions to reduce the state space, and generates a universal GV interaction graph using our pre-defined primitives. It encodes happen-before constraints to formally specify the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">freeness of GV-race</i>, so that the detection of GV-race can be reduced to constraint solving with SMT solvers. We apply Roma to analyze 266 apps. Roma finds 52 apps with app-level GV-race and 56 apps with system-level GV-race. We confirm that 101 apps are true positives.",
    "title_zh": "当语音遇见触控：移动应用中的冲突分析",
    "abstract_zh": "近年来，自动语音识别（ASR）技术的快速发展推动了语音用户界面（VUI）的广泛应用，VUI已广泛集成于各类移动应用中。现代移动操作系统（如Android）上的VUI实现天然涉及多线程机制，这带来了新的竞争问题和挑战，尤其是在定义与识别这些竞争条件方面。具体而言，当图形用户界面（GUI）与语音用户界面（VUI）同时访问同一共享资源时，可能引发一种名为GV-race的数据竞争。GV-race可能导致程序行为异常甚至崩溃。然而，据我们所知，这一问题尚未得到充分研究。本文首次系统地研究了Android应用中的GV-race问题。\n\n由于VUI的引入，系统的并发模型变得更加复杂，影响了事件的时间顺序关系，并导致全局分析中的状态空间爆炸。为应对这些挑战，我们首先定义了若干**原语**（primitives）及其对应的**先行关系规则**（happen-before rules），以抽象化GUI与VUI之间的交互模式。基于这些原语，我们能够对GV-race进行形式化刻画与定义。\n\n随后，我们开发了名为**Roma**（GV-**r**ace detector **o**n **m**obile **a**pps）的自动化检测工具，用于识别应用级和系统级的GV-race。Roma通过静态程序分析，为每一对存在冲突的GV操作提取相关的调用图，从而有效缩小状态空间；并利用预定义的原语构建一个统一的GV交互图。该图编码了先行约束关系，以形式化地表达“GV-race的自由性”（freeness of GV-race），从而使GV-race的检测问题转化为可由SMT求解器处理的约束求解问题。\n\n我们将Roma应用于266个真实Android应用的分析，共发现52个应用存在应用级GV-race，56个应用存在系统级GV-race。经人工验证，其中101个为真实阳性案例，证明了Roma的有效性与实用性。"
  },
  {
    "date": "2026-1-27",
    "title": "Coding with Intelligence: The Impact of AI Tools on Mobile Programming Education",
    "authors": "Álvaro Santos, José Marinho, Cristina Chuva Costa, Anabela Gomes",
    "publish": "2025 7th Experiment@ International Conference (exp.at'25)",
    "url": "https://doi.org/10.1109/exp.at2565440.2025.11348476",
    "source": "IEEE",
    "abstract": "This study analyses student feedback on the Mobile Device Programming (MDP) course, introduced for the first time in the Bachelor of Biomedical Engineering program at the Polytechnic University of Coimbra, during the 2024/2025 academic year. The study analyzes students' utilization of Artificial Intelligence (AI) tools, such as ChatGPT, as a learning aid for their learning process, along with their perceptions of the impact of AI on education and the job market. The findings indicate that students use AI for a variety of purposes, such as understanding code, detecting errors, solving exercises and carrying out practical assignments. Most students believe that AI can personalize learning and improve pass rates in higher education, but they also recognize the risks of over-reliance on AI and the loss of critical thinking.",
    "title_zh": "智能编程：AI工具对移动编程教育的影响",
    "abstract_zh": "本研究分析了学生对科英布拉理工学院生物医学工程学士学位课程中首次开设的移动设备编程（MDP）课程的反馈。该课程于2024/2025学年首次推出。研究还探讨了学生在学习过程中使用人工智能（AI）工具（如ChatGPT）作为学习辅助的情况，以及他们对AI对教育和就业市场影响的看法。研究结果表明，学生将AI用于多种用途，包括理解代码、检测错误、解答练习题以及完成实践任务。大多数学生认为AI能够实现个性化学习，并有助于提高高等教育的通过率，但同时也意识到过度依赖AI可能带来的风险，以及批判性思维能力的削弱。"
  },
  {
    "date": "2026-1-27",
    "title": "cWIDE — A CrossLab Compatible Web Integrated Development Environment for GOLDi Remote Labs",
    "authors": "Pierre Helbing, Johannes Nau, Karsten Henke, Detlef Streitferdt",
    "publish": "2025 7th Experiment@ International Conference (exp.at'25)",
    "url": "https://doi.org/10.1109/exp.at2565440.2025.11348519",
    "source": "IEEE",
    "abstract": "The CrossLab architecture [1] enables a new approach to conducting experiments in online laboratories by connecting multiple laboratory devices via services, increasing their interchangeability and reusability. Integrated development environments (IDEs) are crucial in programming tasks, including online laboratory applications like microcontroller program-ming. The underlying work focuses on developing a CrossLab-compatible web-based IDE by reviewing the state of the art, defining requirements, and designing key functionalities. The developed IDE (see Fig. 1) provides file system management, compilation, debugging, and real-time collaboration capabilities, ensuring compatibility with the CrossLab framework. The demo will show an implementation based on Visual Studio Code and its extension API and discuss requirement fulfillment, alternative solutions, potential extensions, and open challenges. Future research can explore security aspects, complexity reduction, and the use of WebAssembly.",
    "title_zh": "cWIDE — 一种与CrossLab兼容的用于GOLDi远程实验的网络集成开发环境",
    "abstract_zh": "CrossLab架构[1]通过服务连接多个实验设备，为在线实验室中的实验开展提供了一种新方法，提升了设备的互换性和可重用性。集成开发环境（IDE）在编程任务中至关重要，包括微控制器编程等在线实验室应用。本研究的核心工作是基于对当前技术现状的分析，明确需求并设计关键功能，从而开发出一个与CrossLab兼容的基于Web的IDE。所开发的IDE（见图1）具备文件系统管理、编译、调试以及实时协作等功能，确保与CrossLab框架的兼容性。演示将展示基于Visual Studio Code及其扩展API的实现方案，并讨论需求满足情况、替代解决方案、潜在扩展方向以及现存挑战。未来的研究可进一步探索安全性、复杂性降低以及WebAssembly的应用。"
  },
  {
    "date": "2026-1-27",
    "title": "Design of Low Power AMBA APB Protocol Using Clock Gating",
    "authors": "Vangara Kalyan Naga Sai, Muvvala Rohit, Yadlapalli Sharath Chandra, Udarapu Siva Shankar, Sridevi Sathya Priya S",
    "publish": "2025 International Conference on Communication and Smart Devices (ICCoSD)",
    "url": "https://doi.org/10.1109/iccosd66074.2025.11348378",
    "source": "IEEE",
    "abstract": "The Advanced Peripheral Bus (APB) Advanced Microcontroller Bus Architecture (AMBA) is widely used in system-on-chip (SoC) for low-bandwidth peripheral interfacing. However, power consumption has always been one of the significant challenges in present power-aware applications. Here, a low-power AMBA APB protocol design with an efficient clock gating approach has been proposed. Clock gating is a very common power-saving technique that eliminates dynamic power by not supplying the clock signal to idle modules. Clock gating at more than one level is included in the proposed design, which makes it power-frugal during inactive periods without decreasing performance or reliability. The design disables the clock signal for idle modules selectively, actually minimizing redundant switching activity while master-slave communication remains uninterrupted. Simulation results show that power dissipation is decreased from 0.682 mW to 0.567 mW.",
    "title_zh": "基于时钟门控的低功耗AMBA APB协议设计",
    "abstract_zh": "高级外设总线（APB）是先进微控制器总线架构（AMBA）中广泛应用于片上系统（SoC）低带宽外设接口的一种标准。然而，在当前注重功耗的应用中，功耗问题始终是一个重大挑战。本文提出了一种低功耗的AMBA APB协议设计，采用高效的时钟门控技术。时钟门控是一种常见的节能技术，通过不向处于空闲状态的模块提供时钟信号来消除动态功耗。所提出的方案在多个层级上实施了时钟门控，使得在非工作时段能够显著降低功耗，同时不影响性能或可靠性。该设计可选择性地关闭空闲模块的时钟信号，有效减少了不必要的开关活动，而主从设备之间的通信仍能保持连续稳定。仿真结果表明，功耗从0.682 mW降低至0.567 mW。"
  },
  {
    "date": "2026-1-27",
    "title": "NeuroPlat: An FPGA-Based Neuromorphic Computing Platform with Optimized Toolchain for Efficient SNN Deployment",
    "authors": "Zhipeng Liao, Tianyang Li, Ziyang Shen, Chaoming Fang, Jie Yang, Mohamad Sawan",
    "publish": "2025 International Conference on Machine Intelligence and Nature-Inspired Computing (MIND)",
    "url": "https://doi.org/10.1109/mind67540.2025.11351864",
    "source": "IEEE",
    "abstract": "As the applications of brain-inspired computing become increasingly complex, the efficient hardware implementation of spiking neural networks faces two critical challenges: the lack of specialized hardware architectures for simulating spiking neuron behaviors and the absence of dedicated toolchains for mapping SNN algorithms to neuromorphic hardware. To address these limitations, we propose a reconfigurable FPGA-based computing platform featuring specialized computational cores optimized for spiking neuron behavior simulation, incorporating multiple hierarchical storage units, a <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{1 6}$</tex>-parallel spiking processing array, and a dedicated instruction set. Additionally, we develop a comprehensive deployment toolchain that enables the combination of the PyTorch model with our dedicated instruction set, facilitating efficient end-to-end deployment of brain-inspired algorithms on neuromorphic hardware. Spiking-YOLO network has been implemented on this platform and achieves a peak processing speed of 20 FPS, achieving an optimal balance between computational efficiency and resource utilization.",
    "title_zh": "NeuroPlat：一种基于FPGA的类脑计算平台及其优化工具链，实现高效SNN部署",
    "abstract_zh": "随着类脑计算应用的日益复杂，脉冲神经网络（SNN）的高效硬件实现面临两大关键挑战：缺乏专门用于模拟脉冲神经元行为的硬件架构，以及缺少将SNN算法映射到类脑硬件的专用工具链。为解决这些局限性，我们提出了一种可重构的基于FPGA的计算平台，该平台配备针对脉冲神经元行为仿真优化的专用计算核心，集成了多级存储单元、一个16并行脉冲处理阵列以及专用指令集。此外，我们开发了一套完整的部署工具链，能够将PyTorch模型与我们的专用指令集相结合，从而实现类脑算法在类脑硬件上的高效端到端部署。基于该平台，我们成功实现了Spiking-YOLO网络，达到了20 FPS的峰值处理速度，在计算效率与资源利用率之间取得了最佳平衡。"
  },
  {
    "date": "2026-1-27",
    "title": "Enhancing Security and Reliability in IoT Smart Homes via Advanced Engineering Testing Methodologies",
    "authors": "Tarek Kanaan, Ceselia Alyawanseh, Ghassan Kanaan, Nesreen A. Hamad",
    "publish": "2025 12th International Conference on Information Technology (ICIT)",
    "url": "https://doi.org/10.1109/icit64950.2025.11049266",
    "source": "IEEE",
    "abstract": "This paper analyzes how new software testing approaches affect the security and reliability of smart home systems in the Internet of Things (IoT). Given the fluid and multifaceted nature of the IoT environment, it is not possible to perform comprehensive testing of all scenarios. This prompts the need for selecting test cases that provide the needed validation for resource expenditure. It looks into major software testing purposes, functionality, and reliability, as well as robustness on all levels of testing - unit, integration, system, and acceptance testing. Particular emphasis is put on white-box methods, for instance, control flow and dataflow testing IoT software components, which are most capable of detecting faults. Further, the paper analyzes research gaps in combinatorial testing, IoT security, and software automation, underlining their shortcomings. The gaps correspond with the existing knowledge that automated and combinatorial testing while improving coverage and efficiency, are difficult to adapt in IoT ecosystems with high interconnectivity. It could be deduced that further studies should concentrate on adaptive testing frameworks for smart IoT homes to scale with the proposed intelligent techniques for security and reliability.",
    "title_zh": "通过先进的工程测试方法提升物联网智能家居的安全性与可靠性",
    "abstract_zh": "本文分析了新型软件测试方法对物联网（IoT）环境中智能家居系统安全性与可靠性的影响。鉴于物联网环境的动态性和复杂性，全面覆盖所有场景的测试已不可行，因此亟需选择能够有效验证系统性能且合理利用资源的测试用例。研究重点探讨了软件测试的主要目标——功能、可靠性以及在单元测试、集成测试、系统测试和验收测试各层次上的鲁棒性。特别强调了白盒测试方法，如控制流测试和数据流测试，这些方法在检测物联网软件组件中的缺陷方面具有最强的能力。此外，论文还分析了组合测试、物联网安全及软件自动化领域的研究空白，指出了当前存在的不足之处。这些研究空白反映出，尽管自动化和组合测试在提升测试覆盖率与效率方面具有优势，但在高度互联的物联网生态系统中仍难以有效应用。由此可推断，未来的研究应聚焦于为智能物联网家庭设计自适应测试框架，以配合所提出的智能化技术，从而实现安全性和可靠性的持续提升。"
  },
  {
    "date": "2026-1-27",
    "title": "Embedded System Experimentation Powered by Petri Nets-Driven Development and Rapid Prototyping",
    "authors": "Luis Gomes, João-Paulo Barros, Anikó Costa, Filipe Moutinho, Fernando Pereira",
    "publish": "2025 7th Experiment@ International Conference (exp.at'25)",
    "url": "https://doi.org/10.1109/exp.at2565440.2025.11348376",
    "source": "IEEE",
    "abstract": "This work introduces a model-driven development methodology that facilitates the rapid prototyping of Petri net-based embedded controllers. The suggested method takes advantage of using a low-code development strategy along with design automation tools that allow the rapid prototyping of centralized and/or distributed/networked embedded controller systems. It is completely supported by a web-based tool platform that covers all stages of development, starting with the Petri net model edition, covering simulation and property verification, and finally supporting the generating of the execution code, amenable to be deployed at implementation platforms, such as FPGAs and microcontroller-based ones. allowing direct support for hardware- or software-based implementations.",
    "title_zh": "基于Petri网驱动开发与快速原型设计的嵌入式系统实验",
    "abstract_zh": "本文介绍了一种模型驱动的开发方法，可促进基于Petri网的嵌入式控制器的快速原型设计。该方法采用低代码开发策略，并结合设计自动化工具，能够快速实现集中式和/或分布式/网络化嵌入式控制器系统的原型开发。整个开发过程完全由一个基于Web的工具平台支持，涵盖开发全过程：从Petri网模型的编辑、仿真与性质验证，到最终生成可部署于各类实施平台（如FPGA和基于微控制器的系统）的执行代码，从而直接支持硬件或软件实现。"
  },
  {
    "date": "2026-1-27",
    "title": "Preliminary Study for Autonomous Evolutionary Multitasking Method Design",
    "authors": "Yuxiao Huang, Xuebin Lv, Liang Feng, Kay Chen Tan",
    "publish": "2025 International Conference on Machine Intelligence and Nature-Inspired Computing (MIND)",
    "url": "https://doi.org/10.1109/mind67540.2025.11351758",
    "source": "IEEE",
    "abstract": "Evolutionary Multi-task Optimization (EMTO) enhances optimization performance by sharing knowledge across optimization tasks. While existing knowledge transfer methods can improve optimization performance, they often require significant domain expertise that consume huge expert resources. To handle this problem, we introduce a preliminary LLM-assisted framework that autonomously designs knowledge transfer methods for EMTO without human intervention. Empirical studies on WCCI competition benchmarks demonstrate that the knowledge transfer methods designed by our proposed framework can achieve superior performance against existing hand-crafted knowledge transfer approaches.",
    "title_zh": "自主演化多任务方法设计的初步研究",
    "abstract_zh": "进化多任务优化（EMTO）通过在多个优化任务间共享知识来提升优化性能。尽管现有的知识迁移方法能够改善优化效果，但通常需要大量领域专业知识，消耗巨大的专家资源。为解决这一问题，我们提出了一种初步的基于大语言模型（LLM）的辅助框架，该框架能够在无需人工干预的情况下自主设计适用于EMTO的知识迁移方法。在WCCI竞赛基准上的实证研究结果表明，由所提框架设计的知识迁移方法，在性能上优于现有的手工设计方法。"
  },
  {
    "date": "2026-1-27",
    "title": "From Disruptions to Discussions: How GenAI Impacts Human Interactions in Software Development",
    "authors": "Marie Salomon, Ekaterina Koshchenko, Agnia Sergeyuk, Reid Holmes, Gail C. Murphy, Thomas Fritz",
    "publish": "IEEE Transactions on Software Engineering",
    "url": "https://doi.org/10.1109/tse.2026.3655626",
    "source": "IEEE",
    "abstract": "New technologies often change how an individual performs work, such as how generative AI (GenAI) can help a developer write code. New technologies can also impact how people interact with one another, such as how GenAI’s ability to summarize API documentation can reduce the need for developers to ask each other technical questions. In this paper, we report on a two-phase mixed-method study exploring how GenAI influences how humans interact in software development. During phase one, 30 industrial software developers provided data over a period of 5 to 12 days as they worked, contributing 627 experience sampling responses and 207 end-of-workday survey responses. To gain further insight into their work, we interviewed 22 of these developers. During phase two, 131 additional professional developers responded to a survey to explore whether and how the results from phase one are seen across a larger population. Our analysis of the data found that (1) the ability of GenAI to help answer low-level technical questions in a timely way enables developers to see GenAI as a technical mentor, providing opportunities for developers to turn to tools rather than teammates; (2) developers perceive that GenAI can help them experience more focus and experience fewer flow disruptions; (3) GenAI can help developers pursue more meaningful conversations with their colleagues by shifting human interaction towards clarification, joint reasoning, and exploring alternative perspectives; and (4) in the presence of GenAI, developers report still seeking human-to-human interaction for contextual expertise, mentorship, and social connection. Together, these findings show <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">what changes</i>, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">when it changes</i>, and <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">what teams can do next</i> in response to this shift in team interaction dynamics, where GenAI increasingly handles routine technical queries and human conversations center on context, reasoning, and connection. Teams can adopt norms for delegating questions, sustain human judgment in complex decisions, and create space for expertise, mentorship, and connection, alongside increasing technical self-sufficiency.",
    "title_zh": "从干扰到对话：生成式AI如何影响软件开发中的人机互动",
    "abstract_zh": "新技术常常改变个人完成工作的模式，例如生成式人工智能（GenAI）可以帮助开发者编写代码。新技术还可能影响人与人之间的互动方式，例如GenAI能够总结API文档的能力，减少了开发者之间相互询问技术问题的需求。本文报告了一项两阶段混合方法研究，探讨GenAI如何影响软件开发中人类的互动方式。在第一阶段，30名工业界软件开发者在5至12天的工作期间提供了数据，共提交了627份经验采样反馈和207份每日工作结束后的调查问卷。为进一步了解他们的工作情况，我们对其中22名开发者进行了访谈。在第二阶段，又有131名专业开发者参与了调查，以探究第一阶段的结果是否在更广泛的人群中具有代表性。数据分析发现：（1）GenAI能够及时回答低层次的技术问题，使开发者将GenAI视为技术导师，从而为开发者提供转向工具而非同事求助的机会；（2）开发者认为GenAI有助于提升专注度，并减少“心流”中断的情况；（3）GenAI能帮助开发者与同事展开更具意义的对话，推动人际互动从琐碎问答转向澄清、共同推理以及探索不同视角；（4）尽管有GenAI的存在，开发者仍会主动寻求人与人之间的互动，以获取情境知识、指导 mentorship 以及社交连接。综合来看，这些发现揭示了在团队互动动态发生变化的背景下——GenAI越来越多地承担常规技术咨询任务，而人类交流则聚焦于上下文、推理与联结——究竟发生了哪些变化、何时发生这些变化，以及团队接下来可以采取什么行动。团队可建立明确的问题委派规范，保持复杂决策中的人类判断力，并为专业知识、指导关系与人际联结创造空间，同时提升技术自主性。"
  },
  {
    "date": "2026-1-27",
    "title": "A Large Language Model-Assisted Reinforcement Learning Framework with Evolutionary Algorithm for Hybrid Flow-Shop Scheduling",
    "authors": "Fuqing Zhao, Bin Wu, Ling Wang, Hongyan Sang",
    "publish": "IEEE Transactions on Evolutionary Computation",
    "url": "https://doi.org/10.1109/tevc.2026.3658149",
    "source": "IEEE",
    "abstract": "With the growing emphasis on sustainable manufacturing, green scheduling has gained prominence from practitioners and researchers in the industry manufacturing enterprises. This article addresses the hybrid flow shop scheduling problem with peak power consumption constraints (HFSPP) to minimize makespan and total energy consumption (TEC), while ensuring real-time power usage does not exceed a predefined threshold. A hybrid framework, LLM-MODPPO-Evo, is proposed to solve HFSPP by simultaneously minimizing makespan and TEC. The framework consists of three parts: 1) large language models (LLMs) are introduced to automatically design algorithms and generate initial solutions; 2) evolutionary algorithm based on adaptive evolutionary strategy of covariance matrix (CMA-ES) is adopted to diversify solutions; 3) multi-objective distributed proximal policy optimization (MODPPO) is utilized to refine solutions. Firstly, initial scheduling algorithms generated by LLMs via tailored prompt frameworks produce diverse heuristic operators and decoding methods. Secondly, after screening feasible algorithms and producing the initial schemes, these solutions are extended through an EA to create a population of the improved schemes. Finally, the populations are adaptively optimized by MODPPO to yield the best Pareto-optimal solution set to balance makespan and TEC under peak power consumption constraints. The comparative results demonstrate that the framework outperforms that of the existing algorithms in solving the HFSPP.",
    "title_zh": "基于大语言模型辅助与进化算法的混合流水车间调度强化学习框架",
    "abstract_zh": "随着可持续制造理念的日益重视，绿色调度在制造业企业中的实践者与研究者中愈发受到关注。本文针对具有峰值功率消耗约束的混合流水车间调度问题（HFSPP），旨在最小化完工时间（makespan）和总能耗（TEC），同时确保实时功率使用不超过预设阈值。为此，提出一种名为LLM-MODPPO-Evo的混合框架来求解HFSPP，以实现对makespan和TEC的双重优化。该框架包含三个核心部分：1）引入大语言模型（LLMs）自动设计算法并生成初始解；2）采用基于协方差矩阵自适应进化策略（CMA-ES）的进化算法以增强解的多样性；3）利用多目标分布式近端策略优化（MODPPO）对解进行精细化调整。首先，通过定制化的提示框架，LLMs生成多样化的启发式算子和解码方法，从而产生初始调度算法；其次，在筛选出可行算法并生成初始方案后，通过进化算法（EA）对这些方案进行扩展，形成改进方案的种群；最后，利用MODPPO对种群进行自适应优化，获得在峰值功率约束下平衡makespan与TEC的最佳帕累托最优解集。对比实验结果表明，该框架在求解HFSPP问题上优于现有算法。"
  },
  {
    "date": "2026-1-27",
    "title": "Structured Instruction Tuning for Syntax-Semantic Fused Software Defect Detection",
    "authors": "Weihao Zhang, Haoyu Huang, Rui Yang",
    "publish": "2025 International Conference on Machine Intelligence and Nature-Inspired Computing (MIND)",
    "url": "https://doi.org/10.1109/mind67540.2025.11351533",
    "source": "IEEE",
    "abstract": "Software defect detection is crucial for ensuring software quality and reliability. Traditional static analysis approaches often struggle with high false positive rates and limited semantic understanding. This paper presents an approach that combines syntactic analysis with semantic understanding through Large Language Models (LLMs). We introduce the Predicate Event Relation Graph (PERG), a structured protocol for describing code defect patterns, and construct a dataset based on mutual distillation between LLMs and rule-based detection tools. Through structured instruction fine-tuning on this dataset, we develop a specialized 7B parameter LLM that effectively fuses traditional rule knowledge with deep semantic understanding. Experimental results demonstrate that our approach significantly reduces false positives to <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{1 0. 7 5 \\%}$</tex> and improves overall detection precision from 63.75% to 83.3%. The proposed method provides a promising direction for more accurate and reliable software defect detection.",
    "title_zh": "语法-语义融合的软件缺陷检测结构化指令微调",
    "abstract_zh": "软件缺陷检测对于确保软件质量和可靠性至关重要。传统的静态分析方法往往面临误报率高和语义理解能力有限的问题。本文提出一种结合语法分析与大语言模型（LLM）语义理解的新方法。我们引入了谓词事件关系图（PERG），这是一种用于描述代码缺陷模式的结构化协议，并基于大语言模型与基于规则的检测工具之间的相互蒸馏构建了一个数据集。通过对该数据集进行结构化指令微调，我们开发出一个专用于缺陷检测的70亿参数大语言模型，能够有效融合传统规则知识与深层语义理解。实验结果表明，该方法将误报率显著降低至10.75%以下，同时将整体检测准确率从63.75%提升至83.3%。所提出的方案为实现更精准、更可靠的软件缺陷检测提供了极具前景的方向。"
  },
  {
    "date": "2026-1-27",
    "title": "Locally Hosted DeepSeek and Llama3.2 Code Generation and Computer Science Pedagogy",
    "authors": "James Wolfer",
    "publish": "2025 7th Experiment@ International Conference (exp.at'25)",
    "url": "https://doi.org/10.1109/exp.at2565440.2025.11348352",
    "source": "IEEE",
    "abstract": "The emergence of Generative AI as expressed in Large Language Models is having a significant impact on society by encapsulating and correlating knowledge. One aspect of this emergence concerns student adoption of these models for automatic code generation. Most previous work assessed code generation using internet-hosted, very large, language models. In contrast, this work presents the results of deploying smaller, locally hosted, openly available, models on modest hardware consistent with that owned by students. Specifically, this work compares DeepSeek and Llama models on typical student assignments and describes some implications for pedagogy.",
    "title_zh": "本地部署的 DeepSeek 与 Llama3.2 代码生成及计算机科学教学法",
    "abstract_zh": "生成式人工智能，尤其是大型语言模型的出现，正对社会产生重大影响，其通过整合与关联知识展现出强大的能力。其中一个重要方面是学生在自动代码生成中对这些模型的采用。以往大多数研究都基于互联网托管的超大规模语言模型来评估代码生成效果。与此不同，本文研究了在学生普遍拥有的普通硬件上部署小型、本地化、开源可用模型的实际表现。具体而言，本文对比了DeepSeek和Llama模型在典型学生作业中的表现，并探讨了其对教学方法带来的若干启示。"
  }
]