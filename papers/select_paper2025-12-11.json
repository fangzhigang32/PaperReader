[
  {
    "date": "2025-12-11",
    "title": "Does SWE-Bench-Verified Test Agent Ability or Model Memory?",
    "authors": "Thanosan Prathifkumar, Noble Saji Mathews, Meiyappan Nagappan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10218v1",
    "source": "arXiv",
    "abstract": "SWE-Bench-Verified, a dataset comprising 500 issues, serves as a de facto benchmark for evaluating various large language models (LLMs) on their ability to resolve GitHub issues. But this benchmark may overlap with model training data. If that is true, scores may reflect training recall, not issue-solving skill. To study this, we test two Claude models that frequently appear in top-performing agents submitted to the benchmark. We ask them to find relevant files using only issue text, and then issue text plus file paths. We then run the same setup on BeetleBox and SWE-rebench. Despite both benchmarks involving popular open-source Python projects, models performed 3 times better on SWE-Bench-Verified. They were also 6 times better at finding edited files, without any additional context about the projects themselves. This gap suggests the models may have seen many SWE-Bench-Verified tasks during training. As a result, scores on this benchmark may not reflect an agent's ability to handle real software issues, yet it continues to be used in ways that can misrepresent progress and lead to choices that favour agents that use certain models over strong agent design. Our setup tests the localization step with minimal context to the extent that the task should be logically impossible to solve. Our results show the risk of relying on older popular benchmarks and support the shift toward newer datasets built with contamination in mind.",
    "title_zh": "SWE-Bench-Verified 测试的是代理能力还是模型记忆？",
    "abstract_zh": "SWE-Bench-Verified 是一个包含 500 个问题的数据集，已成为评估大型语言模型（LLMs）解决 GitHub 问题能力的行业标准基准。然而，该基准可能与模型训练数据存在重叠。如果属实，那么模型得分可能反映的是训练数据的回忆能力，而非真正的问题求解技能。为探究这一问题，我们测试了两个在该基准中频繁出现的顶级表现代理所使用的 Claude 模型。我们要求它们仅根据问题文本查找相关文件，随后再结合问题文本和文件路径进行查找。接着，我们在 BeetleBox 和 SWE-rebench 上运行相同的实验设置。尽管这两个基准均涉及流行的开源 Python 项目，但模型在 SWE-Bench-Verified 上的表现高出三倍，在未提供任何项目背景信息的情况下，其定位被修改文件的能力也高出六倍。这一显著差距表明，这些模型很可能在训练过程中接触过大量 SWE-Bench-Verified 的任务。因此，该基准上的得分可能并不能真实反映代理处理实际软件问题的能力。然而，该基准仍在被广泛使用，甚至可能误导对进展的评估，并导致选择偏向特定模型而非优秀代理设计。我们的实验设置在极小上下文条件下测试了定位步骤，使得任务在逻辑上几乎不可能完成。结果表明，依赖旧有流行基准存在重大风险，也支持向更新、且充分考虑数据污染问题的数据集过渡。"
  },
  {
    "date": "2025-12-11",
    "title": "Offscript: Automated Auditing of Instruction Adherence in LLMs",
    "authors": "Nicholas Clark, Ryan Bai, Tanu Mitra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10172v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) and generative search systems are increasingly used for information seeking by diverse populations with varying preferences for knowledge sourcing and presentation. While users can customize LLM behavior through custom instructions and behavioral prompts, no mechanism exists to evaluate whether these instructions are being followed effectively. We present Offscript, an automated auditing tool that efficiently identifies potential instruction following failures in LLMs. In a pilot study analyzing custom instructions sourced from Reddit, Offscript detected potential deviations from instructed behavior in 86.4% of conversations, 22.2% of which were confirmed as material violations through human review. Our findings suggest that automated auditing serves as a viable approach for evaluating compliance to behavioral instructions related to information seeking.",
    "title_zh": "离线脚本：大语言模型指令遵循的自动化审计",
    "abstract_zh": "大型语言模型（LLMs）和生成式搜索系统正被越来越多不同背景的用户用于信息获取，这些用户对知识来源和呈现方式有着各异的偏好。尽管用户可以通过自定义指令和行为提示来调整LLM的行为，但目前尚缺乏有效机制来评估这些指令是否被正确执行。我们提出了Offscript——一种自动化审计工具，能够高效识别LLM中潜在的指令遵循失败情况。在一项试点研究中，我们分析了来自Reddit的自定义指令，发现Offscript在86.4%的对话中检测到可能偏离指令的行为，其中22.2%经人工审核后确认为实质性违规。研究结果表明，自动化审计是一种可行的方法，可用于评估LLM在信息获取相关行为指令上的合规性。"
  },
  {
    "date": "2025-12-11",
    "title": "Structural Methods for handling mode changes in multimode DAE systems",
    "authors": "Albert Benveniste, Benoit Caillaud, Yahao Chen, Khalil Ghorbal, Mathias Malandain",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10580v1",
    "source": "arXiv",
    "abstract": "Hybrid systems are an important concept in Cyber-Physical Systems modeling, for which multiphysics modeling from first principles and the reuse of models from libraries are key. To achieve this, DAEs must be used to specify the dynamics in each discrete state (or mode in our context). This led to the development of DAE-based equational languages supporting multiple modes, of which Modelica is a popular standard. Mode switching can be time- or state-based. Impulsive behaviors can occur at mode changes. While mode changes are well understood in particular physics (e.g., contact mechanics), this is not the case in physics-agnostic paradigms such as Modelica. This situation causes difficulties for the compilation of programs, often requiring users to manually smooth out mode changes. In this paper, we propose a novel approach for the hot restart at mode changes in such paradigms. We propose a mathematical meaning for hot restarts (such a mathematical meaning does not exist in general), as well as a combined structural and impulse analysis for mode changes, generating the hot restart even in the presence of impulses. Our algorithm detects at compile time if the mode change is insufficiently specified, in which case it returns diagnostics information to the user.",
    "title_zh": "多模式微分代数方程系统中处理模态变化的结构方法",
    "abstract_zh": "混合系统是网络物理系统建模中的一个重要概念，其核心在于基于第一性原理的多物理场建模以及对模型库中已有模型的复用。为了实现这一目标，必须使用微分代数方程（DAE）来描述每个离散状态（或在本文语境下的“模式”）中的动态行为。这促使了基于DAE的、支持多模式的方程语言的发展，其中Modelica已成为一种广泛采用的标准。模式切换可以基于时间或状态进行。在模式切换时可能会出现脉冲行为。尽管在特定物理领域（如接触力学）中模式切换已有较深入的理解，但在像Modelica这样与物理无关的建模范式中，这一问题仍不明确。这种模糊性给程序编译带来了困难，通常需要用户手动平滑处理模式切换。本文提出了一种针对此类范式中模式切换时热重启的新方法。我们为热重启赋予了明确的数学意义（一般情况下这类数学定义并不存在），并提出了一种结合结构分析与脉冲分析的方法，用于处理模式切换，即使存在脉冲也能生成有效的热重启。我们的算法可在编译时检测出模式切换描述不足的情况，并向用户提供诊断信息。"
  },
  {
    "date": "2025-12-11",
    "title": "NormCode: A Semi-Formal Language for Context-Isolated AI Planning",
    "authors": "Xin Guan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10563v1",
    "source": "arXiv",
    "abstract": "Multistep workflows that chain large language model (LLM) calls suffer from context pollution: as information accumulates across steps, models hallucinate, confuse intermediate outputs, and lose track of task constraints. We present NormCode, a semiformal language for constructing plans of inferences, structured decompositions where each step operates in data isolation and receives only explicitly passed inputs, which eliminates crossstep contamination by design. NormCode enforces a strict separation between semantic operations (LLMdriven reasoning, nondeterministic) and syntactic operations (deterministic data restructuring), enabling precise cost and reliability tracing. The language exists in three isomorphic formats: .ncds for human authoring, .ncd for machine execution, and .ncn for human verification, supporting progressive formalization from sketch to production. We validate NormCode through two demonstrations: (1) a base X addition algorithm achieving 100 percent accuracy on arbitrary length inputs, and (2) self hosted execution of NormCode's own five phase compiler pipeline. The working orchestrator provides dependency driven scheduling, SQLite backed checkpointing, and loop management, making AI workflows auditable by design and addressing a critical need for transparency in high stakes domains such as legal reasoning, medical decision making, and financial analysis.",
    "title_zh": "NormCode：一种用于上下文隔离的AI规划的半形式化语言",
    "abstract_zh": "多步骤工作流通过串联大型语言模型（LLM）调用时，容易出现上下文污染问题：随着各步骤信息不断累积，模型会产生幻觉、混淆中间输出，并偏离任务约束。我们提出 NormCode，一种半形式化语言，用于构建推理计划。该语言采用结构化分解方式，每个步骤在数据隔离中运行，仅接收显式传递的输入，从设计上杜绝了跨步骤的信息污染。NormCode 严格区分语义操作（由 LLM 驱动的推理，具有非确定性）与语法操作（确定性的数据重构），从而实现对成本和可靠性的精确追踪。该语言以三种同构格式存在：.ncds 用于人工编写，.ncd 用于机器执行，.ncn 用于人工验证，支持从草图到生产环境的渐进式形式化过程。我们通过两个演示验证了 NormCode 的有效性：（1）一个基础的 X 加法算法，在任意长度输入下均达到 100% 准确率；（2）NormCode 自身五阶段编译器流水线的自托管执行。其配套的协调器支持依赖驱动调度、基于 SQLite 的检查点机制以及循环管理，使 AI 工作流从设计上具备可审计性，有效应对法律推理、医疗决策和金融分析等高风险领域对透明度的关键需求。"
  },
  {
    "date": "2025-12-11",
    "title": "Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale",
    "authors": "Zhaodong Wang, Zhenting Qi, Sherman Wong, Nathan Hu, Samuel Lin, Jun Ge, Erwin Gao, Yining Yang, Ben Maurer, Wenlin Chen, David Recordon, Yilun Du, Minlan Yu, Ying Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10398v1",
    "source": "arXiv",
    "abstract": "Real-world AI software engineering demands coding agents that can reason over massive repositories, maintain durable memory across and within long sessions, and robustly coordinate complex toolchains at test time. Existing open-source coding agents provide transparency but frequently fall short when pushed to these industrial-scale workloads, while proprietary coding agents offer strong practical performance but limited extensibility, interpretability, and controllability. We present the Confucius Code Agent (CCA), an open-sourced AI software engineer that can operate at an industrial scale. CCA is built atop the Confucius SDK, an open-sourced agent development platform designed around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK introduces a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension module for robust tool use. Moreover, a meta-agent automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid agent development on new tasks, environments, and tool stacks. Instantiated on Confucius SDK with these mechanisms, CCA delivers strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA achieves a state-of-the-art Resolve@1 performance of 54.3%, substantially improving over prior coding agents. Together, the Confucius SDK and CCA provide a transparent, extensible, and reproducible foundation for AI agents, bridge gaps between research prototypes and production-grade systems, and support agent development and deployment at industrial scale.",
    "title_zh": "孔子代码代理：面向工业级规模的开源人工智能软件工程师",
    "abstract_zh": "现实世界中的AI软件工程要求编码代理能够对大规模代码库进行推理，具备跨会话及会话内持久的记忆能力，并在测试时稳健地协调复杂的工具链。现有的开源编码代理虽然具有透明性，但在面对工业级规模的工作负载时常常表现不足；而专有编码代理虽具备出色的实用性能，却在可扩展性、可解释性和可控性方面存在局限。我们提出Confucius Code Agent（CCA），一个可开源的AI软件工程师，能够在工业规模下运行。CCA基于Confucius SDK构建，该SDK是一个开源的代理开发平台，围绕三个互补视角设计：代理体验（AX）、用户体验（UX）和开发者体验（DX）。该SDK引入了统一的编排器与分层工作内存，支持长上下文推理；采用持久化笔记系统，实现跨会话的持续学习；并配备模块化扩展模块，确保工具使用的鲁棒性。此外，一个元代理通过“构建-测试-改进”的循环，自动完成代理配置的合成、评估与优化，从而实现新任务、新环境和新工具栈下的快速代理开发。依托这些机制，在Confucius SDK上实例化的CCA在真实软件工程任务中表现出色。在SWE-Bench-Pro基准测试中，CCA取得了54.3%的Resolve@1领先性能，显著优于以往的编码代理。综上所述，Confucius SDK与CCA共同提供了一个透明、可扩展且可复现的AI代理基础，弥合了研究原型与生产级系统之间的差距，支持在工业规模下进行代理的开发与部署。"
  },
  {
    "date": "2025-12-11",
    "title": "RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI",
    "authors": "Weifan Guan, Huasen Xi, Chenxiao Zhang, Aosheng Li, Qinghao Hu, Jian Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10394v1",
    "source": "arXiv",
    "abstract": "Current embodied AI systems face severe engineering impediments, primarily characterized by poor cross-scenario adaptability, rigid inter-module coupling, and fragmented inference acceleration. To overcome these limitations, we propose RoboNeuron, a universal deployment framework for embodied intelligence. RoboNeuron is the first framework to deeply integrate the cognitive capabilities of Large Language Models (LLMs) and Vision-Language-Action (VLA) models with the real-time execution backbone of the Robot Operating System (ROS). We utilize the Model Context Protocol (MCP) as a semantic bridge, enabling the LLM to dynamically orchestrate underlying robotic tools. The framework establishes a highly modular architecture that strictly decouples sensing, reasoning, and control by leveraging ROS's unified communication interfaces. Crucially, we introduce an automated tool to translate ROS messages into callable MCP functions, significantly streamlining development. RoboNeuron significantly enhances cross-scenario adaptability and component flexibility, while establishing a systematic platform for horizontal performance benchmarking, laying a robust foundation for scalable real-world embodied applications.",
    "title_zh": "RoboNeuron：一个连接基础模型与ROS的模块化框架，用于具身人工智能",
    "abstract_zh": "当前具身人工智能系统面临严峻的工程挑战，主要表现为跨场景适应能力差、模块间耦合僵化以及推理加速碎片化。为克服这些局限，我们提出RoboNeuron——一种面向具身智能的通用部署框架。RoboNeuron是首个将大语言模型（LLMs）与视觉-语言-动作（VLA）模型的认知能力，深度集成于机器人操作系统（ROS）实时执行核心的框架。我们采用模型上下文协议（MCP）作为语义桥梁，使大语言模型能够动态调度底层机器人工具。该框架构建了高度模块化的架构，通过利用ROS统一的通信接口，严格解耦感知、推理与控制三大模块。尤为重要的是，我们引入了一种自动化工具，可将ROS消息自动转换为可调用的MCP函数，显著简化了开发流程。RoboNeuron大幅提升了系统的跨场景适应性与组件灵活性，同时建立了一个系统化的横向性能基准测试平台，为可扩展的真实世界具身应用奠定了坚实基础。"
  },
  {
    "date": "2025-12-11",
    "title": "Cross-modal Retrieval Models for Stripped Binary Analysis",
    "authors": "Guoqiang Chen, Lingyun Ying, Ziyang Song, Daguang Liu, Qiang Wang, Zhiqi Wang, Li Hu, Shaoyin Cheng, Weiming Zhang, Nenghai Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10393v1",
    "source": "arXiv",
    "abstract": "LLM-agent based binary code analysis has demonstrated significant potential across a wide range of software security scenarios, including vulnerability detection, malware analysis, etc. In agent workflow, however, retrieving the positive from thousands of stripped binary functions based on user query remains under-studied and challenging, as the absence of symbolic information distinguishes it from source code retrieval. In this paper, we introduce, BinSeek, the first two-stage cross-modal retrieval framework for stripped binary code analysis. It consists of two models: BinSeekEmbedding is trained on large-scale dataset to learn the semantic relevance of the binary code and the natural language description, furthermore, BinSeek-Reranker learns to carefully judge the relevance of the candidate code to the description with context augmentation. To this end, we built an LLM-based data synthesis pipeline to automate training construction, also deriving a domain benchmark for future research. Our evaluation results show that BinSeek achieved the state-of-the-art performance, surpassing the the same scale models by 31.42% in Rec@3 and 27.17% in MRR@3, as well as leading the advanced general-purpose models that have 16 times larger parameters.",
    "title_zh": "用于剥离二进制分析的跨模态检索模型",
    "abstract_zh": "基于大语言模型（LLM）代理的二进制代码分析在众多软件安全场景中展现出巨大潜力，涵盖漏洞检测、恶意软件分析等。然而，在代理工作流中，如何从成千上万经过剥离处理的二进制函数中根据用户查询准确检索出相关正例，仍是一个研究不足且极具挑战性的问题，因为缺乏符号信息使得其与源代码检索有本质区别。本文提出BinSeek，这是首个用于剥离二进制代码分析的两阶段跨模态检索框架。该框架包含两个核心模型：BinSeekEmbedding在大规模数据集上进行训练，以学习二进制代码与自然语言描述之间的语义关联；BinSeek-Reranker则通过引入上下文增强机制，精细判断候选代码与描述的相关性。为实现这一目标，我们构建了一个基于LLM的数据合成流水线，实现了训练数据的自动化生成，并建立了一个面向未来研究的领域基准。实验结果表明，BinSeek取得了当前最先进的性能，在Rec@3指标上超越同等规模模型31.42%，在MRR@3指标上提升27.17%，同时显著领先于参数量达其16倍的先进通用模型。"
  },
  {
    "date": "2025-12-11",
    "title": "OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification",
    "authors": "Zijian Wu, Lingkai Kong, Wenwei Zhang, Songyang Gao, Yuzhe Gu, Zhongrui Cai, Tianyou Ma, Yuhong Liu, Zhi Wang, Runyuan Ma, Guangyu Wang, Wei Li, Conghui He, Dahua Lin, Kai Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10756v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out OPV-Bench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.",
    "title_zh": "OPV：基于结果的流程验证器，用于高效长链思维验证",
    "abstract_zh": "大型语言模型（LLMs）在通过可验证奖励的强化学习（RLVR）解决复杂推理任务方面取得了显著进展。这一进步也离不开由可靠验证器实现的自动化监督。然而，当前基于结果的验证器（OVs）无法检查长链思维过程（CoTs）中不可靠的中间步骤；而基于过程的验证器（PVs）则受限于高质量标注数据稀缺的问题——由于人工标注成本高昂，难以获取足够的优质标注。因此，我们提出了**基于结果的过程验证器**（OPV），它通过对长CoTs中总结出的结果进行推理过程验证，实现了准确且高效的验证，并支持大规模标注。\n\n为增强所提出验证器的能力，我们采用了一种迭代式主动学习框架，结合专家标注，以较低的标注成本逐步提升OPV的验证能力。具体而言，在每一轮迭代中，当前最优OPV最不确定的样本将被专家标注，随后通过拒绝微调（RFT）和RLVR对新OPV进行训练，进入下一轮优化。大量实验表明，OPV表现出卓越的性能与广泛的适用性：在我们自建的OPV-Bench测试集上，其F1分数达到83.1，超越了参数量大得多的开源模型Qwen3-Max-Preview（76.3）。此外，OPV能有效识别合成数据集中的假阳性样本，其判断结果与专家评估高度一致。当与策略模型协同工作时，OPV持续带来性能提升，例如在AIME2025基准上，随着计算资源增加，DeepSeek-R1-Distill-Qwen-32B的准确率从55.2%提升至73.3%。"
  },
  {
    "date": "2025-12-11",
    "title": "How to Trick Your AI TA: A Systematic Study of Academic Jailbreaking in LLM Code Evaluation",
    "authors": "Devanshu Sahoo, Vasudev Majhi, Arjun Neekhra, Yash Sinha, Murari Mandal, Dhruv Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10415v1",
    "source": "arXiv",
    "abstract": "The use of Large Language Models (LLMs) as automatic judges for code evaluation is becoming increasingly prevalent in academic environments. But their reliability can be compromised by students who may employ adversarial prompting strategies in order to induce misgrading and secure undeserved academic advantages. In this paper, we present the first large-scale study of jailbreaking LLM-based automated code evaluators in academic context. Our contributions are: (i) We systematically adapt 20+ jailbreaking strategies for jailbreaking AI code evaluators in the academic context, defining a new class of attacks termed academic jailbreaking. (ii) We release a poisoned dataset of 25K adversarial student submissions, specifically designed for the academic code-evaluation setting, sourced from diverse real-world coursework and paired with rubrics and human-graded references, and (iii) In order to capture the multidimensional impact of academic jailbreaking, we systematically adapt and define three jailbreaking metrics (Jailbreak Success Rate, Score Inflation, and Harmfulness). (iv) We comprehensively evalulate the academic jailbreaking attacks using six LLMs. We find that these models exhibit significant vulnerability, particularly to persuasive and role-play-based attacks (up to 97% JSR). Our adversarial dataset and benchmark suite lay the groundwork for next-generation robust LLM-based evaluators in academic code assessment.",
    "title_zh": "如何欺骗你的AI助教：对大语言模型代码评估中学术越狱的系统性研究",
    "abstract_zh": "在学术环境中，使用大型语言模型（LLMs）作为自动代码评估的评判工具正变得越来越普遍。然而，学生的对抗性提示策略可能破坏这些模型的可靠性，从而诱导误判并获取不正当的学术优势。本文首次对学术情境下针对基于LLM的自动化代码评估系统进行大规模“越狱”攻击研究。我们的主要贡献包括：（i）我们系统性地适配了20余种越狱策略，专门用于在学术场景中攻破AI代码评估系统，定义了一类新型攻击——学术越狱；（ii）我们发布了一个包含2.5万条对抗性学生提交样本的污染数据集，该数据集专为学术代码评估场景设计，来源涵盖多种真实课程作业，并配有评分标准和人工评分参考；（iii）为了全面捕捉学术越狱攻击的多维度影响，我们系统性地引入并定义了三项越狱评估指标：越狱成功率（Jailbreak Success Rate）、分数虚增率（Score Inflation）和危害性（Harmfulness）；（iv）我们利用六种LLM对学术越狱攻击进行了全面评估，发现这些模型存在显著脆弱性，尤其容易受到说服性提示和角色扮演类攻击的影响（最高越狱成功率达97%）。我们发布的对抗性数据集与基准测试套件，为构建下一代在学术代码评估中具备更强鲁棒性的LLM评估系统奠定了基础。"
  },
  {
    "date": "2025-12-11",
    "title": "Zorya: Automated Concolic Execution of Single-Threaded Go Binaries",
    "authors": "Karolina Gorna, Nicolas Iooss, Yannick Seurin, Rida Khatoun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10799v1",
    "source": "arXiv",
    "abstract": "Go's adoption in critical infrastructure intensifies the need for systematic vulnerability detection, yet existing symbolic execution tools struggle with Go binaries due to runtime complexity and scalability challenges. In this work, we build upon Zorya, a concolic execution framework that translates Go binaries to Ghidra's P-Code intermediate representation to address these challenges. We added the detection of bugs in concretely not taken paths and a multi-layer filtering mechanism to concentrate symbolic reasoning on panic-relevant paths. Evaluation on five Go vulnerabilities demonstrates that panic-reachability gating achieves 1.8-3.9x speedups when filtering 33-70% of branches, and that Zorya detects all panics while existing tools detect at most two. Function-mode analysis proved essential for complex programs, running roughly two orders of magnitude faster than starting from main. This work establishes that specialized concolic execution can achieve practical vulnerability detection in language ecosystems with runtime safety checks.",
    "title_zh": "Zorya：单线程Go二进制文件的自动化符号执行",
    "abstract_zh": "Go语言在关键基础设施中的广泛应用，加剧了对系统化漏洞检测的需求。然而，现有的符号执行工具在处理Go二进制文件时面临运行时复杂性和可扩展性挑战。本文在Zorya——一个将Go二进制文件转换为Ghidra P-Code中间表示的协同执行框架——的基础上进行改进，以应对这些挑战。我们新增了对实际未执行路径中缺陷的检测能力，并引入多层过滤机制，使符号推理聚焦于可能导致panic的路径。在五个Go漏洞上的评估表明，通过panic可达性门控过滤33%-70%的分支，可实现1.8至3.9倍的速度提升；同时，Zorya能够检测出所有panic，而现有工具最多仅能发现两个。函数模式分析在复杂程序中表现尤为关键，其运行速度比从main函数开始的分析快约两个数量级。本研究证明，针对具有运行时安全检查的语言生态，专用的协同执行方法可以实现实用化的漏洞检测。"
  },
  {
    "date": "2025-12-11",
    "title": "UniCoR: Modality Collaboration for Robust Cross-Language Hybrid Code Retrieval",
    "authors": "Yang Yang, Li Kuang, Jiakun Liu, Zhongxin Liu, Yingjie Xia, David Lo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10452v1",
    "source": "arXiv",
    "abstract": "Effective code retrieval is indispensable and it has become an important paradigm to search code in hybrid mode using both natural language and code snippets. Nevertheless, it remains unclear whether existing approaches can effectively leverage such hybrid queries, particularly in cross-language contexts. We conduct a comprehensive empirical study of representative code models and reveal three challenges: (1) insufficient semantic understanding; (2) inefficient fusion in hybrid code retrieval; and (3) weak generalization in cross-language scenarios. To address these challenges, we propose UniCoR, a novel self-supervised framework that learns Unified Code Representations framework designed to learn unified and robust code representations. Firstly, we design a multi-perspective supervised contrastive learning module to enhance semantic understanding and modality fusion. It aligns representations from multiple perspectives, including code-to-code, natural language-to-code, and natural language-to-natural language, enforcing the model to capture a semantic essence among modalities. Secondly, we introduce a representation distribution consistency learning module to improve cross-language generalization, which explicitly aligns the feature distributions of different programming languages, enabling language-agnostic representation learning. Extensive experiments on both empirical benchmark and large-scale benchmark show that UniCoR outperforms all baseline models, achieving an average improvement of 8.64% in MRR and 11.54% in MAP over the best-performing baseline. Furthermore, UniCoR exhibits stability in hybrid code retrieval and generalization capability in cross-language scenarios.",
    "title_zh": "UniCoR：用于鲁棒跨语言混合代码检索的模态协作",
    "abstract_zh": "有效的代码检索不可或缺，且利用自然语言与代码片段相结合的混合模式进行代码搜索，已成为一种重要范式。然而，现有方法能否有效利用此类混合查询，尤其是在跨语言场景下，仍不明确。我们对代表性代码模型进行了全面的实证研究，揭示了三大挑战：（1）语义理解不足；（2）混合代码检索中的融合效率低下；（3）在跨语言场景下的泛化能力弱。为应对这些挑战，我们提出 UniCoR——一种新颖的自监督框架，旨在学习统一且鲁棒的代码表示。首先，我们设计了一种多视角监督对比学习模块，以增强语义理解与模态融合能力。该模块从多个角度对齐表示，包括代码-代码、自然语言-代码以及自然语言-自然语言之间的映射，强制模型捕捉不同模态间的本质语义关联。其次，我们引入了表示分布一致性学习模块，以提升跨语言泛化能力，通过显式对齐不同编程语言的特征分布，实现无语言依赖的表示学习。在多个基准数据集上的大量实验表明，UniCoR 在所有基线模型中表现最优，在 MRR 上平均提升 8.64%，在 MAP 上平均提升 11.54%。此外，UniCoR 在混合代码检索中表现出良好的稳定性，并具备出色的跨语言泛化能力。"
  },
  {
    "date": "2025-12-11",
    "title": "Towards Cumulative Abstract Semantics via Handlers",
    "authors": "Cade Lueker, Andrew Fox, Bor-Yuh Evan Chang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10861v1",
    "source": "arXiv",
    "abstract": "We consider the problem of modularizing control flow in a generic abstract interpretation framework. A generic abstract interpretation framework is not truly flexible if it does not allow interpreting with different path- and flow-sensitivities, by going forwards or backwards, and over- or under-approximately. Most interpreters inherently intertwine syntax and semantics, making the implementation antagonistic to modularity. Current approaches to modular designs require the use of complex data structures (e.g., monad transformers), providing modularity but often proving unwieldy (e.g., lifts). We observe that leveraging scoped effects within an interpreter facilitates the accumulation of semantic fragments against a fixed syntax. In this paper, we define cumulative abstract semantics, illustrating the potential for creating multiple dynamic evaluators and static analyses from one interpreter. This modularity is achieved by grouping effects into two categories: syntax elimination and domain-semantic introduction handlers. Our contribution shows the benefits of using effects as an instrument for designing a clean, elegant, and modular abstract interpretation framework.",
    "title_zh": "通过句柄实现累积抽象语义",
    "abstract_zh": "我们研究在通用抽象解释框架中对控制流进行模块化的问题。如果一个通用的抽象解释框架无法支持以不同路径敏感性与流敏感性进行解释，既可正向也可反向执行，既可过度近似也可不足近似，那么它就并非真正灵活。大多数解释器在实现时不可避免地将语法与语义交织在一起，导致其设计不利于模块化。目前的模块化设计方法通常依赖于复杂的数据结构（如单子变换器），虽然实现了模块化，但往往难以使用（例如存在“提升”操作）。我们观察到，在解释器中利用作用域效应，能够基于固定的语法累积语义片段。本文定义了累积抽象语义，展示了如何从单一解释器中构建多个动态求值器和静态分析工具。这种模块化通过将效应分为两类来实现：语法消除处理程序和领域语义引入处理程序。我们的贡献表明，使用效应作为设计工具，能够构建出清晰、优雅且模块化的抽象解释框架。"
  },
  {
    "date": "2025-12-11",
    "title": "Interpretable and Steerable Concept Bottleneck Sparse Autoencoders",
    "authors": "Akshay Kulkarni, Tsui-Wei Weng, Vivek Narayanaswamy, Shusen Liu, Wesam A. Sakla, Kowshik Thopalli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10805v1",
    "source": "arXiv",
    "abstract": "Sparse autoencoders (SAEs) promise a unified approach for mechanistic interpretability, concept discovery, and model steering in LLMs and LVLMs. However, realizing this potential requires that the learned features be both interpretable and steerable. To that end, we introduce two new computationally inexpensive interpretability and steerability metrics and conduct a systematic analysis on LVLMs. Our analysis uncovers two observations; (i) a majority of SAE neurons exhibit either low interpretability or low steerability or both, rendering them ineffective for downstream use; and (ii) due to the unsupervised nature of SAEs, user-desired concepts are often absent in the learned dictionary, thus limiting their practical utility. To address these limitations, we propose Concept Bottleneck Sparse Autoencoders (CB-SAE) - a novel post-hoc framework that prunes low-utility neurons and augments the latent space with a lightweight concept bottleneck aligned to a user-defined concept set. The resulting CB-SAE improves interpretability by +32.1% and steerability by +14.5% across LVLMs and image generation tasks. We will make our code and model weights available.",
    "title_zh": "可解释且可调控的概念瓶颈稀疏自编码器",
    "abstract_zh": "稀疏自编码器（SAEs）为大语言模型（LLMs）和视觉语言模型（LVLMs）的机制可解释性、概念发现以及模型调控提供了一种统一的方法。然而，要实现这一潜力，所学习到的特征必须同时具备可解释性和可调控性。为此，我们提出了两种计算成本极低的可解释性与可调控性度量指标，并对LVLM进行了系统性分析。我们的分析揭示了两个关键发现：（i）大多数SAE神经元表现出较低的可解释性或较低的可调控性，或两者兼有，导致其在下游任务中效果不佳；（ii）由于SAEs本质上是无监督的，用户期望的概念往往未出现在所学的特征词典中，从而限制了其实际应用价值。\n\n为解决上述局限，我们提出了一种名为“概念瓶颈稀疏自编码器”（CB-SAE）的新后处理框架：该框架通过剪枝低效神经元，并在潜在空间中引入一个轻量级的概念瓶颈模块，使其与用户定义的概念集合对齐。实验结果表明，CB-SAE在各类LVLM及图像生成任务中，将可解释性提升32.1%，可调控性提升14.5%。相关代码与模型权重将公开发布。"
  },
  {
    "date": "2025-12-11",
    "title": "PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code",
    "authors": "Itay Dreyfuss, Antonio Abu Nassar, Samuel Ackerman, Axel Ben David, Rami Katan, Orna Raz, Marcel Zalmanovici",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10713v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM)-based code assistants have emerged as a powerful application of generative AI, demonstrating impressive capabilities in code generation and comprehension. A key requirement for these systems is their ability to accurately follow user instructions. We present Precise Automatically Checked Instruction Following In Code (PACIFIC), a novel framework designed to automatically generate benchmarks that rigorously assess sequential instruction-following and code dry-running capabilities in LLMs, while allowing control over benchmark difficulty. PACIFIC produces benchmark variants with clearly defined expected outputs, enabling straightforward and reliable evaluation through simple output comparisons. In contrast to existing approaches that often rely on tool usage or agentic behavior, our work isolates and evaluates the LLM's intrinsic ability to reason through code behavior step-by-step without execution (dry running) and to follow instructions. Furthermore, our framework mitigates training data contamination by facilitating effortless generation of novel benchmark variations. We validate our framework by generating a suite of benchmarks spanning a range of difficulty levels and evaluating multiple state-of-the-art LLMs. Our results demonstrate that PACIFIC can produce increasingly challenging benchmarks that effectively differentiate instruction-following and dry running capabilities, even among advanced models. Overall, our framework offers a scalable, contamination-resilient methodology for assessing core competencies of LLMs in code-related tasks.",
    "title_zh": "PACIFIC：一种用于生成基准测试的框架，以检查代码中精确的自动验证指令遵循情况",
    "abstract_zh": "基于大语言模型（LLM）的代码助手已成为生成式人工智能的一项强大应用，在代码生成与理解方面展现出令人瞩目的能力。这类系统的一个关键要求是能够准确遵循用户指令。本文提出了一种名为“精确自动验证指令遵循与代码干运行能力”（Precise Automatically Checked Instruction Following In Code, PACIFIC）的新框架，该框架可自动生成基准测试集，严格评估大语言模型在序列化指令遵循和代码干运行方面的性能，同时支持对基准难度的灵活控制。PACIFIC生成的基准测试变体具有明确且清晰的预期输出，使得评估过程可通过简单的输出对比实现，操作简便且结果可靠。\n\n与现有方法通常依赖工具调用或代理行为不同，我们的工作专注于独立评估大语言模型在不实际执行代码的前提下，逐步推理代码行为（即“干运行”）以及准确理解并遵循指令的能力。此外，该框架通过轻松生成全新基准变体，有效避免了训练数据污染问题。我们通过构建涵盖多种难度级别的基准测试套件，并对多个前沿大语言模型进行评估，验证了该框架的有效性。实验结果表明，PACIFIC能够生成越来越具挑战性的测试任务，即使在先进模型之间也能有效区分其在指令遵循与代码干运行方面的真实能力差异。\n\n总体而言，PACIFIC提供了一种可扩展、抗数据污染的评估方法，能够高效衡量大语言模型在代码相关任务中的核心能力。"
  },
  {
    "date": "2025-12-11",
    "title": "Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution",
    "authors": "Zouying Cao, Jiaji Deng, Li Yu, Weikang Zhou, Zhaoyang Liu, Bolin Ding, Hai Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10696v1",
    "source": "arXiv",
    "abstract": "Procedural memory enables large language model (LLM) agents to internalize \"how-to\" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a \"passive accumulation\" paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose $\\textbf{ReMe}$ ($\\textit{Remember Me, Refine Me}$), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1) $\\textit{multi-faceted distillation}$, which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2) $\\textit{context-adaptive reuse}$, which tailors historical insights to new contexts via scenario-aware indexing; and 3) $\\textit{utility-based refinement}$, which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the $\\texttt{reme.library}$ dataset to facilitate further research.",
    "title_zh": "记住我，重塑我：一种驱动经验的智能体演化的动态过程记忆框架",
    "abstract_zh": "过程性记忆使大型语言模型（LLM）代理能够内化“如何做”的知识，理论上可减少重复的试错。然而，现有框架大多遵循“被动积累”范式，将记忆视为静态的、仅可追加的档案库。为弥合静态存储与动态推理之间的鸿沟，我们提出 $\\textbf{ReMe}$（$\\textit{Remember Me, Refine Me}$），一个以经验驱动的代理进化综合框架。ReMe 在记忆生命周期中通过三项创新机制实现突破：1）$\\textit{多维度提炼}$，通过识别成功模式、分析失败诱因并生成对比洞察，提取细粒度的经验；2）$\\textit{上下文自适应复用}$，基于场景感知的索引机制，将历史经验适配至新情境；3）$\\textit{基于效用的精炼}$，自主添加有效记忆并剔除过时内容，以保持一个紧凑且高质量的经验池。在 BFCL-V3 和 AppWorld 上的大量实验表明，ReMe 在代理记忆系统方面建立了新的性能标杆。尤为重要的是，我们观察到显著的内存扩展效应：配备 ReMe 的 Qwen3-8B 表现优于更大的无记忆版本 Qwen3-14B，这表明自演化记忆为持续学习提供了一条计算高效的路径。我们已开源代码及 $\\texttt{reme.library}$ 数据集，以推动后续研究。"
  },
  {
    "date": "2025-12-11",
    "title": "L2 Ethernet Switch VLSI Implementation",
    "authors": "Aniruddh Mishra, Benjamin Oommen, Jimmy Liang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10318v1",
    "source": "arXiv",
    "abstract": "Ethernet switches are foundational to the global internet infrastructure. These devices route packets of data on a local area network between source addresses to destination media access control addresses. On the L2 layer of the Open Systems Interconnections model, Ethernet switches take in digitized data from a Media Independent Interface and send it to the corresponding output port for the destination address. Switches need to handle parallel input and output streams from each port, prioritizing throughput, efficiency, and packet integrity. Due to the confidential nature of the networking device industry, there do not exist many open source implementations of switching fabrics. We propose an open source design for an L2 Ethernet switch along with the power, performance, and area tradeoffs for architecture decisions.",
    "title_zh": "L2以太网交换机VLSI实现",
    "abstract_zh": "以太网交换机是全球互联网基础设施的基石。这些设备在局域网中负责将数据包从源地址路由至目标媒体访问控制（MAC）地址。在开放系统互连（OSI）模型的第二层（L2），以太网交换机接收来自介质无关接口（MII）的数字化数据，并将其发送到对应的目标地址输出端口。交换机需要处理每个端口的并行输入与输出数据流，同时兼顾吞吐量、效率和数据包完整性。由于网络设备行业的保密性较强，目前公开的交换结构开源实现非常有限。本文提出了一种开源的L2以太网交换机设计方案，并分析了架构决策在功耗、性能与面积之间的权衡关系。"
  },
  {
    "date": "2025-12-11",
    "title": "SemanticBBV: A Semantic Signature for Cross-Program Knowledge Reuse in Microarchitecture Simulation",
    "authors": "Zhenguo Liu, Chengao Shi, Chen Ding, Jiang Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10231v1",
    "source": "arXiv",
    "abstract": "For decades, sampling-based techniques have been the de facto standard for accelerating microarchitecture simulation, with the Basic Block Vector (BBV) serving as the cornerstone program representation. Yet, the BBV's fundamental limitations: order-dependent IDs that prevent cross-program knowledge reuse and a lack of semantic content predictive of hardware performance have left a massive potential for optimization untapped. To address these gaps, we introduce SemanticBBV, a novel, two-stage framework that generates robust, performance-aware signatures for cross-program simulation reuse. First, a lightweight RWKV-based semantic encoder transforms assembly basic blocks into rich Basic Block Embeddings (BBEs), capturing deep functional semantics. Second, an order-invariant Set Transformer aggregates these BBEs, weighted by execution frequency, into a final signature. Crucially, this stage is co-trained with a dual objective: a triplet loss for signature distinctiveness and a Cycles Per Instruction (CPI) regression task, directly imbuing the signature with performance sensitivity. Our evaluation demonstrates that SemanticBBV not only matches traditional BBVs in single-program accuracy but also enables unprecedented cross-program analysis. By simulating just 14 universal program points, we estimated the performance of ten SPEC CPU benchmarks with 86.3% average accuracy, achieving a 7143x simulation speedup. Furthermore, the signature shows strong adaptability to new microarchitectures with minimal fine-tuning.",
    "title_zh": "SemanticBBV：一种用于微架构模拟中跨程序知识复用的语义签名",
    "abstract_zh": "数十年来，基于采样的技术一直是加速微架构模拟的行业标准，其中基本块向量（BBV）作为程序表示的核心。然而，BBV存在根本性局限：依赖顺序的ID导致跨程序知识无法复用，且缺乏能够预测硬件性能的语义信息，使得大量优化潜力长期未被挖掘。为解决这些不足，我们提出SemanticBBV——一种新颖的两阶段框架，可生成鲁棒且具备性能感知能力的签名，实现跨程序模拟复用。首先，一个轻量级的RWKV语义编码器将汇编基本块转换为丰富的基本块嵌入（BBE），充分捕捉深层功能语义；其次，一个与顺序无关的Set Transformer对这些BBE进行聚合，按执行频率加权，生成最终签名。关键在于，该阶段通过双重目标联合训练：采用三元组损失确保签名的区分性，同时结合每条指令周期数（CPI）回归任务，直接赋予签名对性能的敏感度。评估结果表明，SemanticBBV不仅在单程序精度上达到传统BBV水平，更实现了前所未有的跨程序分析能力。仅通过模拟14个通用程序点，即可对十个SPEC CPU基准测试的性能进行估算，平均准确率达86.3%，模拟速度提升高达7143倍。此外，该签名在适应新微架构时表现出强大的泛化能力，仅需极少微调即可实现良好效果。"
  },
  {
    "date": "2025-12-11",
    "title": "ATLAS: Automated Toolkit for Large-Scale Verified Code Synthesis",
    "authors": "Mantas Baksys, Stefan Zetzsche, Olivier Bouissou, Remi Delmas, Soonho Kong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10173v1",
    "source": "arXiv",
    "abstract": "Large language models have shown potential for program verification, but progress is hindered by the scarcity of verified code for training. We present ATLAS, an automated pipeline that synthesizes verified programs at scale to address this data bottleneck. ATLAS generates complete Dafny programs with specifications, implementations, and proofs, producing 2.7K verified programs from which we extract over 19K training examples--more than 7 per verified program--by decomposing the synthesis process into multiple specialized tasks. Fine-tuning Qwen 2.5 7B Coder on this dataset produces substantial gains: +23 percentage points on DafnyBench and +50 percentage points on DafnySynthesis. These results demonstrate that synthetic verified code can effectively enhance LLM capabilities for formal verification.",
    "title_zh": "ATLAS：大规模可验证代码合成的自动化工具包",
    "abstract_zh": "大型语言模型在程序验证方面展现出巨大潜力，但其进展受到可用于训练的已验证代码稀缺性的制约。我们提出了ATLAS，一个自动化的流水线，能够大规模合成已验证程序，以解决这一数据瓶颈问题。ATLAS能够生成包含规范、实现和证明的完整Dafny程序，从2,700个已验证程序中提取出超过19,000个训练样本——平均每份已验证程序产生超过7个训练示例——通过将合成过程分解为多个专业化任务来实现。在该数据集上对Qwen 2.5 7B Coder进行微调后，性能显著提升：在DafnyBench上提升23个百分点，在DafnySynthesis上提升50个百分点。这些结果表明，合成的已验证代码能够有效增强大语言模型在形式化验证方面的能力。"
  },
  {
    "date": "2025-12-11",
    "title": "Guided Transfer Learning for Discrete Diffusion Models",
    "authors": "Julian Kleutgens, Claudio Battiloro, Lingkai Kong, Benjamin Grewe, Francesca Dominici, Mauricio Tec",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10877v1",
    "source": "arXiv",
    "abstract": "Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domains. Transfer learning is the natural way to adapt pretrained discrete diffusion models, but current methods require fine-tuning large diffusion models, which is computationally expensive and often impractical. Building on ratio-based transfer learning for continuous diffusion, we provide Guided Transfer Learning for discrete diffusion models (GTL). This enables sampling from a target distribution without modifying the pretrained denoiser. The same guidance formulation applies to both discrete-time diffusion and continuous-time score-based discrete diffusion, yielding a unified treatment. Guided discrete diffusion often requires many forward passes of the guidance network, which becomes impractical for large vocabularies and long sequences. To address this, we further present an efficient guided sampler that concentrates evaluations on planner-selected positions and top candidate tokens, thus lowering sampling time and computation. This makes guided language modeling practical at scale for large vocabularies and long sequences. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling, and provide empirical analyses of its behavior.",
    "title_zh": "用于离散扩散模型的引导式迁移学习",
    "abstract_zh": "离散扩散模型在语言及其他离散领域中表现出色，为自回归模型提供了一种强有力的替代方案。然而，其优异性能依赖于大规模训练数据，而这些数据在获取时成本高昂或存在风险，尤其是在适应新领域时尤为明显。迁移学习是微调预训练离散扩散模型的自然途径，但现有方法通常需要对大型扩散模型进行微调，这在计算上代价巨大，往往不切实际。基于连续扩散模型中的比率型迁移学习思想，我们提出了针对离散扩散模型的引导式迁移学习（Guided Transfer Learning, GTL）。该方法能够在不修改预训练去噪器的前提下，实现从目标分布中采样。相同的引导公式同时适用于离散时间扩散模型和连续时间基于得分的离散扩散模型，从而实现了统一处理。然而，引导式离散扩散通常需要多次前向传播引导网络，在词汇量大且序列长的情况下变得不切实际。为此，我们进一步提出一种高效的引导采样器，该采样器将计算集中在规划器选定的位置以及候选概率最高的词元上，显著降低了采样时间和计算开销。这一改进使得在大规模词汇量和长序列场景下实现引导式语言建模成为可能。我们在序列数据上对GTL进行了评估，包括合成马尔可夫链和语言建模任务，并提供了对其行为的实证分析。"
  },
  {
    "date": "2025-12-11",
    "title": "Reverse Thinking Enhances Missing Information Detection in Large Language Models",
    "authors": "Yuxin Liu, Chaojie Gu, Yihang Zhang, Bin Qian, Shibo He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10273v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various reasoning tasks, yet they often struggle with problems involving missing information, exhibiting issues such as incomplete responses, factual errors, and hallucinations. While forward reasoning approaches like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) have shown success in structured problem-solving, they frequently fail to systematically identify and recover omitted information. In this paper, we explore the potential of reverse thinking methodologies to enhance LLMs' performance on missing information detection tasks. Drawing inspiration from recent work on backward reasoning, we propose a novel framework that guides LLMs through reverse thinking to identify necessary conditions and pinpoint missing elements. Our approach transforms the challenging task of missing information identification into a more manageable backward reasoning problem, significantly improving model accuracy. Experimental results demonstrate that our reverse thinking approach achieves substantial performance gains compared to traditional forward reasoning methods, providing a promising direction for enhancing LLMs' logical completeness and reasoning robustness.",
    "title_zh": "逆向思维提升大语言模型对缺失信息的检测能力",
    "abstract_zh": "大型语言模型（LLMs）在各类推理任务中展现了卓越的能力，但在涉及信息缺失的问题上往往表现不佳，常出现回答不完整、事实错误以及幻觉等问题。尽管正向推理方法如思维链（Chain-of-Thought, CoT）和思维树（Tree-of-Thought, ToT）在结构化问题求解中取得了成功，但它们通常无法系统性地识别并恢复遗漏的信息。本文探讨了逆向思维方法在提升LLMs处理信息缺失检测任务中的潜力。受近期关于逆向推理研究的启发，我们提出了一种新颖的框架，引导LLMs通过逆向思考来识别必要条件，并精确定位缺失要素。该方法将原本复杂的缺失信息识别任务转化为更易于处理的逆向推理问题，显著提升了模型的准确性。实验结果表明，与传统的正向推理方法相比，我们的逆向思维方法在性能上实现了显著提升，为增强LLMs的逻辑完整性与推理鲁棒性提供了极具前景的新方向。"
  },
  {
    "date": "2025-12-11",
    "title": "Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMs",
    "authors": "Minghao LI, Ruihang Wang, Rui Tan, Yonggang Wen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10611v1",
    "source": "arXiv",
    "abstract": "Data center (DC) infrastructure serves as the backbone to support the escalating demand for computing capacity. Traditional design methodologies that blend human expertise with specialized simulation tools scale poorly with the increasing system complexity. Recent studies adopt generative artificial intelligence to design plausible human-centric indoor layouts. However, they do not consider the underlying physics, making them unsuitable for the DC design that sets quantifiable operational objectives and strict physical constraints. To bridge the gap, we propose Phythesis, a novel framework that synergizes large language models (LLMs) and physics-guided evolutionary optimization to automate simulation-ready (SimReady) scene synthesis for energy-efficient DC design. Phythesis employs an iterative bi-level optimization architecture, where (i) the LLM-driven optimization level generates physically plausible three-dimensional layouts and self-criticizes them to refine the scene topology, and (ii) the physics-informed optimization level identifies the optimal asset parameters and selects the best asset combination. Experiments on three generation scales show that Phythesis achieves 57.3% generation success rate increase and 11.5% power usage effectiveness (PUE) improvement, compared with the vanilla LLM-based solution.",
    "title_zh": "物理引导的进化场景合成：基于大语言模型实现能效优化的数据中心设计",
    "abstract_zh": "数据中心（DC）基础设施是支撑计算能力需求持续增长的基石。传统的设计方法依赖人类专家经验与专用仿真工具相结合，但随着系统复杂性的增加，其可扩展性较差。近期研究采用生成式人工智能来设计符合人体工程学的室内布局，然而这些方法未考虑底层物理规律，因此不适用于数据中心设计——后者需要设定可量化的运行目标和严格的物理约束。为弥合这一差距，我们提出了Phythesis，一种新颖的框架，通过融合大型语言模型（LLM）与物理引导的进化优化，实现面向能效优化的数据中心设计的仿真就绪（SimReady）场景自动化生成。Phythesis采用迭代式的双层优化架构：（i）由大语言模型驱动的优化层生成物理上合理的三维布局，并通过自我批判机制不断优化场景拓扑；（ii）基于物理信息的优化层则确定最优设备参数并选择最佳设备组合。在三个不同规模的生成实验中，Phythesis相较于基础的LLM方案，实现了57.3%的生成成功率提升以及11.5%的电源使用效率（PUE）改善。"
  },
  {
    "date": "2025-12-11",
    "title": "Natural Language Interface for Firewall Configuration",
    "authors": "F. Taghiyev, A. Aslanbayli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10789v1",
    "source": "arXiv",
    "abstract": "This paper presents the design and prototype implementation of a natural language interface for configuring enterprise firewalls. The framework allows administrators to express access control policies in plain language, which are then translated into vendor specific configurations. A compact schema bound intermediate representation separates human intent from device syntax and in the current prototype compiles to Palo Alto PAN OS command line configuration while remaining extensible to other platforms. Large language models are used only as assistive parsers that generate typed intermediate representation objects, while compilation and enforcement remain deterministic. The prototype integrates three validation layers, namely a static linter that checks structural and vendor specific constraints, a safety gate that blocks overly permissive rules such as any to any allows, and a Batfish based simulator that validates configuration syntax and referential integrity against a synthetic device model. The paper describes the architecture, implementation, and test methodology on synthetic network context datasets and discusses how this approach can evolve into a scalable auditable and human centered workflow for firewall policy management.",
    "title_zh": "防火墙配置的自然语言接口",
    "abstract_zh": "本文介绍了面向企业防火墙配置的自然语言接口的设计与原型实现。该框架使管理员能够以自然语言表达访问控制策略，系统将这些表述自动转换为特定厂商的配置格式。通过一个紧凑的、与具体设备语法解耦的中间表示（schema-bound intermediate representation），系统能够清晰分离人类意图与设备命令行语法。在当前的原型中，该中间表示可编译为 Palo Alto PAN OS 的命令行配置，同时具备扩展至其他平台的潜力。大型语言模型仅作为辅助解析器使用，用于生成带有类型的中间表示对象，而编译和执行过程始终保持确定性。原型系统集成了三层验证机制：静态检查器用于验证结构及厂商特定约束；安全闸门可阻止过于宽松的规则（如“任何到任何”的允许规则）；基于 Batfish 的模拟器则用于验证配置语法正确性及引用完整性，其依据是一个合成的设备模型。本文详细描述了系统的架构、实现方法以及在合成网络上下文数据集上的测试流程，并探讨了该方法如何演进为一种可扩展、可审计且以人为本的防火墙策略管理流程。"
  },
  {
    "date": "2025-12-11",
    "title": "Multi-Granular Node Pruning for Circuit Discovery",
    "authors": "Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, A. B. Siddique",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10903v1",
    "source": "arXiv",
    "abstract": "Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.",
    "title_zh": "电路发现的多粒度节点剪枝",
    "abstract_zh": "电路发现旨在识别大型语言模型（LLM）中负责特定行为的最小子网络。现有方法主要依赖于迭代式的边剪枝，计算成本高，且仅限于粗粒度单元（如注意力头或MLP模块），忽略了更细粒度的结构，例如单个神经元。我们提出了一种基于节点级别的剪枝框架，用于解决可扩展性与粒度限制的问题。该方法在统一的优化目标下，引入了多层级粒度的可学习掩码，从整个模块到单个神经元均可实现精细控制。通过针对不同粒度设计的稀疏性惩罚项，指导剪枝过程，从而在一次微调运行中实现全面压缩。实验表明，我们的方法所识别出的电路在节点数量上比以往方法更小；此外，我们还证明了许多被粗粒度方法认为重要的神经元实际上并不关键，但模型任务性能仍得以保持。更重要的是，我们的方法具有显著更低的内存开销，仅为原有方法的1/5至1/10，因为它无需在内存中保存中间激活值即可运行。"
  },
  {
    "date": "2025-12-11",
    "title": "Dynamics of Agentic Loops in Large Language Models: A Geometric Theory of Trajectories",
    "authors": "Nicolas Tacheny",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10350v1",
    "source": "arXiv",
    "abstract": "Agentic systems built on large language models operate through recursive feedback loops, where each output becomes the next input. Yet the geometric behavior of these agentic loops (whether they converge, diverge, or exhibit more complex dynamics) remains poorly understood. This paper introduces a geometric framework for analyzing agentic trajectories in semantic embedding space, treating iterative transformations as discrete dynamical systems. We distinguish the artifact space, where linguistic transformations occur, from the embedding space, where geometric measurements are performed. Because cosine similarity is biased by embedding anisotropy, we introduce an isotonic calibration that eliminates systematic bias and aligns similarities with human semantic judgments while preserving high local stability. This enables rigorous measurement of trajectories, clusters and attractors. Through controlled experiments on singular agentic loops, we identify two fundamental regimes. A contractive rewriting loop converges toward a stable attractor with decreasing dispersion, while an exploratory summarize and negate loop produces unbounded divergence with no cluster formation. These regimes display qualitatively distinct geometric signatures of contraction and expansion. Our results show that prompt design directly governs the dynamical regime of an agentic loop, enabling systematic control of convergence, divergence and trajectory structure in iterative LLM transformations.",
    "title_zh": "大语言模型中代理循环的动力学：轨迹的几何理论",
    "abstract_zh": "基于大型语言模型构建的代理系统通过递归反馈环运行，其中每一次输出都成为下一次输入。然而，这些代理循环的几何行为（是否收敛、发散或表现出更复杂的动态）仍缺乏充分理解。本文提出一个几何框架，用于分析语义嵌入空间中的代理轨迹，将迭代变换视为离散动力系统。我们区分了语言转换发生的“表征空间”与进行几何测量的“嵌入空间”。由于余弦相似度受嵌入异质性的影响而存在偏差，我们引入了一种各向同性校准方法，消除了系统性偏差，使相似度与人类语义判断对齐，同时保持高度局部稳定性。这一方法使得对轨迹、聚类和吸引子的严格度量成为可能。通过对单一代理循环的受控实验，我们识别出两种基本动态模式：一种是收缩重写循环，其趋向于一个稳定的吸引子，且分散度持续减小；另一种是探索性地总结并否定的循环，导致无界发散，无法形成聚类。这两种模式呈现出收缩与扩张的定性上截然不同的几何特征。我们的研究结果表明，提示设计直接决定了代理循环的动力学状态，从而实现了对迭代大模型变换中收敛性、发散性及轨迹结构的系统性控制。"
  },
  {
    "date": "2025-12-11",
    "title": "Studying and Automating Issue Resolution for Software Quality",
    "authors": "Antu Saha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10238v1",
    "source": "arXiv",
    "abstract": "Effective issue resolution is crucial for maintaining software quality. Yet developers frequently encounter challenges such as low-quality issue reports, limited understanding of real-world workflows, and a lack of automated support. This research aims to address these challenges through three complementary directions. First, we enhance issue report quality by proposing techniques that leverage LLM reasoning and application-specific information. Second, we empirically characterize developer workflows in both traditional and AI-augmented systems. Third, we automate cognitively demanding resolution tasks, including buggy UI localization and solution identification, through ML, DL, and LLM-based approaches. Together, our work delivers empirical insights, practical tools, and automated methods to advance AI-driven issue resolution, supporting more maintainable and high-quality software systems.",
    "title_zh": "软件质量中的问题研究与自动解决",
    "abstract_zh": "高效的问题解决对于保障软件质量至关重要。然而，开发者常常面临问题报告质量低、对实际工作流程理解有限以及缺乏自动化支持等挑战。本研究旨在通过三个互补方向应对这些挑战：首先，我们提出利用大语言模型（LLM）推理能力与特定应用信息相结合的技术，以提升问题报告的质量；其次，我们通过实证研究刻画了传统系统与AI增强型系统中开发者的实际工作流程；第三，我们采用机器学习、深度学习及基于LLM的方法，自动完成一些认知负担较重的修复任务，如存在缺陷的用户界面定位和解决方案识别。综上所述，我们的工作提供了实证洞察、实用工具以及自动化方法，推动了以AI驱动的问题解决发展，助力构建更可维护、高质量的软件系统。"
  },
  {
    "date": "2025-12-11",
    "title": "MiniF2F-Dafny: LLM-Guided Mathematical Theorem Proving via Auto-Active Verification",
    "authors": "Mantas Baksys, Stefan Zetzsche, Olivier Bouissou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10187v1",
    "source": "arXiv",
    "abstract": "We present miniF2F-Dafny, the first translation of the mathematical reasoning benchmark miniF2F to an automated theorem prover: Dafny. Previously, the benchmark existed only in interactive theorem provers (Lean, Isabelle, HOL Light, Metamath). We find that Dafny's automation verifies 99/244 (40.6%) of the test set and 109/244 (44.7%) of the validation set with empty proofs--requiring no manual proof steps. For problems where empty proofs fail, we evaluate 12 off-the-shelf LLMs on providing proof hints. The best model we test achieves 55.7% pass@4 success rate employing iterative error correction. These preliminary results highlight an effective division of labor: LLMs provide high-level guidance while automation handles low-level details. Our benchmark can be found on GitHub at http://github.com/dafny-lang/miniF2F .",
    "title_zh": "MiniF2F-Dafny：通过自动主动验证实现大语言模型引导的数学定理证明",
    "abstract_zh": "我们提出了 miniF2F-Dafny，这是首个将数学推理基准 miniF2F 翻译至自动化定理证明器 Dafny 的成果。此前，该基准仅存在于交互式定理证明器（Lean、Isabelle、HOL Light、Metamath）中。我们发现，Dafny 的自动化能力能够以空证明（即无需任何手动证明步骤）验证测试集中的 99/244（40.6%）和验证集中的 109/244（44.7%）的问题。对于空证明无法解决的问题，我们评估了 12 个现成的大型语言模型（LLM）在提供证明提示方面的表现。我们测试中表现最佳的模型通过迭代错误修正，达到了 55.7% 的 pass@4 成功率。这些初步结果凸显出一种高效的分工模式：大型语言模型提供高层次的指导，而自动化系统负责处理低层次的细节。我们的基准数据可在 GitHub 上获取：http://github.com/dafny-lang/miniF2F。"
  },
  {
    "date": "2025-12-11",
    "title": "Decoding Human-LLM Collaboration in Coding: An Empirical Study of Multi-Turn Conversations in the Wild",
    "authors": "Binquan Zhang, Li Zhang, Haoyuan Zhang, Fang Liu, Song Wang, Bo Shen, An Fu, Lin Shi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10493v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly acting as dynamic conversational interfaces, supporting multi-turn interactions that mimic human-like conversation and facilitate complex tasks like coding. While datasets such as LMSYS-Chat-1M and WildChat capture real-world user-LLM conversations, few studies systematically explore the mechanisms of human-LLM collaboration in coding scenarios. What tortuous paths do users experience during the interaction process? How well do the LLMs follow instructions? Are users satisfied? In this paper, we conduct an empirical analysis on human-LLM coding collaboration using LMSYS-Chat-1M and WildChat datasets to explore the human-LLM collaboration mechanism, LLMs' instruction following ability, and human satisfaction. This study yields interesting findings: 1) Task types shape interaction patterns(linear, star and tree), with code quality optimization favoring linear patterns, design-driven tasks leaning toward tree structures, and queries preferring star patterns; 2) Bug fixing and code refactoring pose greater challenges to LLMs' instruction following, with non-compliance rates notably higher than in information querying; 3) Code quality optimization and requirements-driven development tasks show lower user satisfaction, whereas structured knowledge queries and algorithm designs yield higher levels. These insights offer recommendations for improving LLM interfaces and user satisfaction in coding collaborations, while highlighting avenues for future research on adaptive dialogue systems. We believe this work broadens understanding of human-LLM synergies and supports more effective AI-assisted development.",
    "title_zh": "解码人与大语言模型在编程中的协作：一项关于真实世界多轮对话的实证研究",
    "abstract_zh": "大型语言模型（LLMs）正日益作为动态的对话接口，支持多轮交互，模拟类人对话，并助力完成诸如编程等复杂任务。尽管像LMSYS-Chat-1M和WildChat这样的数据集捕捉了真实世界中用户与LLM之间的对话，但很少有研究系统地探讨在编程场景下人与LLM协作的机制。用户在交互过程中经历了怎样的曲折路径？LLM遵循指令的能力如何？用户的满意度又如何？本文基于LMSYS-Chat-1M和WildChat数据集，对人类与LLM在编程协作中的表现进行了实证分析，旨在探索人机协作机制、LLM的指令遵循能力以及用户满意度。研究得出若干有趣发现：1）任务类型塑造了不同的交互模式（线性、星型和树状），其中代码质量优化更倾向于线性模式，以设计为导向的任务偏向树状结构，而查询类任务则偏好星型模式；2）Bug修复和代码重构对LLM的指令遵循构成更大挑战，其不合规率显著高于信息查询任务；3）代码质量优化和需求驱动型开发任务带来的用户满意度较低，而结构化知识查询和算法设计则带来更高的满意度。这些发现为改进LLM界面设计、提升用户在编程协作中的体验提供了切实建议，同时也指出了未来自适应对话系统研究的方向。我们相信，这项工作深化了对人机协同关系的理解，有助于推动更高效的人工智能辅助开发实践。"
  },
  {
    "date": "2025-12-11",
    "title": "From Lab to Reality: A Practical Evaluation of Deep Learning Models and LLMs for Vulnerability Detection",
    "authors": "Chaomeng Lu, Bert Lagaisse",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.10485v1",
    "source": "arXiv",
    "abstract": "Vulnerability detection methods based on deep learning (DL) have shown strong performance on benchmark datasets, yet their real-world effectiveness remains underexplored. Recent work suggests that both graph neural network (GNN)-based and transformer-based models, including large language models (LLMs), yield promising results when evaluated on curated benchmark datasets. These datasets are typically characterized by consistent data distributions and heuristic or partially noisy labels. In this study, we systematically evaluate two representative DL models-ReVeal and LineVul-across four representative datasets: Juliet, Devign, BigVul, and ICVul. Each model is trained independently on each respective dataset, and their code representations are analyzed using t-SNE to uncover vulnerability related patterns. To assess realistic applicability, we deploy these models along with four pretrained LLMs, Claude 3.5 Sonnet, GPT-o3-mini, GPT-4o, and GPT-5 on a curated dataset, VentiVul, comprising 20 recently (May 2025) fixed vulnerabilities from the Linux kernel. Our experiments reveal that current models struggle to distinguish vulnerable from non-vulnerable code in representation space and generalize poorly across datasets with differing distributions. When evaluated on VentiVul, our newly constructed time-wise out-of-distribution dataset, performance drops sharply, with most models failing to detect vulnerabilities reliably. These results expose a persistent gap between academic benchmarks and real-world deployment, emphasizing the value of our deployment-oriented evaluation framework and the need for more robust code representations and higher-quality datasets.",
    "title_zh": "从实验室到现实：深度学习模型与大语言模型在漏洞检测中的实践评估",
    "abstract_zh": "基于深度学习（DL）的漏洞检测方法在基准数据集上表现出强劲性能，但其在真实场景中的有效性仍缺乏深入探索。近期研究显示，基于图神经网络（GNN）和Transformer的模型（包括大型语言模型LLMs）在经过精心构建的基准数据集上均取得了令人鼓舞的结果。这些数据集通常具有相对一致的数据分布，以及启发式或部分带噪声的标签。在本研究中，我们系统地评估了两种具有代表性的深度学习模型——ReVeal与LineVul——在四个典型数据集（Juliet、Devign、BigVul和ICVul）上的表现。每种模型均在各自对应的数据集上独立训练，并通过t-SNE对代码表示进行可视化分析，以揭示与漏洞相关的模式特征。\n\n为评估模型在实际应用中的可行性，我们将上述两种DL模型与四种预训练大语言模型（Claude 3.5 Sonnet、GPT-o3-mini、GPT-4o 和 GPT-5）部署于一个精心构建的数据集——VentiVul上。该数据集包含20个最近（2025年5月）修复的Linux内核漏洞，构成一个时间维度上的“分布外”（out-of-distribution）测试集。实验结果表明，当前主流模型在表示空间中难以有效区分有漏洞与无漏洞代码，且在不同数据分布之间泛化能力较差。当在VentiVul这一新构建的时间维度分布外数据集上进行评估时，模型性能急剧下降，大多数模型无法可靠检测出漏洞。\n\n这些发现凸显了学术基准与真实世界部署之间的持续差距，强调了我们所提出的面向部署的评估框架的重要价值，同时也指出了亟需发展更鲁棒的代码表示方法以及更高品质的数据集以推动漏洞检测技术的实际落地。"
  },
  {
    "date": "2025-12-11",
    "title": "Approximate Circuits Versus Quantization for Energy Efficient Deep Neural Networks",
    "authors": "Jordi Fornt, Pau Fontova-Musté, Martí Caro, Jaume Abella, Josep Altet, Antonio Rubio, Francesc Moll",
    "publish": "2025 40th Conference on Design of Circuits and Integrated Systems (DCIS)",
    "url": "https://doi.org/10.1109/dcis67520.2025.11281936",
    "source": "IEEE",
    "abstract": "Deep neural networks dominate the landscape of artificial intelligence models and are used in many applications, but their high computational complexity makes executing them in real time very costly in terms of power. Hence, custom energyefficient accelerators have become a need in some domains. Lowprecision integer arithmetic and approximate compute circuits are two popular optimizations often contemplated for saving hardware resources and power consumption. These techniques are usually considered as separate and independent approximations, but in reality they are inextricably linked. In this work, we explore the interaction and trade-off between quantization and approximate circuits in the context of deep neural network acceleration by evaluating several circuits, including approximate multipliers, approximate adders, and combinations thereof, while using different integer precisions. Additionally, we study how approximate multiplier and adder circuits can be combined to further push energy efficiency. We use the YOLOv3 object detection network to assess the accuracy impact of the circuits in a state-of-the-art complex deep learning model. By combining approximate arithmetic circuits with low-precision quantization, we generate approximate MAD circuits with over 60% less power consumption and near identical accuracy compared to using only quantization. Nevertheless, we find that quantization plays a dominant role in the resulting energy efficiency, since the best design points are always found at the lowest bit precisions.",
    "title_zh": "近似电路与量化在高效能深度神经网络中的比较",
    "abstract_zh": "深度神经网络在人工智能模型领域占据主导地位，并被广泛应用于各种场景，但其高计算复杂性使得实时执行时功耗成本极高。因此，在某些领域中，定制化的能效加速器已成为迫切需求。低精度整数运算和近似计算电路是两种常被考虑用于节省硬件资源和降低功耗的优化技术。这些技术通常被视为独立且互不相关的近似方法，但实际上它们密不可分。在本研究中，我们通过评估多种电路（包括近似乘法器、近似加法器及其组合），在不同整数精度下，深入探讨了量化与近似电路之间的相互作用及权衡关系。此外，我们还研究了如何将近似乘法器与近似加法器相结合，以进一步提升能效。我们采用YOLOv3目标检测网络作为基准，评估这些电路在当前最先进的复杂深度学习模型中的精度影响。结果表明，通过将近似算术电路与低精度量化相结合，所生成的近似MAD电路在功耗上降低了超过60%，同时保持了与仅使用量化方法相近的精度水平。然而，我们发现量化在最终能效表现中起着主导作用，因为所有最优设计点均出现在最低位宽精度下。"
  },
  {
    "date": "2025-12-11",
    "title": "SHACL-Prolog Collaborative Validation Method for Digital Handover of Substation Secondary Systems",
    "authors": "Yu Rong, Hui Zhang, Di Wang, Qiumiao Cheng",
    "publish": "2025 11th International Conference on Energy Materials and Electrical Engineering (ICEMEE)",
    "url": "https://doi.org/10.1109/icemee66610.2025.11276681",
    "source": "IEEE",
    "abstract": "Data quality is the decisive factor for the success of digital handover in smart substations. Existing manual or relational-rule - based checks struggle to guarantee model completeness, compliance, and multi-model consistency simultaneously. This paper presents a graph-database validation framework that couples SHACL with Prolog: SCD, SDD, and GIM are first unified into an RDF graph stored in Neo4j; SHACL enforces structural constraints while Prolog performs complex logical reasoning. The result is a closed-loop workflow of “validate - alert - auto-repair - reject”, which markedly improves the reliability and automation of handover data.",
    "title_zh": "变电站二次系统数字化移交的SHACL-Prolog协作验证方法",
    "abstract_zh": "数据质量是智能变电站数字化移交成功的关键因素。现有的手动或基于关系规则的检查方法难以同时保证模型的完整性、合规性以及多模型的一致性。本文提出一种结合SHACL与Prolog的图数据库验证框架：首先将SCD、SDD和GIM统一为存储在Neo4j中的RDF图；SHACL用于强制执行结构约束，而Prolog则完成复杂的逻辑推理。该方法实现了“验证-告警-自动修复-拒绝”的闭环工作流程，显著提升了移交数据的可靠性与自动化水平。"
  },
  {
    "date": "2025-12-11",
    "title": "Deep Learning for Intelligent Monitoring of the WEST Tokamak First Wall Using Infrared Imaging: An Overview",
    "authors": "Erwan Grelier, Valentin Gorse, Raphael Mitteau, Victor Moncada, Leo Dubus, Sebastien Vives, Julien Marot",
    "publish": "IEEE Transactions on Plasma Science",
    "url": "https://doi.org/10.1109/tps.2025.3632082",
    "source": "IEEE",
    "abstract": "First wall protection is a critical challenge in fusion machine operation, requiring fast and precise diagnostics. Infrared imaging in long-pulse devices, such as the WEST tokamak, generates vast amounts of thermal video data, making both real-time and postpulse analysis demanding for human operators. Traditional real-time protection has relied on thresholding and conventional image processing, which, while robust, require predefined regions of interest (ROIs) and lack adaptability to new hot spots or camera displacements. Deep learning methods have therefore emerged as promising alternatives, offering greater flexibility and improved detection capabilities. This work presents the comprehensive framework developed over several years for monitoring the WEST’s first wall using infrared imaging. The tools fall into two main categories: active real-time systems integrated with plasma control and decision-support tools for postpulse analysis. In real time, the developed methods include a CPU-optimized model that detects electric arcs on the grill of the heating antennae, which has been successfully deployed with the plasma control system (PCS) to regulate the injected power during the C10 and C11 experimental campaigns (October 2024–April 2025). This model achieved 98% accuracy on C10 data, with only a single false positive occurring after a disruption. Another key component is the GPU-based thermal event detection model, which detects, tracks, and characterizes thermal events in real time, overcoming the limitations of fixed ROIs and enabling the tracking of emerging hot spots. Postpulse decision-support tools are equally important. One example is a detection tool designed to identify and track moving tungsten particles in infrared data, supporting studies of correlations between these particles and plasma disturbances. Additionally, a multimodal large language model (LLM) has been developed to automate pulse summary analysis. This LLM has been actively used by infrared experts between pulses during campaigns. Expert evaluations indicate that over 62% of the model’s outputs were satisfactory. Overall, integrating deep learning into the infrared diagnostic workflow significantly enhances first wall monitoring and protection for fusion devices.",
    "title_zh": "基于红外成像的深度学习在WEST托卡马克第一壁智能监测中的应用：综述",
    "abstract_zh": "第一壁保护是聚变装置运行中的关键挑战，需要快速而精确的诊断手段。在长脉冲装置（如WEST托卡马克）中，红外成像会产生海量的热成像视频数据，这对人工操作员而言，无论是实时分析还是脉冲后分析都极具挑战性。传统的实时保护方法依赖于阈值设定和常规图像处理技术，虽然具有较强的鲁棒性，但需要预先定义感兴趣区域（ROIs），难以适应新出现的热点或摄像头位置偏移。因此，深度学习方法应运而生，成为极具前景的替代方案，具备更高的灵活性和更优的检测能力。\n\n本文介绍了多年来为监测WEST装置第一壁所开发的完整红外成像监控框架。相关工具主要分为两大类：一是与等离子体控制系统集成的主动实时系统，二是用于脉冲后分析的决策支持工具。\n\n在实时监控方面，开发了一种针对CPU优化的模型，用于检测加热天线格栅上的电弧现象。该模型已成功部署于等离子体控制系统（PCS）中，在C10和C11实验阶段（2024年10月至2025年4月）实现了对注入功率的动态调节。该模型在C10数据上达到了98%的准确率，仅在一次破裂事件后出现一次误报。另一核心组件是基于GPU的热事件检测模型，能够实现实时的热事件检测、跟踪与特征分析，突破了固定ROI的局限，可有效追踪新出现的热点。\n\n在脉冲后的决策支持方面，同样具有重要意义。例如，开发了一种专门用于识别和追踪红外数据中移动钨颗粒的检测工具，有助于研究这些颗粒与等离子体扰动之间的关联性。此外，还构建了一个多模态大型语言模型（LLM），用于自动化脉冲总结分析。该LLM已在实验周期中被红外专家在脉冲间隙积极使用。专家评估表明，模型输出中有超过62%的内容达到满意水平。\n\n总体而言，将深度学习技术融入红外诊断工作流程，显著提升了聚变装置第一壁的监测与保护能力。"
  },
  {
    "date": "2025-12-11",
    "title": "Modeling the MoM 2025 Satellite Configuration Challenge with Vitruvius",
    "authors": "Benedikt Jutz, Thomas Weber, Arne Lange, Razieh Dehghani, Bowen Jiang, Martin Armbruster, Kevin Feichtinger, Nathan Hagel, Minakshi Kaushik, Lars König, Manar Mazkatli, Muhammad Asim Minhas, Dirk Neumann, Erik Burger, Anne Koziolek, Ralf Reussner",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00115",
    "source": "IEEE",
    "abstract": "We contribute a solution to the Model Management (MoM) Challenge 2025 (https://doi.org/10.5281/zenodo.15285132) with the Vitruvius framework. Vitruvius manages multiple models in a so-called Virtual Single Underlying Model. It maintains consistency between models through preservation rules written in a custom Domain-Specific Language, and projects views defined via view types to interact with the modeled system. We define Metamodels to model the part catalog, system architecture, and satellite requirements in the challenge. Between the part catalog and system architectures, we also define Consistency Preservation Rules. Finally, we construct a view type that generates reports as views. With these components, our Virtual Single Underlying Model handles the first three scenarios of the challenge. In this paper, we also detail our plans to support versioning and collaboration in Vitruvius. We preview future developments, and compare Vitruvius to other model management approaches.",
    "title_zh": "使用维特鲁威斯建模2025年MoM卫星配置挑战",
    "abstract_zh": "我们为2025年模型管理（MoM）挑战赛（https://doi.org/10.5281/zenodo.15285132）提出了一种基于Vitruvius框架的解决方案。Vitruvius通过所谓的“虚拟单一底层模型”来管理多个模型，利用一种自定义领域特定语言编写的保持一致性规则，确保各模型之间的一致性，并通过视图类型定义的视图与建模系统进行交互。在本挑战中，我们定义了元模型以描述零件目录、系统架构以及卫星需求。在零件目录与系统架构之间，我们还定义了保持一致性的规则。最后，我们构建了一种视图类型，用于生成报告作为视图。借助这些组件，我们的虚拟单一底层模型能够处理挑战中的前三个场景。本文还详细介绍了我们在Vitruvius中支持版本管理和协作的规划，展望了未来的发展方向，并将Vitruvius与其他模型管理方法进行了比较。"
  },
  {
    "date": "2025-12-11",
    "title": "A Model-Driven Approach for CI/CD",
    "authors": "Hugo Da Gião",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00014",
    "source": "IEEE",
    "abstract": "Continuous Integration and Continuous Delivery/Deployment (CI/CD) are foundational practices in the DevOps lifecycle, facilitating the automated merging of code changes and deployment across environments. Despite their critical role in modern software development, CI/CD pipelines are particularly susceptible to the challenges posed by the proliferation of diverse technologies, especially during adoption and migration.In this paper, we introduce a model-driven methodology designed to abstract away the tool-specific complexities typically encountered in CI/CD pipelines. Our approach begins with an empirical analysis of open-source software repositories to identify patterns and practices in the usage of various CI/CD tools in real-world projects.From this analysis, we derived a metamodel that captures the base concepts and structures common to a wide range of CI/CD technologies. This metamodel forms the basis of a model-driven framework that allows users to define CI/CD pipelines at a higher level of abstraction, independent of any specific tool or platform.To operationalize our approach, we developed a commandline interface capable of generating user interfaces directly from the metamodel. Building on this, we designed a block-based visual language aligned with the metamodel, enabling users to construct CI/CD pipelines visually. These visual models can then be automatically translated into platform-specific configuration files, supporting multiple CI/CD systems.Our solution is especially beneficial in migration scenarios, where transitioning between different CI/CD tools can be both timely and error-prone. By automating the generation of configuration artifacts and providing semantic mappings across tools, our approach significantly reduces the manual effort and complexity involved in such migrations.",
    "title_zh": "一种基于模型的持续集成与持续交付方法",
    "abstract_zh": "持续集成与持续交付/部署（CI/CD）是DevOps生命周期中的基础实践，能够实现代码变更的自动化合并以及在不同环境中的自动部署。尽管CI/CD在现代软件开发中扮演着至关重要的角色，但随着各类技术的不断涌现，尤其是在技术采纳和迁移过程中，CI/CD流水线极易面临复杂性挑战。本文提出一种基于模型的方法，旨在抽象并消除传统CI/CD流水线中常见的工具特异性复杂问题。\n\n我们的方法首先通过对开源软件仓库进行实证分析，识别真实项目中各类CI/CD工具的实际使用模式与最佳实践。基于该分析结果，我们提炼出一个元模型，该模型概括了多种CI/CD技术共有的核心概念与结构。这一元模型构成了一个模型驱动框架的基础，使用户能够在不依赖特定工具或平台的前提下，以更高层次的抽象来定义CI/CD流水线。\n\n为实现该方法的落地应用，我们开发了一个命令行接口，可直接从元模型生成用户界面。在此基础上，我们设计了一种基于模块的可视化语言，其结构与元模型保持一致，使用户能够通过拖拽方式直观地构建CI/CD流水线。这些可视化模型可被自动转换为针对不同平台的配置文件，从而支持多种CI/CD系统。\n\n本方案在工具迁移场景中尤为突出：当需要在不同的CI/CD工具之间切换时，传统方式往往耗时且易出错。而我们的方法通过自动化生成配置文件，并提供跨工具的语义映射，显著降低了人工操作的工作量与复杂度，有效提升了迁移效率与可靠性。"
  },
  {
    "date": "2025-12-11",
    "title": "LLM-Based Generation of Low-Code Development Platforms",
    "authors": "Bernhard Schenkenfelder",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00015",
    "source": "IEEE",
    "abstract": "Low-Code Development Platforms (LCDPs) empower domain experts, potentially without software development training, to address their software requirements themselves by raising the level of abstraction beyond code. Domain experts typically interact with an LCDP through a graphical or text-based environment, which is more intuitive to use the more specific it is to their domain and to them as users. While most of the LCDPs from major vendors support a variety of users and domains by providing more general languages that require additional customization efforts, the modeling constructs for a specific LCDP must be created manually to support new domains and users-a laborious process. At the same time, Large Language Models (LLMs) demonstrate impressive code generation capabilities. However, domain experts often lack the skills to integrate the generated code into their organization’s software ecosystem.Combining the power of both LCDPs and LLMs, this thesis focuses on automating the building of modeling constructs of LCDPs using LLMs (“LCDP GenAIrator”). Specific LCDPs allow domain experts to approach their tasks naturally because the modeling constructs mirror their understanding of the real world, while leveraging the code generation capabilities of LLMs provides a more efficient, automated way of creating LCDPs. More precisely, this thesis investigates how multimodal LLM input, including text (natural language), documents, structured data, images (e.g., screenshots), videos, code, and language specifications, can be used to create new LCDPs and extend existing software systems with LCDPs. Multimodal input is essential because a variety of artifacts contain domain knowledge, particularly modeling constructs. While their extraction can be automated, it requires different inputs that can be provided by domain experts. Additionally, the thesis explores how to utilize and optimize LLMs to excel at the task of generating modeling constructs from multimodal input using techniques such as fine-tuning, agent orchestration, and prompting strategies.This thesis is carried out through industry-academia collaborations that allow to evaluate the “LCDP GenAIrator” using different scientific methods, from the lab to the industry partners’ sites.CCS Concepts • Software and its engineering → Domain specific languages; Visual languages; Model-driven software engineering; Abstraction, modeling and modularity; • Human-centered computing → HCI design and evaluation methods; User centered design; • Computing methodologies → Artificial intelligence",
    "title_zh": "基于大语言模型的低代码开发平台生成",
    "abstract_zh": "低代码开发平台（LCDPs）使领域专家——即使没有软件开发培训背景——能够通过超越代码的抽象层次，自主解决其软件需求。领域专家通常通过图形化或基于文本的环境与LCDP进行交互，而这些环境越贴近其特定领域以及用户自身，就越易于使用。尽管大多数主流厂商提供的LCDP支持多种用户和领域，通过提供更通用的语言来实现，但需要额外的定制工作；而针对特定LCDP的建模构造必须手动创建以支持新领域和新用户，这一过程十分繁琐。与此同时，大型语言模型（LLMs）展现出惊人的代码生成能力。然而，领域专家往往缺乏将生成的代码集成到其组织现有软件生态系统中的技能。\n\n结合LCDP与LLM的双重优势，本论文聚焦于利用LLM自动化构建LCDP的建模构造（“LCDP GenAIrator”）。通过为特定LCDP设计出与其领域专家对现实世界理解相一致的建模构造，使他们能以自然、直观的方式完成任务；同时借助LLM的代码生成能力，实现LCDP创建过程的更高效、自动化。具体而言，本论文研究如何利用多模态LLM输入（包括自然语言文本、文档、结构化数据、图像（如截图）、视频、代码及语言规范等），来创建新的LCDP，并扩展现有软件系统以支持LCDP。多模态输入至关重要，因为各种类型的资料中蕴含着丰富的领域知识，尤其是建模构造本身。虽然这些知识的提取可以实现自动化，但需要由领域专家提供不同形式的输入。此外，本论文还探索如何利用并优化LLM，使其在从多模态输入生成建模构造的任务中表现卓越，采用的技术手段包括微调、智能体编排（agent orchestration）以及提示策略（prompting strategies）。\n\n本研究通过产学研合作开展，能够在实验室环境及产业合作伙伴的实际应用场景中，采用多种科学方法对“LCDP GenAIrator”进行评估。\n\nCCS概念  \n• 软件及其工程 → 领域特定语言；可视化语言；模型驱动的软件工程；抽象、建模与模块化；  \n• 以人为中心的计算 → 人机交互设计与评估方法；以用户为中心的设计；  \n• 计算方法学 → 人工智能"
  },
  {
    "date": "2025-12-11",
    "title": "From Diagrams to Code: An Exploration into Automated Cloud Template Creation",
    "authors": "Varun Chandrashekar, Vikas Paul Menezes, Thaksha Ganesh, Isha Sudheer Prabhu, Chandrashekhar Pomu Chavan",
    "publish": "2025 IEEE 15th International Conference on Electronics Information and Emergency Communication (ICEIEC)",
    "url": "https://doi.org/10.1109/iceiec65904.2025.11273135",
    "source": "IEEE",
    "abstract": "Infrastructure as Code is the ability to provision and manage cloud infrastructure through code instead of manual and error-prone processes. Despite its benefits, the initial creation and maintenance of Infrastructure as Code templates remains tedious. Manual template creation may lead to security vulnerabilities and inconsistencies between design and implementation. Furthermore, cloud architecture complexity makes it harder to prevent configuration drift, where infrastructure deviates from its intended use case. Moreover, a lack of automation in template creation hinders rapid deployment and leads to inefficiencies. This paper presents an automated system for converting Amazon Web Service cloud architecture diagrams into CloudFormation templates. Using deep learning models and image processing techniques accompanied by a deterministic rule set, the system detects Amazon Web Services’ service components and their relationships from the input architecture diagram. The system detects the various icons (depicting services) present in the diagram with an accuracy of 98.40%. Simultaneously, a group detection module recognises various logical and physical boundaries such as Virtual Private Clouds or Security groups that define network and security segmentation. Rule-based suggestions are made on the extracted information to infer services that are not explicitly illustrated. Finally, the CloudFormation template is generated based on the aggregated output. Through this pipeline, the solution streamlines the automatic creation of CloudFormation templates with a latency under 15 seconds, minimising errors and development effort.",
    "title_zh": "从图表到代码：自动化云模板创建的探索",
    "abstract_zh": "基础设施即代码（Infrastructure as Code）是指通过代码而非手动且易出错的流程来配置和管理云基础设施。尽管其具有诸多优势，但初始创建和维护基础设施即代码模板的过程仍然繁琐。手动编写模板可能导致安全漏洞，并造成设计与实现之间的不一致。此外，云架构的复杂性使得配置漂移（configuration drift）更难防范，即实际基础设施偏离了预期用途。同时，模板创建缺乏自动化也阻碍了快速部署，导致效率低下。\n\n本文提出了一种自动化系统，可将亚马逊网络服务（AWS）的云架构图自动转换为CloudFormation模板。该系统结合深度学习模型、图像处理技术以及确定性规则集，能够从输入的架构图中检测出AWS的服务组件及其相互关系。系统对图中各类图标（代表服务）的识别准确率达到98.40%。同时，一组群组检测模块能够识别出各种逻辑或物理边界，如虚拟私有云（VPC）或安全组，这些边界定义了网络和安全分段。基于提取的信息，系统还提供基于规则的建议，以推断出未明确绘制但应存在的服务。最后，系统根据整合后的输出生成CloudFormation模板。\n\n通过这一全流程自动化方法，该解决方案可在15秒内完成CloudFormation模板的自动生成，显著减少错误并降低开发工作量。"
  },
  {
    "date": "2025-12-11",
    "title": "Security Analysis of MiniApps: Vulnerabilities, Exploits, and a Tailored Mitigation Framework",
    "authors": "Keyhan Mohammadi, Arman Moradi, Reza Ebrahimi Atani",
    "publish": "2025 15th International Conference on Computer and Knowledge Engineering (ICCKE)",
    "url": "https://doi.org/10.1109/iccke68588.2025.11273836",
    "source": "IEEE",
    "abstract": "Telegram MiniApps and WeChat Mini Programs represent two leading implementations of the superApp sub application paradigm, each combining centralized backend services with lightweight, embedded client interfaces. While both platforms enable rich user experiences, they also introduce significant security risks through architectural and implementation flaws. In this paper, we present a comparative analysis of vulnerabilities in Telegram MiniApps and WeChat Mini Programs, drawing from documented exploits and empirical testing. For WeChat, prior studies reveal widespread issues including sensitive data leakage, weak permission enforcement, and cross MiniApp request forgery, affecting millions of deployed apps. For Telegram, we identify unproxied frontend–backend communication leaking IPs and server endpoints, insecure HTTP defaults in the Bot API enabling man in the middle attacks, and inadequate auditing of TON blockchain smart contracts. We further analyze adversarial MiniApps exploiting WebView sandbox weaknesses for malware delivery, cryptomining, and cryptocurrency phishing. Building on these findings, we propose a comprehensive mitigation framework tailored to Telegram but informed by lessons from WeChat’s vulnerabilities. Our approach includes mandatory HTTPS, Telegram-hosted proxying, sandbox isolation, automated malicious activity detection, and AI-assisted code auditing. The results highlight the urgent need for platform level reforms across superApp ecosystems to align rapid feature growth with strong user privacy and security guarantees.",
    "title_zh": "小程序安全分析：漏洞、利用方式及定制化缓解框架",
    "abstract_zh": "Telegram MiniApps 与微信小程序代表了超级应用子应用模式的两种领先实现，二者均将集中式后端服务与轻量级嵌入式客户端界面相结合。尽管两个平台都能提供丰富的用户体验，但其架构和实现中的缺陷也引入了重大的安全风险。本文通过分析已记录的漏洞及实证测试，对 Telegram MiniApps 和微信小程序中的漏洞进行了对比研究。对于微信，已有研究揭示了广泛存在的问题，包括敏感数据泄露、权限控制薄弱以及跨小程序请求伪造攻击，影响了数百万已部署的应用程序。而对于 Telegram，我们识别出前端与后端通信未经过代理导致 IP 地址和服务器端点泄露、Bot API 中默认使用不安全的 HTTP 协议从而易受中间人攻击，以及对 TON 区块链智能合约审计不足等问题。此外，我们还分析了恶意小程序利用 WebView 安全沙箱缺陷进行恶意软件分发、加密货币挖矿和数字货币钓鱼攻击的行为。基于上述发现，我们提出了一套专为 Telegram 设计但借鉴微信漏洞教训的综合性缓解框架。该方案包括强制使用 HTTPS、由 Telegram 主机托管的代理机制、沙箱隔离、自动化恶意行为检测以及人工智能辅助代码审计。研究结果凸显了在超级应用生态系统中亟需开展平台级改革，以确保快速功能迭代与用户隐私及安全保障之间的平衡。"
  },
  {
    "date": "2025-12-11",
    "title": "Generating Software Architecture Description from Source Code using Reverse Engineering and Large Language Model",
    "authors": "Ahmad Hatahet, Christoph Knieke, Andreas Rausch",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00080",
    "source": "IEEE",
    "abstract": "Software Architecture Descriptions (SADs) are indispensable for navigating the complexity of modern software systems. They enable high-level reasoning, guide design decisions, and facilitate communication among diverse stakeholders. Yet in practice, SADs are frequently missing, outdated, or poorly aligned with the system’s actual implementation. As a result, developers are forced to derive architectural insights directly from source code—a time-intensive task that increases mental effort, slows onboarding, and contributes to the gradual degradation of architectural clarity over a system’s lifetime. To address these challenges, we propose an automated generation of SADs from source code by combining reverse engineering (RE) techniques with Large Language Model (LLM). Our approach recovers both static and behavioral views by extracting a comprehensive component diagram, filters architecturally significant elements—core components—via prompt-guided LLM analysis, and generates state machine diagrams to model component behavior based on code logic. This dual-view representation offers a scalable and maintainable alternative to manual architectural documentation. This approach, demonstrated with C++ examples, showcases the potent capability of LLMs to: 1) find abstract component diagram, lowering the reliance on human expert involvement, and 2) represent complex software behaviors, especially when enriched with domain-specific knowledge through few-shot prompting. These findings suggest a viable path toward reducing manual effort while enhancing system understanding and long-term maintainability.",
    "title_zh": "使用逆向工程与大语言模型从源代码生成软件架构描述",
    "abstract_zh": "软件架构描述（SADs）对于应对现代软件系统复杂性至关重要。它们支持高层级的推理，指导设计决策，并促进不同利益相关者之间的沟通。然而在实践中，SADs常常缺失、过时或与系统的实际实现不一致。因此，开发人员不得不直接从源代码中推导架构信息——这一过程耗时费力，增加了认知负担，延缓了新成员的入职速度，并导致系统生命周期中架构清晰度逐渐退化。为解决这些问题，我们提出一种基于源代码自动生成SADs的方法，该方法结合逆向工程（RE）技术与大型语言模型（LLM）。我们的方法通过提取全面的组件图，恢复静态和行为视图；利用提示引导的LLM分析，筛选出具有架构意义的核心组件；并根据代码逻辑生成状态机图，以建模组件的行为。这种双视图表示提供了一种可扩展且易于维护的替代方案，相较于人工编写架构文档更具优势。以C++为例的实证表明，LLM具备强大的能力：1）能够自动发现抽象的组件图，降低对人工专家的依赖；2）在通过少量示例提示引入领域知识后，能够有效表达复杂的软件行为。这些发现表明，借助LLM可显著减少人工工作量，同时提升系统理解能力与长期可维护性。"
  },
  {
    "date": "2025-12-11",
    "title": "User Perceptions of Code and Model Generation with Simulink in Industrial Settings - A Survey",
    "authors": "Johan Cederbladh, Jakob Norin",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00076",
    "source": "IEEE",
    "abstract": "Model-Based Development (MBD) has become an expectation in several industries to support testing & verification during system design. Specifically, MBD reduces the need for physical resources and promotes re-usable digital development frameworks. At the same time, there are still several challenges that exist with using (primarily graphical) MBD tools in industrial settings which are hindering a mature integration for collaboration in Cyber-Physical Systems (CPSs) design and development. In this paper we provide an experience report about using Simulink for code generation & automated testing in industrial settings and discuss the implications for wider model-based adoption. The paper also supports these experiences through results from an internal survey at a company with 23 participants in relation to user experiences of using Simulink. The survey findings highlight concerns in collaboration, particularly from a software engineering perspective.",
    "title_zh": "用户在工业环境中对Simulink进行代码与模型生成的感知调查",
    "abstract_zh": "基于模型的开发（Model-Based Development, MBD）已在多个行业中成为一种普遍期望，用于支持系统设计过程中的测试与验证。具体而言，MBD减少了对物理资源的需求，并促进了可重用的数字化开发框架的建立。然而，在工业环境中使用（主要是图形化）MBD工具仍存在若干挑战，这些挑战阻碍了在信息物理系统（Cyber-Physical Systems, CPSs）设计与开发中实现成熟的协作集成。本文提供了一篇关于在工业环境中使用Simulink进行代码生成与自动化测试的经验报告，并探讨了其对更广泛采用MBD的启示。此外，本文还通过一家公司内部针对23名参与者开展的调查结果，进一步支持上述经验。调查结果突显出在协作方面存在的担忧，尤其是从软件工程的角度来看。"
  },
  {
    "date": "2025-12-11",
    "title": "Collaborative LLM Reasoning for Vulnerability Detection in Smart Contracts",
    "authors": "Amirreza Samari, Parsa Hedayatnia, Seyyed Javad Bozorgzadeh Razavi, Mohammad Allahbakhsh, Haleh Amintoosi",
    "publish": "2025 15th International Conference on Computer and Knowledge Engineering (ICCKE)",
    "url": "https://doi.org/10.1109/iccke68588.2025.11273846",
    "source": "IEEE",
    "abstract": "Smart contracts play a pivotal role in decentralized applications but are subject to security vulnerabilities often difficult to detect. Traditional static and symbolic analysis tools cannot handle intricate logic and are limited in adaptability and explainability. Recent development of large language models (LLMs) provide new opportunities for vulnerability detection, but single-model methods often suffer from inconsistency and prompt sensitivity. This paper introduces a collaborative LLM-based model that enhances detection robustness through semantic similarity-based few-shot prompting and multi-LLM reasoning. Our model integrates diverse LLMs (ChatGPT, Gemini, Grok) as worker nodes, along with an aggregator model to resolve disagreements via justification analysis and final prediction consolidation. Experimental evaluations on the SmartBugs benchmark demonstrated a remarkable enhancement in detection accuracy (96.25%) and response time compared to other models. The proposed model provides a scalable and explainable solution for smart contract auditing, illustrating the strength of LLM collaboration in security-critical applications.",
    "title_zh": "智能合约漏洞检测中的协作式大语言模型推理",
    "abstract_zh": "智能合约在去中心化应用中发挥着关键作用，但其常存在难以检测的安全漏洞。传统的静态分析和符号分析工具无法有效处理复杂的逻辑结构，在适应性和可解释性方面也存在局限。近年来，大型语言模型（LLMs）的发展为漏洞检测带来了新的机遇，但单一模型方法往往面临结果不一致和对提示敏感的问题。本文提出一种基于协作式LLM的检测模型，通过语义相似性驱动的少样本提示和多LLM协同推理，显著提升了检测的鲁棒性。该模型将多种LLM（如ChatGPT、Gemini、Grok）作为工作节点，并引入一个聚合模型，通过理由分析解决分歧并完成最终预测的整合。在SmartBugs基准测试上的实验评估表明，该模型在检测准确率（96.25%）和响应速度方面均显著优于其他现有模型。所提出的方案为智能合约审计提供了一种可扩展且可解释的解决方案，充分展现了LLM协作在安全关键场景中的强大潜力。"
  },
  {
    "date": "2025-12-11",
    "title": "Tilus: A Tile-Level GPGPU Programming Language for Low-Precision Computation",
    "authors": "Yaoyao Ding, Bohan Hou, Xiao Zhang, Allan Lin, Tianqi Chen, Cody Hao Yu, Yida Wang, Gennady Pekhimenko",
    "publish": "Proceedings of the 31st ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1",
    "url": "https://doi.org/10.1145/3760250.3762219",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "Tilus：一种用于低精度计算的基于瓦片级别的GPGPU编程语言",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-11",
    "title": "Analyzing Linux System Call Variability: Real-Time Patch Impact and System Call Monitoring",
    "authors": "Markel Galarraga, Charles-Alexis Lefebvre, Jon Perez-Cerrolaza, Jose A. Pascual",
    "publish": "2025 40th Conference on Design of Circuits and Integrated Systems (DCIS)",
    "url": "https://doi.org/10.1109/dcis67520.2025.11281814",
    "source": "IEEE",
    "abstract": "State-of-the-art safety-critical systems are increasingly integrating advanced functionality that requires high computational power, such as the pedestrian detection required by autonomous vehicles. Consequently, high-performance embedded platforms are becoming increasingly necessary. In this context, the use of Linux is highly attractive to industry due to its extensive ecosystem (platform support, AI libraries, etc.) and its opensource development model. However, Linux was not designed to comply with strict safety standards, which complicates its use in safety-critical systems. Previous works have studied the nondeterminism of Linux kernel system calls regarding their execution paths and execution times, and proposed alternative approaches to justify its use in such systems. In this work, we continue those efforts with two main contributions. First, we compare a regular Linux kernel with the kernel patched with the PREEMPT_RT real-time patch, and show how the patch reduces the variability of system calls, both in terms of timings and execution paths. Then, we propose an additional layer of assurance in the form of a trie-based monitor implemented in hardware, which ensures that the variability measured and estimated during testing holds when the system is fielded, both for execution paths and execution times. We implement a software prototype of the monitor to demonstrate its feasibility and discuss our plan to migrate it to hardware.",
    "title_zh": "分析 Linux 系统调用的可变性：实时补丁影响与系统调用监控",
    "abstract_zh": "当前最先进的安全关键系统正越来越多地集成需要高计算能力的先进功能，例如自动驾驶汽车所需的行人检测。因此，高性能嵌入式平台变得日益必要。在此背景下，Linux因其丰富的生态系统（如平台支持、人工智能库等）以及开源开发模式，对工业界极具吸引力。然而，Linux并非为满足严格的安全标准而设计，这使得其在安全关键系统中的应用面临挑战。以往的研究已探讨了Linux内核系统调用在执行路径和执行时间上的非确定性问题，并提出了替代方案以证明其在这些系统中使用的合理性。本文在此基础上做出两项主要贡献：首先，我们对比了常规Linux内核与应用了PREEMPT_RT实时补丁的内核，展示了该补丁如何降低系统调用在执行时间和执行路径方面的变异性；其次，我们提出了一种额外的保障机制，即基于前缀树（trie-based）的硬件实现监控器，确保在系统部署到现场时，测试期间测量和估算的变异性依然成立，涵盖执行路径和执行时间两个方面。我们实现了一个软件原型来验证该监控器的可行性，并讨论了将其迁移至硬件的后续计划。"
  },
  {
    "date": "2025-12-11",
    "title": "Linear Layouts: Robust Code Generation of Efficient Tensor Computation Using F_2",
    "authors": "Keren Zhou, Mario Lezcano-Casado, Adam P. Goucher, Akhmed Rakhmati, Jeff Niu, Justin Lebar, Pawel Szczerbuk, Peter Bell, Phil Tillet, Thomas Raoux, Zahi Moudallal",
    "publish": "Proceedings of the 31st ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1",
    "url": "https://doi.org/10.1145/3760250.3762221",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "线性布局：使用 F₂ 进行高效张量计算的稳健代码生成",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-11",
    "title": "Sentence-based Sign Language Recognition using CNN and NLP",
    "authors": "Salma Jahan Nisha, N. D. Salih, Wan-Noorshahida Mohd-Isa",
    "publish": "2025 Multimedia University Engineering Conference (MECON)",
    "url": "https://doi.org/10.1109/mecon67253.2025.11277225",
    "source": "IEEE",
    "abstract": "This paper presents a comprehensive real-time sign language gesture recognition framework using a combination of Convolutional Neural Networks (CNNs) and Natural Language Processing (NLP). Although individual letter level sign recognition has seen considerable advancements, interpreting sign language sentences remains a challenging and underexplored area. Our proposed approach utilizes a CNN-based model to capture both spatial and temporal features from real-time inputs, transforming dynamic sequences of hand gestures into coherent short textual sentences using NLP. Leveraging key Python libraries such as Tensorflow, OpenCV, LLM and LabelImg, the system efficiently extracts important key point features to recognize gestures and convert them into sentences in sign language. Experimental evaluations demonstrate the potential of our framework as possible means to reduce communication barriers and expand the beneficial possibilities in technologies for individuals with hearing impairments.",
    "title_zh": "基于CNN和NLP的句法手势识别",
    "abstract_zh": "本文提出了一种基于卷积神经网络（CNN）与自然语言处理（NLP）相结合的综合性实时手语手势识别框架。尽管单个字母级别的手语识别已取得显著进展，但对手语句子的解读仍是一个具有挑战性且研究不足的领域。我们提出的方案采用基于CNN的模型，从实时输入中捕捉空间和时间特征，利用自然语言处理技术将动态的手势序列转化为连贯的简短文本句子。通过使用TensorFlow、OpenCV、大语言模型（LLM）以及LabelImg等关键Python库，该系统能够高效提取关键点特征，实现对手势的识别，并将其转换为手语句子。实验评估表明，本框架具有降低沟通障碍的潜力，为听力障碍人士提供了更广泛的技术应用可能性。"
  },
  {
    "date": "2025-12-11",
    "title": "Hardware Implementation of the Hungarian Algorithm for Optimum Task Assignments",
    "authors": "Lluís Ribas-Xirgo",
    "publish": "2025 40th Conference on Design of Circuits and Integrated Systems (DCIS)",
    "url": "https://doi.org/10.1109/dcis67520.2025.11281938",
    "source": "IEEE",
    "abstract": "Optimal solutions of task assignment problems like, e.g., subcarrier allocation for OFDM, are solved in polynomial time with the Hungarian algorithm. The sequential nature of the related procedure makes it difficult to accelerate its execution. In this work, several hardware implementations of a state version of the algorithm are presented and compared. Results show that the single-memory architecture delivers similar energy consumption than the software version, but multi-block memory systems can significantly cut execution times as well as hardware resources.",
    "title_zh": "匈牙利算法的硬件实现用于最优任务分配",
    "abstract_zh": "像正交频分复用（OFDM）中的子载波分配这类任务分配问题的最优解，可通过匈牙利算法在多项式时间内求解。然而，该算法相关过程的顺序特性使其难以加速执行。本文提出了几种该算法的硬件实现方案，并进行了比较。结果表明，单存储器架构的能耗与软件版本相当，而多块存储器系统则能显著缩短执行时间并减少硬件资源消耗。"
  },
  {
    "date": "2025-12-11",
    "title": "A Lightweight AES Peripheral for RISC-V Cores and IoT Applications",
    "authors": "Carlos Fernández-García, Carmen Baena Oliva, Pilar Parra Fernández, Carlos. J. Jiménez-Fernández",
    "publish": "2025 40th Conference on Design of Circuits and Integrated Systems (DCIS)",
    "url": "https://doi.org/10.1109/dcis67520.2025.11281901",
    "source": "IEEE",
    "abstract": "In this article, we present a lightweight peripheral of the Advanced Encryption Standard (AES) algorithm suitable for its implementation as a memory mapped peripheral in RISC-V cores. The peripheral is based on an 8-bit serial implementation of AES, which achieves a drastic reduction in the time required to encrypt a message with a reduced increase in resource consumption. The peripheral is compared in terms of resource utilization and timing with a software implementation of AES, tinyAES-c, and a hardware implementation that employs a more common 128-bit datapath using the Series-7 FPGA technology of the manufacturer AMD-Xilinx. The results show that the system using the peripheral achieves a speed 71.84 times faster than the software implementation, with a 46.37% increase over the logic used to implement the RISC-V processor.",
    "title_zh": "一种轻量级的AES外设，适用于RISC-V核心及物联网应用",
    "abstract_zh": "本文提出了一种适用于在RISC-V核心中作为内存映射外设实现的高级加密标准（AES）算法的轻量级外设。该外设基于8位串行实现的AES，显著减少了加密消息所需的时间，同时资源消耗的增加幅度较小。我们将该外设与AES的软件实现（tinyAES-c）、以及采用AMD-Xilinx系列7 FPGA技术中更常见的128位数据通路的硬件实现，在资源利用率和时序性能方面进行了对比。结果表明，使用该外设的系统相较于软件实现，速度提升了71.84倍，而逻辑资源的使用量仅比实现RISC-V处理器所用资源增加了46.37%。"
  },
  {
    "date": "2025-12-11",
    "title": "PA-Boot: A Formally Verified Authentication Protocol for Multiprocessor Secure Boot under Hardware Supply-chain Attacks",
    "authors": "Zhuoruo Zhang, Rui Chang, Mingshuai Chen, Wenbo Shen, Chenyang Yu, He Huang, Qinming Dai, Yongwang Zhao",
    "publish": "IEEE Transactions on Information Forensics and Security",
    "url": "https://doi.org/10.1109/tifs.2025.3642638",
    "source": "IEEE",
    "abstract": "Hardware supply-chain attacks are raising significant security threats to the boot process of multiprocessor systems. In this paper, we investigate critical stages of the multiprocessor system boot process and identify a new, prevalent hardware supply-chain attack surface that can bypass secure boot due to the absence of processor-authentication mechanisms. To defend against such attacks, in this paper, we present PA-Boot, the first formally verified processor-authentication protocol for secure boot in multiprocessor systems. PA-Boot is proved functionally correct and is guaranteed to detect multiple adversarial behaviors, such as processor replacements and man-in-the-middle attacks. The fine-grained formalization of PA-Boot and its fully mechanized security proofs are carried out in the Isabelle/HOL theorem prover with 348 lemmas/theorems and ~7,100 LoC. We further implement in C an instance of PA-Boot. Experiments on the proof-of-concept implementation indicate that PA-Boot can effectively identify boot-process attacks with a minor overhead (4.98% on Linux boot process) and thereby improve the security of multiprocessor systems.",
    "title_zh": "PA-Boot：一种在硬件供应链攻击下针对多处理器安全启动的形式化验证认证协议",
    "abstract_zh": "硬件供应链攻击正对多处理器系统的启动过程构成重大安全威胁。本文研究了多处理器系统启动过程中的关键阶段，识别出一种新型且普遍存在的硬件供应链攻击面，该攻击面由于缺乏处理器认证机制而能够绕过安全启动。为应对此类攻击，本文提出PA-Boot，这是首个针对多处理器系统安全启动的经过形式化验证的处理器认证协议。PA-Boot在功能上被证明是正确的，并能确保检测多种恶意行为，如处理器替换和中间人攻击。PA-Boot采用细粒度的形式化描述，并在Isabelle/HOL定理证明器中完成了完全机械化的安全证明，共包含348个引理/定理及约7,100行代码。此外，我们还用C语言实现了一个PA-Boot实例。概念验证的实验结果表明，PA-Boot能够在引入极小开销（Linux启动过程仅增加4.98%）的情况下有效识别启动过程中的攻击，从而显著提升多处理器系统的安全性。"
  },
  {
    "date": "2025-12-11",
    "title": "Automated AADL Architecture Modeling: Leveraging Large Language Models for Safety-Critical Software",
    "authors": "Yaxin Zou, Zhibin Yang, Hao Liu, Jiawei Liang, Yong Zhou, Zonghua Gu",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00050",
    "source": "IEEE",
    "abstract": "Architecture modeling is an essential part of model-driven development of safety-critical software. AADL is a modeling language standard for designing and analyzing safety-critical software. However, there is usually a large gap between software requirements and architectural design. Effectively transforming requirements into formal software architecture models relies on a lot of manual experience and iterative exploration. To address these challenges, we conduct an exploratory study of LLM-supported AADL architecture modeling. We assess three powerful LLMs, GPT-4o, DeepSeekV3, and GLM-4-Plus. First, we decompose and refine high-level software requirements and design constraints, mapping them to the proposed prompt engineering framework, RNL-Prompt, which significantly improved the accuracy of LLMs in generating different modeling elements. Our findings reveal that GPT-4o and DeepSeek-V3 perform on par with each other, and both outperform GLM-4-Plus in complex modeling elements, such as modes, behavior annex, etc. Second, to enhance the potential of GLM-4-Plus, we optimize its performance using N-shot prompting and retrievalaugmented generation (RAG). The results indicate that N-shot prompting performs more effectively. Finally, we demonstrate the effectiveness of our proposed approach in generating AADL architecture models in five examples of safety-critical domains. In addition, we implement an LLM-based modeling tool based on the AADL open source environment OSATE, which supports GPT-4o, DeepSeek-V3, and GLM-4-Plus. The tool is successfully applied to the modeling of an avionics control system in the industry.",
    "title_zh": "自动化AADL架构建模：利用大型语言模型实现关键安全软件",
    "abstract_zh": "架构建模是安全关键软件模型驱动开发中的核心环节。AADL（Architecture Analysis & Design Language）是一种用于设计和分析安全关键软件的建模语言标准。然而，软件需求与架构设计之间通常存在较大差距。将需求高效地转化为形式化的软件架构模型，往往依赖大量人工经验及反复迭代探索。为应对这些挑战，我们开展了一项关于大语言模型（LLM）支持下的AADL架构建模的探索性研究。我们评估了三种强大的大语言模型：GPT-4o、DeepSeek-V3 和 GLM-4-Plus。\n\n首先，我们将高层次的软件需求与设计约束进行分解与细化，并将其映射到我们提出的提示工程框架——RNL-Prompt。该框架显著提升了大语言模型在生成各类建模元素时的准确性。研究结果表明，GPT-4o 与 DeepSeek-V3 表现相当，且在复杂建模元素（如模式、行为附录等）方面均优于 GLM-4-Plus。\n\n其次，为了提升 GLM-4-Plus 的性能，我们采用 N-shot 提示法和基于检索增强生成（Retrieval-Augmented Generation, RAG）的方法对其进行优化。实验结果表明，N-shot 提示法效果更佳。\n\n最后，我们在五个安全关键领域实例中验证了所提出方法在生成 AADL 架构模型方面的有效性。此外，我们基于开源的 AADL 环境 OSATE，实现了一个基于大语言模型的建模工具，支持 GPT-4o、DeepSeek-V3 和 GLM-4-Plus。该工具已成功应用于工业界某航空电子控制系统的设计建模中，展现出良好的实用价值与应用前景。"
  },
  {
    "date": "2025-12-11",
    "title": "Unintended Changes: How LLMs Corrupt and Correct Textual Models",
    "authors": "Lukas Netz, Finn Kampe, Jan Reimer, Bernhard Rumpe",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00087",
    "source": "IEEE",
    "abstract": "This work evaluates to what degree AI-based modeldriven software development approaches may unintentionally alter parts of a model, potentially affecting its semantics, particularly when the model is defined in a domain-specific language unfamiliar to the LLM, and discusses to what degree the perplexity metric can be used to indicate susceptible modeling languages. Although much work has focused on evaluating the correctness of AI-based model creation, it remains important to assess whether and to what extent LLMs introduce unintended modifications in parts of the input model that they are merely expected to reproduce. Previous research has primarily focused on the success of programming and modeling tasks using AI, such as achieving syntactic and semantic correctness. In contrast, this work investigates the side effects of AI usage, specifically the introduction of unintended modifications during iterative modeling processes. We evaluate the likelihood of error introduction in an AI-based modeling approach for uncommon DSLs and use the perplexity-metric to identify error prone elements in the model. We use our own modeling language for class diagrams CD4A, an LLM that is not trained on this DSL and prompt it with simple modeling tasks. Next, we measure additional changes to the model that are not related to the given modeling task. We show that AI-driven Modeling approaches need to also focus on side effects of iterative LLM usage with unfamiliar modeling languages, and demonstrate how these risks can be identified.",
    "title_zh": "无意的改变：大语言模型如何破坏并修正文本模型",
    "abstract_zh": "本研究评估了基于人工智能的模型驱动软件开发方法在多大程度上可能无意中改变模型的某些部分，从而影响其语义，尤其是在模型采用大型语言模型（LLM）不熟悉的领域特定语言（DSL）时的情况，并探讨困惑度（perplexity）指标在多大程度上可用于识别易出错的建模语言。尽管已有大量研究关注基于AI的模型生成正确性评估，但仍然有必要考察大型语言模型在仅被要求复现输入模型的情况下，是否以及在何种程度上引入了非预期的修改。以往的研究主要聚焦于使用AI完成编程和建模任务的成功率，例如实现语法和语义上的正确性。与此不同，本文研究的是AI使用带来的副作用，特别是迭代建模过程中引入的非预期修改。我们评估了在不常见DSL中采用基于AI的建模方法时引入错误的可能性，并利用困惑度指标来识别模型中容易出错的元素。为此，我们采用自研的类图建模语言CD4A，使用一个未在该DSL上进行训练的大型语言模型，并向其提出简单的建模任务。随后，我们测量那些与给定建模任务无关的额外模型变化。研究结果表明，基于AI的建模方法必须同时关注在不熟悉建模语言下迭代使用LLM所带来的副作用，并展示了如何识别这些风险。"
  },
  {
    "date": "2025-12-11",
    "title": "Design Optimization of Security-Critical Stochastic Real-Time Applications",
    "authors": "Anbang Hu, Xingzhi Zhou, Xiong Pan, Wei Jiang, Jinyu Zhan",
    "publish": "2025 5th International Conference on Intelligent Technology and Embedded Systems (ICITES)",
    "url": "https://doi.org/10.1109/icites66466.2025.11274293",
    "source": "IEEE",
    "abstract": "Most security-critical real-time applications have soft real-time properties and the actual executions of tasks are stochastic. Based on the hard real-time model, traditional security-aware real-time tasks scheduling approaches are prone to waste system resources, which is not suitable for current security-critical systems. This paper considers the security-critical stochastic real-time task model, and introduces a cryptographic algorithm to encrypt the sensitive data of tasks, then establish the vulnerability model of real-time tasks. Due to that encryption of data can result in more time overhead, we model the no-deadline violation probability model and energy model of each task, and formulate the design optimization problem of security-driven stochastic real-time tasks. This paper proposes a clustering approximation algorithm based on dynamic programming, which can find the near-optimal solution with low time complexity. Experiments demonstrate the superiorities of the proposed approach comparing with existing candidates.",
    "title_zh": "安全关键型随机实时应用的设计优化",
    "abstract_zh": "大多数安全关键型实时应用具有软实时特性，且任务的实际执行时间具有随机性。基于硬实时模型的传统安全感知实时任务调度方法容易造成系统资源浪费，不适用于当前的安全关键型系统。本文针对安全关键型随机实时任务模型，引入密码学算法对任务的敏感数据进行加密，并建立实时任务的漏洞模型。由于数据加密会带来额外的时间开销，因此本文建立了每项任务的无截止期限违规概率模型和能耗模型，进而提出了面向安全驱动的随机实时任务设计优化问题。本文提出一种基于动态规划的聚类近似算法，能够在较低的时间复杂度下求得接近最优的解。实验结果表明，与现有方案相比，所提方法具有显著优势。"
  },
  {
    "date": "2025-12-11",
    "title": "Benchmarking Large Language Models for Root Cause Analysis in Train Control Software Testing",
    "authors": "Rahmanu Hermawan, Alessio Bucaioni, Eduard Enoiu, Wasif Afzal",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00089",
    "source": "IEEE",
    "abstract": "Software quality assurance is critical in safety-critical domains like railway systems, where failures can have catastrophic consequences. In this context, train control and management systems play a central role, and their software must undergo rigorous validation. Alstom Rail Sweden AB employs a digital twin infrastructure to simulate and validate train control and management systems software. While this setup significantly improves system-level testing, the root cause analysis of test failures remains a manual and time-consuming bottleneck.This study explores the potential of large language models to automate root cause analysis by interpreting execution logs generated during digital twin-based testing. We benchmark seven state-of-the-art large language models, Aion-1.0, DeepSeek R1, DeepSeek V3 0324, Mistral Small 3.1 24B, GPT o3-mini, Gemini 2.5 Pro Experimental, and QwB 32B, using zero-shot chain-of-thought prompting to assess their ability to reason about fault patterns in real-world industrial test execution logs. The logs, sourced from Alstom’s digital twin-based testing environment, capture complex operational behaviour typical of embedded, safety-critical systems.Our results show that Gemini 2.5 Pro Experimental achieved the best performance with 66.7% accuracy and strong reasoning quality in this domain, contributing to the future research agenda to improve the accuracy prediction.",
    "title_zh": "用于列车控制软件测试中根因分析的大型语言模型基准测试",
    "abstract_zh": "在铁路系统等安全关键领域，软件质量保证至关重要，因为系统故障可能带来灾难性后果。在此背景下，列车控制与管理系统发挥着核心作用，其软件必须经过严格的验证。Alstom Rail Sweden AB 采用数字孪生基础设施来模拟和验证列车控制与管理系统的软件。尽管该架构显著提升了系统级测试的效率，但测试失败的根本原因分析仍依赖人工，成为耗时且低效的瓶颈。\n\n本研究探讨了大型语言模型在自动化根本原因分析方面的潜力，通过解读基于数字孪生测试生成的执行日志，以识别故障模式。我们采用零样本思维链（zero-shot chain-of-thought）提示方法，对七种前沿大型语言模型——Aion-1.0、DeepSeek R1、DeepSeek V3 0324、Mistral Small 3.1 24B、GPT o3-mini、Gemini 2.5 Pro Experimental 和 QwB 32B——进行了基准测试，评估它们在真实工业测试执行日志中推理故障模式的能力。这些日志源自 Alstom 的数字孪生测试环境，记录了嵌入式、安全关键系统中典型的复杂运行行为。\n\n实验结果表明，Gemini 2.5 Pro Experimental 在该领域表现最佳，准确率达到 66.7%，且具备出色的推理质量，为未来提升故障预测准确性研究提供了重要方向。"
  },
  {
    "date": "2025-12-11",
    "title": "On the Generalization Capabilities of LLMs for Reverse Engineering Sequence Diagrams",
    "authors": "Sandra Greiner, Judi Abdullah, Timo Kehrer",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00084",
    "source": "IEEE",
    "abstract": "Reverse engineering models from source code is a crucial activity for facilitating program comprehension and supporting software modernization. Existing reverse engineering tools are typically tailored to specific programming languages and often lack the flexibility to be easily extended or adapted to others. While sophisticated support exists for some languages such as Java, many other languages remain poorly supported. Motivated by the recent success of large language models (LLMs) in code understanding and translation tasks across heterogeneous programming languages, we aim to explore whether LLMs can mitigate this imbalance. We envision LLMs to easily transfer reverse engineering capabilities between programming languages once understanding the reverse engineering task. As step towards this vision, this paper presents an experiment in which we finetuned CodeT5, an LLM pretrained on code translation tasks, on the task of generating sequence diagrams from Java methods. We systematically evaluate its generalization capabilities by applying the finetuned model to generate sequence diagrams for Python methods. Our quantitative results are promising but not without limitations. The finetuned model achieves almost perfect accuracy on Java methods. The transfer performance for Python input reaches approximately 80% accuracy, consistently measured across different evaluation metrics. In a qualitative analysis, we find that the good results stem from similar Java and Python code structures but the model fails, for instance to transfer keywords. Building on our experimental infrastructure and datasets, we lay the groundwork for future research on examining the generalization capabilities.",
    "title_zh": "大语言模型在逆向工程序列图中的泛化能力研究",
    "abstract_zh": "从源代码中逆向工程生成模型是促进程序理解并支持软件现代化的关键活动。现有的逆向工程工具通常针对特定编程语言设计，往往缺乏灵活性，难以轻松扩展或适配其他语言。尽管像Java这样的某些语言已有较为成熟的工具支持，但许多其他语言仍缺乏充分的支持。受大型语言模型（LLMs）在跨异构编程语言的代码理解与翻译任务中取得成功的启发，我们旨在探索LLMs是否能够缓解这种不平衡。我们设想，一旦LLM理解了逆向工程任务，便能轻松地将该能力迁移至不同编程语言。作为迈向这一愿景的一步，本文开展了一项实验：我们将CodeT5——一个在代码翻译任务上预训练的大型语言模型——微调用于从Java方法生成序列图。我们通过将微调后的模型应用于Python方法生成序列图，系统评估其泛化能力。定量结果令人鼓舞，但也存在局限性：该微调模型在Java方法上的准确率几乎达到完美；而在Python输入上的迁移性能约为80%的准确率，且在不同评估指标下均保持一致。在定性分析中，我们发现良好表现主要源于Java与Python代码结构的相似性，但模型在关键词迁移方面仍存在失败情况。基于本实验所构建的基础设施与数据集，我们为未来研究探讨LLMs的泛化能力奠定了基础。"
  },
  {
    "date": "2025-12-11",
    "title": "Extending Version Control Systems to Ensure Semantic Model Consistency",
    "authors": "Arkadiusz Ryś, Yon Vanommeslaeghe, Milan Cornelis, Bert Van Acker, Paul De Meulenaere, Hans Vangheluwe",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00095",
    "source": "IEEE",
    "abstract": "Ontological models for systems engineering, such as the Cross-Domain Knowledge Model (CDKM), now play an increasingly central role in engineering knowledge representation. However, as engineers from different domains contribute asynchronously to a single knowledge model, they often introduce inconsistencies that remain unnoticed. Version control systems, which are used to synchronize changes to such models, are however, content agnostic and, therefore, are not able to check semantic relations within a model. We introduce a framework designed to also maintain the semantic consistency of CDKM instances during concurrent, distributed editing. It operates in environments where engineers use version control systems to manage shared ontological models across interdisciplinary teams. This way, engineers can address problems faster and notice inconsistencies earlier by embedding this validation and correction process into their integration workflow.",
    "title_zh": "扩展版本控制系统以确保语义模型的一致性",
    "abstract_zh": "系统工程中的本体论模型，如跨领域知识模型（CDKM），在工程知识表示中正发挥着越来越核心的作用。然而，当来自不同领域的工程师异步地对同一知识模型进行贡献时，常常会引入一些未被察觉的不一致性。尽管版本控制系统可用于同步这些模型的变更，但它们本身是内容无关的，无法检查模型内部的语义关系。为此，我们提出了一种框架，旨在支持在并发、分布式编辑过程中维护CDKM实例的语义一致性。该框架适用于工程师使用版本控制系统在跨学科团队间管理共享本体模型的环境。通过将验证与修正过程嵌入集成工作流程，工程师能够更快速地发现问题，并及早发现不一致之处。"
  },
  {
    "date": "2025-12-11",
    "title": "Towards LLM Agents for Model-Based Engineering: A Case in Transformation Selection",
    "authors": "Zakaria Hachm, Théo Le Calvar, Hugo Bruneliere, Massimo Tisi",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00061",
    "source": "IEEE",
    "abstract": "In Model-Based Engineering (MBE), practitioners frequently face the challenge of selecting appropriate tools from a large number of options. This requires both deep domainspecific knowledge and technical expertise. LLM-based agents are software components that depend on Large Language Models (LLMs) to autonomously select and apply software tools to perform specific tasks. Although LLMs have already been applied to support various MBE activities, considering LLMbased agents to autonomously assist users of MBE tools remains underexplored. This is particularly challenging in industrial MBE environments where only medium-sized on-premise LLMs can be used due to company policies related to security or data privacy (for instance). To investigate the potential of LLM-based agents for MBE, we start with model-to-model transformation as a core MBE technique. Currently, off-the-shelf agents such as Microsoft Copilot can invoke a transformation engine (e.g., ATL) when the task is explicitly described. However, these agents struggle to select the correct transformation when they only have limited contextual information, especially when coupled with medium-size LLMs. To overcome this, we propose an approach based on complementary mechanisms. First, we build a model transformation server and an LLM agent with dedicated tools for each transformation available on the server. Second, to enable the agent to efficiently select transformations, we rely on a tool retrieval technique based on a tool relevance score computed by an LLM. We evaluate our LLM agent on a transformation dataset we also contribute to the community. Our comparative study shows that the newly proposed LLM agent responds more accurately to user instructions.",
    "title_zh": "面向基于模型工程的大型语言模型代理：一种在转换选择中的案例研究",
    "abstract_zh": "在基于模型的工程（Model-Based Engineering, MBE）中，从业者经常面临从大量可用工具中选择合适工具的挑战。这一过程不仅需要深入的领域知识，还需具备扎实的技术能力。基于大语言模型（LLM）的智能代理（LLM-based agents）是依赖大语言模型自主选择并应用软件工具以完成特定任务的软件组件。尽管LLM已应用于支持多种MBE活动，但将基于LLM的智能代理用于自主协助MBE工具用户的研究仍处于探索阶段。这一问题在工业级MBE环境中尤为突出，由于企业安全或数据隐私政策的限制，通常只能使用中等规模的本地部署LLM。\n\n为探究基于LLM的智能代理在MBE中的潜力，我们以“模型到模型转换”作为核心MBE技术展开研究。目前，现成的智能代理（如微软Copilot）可在任务被明确描述时调用转换引擎（例如ATL）。然而，当代理仅获得有限上下文信息时，尤其在使用中等规模LLM的情况下，往往难以准确选择正确的转换方法。为克服这一局限，我们提出一种基于互补机制的方法：首先，构建一个模型转换服务器，并为服务器上每种可用的转换方法配备专门的工具和对应的LLM代理；其次，为使代理能够高效地选择合适的转换，我们采用一种基于LLM计算出的工具相关性评分的工具检索技术。\n\n我们在一个由我们贡献给社区的转换数据集上对所提出的LLM代理进行了评估。对比实验结果表明，新提出的LLM代理在响应用户指令方面具有更高的准确性。"
  },
  {
    "date": "2025-12-11",
    "title": "Ensemble-Based Intrusion Detection Enhanced with LLM-Driven Incident Response Automation",
    "authors": "Srinivasa Rao Thumala, Vijay Mane, Chinmay Inamdar, Piyush Pethkar, Akhilesh Poke, Rajat Patil",
    "publish": "2025 Third International Conference on Industry 4.0 Technology (I4Tech)",
    "url": "https://doi.org/10.1109/i4tech64670.2025.11277913",
    "source": "IEEE",
    "abstract": "Traditional incident response systems lack adapt-ability and autonomous decision-making, limiting their effectiveness against sophisticated cyber threats. A modular AI framework is implemented to address this challenge by integrating ensemble-based binary intrusion detection and multiclass attack classification with real-time automation. Using the UNSW-NB15 dataset, Random Forest, XGBoost, and LightGBM models are trained for binary threat detection, followed by classification into nine attack categories. To enhance interpretability and operational readiness, incident reports are generated via the Mixtral-8x7B-Instruct large language model using LangChain and Hugging Face Inference API. Real-time interaction and deployment are enabled through a Flask-based REST API interface. The system achieves 93% accuracy and 95% recall, demonstrating its reliability in minimizing false negatives. Designed for seamless integration and minimal manual oversight, the framework supports real-time threat detection, classification, and automated response generation—making it suitable for deployment in security-critical environments with limited in-house expertise.",
    "title_zh": "基于集成学习的入侵检测系统与大语言模型驱动的事件响应自动化增强",
    "abstract_zh": "传统事件响应系统缺乏适应性和自主决策能力，难以有效应对复杂的网络威胁。为解决这一挑战，本文提出一种模块化人工智能框架，通过集成基于集成学习的二分类入侵检测与多类攻击分类，并结合实时自动化机制，提升安全防护能力。基于UNSW-NB15数据集，分别训练了随机森林（Random Forest）、XGBoost和LightGBM模型用于二分类威胁检测，随后对攻击行为进行九类分类。为增强可解释性与实际操作性，利用LangChain与Hugging Face推理API，通过Mixtral-8x7B-Instruct大语言模型生成详细的事件报告。系统通过基于Flask的REST API接口实现实时交互与部署。实验结果表明，该系统在准确率上达到93%，召回率达到95%，有效降低了误报率，展现出优异的可靠性。该框架设计注重无缝集成与最小化人工干预，支持实时威胁检测、分类及自动化响应生成，适用于对安全性要求高且内部安全专业人才有限的环境部署。"
  },
  {
    "date": "2025-12-11",
    "title": "YANG-APR: Towards Supporting Evolution in Model-driven Network Management Systems",
    "authors": "Hesham Elabd, Juergen Dingel, Robert Lee, Ali Tizghadam",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00067",
    "source": "IEEE",
    "abstract": "In model-driven network ecosystems, high-level specifications such as YANG data models define APIs that engineers extend with custom code and handlers. When the model evolves, it can become misaligned with its API implementation, which typically requires manual, costly, and error-prone realignment, highlighting the need for automated repair. This paper presents our ongoing work on an automated repair approach to resynchronize evolving YANG models with their API implementations, using a four-stage pipeline: (i) localize compatible-vs-breaking diffs between the current and updated models, (ii) enrich each diff record with contextual information, (iii) instantiate precise transformation rules for every change, and (iv) apply those rules to generate a repaired version of the code, complete with a reviewable change log for engineer validation. To explore the feasibility of this approach, we have developed an initial prototype-YANG-APR-that targets five common model evolution scenarios: datatype change, node rename, endpoint URL rename, endpoint removal, and endpoint addition. We illustrate the approach through two representative cases: a breaking datatype modification and a non-breaking endpoint addition. These early results show promising potential to facilitate model-implementation coevolution, providing a foundation for continued development and broader evaluation.",
    "title_zh": "YANG-APR：面向模型驱动网络管理系统演进的支持",
    "abstract_zh": "在模型驱动的网络生态系统中，诸如YANG数据模型等高层次规范定义了API，工程师通过自定义代码和处理程序对其进行扩展。当模型演进时，其与API实现之间可能产生偏差，通常需要人工进行耗时、昂贵且易出错的重新对齐工作，这凸显了自动化修复的必要性。本文介绍了我们正在进行的自动化修复方法研究，旨在将不断演进的YANG模型与其API实现重新同步，采用四阶段流水线：（i）定位当前模型与更新后模型之间的兼容性差异与破坏性变更；（ii）为每个差异记录补充上下文信息；（iii）为每项变更实例化精确的转换规则；（iv）应用这些规则生成修复后的代码，并附带可审查的变更日志，供工程师验证。为探索该方法的可行性，我们开发了一个初步原型系统——YANG-APR，针对五种常见的模型演进场景：数据类型变更、节点重命名、端点URL重命名、端点移除以及端点添加。本文通过两个典型案例加以说明：一次具有破坏性的数据类型修改，以及一次非破坏性的端点添加。早期实验结果表明，该方法在促进模型与实现共同演进方面展现出良好的潜力，为后续的持续开发和更广泛评估奠定了基础。"
  },
  {
    "date": "2025-12-11",
    "title": "Graphite: Automated Development of Hybrid Graphical-Textual DSL Editors",
    "authors": "Ionut Predoaia, Dimitris Kolovos, Antonio García-Domínguez",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00021",
    "source": "IEEE",
    "abstract": "Hybrid graphical-textual domain-specific languages can deliver the best of both worlds of graphical and textual modelling, by providing a graphical syntax for some parts of the language and a textual syntax for others. Graphite is a tool that facilitates the automated development of hybrid graphical-textual model editors for domain-specific languages. This paper outlines the capabilities of the hybrid editors generated by Graphite: smart textual editors, textual-graphical cross-referencing, integrated refactoring, consistency enforcement, tolerance of temporary inconsistencies, integrated abstract syntax graph, uniform error reporting, and conditional storage of derived model elements. Furthermore, the language engineering process employed by Graphite is demonstrated.",
    "title_zh": "石墨：混合图形-文本领域特定语言编辑器的自动化开发",
    "abstract_zh": "混合式图形-文本领域特定语言能够结合图形化建模与文本化建模的优势，通过为语言的不同部分分别采用图形语法和文本语法来实现。Graphite 是一个工具，可促进为领域特定语言自动生成混合式图形-文本模型编辑器。本文概述了 Graphite 生成的混合式编辑器所具备的功能：智能文本编辑、文本与图形之间的交叉引用、集成重构、一致性强制、对临时不一致性的容忍、集成的抽象语法图、统一的错误报告，以及派生模型元素的条件存储。此外，本文还展示了 Graphite 所采用的语言工程过程。"
  },
  {
    "date": "2025-12-11",
    "title": "Impact of Oversampling Methods on Imbalanced Dataset for Software Fault Prediction",
    "authors": "Alireza Abiri, Alireza Tajary, Mansoor Fateh",
    "publish": "2025 15th International Conference on Computer and Knowledge Engineering (ICCKE)",
    "url": "https://doi.org/10.1109/iccke68588.2025.11273874",
    "source": "IEEE",
    "abstract": "In today's world, marked by swift technological progress and the growing use and scale of software systems both in terms of data volume and number of users, the occurrence of software faults has become inevitable. Consequently, software fault prediction has gained significant importance for the early identification of faulty modules during the software development process. However, one of the key challenges in this domain is the class imbalance problem, where the number of faulty and non-faulty instances in software datasets is highly unequal. To address this issue, data oversampling techniques are commonly employed to balance the datasets. In this study, we investigate and compare the performance of three data oversampling methods on the BugHunter software fault dataset. The results indicate that using Generative Adversarial Networks (GANs) for data generation and oversampling is a more effective approach for addressing class imbalance, achieving better performance compared to alternative methods.",
    "title_zh": "过采样方法对不平衡数据集在软件缺陷预测中的影响",
    "abstract_zh": "在当今这个技术飞速发展、软件系统在数据量和用户规模上不断增长的时代，软件故障的发生已成为不可避免的现象。因此，软件故障预测在软件开发过程中对早期识别存在缺陷的模块具有重要意义。然而，该领域面临的一个关键挑战是类别不平衡问题，即软件数据集中故障与非故障实例的数量极不均衡。为解决这一问题，通常采用数据过采样技术来平衡数据集。本研究针对BugHunter软件故障数据集，探讨并比较了三种数据过采样方法的性能。结果表明，利用生成对抗网络（GANs）进行数据生成与过采样，是一种更有效的应对类别不平衡的方法，其表现优于其他替代方案。"
  },
  {
    "date": "2025-12-11",
    "title": "A Proof-Of-Concept ASIC RISC-V Based SoC for Industrial Applications",
    "authors": "Sara Alonso, Alejandro Arteaga, Leire Muguira, Carlos Cuadrado, Aitzol Zuloaga, Jaime Jiménez, Jesús Lázaro, José Ignacio Gárate, José Angel Araujo, Victor Martínez, Unai Bidarte, Armando Astarloa",
    "publish": "2025 40th Conference on Design of Circuits and Integrated Systems (DCIS)",
    "url": "https://doi.org/10.1109/dcis67520.2025.11281905",
    "source": "IEEE",
    "abstract": "This work presents SoC4cris_p1, a proof-ofconcept ASIC implementation of a RISC-V-based System-on-Chip (SoC) tailored for Industrial Internet of Things (IIoT) applications. Built on the neorv32 RISC-V HDL core, SoC4cris_p1 prioritizes execution safety and deterministic behavior. Key enhancements include a redesigned memory map for improved internal memory usage, an extended boot system, optimized peripherals, and integration of four experimental IPs from Basque Country research centers to support IIoT-specific functions. The paper covers architectural modifications, front-end FPGA prototyping, back-end ASIC design using 65nm UMC technology, and validation using a custom test board.",
    "title_zh": "用于工业应用的基于RISC-V的原型ASIC片上系统",
    "abstract_zh": "本文介绍了SoC4cris_p1，这是一个面向工业物联网（IIoT）应用的基于RISC-V的片上系统（SoC）概念验证ASIC实现。该设计基于neorv32 RISC-V HDL核心，特别注重执行安全性和行为确定性。主要改进包括：重新设计的内存映射以提升内部内存使用效率，扩展的启动系统，优化的外设配置，以及集成了来自巴斯克地区研究机构的四个实验性IP核，以支持IIoT特定功能。论文涵盖了架构修改、前端FPGA原型设计、采用65nm UMC工艺的后端ASIC设计，以及通过定制测试板完成的验证工作。"
  },
  {
    "date": "2025-12-11",
    "title": "A Framework for Automated CGRA Design Space Exploration with Genetic Algorithm Optimization",
    "authors": "Maryam Katebzadeh, Daniel Vazquez, Andres Otero, Alfonso Rodriguez",
    "publish": "2025 40th Conference on Design of Circuits and Integrated Systems (DCIS)",
    "url": "https://doi.org/10.1109/dcis67520.2025.11281902",
    "source": "IEEE",
    "abstract": "The rapid growth of compute-intensive applications has created a pressing need for computing architectures that effectively balance flexibility, efficiency, and performance. While Field-Programmable Gate Arrays (FPGAs) offer a good level of flexibility, they suffer from high configuration overhead and energy consumption. Coarse-Grained Reconfigurable Architectures (CGRAs) provide a more energy-efficient alternative with lower configuration costs. They can be customized for domainspecific applications by modifying their coarse-grained processing elements to execute particular sequences of operations. In fact, their domain-specific nature can be used to further improve their energy efficiency and reduce their area overhead by exploiting computing fabric specialization. This can be achieved by replacing homogeneous processing elements with a subset of heterogeneous, more optimized ones that are specifically suited to the target application domain. However, achieving an optimal CGRA configuration requires extensive design space exploration (DSE), which involves evaluating many architectural possibilities. Existing CGRA frameworks struggle with slow and inefficient exploration due to long runtimes and constrained customization options. These issues make it hard to find the best configurations rapidly. To tackle these challenges, this paper presents Genetic Algorithm-based CGRA Generator (GA-CG), a framework that enhances DSE in the CGRA design process. GA-CG uses a genetic algorithm to discover an efficient structural configuration, thereby improving resource utilization and reducing power consumption.",
    "title_zh": "基于遗传算法优化的自动化CGRA设计空间探索框架",
    "abstract_zh": "计算密集型应用的快速发展催生了对计算架构的迫切需求，这类架构需在灵活性、效率和性能之间实现有效平衡。尽管现场可编程门阵列（FPGAs）提供了良好的灵活性，但其存在配置开销高和能耗大的问题。粗粒度可重构架构（CGRAs）则提供了一种更为节能的替代方案，具有更低的配置成本。通过修改其粗粒度处理单元，CGRAs可针对特定应用领域进行定制，以执行特定的操作序列。事实上，其领域专用特性可通过利用计算结构的专门化进一步提升能效并降低面积开销。这可以通过用一组异构且更优化的处理单元替代原本同质的处理单元来实现，这些处理单元专为特定应用领域量身打造。然而，要获得最优的CGRA配置，需要进行广泛的设计空间探索（DSE），即评估大量可能的架构设计。现有的CGRA框架在探索过程中面临运行时间长、定制选项受限等问题，导致难以快速找到最佳配置。为应对这些挑战，本文提出了一种基于遗传算法的CGRA生成器（GA-CG），该框架能够提升CGRA设计过程中的设计空间探索效率。GA-CG采用遗传算法自动发现高效的结构配置，从而提高资源利用率并降低功耗。"
  },
  {
    "date": "2025-12-11",
    "title": "Enhancing Software Defect Prediction Accuracy through Feature Selection-Driven Hybrid Intelligence",
    "authors": "Vanapalli Kiran Kumar, Balajee Maram, Shanker Chandre",
    "publish": "2025 Third International Conference on Industry 4.0 Technology (I4Tech)",
    "url": "https://doi.org/10.1109/i4tech64670.2025.11277790",
    "source": "IEEE",
    "abstract": "Foremost, predicting software defects is essential to enhance software quality, as well as to minimize development costs. There is no doubt that defect identification is vital to software quality. The authors of this paper propose a hybrid intelligent model which incorporates feature selection processes with algorithms to increase accuracy in defect prediction. Using publicly accessible datasets from the PROMISE repository, including NASA's MDP datasets, the model attained a mean accuracy of 92.4%, an increase of 11.3% relative to traditional models. The accuracy increase of 14% alongside model complexity reduction of 25% from RFE and Mutual Information based feature selection methods demonstrate the robustness of these feature selection techniques. Additional tests done on the hybrid model of random forest and support vector machines confirmed the model’s reliability in addition to the successful generalizability tests. The claim that the model is adept at identifying accurate and precise measurements of fault-prone modules is validated by the experimental results, reinforcing the confidence in the model’s adaptability and robustness with regard to automation in processes of software quality engineering.",
    "title_zh": "通过特征选择驱动的混合智能提升软件缺陷预测准确性",
    "abstract_zh": "首先，预测软件缺陷对于提升软件质量以及降低开发成本至关重要。毫无疑问，缺陷识别对软件质量具有关键作用。本文作者提出了一种混合智能模型，通过结合特征选择过程与算法，以提高缺陷预测的准确性。利用来自PROMISE数据仓库的公开数据集（包括NASA的MDP数据集），该模型实现了92.4%的平均准确率，相较于传统模型提升了11.3%。基于递归特征消除（RFE）和互信息的特征选择方法，在实现14%准确率提升的同时，还将模型复杂度降低了25%，充分证明了这些特征选择技术的稳健性。对随机森林与支持向量机混合模型进行的额外测试进一步验证了该模型的可靠性，并通过了成功的泛化能力测试。实验结果证实，该模型能够有效识别出故障易发模块的精确且准确的度量指标，从而增强了人们对该模型在软件质量工程自动化过程中适应性和鲁棒性的信心。"
  },
  {
    "date": "2025-12-11",
    "title": "AI-assisted JSON Schema Creation and Mapping",
    "authors": "Felix Neubauer, Benjamin Uekermann, Jürgen Pleiss",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00019",
    "source": "IEEE",
    "abstract": "Model-Driven Engineering (MDE) places models at the core of system and data engineering processes. In the context of research data, these models are typically expressed as schemas that define the structure and semantics of datasets. However, many domains still lack standardized models, and creating them remains a significant barrier, especially for non-experts. We present a hybrid approach that combines large language models (LLMs) with deterministic techniques to enable JSON Schema creation, modification, and schema mapping based on natural language inputs by the user. These capabilities are integrated into the open-source tool MetaConfigurator, which already provides visual model editing, validation, code generation, and form generation from models. For data integration, we generate schema mappings from heterogeneous JSON, CSV, XML, and YAML data using LLMs, while ensuring scalability and reliability through deterministic execution of generated mapping rules. The applicability of our work is demonstrated in an application example in the field of chemistry. By combining natural language interaction with deterministic safeguards, this work significantly lowers the barrier to structured data modeling and data integration for non-experts.",
    "title_zh": "AI辅助的JSON Schema创建与映射",
    "abstract_zh": "模型驱动工程（MDE）将模型置于系统与数据工程流程的核心位置。在研究数据的背景下，这些模型通常以定义数据集结构和语义的模式（schema）形式表达。然而，许多领域仍缺乏标准化的模型，而创建这些模型对非专家而言仍是重大障碍。本文提出一种混合方法，结合大型语言模型（LLM）与确定性技术，使用户能够通过自然语言输入实现JSON Schema的创建、修改以及模式映射。这些功能已集成至开源工具MetaConfigurator中，该工具原本就支持基于模型的可视化编辑、验证、代码生成及表单生成。在数据集成方面，我们利用大语言模型从异构的JSON、CSV、XML和YAML数据中生成模式映射，并通过确定性执行生成的映射规则来确保可扩展性与可靠性。我们的工作在化学领域的应用实例中得到了验证。通过将自然语言交互与确定性保障相结合，本研究显著降低了非专家在结构化数据建模与数据集成方面的门槛。"
  },
  {
    "date": "2025-12-11",
    "title": "Engineering Digital Twins with Statecharts: A Smart Home Application",
    "authors": "Sahil Salma, Zenan Zha, Protik Mukherjee, Sadaf Mustafiz",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00037",
    "source": "IEEE",
    "abstract": "This paper presents a model-driven approach for the design and development of digital twins. Our work leverages statecharts for behaviour modelling and for synthesizing application code to be deployed on both the physical twin (PT) and digital twin (DT). This ensures consistency between physical and digital entities and enables real-time synchronization and coordinated control. A real-time cloud database integrated with the models facilitates bidirectional communication, while user interfaces, such as a dashboard and mobile app, support monitoring, analysis, and control. We demonstrate our approach with a smart home application consisting of a smart hub of lights, a garage door controller, and a fire alarm system, all coordinated through a central smart home hub. The smart home DT supports simulation, reasoning, and run-time adaptation. https://cs.torontomu. ca/~sml/demos/smarthomedt-demo.html",
    "title_zh": "使用状态图构建数字孪生：一个智能家居应用",
    "abstract_zh": "本文提出了一种基于模型驱动的方法，用于数字孪生的设计与开发。我们的工作利用状态图进行行为建模，并自动生成可部署在物理孪生（PT）和数字孪生（DT）上的应用代码，从而确保物理实体与数字实体之间的一致性，实现实时同步与协同控制。一个集成于模型中的实时云数据库支持双向通信，而用户界面（如仪表板和移动应用）则支持监控、分析与控制功能。我们通过一个智能家居应用实例展示了该方法的有效性，该应用包括智能灯光集线器、车库门控制器和火灾报警系统，均由中央智能家居枢纽统一协调。该智能家居数字孪生支持仿真、推理以及运行时自适应。演示视频可访问：https://cs.torontomu. ca/~sml/demos/smarthomedt-demo.html"
  },
  {
    "date": "2025-12-11",
    "title": "Fine-Tuning and Deploying Large Language Models Over Edges: Issues and Approaches",
    "authors": "Yanjie Dong, Haijun Zhang, Chengming Li, Song Guo, Victor C. M. Leung, Xiping Hu",
    "publish": "IEEE Communications Magazine",
    "url": "https://doi.org/10.1109/mcom.001.2400602",
    "source": "IEEE",
    "abstract": "Since the release of GPT2-1.5B in 2019, the large language models (LLMs) have evolved from specialized deep models to versatile foundation models. While demonstrating remarkable zero-shot ability, the LLMs still require fine-tuning on local datasets and substantial memory for deployment over the network edges. Traditional first-order fine-tuning techniques require significant GPU memory that exceeds the capacity of mainstream hardware. Besides, the LLMs have been expanded beyond text generation to create images, audio, video, and multi-modal content, necessitating careful investigation of efficient deployment strategies for large-scale foundation models. In response to these challenges, model fine-tuning and model-compression techniques have been developed to support the sustainable growth of LLMs by reducing both operational and capital expenditures. In this work, we provide a comprehensive overview of prevalent memory-efficient fine-tuning methods for deployment at the network edge. We also review state-of-the-art literature on model compression, offering insights into the deployment of LLMs at network edges.",
    "title_zh": "在边缘端微调与部署大型语言模型：问题与方法",
    "abstract_zh": "自2019年发布GPT-2-1.5B以来，大型语言模型（LLMs）已从专用的深度模型演变为多功能的基础模型。尽管在零样本学习方面表现出色，但这些模型在边缘网络部署时仍需在本地数据集上进行微调，并消耗大量内存。传统的基于一阶优化的微调方法需要大量的GPU内存，超出了主流硬件的承载能力。此外，LLMs的应用已从文本生成扩展至图像、音频、视频及多模态内容的生成，这要求对大规模基础模型的高效部署策略进行深入研究。为应对这些挑战，模型微调与模型压缩技术应运而生，旨在通过降低运营和资本支出，推动LLMs的可持续发展。本文全面综述了适用于网络边缘部署的主流内存高效微调方法，并回顾了模型压缩领域的最新研究成果，为LLMs在边缘网络中的部署提供了深刻见解。"
  },
  {
    "date": "2025-12-11",
    "title": "Comparing High- and Low-Level Model Representations for Evolutionary Algorithms",
    "authors": "Henrik Eckhardt, Jens Kosiol",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00120",
    "source": "IEEE",
    "abstract": "Model-driven optimization promises the availability of meta-heuristic approaches, such as evolutionary algorithms, for optimization problems to domain experts, without requiring deeper knowledge of the underlying technologies. Models directly serve as the problem specification, while model transformations form the evolutionary operators for exploring the search space. Evolutionary algorithms, however, are usually designed to operate on low-level representations (or encodings) such as bit strings or vectors of integers or real numbers. As models generally consist of multiple high-level constructs and are much more complex than the usual low-level encodings, a performance penalty is to be expected when operating directly on such models. On the other hand, models provide additional domain knowledge and, as such, allow for the design of more sophisticated evolutionary operators. In this work we compare the performance of evolutionary algorithms operating on high- and low-level representations of solutions on two problems, the class responsibility assignment problem as well as the multi-objective knapsack problem. The results show a clear advantage of high-level model representations in terms of solution quality, producing higher-quality results for all evaluated instances, which generally come at the cost of a higher total duration. The extent of the differences and their reasons are found to greatly depend on the complexity of the model and its instances.",
    "title_zh": "进化算法中高低层模型表示的比较",
    "abstract_zh": "模型驱动的优化为领域专家提供了元启发式方法（如进化算法）来解决优化问题，而无需深入了解底层技术。在这一过程中，模型直接作为问题规范，而模型转换则构成探索搜索空间的进化算子。然而，进化算法通常设计用于操作低层次表示（或编码），例如位串或整数/实数向量。由于模型通常由多个高层次构造组成，且比常见的低层次编码复杂得多，因此直接在模型上操作时不可避免地会带来性能开销。另一方面，模型还提供了额外的领域知识，从而允许设计更为复杂的进化算子。本文通过在两个问题——类责任分配问题和多目标背包问题——上比较基于高层次与低层次解表示的进化算法性能，发现高层次模型表示在解的质量方面具有明显优势：对于所有评估实例，均能产生更高质量的结果，尽管这通常伴随着更高的总运行时间。研究结果表明，两者之间的差异程度及其原因在很大程度上取决于模型及其实例的复杂性。"
  },
  {
    "date": "2025-12-11",
    "title": "Modeling the Full Stack: Frontend and Backend Generation with Extended Domain Models",
    "authors": "Gagandeep Singh, Gunter Mussbacher",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.00009",
    "source": "IEEE",
    "abstract": "In model-driven engineering courses, students are often asked to implement complete applications from domain models with code generation following architectures such as Model-View-Controller. However, much of the implementa-tion-both backend logic and user interface still involves substantial manual effort. FeatureLanguage is a lightweight domainspecific language built on top of domain models and introduced to enable code generation from high-level feature specifications in such educational settings. In this work, we extend FeatureLanguage to also support User Interface (UI) generation. This extension enables automatic generation of frontend alongside backend components, all from a user-defined domain model, layout related constructs, and UI annotations, which are all expressed in an extended class diagram. The result is a more complete transformation pipeline that reduces the implementation burden on students and instructors. According to a comparison of the generated UI screens against the manually crafted UI implementation over four course projects, on average $83 \\%$ of required UI elements per screen are automatically generated.",
    "title_zh": "建模全栈：基于扩展领域模型的前端与后端生成",
    "abstract_zh": "在模型驱动工程课程中，学生通常被要求根据领域模型通过代码生成的方式实现完整的应用程序，并遵循如模型-视图-控制器（Model-View-Controller）之类的架构。然而，大部分实现工作——包括后端逻辑和用户界面——仍然需要大量的手动操作。FeatureLanguage 是一种基于领域模型构建的轻量级领域特定语言，旨在教育环境中通过高层次的功能规格来实现代码生成。在本研究中，我们扩展了 FeatureLanguage，使其也支持用户界面（UI）的自动生成。这一扩展使得前端与后端组件能够全部从用户定义的领域模型、与布局相关的构造以及 UI 注解自动生成，而这些元素均以扩展的类图形式表达。结果是一个更加完整的转换流程，显著减轻了学生和教师的实现负担。根据对四个课程项目中生成的 UI 界面与手工编写的 UI 实现之间的对比分析，平均每个界面有 83% 的所需 UI 元素可被自动生成。"
  },
  {
    "date": "2025-12-11",
    "title": "Large Language Models-based Software Test Input Generation",
    "authors": "Seda Akin Akman, Berkay Ertem, Cagatay Catal",
    "publish": "2025 IEEE Latin American Conference on Computational Intelligence (LA-CCI)",
    "url": "https://doi.org/10.1109/la-cci66231.2025.11270460",
    "source": "IEEE",
    "abstract": "Test input generation is a critical aspect of software testing, ensuring the quality and reliability of software systems. In recent years, Large Language Models (LLMs) have gained significant attention for their potential to automate and enhance this process. While several studies have explored the use of LLMs in test input generation, a systematic overview of the state of the art in LLM-based test input generation is lacking. Therefore, this systematic literature review (SLR) examines the current state of LLMs in test input generation. A search across multiple databases identified 113 relevant papers, of which 17 specifically focused on test input generation and were selected for in-depth analysis. The study evaluates LLMs based on their applicability, challenges, and limitations. The findings indicate that while LLMs effectively automate and diversify test input generation, challenges remain in scalability and domain-specific adaptability. This study provides insights into the current capabilities of LLMs and their future potential in test input generation.",
    "title_zh": "基于大语言模型的软件测试输入生成",
    "abstract_zh": "测试输入生成是软件测试中的关键环节，对于确保软件系统的质量和可靠性至关重要。近年来，大型语言模型（LLMs）因其在自动化和提升该过程方面的潜力而受到广泛关注。尽管已有若干研究探讨了LLMs在测试输入生成中的应用，但目前仍缺乏对基于LLMs的测试输入生成领域最新进展的系统性综述。因此，本系统文献回顾（SLR）旨在全面分析当前LLMs在测试输入生成中的应用现状。通过在多个数据库中进行检索，共识别出113篇相关论文，其中17篇专门聚焦于测试输入生成，被选中进行深入分析。研究从适用性、挑战与局限性等方面评估了LLMs的表现。结果表明，虽然LLMs在自动化和多样化测试输入生成方面表现出色，但在可扩展性和特定领域适应性方面仍存在挑战。本研究为理解LLMs在测试输入生成中的当前能力及其未来潜力提供了重要见解。"
  }
]