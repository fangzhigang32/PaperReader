[
  {
    "date": "2026-02-02",
    "title": "Self-Consolidation for Self-Evolving Agents",
    "authors": "Hongzhuo Yu, Fei Zhu, Guo-Sen Xie, Ling Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01966v1",
    "source": "arXiv",
    "abstract": "While large language model (LLM) agents have demonstrated impressive problem-solving capabilities, they typically operate as static systems, lacking the ability to evolve through lifelong interaction. Existing attempts to bridge this gap primarily rely on retrieving successful past trajectories as demonstrations. However, this paradigm faces two critical limitations. First, by focusing solely on success, agents overlook the rich pedagogical value embedded in failed attempts, preventing them from identifying and avoiding recurrent pitfalls. Second, continually accumulating textual experiences not only increases the time consumption during retrieval but also inevitably introduces noise and exhausts the largest context window of current LLMs. To address these challenges, we propose a novel self-evolving framework for LLM agents that introduces a complementary evolution mechanism: First, a contrastive reflection strategy is introduced to explicitly summarize error-prone patterns and capture reusable insights. Second, we propose a self-consolidation mechanism that distills non-parametric textual experience into compact learnable parameters. This enables the agent to internalize extensive historical experience directly into its latent space. Extensive experiments demonstrate the advantages of our method in long-term agent evolution.",
    "title_zh": "自我固化以实现自我演进的智能体",
    "abstract_zh": "尽管大型语言模型（LLM）代理在解决问题方面展现了令人瞩目的能力，但它们通常作为静态系统运行，缺乏通过长期交互实现自我演进的能力。现有的尝试主要依赖于检索过往成功轨迹作为示范，以弥合这一差距。然而，这种范式存在两个关键局限：首先，仅关注成功案例使代理忽略了失败尝试中蕴含的丰富教学价值，导致其无法识别并避免反复出现的陷阱；其次，持续积累的文本经验不仅增加了检索时间，还不可避免地引入噪声，并耗尽当前LLM最大上下文窗口的容量。为应对这些挑战，我们提出了一种新型的LLM代理自演化框架，引入了一种互补的演化机制：其一，提出对比反思策略，显式地总结易错模式并捕捉可复用的洞见；其二，设计自巩固机制，将非参数化的文本经验提炼为紧凑的可学习参数。这使得代理能够将大量历史经验直接内化至其隐空间中。大量实验表明，该方法在长期代理演化方面具有显著优势。"
  },
  {
    "date": "2026-02-02",
    "title": "SQLAgent: Learning to Explore Before Generating as a Data Engineer",
    "authors": "Wenjia Jiang, Yiwei Wang, Boyan Han, Joey Tianyi Zhou, Chi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01952v1",
    "source": "arXiv",
    "abstract": "Large Language Models have recently shown impressive capabilities in reasoning and code generation, making them promising tools for natural language interfaces to relational databases. However, existing approaches often fail to generalize in complex, real-world settings due to the highly database-specific nature of SQL reasoning, which requires deep familiarity with unique schemas, ambiguous semantics, and intricate join paths. To address this challenge, we introduce a novel two-stage LLM-based framework that decouples knowledge acquisition from query generation. In the Exploration Stage, the system autonomously constructs a database-specific knowledge base by navigating the schema with a Monte Carlo Tree Search-inspired strategy, generating triplets of schema fragments, executable queries, and natural language descriptions as usage examples. In the Deployment Stage, a dual-agent system leverages the collected knowledge as in-context examples to iteratively retrieve relevant information and generate accurate SQL queries in response to user questions. This design enables the agent to proactively familiarize itself with unseen databases and handle complex, multi-step reasoning. Extensive experiments on large-scale benchmarks demonstrate that our approach significantly improves accuracy over strong baselines, highlighting its effectiveness and generalizability.",
    "title_zh": "SQLAgent：作为数据工程师，先学习探索再生成",
    "abstract_zh": "大型语言模型（LLM）近期在推理和代码生成方面展现出令人瞩目的能力，使其成为自然语言与关系型数据库交互的有力工具。然而，现有方法在复杂的真实场景中往往难以泛化，原因在于SQL推理具有高度依赖数据库的特性，需要对独特的数据模式、模糊的语义以及复杂的连接路径有深入理解。为应对这一挑战，我们提出了一种新颖的两阶段LLM框架，将知识获取与查询生成过程解耦。在探索阶段，系统通过受蒙特卡洛树搜索启发的策略自主导航数据库模式，构建一个面向特定数据库的知识库，生成由模式片段、可执行查询和自然语言描述组成的三元组作为使用示例。在部署阶段，一个双代理系统利用所收集的知识作为上下文示例，迭代地检索相关信息，并根据用户问题生成准确的SQL查询。该设计使代理能够主动熟悉未见过的数据库，并有效处理复杂的多步推理任务。在大规模基准测试上的大量实验表明，我们的方法显著优于多个强基线模型，充分证明了其有效性与良好的泛化能力。"
  },
  {
    "date": "2026-02-02",
    "title": "Boundary-Constrained Diffusion Models for Floorplan Generation: Balancing Realism and Diversity",
    "authors": "Leonardo Stoppani, Davide Bacciu, Shahab Mokarizadeh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01949v1",
    "source": "arXiv",
    "abstract": "Diffusion models have become widely popular for automated floorplan generation, producing highly realistic layouts conditioned on user-defined constraints. However, optimizing for perceptual metrics such as the Fréchet Inception Distance (FID) causes limited design diversity. To address this, we propose the Diversity Score (DS), a metric that quantifies layout diversity under fixed constraints. Moreover, to improve geometric consistency, we introduce a Boundary Cross-Attention (BCA) module that enables conditioning on building boundaries. Our experiments show that BCA significantly improves boundary adherence, while prolonged training drives diversity collapse undiagnosed by FID, revealing a critical trade-off between realism and diversity. Out-Of-Distribution evaluations further demonstrate the models' reliance on dataset priors, emphasizing the need for generative systems that explicitly balance fidelity, diversity, and generalization in architectural design tasks.",
    "title_zh": "边界约束的扩散模型用于平面布局生成：平衡真实感与多样性",
    "abstract_zh": "扩散模型在自动化户型图生成中已广受欢迎，能够根据用户定义的约束生成高度逼真的布局。然而，仅优化感知指标（如Fréchet Inception距离，FID）会导致设计多样性受限。为解决这一问题，我们提出了多样性评分（Diversity Score, DS），用于在固定约束条件下量化布局的多样性。此外，为提升几何一致性，我们引入了边界交叉注意力（Boundary Cross-Attention, BCA）模块，使模型能够基于建筑边界进行条件生成。实验结果表明，BCA显著提升了边界贴合度；而长时间训练则会引发多样性崩溃，这一问题却未被FID所察觉，揭示了真实感与多样性之间存在的关键权衡。分布外评估进一步表明，现有模型严重依赖数据集先验，凸显了在建筑设计任务中，生成系统必须显式平衡保真度、多样性与泛化能力的迫切需求。"
  },
  {
    "date": "2026-02-02",
    "title": "COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation",
    "authors": "Annabelle Sujun Tang, Christopher Priebe, Lianhui Qin, Hadi Esmaeilzadeh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01935v1",
    "source": "arXiv",
    "abstract": "Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. However, using a single large model throughout the search is expensive, while smaller models are less reliable when used alone. Thus, this paper seeks to answer whether multi-LLM collaborative reasoning relying primarily on small LLMs can match or exceed the performance of a single large model. As such, we propose a lightweight collaborative multi-LLM framework, dubbed COLT, for compiler optimization that enables coordinated reasoning across multiple models within a single Monte Carlo tree search (MCTS) process. A key contribution is the use of a single shared MCTS tree as the collaboration substrate across LLMs, enabling the reuse of transformation prefixes and cross-model value propagation. Hence, we circumvent both heavy internal reasoning mechanisms and conventional agentic machinery that relies on external planners, multiple concurrent LLMs, databases, external memory/versioning of intermediate results, and controllers by simply endogenizing model selection within the lightweight MCTS optimization loop. Every iteration, the acting LLM proposes a joint action: (compiler transformation, model to be queried next). We also introduce a model-aware tree policy that biases search toward smaller models while preserving exploration, and a course-alteration mechanism that escalates to the largest model when the search exhibits persistent regressions attributable to smaller models.",
    "title_zh": "COLT：通过共享MCTS推理实现轻量级多大模型协作的模型编译方法",
    "abstract_zh": "模型服务成本在人工智能系统中占据主导地位，因此编译器优化对于实现可扩展部署至关重要。近期研究显示，大型语言模型（LLM）可通过推理程序结构和优化历史来引导编译器搜索过程。然而，全程使用单一大型模型进行搜索成本高昂，而单独使用小型模型又缺乏可靠性。因此，本文旨在探讨：是否可以通过主要依赖小型模型的多LLM协同推理，实现与单一大型模型相当甚至更优的性能？为此，我们提出了一种轻量级的多LLM协作框架——COLT，用于编译器优化。该框架在单一蒙特卡洛树搜索（MCTS）过程中实现多个模型间的协同推理。其关键贡献在于，采用单一共享的MCTS树作为各LLM之间的协作基础，从而实现变换前缀的复用以及跨模型价值传播。由此，我们避免了复杂的内部推理机制，也无需依赖外部规划器、多个并发LLM、数据库、外部记忆/中间结果版本控制以及控制器等传统代理式架构。通过将模型选择机制内置于轻量级MCTS优化循环中，实现了系统简化。在每次迭代中，当前执行的LLM会提出一个联合动作：（编译器变换操作，下一个要查询的模型）。此外，我们还引入了一种模型感知的树策略，能够在保持探索能力的同时，倾向于选择较小的模型；并设计了一种“路径修正”机制，当搜索因小型模型导致持续性能退化时，自动升级至最大模型以纠正方向。"
  },
  {
    "date": "2026-02-02",
    "title": "SWE-Universe: Scale Real-World Verifiable Environments to Millions",
    "authors": "Mouxiang Chen, Lei Zhang, Yunlong Feng, Xuwu Wang, Wenting Zhao, Ruisheng Cao, Jiaxi Yang, Jiawei Chen, Mingze Li, Zeyao Ma, Hao Ge, Zongmeng Zhang, Zeyu Cui, Dayiheng Liu, Jingren Zhou, Jianling Sun, Junyang Lin, Binyuan Hui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02361v1",
    "source": "arXiv",
    "abstract": "We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model. This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning. Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified. Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents.",
    "title_zh": "SWE-Universe：将真实可验证的环境扩展至数百万规模",
    "abstract_zh": "我们提出了 SWE-Universe，这是一个可扩展且高效的框架，能够从 GitHub 拉取请求（PRs）中自动构建真实世界软件工程（SWE）可验证的环境。为克服自动构建中普遍存在的挑战，如产出率低、验证能力弱以及成本过高，我们的框架采用了一个由高效定制训练模型驱动的构建智能体。该智能体通过迭代式自我验证和循环内黑客检测机制，确保生成高质量、可验证的任务。借助这一方法，我们将真实世界多语言 SWE 环境的数量扩展至百万级别（807,693 个）。我们通过大规模智能体中段训练和强化学习，充分展示了这些环境的深远价值。最后，我们将该技术应用于 Qwen3-Max-Thinking 模型，在 SWE-Bench Verified 上取得了 75.3% 的成绩。我们的工作不仅提供了一个关键资源，也建立了一套稳健的方法论，推动下一代编程智能体的发展。"
  },
  {
    "date": "2026-02-02",
    "title": "Kimi K2.5: Visual Agentic Intelligence",
    "authors": "Kimi Team, Tongtong Bai, Yifan Bai, Yiping Bao, S. H. Cai, Yuan Cao, Y. Charles, H. S. Che, Cheng Chen, Guanduo Chen, Huarong Chen, Jia Chen, Jiahao Chen, Jianlong Chen, Jun Chen, Kefan Chen, Liang Chen, Ruijue Chen, Xinhao Chen, Yanru Chen, Yanxu Chen, Yicun Chen, Yimin Chen, Yingjiang Chen, Yuankun Chen, Yujie Chen, Yutian Chen, Zhirong Chen, Ziwei Chen, Dazhi Cheng, Minghan Chu, Jialei Cui, Jiaqi Deng, Muxi Diao, Hao Ding, Mengfan Dong, Mengnan Dong, Yuxin Dong, Yuhao Dong, Angang Du, Chenzhuang Du, Dikang Du, Lingxiao Du, Yulun Du, Yu Fan, Shengjun Fang, Qiulin Feng, Yichen Feng, Garimugai Fu, Kelin Fu, Hongcheng Gao, Tong Gao, Yuyao Ge, Shangyi Geng, Chengyang Gong, Xiaochen Gong, Zhuoma Gongque, Qizheng Gu, Xinran Gu, Yicheng Gu, Longyu Guan, Yuanying Guo, Xiaoru Hao, Weiran He, Wenyang He, Yunjia He, Chao Hong, Hao Hu, Jiaxi Hu, Yangyang Hu, Zhenxing Hu, Ke Huang, Ruiyuan Huang, Weixiao Huang, Zhiqi Huang, Tao Jiang, Zhejun Jiang, Xinyi Jin, Yu Jing, Guokun Lai, Aidi Li, C. Li, Cheng Li, Fang Li, Guanghe Li, Guanyu Li, Haitao Li, Haoyang Li, Jia Li, Jingwei Li, Junxiong Li, Lincan Li, Mo Li, Weihong Li, Wentao Li, Xinhang Li, Xinhao Li, Yang Li, Yanhao Li, Yiwei Li, Yuxiao Li, Zhaowei Li, Zheming Li, Weilong Liao, Jiawei Lin, Xiaohan Lin, Zhishan Lin, Zichao Lin, Cheng Liu, Chenyu Liu, Hongzhang Liu, Liang Liu, Shaowei Liu, Shudong Liu, Shuran Liu, Tianwei Liu, Tianyu Liu, Weizhou Liu, Xiangyan Liu, Yangyang Liu, Yanming Liu, Yibo Liu, Yuanxin Liu, Yue Liu, Zhengying Liu, Zhongnuo Liu, Enzhe Lu, Haoyu Lu, Zhiyuan Lu, Junyu Luo, Tongxu Luo, Yashuo Luo, Long Ma, Yingwei Ma, Shaoguang Mao, Yuan Mei, Xin Men, Fanqing Meng, Zhiyong Meng, Yibo Miao, Minqing Ni, Kun Ouyang, Siyuan Pan, Bo Pang, Yuchao Qian, Ruoyu Qin, Zeyu Qin, Jiezhong Qiu, Bowen Qu, Zeyu Shang, Youbo Shao, Tianxiao Shen, Zhennan Shen, Juanfeng Shi, Lidong Shi, Shengyuan Shi, Feifan Song, Pengwei Song, Tianhui Song, Xiaoxi Song, Hongjin Su, Jianlin Su, Zhaochen Su, Lin Sui, Jinsong Sun, Junyao Sun, Tongyu Sun, Flood Sung, Yunpeng Tai, Chuning Tang, Heyi Tang, Xiaojuan Tang, Zhengyang Tang, Jiawen Tao, Shiyuan Teng, Chaoran Tian, Pengfei Tian, Ao Wang, Bowen Wang, Chensi Wang, Chuang Wang, Congcong Wang, Dingkun Wang, Dinglu Wang, Dongliang Wang, Feng Wang, Hailong Wang, Haiming Wang, Hengzhi Wang, Huaqing Wang, Hui Wang, Jiahao Wang, Jinhong Wang, Jiuzheng Wang, Kaixin Wang, Linian Wang, Qibin Wang, Shengjie Wang, Shuyi Wang, Si Wang, Wei Wang, Xiaochen Wang, Xinyuan Wang, Yao Wang, Yejie Wang, Yipu Wang, Yiqin Wang, Yucheng Wang, Yuzhi Wang, Zhaoji Wang, Zhaowei Wang, Zhengtao Wang, Zhexu Wang, Zihan Wang, Zizhe Wang, Chu Wei, Ming Wei, Chuan Wen, Zichen Wen, Chengjie Wu, Haoning Wu, Junyan Wu, Rucong Wu, Wenhao Wu, Yuefeng Wu, Yuhao Wu, Yuxin Wu, Zijian Wu, Chenjun Xiao, Jin Xie, Xiaotong Xie, Yuchong Xie, Yifei Xin, Bowei Xing, Boyu Xu, Jianfan Xu, Jing Xu, Jinjing Xu, L. H. Xu, Lin Xu, Suting Xu, Weixin Xu, Xinbo Xu, Xinran Xu, Yangchuan Xu, Yichang Xu, Yuemeng Xu, Zelai Xu, Ziyao Xu, Junjie Yan, Yuzi Yan, Guangyao Yang, Hao Yang, Junwei Yang, Kai Yang, Ningyuan Yang, Ruihan Yang, Xiaofei Yang, Xinlong Yang, Ying Yang, Yi Yang, Yi Yang, Zhen Yang, Zhilin Yang, Zonghan Yang, Haotian Yao, Dan Ye, Wenjie Ye, Zhuorui Ye, Bohong Yin, Chengzhen Yu, Longhui Yu, Tao Yu, Tianxiang Yu, Enming Yuan, Mengjie Yuan, Xiaokun Yuan, Yang Yue, Weihao Zeng, Dunyuan Zha, Haobing Zhan, Dehao Zhang, Hao Zhang, Jin Zhang, Puqi Zhang, Qiao Zhang, Rui Zhang, Xiaobin Zhang, Y. Zhang, Yadong Zhang, Yangkun Zhang, Yichi Zhang, Yizhi Zhang, Yongting Zhang, Yu Zhang, Yushun Zhang, Yutao Zhang, Yutong Zhang, Zheng Zhang, Chenguang Zhao, Feifan Zhao, Jinxiang Zhao, Shuai Zhao, Xiangyu Zhao, Yikai Zhao, Zijia Zhao, Huabin Zheng, Ruihan Zheng, Shaojie Zheng, Tengyang Zheng, Junfeng Zhong, Longguang Zhong, Weiming Zhong, M. Zhou, Runjie Zhou, Xinyu Zhou, Zaida Zhou, Jinguo Zhu, Liya Zhu, Xinhao Zhu, Yuxuan Zhu, Zhen Zhu, Jingze Zhuang, Weiyu Zhuang, Ying Zou, Xinxing Zu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02276v1",
    "source": "arXiv",
    "abstract": "We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to $4.5\\times$ over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.",
    "title_zh": "Kimi K2.5：视觉智能代理",
    "abstract_zh": "我们推出Kimi K2.5，这是一个开源的多模态智能体模型，旨在推动通用智能体智能的发展。K2.5强调文本与视觉模态的联合优化，使两种模态相互促进。这包括一系列技术，如联合文本-视觉预训练、零视觉监督微调（SFT）以及联合文本-视觉强化学习。在此多模态基础之上，K2.5引入了Agent Swarm——一种自驱动的并行智能体编排框架，能够动态地将复杂任务分解为异构的子问题，并实现并发执行。大量评估表明，Kimi K2.5在编程、视觉、推理及智能体任务等多个领域均达到当前最优性能。同时，Agent Swarm相比单智能体基线，将延迟降低了最高达4.5倍。我们已发布经过后训练的Kimi K2.5模型检查点，以促进未来智能体智能的研究与实际应用。"
  },
  {
    "date": "2026-02-02",
    "title": "CoMeT: Collaborative Memory Transformer for Efficient Long Context Modeling",
    "authors": "Runsong Zhao, Shilei Liu, Jiwei Tang, Langming Liu, Haibin Chen, Weidong Zhang, Yujin Yuan, Tong Xiao, Jingbo Zhu, Wenbo Su, Bo Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01766v1",
    "source": "arXiv",
    "abstract": "The quadratic complexity and indefinitely growing key-value (KV) cache of standard Transformers pose a major barrier to long-context processing. To overcome this, we introduce the Collaborative Memory Transformer (CoMeT), a novel architecture that enables LLMs to handle arbitrarily long sequences with constant memory usage and linear time complexity. Designed as an efficient, plug-in module, CoMeT can be integrated into pre-trained models with only minimal fine-tuning. It operates on sequential data chunks, using a dual-memory system to manage context: a temporary memory on a FIFO queue for recent events, and a global memory with a gated update rule for long-range dependencies. These memories then act as a dynamic soft prompt for the next chunk. To enable efficient fine-tuning on extremely long contexts, we introduce a novel layer-level pipeline parallelism strategy. The effectiveness of our approach is remarkable: a model equipped with CoMeT and fine-tuned on 32k contexts can accurately retrieve a passkey from any position within a 1M token sequence. On the SCROLLS benchmark, CoMeT surpasses other efficient methods and achieves performance comparable to a full-attention baseline on summarization tasks. Its practical effectiveness is further validated on real-world agent and user behavior QA tasks. The code is available at: https://anonymous.4open.science/r/comet-B00B/",
    "title_zh": "CoMeT：用于高效长上下文建模的协作记忆Transformer",
    "abstract_zh": "标准Transformer模型的二次方复杂度以及不断增长的键值（KV）缓存，严重阻碍了长上下文处理能力。为克服这一瓶颈，我们提出了一种新型架构——协作记忆Transformer（Collaborative Memory Transformer, CoMeT），该架构使大语言模型能够以恒定内存消耗和线性时间复杂度处理任意长度的序列。CoMeT被设计为一种高效、可即插即用的模块，仅需少量微调即可集成到预训练模型中。它通过分块处理序列数据，采用双记忆系统来管理上下文信息：一个基于先进先出（FIFO）队列的临时记忆用于存储近期事件，一个带有门控更新机制的全局记忆用于捕捉长距离依赖关系。这两个记忆模块共同作为下一数据块的动态软提示。为实现超长上下文下的高效微调，我们提出了一种新颖的层级流水线并行策略。实验结果表明，该方法效果显著：一个在32k上下文上微调并配备CoMeT的模型，能够准确从长达100万token的序列中任意位置检索出“密钥”信息。在SCROLLS基准测试中，CoMeT超越了其他高效方法，在摘要任务上的表现接近全注意力基线模型。其实际应用效果也在真实世界中的智能体与用户行为问答任务中得到验证。代码已公开：https://anonymous.4open.science/r/comet-B00B/"
  },
  {
    "date": "2026-02-02",
    "title": "vLLM-Omni: Fully Disaggregated Serving for Any-to-Any Multimodal Models",
    "authors": "Peiqi Yin, Jiangyun Zhu, Han Gao, Chenguang Zheng, Yongxiang Huang, Taichang Zhou, Ruirui Yang, Weizhi Liu, Weiqing Chen, Canlin Guo, Didan Deng, Zifeng Mo, Cong Wang, James Cheng, Roger Wang, Hongsheng Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02204v1",
    "source": "arXiv",
    "abstract": "Any-to-any multimodal models that jointly handle text, images, video, and audio represent a significant advance in multimodal AI. However, their complex architectures (typically combining multiple autoregressive LLMs, diffusion transformers, and other specialized components) pose substantial challenges for efficient model serving. Existing serving systems are mainly tailored to a single paradigm, such as autoregressive LLMs for text generation or diffusion transformers for visual generation. They lack support for any-to-any pipelines that involve multiple interconnected model components. As a result, developers must manually handle cross-stage interactions, leading to huge performance degradation. We present vLLM-Omni, a fully disaggregated serving system for any-to-any models. vLLM-Omni features a novel stage abstraction that enables users to decompose complex any-to-any architectures into interconnected stages represented as a graph, and a disaggregated stage execution backend that optimizes resource utilization and throughput across stages. Each stage is independently served by an LLM or diffusion engine with per-stage request batching, flexible GPU allocation, and unified inter-stage connectors for data routing. Experimental results demonstrate that vLLM-Omni reduces job completion time (JCT) by up to 91.4% compared to baseline methods. The code is public available at https://github.com/vllm-project/vllm-omni.",
    "title_zh": "vLLM-Omni：面向任意到任意多模态模型的完全解耦服务架构",
    "abstract_zh": "能够同时处理文本、图像、视频和音频的任意到任意多模态模型，代表了多模态人工智能领域的重要进展。然而，这些模型通常具有复杂的架构（通常由多个自回归大语言模型、扩散Transformer及其他专用组件组合而成），在高效部署方面面临巨大挑战。现有的推理系统大多仅针对单一范式进行优化，例如专为文本生成设计的自回归大语言模型，或专为视觉生成设计的扩散Transformer。它们缺乏对涉及多个相互关联模型组件的任意到任意流水线的支持。因此，开发者不得不手动处理跨阶段交互，导致性能严重下降。\n\n我们提出了vLLM-Omni，一个面向任意到任意多模态模型的完全解耦式推理系统。vLLM-Omni引入了一种新颖的阶段抽象机制，使用户能够将复杂的任意到任意架构分解为由图结构表示的互联阶段；同时配备一个解耦的阶段执行后端，以优化各阶段之间的资源利用率与整体吞吐量。每个阶段均可独立由大语言模型或扩散引擎服务，支持按阶段请求批处理、灵活的GPU资源分配，以及统一的阶段间数据路由连接器。实验结果表明，与基线方法相比，vLLM-Omni可将任务完成时间（JCT）降低高达91.4%。代码已公开，地址为：https://github.com/vllm-project/vllm-omni。"
  },
  {
    "date": "2026-02-02",
    "title": "AR-MAP: Are Autoregressive Large Language Models Implicit Teachers for Diffusion Large Language Models?",
    "authors": "Liang Lin, Feng Xiong, Zengbin Wang, Kun Wang, Junhao Dong, Xuecai Hu, Yong Wang, Xiangxiang Chu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02178v1",
    "source": "arXiv",
    "abstract": "Diffusion Large Language Models (DLLMs) have emerged as a powerful alternative to autoregressive models, enabling parallel token generation across multiple positions. However, preference alignment of DLLMs remains challenging due to high variance introduced by Evidence Lower Bound (ELBO)-based likelihood estimation. In this work, we propose AR-MAP, a novel transfer learning framework that leverages preference-aligned autoregressive LLMs (AR-LLMs) as implicit teachers for DLLM alignment. We reveal that DLLMs can effectively absorb alignment knowledge from AR-LLMs through simple weight scaling, exploiting the shared architectural structure between these divergent generation paradigms. Crucially, our approach circumvents the high variance and computational overhead of direct DLLM alignment and comprehensive experiments across diverse preference alignment tasks demonstrate that AR-MAP achieves competitive or superior performance compared to existing DLLM-specific alignment methods, achieving 69.08\\% average score across all tasks and models. Our Code is available at https://github.com/AMAP-ML/AR-MAP.",
    "title_zh": "AR-MAP：自回归大语言模型是扩散大语言模型的隐式教师吗？",
    "abstract_zh": "扩散型大语言模型（DLLMs）作为一种强大的非自回归生成范式，能够实现多个位置的并行标记生成，成为自回归模型的有力替代方案。然而，由于基于证据下界（ELBO）的似然估计引入了较高的方差，DLLMs的偏好对齐仍面临挑战。本文提出了一种名为AR-MAP的新颖迁移学习框架，利用偏好对齐的自回归大语言模型（AR-LLMs）作为隐式教师，指导DLLM的对齐过程。我们发现，得益于两类生成范式在架构上的共性，DLLMs可通过简单的权重缩放机制，有效吸收来自AR-LLMs的对齐知识。关键在于，该方法避免了直接对DLLM进行对齐所带来的高方差与计算开销。在多种偏好对齐任务上的全面实验表明，AR-MAP在性能上达到或超越现有DLLM专用对齐方法，所有任务与模型的平均得分达到69.08%。相关代码已开源，地址为：https://github.com/AMAP-ML/AR-MAP。"
  },
  {
    "date": "2026-02-02",
    "title": "Co-RedTeam: Orchestrated Security Discovery and Exploitation with LLM Agents",
    "authors": "Pengfei He, Ash Fox, Lesly Miculicich, Stefan Friedli, Daniel Fabian, Burak Gokturk, Jiliang Tang, Chen-Yu Lee, Tomas Pfister, Long T. Le",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02164v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have shown promise in assisting cybersecurity tasks, yet existing approaches struggle with automatic vulnerability discovery and exploitation due to limited interaction, weak execution grounding, and a lack of experience reuse. We propose Co-RedTeam, a security-aware multi-agent framework designed to mirror real-world red-teaming workflows by integrating security-domain knowledge, code-aware analysis, execution-grounded iterative reasoning, and long-term memory. Co-RedTeam decomposes vulnerability analysis into coordinated discovery and exploitation stages, enabling agents to plan, execute, validate, and refine actions based on real execution feedback while learning from prior trajectories. Extensive evaluations on challenging security benchmarks demonstrate that Co-RedTeam consistently outperforms strong baselines across diverse backbone models, achieving over 60% success rate in vulnerability exploitation and over 10% absolute improvement in vulnerability detection. Ablation and iteration studies further confirm the critical role of execution feedback, structured interaction, and memory for building robust and generalizable cybersecurity agents.",
    "title_zh": "协同红队：基于大语言模型代理的自动化安全发现与利用",
    "abstract_zh": "大型语言模型（LLMs）在辅助网络安全任务方面展现出巨大潜力，但现有方法在自动发现和利用漏洞方面仍面临挑战，主要受限于交互能力不足、执行过程缺乏坚实依据以及无法复用过往经验。为此，我们提出了 Co-RedTeam——一种面向安全领域的多智能体框架，旨在模拟真实世界红队攻防流程，融合安全领域知识、代码感知分析、基于执行反馈的迭代推理以及长期记忆机制。Co-RedTeam 将漏洞分析分解为协同的发现与利用两个阶段，使智能体能够根据实际执行反馈进行规划、执行、验证与优化，并从以往的行动轨迹中持续学习。在多个具有挑战性的安全基准上的广泛评估表明，Co-RedTeam 在多种主干模型上均显著优于现有强基线方法，漏洞利用成功率超过60%，漏洞检测准确率提升超过10个百分点。消融实验与迭代分析进一步验证了执行反馈、结构化交互和记忆机制在构建鲁棒且具备泛化能力的网络安全智能体中的关键作用。"
  },
  {
    "date": "2026-02-02",
    "title": "DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations",
    "authors": "Minghao Li, Ruihang Wang, Rui Tan, Yonggang Wen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02137v1",
    "source": "arXiv",
    "abstract": "Modern data centers (DCs) hosting artificial intelligence (AI)-dedicated devices operate at high power densities with rapidly varying workloads, making minute-level adaptation essential for safe and energy-efficient operation. However, manually designing piecewise deep reinforcement learning (DRL) agents cannot keep pace with frequent dynamics shifts and service-level agreement (SLA) changes of an evolving DC. This specification-to-policy lag causes a lack of timely, effective control policies, which may lead to service outages. To bridge the gap, we present DCoPilot, a hybrid framework for generative control policies in dynamic DC operation. DCoPilot synergizes two distinct generative paradigms, i.e., a large language model (LLM) that performs symbolic generation of structured reward forms, and a hypernetwork that conducts parametric generation of policy weights. DCoPilot operates through three coordinated phases: (i) simulation scale-up, which stress-tests reward candidates across diverse simulation-ready (SimReady) scenes; (ii) meta policy distillation, where a hypernetwork is trained to output policy weights conditioned on SLA and scene embeddings; and (iii) online adaptation, enabling zero-shot policy generation in response to updated specifications. Evaluated across five control task families spanning diverse DC components, DCoPilot achieves near-zero constraint violations and outperforms all baselines across specification variations. Ablation studies validate the effectiveness of LLM-based unified reward generation in enabling stable hypernetwork convergence.",
    "title_zh": "DCoPilot：面向动态数据中心运营的生成式人工智能赋能策略自适应",
    "abstract_zh": "现代数据中心（DC）搭载人工智能（AI）专用设备，其运行功率密度高且工作负载变化迅速，因此必须实现分钟级的动态适应，以确保安全与能效。然而，手动设计分段式深度强化学习（DRL）智能体难以跟上不断变化的数据中心动态特性以及服务等级协议（SLA）的频繁调整，导致“需求到策略”的响应滞后，进而造成缺乏及时有效的控制策略，可能引发服务中断。为弥合这一差距，本文提出DCoPilot——一种面向动态数据中心运行的生成式控制策略混合框架。DCoPilot融合两种不同的生成范式：一是利用大语言模型（LLM）进行结构化奖励形式的符号生成；二是通过超网络（hypernetwork）实现策略权重的参数化生成。DCoPilot通过三个协同阶段运行：（i）仿真规模扩展，对多种仿真就绪（SimReady）场景下的奖励候选方案进行压力测试；（ii）元策略蒸馏，训练超网络根据SLA和场景嵌入输出相应的策略权重；（iii）在线适应，支持在新需求更新时实现零样本策略生成。在涵盖多种数据中心组件的五类控制任务上进行评估，DCoPilot实现了近乎零的约束违规，并在各类需求变化下均显著优于所有基线方法。消融实验验证了基于LLM的统一奖励生成机制在促进超网络稳定收敛方面的有效性。"
  },
  {
    "date": "2026-02-02",
    "title": "RAPT: Model-Predictive Out-of-Distribution Detection and Failure Diagnosis for Sim-to-Real Humanoid Robots",
    "authors": "Humphrey Munn, Brendan Tidd, Peter Bohm, Marcus Gallagher, David Howard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01515v1",
    "source": "arXiv",
    "abstract": "Deploying learned control policies on humanoid robots is challenging: policies that appear robust in simulation can execute confidently in out-of-distribution (OOD) states after Sim-to-Real transfer, leading to silent failures that risk hardware damage. Although anomaly detection can mitigate these failures, prior methods are often incompatible with high-rate control, poorly calibrated at the extremely low false-positive rates required for practical deployment, or operate as black boxes that provide a binary stop signal without explaining why the robot drifted from nominal behavior. We present RAPT, a lightweight, self-supervised deployment-time monitor for 50Hz humanoid control. RAPT learns a probabilistic spatio-temporal manifold of nominal execution from simulation and evaluates execution-time predictive deviation as a calibrated, per-dimension signal. This yields (i) reliable online OOD detection under strict false-positive constraints and (ii) a continuous, interpretable measure of Sim-to-Real mismatch that can be tracked over time to quantify how far deployment has drifted from training. Beyond detection, we introduce an automated post-hoc root-cause analysis pipeline that combines gradient-based temporal saliency derived from RAPT's reconstruction objective with LLM-based reasoning conditioned on saliency and joint kinematics to produce semantic failure diagnoses in a zero-shot setting. We evaluate RAPT on a Unitree G1 humanoid across four complex tasks in simulation and on physical hardware. In large-scale simulation, RAPT improves True Positive Rate (TPR) by 37% over the strongest baseline at a fixed episode-level false positive rate of 0.5%. On real-world deployments, RAPT achieves a 12.5% TPR improvement and provides actionable interpretability, reaching 75% root-cause classification accuracy across 16 real-world failures using only proprioceptive data.",
    "title_zh": "RAPT：面向仿真到现实迁移的人形机器人分布外检测与故障诊断的模型预测方法",
    "abstract_zh": "在人形机器人上部署学习到的控制策略极具挑战性：在仿真环境中表现稳健的策略，在经过仿真到现实（Sim-to-Real）迁移后，面对分布外（OOD）状态时可能仍会自信执行，从而导致无声失败，危及硬件安全。尽管异常检测可缓解此类问题，但以往方法通常难以适配高频控制、在实际部署所需的极低误报率下校准效果不佳，或作为“黑箱”运行，仅提供二元停止信号，无法解释机器人为何偏离正常行为。我们提出 RAPT，一种轻量级、自监督的部署时监控系统，专为 50Hz 人形机器人控制设计。RAPT 从仿真中学习正常执行的时空概率流形，并在运行时以校准的、按维度划分的预测偏差信号评估执行偏差。该方法实现了：(i) 在严格误报率约束下可靠的在线 OOD 检测；(ii) 一种连续且可解释的 Sim-to-Real 匹配度度量，可随时间追踪部署状态与训练状态的偏离程度。除检测外，我们还引入了一种自动化的后处理根本原因分析流程，结合 RAPT 重构目标所导出的基于梯度的时间显著性，以及基于大语言模型（LLM）的推理机制，该推理以显著性与关节运动学为条件，可在零样本设置下生成语义化的故障诊断。我们在 Unitree G1 人形机器人上对 RAPT 进行了评估，涵盖四种复杂任务，分别在仿真环境和真实硬件上进行测试。在大规模仿真中，RAPT 在固定每轮任务误报率为 0.5% 的条件下，相比最强基线将真正例率（TPR）提升了 37%。在真实部署中，RAPT 实现了 12.5% 的 TPR 提升，并提供了可操作的可解释性，仅依赖本体感知数据，即在 16 次真实故障中达到了 75% 的根本原因分类准确率。"
  },
  {
    "date": "2026-02-02",
    "title": "Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents",
    "authors": "Zeping Li, Hongru Wang, Yiwen Zhao, Guanhua Chen, Yixia Li, Keyang Chen, Yixin Cao, Guangnan Ye, Hongfeng Chai, Mengdi Wang, Zhenfei Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02050v1",
    "source": "arXiv",
    "abstract": "Tool-using agents based on Large Language Models (LLMs) excel in tasks such as mathematical reasoning and multi-hop question answering. However, in long trajectories, agents often trigger excessive and low-quality tool calls, increasing latency and degrading inference performance, making managing tool-use behavior challenging. In this work, we conduct entropy-based pilot experiments and observe a strong positive correlation between entropy reduction and high-quality tool calls. Building on this finding, we propose using entropy reduction as a supervisory signal and design two reward strategies to address the differing needs of optimizing tool-use behavior. Sparse outcome rewards provide coarse, trajectory-level guidance to improve efficiency, while dense process rewards offer fine-grained supervision to enhance performance. Experiments across diverse domains show that both reward designs improve tool-use behavior: the former reduces tool calls by 72.07% compared to the average of baselines, while the latter improves performance by 22.27%. These results position entropy reduction as a key mechanism for enhancing tool-use behavior, enabling agents to be more adaptive in real-world applications.",
    "title_zh": "重新思考熵在优化大型语言模型智能体工具使用行为中的作用",
    "abstract_zh": "基于大语言模型（LLMs）的工具使用智能体在数学推理和多跳问答等任务中表现出色。然而，在长轨迹任务中，这些智能体常常产生过多且质量较低的工具调用，导致延迟增加并降低推理性能，使得工具使用行为的管理变得极具挑战性。在本研究中，我们开展了基于熵的初步实验，发现熵的降低与高质量工具调用之间存在显著的正相关关系。基于这一发现，我们提出将熵的降低作为监督信号，并设计了两种奖励策略，以满足优化工具使用行为的不同需求：稀疏结果奖励提供粗粒度的、基于轨迹层面的指导，以提升效率；而密集过程奖励则提供细粒度的监督，以增强性能表现。在多个不同领域的实验中，两种奖励设计均有效改善了工具使用行为：前者相比基线平均值减少了72.07%的工具调用次数，后者则提升了22.27%的性能表现。这些结果表明，熵的降低是提升工具使用行为的关键机制，使智能体在真实应用场景中具备更强的适应能力。"
  },
  {
    "date": "2026-02-02",
    "title": "Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation",
    "authors": "Zhongyuan Lyu, Shuoyu Hu, Lujie Liu, Hongxia Yang, Ming LI",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02029v1",
    "source": "arXiv",
    "abstract": "Automatically formulating optimization models from natural language descriptions is a growing focus in operations research, yet current LLM-based approaches struggle with the composite constraints and appropriate modeling paradigms required by complex operational rules. To address this, we introduce the Canonical Intermediate Representation (CIR): a schema that LLMs explicitly generate between problem descriptions and optimization models. CIR encodes the semantics of operational rules through constraint archetypes and candidate modeling paradigms, thereby decoupling rule logic from its mathematical instantiation. Upon a newly generated CIR knowledge base, we develop the rule-to-constraint (R2C) framework, a multi-agent pipeline that parses problem texts, synthesizes CIR implementations by retrieving domain knowledge, and instantiates optimization models. To systematically evaluate rule-to-constraint reasoning, we test R2C on our newly constructed benchmark featuring rich operational rules, and benchmarks from prior work. Extensive experiments show that R2C achieves state-of-the-art accuracy on the proposed benchmark (47.2% Accuracy Rate). On established benchmarks from the literature, R2C delivers highly competitive results, approaching the performance of proprietary models (e.g., GPT-5). Moreover, with a reflection mechanism, R2C achieves further gains and sets new best-reported results on some benchmarks.",
    "title_zh": "基于大语言模型的优化问题建模与代码生成的规范中间表示",
    "abstract_zh": "从自然语言描述中自动构建优化模型是运筹学领域日益关注的研究方向，然而现有的基于大语言模型（LLM）的方法在处理复杂运营规则所要求的复合约束和恰当建模范式方面仍面临挑战。为解决这一问题，我们提出了一种**规范中间表示**（Canonical Intermediate Representation, CIR）：一种由LLM显式生成于问题描述与优化模型之间的结构化框架。CIR通过约束原型和候选建模范式来编码运营规则的语义，从而实现规则逻辑与其数学表达形式的解耦。基于新生成的CIR知识库，我们构建了**规则到约束**（Rule-to-Constraint, R2C）框架——一个由多智能体组成的流水线系统，能够解析问题文本，通过检索领域知识合成CIR实现，并最终实例化出优化模型。为系统评估规则到约束的推理能力，我们在新构建的、包含丰富运营规则的基准数据集上测试R2C，并对比了先前研究中的多个基准。大量实验表明，R2C在所提出的基准上达到了最先进的准确率（47.2%），在已有文献中的标准基准上也表现出极强的竞争力，其性能接近专有模型（如GPT-5）的表现。此外，通过引入反思机制，R2C进一步提升了性能，在部分基准上创下了新的最高报告结果。"
  },
  {
    "date": "2026-02-02",
    "title": "Optimizing Prompts for Large Language Models: A Causal Approach",
    "authors": "Wei Chen, Yanbin Fang, Shuran Fu, Fasheng Xu, Xuan Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01711v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.",
    "title_zh": "大型语言模型提示优化：一种因果方法",
    "abstract_zh": "大型语言模型（LLMs）正越来越多地嵌入企业工作流中，但其性能仍对提示设计高度敏感。自动提示优化（APO）旨在缓解这种不稳定性，然而现有方法面临两个长期存在的挑战：首先，常用的提示策略依赖于静态指令，虽然在平均表现上良好，却难以适应多样化的查询；其次，更动态的方法依赖于离线奖励模型，而这些模型本质上是相关性的，导致提示效果与查询特征相互混淆。为此，我们提出因果提示优化（CPO），将提示设计重构为因果估计问题。CPO分为两个阶段：第一阶段，通过将双重机器学习（DML）应用于提示与查询的语义嵌入，构建一个离线因果奖励模型，从而将提示变化的因果效应从混淆的查询属性中分离出来；第二阶段，利用这一无偏的奖励信号，以资源高效的方式搜索针对特定查询的最优提示，无需依赖昂贵的在线评估。我们在数学推理、可视化和数据分析等多个基准上对CPO进行了评估，结果表明，CPO始终优于人工设计的提示以及当前最先进的自动化优化器。性能提升主要源于在困难查询上的更强鲁棒性，而现有方法在这些场景下往往表现下降。除了性能优势，CPO从根本上改变了提示优化的经济性：通过将评估从实时模型执行转移到离线因果模型，它实现了高精度、按查询定制的优化，且推理成本仅为在线方法的极小部分。综上，这些成果确立了因果推断作为企业级LLM部署中可靠、高效且可扩展的提示优化基础。"
  },
  {
    "date": "2026-02-02",
    "title": "Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner",
    "authors": "Haoqiang Kang, Yizhe Zhang, Nikki Lijing Kuang, Yi-An Ma, Lianhui Qin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01705v1",
    "source": "arXiv",
    "abstract": "Recent reinforcement learning (RL) methods improve LLM reasoning by optimizing discrete Chain-of-Thought (CoT) generation; however, exploration in token space often suffers from diversity collapse as policy entropy decreases due to mode elicitation behavior in discrete RL. To mitigate this issue, we propose Latent Diffusion Reasoning with Reinforcement Learning (LaDi-RL), a framework that conducts exploration directly in a continuous latent space, where latent variables encode semantic-level reasoning trajectories. By modeling exploration via guided diffusion, multi-step denoising distributes stochasticity and preserves multiple coexisting solution modes without mutual suppression. Furthermore, by decoupling latent-space exploration from text-space generation, we show that latent diffusion-based optimization is more effective than text-space policy optimization alone, while a complementary text policy provides additional gains when combined with latent exploration. Experiments on code generation and mathematical reasoning benchmarks demonstrate consistent improvements in both pass@1 and pass@k over discrete RL baselines, with absolute pass@1 gains of +9.4% on code generation and +5.7% on mathematical reasoning, highlighting diffusion-based latent RL as a principled alternative to discrete token-level RL for reasoning.",
    "title_zh": "超越模式诱发：通过潜在扩散推理器实现多样性保留的强化学习",
    "abstract_zh": "近期的强化学习（RL）方法通过优化离散思维链（CoT）生成来提升大语言模型（LLM）的推理能力；然而，在标记空间中的探索常因策略熵随离散RL中模式激发行为而降低，导致多样性崩溃。为缓解此问题，我们提出了一种基于强化学习的潜在扩散推理框架——LaDi-RL。该框架直接在连续潜在空间中进行探索，其中潜在变量编码语义层面的推理轨迹。通过引导扩散建模探索过程，多步去噪能够分布随机性，并在不相互抑制的前提下保持多个共存解模式。此外，通过将潜在空间探索与文本空间生成解耦，我们证明基于潜在扩散的优化比仅在文本空间进行策略优化更为有效；而当与互补的文本策略结合时，潜在探索还能带来额外性能提升。在代码生成和数学推理基准上的实验表明，LaDi-RL在pass@1和pass@k指标上均持续优于离散RL基线方法，分别在代码生成任务上实现+9.4%的绝对pass@1提升，在数学推理任务上实现+5.7%的提升，凸显了基于扩散的潜在强化学习作为离散标记级强化学习在推理任务中的一种更合理替代方案。"
  },
  {
    "date": "2026-02-02",
    "title": "What LLMs Think When You Don't Tell Them What to Think About?",
    "authors": "Yongchan Kwon, James Zou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01689v1",
    "source": "arXiv",
    "abstract": "Characterizing the behavior of large language models (LLMs) across diverse settings is critical for reliable monitoring and AI safety. However, most existing analyses rely on topic- or task-specific prompts, which can substantially limit what can be observed. In this work, we study what LLMs generate from minimal, topic-neutral inputs and probe their near-unconstrained generative behavior. Despite the absence of explicit topics, model outputs cover a broad semantic space, and surprisingly, each model family exhibits strong and systematic topical preferences. GPT-OSS predominantly generates programming (27.1%) and mathematical content (24.6%), whereas Llama most frequently generates literary content (9.1%). DeepSeek often generates religious content, while Qwen frequently generates multiple-choice questions. Beyond topical preferences, we also observe differences in content specialization and depth: GPT-OSS often generates more technically advanced content (e.g., dynamic programming) compared with other models (e.g., basic Python). Furthermore, we find that the near-unconstrained generation often degenerates into repetitive phrases, revealing interesting behaviors unique to each model family. For instance, degenerate outputs from Llama include multiple URLs pointing to personal Facebook and Instagram accounts. We release the complete dataset of 256,000 samples from 16 LLMs, along with a reproducible codebase.",
    "title_zh": "当你不告诉它们该思考什么时，大型语言模型会怎样思考？",
    "abstract_zh": "在多样场景下对大型语言模型（LLMs）行为进行表征，对于实现可靠的监控和保障人工智能安全至关重要。然而，现有的大多数分析依赖于特定主题或任务的提示（prompt），这在很大程度上限制了可观测的范围。在本研究中，我们探讨了大型语言模型在极简、无主题输入下的生成行为，以探查其近乎无约束的生成特性。尽管输入中没有明确的主题，模型的输出仍覆盖了广泛的语义空间，令人惊讶的是，每种模型家族均表现出强烈且系统性的主题偏好。GPT-OSS主要生成编程内容（27.1%）和数学内容（24.6%），而Llama则最常生成文学类内容（9.1%）。DeepSeek倾向于生成宗教相关内容，Qwen则频繁生成选择题。除了主题偏好外，我们还观察到各模型在内容专精程度和深度上的差异：GPT-OSS常生成更技术性较强的文本（如动态规划），而其他模型则更多生成基础内容（如基础Python代码）。此外，我们发现，在近乎无约束的生成过程中，模型输出往往退化为重复的短语，暴露出各模型家族独特的异常行为。例如，Llama的退化输出中包含多个指向个人Facebook和Instagram账号的网址。我们已公开发布来自16个大型语言模型的共计25.6万条样本数据集，以及可复现的代码库。"
  },
  {
    "date": "2026-02-02",
    "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System",
    "authors": "Yinjie Wang, Tianbao Xie, Ke Shen, Mengdi Wang, Ling Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02488v1",
    "source": "arXiv",
    "abstract": "We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL",
    "title_zh": "RLAnything：在完全动态的强化学习系统中构建环境、策略与奖励模型",
    "abstract_zh": "我们提出 RLAnything，这是一个强化学习框架，通过闭环优化动态构建环境、策略和奖励模型，从而增强学习信号并提升整体强化学习系统在任意大语言模型（LLM）或智能体场景下的性能。具体而言，策略模型通过整合逐步反馈与最终结果信号进行训练，而奖励模型则通过一致性反馈实现联合优化，进而进一步提升策略训练效果。此外，基于理论指导的自动环境适应机制，利用双方的评判者反馈，使奖励模型和策略模型均能从经验中学习，显著改善训练过程。实证结果表明，每一新增组件均持续提升系统整体表现：在多个代表性 LLM 与智能体任务中，RLAnything 显著提升了性能——在 OSWorld 上使 Qwen3-VL-8B-Thinking 提升 9.1%，在 AlfWorld 和 LiveBench 上分别使 Qwen2.5-7B-Instruct 提升 18.7% 和 11.9%。我们还发现，经过优化的奖励模型信号优于依赖人工标注的结果信号。代码地址：https://github.com/Gen-Verse/Open-AgentRL"
  },
  {
    "date": "2026-02-02",
    "title": "Structure Enables Effective Self-Localization of Errors in LLMs",
    "authors": "Ankur Samanta, Akshayaa Magesh, Ayush Jain, Kavosh Asadi, Youliang Yu, Daniel Jiang, Boris Vidolov, Kaveh Hassani, Paul Sajda, Jalaj Bhandari, Yonathan Efroni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02416v1",
    "source": "arXiv",
    "abstract": "Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.",
    "title_zh": "结构助力大语言模型有效实现错误自定位",
    "abstract_zh": "语言模型中的自我修正仍然难以实现。在本研究中，我们探讨了语言模型是否能够显式地定位错误推理中的错误，以此作为构建能够有效自我修正的AI系统的一条路径。我们提出了一种提示方法，将推理过程结构化为离散且语义连贯的思维步骤，并证明模型能够在这种结构中可靠地定位错误，而在传统的、非结构化的思维链推理中则无法做到这一点。受人类大脑在离散决策点监控错误并重新采样备选方案的启发，我们提出了“思维迭代修正采样”（Thought-ICS）这一自我修正框架。Thought-ICS 通过迭代提示模型一次生成一个离散且完整的思维步骤——每个思维步骤代表模型的一次有意决策——从而在推理过程中自然形成精确的错误定位边界。在验证过程中，模型能够定位到第一个出错的步骤，系统则回溯至最后一个正确点，生成替代性推理。当要求模型修正由“预言机”验证为错误的推理时，Thought-ICS 实现了20%至40%的自我修正提升。在完全自主、无需外部验证的设置下，其性能也优于当前主流的自我修正基线方法。"
  },
  {
    "date": "2026-02-02",
    "title": "SysFuSS: System-Level Firmware Fuzzing with Selective Symbolic Execution",
    "authors": "Dakshina Tharindu, Aruna Jayasena, Prabhat Mishra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02243v1",
    "source": "arXiv",
    "abstract": "Firmware serves as the critical interface between hardware and software in computing systems, making any bugs or vulnerabilities particularly dangerous as they can cause catastrophic system failures. While fuzzing is a promising approach for identifying design flaws and security vulnerabilities, traditional fuzzers are ineffective at detecting firmware vulnerabilities. For example, existing fuzzers focus on user-level fuzzing, which is not suitable for detecting kernel-level vulnerabilities. Existing fuzzers also face a coverage plateau problem when dealing with complex interactions between firmware and hardware. In this paper, we present an efficient firmware verification framework, SysFuSS, that integrates system-level fuzzing with selective symbolic execution. Our approach leverages system-level emulation for initial fuzzing, and automatically transitions to symbolic execution when coverage reaches a plateau. This strategy enables us to generate targeted test cases that can trigger previously unexplored regions in firmware designs. We have evaluated SysFuSS on real-world embedded firmware, including OpenSSL, WolfBoot, WolfMQTT, HTSlib, MXML, and libIEC. Experimental evaluation demonstrates that SysFuSS significantly outperforms state-of-the-art fuzzers in terms of both branch coverage and detection of firmware vulnerabilities. Specifically, SysFuSS can detect 118 known vulnerabilities while state-of-the-art can cover only 13 of them. Moreover, SysFuSS takes significantly less time (up to 3.3X, 1.7X on average) to activate these vulnerabilities.",
    "title_zh": "SysFuSS：基于选择性符号执行的系统级固件模糊测试",
    "abstract_zh": "固件是计算系统中硬件与软件之间至关重要的接口，因此其中的任何缺陷或漏洞都可能带来灾难性的系统故障。尽管模糊测试（fuzzing）是一种识别设计缺陷和安全漏洞的有前景方法，但传统模糊测试工具在检测固件漏洞方面效果有限。例如，现有模糊测试工具主要针对用户级程序进行测试，无法有效发现内核级漏洞；同时，在处理固件与硬件之间复杂交互时，现有工具还面临覆盖率停滞的问题。本文提出了一种高效的固件验证框架——SysFuSS，该框架将系统级模糊测试与选择性符号执行相结合。我们的方法首先利用系统级仿真进行初始模糊测试，当覆盖率进入平台期时，自动切换至符号执行模式。这一策略能够生成有针对性的测试用例，从而触发固件设计中此前未被探索的区域。我们在真实嵌入式固件上对SysFuSS进行了评估，包括OpenSSL、WolfBoot、WolfMQTT、HTSlib、MXML和libIEC等。实验结果表明，SysFuSS在分支覆盖率和固件漏洞检测方面均显著优于当前最先进的模糊测试工具。具体而言，SysFuSS成功检测到118个已知漏洞，而现有先进工具仅能覆盖其中的13个。此外，SysFuSS激活这些漏洞所需时间显著更短，最快可提升3.3倍，平均提升1.7倍。"
  },
  {
    "date": "2026-02-02",
    "title": "Agent-Based Software Artifact Evaluation",
    "authors": "Zhaonan Wu, Yanjie Zhao, Zhenpeng Chen, Zheng Wang, Haoyu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02235v1",
    "source": "arXiv",
    "abstract": "Artifact evaluation has been adopted in the Software Engineering (SE) research community for 15 years, substantially improving research reproducibility across major SE conferences. However, this success has introduced a growing scalability challenge, as artifact evaluation relies heavily on reviewers' manual execution and debugging, leading to escalating human effort amid rapidly increasing paper submissions. To address this problem, we investigate automated artifact evaluation. We first conduct a preliminary study on artifacts from top-tier SE conferences and identify three key challenges: perceiving execution states, maintaining stable execution environments, and recovering from execution errors. Inspired by these findings, we propose ArtifactCopilot, the first end-to-end agent-based framework for automated artifact evaluation. ArtifactCopilot automates environment construction, instruction execution, and error recovery by combining an execution normalization strategy to ensure environment stability with an artifact evaluation graph that transforms README documents into dependency-aware command graphs, enabling structured execution planning, execution-state tracking, and error recovery. Evaluation on 48 real-world artifacts shows that ArtifactCopilot matches human artifact evaluation outcomes for 85.42% of the artifacts, outperforming Claude Code by 52.09 percentage points, while costing only \\$0.091 per artifact on average and requiring zero human intervention for 45 out of 48 artifacts.",
    "title_zh": "基于代理的软件制品评估",
    "abstract_zh": "在软件工程（SE）研究领域，成果评估（Artifact Evaluation）已实施15年，显著提升了各大SE会议的研究可复现性。然而，这一成功也带来了日益严峻的可扩展性挑战：由于成果评估严重依赖评审人员的手动执行与调试，随着论文投稿量的迅速增长，所需的人力成本不断攀升。为应对这一问题，我们开展了自动化成果评估的研究。首先，我们对顶级SE会议中的成果进行了初步研究，识别出三大关键挑战：执行状态的感知、执行环境的稳定性维持以及执行错误的恢复。基于这些发现，我们提出了ArtifactCopilot——首个端到端的基于智能体（agent-based）的自动化成果评估框架。ArtifactCopilot通过结合执行标准化策略以保障环境稳定性，以及将README文档转化为依赖感知的命令图的成果评估图（Artifact Evaluation Graph），实现了环境自动构建、指令自动执行与错误自动恢复。该框架支持结构化的执行规划、执行状态追踪与错误恢复。在48个真实世界成果上的评估表明，ArtifactCopilot在85.42%的成果上达到了与人工评估一致的结果，较Claude Code高出52.09个百分点，且平均每个成果仅需0.091美元成本，其中45个成果无需任何人工干预即可完成评估。"
  },
  {
    "date": "2026-02-02",
    "title": "Generating Physically Sound Designs from Text and a Set of Physical Constraints",
    "authors": "Gregory Barber, Todd C. Henry, Mulugeta A. Haile",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02213v1",
    "source": "arXiv",
    "abstract": "We present TIDES, a text informed design approach for generating physically sound designs based on a textual description and a set of physical constraints. TIDES jointly optimizes structural (topology) and visual properties. A pre-trained text-image model is used to measure the design's visual alignment with a text prompt and a differentiable physics simulator is used to measure its physical performance. We evaluate TIDES on a series of structural optimization problems operating under different load and support conditions, at different resolutions, and experimentally in the lab by performing the 3-point bending test on 2D beam designs that are extruded and 3D printed. We find that it can jointly optimize the two objectives and return designs that satisfy engineering design requirements (compliance and density) while utilizing features specified by text.",
    "title_zh": "从文本和一组物理约束生成物理上合理的设计方案",
    "abstract_zh": "我们提出了TIDES，一种基于文本描述和一组物理约束生成物理上合理设计的文本引导设计方法。TIDES联合优化结构（拓扑）属性与视觉属性。该方法利用预训练的文本-图像模型来衡量设计与文本提示之间的视觉一致性，同时采用可微分的物理仿真器来评估其物理性能。我们在一系列结构优化问题上对TIDES进行了评估，涵盖不同的载荷与支撑条件、不同分辨率，并在实验室中通过三点弯曲测试对二维梁结构进行拉伸并3D打印后进行实验验证。结果表明，TIDES能够有效联合优化两个目标，生成满足工程设计要求（如柔度和密度）的设计，同时充分利用文本中指定的特征。"
  },
  {
    "date": "2026-02-02",
    "title": "RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents",
    "authors": "Jialiang Zhu, Gongrui Zhang, Xiaolong Ma, Lin Xu, Miaosen Zhang, Ruiqi Yang, Song Wang, Kai Qiu, Zhirong Wu, Qi Dai, Ruichun Ma, Bei Liu, Yifan Yang, Chong Luo, Zhengyuan Yang, Linjie Li, Lijuan Wang, Weizhu Chen, Xin Geng, Baining Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02486v1",
    "source": "arXiv",
    "abstract": "LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.",
    "title_zh": "RE-TRAC：用于深度搜索智能体的递归轨迹压缩",
    "abstract_zh": "基于大语言模型（LLM）的深度研究智能体大多基于ReAct框架构建。这种线性设计使得智能体难以回溯早期状态、分支探索其他搜索路径，或在长上下文场景下保持全局认知，常常导致陷入局部最优、重复探索以及搜索效率低下。为此，我们提出了Re-TRAC——一种新型智能体框架，通过在每条轨迹结束后生成结构化的状态表示，总结证据、不确定性、失败原因及未来规划，并以此作为后续轨迹的条件，实现跨轨迹的探索。该机制支持迭代式反思与全局导向的规划，将研究过程重新定义为一个渐进式演进的过程。实验结果表明，在使用前沿大模型的情况下，Re-TRAC在BrowseComp任务上相比ReAct稳定提升15%-20%。对于较小规模模型，我们进一步引入了面向Re-TRAC的监督微调方法，在相近模型规模下实现了当前最优性能。值得注意的是，Re-TRAC在各轮次中均表现出工具调用次数和令牌消耗的单调递减趋势，表明其探索行为正因跨轨迹反思而日益精准，而非重复冗余的搜索。"
  },
  {
    "date": "2026-02-02",
    "title": "Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning",
    "authors": "Ethan Mendes, Jungsoo Park, Alan Ritter",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02405v1",
    "source": "arXiv",
    "abstract": "Improving the reasoning capabilities of large language models (LLMs) typically relies either on the model's ability to sample a correct solution to be reinforced or on the existence of a stronger model able to solve the problem. However, many difficult problems remain intractable for even current frontier models, preventing the extraction of valid training signals. A promising alternative is to leverage high-quality expert human solutions, yet naive imitation of this data fails because it is fundamentally out of distribution: expert solutions are typically didactic, containing implicit reasoning gaps intended for human readers rather than computational models. Furthermore, high-quality expert solutions are expensive, necessitating generalizable sample-efficient training methods. We propose Distribution Aligned Imitation Learning (DAIL), a two-step method that bridges the distributional gap by first transforming expert solutions into detailed, in-distribution reasoning traces and then applying a contrastive objective to focus learning on expert insights and methodologies. We find that DAIL can leverage fewer than 1000 high-quality expert solutions to achieve 10-25% pass@k gains on Qwen2.5-Instruct and Qwen3 models, improve reasoning efficiency by 2x to 4x, and enable out-of-domain generalization.",
    "title_zh": "从教学性到建设性：将专家解答转化为可学习的推理过程",
    "abstract_zh": "提升大型语言模型（LLM）的推理能力，通常依赖于模型自身采样出正确解并加以强化，或依赖于更强的模型来解决该问题。然而，许多复杂问题对当前前沿模型而言仍难以处理，导致无法提取有效的训练信号。一种有前景的替代方案是利用高质量的专家人类解法，但直接模仿这类数据效果不佳，因为其本质上属于分布外数据：专家解法通常具有教学性质，包含为人类读者设计的隐式推理空白，而非面向计算模型的完整逻辑链条。此外，高质量的专家解法成本高昂，因此亟需具备泛化能力且样本高效的训练方法。为此，我们提出分布对齐模仿学习（Distribution Aligned Imitation Learning, DAIL），一种两阶段方法：首先将专家解法转化为详细、符合模型分布的推理轨迹，以弥合分布差距；随后采用对比学习目标，聚焦于专家的洞察与方法论。实验表明，DAIL仅需少于1000个高质量专家解法，即可在Qwen2.5-Instruct和Qwen3模型上实现10%-25%的pass@k性能提升，推理效率提高2至4倍，并支持跨领域泛化。"
  },
  {
    "date": "2026-02-02",
    "title": "ReasonCACHE: Teaching LLMs To Reason Without Weight Updates",
    "authors": "Sharut Gupta, Phillip Isola, Stefanie Jegelka, David Lopez-Paz, Kartik Ahuja, Mark Ibrahim, Mohammad Pezeshki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02366v1",
    "source": "arXiv",
    "abstract": "Can Large language models (LLMs) learn to reason without any weight update and only through in-context learning (ICL)? ICL is strikingly sample-efficient, often learning from only a handful of demonstrations, but complex reasoning tasks typically demand many training examples to learn from. However, naively scaling ICL by adding more demonstrations breaks down at this scale: attention costs grow quadratically, performance saturates or degrades with longer contexts, and the approach remains a shallow form of learning. Due to these limitations, practitioners predominantly rely on in-weight learning (IWL) to induce reasoning. In this work, we show that by using Prefix Tuning, LLMs can learn to reason without overloading the context window and without any weight updates. We introduce $\\textbf{ReasonCACHE}$, an instantiation of this mechanism that distills demonstrations into a fixed key-value cache. Empirically, across challenging reasoning benchmarks, including GPQA-Diamond, ReasonCACHE outperforms standard ICL and matches or surpasses IWL approaches. Further, it achieves this all while being more efficient across three key axes: data, inference cost, and trainable parameters. We also theoretically prove that ReasonCACHE can be strictly more expressive than low-rank weight update since the latter ties expressivity to input rank, whereas ReasonCACHE bypasses this constraint by directly injecting key-values into the attention mechanism. Together, our findings identify ReasonCACHE as a middle path between in-context and in-weight learning, providing a scalable algorithm for learning reasoning skills beyond the context window without modifying parameters. Our project page: https://reasoncache.github.io/",
    "title_zh": "ReasonCACHE：让大语言模型在不更新权重的情况下学会推理",
    "abstract_zh": "大型语言模型（LLMs）能否在不进行任何权重更新的情况下，仅通过上下文学习（In-Context Learning, ICL）实现推理能力？ICL表现出惊人的样本高效性，通常仅需少量示例即可完成学习，但复杂推理任务通常需要大量训练样本才能掌握。然而，简单地通过增加演示示例来扩展ICL在规模上会失效：注意力计算成本随上下文长度呈二次增长，性能在长上下文下趋于饱和甚至下降，且该方法本质上仍属于浅层学习。由于这些局限，实践者普遍依赖于权重内学习（In-Weight Learning, IWL）来诱导模型推理能力。\n\n在本研究中，我们证明：通过采用前缀调优（Prefix Tuning）技术，LLMs可以在不占用上下文窗口资源、且无需任何权重更新的情况下实现推理学习。我们提出了$\\textbf{ReasonCACHE}$——这一机制的具体实现，它将演示示例提炼为一个固定的关键-值缓存（key-value cache）。在多个具有挑战性的推理基准测试中（包括GPQA-Diamond），实验结果表明，ReasonCACHE的表现优于标准ICL，并达到或超越了IWL方法的水平。此外，ReasonCACHE在三个关键维度上均展现出更高的效率：数据需求、推理成本以及可训练参数量。\n\n我们还从理论上证明，ReasonCACHE在表达能力上可严格超越低秩权重更新方法，因为后者将表达能力受限于输入的秩，而ReasonCACHE通过直接向注意力机制注入关键-值对，绕过了这一限制。\n\n综上所述，我们的研究揭示了ReasonCACHE作为“上下文学习”与“权重内学习”之间的一种中间路径，提供了一种可扩展的算法，使模型能够在不修改参数的前提下，突破上下文窗口限制，学习复杂的推理技能。项目主页：https://reasoncache.github.io/"
  },
  {
    "date": "2026-02-02",
    "title": "A Task-Level Evaluation of AI Agents in Open-Source Projects",
    "authors": "Shojibur Rahman, Md Fazle Rabbi, Minhaz Zibran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02345v1",
    "source": "arXiv",
    "abstract": "In this paper, we present a comparative study of five autonomous coding agents using AIDev-pop, which is a public dataset containing thousands of AI-generated pull requests (PRs) across popular open-source repositories. We evaluate agents' performance along three task-aware dimensions spanning the PR lifecycle: (1) PR acceptance rate, (2) review discussion volume, and (3) commit message quality. Our quantitative analysis finds that Codex consistently achieves high PR acceptance rates across most task categories, while Copilot's PRs trigger the highest volume of both human and automated review discussions. In contrast, commit-level quality varies independently of acceptance outcomes. Claude and Cursor produce higher proportions of high-quality commit messages across several task types, and Codex exhibiting comparatively lower commit quality despite strong integration outcomes. Our findings inform selection and improvements of AI agents for their effective integration to collaborative software engineering.",
    "title_zh": "开源项目中AI代理的任务级评估",
    "abstract_zh": "本文通过AIDev-pop这一公开数据集，对五种自主编码代理进行了比较研究。AIDev-pop包含来自多个热门开源仓库的数千个由AI生成的拉取请求（PR）。我们从覆盖PR生命周期的三个任务感知维度评估了各代理的表现：（1）PR接受率，（2）评审讨论量，（3）提交信息质量。定量分析结果显示，Codex在大多数任务类别中均表现出较高的PR接受率，而Copilot生成的PR引发了最多的人工与自动化评审讨论。相比之下，提交级别质量与接受结果之间并无明显关联。Claude和Cursor在多个任务类型中生成了更高比例的高质量提交信息，而尽管Codex在集成效果方面表现优异，其提交信息质量却相对较低。本研究结果为AI代理在协作软件工程中的有效选择与优化提供了重要参考。"
  },
  {
    "date": "2026-02-02",
    "title": "OmniCode: A Benchmark for Evaluating Software Engineering Agents",
    "authors": "Atharv Sonwane, Eng-Shen Tu, Wei-Chung Lu, Claas Beger, Carter Larsen, Debjit Dhar, Rachel Chen, Ronit Pattanayak, Tuan Anh Dang, Guohao Chen, Gloria Geng, Kevin Ellis, Saikat Dutta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02262v1",
    "source": "arXiv",
    "abstract": "LLM-powered coding agents are redefining how real-world software is developed. To drive the research towards better coding agents, we require challenging benchmarks that can rigorously evaluate the ability of such agents to perform various software engineering tasks. However, popular coding benchmarks such as HumanEval and SWE-Bench focus on narrowly scoped tasks such as competition programming and patch generation. In reality, software engineers have to handle a broader set of tasks for real-world software development. To address this gap, we propose OmniCode, a novel software engineering benchmark that contains a broader and more diverse set of task categories beyond code or patch generation. Overall, OmniCode contains 1794 tasks spanning three programming languages (Python, Java, and C++) and four key categories: bug fixing, test generation, code review fixing, and style fixing. In contrast to prior software engineering benchmarks, the tasks in OmniCode are (1) manually validated to eliminate ill-defined problems, and (2) synthetically crafted or recently curated to avoid data leakage issues, presenting a new framework for synthetically generating diverse software tasks from limited real-world data. We evaluate OmniCode with popular agent frameworks such as SWE-Agent and show that while they may perform well on bug fixing for Python, they fall short on tasks such as Test Generation and in languages such as C++ and Java. For instance, SWE-Agent achieves a maximum of 20.9% with DeepSeek-V3.1 on Java Test Generation tasks. OmniCode aims to serve as a robust benchmark and spur the development of agents that can perform well across different aspects of software development. Code and data are available at https://github.com/seal-research/OmniCode.",
    "title_zh": "OmniCode：评估软件工程智能体的基准测试",
    "abstract_zh": "由大语言模型（LLM）驱动的编程代理正在重新定义现实世界软件的开发方式。为了推动该领域研究向更优的编程代理发展，我们需要具有挑战性的基准测试，以严格评估这些代理在各类软件工程任务中的表现能力。然而，当前流行的编程基准测试，如HumanEval和SWE-Bench，主要聚焦于范围狭窄的任务，例如编程竞赛题目和代码补丁生成。而在实际软件开发中，工程师需要应对更广泛的任务类型。为填补这一空白，我们提出了OmniCode——一个全新的软件工程基准测试，其任务类别不仅限于代码或补丁生成，而是覆盖更广、更具多样性的任务类型。总体而言，OmniCode包含1794个任务，涵盖Python、Java和C++三种编程语言，以及四个核心任务类别：缺陷修复、测试生成、代码审查修复和代码风格修复。与以往的软件工程基准不同，OmniCode中的任务具有以下特点：（1）经过人工验证，确保问题定义清晰、无歧义；（2）通过合成生成或近期精心整理，有效避免了数据泄露问题，构建了一种从有限真实数据中合成多样化软件任务的新范式。我们使用SWE-Agent等主流代理框架对OmniCode进行了评估，结果表明，尽管这些代理在Python的缺陷修复任务上表现尚可，但在测试生成等任务，以及在C++和Java等语言上的表现则明显不足。例如，SWE-Agent在Java测试生成任务上使用DeepSeek-V3.1模型时，最高仅达到20.9%的准确率。OmniCode旨在成为一个稳健可靠的基准，推动开发出能在软件开发各个层面均表现出色的智能代理。代码与数据已公开，访问地址为：https://github.com/seal-research/OmniCode。"
  },
  {
    "date": "2026-02-02",
    "title": "Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation",
    "authors": "Zhanghao Hu, Qinglin Zhu, Hanqi Yan, Yulan He, Lin Gui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02007v1",
    "source": "arXiv",
    "abstract": "Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.",
    "title_zh": "超越RAG的智能体记忆：解耦与聚合的检索方法",
    "abstract_zh": "代理记忆系统通常采用标准的检索增强生成（RAG）流程，但在此场景下其底层假设存在显著差异。RAG 面向的是大规模、异构的语料库，检索到的文本片段具有高度多样性；而代理记忆则是一个有限、连贯的对话流，其中的语义片段高度相关，且常出现重复内容。在这一转变下，传统的固定 top-$k$ 相似性检索容易返回冗余上下文，而事后过滤又可能误删对正确推理至关重要的时间上关联的前提信息。我们认为，检索机制应超越简单的相似性匹配，转而基于潜在语义组件进行操作，遵循“解耦—聚合”的范式：将记忆解离为语义组件，构建层次化组织结构，并利用该结构驱动检索过程。为此，我们提出 xMemory，它通过一种稀疏性—语义性目标，构建完整单元的层次结构，同时保持可搜索且忠实的高层节点组织。在推理阶段，xMemory 采用自顶向下的检索策略，针对多事实查询，优先选择紧凑且多样化的主题与语义集合；仅当进一步展开到具体事件或原始消息能有效降低读者不确定性时，才进行细化。在最新三款大语言模型上，针对 LoCoMo 和 PerLTQA 的实验表明，xMemory 在答案质量与 token 效率方面均实现了稳定提升。"
  },
  {
    "date": "2026-02-02",
    "title": "Emergent Analogical Reasoning in Transformers",
    "authors": "Gouki Minegishi, Jingyuan Feng, Hiroki Furuta, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01992v1",
    "source": "arXiv",
    "abstract": "Analogy is a central faculty of human intelligence, enabling abstract patterns discovered in one domain to be applied to another. Despite its central role in cognition, the mechanisms by which Transformers acquire and implement analogical reasoning remain poorly understood. In this work, inspired by the notion of functors in category theory, we formalize analogical reasoning as the inference of correspondences between entities across categories. Based on this formulation, we introduce synthetic tasks that evaluate the emergence of analogical reasoning under controlled settings. We find that the emergence of analogical reasoning is highly sensitive to data characteristics, optimization choices, and model scale. Through mechanistic analysis, we show that analogical reasoning in Transformers decomposes into two key components: (1) geometric alignment of relational structure in the embedding space, and (2) the application of a functor within the Transformer. These mechanisms enable models to transfer relational structure from one category to another, realizing analogy. Finally, we quantify these effects and find that the same trends are observed in pretrained LLMs. In doing so, we move analogy from an abstract cognitive notion to a concrete, mechanistically grounded phenomenon in modern neural networks.",
    "title_zh": "变压器中的涌现类比推理",
    "abstract_zh": "类比是人类智能的核心能力，使人们能够将某一领域中发现的抽象模式应用于另一领域。尽管类比在认知过程中扮演着核心角色，但Transformer模型如何获取并实现类比推理的机制仍不清晰。受范畴论中“函子”概念的启发，本文将类比推理形式化为跨范畴实体之间对应关系的推断。基于这一形式化框架，我们设计了合成任务，在受控条件下评估类比推理的涌现。研究发现，类比推理的涌现对数据特征、优化策略以及模型规模极为敏感。通过机制分析，我们揭示出Transformer中的类比推理可分解为两个关键组成部分：（1）嵌入空间中关系结构的几何对齐；（2）Transformer内部对函子的应用。这些机制使模型能够将一个范畴中的关系结构迁移到另一个范畴，从而实现类比。最后，我们量化了这些效应，并发现预训练大语言模型中也呈现出相同的规律。由此，我们将类比从一种抽象的认知概念，转变为现代神经网络中具有明确机制基础的可解释现象。"
  },
  {
    "date": "2026-02-02",
    "title": "Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models",
    "authors": "Jinbin Bai, Yixuan Li, Yuchen Zhu, Yi Xin, Qingyu Shi, Aosong Feng, Xiaohong Liu, Molei Tao, Jianru Xue, Xiangtai Li, Ming-Hsuan Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01842v1",
    "source": "arXiv",
    "abstract": "Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at https://github.com/viiika/Prism.",
    "title_zh": "棱镜：通过分层搜索与自验证实现离散扩散语言模型的高效测试时扩展",
    "abstract_zh": "推理时计算重新成为提升大语言模型（LLM）推理能力的一种实用方法。大多数测试时扩展（TTS）算法依赖自回归解码，而这种方式并不适合离散扩散语言模型（dLLMs），因为dLLMs采用整个序列的并行解码机制。因此，开发高效且有效的TTS方法以充分释放dLLMs的生成潜力，仍是亟待探索的挑战。为应对这一问题，我们提出了Prism（剪枝、重掩码与集成自验证方法），这是一种针对dLLMs的高效TTS框架，具备以下三个核心特性：（i）执行分层轨迹搜索（HTS），在早期至中期去噪阶段动态剪枝并重新分配计算资源；（ii）引入局部分支机制并结合部分重掩码，以在保留高置信度标记的同时探索多样化的生成路径；（iii）用通过中间生成结果的自评估提示获得的自验证反馈（SVF）替代外部验证器。在三个dLLMs（包括LLaDA 8B Instruct、Dream 7B Instruct和LLaDA 2.0-mini）上的四个数学推理与代码生成基准测试中，Prism实现了优异的性能-效率权衡，在显著减少函数评估次数（NFE）的情况下，达到了与“最佳N个样本”（best-of-N）相当的性能。代码已开源，地址为：https://github.com/viiika/Prism。"
  },
  {
    "date": "2026-02-02",
    "title": "Read As Human: Compressing Context via Parallelizable Close Reading and Skimming",
    "authors": "Jiwei Tang, Shilei Liu, Zhicheng Zhang, Qingsong Lv, Runsong Zhao, Tingwei Lu, Langming Liu, Haibin Chen, Yujin Yuan, Hai-Tao Zheng, Wenbo Su, Bo Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01840v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) demonstrate exceptional capability across diverse tasks. However, their deployment in long-context scenarios is hindered by two challenges: computational inefficiency and redundant information. We propose RAM (Read As HuMan), a context compression framework that adopts an adaptive hybrid reading strategy, to address these challenges. Inspired by human reading behavior (i.e., close reading important content while skimming less relevant content), RAM partitions the context into segments and encodes them with the input query in parallel. High-relevance segments are fully retained (close reading), while low-relevance ones are query-guided compressed into compact summary vectors (skimming). Both explicit textual segments and implicit summary vectors are concatenated and fed into decoder to achieve both superior performance and natural language format interpretability. To refine the decision boundary between close reading and skimming, we further introduce a contrastive learning objective based on positive and negative query-segment pairs. Experiments demonstrate that RAM outperforms existing baselines on multiple question answering and summarization benchmarks across two backbones, while delivering up to a 12x end-to-end speedup on long inputs (average length 16K; maximum length 32K).",
    "title_zh": "像人类一样阅读：通过可并行的精读与略读压缩上下文",
    "abstract_zh": "大型语言模型（LLMs）在多种任务中展现出卓越的能力。然而，在长上下文场景中部署时，其面临两大挑战：计算效率低下和信息冗余。为此，我们提出了RAM（Read As HuMan）——一种上下文压缩框架，采用自适应混合阅读策略，以应对上述问题。该方法受到人类阅读行为的启发：对重要内容进行精读，对次要内容则快速略读。RAM将上下文划分为多个段落，并并行地将这些段落与输入查询进行编码。高相关性段落被完整保留（精读），而低相关性段落则在查询引导下被压缩为紧凑的摘要向量（略读）。显式文本段落与隐式摘要向量被拼接后输入解码器，从而在保证优异性能的同时，保持自然语言格式的可解释性。为进一步优化精读与略读之间的决策边界，我们引入了一种基于正负样本查询-段落对的对比学习目标。实验表明，RAM在两个不同主干模型上，于多个问答和摘要基准测试中均优于现有基线方法，同时在长输入场景下实现了高达12倍的端到端加速（平均长度16K，最大长度32K）。"
  },
  {
    "date": "2026-02-02",
    "title": "Fat-Cat: Document-Driven Metacognitive Multi-Agent System for Complex Reasoning",
    "authors": "Tong Yang, Yemin Wang, Chaoning Zhang, Aming Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02206v1",
    "source": "arXiv",
    "abstract": "The effectiveness of LLM-based agents is often limited not by model capacity alone, but by how efficiently contextual information is utilized at runtime. Existing agent frameworks rely on rigid, syntax-heavy state representations such as nested JSON, which require models to devote a substantial portion of their limited attention to syntactic processing rather than semantic reasoning. In this paper, we propose Fat-Cat, a document-driven agent architecture that improves the signal-to-noise ratio of state management. By integrating three key components: (1) a Semantic File System that represents agent state as Markdown documents aligned with common pre-training corpora, (2) a Textual Strategy Evolution module that accumulates task-solving knowledge without parameter updates, and (3) a Closed-Loop Watcher that monitors reasoning trajectories to reduce hallucinations. Extensive reasoning, retrieval, and coding benchmarks, Fat-Cat consistently improves agent performance. It enables the Kimi-k2 model to outperform the proprietary GPT-4o baseline on HotPotQA. Replacing the document-based state with JSON leads to performance drop, while empirically validating the critical necessity of document-driven state modeling over rigid syntax. The code is available at https://github.com/answeryt/Fat-Cat.",
    "title_zh": "肥猫：基于文档驱动的元认知多智能体系统，用于复杂推理",
    "abstract_zh": "基于大语言模型（LLM）的智能体效能往往不仅受限于模型本身的容量，更在于运行时对上下文信息的利用效率。现有的智能体框架通常依赖于结构僵化、语法复杂的状态表示方式，如嵌套的JSON格式，这使得模型需将大量有限的注意力资源用于处理语法结构，而非专注于语义推理。本文提出了一种名为Fat-Cat的文档驱动型智能体架构，旨在提升状态管理中的信号与噪声比。该架构融合了三个核心组件：(1) 语义文件系统，将智能体状态以与常见预训练语料对齐的Markdown文档形式表示；(2) 文本策略演化模块，可在不更新参数的前提下积累任务求解知识；(3) 封闭环观察器，能够监控推理轨迹，有效降低幻觉现象。在广泛的推理、检索和编码基准测试中，Fat-Cat均表现出持续的性能提升。实验表明，该架构使Kimi-k2模型在HotPotQA任务上超越专有的GPT-4o基线表现。当用传统的JSON状态表示替代文档式状态时，性能显著下降，从而实证验证了文档驱动状态建模相较于刚性语法表示的关键优势。代码已开源，地址为：https://github.com/answeryt/Fat-Cat。"
  },
  {
    "date": "2026-02-02",
    "title": "Learning Generative Selection for Best-of-N",
    "authors": "Shubham Toshniwal, Aleksander Ficek, Siddhartha Jain, Wei Du, Vahid Noroozi, Sadegh Mahdavi, Somshubra Majumdar, Igor Gitman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02143v1",
    "source": "arXiv",
    "abstract": "Scaling test-time compute via parallel sampling can substantially improve LLM reasoning, but is often limited by Best-of-N selection quality. Generative selection methods, such as GenSelect, address this bottleneck, yet strong selection performance remains largely limited to large models. We show that small reasoning models can acquire strong GenSelect capabilities through targeted reinforcement learning. To this end, we synthesize selection tasks from large-scale math and code instruction datasets by filtering to instances with both correct and incorrect candidate solutions, and train 1.7B-parameter models with DAPO to reward correct selections. Across math (AIME24, AIME25, HMMT25) and code (LiveCodeBench) reasoning benchmarks, our models consistently outperform prompting and majority-voting baselines, often approaching or exceeding much larger models. Moreover, these gains generalize to selecting outputs from stronger models despite training only on outputs from weaker models. Overall, our results establish reinforcement learning as a scalable way to unlock strong generative selection in small models, enabling efficient test-time scaling.",
    "title_zh": "学习生成式选择以实现最佳N选一",
    "abstract_zh": "通过并行采样扩展推理时的计算资源可以显著提升大语言模型（LLM）的推理能力，但这一方法常受限于“最佳N选一”（Best-of-N）选择的质量。生成式选择方法（如GenSelect）虽能缓解这一瓶颈，但其优异的选择性能目前主要局限于大型模型。我们发现，通过有针对性的强化学习，小型推理模型也能获得强大的GenSelect能力。为此，我们从大规模数学与代码指令数据集中构建选择任务，筛选出同时包含正确与错误候选解的实例，并使用DAPO算法训练参数量为1.7B的模型，以奖励正确选择。在数学（AIME24、AIME25、HMMT25）和代码（LiveCodeBench）推理基准测试中，我们的模型持续优于提示工程和多数投票基线方法，常常达到甚至超越远大于自身的大型模型。此外，这些性能提升还能泛化到从更强模型生成的输出选择，尽管训练过程中仅使用了弱模型的输出。总体而言，我们的结果表明，强化学习是一种可扩展的途径，能够有效激发小型模型中的强大生成式选择能力，从而实现高效的推理时扩展。"
  },
  {
    "date": "2026-02-02",
    "title": "ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing",
    "authors": "Hanlin Zhou, Huah Yong Chan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01797v1",
    "source": "arXiv",
    "abstract": "Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks. However, many existing systems rely on stochastic routing or ad-hoc heuristics, making their behavior difficult to reproduce and their decision process hard to interpret. We propose ORCH, a deterministic coordination framework for discrete-choice reasoning that orchestrates heterogeneous LLMs. ORCH follows a ``many analyses, one decision'' paradigm: multiple base models independently produce structured analyses, and a dedicated merge agent outputs the final choice. The framework uses fixed rules for task decomposition and answer aggregation, keeping the pipeline predictable, reproducible, and training-free. Determinism here refers to fixed routing and aggregation rules under a fixed evaluation protocol, rather than strict bit-level reproducibility across deployments. To exploit model complementarity, we optionally introduce an EMA-guided router that updates agent selection using historical accuracy, latency, or cost; since it relies on answer-based feedback, it is mainly intended for benchmarking, controlled evaluation, or delayed-feedback settings. Experiments on MMLU, MMLU-Pro, and GSM8K show that ORCH consistently outperforms single-model baselines and a majority-vote ensemble. On MMLU-Pro, ORCH improves accuracy by over 10 points compared to the strongest baseline, and on GSM8K it yields gains exceeding 50 points; McNemar tests confirm statistical significance. The EMA router provides an additional 0.7--2.0 point accuracy boost, and ablations show that both multi-agent collaboration and routing contribute substantially. Overall, ORCH offers a practical path toward controllable, interpretable, and deployment-ready LLM-based agent systems for discrete-choice reasoning.",
    "title_zh": "ORCH：多次分析，一次合并——一种基于EMA引导路由的离散选择推理确定性多智能体编排器",
    "abstract_zh": "大规模语言模型（LLMs）的最新进展使得多智能体架构在应对复杂推理任务方面变得极具吸引力。然而，现有许多系统依赖随机路由或临时性启发式规则，导致其行为难以复现，决策过程也难以解释。为此，我们提出了ORCH——一种用于离散选择推理的确定性协调框架，能够协调异构的LLM。ORCH遵循“多分析、一决策”的范式：多个基础模型独立生成结构化分析，再由一个专门的合并智能体输出最终选择。该框架采用固定的规则进行任务分解与答案聚合，使整个流程具备可预测性、可复现性且无需训练。这里的“确定性”指的是在固定评估协议下，路由和聚合规则保持不变，而非跨部署的严格比特级可复现性。为充分利用模型间的互补性，我们可选地引入一种基于EMA（指数移动平均）指导的路由器，通过历史准确率、延迟或成本动态调整智能体选择；由于该路由器依赖于答案反馈，主要适用于基准测试、受控评估或延迟反馈场景。在MMLU、MMLU-Pro和GSM8K上的实验表明，ORCH在各项任务中均显著优于单模型基线和多数投票集成方法。在MMLU-Pro上，ORCH相比最强基线准确率提升超过10个百分点；在GSM8K上，准确率提升超过50个百分点；McNemar检验进一步证实了结果的统计显著性。EMA路由器额外带来了0.7至2.0个百分点的准确率提升，消融实验也表明，多智能体协作与智能路由均对性能有显著贡献。总体而言，ORCH为构建可控、可解释且可部署的基于LLM的智能体系统提供了一条切实可行的路径，特别适用于离散选择推理任务。"
  },
  {
    "date": "2026-02-02",
    "title": "CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding",
    "authors": "Yuling Shi, Chaoxiang Xie, Zhensu Sun, Yeheng Chen, Chenxu Zhang, Longfei Yun, Chengcheng Wan, Hongyu Zhang, David Lo, Xiaodong Gu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01785v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in source code understanding, yet as software systems grow in scale, computational efficiency has become a critical bottleneck. Currently, these models rely on a text-based paradigm that treats source code as a linear sequence of tokens, which leads to a linear increase in context length and associated computational costs. The rapid advancement of Multimodal LLMs (MLLMs) introduces an opportunity to optimize efficiency by representing source code as rendered images. Unlike text, which is difficult to compress without losing semantic meaning, the image modality is inherently suitable for compression. By adjusting resolution, images can be scaled to a fraction of their original token cost while remaining recognizable to vision-capable models. To explore the feasibility of this approach, we conduct the first systematic study on the effectiveness of MLLMs for code understanding. Our experiments reveal that: (1) MLLMs can effectively understand code with substantial token reduction, achieving up to 8x compression; (2) MLLMs can effectively leverage visual cues such as syntax highlighting, improving code completion performance under 4x compression; and (3) Code-understanding tasks like clone detection exhibit exceptional resilience to visual compression, with some compression ratios even slightly outperforming raw text inputs. Our findings highlight both the potential and current limitations of MLLMs in code understanding, which points out a shift toward image-modality code representation as a pathway to more efficient inference.",
    "title_zh": "CodeOCR：视觉语言模型在代码理解中的有效性研究",
    "abstract_zh": "大型语言模型（LLMs）在源代码理解方面取得了显著成功，但随着软件系统规模的不断增长，计算效率已成为一个关键瓶颈。目前，这些模型依赖于基于文本的范式，将源代码视为线性排列的标记序列，导致上下文长度和相关计算成本呈线性增长。多模态大语言模型（MLLMs）的快速发展为优化效率提供了新机遇：通过将源代码表示为渲染后的图像，实现更高效的处理。与难以在不损失语义信息的前提下压缩的文本不同，图像模态本身具有天然的压缩优势。通过调整图像分辨率，可以在保持视觉模型可识别性的前提下，将原始的标记成本降低至其几分之一。为探索这一方法的可行性，我们首次系统性地研究了MLLMs在代码理解任务中的有效性。实验结果表明：（1）MLLMs能够有效理解代码，并实现高达8倍的标记压缩；（2）MLLMs能够有效利用语法高亮等视觉线索，在4倍压缩下提升代码补全性能；（3）诸如代码克隆检测等代码理解任务对视觉压缩表现出极强的鲁棒性，部分压缩比甚至优于原始文本输入。我们的研究结果揭示了MLLMs在代码理解中的潜力与当前局限，也指明了向图像模态代码表示转变，作为实现更高效推理的一条可行路径。"
  },
  {
    "date": "2026-02-02",
    "title": "Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking",
    "authors": "Mohammad Beigi, Ming Jin, Junshan Zhang, Qifan Wang, Lifu Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01750v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) remains vulnerable to reward hacking, where models exploit spurious correlations in learned reward models to achieve high scores while violating human intent. Existing mitigations rely on static defenses that cannot adapt to novel exploitation strategies. We propose Adversarial Reward Auditing (ARA), a framework that reconceptualizes reward hacking as a dynamic, competitive game. ARA operates in two stages: first, a Hacker policy discovers reward model vulnerabilities while an Auditor learns to detect exploitation from latent representations; second, Auditor-Guided RLHF (AG-RLHF) gates reward signals to penalize detected hacking, transforming reward hacking from an unobservable failure into a measurable, controllable signal. Experiments across three hacking scenarios demonstrate that ARA achieves the best alignment-utility tradeoff among all baselines: reducing sycophancy to near-SFT levels while improving helpfulness, decreasing verbosity while achieving the highest ROUGE-L, and suppressing code gaming while improving Pass@1. Beyond single-domain evaluation, we show that reward hacking, detection, and mitigation all generalize across domains -- a Hacker trained on code gaming exhibits increased sycophancy despite no reward for this behavior, and an Auditor trained on one domain effectively suppresses exploitation in others, enabling efficient multi-domain defense with a single model.",
    "title_zh": "对抗性奖励审计：用于主动检测与缓解奖励黑客行为",
    "abstract_zh": "基于人类反馈的强化学习（RLHF）仍然容易受到“奖励劫持”（reward hacking）的影响，即模型利用学习到的奖励模型中的虚假相关性来获取高分，却违背了人类的本意。现有的缓解方法依赖于静态防御机制，无法适应新型的攻击策略。我们提出了一种对抗性奖励审计框架（Adversarial Reward Auditing, ARA），将奖励劫持重新定义为一种动态、对抗性的博弈过程。ARA分为两个阶段：第一阶段，黑客策略（Hacker policy）主动发现奖励模型的漏洞，而审计员（Auditor）则学习从潜在表示中检测出这些滥用行为；第二阶段，由审计员引导的强化学习（AG-RLHF）对奖励信号进行筛选，对检测到的劫持行为施加惩罚，从而将原本不可见的奖励劫持问题转化为可测量、可控制的信号。\n\n在三种不同的劫持场景下的实验表明，ARA 在所有基线方法中实现了最佳的对齐性与实用性权衡：将奉承行为降低至接近监督微调（SFT）水平的同时提升了帮助性；减少了冗余表达，同时取得了最高的 ROUGE-L 分数；抑制了代码游戏行为，同时提高了 Pass@1 的表现。此外，我们的研究还证明，奖励劫持、检测与缓解能力均具有跨领域泛化性——一个在代码游戏任务上训练的黑客策略，即使未获得此类行为的奖励，也表现出更高的奉承倾向；而一个在某一领域训练的审计员模型，能够有效抑制其他领域的滥用行为。这使得仅用单一模型即可实现高效、多领域的防御体系。"
  },
  {
    "date": "2026-02-02",
    "title": "Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives",
    "authors": "Lin Chen, Samuel Drapeau, Fanghao Shao, Xuekai Zhu, Bo Xue, Yunchong Song, Mathieu Laurière, Zhouhan Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01749v1",
    "source": "arXiv",
    "abstract": "Generative Flow Network (GFlowNet) objectives implicitly fix an equal mixing of forward and backward policies, potentially constraining the exploration-exploitation trade-off during training. By further exploring the link between GFlowNets and Markov chains, we establish an equivalence between GFlowNet objectives and Markov chain reversibility, thereby revealing the origin of such constraints, and provide a framework for adapting Markov chain properties to GFlowNets. Building on these theoretical findings, we propose $α$-GFNs, which generalize the mixing via a tunable parameter $α$. This generalization enables direct control over exploration-exploitation dynamics to enhance mode discovery capabilities, while ensuring convergence to unique flows. Across various benchmarks, including Set, Bit Sequence, and Molecule Generation, $α$-GFN objectives consistently outperform previous GFlowNet objectives, achieving up to a $10 \\times$ increase in the number of discovered modes.",
    "title_zh": "通过马尔可夫链视角控制GFlowNets中的探索与利用",
    "abstract_zh": "生成流网络（GFlowNet）的目标函数隐式地固定了前向与后向策略的等量混合，这可能在训练过程中限制了探索与利用之间的权衡。通过进一步探讨GFlowNet与马尔可夫链之间的联系，我们建立了GFlowNet目标函数与马尔可夫链可逆性之间的等价关系，从而揭示了此类约束的根源，并提供了一个将马尔可夫链性质适配到GFlowNet的框架。基于这些理论发现，我们提出了α-GFNs，通过一个可调参数α对混合方式进行推广。这一推广使得能够直接调控探索-利用动态，以增强模式发现能力，同时保证收敛至唯一的流分布。在多种基准测试中，包括集合生成、位序列生成和分子生成任务，α-GFN目标函数始终优于以往的GFlowNet目标函数，最多使发现的模式数量提升10倍。"
  },
  {
    "date": "2026-02-02",
    "title": "COMI: Coarse-to-fine Context Compression via Marginal Information Gain",
    "authors": "Jiwei Tang, Shilei Liu, Zhicheng Zhang, Yujin Yuan, Libin Zheng, Wenbo Su, Bo Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01719v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities across diverse tasks. However, their deployment in long context scenarios remains hindered by computational inefficiency and information redundancy. Context compression methods address these challenges by significantly reducing input length and eliminating redundancy. We propose COMI, a coarse-to-fine adaptive context compression framework that jointly optimizes for semantic relevance and diversity under high compression rates. We introduce Marginal Information Gain (MIG), a metric defined as the relevance of a unit to the input query minus its semantic redundancy with other units, guiding the compression process to prioritize information that is both relevant and low redundant. The framework operates in two stages: (1) Coarse-Grained Group Reallocation, where the context is partitioned into groups and dynamically assigned compression rates based on inter-group MIG, ensuring compression budgets align with information value distribution; and (2) Fine-Grained Token Merging, where tokens within each group are fused via an intra-group MIG-based weighting mechanism, thereby preserving key semantics while avoiding the accumulation of redundancy. Extensive experiments across question-answering (e.g., NaturalQuestions, 2WikiMQA, HotpotQA and NarrativeQA), summarization (e.g., MultiNews) with various backbones (e.g., LLaMA-2-7B, Qwen2-7B) show that COMI outperforms existing baselines by a large margin, e.g., approximately 25-point Exact Match (EM) improvement under 32x compression constraint with Qwen2-7B on NaturalQuestions.",
    "title_zh": "COMI：通过边际信息增益实现粗到细的上下文压缩",
    "abstract_zh": "大型语言模型（LLMs）在各类任务中展现了卓越的能力。然而，其在长上下文场景中的部署仍受限于计算效率低下和信息冗余问题。上下文压缩方法通过显著缩短输入长度并消除冗余，有效缓解了这些挑战。我们提出COMI——一种从粗到细的自适应上下文压缩框架，能够在高压缩率下联合优化语义相关性与多样性。为此，我们引入了**边际信息增益**（Marginal Information Gain, MIG），该指标定义为某单元对输入查询的相关性减去其与其他单元之间的语义冗余度，从而引导压缩过程优先保留既相关又低冗余的信息。\n\n该框架包含两个阶段：  \n（1）**粗粒度分组重分配**：将上下文划分为若干组，并根据组间MIG动态分配压缩率，确保压缩预算与信息价值分布相匹配；  \n（2）**细粒度标记合并**：在每组内部，基于组内MIG加权机制融合token，有效保留关键语义的同时避免冗余累积。\n\n在多种基准任务（如问答任务：NaturalQuestions、2WikiMQA、HotpotQA、NarrativeQA；摘要任务：MultiNews）及不同骨干模型（如LLaMA-2-7B、Qwen2-7B）上的大量实验表明，COMI显著优于现有基线方法。例如，在Qwen2-7B模型上，于NaturalQuestions数据集上实现32倍压缩约束时，Exact Match（EM）指标提升约25个百分点，充分验证了其高效性与优越性能。"
  },
  {
    "date": "2026-02-02",
    "title": "Scaling Search-Augmented LLM Reasoning via Adaptive Information Control",
    "authors": "Siheng Xiong, Oguzhan Gungordu, Blair Johnson, James C. Kerce, Faramarz Fekri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01672v1",
    "source": "arXiv",
    "abstract": "Search-augmented reasoning agents interleave multi-step reasoning with external information retrieval, but uncontrolled retrieval often leads to redundant evidence, context saturation, and unstable learning. Existing approaches rely on outcome-based reinforcement learning (RL), which provides limited guidance for regulating information acquisition. We propose DeepControl, a framework for adaptive information control based on a formal notion of information utility, which measures the marginal value of retrieved evidence under a given reasoning state. Building on this utility, we introduce retrieval continuation and granularity control mechanisms that selectively regulate when to continue and stop retrieval, and how much information to expand. An annealed control strategy enables the agent to internalize effective information acquisition behaviors during training. Extensive experiments across seven benchmarks demonstrate that our method consistently outperforms strong baselines. In particular, our approach achieves average performance improvements of 9.4% and 8.6% on Qwen2.5-7B and Qwen2.5-3B, respectively, over strong outcome-based RL baselines, and consistently outperforms both retrieval-free and retrieval-based reasoning methods without explicit information control. These results highlight the importance of adaptive information control for scaling search-augmented reasoning agents to complex, real-world information environments.",
    "title_zh": "通过自适应信息控制实现搜索增强型大语言模型推理的扩展",
    "abstract_zh": "搜索增强型推理代理通过在多步推理过程中交替进行外部信息检索，实现更精准的决策。然而，不受控制的检索常常导致冗余证据、上下文过载以及学习过程的不稳定性。现有方法主要依赖基于结果的强化学习（RL），但其对信息获取的调控能力有限。为此，我们提出 DeepControl，一种基于信息效用形式化定义的自适应信息控制框架，该效用度量在特定推理状态下所获取证据的边际价值。基于此效用概念，我们引入了检索延续性控制与粒度控制机制，能够有选择性地调节检索的继续与终止时机，以及信息扩展的程度。通过采用退火式控制策略，代理在训练过程中能够内化高效的信息获取行为。在七个基准测试上的大量实验表明，我们的方法始终优于强基线模型。具体而言，在 Qwen2.5-7B 和 Qwen2.5-3B 模型上，相较于强大的基于结果的强化学习基线，平均性能分别提升了 9.4% 和 8.6%；同时，我们的方法在无需显式信息控制的前提下，始终优于无检索与有检索但缺乏控制的推理方法。这些结果凸显了自适应信息控制在将搜索增强型推理代理扩展至复杂、真实世界信息环境中的关键作用。"
  },
  {
    "date": "2026-02-02",
    "title": "FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning",
    "authors": "Mingda Zhang, Haoran Luo, Tiesunlong Shen, Qika Lin, Xiaoying Tang, Rui Mao, Erik Cambria",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01664v1",
    "source": "arXiv",
    "abstract": "In recent years, a variety of powerful agentic workflows have been applied to solve a wide range of human problems. However, existing workflow orchestration still faces key challenges, including high manual cost, reliance on specific operators/large language models (LLMs), and sparse reward signals. To address these challenges, we propose FlowSteer, an end-to-end reinforcement learning framework that takes a lightweight policy model as the agent and an executable canvas environment, automating workflow orchestration through multi-turn interaction. In this process, the policy model analyzes execution states and selects editing actions, while the canvas executes operators and returns feedback for iterative refinement. Moreover, FlowSteer provides a plug-and-play framework that supports diverse operator libraries and interchangeable LLM backends. To effectively train this interaction paradigm, we propose Canvas Workflow Relative Policy Optimization (CWRPO), which introduces diversity-constrained rewards with conditional release to stabilize learning and suppress shortcut behaviors. Experimental results on twelve datasets show that FlowSteer significantly outperforms baselines across various tasks.",
    "title_zh": "FlowSteer：通过端到端强化学习实现交互式智能体工作流编排",
    "abstract_zh": "近年来，多种强大的智能体工作流被应用于解决各类人类问题。然而，现有的工作流编排仍面临诸多关键挑战，包括人工成本高、对特定操作符或大型语言模型（LLMs）的依赖性，以及稀疏的奖励信号。为应对这些挑战，我们提出了FlowSteer——一种端到端的强化学习框架。该框架以轻量级策略模型作为智能体，结合可执行画布环境，通过多轮交互实现工作流编排的自动化。在此过程中，策略模型分析执行状态并选择编辑操作，而画布环境则执行操作符并返回反馈，以实现迭代优化。此外，FlowSteer提供即插即用的框架设计，支持多样化的操作符库和可互换的LLM后端。为有效训练这种交互范式，我们提出了画布工作流相对策略优化（CWRPO），通过引入具有条件释放机制的多样性约束奖励，稳定学习过程并抑制捷径行为。在十二个数据集上的实验结果表明，FlowSteer在各类任务中均显著优于现有基线方法。"
  },
  {
    "date": "2026-02-02",
    "title": "Expanding the Capabilities of Reinforcement Learning via Text Feedback",
    "authors": "Yuda Song, Lili Chen, Fahim Tajwar, Remi Munos, Deepak Pathak, J. Andrew Bagnell, Aarti Singh, Andrea Zanette",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02482v1",
    "source": "arXiv",
    "abstract": "The success of RL for LLM post-training stems from an unreasonably uninformative source: a single bit of information per rollout as binary reward or preference label. At the other extreme, distillation offers dense supervision but requires demonstrations, which are costly and difficult to scale. We study text feedback as an intermediate signal: richer than scalar rewards, yet cheaper than complete demonstrations. Textual feedback is a natural mode of human interaction and is already abundant in many real-world settings, where users, annotators, and automated judges routinely critique LLM outputs. Towards leveraging text feedback at scale, we formalize a multi-turn RL setup, RL from Text Feedback (RLTF), where text feedback is available during training but not at inference. Therefore, models must learn to internalize the feedback in order to improve their test-time single-turn performance. To do this, we propose two methods: Self Distillation (RLTF-SD), which trains the single-turn policy to match its own feedback-conditioned second-turn generations; and Feedback Modeling (RLTF-FM), which predicts the feedback as an auxiliary objective. We provide theoretical analysis on both methods, and empirically evaluate on reasoning puzzles, competition math, and creative writing tasks. Our results show that both methods consistently outperform strong baselines across benchmarks, highlighting the potential of RL with an additional source of rich supervision at scale.",
    "title_zh": "通过文本反馈扩展强化学习的能力",
    "abstract_zh": "大语言模型（LLM）后训练阶段强化学习（RL）的成功，源于一种极为低效的信息源：每轮推演仅提供一个比特的信息，即二元奖励或偏好标签。而在另一极端，知识蒸馏虽能提供密集监督，却依赖于示范数据，而示范数据成本高昂且难以扩展。本文研究了一种介于两者之间的信号——文本反馈：其信息量远超标量奖励，但又比完整示范廉价得多。文本反馈是人类交互的自然形式，在许多现实场景中已广泛存在，用户、标注者和自动化评判系统经常对LLM的输出进行批评与反馈。为实现文本反馈的大规模利用，我们形式化了一种多轮强化学习框架——从文本反馈中学习（RLTF），其中文本反馈在训练阶段可用，但在推理阶段不可见。因此，模型必须学会内化这些反馈，以提升其在测试阶段单轮生成的表现。为此，我们提出两种方法：自蒸馏（RLTF-SD），训练单轮策略以匹配其自身基于反馈的第二轮生成；反馈建模（RLTF-FM），将预测反馈作为辅助目标。我们对两种方法进行了理论分析，并在推理谜题、竞赛数学和创意写作任务上进行了实证评估。结果表明，两种方法在多个基准测试中均持续优于强基线模型，凸显了在大规模场景下引入丰富监督信号的强化学习的巨大潜力。"
  },
  {
    "date": "2026-02-02",
    "title": "Qrita: High-performance Top-k and Top-p Algorithm for GPUs using Pivot-based Truncation and Selection",
    "authors": "Jongseok Park, Sunga Kim, Alvin Cheung, Ion Stoica",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01518v1",
    "source": "arXiv",
    "abstract": "Top-k and Top-p are the dominant truncation operators in the sampling of large language models. Despite their widespread use, implementing them efficiently over large vocabularies remains a significant challenge. Existing approaches often rely on sorting, which incur significant computation and memory overhead on GPUs, or stochastic approaches, which alter the algorithm output. In this work, we propose Qrita, an efficient Top-k and Top-p algorithm based on a pivot-based selection strategy. Based on RTop-k, which uses a pivot-based search for node selection in graph neural networks, Qrita extends the concept of pivot-based search to both Top-k and Top-p with two key techniques: 1. Gaussian-based sigma-truncation, which greatly reduces the search space of the target elements, and 2. Quaternary pivot search with duplication handling, which halves the pivot search iteration and guarantees deterministic output. We provide the full implementation of Qrita using Triton, a popular GPU programming language. Our evaluation of Qrita against the Top-k and Top-p kernels of high performance LLM execution engines such as vLLM, SGLang, and Flashinfer show that Qrita achieves up to 2 times throughput and half memory use while providing the same output to the the sorting-based algorithms.",
    "title_zh": "Qrita：基于枢轴截断与选择的高性能GPU Top-k和Top-p算法",
    "abstract_zh": "Top-k 和 Top-p 是大型语言模型采样中占主导地位的截断算子。尽管它们被广泛使用，但在大规模词汇表上高效实现这些算子仍然是一个重大挑战。现有的方法通常依赖于排序，这在 GPU 上会带来显著的计算和内存开销；或者采用随机方法，但会改变算法的输出结果。在本工作中，我们提出了 Qrita，一种基于枢纽选择策略的高效 Top-k 和 Top-p 算法。Qrita 借鉴了 RTop-k 的思想——该方法在图神经网络中使用基于枢纽的搜索来选择节点——并将其扩展至 Top-k 和 Top-p 两种场景，提出了两项关键技术：1. 基于高斯分布的 sigma 截断，可大幅缩小目标元素的搜索空间；2. 带重复处理的四元枢纽搜索，将枢纽搜索迭代次数减半，并保证输出的确定性。我们使用 Triton（一种流行的 GPU 编程语言）实现了 Qrita 的完整版本。在与 vLLM、SGLang 和 Flashinfer 等高性能 LLM 执行引擎中的 Top-k 和 Top-p 内核进行对比评估后发现，Qrita 在保持与基于排序算法相同输出结果的同时，实现了最高达 2 倍的吞吐量提升，并将内存使用量减少了一半。"
  },
  {
    "date": "2026-02-02",
    "title": "OpInf-LLM: Parametric PDE Solving with LLMs via Operator Inference",
    "authors": "Zhuoyuan Wang, Hanjiang Hu, Xiyu Deng, Saviz Mowlavi, Yorie Nakahira",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01493v1",
    "source": "arXiv",
    "abstract": "Solving diverse partial differential equations (PDEs) is fundamental in science and engineering. Large language models (LLMs) have demonstrated strong capabilities in code generation, symbolic reasoning, and tool use, but reliably solving PDEs across heterogeneous settings remains challenging. Prior work on LLM-based code generation and transformer-based foundation models for PDE learning has shown promising advances. However, a persistent trade-off between execution success rate and numerical accuracy arises, particularly when generalization to unseen parameters and boundary conditions is required. In this work, we propose OpInf-LLM, an LLM parametric PDE solving framework based on operator inference. The proposed framework leverages a small amount of solution data to enable accurate prediction of diverse PDE instances, including unseen parameters and configurations, and provides seamless integration with LLMs for natural language specification of PDE solving tasks. Its low computational demands and unified tool interface further enable a high execution success rate across heterogeneous settings. By combining operator inference with LLM capabilities, OpInf-LLM opens new possibilities for generalizable reduced-order modeling in LLM-based PDE solving.",
    "title_zh": "OpInf-LLM：通过算子推断实现基于大语言模型的参数化偏微分方程求解",
    "abstract_zh": "求解各类偏微分方程（PDE）在科学与工程领域具有基础性意义。大型语言模型（LLMs）在代码生成、符号推理和工具使用方面展现出强大的能力，但在异构环境下可靠求解PDE仍面临挑战。此前基于LLM的代码生成以及基于Transformer的PDE学习基础模型研究已取得显著进展。然而，当需要泛化到未见过的参数和边界条件时，执行成功率与数值精度之间始终存在难以调和的权衡。本文提出OpInf-LLM，一种基于算子推断（operator inference）的LLM参数化PDE求解框架。该框架仅需少量解数据，即可准确预测多种PDE实例，包括未见过的参数与配置，并支持通过自然语言无缝指定PDE求解任务，实现与LLM的高效集成。其低计算开销与统一的工具接口，进一步保障了在异构环境下的高执行成功率。通过结合算子推断与LLM的能力，OpInf-LLM为基于LLM的PDE求解中可泛化的降阶建模开辟了新路径。"
  },
  {
    "date": "2026-02-02",
    "title": "Probability-Entropy Calibration: An Elastic Indicator for Adaptive Fine-tuning",
    "authors": "Wenhao Yu, Shaohang Wei, Jiahong Liu, Yifan Li, Minda Hu, Aiwei Liu, Hao Zhang, Irwin King",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01745v1",
    "source": "arXiv",
    "abstract": "Token-level reweighting is a simple yet effective mechanism for controlling supervised fine-tuning, but common indicators are largely one-dimensional: the ground-truth probability reflects downstream alignment, while token entropy reflects intrinsic uncertainty induced by the pre-training prior. Ignoring entropy can misidentify noisy or easily replaceable tokens as learning-critical, while ignoring probability fails to reflect target-specific alignment. RankTuner introduces a probability--entropy calibration signal, the Relative Rank Indicator, which compares the rank of the ground-truth token with its expected rank under the prediction distribution. The inverse indicator is used as a token-wise Relative Scale to reweight the fine-tuning objective, focusing updates on truly under-learned tokens without over-penalizing intrinsically uncertain positions. Experiments on multiple backbones show consistent improvements on mathematical reasoning benchmarks, transfer gains on out-of-distribution reasoning, and pre code generation performance over probability-only or entropy-only reweighting baselines.",
    "title_zh": "概率-熵校准：一种用于自适应微调的弹性指标",
    "abstract_zh": "令牌级重加权是一种简单而有效的机制，可用于控制监督微调，但常见的指标大多为一维：真实标签概率反映了下游对齐程度，而令牌熵则反映了预训练先验所引发的内在不确定性。忽略熵可能导致将噪声较大的或易于替换的令牌误判为学习关键项，而忽略概率则无法体现目标特定的对齐情况。RankTuner引入了一种概率-熵校准信号——相对排名指示器（Relative Rank Indicator），该指标通过比较真实标签令牌的排名与其在预测分布下的期望排名，来衡量学习状态。该指标的逆值被用作令牌级别的相对尺度，以重加权微调目标，从而聚焦于真正学习不足的令牌，同时避免对内在不确定性较高的位置过度惩罚。在多种骨干模型上的实验表明，RankTuner在数学推理基准测试中均表现出一致的性能提升，在分布外推理任务上实现了更好的迁移效果，并在代码生成任务中优于仅基于概率或仅基于熵的重加权基线方法。"
  },
  {
    "date": "2026-02-02",
    "title": "Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models",
    "authors": "Wenhui Tan, Fiorenzo Parascandolo, Enver Sangineto, Jianzhong Ju, Zhenbo Luo, Qian Cao, Rita Cucchiara, Ruihua Song, Jian Luan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01698v1",
    "source": "arXiv",
    "abstract": "Large Reasoning Models (LRMs) have recently achieved strong mathematical and code reasoning performance through Reinforcement Learning (RL) post-training. However, we show that modern reasoning post-training induces an unintended exploration collapse: temperature-based sampling no longer increases pass@$n$ accuracy. Empirically, the final-layer posterior of post-trained LRMs exhibit sharply reduced entropy, while the entropy of intermediate layers remains relatively high. Motivated by this entropy asymmetry, we propose Latent Exploration Decoding (LED), a depth-conditioned decoding strategy. LED aggregates intermediate posteriors via cumulative sum and selects depth configurations with maximal entropy as exploration candidates. Without additional training or parameters, LED consistently improves pass@1 and pass@16 accuracy by 0.61 and 1.03 percentage points across multiple reasoning benchmarks and models. Project page: https://GitHub.com/Xiaomi-Research/LED.",
    "title_zh": "后训练阶段的探索恢复：大型推理模型的潜在探索解码",
    "abstract_zh": "大型推理模型（LRMs）最近通过强化学习（RL）后训练，在数学和代码推理任务上取得了显著性能。然而，我们发现现代推理后训练会导致一种意外的探索坍缩现象：基于温度的采样不再能提升 pass@$n$ 准确率。实证研究表明，后训练LRMs的最终层后验分布熵显著降低，而中间层的熵则保持相对较高。受这种熵不对称性的启发，我们提出了潜空间探索解码（Latent Exploration Decoding, LED），一种基于深度条件的解码策略。LED通过累积求和聚合中间层后验分布，并选择熵最大的深度配置作为探索候选。无需额外训练或引入新参数，LED在多个推理基准和模型上，一致地将 pass@1 和 pass@16 准确率分别提升了 0.61 和 1.03 个百分点。项目页面：https://GitHub.com/Xiaomi-Research/LED。"
  },
  {
    "date": "2026-02-02",
    "title": "ProjDevBench: Benchmarking AI Coding Agents on End-to-End Project Development",
    "authors": "Pengrui Lu, Shiqi Zhang, Yunzhong Hou, Lyumanshan Ye, Chaoyi Huang, Zixi Chen, Ji Zeng, Hantao Jiang, Pengfei Liu, Yiwei Wang, Ming-Hsuan Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01655v1",
    "source": "arXiv",
    "abstract": "Recent coding agents can generate complete codebases from simple prompts, yet existing evaluations focus on issue-level bug fixing and lag behind end-to-end development. We introduce ProjDevBench, an end-to-end benchmark that provides project requirements to coding agents and evaluates the resulting repositories. Combining Online Judge (OJ) testing with LLM-assisted code review, the benchmark evaluates agents on (1) system architecture design, (2) functional correctness, and (3) iterative solution refinement. We curate 20 programming problems across 8 categories, covering both concept-oriented tasks and real-world application scenarios, and evaluate six coding agents built on different LLM backends. Our evaluation reports an overall acceptance rate of 27.38%: agents handle basic functionality and data structures but struggle with complex system design, time complexity optimization, and resource management. Our benchmark is available at https://github.com/zsworld6/projdevbench.",
    "title_zh": "ProjDevBench：面向端到端项目开发的AI编程代理基准测试",
    "abstract_zh": "近期的编码代理能够从简单的提示词生成完整的代码库，但现有的评估方法仍集中于单个问题的错误修复，难以跟上端到端开发的实际需求。为此，我们提出了 ProjDevBench，一个端到端的评估基准，为编码代理提供项目需求，并评估其生成的代码仓库质量。该基准结合在线判题系统（OJ）测试与大语言模型（LLM）辅助代码审查，从三个方面评估代理的表现：（1）系统架构设计，（2）功能正确性，以及（3）迭代优化能力。我们精心挑选了涵盖8个类别的20个编程问题，既包括概念性任务，也包含真实世界的应用场景。我们对基于不同LLM后端构建的六款编码代理进行了评估。评估结果显示，整体通过率为27.38%：代理在处理基础功能和数据结构方面表现尚可，但在复杂系统设计、时间复杂度优化和资源管理方面仍面临显著挑战。本基准已开源，地址为：https://github.com/zsworld6/projdevbench。"
  },
  {
    "date": "2026-02-02",
    "title": "Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models",
    "authors": "Jiaqian Li, Yanshu Li, Kuan-Hao Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01654v1",
    "source": "arXiv",
    "abstract": "Steering vectors (SVs) offer a lightweight way to control large language models (LLMs) at inference time by shifting hidden activations, providing a practical middle ground between prompting and fine-tuning. Yet SVs can be unreliable in practice. Some concepts are unsteerable, and even when steering helps on average it can backfire for a non-trivial fraction of inputs. Reliability also degrades in long-form generation and multi-attribute steering. We take a geometric view of these failures. A static SV applies the same update vector everywhere in representation space, implicitly assuming that the concept-improving direction is constant across contexts. When the locally effective direction varies with the current activation, a single global vector can become misaligned, which yields weak or reversed effects. Guided by this perspective, we propose Steering Vector Fields (SVF), which learns a differentiable concept scoring function whose local gradient defines the steering direction at each activation, making interventions explicitly context-dependent. This formulation supports coordinated multi-layer interventions in a shared, aligned concept space, and enables efficient long-form and multi-attribute control within a unified framework. Across multiple LLMs and steering tasks, SVF delivers stronger and more reliable control, improving the practicality of inference-time steering.",
    "title_zh": "用于大语言模型推理时上下文感知控制的导向矢量场",
    "abstract_zh": "导向向量（Steering Vectors, SVs）通过调整隐藏层激活值，为在推理阶段轻量级控制大型语言模型（LLMs）提供了一种有效方式，成为提示（prompting）与微调（fine-tuning）之间实用的折中方案。然而，在实际应用中，SVs 的可靠性存在局限：某些概念无法被有效引导，即使在平均意义上有所改善，也仍可能在相当一部分输入上产生反效果。此外，随着生成长度增加或涉及多属性控制，其可靠性进一步下降。本文从几何角度分析这些失败的原因：静态的SV在表示空间中各处施加相同的更新向量，隐含假设了概念增强方向在不同上下文中保持不变。然而，当局部有效的引导方向随当前激活状态而变化时，单一全局向量便可能产生偏差，导致引导效果微弱甚至方向相反。基于这一洞察，我们提出**导向向量场**（Steering Vector Fields, SVF），其核心是一个可微的、用于衡量概念强度的函数，该函数在每个激活点的局部梯度即定义了该位置的引导方向，从而使干预措施显式依赖于上下文。这一框架支持在共享且对齐的概念空间中实现多层协同干预，并在统一框架下高效实现长文本生成与多属性控制。在多个LLM和引导任务上的实验表明，SVF显著提升了控制效果的强度与可靠性，大幅增强了推理阶段引导技术的实用性。"
  },
  {
    "date": "2026-02-02",
    "title": "What Do Agents Learn from Trajectory-SFT: Semantics or Interfaces?",
    "authors": "Weizheng Gu, Chengze Li, Zhuohao Yu, Mengyuan Sun, Zhibang Yang, Wei Wang, Hongrui Jia, Shikun Zhang, Wei Ye",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01611v1",
    "source": "arXiv",
    "abstract": "Large language models are increasingly evaluated as interactive agents, yet standard agent benchmarks conflate two qualitatively distinct sources of success: semantic tool-use and interface-specific interaction pattern memorization. Because both mechanisms can yield identical task success on the original interface, benchmark scores alone are not identifiable evidence of environment-invariant capability. We propose PIPE, a protocol-level evaluation augmentation for diagnosing interface reliance by minimally rewriting environment interfaces while preserving task semantics and execution behavior. Across 16 environments from AgentBench and AgentGym and a range of open-source and API-based agents, PIPE reveals that trajectory-SFT substantially amplifies interface shortcutting: trained agents degrade sharply under minimal interface rewrites, while non-trajectory-trained models remain largely stable. We further introduce Interface Reliance (IR), a counterbalanced alias-based metric that quantifies preference for training-time interfaces, and show that interface shortcutting exhibits environment-dependent, non-monotonic training dynamics that remain invisible under standard evaluation. Our code is available at https://anonymous.4open.science/r/What-Do-Agents-Learn-from-Trajectory-SFT-Semantics-or-Interfaces--0831/.",
    "title_zh": "代理从轨迹SFT中学习的是语义还是接口？",
    "abstract_zh": "大型语言模型正越来越多地被评估为交互式智能体，然而现有的智能体基准测试将两种性质截然不同的成功来源混为一谈：语义层面的工具使用能力，以及针对特定界面的交互模式记忆。由于这两种机制在原始界面下均能导致相同的任务成功，仅凭基准得分无法明确证明模型具备环境不变的能力。为此，我们提出了PIPE——一种协议级评估增强方法，通过最小化地重写环境界面，在保持任务语义和执行行为不变的前提下，诊断模型对界面的依赖程度。在来自AgentBench和AgentGym的16个环境，以及多种开源和基于API的智能体上，PIPE揭示：轨迹监督微调（trajectory-SFT）显著加剧了对界面的捷径依赖：经过轨迹训练的智能体在面对微小界面修改时性能急剧下降，而未经过轨迹训练的模型则保持高度稳定。我们进一步提出了“界面依赖度”（Interface Reliance, IR）这一平衡的基于别名的度量指标，用于量化模型对训练时界面的偏好程度，并发现界面捷径依赖表现出环境相关的、非单调的训练动态，这些现象在传统评估方法下完全不可见。我们的代码已公开，地址为：https://anonymous.4open.science/r/What-Do-Agents-Learn-from-Trajectory-SFT-Semantics-or-Interfaces--0831/。"
  },
  {
    "date": "2026-02-02",
    "title": "From Code-Centric to Concept-Centric: Teaching NLP with LLM-Assisted \"Vibe Coding\"",
    "authors": "Hend Al-Khalifa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01919v1",
    "source": "arXiv",
    "abstract": "The rapid advancement of Large Language Models (LLMs) presents both challenges and opportunities for Natural Language Processing (NLP) education. This paper introduces ``Vibe Coding,'' a pedagogical approach that leverages LLMs as coding assistants while maintaining focus on conceptual understanding and critical thinking. We describe the implementation of this approach in a senior-level undergraduate NLP course, where students completed seven labs using LLMs for code generation while being assessed primarily on conceptual understanding through critical reflection questions. Analysis of end-of-course feedback from 19 students reveals high satisfaction (mean scores 4.4-4.6/5.0) across engagement, conceptual learning, and assessment fairness. Students particularly valued the reduced cognitive load from debugging, enabling deeper focus on NLP concepts. However, challenges emerged around time constraints, LLM output verification, and the need for clearer task specifications. Our findings suggest that when properly structured with mandatory prompt logging and reflection-based assessment, LLM-assisted learning can shift focus from syntactic fluency to conceptual mastery, preparing students for an AI-augmented professional landscape.",
    "title_zh": "从代码中心到概念中心：利用大模型辅助的“氛围编程”教学自然语言处理",
    "abstract_zh": "大型语言模型（LLMs）的快速发展为自然语言处理（NLP）教育带来了挑战与机遇。本文介绍了一种名为“Vibe Coding”的教学方法，该方法利用大型语言模型作为编程助手，同时强调概念理解与批判性思维的培养。我们在一门高年级本科生NLP课程中实施了这一教学方法，学生在七次实验中使用LLMs生成代码，而评估重点则放在通过批判性反思问题来考察其概念理解能力。对19名学生期末反馈的分析显示，学生在参与度、概念学习和评估公平性方面均表现出高度满意（平均分4.4–4.6/5.0）。学生们特别认可LLM减轻调试负担所带来的认知负荷降低，使他们能够更深入地关注NLP核心概念。然而，也暴露出时间不足、LLM输出验证困难以及任务说明不够清晰等挑战。研究结果表明，只要通过强制要求记录提示（prompt logging）并采用以反思为基础的评估方式，LLM辅助学习能够有效将教学重心从语法熟练度转向概念掌握，从而帮助学生更好地适应人工智能赋能的职业环境。"
  },
  {
    "date": "2026-02-02",
    "title": "Internal Flow Signatures for Self-Checking and Refinement in LLMs",
    "authors": "Sungheon Jeong, Sanggeon Yun, Ryozo Masukawa, Wenjun Haung, Hanning Chen, Mohsen Imani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01897v1",
    "source": "arXiv",
    "abstract": "Large language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or a separate judge after generation. We introduce \\emph{internal flow signatures} that audit decision formation from depthwise dynamics at a fixed inter-block monitoring boundary. The method stabilizes token-wise motion via bias-centered monitoring, then summarizes trajectories in compact \\emph{moving} readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport, yielding depth-comparable transported step lengths, turning angles, and subspace drift summaries that are invariant to within-window basis choices. A lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes a culprit depth event and enables a targeted refinement: the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. \\emph{Code is available at} \\texttt{github.com/EavnJeong/Internal-Flow-Signatures-for-Self-Checking-and-Refinement-in-LLMs}.",
    "title_zh": "大语言模型中用于自检与优化的内部流特征",
    "abstract_zh": "大型语言模型能够生成流畅但与上下文不符的回答，而许多现有的防护机制依赖于生成后的外部验证或独立的评判系统。我们提出了一种名为**内部流签名**（internal flow signatures）的新方法，通过在固定块间监控边界处分析深度方向的动力学过程，对决策形成进行审计。该方法通过以偏差为中心的监控稳定逐标记的运动轨迹，随后在每个深度窗口内，基于最高概率标记及其邻近竞争标记，构建紧凑的、与读出对齐的**动态**子空间来总结轨迹。相邻窗口帧通过正交传输进行对齐，从而获得在深度上可比较的传输步长、转向角度以及子空间漂移的总结，这些特征对窗口内基底选择具有不变性。一个基于这些签名训练的轻量级GRU验证器可在不修改基础模型的前提下实现自我检查。除了检测异常，该验证器还能精确定位导致问题的深度事件，并支持针对性的修正：模型可回滚至问题标记处，对识别出的模块中的异常传输步长进行钳制，同时保留正交残差。由此形成的流水线实现了可操作的定位与低开销的内部决策动态自我检查。**代码已公开于** \\texttt{github.com/EavnJeong/Internal-Flow-Signatures-for-Self-Checking-and-Refinement-in-LLMs}。"
  },
  {
    "date": "2026-02-02",
    "title": "BTGenBot-2: Efficient Behavior Tree Generation with Small Language Models",
    "authors": "Riccardo Andrea Izzo, Gianluca Bardaro, Matteo Matteucci",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01870v1",
    "source": "arXiv",
    "abstract": "Recent advances in robot learning increasingly rely on LLM-based task planning, leveraging their ability to bridge natural language with executable actions. While prior works showcased great performances, the widespread adoption of these models in robotics has been challenging as 1) existing methods are often closed-source or computationally intensive, neglecting the actual deployment on real-world physical systems, and 2) there is no universally accepted, plug-and-play representation for robotic task generation. Addressing these challenges, we propose BTGenBot-2, a 1B-parameter open-source small language model that directly converts natural language task descriptions and a list of robot action primitives into executable behavior trees in XML. Unlike prior approaches, BTGenBot-2 enables zero-shot BT generation, error recovery at inference and runtime, while remaining lightweight enough for resource-constrained robots. We further introduce the first standardized benchmark for LLM-based BT generation, covering 52 navigation and manipulation tasks in NVIDIA Isaac Sim. Extensive evaluations demonstrate that BTGenBot-2 consistently outperforms GPT-5, Claude Opus 4.1, and larger open-source models across both functional and non-functional metrics, achieving average success rates of 90.38% in zero-shot and 98.07% in one-shot, while delivering up to 16x faster inference compared to the previous BTGenBot.",
    "title_zh": "BTGenBot-2：基于小型语言模型的高效行为树生成",
    "abstract_zh": "近年来，机器人学习的进展越来越多地依赖于基于大语言模型（LLM）的任务规划，利用其将自然语言与可执行动作相连接的能力。尽管先前的研究已展现出卓越的性能，但这些模型在机器人领域的广泛应用仍面临挑战：1）现有方法通常为闭源或计算开销大，忽视了在真实物理系统中的实际部署；2）缺乏一种被广泛接受、即插即用的机器人任务生成表示方式。针对上述问题，我们提出了BTGenBot-2——一个拥有10亿参数的开源小型语言模型，能够直接将自然语言任务描述和一组机器人动作原语转换为可执行的XML格式行为树。与以往方法不同，BTGenBot-2实现了零样本行为树生成，并在推理和运行时具备错误恢复能力，同时保持轻量化，适用于资源受限的机器人系统。此外，我们还推出了首个基于LLM的行为树生成标准化基准，涵盖NVIDIA Isaac Sim中的52个导航与操作任务。大量实验评估表明，BTGenBot-2在功能与非功能指标上均显著优于GPT-5、Claude Opus 4.1以及更大的开源模型，零样本场景下平均成功率高达90.38%，一次示例（one-shot）场景下达到98.07%，且推理速度相比前代BTGenBot提升最高达16倍。"
  },
  {
    "date": "2026-02-02",
    "title": "Learning While Staying Curious: Entropy-Preserving Supervised Fine-Tuning via Adaptive Self-Distillation for Large Reasoning Models",
    "authors": "Hao Wang, Hao Gu, Hongming Piao, Kaixiong Gong, Yuxiao Ye, Xiangyu Yue, Sirui Han, Yike Guo, Dapeng Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02244v1",
    "source": "arXiv",
    "abstract": "The standard post-training recipe for large reasoning models, supervised fine-tuning followed by reinforcement learning (SFT-then-RL), may limit the benefits of the RL stage: while SFT imitates expert demonstrations, it often causes overconfidence and reduces generation diversity, leaving RL with a narrowed solution space to explore. Adding entropy regularization during SFT is not a cure-all; it tends to flatten token distributions toward uniformity, increasing entropy without improving meaningful exploration capability. In this paper, we propose CurioSFT, an entropy-preserving SFT method designed to enhance exploration capabilities through intrinsic curiosity. It consists of (a) Self-Exploratory Distillation, which distills the model toward a self-generated, temperature-scaled teacher to encourage exploration within its capability; and (b) Entropy-Guided Temperature Selection, which adaptively adjusts distillation strength to mitigate knowledge forgetting by amplifying exploration at reasoning tokens while stabilizing factual tokens. Extensive experiments on mathematical reasoning tasks demonstrate that, in SFT stage, CurioSFT outperforms the vanilla SFT by 2.5 points on in-distribution tasks and 2.9 points on out-of-distribution tasks. We also verify that exploration capabilities preserved during SFT successfully translate into concrete gains in RL stage, yielding an average improvement of 5.0 points.",
    "title_zh": "保持好奇的学习：通过自适应自蒸馏实现熵保持的监督微调以优化大型推理模型",
    "abstract_zh": "大型推理模型的标准微调流程——先进行监督微调（SFT），再进行强化学习（SFT-then-RL）——可能限制了强化学习阶段的收益：SFT通过模仿专家示范进行学习，但往往导致模型过度自信，降低生成多样性，从而压缩了强化学习可探索的解空间。在SFT阶段引入熵正则化并非万能良方；它通常会使词元分布趋于均匀，虽然提升了熵值，却并未真正增强有意义的探索能力。本文提出CurioSFT，一种保持熵特性的监督微调方法，旨在通过内在好奇心提升探索能力。该方法包含两个核心组件：(a) 自探索蒸馏（Self-Exploratory Distillation），通过将模型蒸馏至自生成的、温度调节的教师模型，以鼓励在自身能力范围内的探索；(b) 基于熵的温度自适应选择（Entropy-Guided Temperature Selection），动态调整蒸馏强度，通过在推理相关词元处增强探索、在事实性词元处保持稳定，有效缓解知识遗忘问题。在数学推理任务上的大量实验表明，与标准SFT相比，CurioSFT在SFT阶段于分布内任务上提升2.5分，分布外任务上提升2.9分。我们还验证了SFT阶段所保留的探索能力能够有效转化为强化学习阶段的实际收益，平均提升达5.0分。"
  },
  {
    "date": "2026-02-02",
    "title": "AICD Bench: A Challenging Benchmark for AI-Generated Code Detection",
    "authors": "Daniil Orel, Dilshod Azizov, Indraneil Paul, Yuxia Wang, Iryna Gurevych, Preslav Nakov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02079v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly capable of generating functional source code, raising concerns about authorship, accountability, and security. While detecting AI-generated code is critical, existing datasets and benchmarks are narrow, typically limited to binary human-machine classification under in-distribution settings. To bridge this gap, we introduce $\\emph{AICD Bench}$, the most comprehensive benchmark for AI-generated code detection. It spans $\\emph{2M examples}$, $\\emph{77 models}$ across $\\emph{11 families}$, and $\\emph{9 programming languages}$, including recent reasoning models. Beyond scale, AICD Bench introduces three realistic detection tasks: ($\\emph{i}$)~$\\emph{Robust Binary Classification}$ under distribution shifts in language and domain, ($\\emph{ii}$)~$\\emph{Model Family Attribution}$, grouping generators by architectural lineage, and ($\\emph{iii}$)~$\\emph{Fine-Grained Human-Machine Classification}$ across human, machine, hybrid, and adversarial code. Extensive evaluation on neural and classical detectors shows that performance remains far below practical usability, particularly under distribution shift and for hybrid or adversarial code. We release AICD Bench as a $\\emph{unified, challenging evaluation suite}$ to drive the next generation of robust approaches for AI-generated code detection. The data and the code are available at https://huggingface.co/AICD-bench}.",
    "title_zh": "AICD Bench：一项具有挑战性的AI生成代码检测基准",
    "abstract_zh": "大型语言模型（LLMs）在生成功能性源代码方面的能力日益增强，这引发了关于作者身份、责任归属以及安全性的担忧。尽管检测AI生成代码至关重要，但现有的数据集和基准测试范围有限，通常仅限于在分布内设置下的二元人类-机器分类任务。为弥补这一差距，我们提出了 $\\emph{AICD Bench}$——目前最全面的AI生成代码检测基准。该基准涵盖 $\\emph{200万条样本}$、$\\emph{77个模型}$，覆盖 $\\emph{11个模型家族}$ 以及 $\\emph{9种编程语言}$，包括近期的推理类模型。除了规模上的突破，AICD Bench 还引入了三项更贴近实际场景的检测任务：（i）在语言和领域分布偏移下的 $\\emph{鲁棒二元分类}$，（ii）$\\emph{模型家族溯源}$，按架构谱系对生成器进行分组识别，以及（iii）跨人类、机器、混合及对抗性代码的 $\\emph{细粒度人类-机器分类}$。对神经网络与传统检测器的广泛评估表明，当前方法在分布外情况以及面对混合或对抗性代码时的表现仍远未达到实际可用水平。我们公开发布 AICD Bench 作为一个 $\\emph{统一且具有挑战性的评估套件}$，以推动下一代鲁棒性AI生成代码检测技术的发展。相关数据与代码已开放获取，地址为 https://huggingface.co/AICD-bench。"
  },
  {
    "date": "2026-02-02",
    "title": "Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability",
    "authors": "Xiao Liang, Zhong-Zhi Li, Zhenghao Lin, Eric Hancheng Jiang, Hengyuan Zhang, Yelong Shen, Kai-Wei Chang, Ying Nian Wu, Yeyun Gong, Weizhu Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02477v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability. A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability, surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.",
    "title_zh": "训练大语言模型进行分而治之推理可提升测试时的可扩展性",
    "abstract_zh": "大型语言模型（LLMs）通过逐步的思维链（Chain-of-Thought, CoT）推理展现出强大的推理能力。然而，在模型能力的极限情况下，CoT往往显得不足，其严格的顺序性也限制了推理过程在测试阶段的可扩展性。一种潜在的替代方案是分而治之（Divide-and-Conquer, DAC）推理，它将复杂问题分解为多个子问题，从而更有效地探索解决方案。尽管前景可观，但我们的分析揭示了通用型后训练方法与DAC式推理之间存在根本性不匹配，这限制了模型充分发挥DAC潜力的能力。为弥合这一差距，并在最具挑战性的任务上充分释放LLM的推理潜能，我们提出了一种端到端的强化学习（Reinforcement Learning, RL）框架，以增强模型的DAC式推理能力。在每一步中，策略将问题分解为一组子问题，顺序求解这些子问题，并基于子问题的解来解决原始问题，其中分解与求解过程均被整合进强化学习训练中。在相当的训练条件下，我们的DAC式框架使模型具备更高的性能上限和更强的测试阶段可扩展性，在竞赛级基准测试中，其Pass@1指标比CoT高出8.6%，Pass@32指标高出6.3%。"
  },
  {
    "date": "2026-02-02",
    "title": "Certain Head, Uncertain Tail: Expert-Sample for Test-Time Scaling in Fine-Grained MoE",
    "authors": "Yuanteng Chen, Peisong Wang, Nanxin Zeng, Yuantian Shao, Gang Li, Jing Liu, Jian Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02443v1",
    "source": "arXiv",
    "abstract": "Test-time scaling improves LLM performance by generating multiple candidate solutions, yet token-level sampling requires temperature tuning that trades off diversity against stability. Fine-grained MoE, featuring hundreds of well-trained experts per layer and multi-expert activation per token, offers an unexplored alternative through its rich routing space. We empirically characterize fine-grained MoE routing and uncover an informative pattern: router scores exhibit a certain head of high-confidence experts followed by an uncertain tail of low-confidence candidates. While single-run greedy accuracy remains stable when fewer experts are activated, multi-sample pass@n degrades significantly-suggesting that the certain head governs core reasoning capability while the uncertain tail correlates with reasoning diversity. Motivated by these findings, we propose Expert-Sample, a training-free method that preserves high-confidence selections while injecting controlled stochasticity into the uncertain tail, enabling diverse generation without destabilizing outputs. Evaluated on multiple fine-grained MoE models across math, knowledge reasoning, and code tasks, Expert-Sample consistently improves pass@n and verification-based accuracy. On Qwen3-30B-A3B-Instruct evaluated on GPQA-Diamond with 32 parallel samples, pass@32 rises from 85.4% to 91.9%, and accuracy improves from 59.1% to 62.6% with Best-of-N verification.",
    "title_zh": "特定头，不确定尾：细粒度MoE中的测试时扩展专家样本",
    "abstract_zh": "测试时缩放通过生成多个候选解决方案来提升大语言模型的性能，然而在标记级别进行采样时，温度调节需要在多样性与稳定性之间权衡。细粒度的混合专家（MoE）架构，每层包含数百个训练良好的专家，并在每个标记上激活多个专家，其丰富的路由空间提供了一种尚未被充分探索的替代方案。我们通过实证研究刻画了细粒度MoE的路由行为，发现了一个具有信息量的规律：路由器得分呈现出一个高置信度专家的“头部”，随后是低置信度候选者的“尾部”。尽管在单次运行中，激活较少专家时的贪心准确率保持稳定，但多样本的pass@n性能却显著下降——这表明高置信度的“头部”主导了核心推理能力，而低置信度的“尾部”则与推理多样性相关。受此启发，我们提出了一种无需训练的方法——Expert-Sample：在保留高置信度选择的同时，向不确定的尾部注入可控的随机性，从而在不破坏输出稳定性的前提下实现多样化生成。在多个细粒度MoE模型上，针对数学、知识推理和代码生成任务的评估表明，Expert-Sample持续提升了pass@n和基于验证的准确率。以Qwen3-30B-A3B-Instruct模型在GPQA-Diamond数据集上进行32个并行样本测试为例，pass@32从85.4%提升至91.9%，在Best-of-N验证下准确率也从59.1%提升至62.6%。"
  },
  {
    "date": "2026-02-02",
    "title": "From Sycophancy to Sensemaking: Premise Governance for Human-AI Decision Making",
    "authors": "Raunak Jain, Mudita Khurana, John Stephens, Srinivas Dharmasanam, Shankar Venkataraman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02378v1",
    "source": "arXiv",
    "abstract": "As LLMs expand from assistance to decision support, a dangerous pattern emerges: fluent agreement without calibrated judgment. Low-friction assistants can become sycophantic, baking in implicit assumptions and pushing verification costs onto experts, while outcomes arrive too late to serve as reward signals. In deep-uncertainty decisions (where objectives are contested and reversals are costly), scaling fluent agreement amplifies poor commitments faster than it builds expertise. We argue reliable human-AI partnership requires a shift from answer generation to collaborative premise governance over a knowledge substrate, negotiating only what is decision-critical. A discrepancy-driven control loop operates over this substrate: detecting conflicts, localizing misalignment via typed discrepancies (teleological, epistemic, procedural), and triggering bounded negotiation through decision slices. Commitment gating blocks action on uncommitted load-bearing premises unless overridden under logged risk; value-gated challenge allocates probing under interaction cost. Trust then attaches to auditable premises and evidence standards, not conversational fluency. We illustrate with tutoring and propose falsifiable evaluation criteria.",
    "title_zh": "从阿谀奉承到意义建构：人机决策中的前提治理",
    "abstract_zh": "随着大语言模型（LLM）从辅助工具演变为决策支持系统，一种危险的模式逐渐显现：表面上流利的赞同，却缺乏经过校准的判断力。低摩擦的助手容易变得阿谀奉承，将隐含假设内嵌其中，并将验证成本转嫁给专家，而最终结果往往来得太晚，无法作为有效的反馈信号。在深层不确定性决策情境中（即目标存在争议、逆转成本高昂），单纯扩大流利的共识只会比积累专业知识更快地放大错误承诺。我们主张，实现可靠的“人-机协同”关系，必须从生成答案转向对知识基础的协作式前提治理，仅就决策关键部分进行协商。一种以差异驱动的控制循环在此基础上运行：识别冲突，通过类型化的差异（目的论、认识论、程序性）定位不一致之处，并通过“决策切片”触发有限范围的协商。承诺门控机制阻止在未达成共识的关键前提上采取行动，除非在记录风险的前提下被明确 override；价值门控挑战机制则根据交互成本分配探查资源。最终，信任应建立在可审计的前提与证据标准之上，而非对话的流畅性。我们以教学辅导为例进行说明，并提出可证伪的评估标准。"
  },
  {
    "date": "2026-02-02",
    "title": "Context Learning for Multi-Agent Discussion",
    "authors": "Xingyuan Hua, Sheng Yue, Xinyi Li, Yizhe Zhao, Jinrui Zhang, Ju Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02350v1",
    "source": "arXiv",
    "abstract": "Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency, LLMs fail to reach a coherent solution, due to the misalignment between their individual contexts.In this paper, we introduce a multi-LLM context learning method (M2CL) that learns a context generator for each agent, capable of dynamically generating context instructions per discussion round via automatic information organization and refinement. Specifically, inspired by our theoretical insights on the context instruction, M2CL train the generators to control context coherence and output discrepancies via a carefully crafted self-adaptive mechanism.It enables LLMs to avoid premature convergence on majority noise and progressively reach the correct consensus. We evaluate M2CL on challenging tasks, including academic reasoning, embodied tasks, and mobile control. The results show that the performance of M2CL significantly surpasses existing methods by 20%--50%, while enjoying favorable transferability and computational efficiency.",
    "title_zh": "多智能体讨论中的上下文学习",
    "abstract_zh": "多智能体讨论（Multi-Agent Discussion, MAD）最近受到越来越多的关注，其中多个大语言模型（LLM）实例通过结构化的讨论协作解决问题。然而，我们发现当前的MAD方法容易出现讨论不一致的问题，导致各LLM无法达成连贯一致的解决方案，其根本原因在于个体上下文之间的错位。本文提出一种多LLM上下文学习方法（M2CL），为每个智能体学习一个上下文生成器，能够通过自动的信息组织与优化，在每轮讨论中动态生成上下文指令。具体而言，基于我们对上下文指令的理论洞察，M2CL通过精心设计的自适应机制训练生成器，以控制上下文的一致性并减少输出差异。该机制使LLM能够避免过早陷入多数噪声，逐步达成正确共识。我们在具有挑战性的任务上对M2CL进行了评估，包括学术推理、具身任务和移动控制任务。实验结果表明，M2CL的性能显著优于现有方法，提升幅度达20%至50%，同时具备良好的可迁移性和计算效率。"
  },
  {
    "date": "2026-02-02",
    "title": "Building a Correct-by-Design Lakehouse. Data Contracts, Versioning, and Transactional Pipelines for Humans and Agents",
    "authors": "Weiming Sheng, Jinlang Wang, Manuel Barros, Aldrin Montana, Jacopo Tagliabue, Luca Bigon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02335v1",
    "source": "arXiv",
    "abstract": "Lakehouses are the default cloud platform for analytics and AI, but they become unsafe when untrusted actors concurrently operate on production data: upstream-downstream mismatches surface only at runtime, and multi-table pipelines can leak partial effects. Inspired by software engineering, we design Bauplan, a code-first lakehouse that aims to make (most) illegal states unrepresentable using familiar abstractions. Bauplan acts along three axes: typed table contracts to make pipeline boundaries checkable, Git-like data versioning for review and reproducibility, and transactional runs that guarantee pipeline-level atomicity. We report early results from a lightweight formal transaction model and discuss future work motivated by counterexamples.",
    "title_zh": "构建“设计即正确”的数据湖仓：面向人类与智能体的数据契约、版本控制与事务型数据流水线",
    "abstract_zh": "湖仓（Lakehouses）是分析和人工智能的默认云平台，但当不受信任的用户并发操作生产数据时，其安全性会受到威胁：上游-下游不一致问题仅在运行时显现，多表数据管道还可能泄露部分影响。受软件工程的启发，我们设计了 Bauplan——一种以代码为先的湖仓系统，旨在通过熟悉的抽象机制，使（大多数）非法状态无法表示。Bauplan 沿三个维度运作：使用类型化表合约，使数据管道边界可验证；采用类似 Git 的数据版本控制，支持审查与可复现性；以及事务性运行，确保数据管道级别的原子性。我们报告了基于轻量级形式化事务模型的初步结果，并讨论了由反例所启发的未来工作方向。"
  },
  {
    "date": "2026-02-02",
    "title": "Constrained Process Maps for Multi-Agent Generative AI Workflows",
    "authors": "Ananya Joshi, Michael Rudow",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02034v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single agent, making it difficult to observe or compare how models handle uncertainty and coordination across interconnected decision stages and with human oversight. We introduce a multi-agent system formalized as a finite-horizon Markov Decision Process (MDP) with a directed acyclic structure. Each agent corresponds to a specific role or decision stage (e.g., content, business, or legal review in a compliance workflow), with predefined transitions representing task escalation or completion. Epistemic uncertainty is quantified at the agent level using Monte Carlo estimation, while system-level uncertainty is captured by the MDP's termination in either an automated labeled state or a human-review state. We illustrate the approach through a case study in AI safety evaluation for self-harm detection, implemented as a multi-agent compliance system. Results demonstrate improvements over a single-agent baseline, including up to a 19\\% increase in accuracy, up to an 85x reduction in required human review, and, in some configurations, reduced processing time.",
    "title_zh": "多智能体生成式人工智能工作流的约束过程图",
    "abstract_zh": "基于大语言模型（LLM）的智能体正越来越多地应用于合规与尽职调查等受监管环境中，以执行复杂且多步骤的工作流程。然而，许多智能体架构主要依赖单一智能体的提示工程，难以观察或比较模型在相互关联的决策阶段中如何处理不确定性，以及在人类监督下的协作机制。为此，我们提出一种多智能体系统，形式化为具有有向无环结构的有限时域马尔可夫决策过程（MDP）。每个智能体对应一个特定角色或决策阶段（例如合规工作流中的内容、业务或法律审查），其预定义的转移规则表示任务的升级或完成。在智能体层面，通过蒙特卡洛估计量化认知不确定性；在系统层面，通过MDP终止于自动标注状态或人工审核状态来捕捉整体不确定性。我们通过一个关于自残检测的AI安全评估案例研究，展示了该方法的应用，将其实施为一个多智能体合规系统。实验结果表明，相较于单智能体基线，该方法在多个方面均有显著提升：准确率最高提升19%，所需人工审核量最多减少85倍，且在某些配置下处理时间也有所缩短。"
  },
  {
    "date": "2026-02-02",
    "title": "Logic-Guided Vector Fields for Constrained Generative Modeling",
    "authors": "Ali Baheri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02009v1",
    "source": "arXiv",
    "abstract": "Neuro-symbolic systems aim to combine the expressive structure of symbolic logic with the flexibility of neural learning; yet, generative models typically lack mechanisms to enforce declarative constraints at generation time. We propose Logic-Guided Vector Fields (LGVF), a neuro-symbolic framework that injects symbolic knowledge, specified as differentiable relaxations of logical constraints, into flow matching generative models. LGVF couples two complementary mechanisms: (1) a training-time logic loss that penalizes constraint violations along continuous flow trajectories, with weights that emphasize correctness near the target distribution; and (2) an inference-time adjustment that steers sampling using constraint gradients, acting as a lightweight, logic-informed correction to the learned dynamics. We evaluate LGVF on three constrained generation case studies spanning linear, nonlinear, and multi-region feasibility constraints. Across all settings, LGVF reduces constraint violations by 59-82% compared to standard flow matching and achieves the lowest violation rates in each case. In the linear and ring settings, LGVF also improves distributional fidelity as measured by MMD, while in the multi-obstacle setting, we observe a satisfaction-fidelity trade-off, with improved feasibility but increased MMD. Beyond quantitative gains, LGVF yields constraint-aware vector fields exhibiting emergent obstacle-avoidance behavior, routing samples around forbidden regions without explicit path planning.",
    "title_zh": "逻辑引导的向量场在约束生成建模中的应用",
    "abstract_zh": "神经符号系统旨在结合符号逻辑的表达性结构与神经网络学习的灵活性；然而，生成模型通常缺乏在生成过程中强制执行声明性约束的机制。我们提出了一种名为逻辑引导向量场（Logic-Guided Vector Fields, LGVF）的神经符号框架，该框架将符号知识以可微分的逻辑约束松弛形式注入流匹配生成模型中。LGVF结合了两种互补机制：（1）训练阶段的逻辑损失，通过在连续流轨迹上惩罚约束违反行为，并赋予接近目标分布区域更高的权重，以强调正确性；（2）推理阶段的调整机制，利用约束梯度引导采样过程，作为对学习到的动力学的轻量级、逻辑感知的修正。我们在三个涵盖线性、非线性以及多区域可行性约束的受限生成案例研究中评估了LGVF。在所有设置中，LGVF相较于标准流匹配方法将约束违反率降低了59%至82%，并在每种情况下均实现了最低的违反率。在线性与环形设置中，LGVF还通过MMD指标提升了分布保真度；而在多障碍物设置中，我们观察到可行性与保真度之间的权衡：可行性得到改善，但MMD有所增加。除了定量性能提升外，LGVF生成的向量场表现出对约束的感知能力，展现出自发的避障行为，能够在不依赖显式路径规划的情况下，引导样本绕开禁止区域。"
  },
  {
    "date": "2026-02-02",
    "title": "Position: The Need for Ultrafast Training",
    "authors": "Duc Hoang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02005v1",
    "source": "arXiv",
    "abstract": "Domain-specialized FPGAs have delivered unprecedented performance for low-latency inference across scientific and industrial workloads, yet nearly all existing accelerators assume static models trained offline, relegating learning and adaptation to slower CPUs or GPUs. This separation fundamentally limits systems that must operate in non-stationary, high-frequency environments, where model updates must occur at the timescale of the underlying physics. In this paper, I argue for a shift from inference-only accelerators to ultrafast on-chip learning, in which both inference and training execute directly within the FPGA fabric under deterministic, sub-microsecond latency constraints. Bringing learning into the same real-time datapath as inference would enable closed-loop systems that adapt as fast as the physical processes they control, with applications spanning quantum error correction, cryogenic qubit calibration, plasma and fusion control, accelerator tuning, and autonomous scientific experiments. Enabling such regimes requires rethinking algorithms, architectures, and toolflows jointly, but promises to transform FPGAs from static inference engines into real-time learning machines.",
    "title_zh": "职位：超快训练的必要性",
    "abstract_zh": "领域专用FPGA在科学与工业工作负载的低延迟推理方面已实现前所未有的性能，然而几乎所有现有的加速器都假设采用离线训练的静态模型，将学习与自适应任务交由速度较慢的CPU或GPU处理。这种分离从根本上限制了那些必须在非平稳、高频环境中运行的系统，因为在这些场景中，模型更新必须与底层物理过程的时间尺度保持一致。本文主张从仅支持推理的加速器转向超快片上学习，即在FPGA硬件内部，以确定性、亚微秒级的延迟约束下，直接并行执行推理与训练。将学习纳入与推理相同的实时数据路径，将使闭环系统能够以与所控制物理过程相同的速度进行自适应，其应用涵盖量子纠错、低温量子比特校准、等离子体与聚变控制、加速器调谐以及自主科学实验等多个领域。实现此类实时学习场景需要对算法、架构和工具链进行协同重构，但有望彻底改变FPGA的角色——从静态推理引擎转变为实时学习机器。"
  },
  {
    "date": "2026-02-02",
    "title": "Optimizing Tensor Train Decomposition in DNNs for RISC-V Architectures Using Design Space Exploration and Compiler Optimizations",
    "authors": "Theologos Anthimopoulos, Milad Kokhazadeh, Vasilios Kelefouras, Benjamin Himpel, Georgios Keramidas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01996v1",
    "source": "arXiv",
    "abstract": "Deep neural networks (DNNs) have become indispensable in many real-life applications like natural language processing, and autonomous systems. However, deploying DNNs on resource-constrained devices, e.g., in RISC-V platforms, remains challenging due to the high computational and memory demands of fully connected (FC) layers, which dominate resource consumption. Low-rank factorization (LRF) offers an effective approach to compressing FC layers, but the vast design space of LRF solutions involves complex trade-offs among FLOPs, memory size, inference time, and accuracy, making the LRF process complex and time-consuming. This paper introduces an end-to-end LRF design space exploration methodology and a specialized design tool for optimizing FC layers on RISC-V processors. Using Tensor Train Decomposition (TTD) offered by TensorFlow T3F library, the proposed work prunes the LRF design space by excluding first, inefficient decomposition shapes and second, solutions with poor inference performance on RISC-V architectures. Compiler optimizations are then applied to enhance custom T3F layer performance, minimizing inference time and boosting computational efficiency. On average, our TT-decomposed layers run 3x faster than IREE and 8x faster than Pluto on the same compressed model. This work provides an efficient solution for deploying DNNs on edge and embedded devices powered by RISC-V architectures.",
    "title_zh": "基于设计空间探索与编译器优化的RISC-V架构下DNN中张量列车分解的优化",
    "abstract_zh": "深度神经网络（DNNs）在自然语言处理、自主系统等众多实际应用中已成为不可或缺的技术。然而，由于全连接（FC）层对计算和内存资源的高需求，导致在资源受限的设备（如RISC-V平台）上部署DNN仍面临挑战。低秩分解（LRF）为压缩FC层提供了一种有效方法，但LRF方案的设计空间极为庞大，需在浮点运算量（FLOPs）、内存占用、推理时间和精度之间进行复杂的权衡，使得LRF过程既复杂又耗时。本文提出了一种端到端的LRF设计空间探索方法，并开发了一款专用于优化RISC-V处理器上FC层的定制化设计工具。通过TensorFlow T3F库提供的张量列车分解（TTD）技术，本文方法首先剔除了初始阶段效率低下的分解结构，其次排除了在RISC-V架构上推理性能较差的方案，从而有效缩小了设计空间。随后，通过编译器优化进一步提升自定义T3F层的性能，显著降低推理时间并提高计算效率。实验结果表明，与相同压缩模型下的IREE相比，我们的TT分解层平均提速3倍；与Pluto相比，提速达8倍。本研究为在基于RISC-V架构的边缘和嵌入式设备上高效部署DNN提供了切实可行的解决方案。"
  },
  {
    "date": "2026-02-02",
    "title": "Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning",
    "authors": "Xintian Shen, Jiawei Chen, Lihao Zheng, Hao Ma, Tao Wei, Kun Zhan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01983v1",
    "source": "arXiv",
    "abstract": "Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%$\\uparrow$ and +23.04%$\\uparrow$ on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.",
    "title_zh": "通过无训练经验重用实现从工具使用者到创造者的转变：多模态推理中的探索",
    "abstract_zh": "现有的工具集成推理（TIR）模型通过引入外部工具，有效拓展了大语言模型（LLM）的问答能力。然而，在现实场景中，存在大量开放性问题，固定工具往往难以满足任务需求。此外，由于缺乏自我优化机制，错误的工具输出可能误导LLM的推理过程。同时，现有工具的构建需要大量人工投入，严重限制了其应用范围。我们注意到，LLM的推理轨迹中蕴含着隐式的求解能力，因此提出UCT——一种无需训练的新颖框架，将智能体从工具使用者转变为工具创造者。该方法通过挖掘和提炼推理经验，将其转化为可复用的资源。这一机制使智能体不再局限于使用工具，而是能够在推理过程中自主创建和自我更新工具。我们还引入了一种记忆固化机制，用于维护工具库，确保保留的经验记忆在后续推理任务中具有高复用性。这种新型的自动化工具构建范式在推理过程中持续提升工具质量，使整个智能体系统在无需额外训练的情况下实现持续进化。大量实验表明，我们的方法为提升TIR模型能力提供了一种全新范式。特别是在多领域数学与科学推理任务的基准测试中，性能显著提升，分别达到+20.86%↑和+23.04%↑，充分验证了智能体的自我演化能力。"
  },
  {
    "date": "2026-02-02",
    "title": "S3-CoT: Self-Sampled Succinct Reasoning Enables Efficient Chain-of-Thought LLMs",
    "authors": "Yanrui Du, Sendong Zhao, Yibo Gao, Danyang Zhao, Qika Lin, Ming Ma, Jiayun Li, Yi Jiang, Kai He, Qianyi Xu, Bing Qin, Mengling Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01982v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) equipped with chain-of-thought (CoT) achieve strong performance and offer a window into LLM behavior. However, recent evidence suggests that improvements in CoT capabilities often come with redundant reasoning processes, motivating a key question: Can LLMs acquire a fast-thinking mode analogous to human System 1 reasoning? To explore this, our study presents a self-sampling framework based on activation steering for efficient CoT learning. Our method can induce style-aligned and variable-length reasoning traces from target LLMs themselves without any teacher guidance, thereby alleviating a central bottleneck of SFT-based methods-the scarcity of high-quality supervision data. Using filtered data by gold answers, we perform SFT for efficient CoT learning with (i) a human-like dual-cognitive system, and (ii) a progressive compression curriculum. Furthermore, we explore a self-evolution regime in which SFT is driven solely by prediction-consistent data of variable-length variants, eliminating the need for gold answers. Extensive experiments on math benchmarks, together with cross-domain generalization tests in medicine, show that our method yields stable improvements for both general and R1-style LLMs. Our data and model checkpoints can be found at https://github.com/DYR1/S3-CoT.",
    "title_zh": "S3-CoT：自采简洁推理实现高效链式思维大模型",
    "abstract_zh": "配备思维链（CoT）的大语言模型（LLMs）展现出强大的性能，并为理解LLM的行为提供了重要窗口。然而，近期研究表明，CoT能力的提升往往伴随着冗余的推理过程，这引发了一个关键问题：大语言模型能否像人类的系统1思维一样，具备一种快速思考的模式？为探索这一问题，本研究提出了一种基于激活调控的自采样框架，以实现高效CoT学习。我们的方法能够从目标LLM自身生成风格一致且长度可变的推理轨迹，无需任何教师指导，从而缓解基于监督微调（SFT）方法的核心瓶颈——高质量监督数据的稀缺性。通过使用基于黄金答案筛选的数据，我们实现了高效的CoT学习，具体包括：(i) 模拟人类双认知系统的架构，以及(ii) 逐步压缩的课程学习策略。此外，我们还探索了一种自进化机制，其中SFT仅由不同长度变体的预测一致性数据驱动，完全无需黄金答案。在数学基准上的大量实验，以及在医学等跨领域任务中的泛化测试表明，我们的方法对通用型和R1风格的LLM均能带来稳定且显著的性能提升。相关数据与模型检查点可于 https://github.com/DYR1/S3-CoT 获取。"
  },
  {
    "date": "2026-02-02",
    "title": "S1-NexusAgent: a Self-Evolving Agent Framework for Multidisciplinary Scientific Research",
    "authors": "S1-NexusAgent Team",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01550v1",
    "source": "arXiv",
    "abstract": "Modern scientific research relies on large-scale data, complex workflows, and specialized tools, which existing LLMs and tool-based agents struggle to handle due to limitations in long-horizon planning, robust goal maintenance, and continual learning from execution. To address these issues, in this work, we propose S1-NexusAgent, a self-evolving agent framework designed for multidisciplinary scientific research. S1-NexusAgent adopts a hierarchical Plan-and-CodeAct execution paradigm, decoupling global scientific planning from subtask-level tool execution through a dual-loop architecture, thereby enabling stable modeling of complex research workflows. The system natively supports the Model Context Protocol (MCP), integrates up to thousands of cross-disciplinary scientific tools, and achieves efficient orchestration of heterogeneous research tools via intention-aware dynamic tool retrieval and hot-plug mechanisms. To address long-context and large-scale data challenges in scientific settings, S1-NexusAgent introduces object-reference-based sparse context management, which enables sub-task context isolation and intermediate result compression. Building on this, a Critic Agent automatically evaluates complete execution trajectories and distills high-quality research paths into reusable Scientific Skills, forming a closed loop for continuous self-evolution, which is valuable for sustainable and long-horizon scientific research. Experiments on authoritative scientific benchmarks involving long-horizon planning and complex specialized tool orchestration, including biomini-eval (biology), ChemBench (chemistry), and MatSciBench (material science), demonstrate that S1-NexusAgent achieves state-of-the-art performance, validating its effectiveness and generalization capability in complex scientific tasks.",
    "title_zh": "S1-NexusAgent：一种用于多学科科学研究的自演化智能体框架",
    "abstract_zh": "现代科学研究依赖于大规模数据、复杂的流程以及专业化的工具，而现有的大语言模型（LLM）和基于工具的智能体在处理这些任务时面临诸多挑战，主要受限于长周期规划能力不足、目标维持的鲁棒性差，以及从执行过程中持续学习的能力有限。为解决上述问题，本文提出S1-NexusAgent——一个专为多学科科学研究所设计的自演化智能体框架。S1-NexusAgent采用分层的“规划-编码执行”（Plan-and-CodeAct）范式，通过双环架构将全局科研规划与子任务级别的工具执行解耦，从而实现对复杂科研流程的稳定建模。该系统原生支持模型上下文协议（Model Context Protocol, MCP），可集成多达数千个跨学科科学工具，并借助意图感知的动态工具检索与热插拔机制，高效协调异构研究工具。\n\n为应对科学场景中常见的长上下文与大规模数据处理难题，S1-NexusAgent引入基于对象引用的稀疏上下文管理机制，实现子任务间上下文隔离与中间结果压缩。在此基础上，Critic智能体能够自动评估完整的执行轨迹，并将高质量的研究路径提炼为可复用的“科学技能”，形成闭环式的持续自我演化机制，为可持续的长期科研任务提供有力支持。在涵盖长周期规划与复杂专业工具编排的权威科学基准测试中，包括生物领域的biomini-eval、化学领域的ChemBench，以及材料科学领域的MatSciBench，实验结果表明，S1-NexusAgent达到了当前最先进的性能水平，充分验证了其在复杂科学任务中的有效性与泛化能力。"
  },
  {
    "date": "2026-02-02",
    "title": "Grad2Reward: From Sparse Judgment to Dense Rewards for Improving Open-Ended LLM Reasoning",
    "authors": "Zheng Zhang, Ao Lu, Yuanhao Zeng, Ziwei Shan, Jinjin Guo, Lufei Li, Yexin Li, Kan Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01791v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has catalyzed significant breakthroughs in complex LLM reasoning within verifiable domains, such as mathematics and programming. Recent efforts have sought to extend this paradigm to open-ended tasks by employing LLMs-as-a-Judge to provide sequence-level rewards for policy optimization. However, these rewards are inherently sparse, failing to provide the fine-grained supervision necessary for generating complex, long-form trajectories. Furthermore, current work treats the Judge as a black-box oracle, discarding the rich intermediate feedback signals encoded in it. To address these limitations, we introduce Grad2Reward, a novel framework that extracts dense process rewards directly from the Judge's model inference process via a single backward pass. By leveraging gradient-based attribution, Grad2Reward enables precise token-level credit assignment, substantially enhancing training efficiency and reasoning quality. Additionally, Grad2Reward introduces a self-judging mechanism, allowing the policy to improve through its own evaluative signals without training specialized reward models or reliance on superior external Judges. The experiments demonstrate that policies optimized with Grad2Reward achieve outstanding performance across diverse open-ended tasks, affirming its effectiveness and broad generalizability.",
    "title_zh": "Grad2Reward：从稀疏判断到密集奖励，以提升开放式大语言模型的推理能力",
    "abstract_zh": "基于可验证奖励的强化学习（RLVR）在数学和编程等可验证领域中，推动了复杂大语言模型（LLM）推理的重大突破。近期研究尝试将这一范式扩展至开放性任务，通过使用“大模型作为裁判”（LLM-as-a-Judge）为策略优化提供序列级奖励。然而，这类奖励本质上稀疏，无法提供生成复杂、长序列轨迹所必需的细粒度监督。此外，现有方法将裁判模型视为黑箱，忽略了其中蕴含的丰富中间反馈信号。为解决上述局限，我们提出一种新框架——Grad2Reward，该框架通过一次反向传播，直接从裁判模型的推理过程中提取密集的过程奖励。借助基于梯度的归因方法，Grad2Reward实现了精确的 token 级信用分配，显著提升了训练效率与推理质量。此外，Grad2Reward引入了自裁判机制，使策略能够基于自身生成的评估信号进行改进，无需训练专用的奖励模型，也无需依赖更强大的外部裁判。实验结果表明，采用 Grad2Reward 优化的策略在多种开放性任务中均表现出色，充分验证了其有效性与广泛的泛化能力。"
  },
  {
    "date": "2026-02-02",
    "title": "<SOG_k>: One LLM Token for Explicit Graph Structural Understanding",
    "authors": "Jingyao Wu, Bin Lu, Zijun Di, Xiaoying Gan, Meng Jin, Luoyi Fu, Xinbing Wang, Chenghu Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01771v1",
    "source": "arXiv",
    "abstract": "Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token <SOG_k> to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, <SOG_k> empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at https://github.com/Jingyao-Wu/SOG.",
    "title_zh": "一种用于显式图结构理解的LLM令牌",
    "abstract_zh": "大型语言模型在非结构化数据理解方面展现出巨大潜力，但在处理图数据时仍面临结构幻觉等重大挑战。现有方法主要分为两类：一类是将图结构转化为自然语言，但这会导致令牌消耗过多且注意力分散；另一类是将图转化为可训练的连续嵌入（即软提示），但其与原始文本令牌之间存在严重错位。为解决这一问题，我们提出引入一个特殊令牌 <SOG_k>，在统一的令牌空间中完整表示图的结构（Structure Of Graph），从而实现显式的拓扑信息输入与结构信息共享。具体而言，我们设计了一种拓扑感知的结构分词器，将每种图拓扑映射为一个高度选择性的单一令牌。随后，我们构建了一组混合结构的问答语料库，以对齐新引入的结构令牌与现有文本令牌。通过该方法，<SOG_k> 使大语言模型能够以简洁而准确的方式理解、生成和推理图结构信息。在五个图级别基准上的大量实验表明，我们的方法显著优于基线模型，性能提升达 9.9% 至 41.4%，同时具备良好的可解释性与一致性。此外，该方法还可灵活扩展至节点级别任务，实现全局与局部结构理解的统一。代码库已公开，地址为：https://github.com/Jingyao-Wu/SOG。"
  },
  {
    "date": "2026-02-02",
    "title": "Phoenix: A Modular and Versatile Framework for C/C++ Pointer Analysis",
    "authors": "Peisen Yao, Zinan Gu, Qingkai Shi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01720v1",
    "source": "arXiv",
    "abstract": "We present Phoenix, a modular pointer analysis framework for C/C++ that unifies multiple state-of-the-art alias analysis algorithms behind a single, stable interface. Phoenix addresses the fragmentation of today's C/C++ pointer analysis ecosystem by cleanly separating IR construction, constraint generation, solver backends, and client-facing queries, making analyses easy to compare, swap, and compose while exposing explicit precision-performance trade-offs. We evaluate Phoenix against SVF under two representative configurations: a flow- and context-insensitive setting and a more precise flow- and context-sensitive setting, on 28 GNU coreutils programs. Phoenix delivers robust speedups in the baseline configuration (up to 2.88x) and remains competitive, and often faster, even in the stronger precision regime (up to 2.91x), without a systematic runtime penalty. In production, Phoenix serves as the analysis substrate for static analysis and fuzzing tools that have uncovered hundreds of new bugs and enabled deployments reporting more than 1000 bugs found in an industrial toolchain.",
    "title_zh": "Phoenix：一种模块化且通用的C/C++指针分析框架",
    "abstract_zh": "我们提出了Phoenix，这是一个针对C/C++的模块化指针分析框架，它通过单一且稳定的接口统一了多种前沿的别名分析算法。Phoenix通过清晰地分离中间表示（IR）构建、约束生成、求解器后端以及面向客户端的查询，解决了当前C/C++指针分析生态系统的碎片化问题，使得不同分析方法的比较、替换和组合变得简单，并明确揭示了精度与性能之间的权衡。我们在28个GNU coreutils程序上，针对两种典型配置对Phoenix与SVF进行了评估：一种是不考虑流和上下文的配置，另一种是更精确的流敏感和上下文敏感配置。在基础配置下，Phoenix实现了稳定的加速（最高达2.88倍），即使在更高精度的配置下，其表现依然具有竞争力，甚至常常更快（最高达2.91倍），且未出现系统性的运行时开销。在实际生产环境中，Phoenix已成为静态分析和模糊测试工具的分析基础，成功发现了数百个新漏洞，并支持的部署报告在工业级工具链中发现了超过1000个漏洞。"
  },
  {
    "date": "2026-02-02",
    "title": "ARTIS: Agentic Risk-Aware Test-Time Scaling via Iterative Simulation",
    "authors": "Xingshan Zeng, Lingzhi Wang, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01709v1",
    "source": "arXiv",
    "abstract": "Current test-time scaling (TTS) techniques enhance large language model (LLM) performance by allocating additional computation at inference time, yet they remain insufficient for agentic settings, where actions directly interact with external environments and their effects can be irreversible and costly. We propose \\emph{\\name}, \\emph{\\underline{A}gentic \\underline{R}isk-Aware \\underline{T}est-Time Scaling via \\underline{I}terative \\underline{S}imulation}, a framework that decouples exploration from commitment by enabling test-time exploration through simulated interactions prior to real-world execution. This design allows extending inference-time computation to improve action-level reliability and robustness without incurring environmental risk. We further show that naive LLM-based simulators struggle to capture rare but high-impact failure modes, substantially limiting their effectiveness for agentic decision making. To address this limitation, we introduce a \\emph{risk-aware tool simulator} that emphasizes fidelity on failure-inducing actions via targeted data generation and rebalanced training. Experiments on multi-turn and multi-step agentic benchmarks demonstrate that iterative simulation substantially improves agent reliability, and that risk-aware simulation is essential for consistently realizing these gains across models and tasks.",
    "title_zh": "ARTIS：通过迭代模拟实现的代理风险感知测试时扩展",
    "abstract_zh": "当前的测试时缩放（Test-Time Scaling, TTS）技术通过在推理阶段分配额外计算来提升大语言模型（LLM）的性能，但在代理（agentic）场景中仍显不足。这类场景中，代理的动作会直接与外部环境交互，其后果可能不可逆且代价高昂。为此，我们提出了 \\emph{\\name}，即 \\emph{\\underline{A}gentic \\underline{R}isk-Aware \\underline{T}est-Time Scaling via \\underline{I}terative \\underline{S}imulation}（基于迭代仿真的代理风险感知测试时缩放），该框架通过在真实执行前利用模拟交互进行测试时探索，将探索过程与实际承诺解耦。这一设计使得我们能够在不承担环境风险的前提下，通过延长推理阶段的计算来提升动作层面的可靠性与鲁棒性。\n\n我们进一步发现，直接基于LLM构建的模拟器难以捕捉那些罕见但影响重大的失败模式，这严重限制了其在代理决策中的有效性。为解决这一问题，我们引入了一种**风险感知工具模拟器**，通过有针对性的数据生成和再平衡训练，重点提升对引发失败动作的模拟保真度。在多轮、多步骤代理基准任务上的实验表明，迭代仿真显著提升了代理的可靠性，而风险感知的仿真对于在不同模型和任务间持续实现这些性能提升至关重要。"
  },
  {
    "date": "2026-02-02",
    "title": "LLM-based Embeddings: Attention Values Encode Sentence Semantics Better Than Hidden States",
    "authors": "Yeqin Zhang, Yunfei Wang, Jiaxuan Chen, Ke Qin, Yizheng Zhao, Cam-Tu Nguyen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01572v1",
    "source": "arXiv",
    "abstract": "Sentence representations are foundational to many Natural Language Processing (NLP) applications. While recent methods leverage Large Language Models (LLMs) to derive sentence representations, most rely on final-layer hidden states, which are optimized for next-token prediction and thus often fail to capture global, sentence-level semantics. This paper introduces a novel perspective, demonstrating that attention value vectors capture sentence semantics more effectively than hidden states. We propose Value Aggregation (VA), a simple method that pools token values across multiple layers and token indices. In a training-free setting, VA outperforms other LLM-based embeddings, even matches or surpasses the ensemble-based MetaEOL. Furthermore, we demonstrate that when paired with suitable prompts, the layer attention outputs can be interpreted as aligned weighted value vectors. Specifically, the attention scores of the last token function as the weights, while the output projection matrix ($W_O$) aligns these weighted value vectors with the common space of the LLM residual stream. This refined method, termed Aligned Weighted VA (AlignedWVA), achieves state-of-the-art performance among training-free LLM-based embeddings, outperforming the high-cost MetaEOL by a substantial margin. Finally, we highlight the potential of obtaining strong LLM embedding models through fine-tuning Value Aggregation.",
    "title_zh": "基于大语言模型的嵌入：注意力值比隐藏状态更能有效编码句子语义",
    "abstract_zh": "句子表示是许多自然语言处理（NLP）应用的基础。尽管近期的方法利用大语言模型（LLM）来生成句子表示，但大多数方法依赖于最后一层的隐藏状态，而这些状态是为预测下一个词而优化的，因此往往难以捕捉全局的、句子级别的语义。本文提出了一种新视角，证明注意力值向量比隐藏状态更能有效捕捉句子语义。我们提出了值聚合（Value Aggregation, VA）方法，该方法通过在多个层和词元位置上对 token 值进行池化，实现简单高效的句子表示。在无需训练的设置下，VA 的表现优于其他基于 LLM 的嵌入方法，甚至可与基于集成的 MetaEOL 相媲美或超越。此外，我们证明，当搭配合适的提示（prompt）时，层级注意力输出可被解释为对齐的加权值向量：最后一个词元的注意力分数充当权重，而输出投影矩阵（$W_O$）则将这些加权值向量对齐至 LLM 残差流的公共空间。这一改进方法被称为对齐加权 VA（Aligned Weighted VA, AlignedWVA），在无需训练的 LLM 嵌入方法中达到了当前最优性能，显著超越了成本高昂的 MetaEOL。最后，我们展示了通过微调值聚合方法，有望获得性能强大的 LLM 嵌入模型。"
  },
  {
    "date": "2026-02-02",
    "title": "Reasoning in a Combinatorial and Constrained World: Benchmarking LLMs on Natural-Language Combinatorial Optimization",
    "authors": "Xia Jiang, Jing Chen, Cong Zhang, Jie Gao, Chengpeng Hu, Chenhao Zhang, Yaoxin Wu, Yingqian Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02188v1",
    "source": "arXiv",
    "abstract": "While large language models (LLMs) have shown strong performance in math and logic reasoning, their ability to handle combinatorial optimization (CO) -- searching high-dimensional solution spaces under hard constraints -- remains underexplored. To bridge the gap, we introduce NLCO, a \\textbf{N}atural \\textbf{L}anguage \\textbf{C}ombinatorial \\textbf{O}ptimization benchmark that evaluates LLMs on end-to-end CO reasoning: given a language-described decision-making scenario, the model must output a discrete solution without writing code or calling external solvers. NLCO covers 43 CO problems and is organized using a four-layer taxonomy of variable types, constraint families, global patterns, and objective classes, enabling fine-grained evaluation. We provide solver-annotated solutions and comprehensively evaluate LLMs by feasibility, solution optimality, and reasoning efficiency. Experiments across a wide range of modern LLMs show that high-performing models achieve strong feasibility and solution quality on small instances, but both degrade as instance size grows, even if more tokens are used for reasoning. We also observe systematic effects across the taxonomy: set-based tasks are relatively easy, whereas graph-structured problems and bottleneck objectives lead to more frequent failures.",
    "title_zh": "在组合与约束世界中的推理：基于自然语言组合优化的大型语言模型基准测试",
    "abstract_zh": "尽管大型语言模型（LLMs）在数学和逻辑推理方面表现出色，但其在组合优化（CO）——即在硬性约束条件下搜索高维解空间——方面的处理能力仍鲜有研究。为填补这一空白，我们提出了NLCO，一个**自然语言组合优化**基准，用于评估LLMs在端到端组合优化推理方面的能力：给定一个以自然语言描述的决策场景，模型需直接输出离散解，而无需编写代码或调用外部求解器。NLCO涵盖43个组合优化问题，并采用四层分类体系进行组织，包括变量类型、约束族、全局模式和目标类别，从而实现细粒度的评估。我们提供了带求解器标注的解，并从可行性、解的最优性以及推理效率三个方面对LLMs进行了全面评估。在多种现代LLM上的实验表明，高性能模型在小规模实例上表现出较强的可行性和解的质量，但随着实例规模增大，这两项指标均显著下降，即使增加推理时使用的上下文长度也难以改善。此外，我们在分类体系中观察到系统性规律：基于集合的任务相对容易，而图结构问题和瓶颈型目标则更容易导致失败。"
  },
  {
    "date": "2026-02-02",
    "title": "D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use",
    "authors": "Bowen Xu, Shaoyu Wu, Hao Jiang, Kai Liu, Xin Chen, Lulu Hu, Bin Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02160v1",
    "source": "arXiv",
    "abstract": "Effective tool use and reasoning are essential capabilities for large reasoning models~(LRMs) to address complex real-world problems. Through empirical analysis, we identify that current LRMs lack the capability of sub-task decomposition in complex tool use scenarios, leading to Lazy Reasoning. To address this, we propose a two-stage training framework D-CORE~(\\underline{\\textbf{D}}ecomposing tasks and \\underline{\\textbf{Co}}mposing \\underline{\\textbf{Re}}asoning processes) that first incentivize the LRMs' task decomposition reasoning capability via self-distillation, followed by diversity-aware reinforcement learning~(RL) to restore LRMs' reflective reasoning capability. D-CORE achieves robust tool-use improvements across diverse benchmarks and model scales. Experiments on BFCLv3 demonstrate superiority of our method: D-CORE-8B reaches 77.7\\% accuracy, surpassing the best-performing 8B model by 5.7\\%. Meanwhile, D-CORE-14B establishes a new state-of-the-art at 79.3\\%, outperforming 70B models despite being 5$\\times$ smaller. The source code is available at https://github.com/alibaba/EfficientAI.",
    "title_zh": "D-CORE：激励大型推理模型在复杂工具使用中进行任务分解",
    "abstract_zh": "高效工具使用与推理能力是大型推理模型（LRMs）应对复杂现实问题所必需的核心能力。通过实证分析，我们发现当前的LRMs在复杂工具使用场景中缺乏子任务分解能力，导致出现“懒惰推理”（Lazy Reasoning）现象。为解决这一问题，我们提出了一种两阶段训练框架D-CORE（\\underline{\\textbf{D}}ecomposing tasks and \\underline{\\textbf{Co}}mposing \\underline{\\textbf{Re}}asoning processes）：首先通过自蒸馏（self-distillation）激励LRMs的任务分解推理能力，随后采用面向多样性的强化学习（RL）恢复其反思性推理能力。D-CORE在多种基准测试和不同模型规模下均实现了稳健的工具使用性能提升。在BFCLv3上的实验表明，我们的方法具有显著优势：D-CORE-8B达到77.7%的准确率，比表现最佳的8B模型高出5.7%；而D-CORE-14B更是以79.3%的准确率创下新纪录，尽管其规模仅为70B模型的五分之一。相关源代码已开源，地址为：https://github.com/alibaba/EfficientAI。"
  },
  {
    "date": "2026-02-02",
    "title": "CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems",
    "authors": "Lyu Zongyi, Ji Zhenlan, Chen Songqiang, Wang Liwen, Huang Yuheng, Wang Shuai, Cheung Shing-Chi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02138v1",
    "source": "arXiv",
    "abstract": "Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these intermediate outputs to the system correctness remains opaque, which impedes targeted optimization of MACGS designs. To address this challenge, we propose CAM, the first \\textbf{C}ausality-based \\textbf{A}nalysis framework for \\textbf{M}ACGS that systematically quantifies the contribution of different intermediate features for system correctness. By comprehensively categorizing intermediate outputs and systematically simulating realistic errors on intermediate features, we identify the important features for system correctness and aggregate their importance rankings. We conduct extensive empirical analysis on the identified importance rankings. Our analysis reveals intriguing findings: first, we uncover context-dependent features\\textemdash features whose importance emerges mainly through interactions with other features, revealing that quality assurance for MACGS should incorporate cross-feature consistency checks; second, we reveal that hybrid backend MACGS with different backend LLMs assigned according to their relative strength achieves up to 7.2\\% Pass@1 improvement, underscoring hybrid architectures as a promising direction for future MACGS design. We further demonstrate CAM's practical utility through two applications: (1) failure repair which achieves a 73.3\\% success rate by optimizing top-3 importance-ranked features and (2) feature pruning that reduces up to 66.8\\% intermediate token consumption while maintaining generation performance. Our work provides actionable insights for MACGS design and deployment, establishing causality analysis as a powerful approach for understanding and improving MACGS.",
    "title_zh": "CAM：一种基于因果关系的多智能体代码生成系统分析框架",
    "abstract_zh": "尽管多智能体代码生成系统（MACGS）取得了显著成功，但其固有的多智能体架构带来了大量中间输出，而这些中间输出对系统正确性的影响至今仍不明确，这严重阻碍了对MACGS设计的针对性优化。为应对这一挑战，我们提出了CAM——首个基于因果关系的多智能体代码生成系统分析框架（Causality-based Analysis framework for MACGS），该框架系统地量化了不同中间特征对系统正确性的贡献。通过全面分类中间输出，并系统性地模拟中间特征中的真实错误，我们识别出对系统正确性至关重要的特征，并对其重要性进行排序与聚合。我们对所识别的重要性排序进行了广泛的实证分析，揭示了若干引人深思的发现：首先，我们发现了情境依赖型特征——这些特征的重要性主要通过与其他特征的交互才得以显现，这表明MACGS的质量保障应引入跨特征一致性检查；其次，我们发现根据各后端大语言模型（LLM）相对能力分配不同后端的混合型MACGS架构，可实现最高达7.2%的Pass@1性能提升，凸显了混合架构在未来MACGS设计中的巨大潜力。此外，我们通过两个实际应用进一步验证了CAM的实用性：（1）故障修复——通过优化重要性排名前3的特征，成功率达到73.3%；（2）特征剪枝——在保持生成性能的同时，最多可减少66.8%的中间token消耗。我们的工作为MACGS的设计与部署提供了切实可行的洞见，确立了因果分析作为理解与提升MACGS性能的强大方法。"
  },
  {
    "date": "2026-02-02",
    "title": "Closing the Loop: Universal Repository Representation with RPG-Encoder",
    "authors": "Jane Luo, Chengyu Yin, Xin Zhang, Qingtao Li, Steven Liu, Yiming Huang, Jie Wu, Hao Liu, Yangyu Huang, Yu Kang, Fangkai Yang, Ying Xin, Scarlett Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02084v1",
    "source": "arXiv",
    "abstract": "Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.",
    "title_zh": "闭环闭合：基于RPG-编码器的通用存储库表示",
    "abstract_zh": "当前的仓库代理因表示碎片化而面临推理断层问题，现有方法依赖孤立的API文档或依赖图，缺乏语义深度。我们认为仓库理解与生成是统一循环中的互逆过程：生成将意图扩展为实现，而理解则将实现压缩回意图。为此，我们提出RPG-Encoder框架，将仓库规划图（RPG）从静态生成蓝图推广为统一的、高保真的表示形式。RPG-Encoder通过三种机制实现推理闭环：（1）将原始代码编码为融合了提升语义特征与代码依赖关系的RPG；（2）逐步演化图结构拓扑，实现维护成本与仓库规模的解耦，将开销降低95.7%；（3）作为结构感知导航的统一接口。在评估中，RPG-Encoder在SWE-bench Verified上达到93.7%的Acc@5，创下当前最佳性能，并在SWE-bench Live Lite上超越最优基线超过10%。这些结果凸显了我们在复杂代码库中卓越的细粒度定位精度。此外，其在RepoCraft上实现了98.5%的重构覆盖率，证实了RPG在高保真还原原始代码库方面的强大能力，成功实现了意图与实现之间的闭环。"
  },
  {
    "date": "2026-02-02",
    "title": "Generative Visual Code Mobile World Models",
    "authors": "Woosung Koh, Sungjun Han, Segyu Lee, Se-Young Yun, Jamin Shin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.01576v1",
    "source": "arXiv",
    "abstract": "Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation, where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework (gWorld) that automatically synthesizes code-based training data. In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance.",
    "title_zh": "生成式视觉代码移动世界模型",
    "abstract_zh": "移动图形用户界面（GUI）世界模型（WMs）为提升移动GUI智能体在训练和推理阶段的性能提供了一条极具前景的路径。然而，现有方法面临一个关键权衡：基于文本的世界模型牺牲了视觉保真度，而视觉世界模型在精确文本渲染方面的不足，导致其依赖于复杂且低效的外部模型集成管道。我们提出一种新范式：通过可渲染代码生成实现视觉世界建模，即单一视觉-语言模型（VLM）将下一GUI状态预测为可执行的网页代码，该代码可直接渲染为像素，而非直接生成像素。这一方法融合了两种路径的优势：VLM保留其语言先验以实现精确的文本渲染，同时其在结构化网页代码上的预训练使其具备高保真度的视觉生成能力。我们提出了gWorld（8B、32B），首个基于该范式的开源权重移动GUI视觉世界模型，并配套开发了gWorld数据生成框架，可自动合成基于代码的训练数据。在4个分布内和2个分布外基准上的广泛评估表明，gWorld在准确率与模型规模之间树立了新的帕累托前沿，其性能超越了50.25倍更大的8个前沿开源模型。进一步分析显示：（1）通过gWorld扩展训练数据可带来显著性能提升；（2）我们流水线中的每个组件均有效提升了数据质量；（3）更强的世界建模能力显著改善了下游移动GUI策略的表现。"
  },
  {
    "date": "2026-02-02",
    "title": "AgentRx: Diagnosing AI Agent Failures from Execution Trajectories",
    "authors": "Shraddha Barke, Arnav Goyal, Alind Khare, Avaljot Singh, Suman Nath, Chetan Bansal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02475v1",
    "source": "arXiv",
    "abstract": "AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with a critical failure step and a category from a grounded-theory derived, cross-domain failure taxonomy. To mitigate the human cost of failure attribution, we present AGENTRX, an automated domain-agnostic diagnostic framework that pinpoints the critical failure step in a failed agent trajectory. It synthesizes constraints, evaluates them step-by-step, and produces an auditable validation log of constraint violations with associated evidence; an LLM-based judge uses this log to localize the critical step and category. Our framework improves step localization and failure attribution over existing baselines across three domains.",
    "title_zh": "AgentRx：从执行轨迹中诊断AI代理故障",
    "abstract_zh": "AI代理在执行过程中常常以难以定位的方式失败，原因在于其执行过程具有概率性、长时程性、多智能体协作特性，并且受到噪声工具输出的干扰。为弥补这一缺陷，我们手动标注了多个失败的代理运行实例，并发布了一个全新的基准数据集，包含115条失败轨迹，覆盖结构化API工作流、事件管理以及开放式网页/文件操作任务。每条轨迹均被标注了关键失败步骤，以及基于扎根理论构建的跨领域失败分类体系中的具体类别。为降低人工进行故障归因的成本，我们提出了AGENTRX——一种自动化的、领域无关的诊断框架，能够精准定位失败代理轨迹中的关键失败步骤。该框架通过合成约束条件，逐步评估并生成可审计的验证日志，记录违反约束的情况及其相关证据；随后，一个基于大语言模型（LLM）的评判器利用此日志来确定关键失败步骤及其所属类别。实验结果表明，与现有基线方法相比，我们的框架在三个不同领域中均显著提升了步骤定位精度和故障归因能力。"
  },
  {
    "date": "2026-02-02",
    "title": "Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction",
    "authors": "Han Bao, Zheyuan Zhang, Pengcheng Jing, Zhengqing Yuan, Kaiwen Shi, Yanfang Ye",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02455v1",
    "source": "arXiv",
    "abstract": "As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \\textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \\textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \\textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \\MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.",
    "title_zh": "Drift-Bench：通过多轮交互诊断在输入故障下大语言模型智能体的协作失效问题",
    "abstract_zh": "随着大型语言模型向自主智能体的演进，用户输入常常违背合作性假设（例如隐含意图、参数缺失、错误预设或表达模糊），从而引发执行风险，而这些风险在仅基于文本的评估中无法被捕捉。现有的评估基准通常假设指令是明确指定的，或仅将评估限制在文本形式、单轮澄清的场景，因此无法衡量在存在实际执行风险的情况下，多轮澄清机制的有效性。为此，我们提出了 \\textbf{Drift-Bench}，这是首个通过在以状态为导向和服务导向的执行环境中进行多轮澄清，诊断输入故障下智能体语用能力的基准测试。基于经典的沟通理论，\\textbf{Drift-Bench} 构建了一个统一的协作失效分类体系，并采用基于角色的用户模拟器与 \\textbf{Rise} 评估协议。实验结果表明，在各类故障下模型性能显著下降，且澄清效果因用户角色和故障类型而异。\\MethodName 将澄清研究与智能体安全评估相连接，能够系统性地诊断可能导致不安全执行的失败原因。"
  },
  {
    "date": "2026-02-02",
    "title": "Maximizing Reliability with Bayesian Optimization",
    "authors": "Jack M. Buckingham, Ivo Couckuyt, Juergen Branke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02432v1",
    "source": "arXiv",
    "abstract": "Bayesian optimization (BO) is a popular, sample-efficient technique for expensive, black-box optimization. One such problem arising in manufacturing is that of maximizing the reliability, or equivalently minimizing the probability of a failure, of a design which is subject to random perturbations - a problem that can involve extremely rare failures ($P_\\mathrm{fail} = 10^{-6}-10^{-8}$). In this work, we propose two BO methods based on Thompson sampling and knowledge gradient, the latter approximating the one-step Bayes-optimal policy for minimizing the logarithm of the failure probability. Both methods incorporate importance sampling to target extremely small failure probabilities. Empirical results show the proposed methods outperform existing methods in both extreme and non-extreme regimes.",
    "title_zh": "利用贝叶斯优化最大化可靠性",
    "abstract_zh": "贝叶斯优化（BO）是一种在昂贵的黑箱优化问题中广泛应用且样本效率较高的技术。在制造领域中，一个典型的问题是：在存在随机扰动的情况下，最大化设计的可靠性，或等价地最小化故障发生的概率——这类问题可能涉及极低概率的故障（$P_\\mathrm{fail} = 10^{-6}-10^{-8}$）。本文提出两种基于汤普森采样（Thompson Sampling）和知识梯度（Knowledge Gradient）的贝叶斯优化方法，其中后者近似于最小化故障概率对数的一步贝叶斯最优策略。两种方法均引入重要性采样技术，以有效处理极小故障概率的场景。实验结果表明，所提出的方法在极端和非极端情形下均显著优于现有方法。"
  },
  {
    "date": "2026-02-02",
    "title": "Embedding Perturbation may Better Reflect the Uncertainty in LLM Reasoning",
    "authors": "Qihao Wen, Jiahao Wang, Yang Nan, Pengfei He, Ravi Tandon, Han Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02427v1",
    "source": "arXiv",
    "abstract": "Large language Models (LLMs) have achieved significant breakthroughs across diverse domains; however, they can still produce unreliable or misleading outputs. For responsible LLM application, Uncertainty Quantification (UQ) techniques are used to estimate a model's uncertainty about its outputs, indicating the likelihood that those outputs may be problematic. For LLM reasoning tasks, it is essential to estimate the uncertainty not only for the final answer, but also for the intermediate steps of the reasoning, as this can enable more fine-grained and targeted interventions. In this study, we explore what UQ metrics better reflect the LLM's ``intermediate uncertainty''during reasoning. Our study reveals that an LLMs' incorrect reasoning steps tend to contain tokens which are highly sensitive to the perturbations on the preceding token embeddings. In this way, incorrect (uncertain) intermediate steps can be readily identified using this sensitivity score as guidance in practice. In our experiments, we show such perturbation-based metric achieves stronger uncertainty quantification performance compared with baseline methods such as token (generation) probability and token entropy. Besides, different from approaches that rely on multiple sampling, the perturbation-based metrics offer better simplicity and efficiency.",
    "title_zh": "嵌入扰动可能更好地反映大语言模型推理中的不确定性",
    "abstract_zh": "大型语言模型（LLMs）在多个领域已取得显著突破；然而，它们仍可能产生不可靠或具有误导性的输出。为了负责任地应用大型语言模型，不确定性量化（Uncertainty Quantification, UQ）技术被用来估计模型对其输出的不确定性，从而反映这些输出可能存在问题的概率。在涉及模型推理的任务中，不仅需要对最终答案进行不确定性估计，还应评估推理过程中的中间步骤，因为这有助于实现更精细、更具针对性的干预措施。本研究探讨了哪些不确定性量化（UQ）指标能够更好地反映LLM在推理过程中的“中间不确定性”。研究发现，LLM产生错误推理步骤时，其生成的标记（tokens）往往对前序标记嵌入的扰动表现出高度敏感性。因此，在实际应用中，可以利用这种敏感性得分来有效识别出错误（不确定）的中间推理步骤。实验结果表明，与基于标记生成概率或标记熵的基线方法相比，基于扰动的度量方法在不确定性量化方面表现更优。此外，与依赖多次采样的方法不同，基于扰动的度量方法具有更高的简洁性和计算效率。"
  },
  {
    "date": "2026-02-02",
    "title": "Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics",
    "authors": "Ziwen Xu, Chenyan Wu, Hengyu Sun, Haiwen Hong, Mengru Wang, Yunzhi Yao, Longtao Huang, Hui Xue, Shumin Deng, Zhixuan Chu, Huajun Chen, Ningyu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02343v1",
    "source": "arXiv",
    "abstract": "Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md.",
    "title_zh": "为什么转向有效：迈向对语言模型参数动态的统一理解",
    "abstract_zh": "控制大型语言模型（LLMs）的方法，包括局部权重微调、基于LoRA的适配以及基于激活的干预，通常被孤立地研究，这掩盖了它们之间的内在联系，也使得方法间的比较变得困难。在本研究中，我们提出一种统一的视角，将这些干预措施视为由控制信号引发的动态权重更新，并将其置于同一概念框架下。基于这一视角，我们进一步提出一种统一的偏好-效用分析方法，将控制效果分解为“偏好”（即向目标概念的倾向性）和“效用”（即生成内容的一致性与任务有效性），并利用极性配对的对比样例，在共享的对数几率尺度上对两者进行度量。在不同方法中，我们观察到偏好与效用之间存在一致的权衡关系：更强的控制虽能提升偏好，但会可预测地降低效用。我们进一步通过激活流形的视角解释这一现象：控制操作会将模型表示沿目标概念方向移动以增强偏好，而效用的下降主要发生在干预使表示偏离模型有效生成流形时。最后，我们提出一种新的控制方法SPLIT，该方法基于上述分析，能够在提升偏好同时更好地保持效用。代码已公开，详见：https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md。"
  },
  {
    "date": "2026-02-02",
    "title": "Interpreting and Controlling LLM Reasoning through Integrated Policy Gradient",
    "authors": "Changming Li, Kaixing Zhang, Haoyun Xu, Yingdong Shi, Zheng Zhang, Kaitao Song, Kan Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02313v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) demonstrate strong reasoning abilities in solving complex real-world problems. Yet, the internal mechanisms driving these complex reasoning behaviors remain opaque. Existing interpretability approaches targeting reasoning either identify components (e.g., neurons) correlated with special textual patterns, or rely on human-annotated contrastive pairs to derive control vectors. Consequently, current methods struggle to precisely localize complex reasoning mechanisms or capture sequential influence from model internal workings to the reasoning outputs. In this paper, built on outcome-oriented and sequential-influence-aware principles, we focus on identifying components that have sequential contribution to reasoning behavior where outcomes are cumulated by long-range effects. We propose Integrated Policy Gradient (IPG), a novel framework that attributes reasoning behaviors to model's inner components by propagating compound outcome-based signals such as post reasoning accuracy backward through model inference trajectories. Empirical evaluations demonstrate that our approach achieves more precise localization and enables reliable modulation of reasoning behaviors (e.g., reasoning capability, reasoning strength) across diverse reasoning models.",
    "title_zh": "通过集成策略梯度实现对大语言模型推理的解释与控制",
    "abstract_zh": "大型语言模型（LLMs）在解决复杂现实问题时展现出强大的推理能力，但驱动这些复杂推理行为的内部机制仍不透明。现有的可解释性方法在研究推理过程时，要么识别与特定文本模式相关的组件（如神经元），要么依赖人工标注的对比样本对来推导控制向量。因此，现有方法在精确定位复杂推理机制或捕捉模型内部运作对推理输出的序列性影响方面仍存在困难。本文基于结果导向与序列影响感知的原则，聚焦于识别那些在推理行为中具有序列性贡献、其影响通过长程效应累积的模型内部组件。我们提出了一种名为集成策略梯度（Integrated Policy Gradient, IPG）的新框架，通过将基于复合结果的信号（如推理后的准确率）沿模型推理轨迹反向传播，来将推理行为归因于模型的内部组件。实证评估表明，该方法实现了更精确的定位，并能够可靠地调控多种推理模型中的推理行为（如推理能力、推理强度）。"
  },
  {
    "date": "2026-2-2",
    "title": "BinFuse: Binary Code Similarity Detection via Lightweight Fused Semantic Embedding",
    "authors": "Shengjia Chang, Baojiang Cui, Shaocong Feng",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00317",
    "source": "IEEE",
    "abstract": "Binary code similarity detection (BCSD) is critical for ensuring software security and reliability; however, current approaches often fall short in capturing comprehensive program semantics. Existing methods typically rely on isolated code or structural embeddings; others apply naive strategies to combine these embeddings, which limits their effectiveness—particularly in complex scenarios such as cross-architecture and cross-optimization binary comparisons. To address these limitations, we propose BinFuse, a lightweight framework designed for high-performance BCSD through the efficient fusion of code and structural semantics. BinFuse introduces a novel Markov matrix construction for fine-grained code feature extraction and employs an enhanced concrete autoencoder (CAE) for optimal feature selection. These extracted features are then assigned as node attributes to construct a fused semantic control flow graph (FSCFG), which is then jointly modeled by a Siamese network to enable accurate and efficient code similarity detection. Experimental results show that BinFuse achieves an impressive accuracy of 96.3% in complex scenarios, significantly outperforming established baselines such as Asm2Vec and Gemini in multiple evaluation metrics. Notably, BinFuse achieves accuracy comparable to the state-of-the-art IoTSim while reducing the detection time by 15%. The favorable balance between accuracy and efficiency achieved by BinFuse underscores its potential as a practical and scalable solution for BCSD in complex scenarios, thereby contributing to the development of more secure and trustworthy software systems.",
    "title_zh": "BinFuse：通过轻量级融合语义嵌入实现二进制代码相似性检测",
    "abstract_zh": "二进制代码相似性检测（BCSD）对于保障软件安全性和可靠性至关重要；然而，现有方法在捕捉全面的程序语义方面往往存在不足。当前的方法通常依赖于孤立的代码或结构嵌入，或采用简单的策略组合这些嵌入，这限制了其在复杂场景（如跨架构、跨优化级别的二进制比较）下的有效性。为解决上述问题，我们提出 BinFuse——一种轻量级框架，通过高效融合代码与结构语义，实现高性能的二进制代码相似性检测。BinFuse 引入了一种新颖的马尔可夫矩阵构建方法，用于细粒度的代码特征提取，并采用改进的混凝土自编码器（CAE）实现最优特征选择。提取出的特征随后被作为节点属性，用于构建融合语义控制流图（FSCFG），并由孪生网络联合建模，从而实现准确且高效的代码相似性检测。实验结果表明，BinFuse 在复杂场景下达到了 96.3% 的惊人准确率，显著优于 Asm2Vec 和 Gemini 等成熟基线方法，在多项评估指标上表现突出。值得注意的是，BinFuse 的准确率可与当前最先进的 IoTSim 相媲美，同时将检测时间减少了 15%。BinFuse 在准确率与效率之间取得的优异平衡，凸显了其在复杂场景下作为实用且可扩展的 BCSD 解决方案的巨大潜力，从而为构建更安全、更可信的软件系统提供了有力支持。"
  },
  {
    "date": "2026-2-2",
    "title": "ORThrus: Detecting Deep Learning Compiler Bugs via Optimization Resistance Transformations",
    "authors": "Tongwei Zhang, Baojian Hua",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00258",
    "source": "IEEE",
    "abstract": "Deep learning compilers are essential for deploying deep learning applications across heterogeneous hardware platforms. To improve execution efficiency, they employ sophisticated optimizations, which inevitably introduce bugs due to their considerably large code size and complex logic. Therefore, effectively detecting optimization bugs is essential to guarantee the correctness and trustworthiness of deep learning compilers.In this paper, we present ORThrus, an automatic approach to effectively detect optimization bugs in deep learning compilers. Conceptually, our approach develops a non-optimizing reference compiler to an optimizing compiler, then to detect optimization bugs by comparing the discrepancies in the two compilers’ outputs. Obtaining a non-optimizing reference compiler is challenging, because existing deep learning compilers provide limited control over optimizations. We thus propose a novel approach dubbed optimization resistance transformation that structurally transforms an input deep learning model from an optimizable form to an unoptimizable form that the deep learning compiler can no longer perform the potential optimizations. We build a prototype for our approach and evaluate it in an extensive testing campaign on two widely-used deep learning compilers TVM and ONNXRuntime. ORThrus detects 21 bugs, of which 9 are non-crash optimization bugs and 1 is missed by the state-of-the-art tool NNSmith even with its cross reference feature enabled. Meanwhile, ORThrus introduces negligible execution overhead.",
    "title_zh": "ORThrus：通过优化抵抗变换检测深度学习编译器漏洞",
    "abstract_zh": "深度学习编译器对于在异构硬件平台上部署深度学习应用至关重要。为了提高执行效率，它们采用了复杂的优化技术，但这些技术由于代码规模庞大且逻辑复杂，不可避免地引入了错误。因此，有效检测优化错误对于保证深度学习编译器的正确性和可信度至关重要。\n\n本文提出 ORThrus，一种自动检测深度学习编译器中优化错误的高效方法。其核心思想是：构建一个非优化的参考编译器，与优化编译器进行对比，通过分析两者输出的差异来发现优化错误。然而，获取一个非优化的参考编译器颇具挑战性，因为现有的深度学习编译器对优化过程的控制能力有限。为此，我们提出了一种新颖的方法——“优化抗性变换”（optimization resistance transformation），该方法通过结构化地将输入的深度学习模型从可优化形式转换为不可优化形式，使得深度学习编译器无法执行潜在的优化操作。\n\n我们实现了该方法的原型，并在两个广泛使用的深度学习编译器 TVM 和 ONNXRuntime 上进行了大规模测试。实验结果表明，ORThrus 共检测出 21 个错误，其中 9 个为非崩溃型优化错误，且有 1 个错误是当前最先进的工具 NNSmith 即使启用了交叉引用功能也未能发现的。同时，ORThrus 的执行开销极低，几乎可以忽略不计。"
  },
  {
    "date": "2026-2-2",
    "title": "Beyond Algorithmic Proofs: Towards Implementation-Level Provable Security",
    "authors": "Jiahui Shang, Luning Zhang, Zhongxiang Zheng",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00215",
    "source": "IEEE",
    "abstract": "While traditional cryptographic research focuses on algorithm-level provable security, many real-world attacks exploit weaknesses in system implementations, such as memory mismanagement, poor entropy sources, and insecure key lifecycles. Existing approaches address these risks in isolation but lack a unified, verifiable framework for modeling implementation-layer security. In this work, we propose Implementation-Level Provable Security, a new paradigm that defines security in terms of structurally verifiable resilience against real-world attack surfaces during deployment. To demonstrate its feasibility, we present SEER (Secure and Efficient Encryption-based Erasure via Ransomware), a file destruction system that repurposes and reinforces the encryption core of Babuk ransomware. SEER incorporates key erasure, entropy validation, and execution consistency checks to ensure a well-constrained, auditable attack surface. Our evaluation shows that SEER achieves strong irrecoverability guarantees while maintaining practical performance. This work demonstrates a shift from abstract theoretical models toward practically verifiable implementation-layer security.",
    "title_zh": "超越算法证明：迈向实现级别的可证明安全",
    "abstract_zh": "尽管传统密码学研究聚焦于算法层面的可证明安全性，但许多现实世界中的攻击却利用了系统实现中的弱点，例如内存管理不当、熵源质量差以及密钥生命周期不安全等问题。现有方法虽然分别针对这些风险进行了应对，但却缺乏一个统一且可验证的框架来建模实现层的安全性。在本研究中，我们提出了“实现层面可证明安全”这一新范式，其将安全性定义为在部署过程中对真实世界攻击面具备结构化可验证的鲁棒性。为证明该范式的可行性，我们提出了SEER（基于勒索软件的可靠且高效的加密擦除系统），这是一种文件销毁系统，它重新利用并强化了Babuk勒索软件的加密核心。SEER通过引入密钥擦除、熵值验证和执行一致性检查，确保攻击面受到严格约束且可审计。我们的评估表明，SEER在保持实际性能的同时，实现了强大的不可恢复性保障。这项工作标志着从抽象的理论模型向可实际验证的实现层安全性的转变。"
  },
  {
    "date": "2026-2-2",
    "title": "Generating Structured BPMN Models from Smart Contracts Using LLMs",
    "authors": "Linlin Chen",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00402",
    "source": "IEEE",
    "abstract": "The increasing complexity and widespread deployment of smart contracts (SCs) on blockchain platforms have heightened the need for interpretable and verifiable representations. While smart contracts encode critical business logic, their low-level implementations remain difficult for auditors and regulators to interpret. To bridge this semantic gap, we propose a structure-aware instruction-tuning framework that translates Solidity functions into Business Process Model and Notation (BPMN) diagrams using large language models (LLMs). Our approach constructs a high-quality dataset of 15K Solidity-BPMN pairs through embedding-based clustering, prompt engineering, and multi-template augmentation. We fine-tune DeepSeek-Coder using LoRA for efficient domain adaptation, enabling the model to generate syntactically valid and semantically faithful BPMN structures. Experimental results show that our fine-tuned model outperforms GPT-4o, Gemini, and baseline LLMs in both structural precision and semantic fidelity. This work lays the groundwork for structure-level explainability of smart contracts and supports future research in code-to-process modeling and blockchain compliance analysis.",
    "title_zh": "使用大语言模型从智能合约生成结构化的BPMN模型",
    "abstract_zh": "随着区块链平台上智能合约（SCs）的复杂性日益增加以及部署范围不断扩大，对可解释、可验证的表示形式的需求也愈发迫切。尽管智能合约编码了关键的业务逻辑，但其底层实现对于审计人员和监管机构而言仍难以理解。为弥合这一语义鸿沟，我们提出了一种结构感知的指令微调框架，利用大语言模型（LLMs）将Solidity函数转换为业务流程模型与符号（BPMN）图。我们的方法通过基于嵌入的聚类、提示工程以及多模板增强技术，构建了一个包含15,000对Solidity-BPMN的高质量数据集。我们采用LoRA对DeepSeek-Coder进行微调，实现了高效的领域适应，使模型能够生成语法正确且语义忠实的BPMN结构。实验结果表明，经过微调的模型在结构精确度和语义保真度方面均优于GPT-4o、Gemini及基线LLM。本研究为智能合约的结构级可解释性奠定了基础，并推动了未来代码到流程建模以及区块链合规分析领域的研究发展。"
  },
  {
    "date": "2026-2-2",
    "title": "OSSDetector: Towards a More Accurate Approach for C/C++ Third-Party Library Detection",
    "authors": "Xiang Hai, Jia Zeng, Zhiyuan Fu, Siyu Chen, Yansong Shi, Hongyu Sun, Jice Wang, Fannv He, Yuqing Zhang",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00285",
    "source": "IEEE",
    "abstract": "In today’s software development environment, third-party libraries (TPLs) enhance productivity but also introduce security risks. Effective Software Composition Analysis (SCA) is crucial for managing these risks. Yet, existing SCA tools for C/C++ projects struggle with challenges like detecting modified and nested TPLs, precise version representation, and comprehensive TPL databases. In modern software development, third-party libraries (TPLs) are commonly used to boost functionality and save development time. However, this convenience introduces security risks. We introduce OSSDetector, a new SCA tool that addresses these issues. OSSDetector uses sliding window and fuzzy hashing techniques to generate detailed signatures, improving detection of modified TPLs. It features a \"Nested TPL Function Filtering\" algorithm to accurately identify and filter nested TPL functions, and a \"TPL Recognition\" algorithm based on import ratios and function paths to determine the TPLs used in the software. It also addresses version representation by using function weights and release times. To overcome the lack of a comprehensive TPL database, we have developed a large database with 29,416 C/C++ TPLs and 767,405 versions. Experimental results demonstrate that OSSDetector surpasses state-of-the-art tools, achieving better precision (85.52%), recall (79.82%), and F1 score (82.57%), and higher precision (84.27%) at the library version level.",
    "title_zh": "OSSDetector：一种更精确的C/C++第三方库检测方法",
    "abstract_zh": "在当今的软件开发环境中，第三方库（TPLs）虽然提升了开发效率，但也带来了安全风险。有效的软件成分分析（SCA）对于管理这些风险至关重要。然而，现有的针对C/C++项目的SCA工具在检测修改过的和嵌套的第三方库、精确表示版本信息以及构建全面的第三方库数据库方面仍面临诸多挑战。在现代软件开发中，第三方库被广泛用于增强功能并节省开发时间，但这种便利性也引入了潜在的安全隐患。为此，我们提出了一种新的SCA工具——OSSDetector，以解决上述问题。\n\nOSSDetector采用滑动窗口与模糊哈希技术生成详细的代码签名，显著提升了对修改后第三方库的检测能力。它引入了“嵌套第三方库函数过滤”算法，能够准确识别并过滤嵌套的第三方库函数；同时，基于导入比例与函数路径的“第三方库识别”算法，可有效判断软件中实际使用的第三方库。此外，为解决版本表示不准确的问题，OSSDetector通过函数权重与发布时序信息实现更精细的版本刻画。\n\n针对现有第三方库数据库不完整的问题，我们构建了一个包含29,416个C/C++第三方库及其767,405个版本的大型数据库。实验结果表明，OSSDetector在性能上超越了当前最先进的工具：在整体检测精度（85.52%）、召回率（79.82%）和F1分数（82.57%）方面表现优异，并在库版本级别实现了更高的精度（84.27%）。"
  },
  {
    "date": "2026-2-2",
    "title": "RL-Optimized Lightweight Obfuscation Against Binary Code Similarity Detection",
    "authors": "Ran Wei, Hui Shu, Fei Kang",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00096",
    "source": "IEEE",
    "abstract": "Binary Code Similarity Detection (BCSD) identifies functions with similar functionality across binaries. Reverse engineers leverage BCSD techniques to locate critical functions in software, thereby compromising associated functional modules. This poses significant challenges for software protection. Although code obfuscation can counter BCSD, existing methods typically apply global, undifferentiated obfuscation, leading to unnecessary code size and runtime overhead. This paper proposes ReinObf, a reinforcement learning-optimized method for lightweight and differentiated obfuscation. In the LLVM intermediate representation of functions, we implement a custom pass to extract statistical and structural features from basic blocks and construct Attributed Control Flow Graphs (ACFGs). A hierarchical RL agent encodes ACFGs using graph neural networks, selects critical blocks and optimal obfuscation methods, then iteratively generates optimized obfuscation sequences that maximize evasion effectiveness while minimizing overhead. Experimental validation demonstrates that ReinObf effectively evades BinDiff, jTrans, CLAP, and Gemini, with an average similarity of 0.391. Compared to OLLVM’s combined obfuscation, it reduces code size overhead by 66.3% and runtime overhead by 34.7%, achieving a favorable security-performance tradeoff.",
    "title_zh": "面向二进制代码相似性检测的强化学习优化轻量级混淆技术",
    "abstract_zh": "二进制代码相似性检测（BCSD）能够识别跨二进制文件中功能相似的函数。逆向工程师利用BCSD技术可定位软件中的关键函数，从而破坏相关功能模块，给软件保护带来严峻挑战。尽管代码混淆可有效对抗BCSD，但现有方法通常采用全局统一的混淆策略，导致代码体积和运行时开销过大。本文提出ReinObf，一种基于强化学习优化的轻量级、差异化混淆方法。在函数的LLVM中间表示中，我们实现了一个自定义优化传递，从基本块中提取统计与结构特征，并构建带属性的控制流图（ACFG）。采用分层强化学习代理，利用图神经网络对ACFG进行编码，选择关键代码块及最优混淆方法，迭代生成能够最大化规避效果同时最小化开销的优化混淆序列。实验结果表明，ReinObf能有效规避BinDiff、jTrans、CLAP和Gemini等工具检测，平均相似度仅为0.391。与OLLVM的综合混淆方案相比，其代码体积开销降低66.3%，运行时开销减少34.7%，实现了良好的安全与性能权衡。"
  },
  {
    "date": "2026-2-2",
    "title": "Enhancing Commercial Laboratory Efficiency and Knowledge Management: Leveraging Local Large Language Models with Retrieval-Augmented Generation",
    "authors": "Shui Lun Au, Shu Lun Mak, Fanny Tang",
    "publish": "2025 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)",
    "url": "https://doi.org/10.1109/ieem63636.2025.11357684",
    "source": "IEEE",
    "abstract": "Modern commercial laboratories grapple with an increasing volume and complexity of data, demanding sophisticated methods for efficient retrieval and robust knowledge management. Traditional approaches often struggle to handle the scale and diversity of laboratory information. Large Language Models (LLMs) offer a promising solution, particularly when deployed locally and integrated with Retrieval-Augmented Generation (RAG). This paper explores the potential of leveraging local LLMs with RAG to enhance laboratory efficiency and knowledge management significantly. By combining the generative power of LLMs with the ability to retrieve relevant information from diverse laboratory data sources, this approach can streamline data access, improve decision-making, and facilitate technological advancements within commercial laboratory settings.",
    "title_zh": "提升商业实验室效率与知识管理：利用本地大语言模型结合检索增强生成技术",
    "abstract_zh": "现代商业实验室面临着日益增长且复杂的数据量，亟需高效的数据检索与稳健的知识管理方法。传统方法在应对实验室信息的规模与多样性方面常常力不从心。大型语言模型（LLMs）提供了一种有前景的解决方案，尤其是当其在本地部署并与检索增强生成（RAG）技术相结合时。本文探讨了利用本地部署的LLM结合RAG技术，以显著提升实验室效率与知识管理水平的潜力。通过将LLM的生成能力与从多样化实验室数据源中检索相关信息的能力相结合，该方法能够简化数据获取流程，提升决策质量，并推动商业实验室环境中的技术进步。"
  },
  {
    "date": "2026-2-2",
    "title": "An AI-Driven Multimodal Feature Fusion Framework for Integrated Circuit Fault Diagnosis",
    "authors": "Hongyi Xie",
    "publish": "2025 5th International Conference on Electrical Engineering and Control Science (IC2ECS)",
    "url": "https://doi.org/10.1109/ic2ecs68700.2025.11362036",
    "source": "IEEE",
    "abstract": "To address the limitations of single-feature circuit diagnostics-insufficient information, reduced accuracy, and weak real-time performance-this paper proposes an AI-driven integrated circuit (IC) fault diagnosis framework based on multimodal feature fusion. The framework acquires voltage, current, temperature, and time-domain waveform data via onboard sensors; performs cleaning, synchronization, and normalization; then feeds the processed streams into a fusion network that uses attention to adaptively weight modalities according to reliability. The diagnostic core is an improved deep model enhanced with transfer learning to remain effective under small-sample regimes and distribution shifts across boards and process corners. In experiments with twelve representative fault types (short, open, and parameter drift among others), the framework achieves 98.7% average accuracy, an 11.3 -point improvement over a single-feature baseline, while keeping end-toend latency under 5 ms on an industrial edge GPU. These results indicate the framework’s suitability for high-reliability, real-time IC testing and maintenance with practical deployment paths in production lines and in-system monitors.",
    "title_zh": "一种基于人工智能的多模态特征融合框架用于集成电路故障诊断",
    "abstract_zh": "为解决单一特征电路诊断中存在的信息不足、准确率低以及实时性弱等局限性，本文提出了一种基于多模态特征融合的AI驱动集成电路（IC）故障诊断框架。该框架通过机载传感器采集电压、电流、温度及时域波形数据，经数据清洗、同步与归一化处理后，将处理后的多源数据流输入融合网络，该网络利用注意力机制根据各模态的可靠性自适应地分配权重。诊断核心采用一种改进的深度学习模型，结合迁移学习技术，使其在小样本场景下以及在不同电路板和工艺角之间存在分布偏移的情况下仍保持高效性能。在包含十二种典型故障类型（如短路、开路及参数漂移等）的实验中，该框架实现了98.7%的平均诊断准确率，较单一特征基线提升11.3个百分点，同时在工业级边缘GPU上保持端到端延迟低于5毫秒。实验结果表明，该框架适用于高可靠性、实时性要求严格的IC测试与维护，具备在生产线及系统内监测设备中实际部署的可行性。"
  },
  {
    "date": "2026-2-2",
    "title": "RuDyna: Towards A Dynamic Analysis Framework for Rust",
    "authors": "Shanlin Deng, Baojian Hua",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00085",
    "source": "IEEE",
    "abstract": "Rust emerges as a promising safe language and is gaining rapid adoption in security-critical domains. However, Rust programs are susceptible to memory and thread safety issues, making dynamically analyzing Rust issues imperative. Unfortunately, a dynamic analysis framework for Rust is still lacking, hampering the advancement of dynamic analysis for Rust and posing security risks for the language.In this paper, we present RuDyna, the first Rust native dynamic analysis framework to the best of our knowledge. Our framework aims to instrument Rust programs and provide a set of hooks for monitoring runtime events. To this end, we first propose instrumenting the Rust MIR with three rules designed for satisfying its constraints. We then present four instrument strategies to inject various runtime events on MIR. Finally, we develop a hierarchical strategy to instrument configurable hooks to reduce overheads. We implement RuDyna by extending Rust’s official rustc compiler and hooks are provided as a Rust library. We conduct evaluation on a set of micro-benchmarks and 4 real-world large Rust projects. Experimental results indicate that RuDyna preserves the original semantics of programs, with an acceptable runtime overhead ranging from 1.1 × to 3.6 ×, which aligns with built-in instrumentation in rustc and similar frameworks for other languages. Moreover, we implement six analyses based on RuDyna, demonstrating its practical usability.",
    "title_zh": "RuDyna：面向 Rust 的动态分析框架",
    "abstract_zh": "Rust作为一种前景广阔的内存安全语言，正迅速在安全关键领域得到应用。然而，Rust程序仍可能面临内存安全和线程安全问题，因此动态分析Rust程序中的缺陷变得至关重要。遗憾的是，目前尚缺乏针对Rust的动态分析框架，这严重制约了Rust动态分析技术的发展，并给该语言带来了潜在的安全风险。本文中，我们提出了RuDyna——据我们所知，这是首个原生支持Rust的动态分析框架。该框架旨在对Rust程序进行插桩，并提供一组用于监控运行时事件的钩子。为此，我们首先提出了一套针对Rust中间表示（MIR）的三规则插桩方法，以满足Rust语言的约束条件；随后，我们设计了四种插桩策略，用于在MIR层面注入多种运行时事件；最后，我们提出了一种分层插桩策略，通过可配置的钩子实现更高效的性能控制，从而降低开销。我们通过扩展Rust官方的rustc编译器实现了RuDyna，并将钩子以Rust库的形式提供。我们在一系列微基准测试以及4个真实世界大型Rust项目上进行了评估。实验结果表明，RuDyna能够保持程序原有的语义，运行时开销在1.1倍至3.6倍之间，与rustc内置的插桩机制及其他语言的类似框架相当。此外，我们基于RuDyna实现了六种不同的静态与动态分析，充分验证了其在实际应用中的可用性与有效性。"
  },
  {
    "date": "2026-2-2",
    "title": "Interprocedural Call Graph Embedding with GAT for Memory safety Vulnerability Detection",
    "authors": "Rong Ren, JingYi Wu, HongBo Jin, QingYu Song, Bing Zhang, Qian Wang",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00123",
    "source": "IEEE",
    "abstract": "Memory safety vulnerabilities remain a critical threat to software security, often leading to system crashes, data leakage, and service disruptions. Existing deep learning-based detection methods mainly rely on intra-procedural analysis, which limits their ability to capture complex memory behaviors involving pointer variable flows across function boundaries. This study proposes IpGAT, an InterProcedural memory vulnerability detection framework based on Graph Attention Network (GAT) that aims to overcome the limitations of intra-procedural approaches by modeling cross-function data flows of pointer variables. IpGAT constructs an Interprocedural Program Call Graph (IpCG) that integrates Abstract Syntax Trees (AST), Control Flow Graphs (CFG), and Data Flow Graphs (DFG) to represent memory-sensitive function interactions. The IpCG is embedded using Word2Vec and then fed into a GAT for vulnerability classification. Experimental results show that IpGAT achieves an accuracy of 88.9%, a precision of 86.5%, and an F1-score of 89.1%, significantly outperforming six state-of-the-art tools and intra-procedural baselines. Furthermore, IpGAT successfully identified eight real-world memory safety vulnerabilities in open-source projects such as ffdshow, Libav, Seamonkey, and VLC, all of which have been confirmed in the CVE database. By incorporating interprocedural analysis and graph-based learning, IpGAT effectively captures the semantics of memory-sensitive operations and demonstrates strong generalizability across both benchmark datasets and real-world software.",
    "title_zh": "基于图注意力网络的跨过程调用图嵌入在内存安全漏洞检测中的应用",
    "abstract_zh": "内存安全漏洞仍然是软件安全领域的一个重大威胁，常常导致系统崩溃、数据泄露和服务中断。现有的基于深度学习的检测方法主要依赖于过程内（intra-procedural）分析，这限制了其捕捉跨函数边界涉及指针变量流动的复杂内存行为的能力。本研究提出了一种基于图注意力网络（GAT）的跨过程（InterProcedural）内存漏洞检测框架——IpGAT，旨在通过建模指针变量的跨函数数据流，克服过程内方法的局限性。IpGAT构建了一个跨过程程序调用图（IpCG），该图整合了抽象语法树（AST）、控制流图（CFG）和数据流图（DFG），以表征与内存敏感相关的函数间交互关系。随后，IpCG采用Word2Vec进行嵌入表示，并输入到GAT中完成漏洞分类。实验结果表明，IpGAT在准确率、精确率和F1分数上分别达到88.9%、86.5%和89.1%，显著优于六种最先进的工具及过程内基线方法。此外，IpGAT成功在fddshow、Libav、Seamonkey和VLC等开源项目中识别出八个真实存在的内存安全漏洞，所有漏洞均已获得CVE数据库的确认。通过融合跨过程分析与基于图的机器学习方法，IpGAT能够有效捕捉内存敏感操作的语义信息，并在基准数据集与真实软件场景中均展现出强大的泛化能力。"
  },
  {
    "date": "2026-2-2",
    "title": "LLM-Generated Description and Reasoning: Use-case for Library Recommendations",
    "authors": "Arash Sal Moslehian, Eya Briki, Michalis Vlachos",
    "publish": "2025 ACM/IEEE Joint Conference on Digital Libraries (JCDL)",
    "url": "https://doi.org/10.1109/jcdl67857.2025.00015",
    "source": "IEEE",
    "abstract": "Recent advances in recommender systems have begun to explore how large language models can enhance user and item representations through natural language. However, the effectiveness of using LLM-generated descriptions and internal reasoning directly within collaborative filtering models remains underexplored. In this work, we evaluate various content-based embeddings, either by directly encoding metadata or by constructing richer user and item profiles using LLMs with internal reasoning. These embeddings are integrated into standard collaborative filtering models without modifying their architectures. Using a real-world library dataset enriched through external book databases, we show that on average, content-based embeddings improve recommendation performance by $40 \\%$ in recall and NDCG over baseline models, and LLM-generated profiles further improve performance and provide compact, interpretable representations. Our findings suggest that LLMgenerated profiles and reasoning not only enhance explainability, but also improve recommendation quality in sparse, real-world environments.",
    "title_zh": "大语言模型生成的描述与推理：图书馆推荐的应用场景",
    "abstract_zh": "近年来，推荐系统领域的进展开始探索如何利用大语言模型（LLM）通过自然语言来增强用户和物品的表示。然而，将LLM生成的描述以及内部推理直接应用于协同过滤模型的有效性仍缺乏充分研究。在本工作中，我们评估了多种基于内容的嵌入方法：一种是直接编码元数据，另一种是利用具有内部推理能力的LLM构建更丰富的用户与物品画像。这些嵌入被整合进标准的协同过滤模型中，且无需修改其原有架构。基于一个通过外部图书数据库丰富后的实际图书馆数据集，我们发现，相较于基线模型，基于内容的嵌入平均使推荐性能在召回率和NDCG指标上提升了40%；而由LLM生成的用户画像进一步提升了性能，并提供了紧凑且可解释的表示形式。我们的研究结果表明，LLM生成的画像及其推理不仅增强了推荐结果的可解释性，还在稀疏的真实场景中有效提升了推荐质量。"
  },
  {
    "date": "2026-2-2",
    "title": "CrossMiner: Smart Contract Vulnerability Detection in Interactive Scenarios",
    "authors": "Xiangfu Liu, Teng Huang, Caiyan Tan, Jiahui Huang, Qiong Wang, Yan Pang",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00200",
    "source": "IEEE",
    "abstract": "Vulnerability attacks targeting smart contracts have caused significant losses of digital assets. Many approaches based on static analysis, fuzzing, and deep learning have been proposed for detecting contract vulnerabilities. However, most existing methods only support vulnerability detection within individual contracts. When contracts interact with each other through external calls, these methods fail to perform effective cross-contract security analysis, leading to false negatives and false positives. To address these limitations, we propose CrossMiner, a deep learning-based approach for vulnerability detection in contract interaction scenarios. CrossMiner enables comprehensive risk assessment for cross-contract security through trace analysis of function call chains. Specifically, CrossMiner first constructs a cross-contract dependency graph based on function call chains to effectively model inter-contract dependencies and network dynamics, and collect semantic information about contract interactions. Then, it employs a heterogeneous graph neural network with a two-level attention mechanism to finely extract and integrate complex features from the dependency graph, ultimately achieving precise risk assessment and vulnerability detection. We evaluate the effectiveness of CrossMiner on three types of smart contract vulnerabilities: reentrancy, timestamp dependency, and transaction state dependency. Experimental results demonstrate that CrossMiner achieves the best performance among all baseline methods, improving detection accuracy by 5.52%, 4.94%, and 5.60% for these vulnerabilities, and the F1 scores are improved by 5.44%, 5.02%, and 5.40%, respectively.",
    "title_zh": "CrossMiner：交互场景中智能合约漏洞检测",
    "abstract_zh": "针对智能合约的漏洞攻击已造成大量数字资产损失。为检测合约漏洞，已有诸多基于静态分析、模糊测试和深度学习的方法被提出。然而，大多数现有方法仅能支持单个合约内的漏洞检测。当合约通过外部调用相互交互时，这些方法无法有效进行跨合约安全分析，导致出现误报和漏报。为解决上述局限性，我们提出了CrossMiner——一种基于深度学习的跨合约交互场景漏洞检测方法。CrossMiner通过分析函数调用链的执行轨迹，实现对跨合约安全性的全面风险评估。具体而言，CrossMiner首先基于函数调用链构建跨合约依赖图，以有效建模合约间的依赖关系与网络动态，并收集合约交互的语义信息；随后，采用具有两级注意力机制的异构图神经网络，精细提取并融合依赖图中的复杂特征，最终实现精准的风险评估与漏洞检测。我们在三类典型智能合约漏洞（重入漏洞、时间戳依赖漏洞、交易状态依赖漏洞）上评估了CrossMiner的有效性。实验结果表明，CrossMiner在所有基线方法中表现最佳，其检测准确率分别提升了5.52%、4.94%和5.60%，F1分数也相应提高了5.44%、5.02%和5.40%。"
  },
  {
    "date": "2026-2-2",
    "title": "On the Limitations of Fuzzy Hashing for Malware Similarity: An Analysis of Vulnerable Code Detection in Malware",
    "authors": "Nathan Ross, Oluwafemi Olukoya, Jesús Martínez Del Rincón",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00044",
    "source": "IEEE",
    "abstract": "As malware variants continue to increase, the risk of evading detection also grows. While fuzzy hashing has traditionally been successful at clustering malware samples based on their structural similarities, its potential as an active defense tool remains largely unexplored. This study investigates the application of fuzzy hashing for the static analysis of malware binaries to identify common vulnerabilities prevalent in malware, serving as a proactive security measure. We utilized a labeled dataset comprising real-world and synthetic Windows binaries to evaluate six fuzzy hashing algorithms for full binary classification and two for function-level matching. Our results indicate that, while fuzzy hashing is effective in simpler tasks such as malware classification and binary-level vulnerability detection, its performance decreases in more complex scenarios, including multi-class vulnerability identification and matching functions from real-world malware. Moreover, we observed a significant drop in performance, by up to 50%, when transitioning from synthetic to actual malware functions. These findings highlight both the potential and limitations of fuzzy hashing in vulnerability analysis, emphasizing the necessity for more robust techniques to detect vulnerable patterns in real-world malware.",
    "title_zh": "模糊哈希在恶意软件相似性检测中的局限性：关于恶意软件中脆弱代码检测的分析",
    "abstract_zh": "随着恶意软件变种的持续增加，逃避检测的风险也在不断上升。尽管模糊哈希在基于结构相似性对恶意软件样本进行聚类方面传统上表现良好，但其作为主动防御工具的潜力仍鲜少被探索。本研究探讨了将模糊哈希应用于恶意软件二进制文件的静态分析，以识别恶意软件中普遍存在的共性漏洞，从而实现主动安全防护。我们使用了一个包含真实世界与合成Windows二进制文件的标注数据集，评估了六种模糊哈希算法在完整二进制分类中的表现，以及两种算法在函数级别匹配中的效果。研究结果表明，尽管模糊哈希在较简单任务（如恶意软件分类和二进制级别漏洞检测）中表现有效，但在更复杂的场景下（如多类漏洞识别以及真实恶意软件函数的匹配）性能显著下降。此外，我们观察到，当从合成函数过渡到真实恶意软件函数时，性能最高下降达50%。这些发现揭示了模糊哈希在漏洞分析中的潜力与局限性，强调了开发更稳健技术以检测真实世界恶意软件中脆弱模式的必要性。"
  },
  {
    "date": "2026-2-2",
    "title": "Chaos of Functionalities: Understanding Security Risks in Heterogeneity of IoT Matter Controllers",
    "authors": "Yiwei Fang, Haoqiang Wang, Ze Jin, Qixu Liu",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00019",
    "source": "IEEE",
    "abstract": "The Matter protocol has rapidly become the new standard for secure and interoperable IoT connectivity, adopted by major industry players and integrated into millions of devices. A core feature of Matter is its ability to support device sharing across users and controllers. However, as vendors independently implement Matter and blend it with their proprietary ecosystems, significant inconsistencies emerge. These inconsistencies result in heterogeneous user capabilities depending on which Matter Controller (MC) or OEM app is used, introducing a new and largely unexplored class of security risks. In this work, we present the first systematic study on security risks stemming from heterogeneous Matter controller implementations in shared device environments. We analyze 18 major IoT vendors and uncover a novel category of vulnerabilities, which we term MCG (Matter Controller Gaps), where differences in controller capabilities can enable unauthorized access or stealthy device manipulation. To uncover these flaws at scale, we develop MCG-Checker, a semi-automated analysis tool that combines large language models and UI automation to detect control disparities across Matter controllers and OEM apps. Using MCG-Checker, we evaluate 14 Matter controllers and 8 OEM apps, discovering 5 previously unknown attack vectors affecting top vendors such as Google, Apple, and Amazon Alexa. Our work reveals critical design and implementation issues in current Matter deployments. We offer concrete recommendations for protocol designers, vendors, and end users to address these gaps, contributing to more secure and predictable IoT ecosystems.",
    "title_zh": "功能繁杂的混乱：理解物联网物理事物控制器异构性中的安全风险",
    "abstract_zh": "Matter协议已迅速成为安全且可互操作的物联网（IoT）连接新标准，被众多行业领军企业采纳，并集成到数以百万计的设备中。Matter的核心特性之一是支持跨用户和控制器的设备共享。然而，由于各厂商独立实现Matter协议，并将其与自有生态系统融合，导致出现显著的不一致性。这些不一致性使得用户在使用不同Matter控制器（MC）或OEM应用时，所具备的功能能力存在差异，从而引入了一类全新且尚未被充分研究的安全风险。在本研究中，我们首次系统性地探讨了在共享设备环境中，由Matter控制器实现差异所引发的安全风险。我们分析了18家主要物联网厂商，发现了一类新型漏洞，我们将其命名为MCG（Matter控制器差距，Matter Controller Gaps），即不同控制器间功能差异可能被利用，实现未经授权的访问或隐蔽的设备操控。为大规模发现此类缺陷，我们开发了MCG-Checker——一种结合大语言模型与UI自动化技术的半自动化分析工具，用于检测Matter控制器与OEM应用之间的控制能力差异。利用MCG-Checker，我们评估了14款Matter控制器和8款OEM应用，发现了5个此前未知的攻击向量，影响谷歌、苹果及亚马逊Alexa等头部厂商。本研究揭示了当前Matter部署中存在的关键设计与实现问题。我们为协议设计者、厂商及终端用户提供了具体可行的改进建议，以弥合这些安全差距，助力构建更安全、更可预测的物联网生态系统。"
  },
  {
    "date": "2026-2-2",
    "title": "Enhancing Data Security in RISC-V Embedded Systems: A Lightweight Architecture",
    "authors": "Dunkai Mao, Lifeng Xi, Fujia Zhang",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00382",
    "source": "IEEE",
    "abstract": "Ensuring robust, hardware-level data security has become an urgent challenge, driven by the proliferation of Reduced Instruction Set Computer (RISC-V) architectures in resource-constrained embedded systems. This paper focuses on key security aspects such as memory safety and execution privilege control in embedded platforms. We present NanoSafe, a lightweight RV64IMAZicsr_Zifencei pipelined CPU architecture designed in-house. By designing a subset of interrupts/exceptions, integrating their handling process, and implementing a custom priority scheme, we have realized the necessary security mechanisms within this lightweight CPU structure. This design effectively thwarts attack primitives such as out-of-bounds memory access, illegal instruction execution, and privilege escalation. It is suitable for various application scenarios, including storage device controllers, low-power network devices, and educational platforms for computer architecture.",
    "title_zh": "提升RISC-V嵌入式系统中的数据安全：一种轻量级架构",
    "abstract_zh": "确保强大的硬件级数据安全已成为一项紧迫挑战，这主要源于精简指令集计算机（RISC-V）架构在资源受限嵌入式系统中的广泛应用。本文聚焦于嵌入式平台中的关键安全问题，如内存安全与执行权限控制。我们自主设计并实现了一种轻量级的RV64IMAZicsr_Zifencei流水线CPU架构——NanoSafe。通过设计特定的中断/异常子集，集成其处理流程，并实现自定义的优先级机制，我们在该轻量级CPU结构中成功实现了必要的安全防护机制。该设计有效抵御了越界内存访问、非法指令执行以及权限提升等攻击手段。该架构适用于多种应用场景，包括存储设备控制器、低功耗网络设备以及计算机体系结构教学平台。"
  },
  {
    "date": "2026-2-2",
    "title": "Large Language Model hallucination mitigation in three industrial use cases",
    "authors": "Petri Tikka, Jaakko Karjalainen, Andrea Alesani, Vladimir Goriachev",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3659997",
    "source": "IEEE",
    "abstract": "Large-language models (LLMs) can produce factually false or ungrounded information. This occurs when the language model, being fundamentally a statistical model, generates inaccurate or non-existent information with high confidence in response to a given query. This phenomenon is particularly dangerous in safety-critical systems and involves risks when LLMs are used to access or control hardware such as robots, sensors, and other internet-of-things (IoT) applications. Additionally, in automation-rich industrial environments, effective human–machine cooperation depends on maintaining a shared and adaptive understanding of complex situations. Distributed Situation Awareness (DSA) provides a framework for how awareness emerges collectively across networks of operators, robots, sensors, digital interfaces, and LLM based Artificial Intelligent (AI) systems. LLMs can fuse fragmented data streams into coherent, actionable context, enabling Extended Reality (XR) technologies to strengthen DSA by embedding digital cues into physical workflows. While this process improves coordination and adaptability, it also makes reliable and verifiable model outputs essential, as hallucinations can erode operator trust and compromise distributed decision-making. Therefore, mitigation of hallucinations becomes essential for sustaining stable human–AI teaming. We present three industrial projects where LLMs are at the forefront, highlighting practical approaches for hallucination mitigation and demonstrating a transition from online to offline model.",
    "title_zh": "大语言模型幻觉在三个工业应用场景中的缓解策略",
    "abstract_zh": "大型语言模型（LLMs）可能生成事实错误或缺乏依据的信息。当语言模型作为基础的统计模型时，它可能在回应特定查询时以高度自信生成不准确甚至虚构的信息。这一现象在安全关键系统中尤为危险，尤其是在LLM被用于访问或控制机器人、传感器及其他物联网（IoT）设备等硬件时。此外，在自动化程度较高的工业环境中，高效的人机协作依赖于各方对复杂情境保持共享且可动态调整的理解。分布式情境意识（DSA）为此提供了一个框架，说明情境意识如何在操作员、机器人、传感器、数字界面以及基于LLM的人工智能（AI）系统构成的网络中集体涌现。LLM能够将碎片化的数据流融合为连贯且可操作的情境信息，使扩展现实（XR）技术通过将数字提示嵌入物理工作流程，进一步增强DSA。尽管这一过程提升了协调性与适应性，但也使得模型输出的可靠性与可验证性变得至关重要，因为幻觉现象会削弱操作员的信任，损害分布式决策过程。因此，对幻觉的有效缓解成为维持稳定人机协同的关键。本文介绍了三个工业项目，其中LLM处于核心地位，重点展示了实用的幻觉缓解策略，并推动模型从在线模式向离线模式的转型。"
  },
  {
    "date": "2026-2-2",
    "title": "CyberSOIE-LLM: Cybersecurity Semi-Open Information Extraction with Large Language Models",
    "authors": "Xinzheng Liu, Zhaoyun Ding",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00166",
    "source": "IEEE",
    "abstract": "Advanced Persistent Threats (APTs) are increasing in frequency and sophistication, rendering traditional defenses inadequate against the pronounced asymmetry inherent in contemporary cybersecurity. Cyber Threat Intelligence (CTI) is widely viewed as pivotal for transitioning from reactive to proactive defence; however, the exponential growth of unstructured CTI far exceeds the speed of manual analysis. We introduce CyberSOIE-LLM, the first cybersecurity-oriented Semi-Open Information Extraction framework that employs Large Language Models as domain experts to extract security knowledge from CTI efficiently, automatically and accurately. The framework unites three synergistic modules. Generator blends external knowledge enhancement with Chain-of-Thought (CoT) prompting to produce initial triples. Refiner enforces precision through multi-level rule- and semantics-based validation coupled with self-correction. Unifier externally aligns and internally normalises relation labels, yielding high-quality, low-redundancy cybersecurity triples. Extensive experiments on four Chinese–English CTI benchmarks show that CyberSOIE-LLM significantly surpasses state-of-the-art baselines, providing a scalable and trustworthy knowledge substrate for dynamic, proactive defence.",
    "title_zh": "CyberSOIE-LLM：基于大语言模型的网络安全半开放信息抽取",
    "abstract_zh": "高级持续性威胁（APTs）的频率和复杂性持续上升，使得传统防御手段难以应对现代网络安全中固有的显著不对称性。网络威胁情报（CTI）被广泛认为是实现从被动防御向主动防御转型的关键，然而，非结构化CTI数据的指数级增长远远超过了人工分析的速度。为此，我们提出了CyberSOIE-LLM——首个面向网络安全领域的半开放信息抽取框架，该框架利用大型语言模型作为领域专家，高效、自动且准确地从CTI中提取安全知识。该框架由三个协同工作的模块组成：生成器通过融合外部知识增强与思维链（Chain-of-Thought, CoT）提示技术，生成初始三元组；精炼器通过多层次基于规则与语义的验证机制，结合自我修正能力，确保结果的精确性；统一器则对外部对齐关系标签、内部规范化关系表达，最终生成高质量、低冗余的网络安全三元组。在四个中英双语CTI基准数据集上的大量实验表明，CyberSOIE-LLM显著优于现有最先进方法，为动态、主动的防御体系提供了可扩展且可信的知识基础。"
  },
  {
    "date": "2026-2-2",
    "title": "SPFuzz: Program-State-Aware Fuzzing for Mail Protocols",
    "authors": "Hangzhou Fei, Xiaobing Xiong, Hui Shu",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00313",
    "source": "IEEE",
    "abstract": "Mail has become a crucial tool in daily work and communication, making the security testing of mail protocols essential for identifying potential vulnerabilities. Fuzzing, as one of the most widely adopted vulnerability discovery techniques, has evolved into an automated and mature method extensively applied in both software and protocol testing across industry. Recently, several fuzzers targeting network protocols have been proposed; however, they suffer from notable limitations. These include insufficient or imprecise representations of protocol states, often relying on generalized state models that fail to capture the specific internal states of individual protocols.In this paper, we address these limitations by proposing SPFuzz, a state-aware fuzzing approach for mail protocols based on program states. We investigate typical implementations of mail protocol services to determine how their internal program states interact with clients. First, we model the program state using key variables; then, we perform compile-time instrumentation to track these variables and infer runtime state transitions of the mail protocol implementations. Finally, we leverage the state information to prioritize test cases that are more likely to trigger new states and apply state feedback to refine the mutation strategy of a coverage-guided fuzzer. We implemented a prototype of SPFuzz and evaluated it on multiple real-world mail protocol programs. Experimental results demonstrate that SPFuzz significantly outperforms state-of-the-art fuzzers, including AFLNET and StateAFL, in terms of both code and state coverage. Specifically, SPFuzz achieves average improvements of 148.75% in the number of discovered states, 7.09% in state space coverage, 43.98% in map density, and 11.48% in branch coverage.",
    "title_zh": "SPFuzz：面向程序状态的邮件协议模糊测试",
    "abstract_zh": "邮件已成为日常工作中不可或缺的沟通工具，因此对邮件协议的安全性测试变得至关重要，以识别潜在漏洞。模糊测试（Fuzzing）作为目前最广泛采用的漏洞发现技术之一，已发展为一种自动化且成熟的测试方法，被广泛应用于工业界软件和协议测试中。近年来，尽管已有多种针对网络协议的模糊测试工具被提出，但它们仍存在显著局限性，主要体现在对协议状态的表示不足或不够精确，通常依赖于通用的状态模型，难以准确捕捉特定协议的内部状态变化。\n\n本文针对上述问题，提出了一种基于程序状态的、具备状态感知能力的邮件协议模糊测试方法——SPFuzz。我们深入研究了典型邮件协议服务的实现方式，分析其内部程序状态与客户端之间的交互机制。首先，通过关键变量对程序状态进行建模；接着，在编译时进行插桩，以追踪这些变量并推断邮件协议实现的运行时状态转移过程；最后，利用获得的状态信息来优先选择更可能触发新状态的测试用例，并将状态反馈用于优化基于覆盖率引导的模糊测试器的变异策略。\n\n我们实现了一个SPFuzz的原型系统，并在多个真实世界的邮件协议程序上进行了评估。实验结果表明，SPFuzz在代码覆盖率和状态覆盖率方面均显著优于当前最先进的模糊测试工具，包括AFLNET和StateAFL。具体而言，SPFuzz在发现状态数量上平均提升了148.75%，在状态空间覆盖率上提升了7.09%，在映射密度上提升了43.98%，在分支覆盖率上提升了11.48%。"
  },
  {
    "date": "2026-2-2",
    "title": "HiFi-XAI: A Fidelity-Aware, LLM-Powered Framework for Trustworthy Intrusion Detection",
    "authors": "Avinash Awasthi, Pritam Vediya, Hemant Miranka, Ramesh Babu Battula, Priyadarsi Nanda",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00379",
    "source": "IEEE",
    "abstract": "The increasing deployment of complex \"black box\" AI models in anomaly-based Intrusion Detection Systems (IDS) for future networks has opened up a trust gap that requires human-interpretable explanations in order for analysts to feel confident in acting on alerts. Current approaches to Explainable AI (XAI), such as SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations), do not properly address the challenges inherent in the problem domain. These techniques fundamentally fail from a fidelity standpoint due to their incorrect assumption of independence between features that results in untrustworthy explanations, which are fundamentally based on correlated network data. We address these shortcomings by proposing HiFi-XAI, which leverages a new, novel framework to provide faithful and semantically rich explanations. HiFi-XAI introduces a model-agnostic Conditional Value Attribution Explanation (CVAE), a method based on probabilistic Shapley values that models feature dependencies to ensure explanations are derived from plausible data distributions. These high-fidelity attributions are then translated into actionable, natural-language narratives by a fine-tuned Large Language Model (LLM). We validate our framework through allaware scenario feature ablation studies on the CICIDS2017 and CICIOT2023 datasets. This demonstrates that CVAE consistently identifies more impactful features than SHAP and LIME across five anomaly-based IDS models. Furthermore, we deploy the HiFi-XAI to prove its practical feasibility and test it on a resource-constrained Raspberry Pi 4. Our work presents a complete, end-to-end solution for building trust in AI-driven IDS.",
    "title_zh": "HiFi-XAI：一种注重保真度的、基于大语言模型的可信入侵检测框架",
    "abstract_zh": "未来网络中，复杂“黑箱”型人工智能模型在基于异常的入侵检测系统（IDS）中的日益广泛应用，引发了一个信任缺口。为使分析人员能够对警报产生信心并采取行动，亟需提供人类可理解的解释。当前的可解释人工智能（XAI）方法，如SHAP（SHapley Additive exPlanations）和LIME（局部可解释模型无关解释），未能有效应对该问题领域固有的挑战。这些方法在保真度方面存在根本性缺陷，源于其对特征间独立性的错误假设，导致在高度相关的网络数据基础上生成不可靠的解释。为解决上述问题，我们提出HiFi-XAI，这是一种基于全新框架的可解释方法，能够提供高保真度且语义丰富的解释。HiFi-XAI引入了一种模型无关的条件值归因解释（CVAE）方法，该方法基于概率Shapley值，建模特征间的依赖关系，确保解释基于合理的数据分布。随后，通过微调的大语言模型（LLM），将这些高保真度的归因结果转化为可操作、自然语言风格的叙述。我们在CICIDS2017和CICIOT2023数据集上，通过全场景特征消融实验验证了该框架的有效性。结果表明，CVAE在五种基于异常的IDS模型中，始终能比SHAP和LIME识别出更具影响力的特征。此外，我们将HiFi-XAI部署于资源受限的树莓派4上，验证了其实际可行性。本研究提供了一个完整、端到端的解决方案，旨在建立人工智能驱动的入侵检测系统中的可信度。"
  },
  {
    "date": "2026-2-2",
    "title": "OmniNova: A General Multimodal Multi-Agent Framework",
    "authors": "Bingzhen Li, Zihan Wang, Pengfei Du, Yupeng Jiang",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00393",
    "source": "IEEE",
    "abstract": "The integration of Large Language Models (LLMs) with external tools enables intelligent automation far beyond text generation, yet coordinating multiple LLM-based agents remains difficult due to interaction overhead, resource waste, and fragile information flow. This paper introduces OmniNova, a modular and hierarchical multi-agent framework that unifies language models with capabilities for web search, browser automation, and code execution. OmniNova advances the state of the art through a hierarchical architecture that separates coordination, planning, supervision, and specialization; a dynamic routing mechanism that activates agents according to task complexity and state; and a multi-layered LLM integration strategy that allocates high-capability reasoning models only where they are cognitively necessary while assigning routine work to lighter models. Across 50 complex tasks in research, data analysis, and web interaction, OmniNova improves task completion (87% versus a 62% baseline), reduces token usage by 41%, and delivers higher human-rated quality (4.2/5 versus 3.1/5). The contribution includes both a principled system design and an open-source implementation intended to support research and practical deployment. Code is available at https://github.com/Superagentsys/OmniNoval.git.",
    "title_zh": "OmniNova：一种通用的多模态多智能体框架",
    "abstract_zh": "将大型语言模型（LLMs）与外部工具相结合，可实现远超文本生成的智能自动化。然而，由于交互开销大、资源浪费严重以及信息流脆弱，协调多个基于LLM的智能体仍面临挑战。本文提出OmniNova，一种模块化且分层的多智能体框架，将语言模型与网络搜索、浏览器自动化及代码执行等能力深度融合。OmniNova通过以下创新推动了该领域的技术前沿：采用分层架构，将协调、规划、监督和专业化功能分离；设计动态路由机制，根据任务复杂度和当前状态激活相应智能体；实施多层次LLM集成策略，在认知需求高的环节仅启用高性能推理模型，而将常规任务交由轻量级模型处理。在科研、数据分析和网络交互等50个复杂任务上的实验表明，OmniNova显著提升了任务完成率（87% vs 基线62%），token使用量减少41%，并获得更高的人工评分质量（4.2/5 vs 3.1/5）。本研究的贡献不仅在于一套严谨的系统设计，还包括一个开源实现，旨在支持学术研究与实际部署。代码已公开，地址为：https://github.com/Superagentsys/OmniNoval.git。"
  },
  {
    "date": "2026-2-2",
    "title": "On-Chain Risk Signals: Predicting Security Threats in DeFi Projects",
    "authors": "Bahareh Parhizkari, Antonio Ken Iannillo, Ed Zulkoski, Christof Ferreira Torres, Radu State",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00112",
    "source": "IEEE",
    "abstract": "Blockchain has revolutionized finance through decentralization, eliminating the need for traditional intermediaries. However, security concerns remain a major barrier to adoption, as DeFi platforms increasingly face targeted attacks. In this paper, we present the first methodology for automatically assessing and quantifying the risk of fund loss in DeFi projects due to smart contract exploits. By analyzing on-chain behaviors that signal potential malicious interactions, our approach assigns a dynamic risk score to DeFi projects over time. Relying solely on on-chain data ensures resistance to data manipulation and enhances the integrity of the assessment.We evaluated 220 compromised and 200 unaffected DeFi projects on multiple EVM-compatible blockchains – including Ethereum, BSC, Polygon, Arbitrum, Optimism, and Fantom – and conducted a comparative risk assessment on these projects. Our findings reveal statistically significant differences in risk scores before attacks compared to a control group without attacks. We anticipated potential threats to 86% of the projects that were later attacked, one day before the incidents, with a precision of 78%.",
    "title_zh": "链上风险信号：预测去中心化金融项目的安全威胁",
    "abstract_zh": "区块链通过去中心化彻底改变了金融行业，消除了对传统中介的需求。然而，安全问题仍是阻碍其广泛采用的主要障碍，因为去中心化金融（DeFi）平台正面临日益增多的针对性攻击。本文提出了首个自动评估和量化DeFi项目因智能合约漏洞导致资金损失风险的方法。通过分析表明潜在恶意交互的链上行为，我们的方法能够动态地为DeFi项目随时间变化赋予风险评分。该方法仅依赖链上数据，确保了对数据篡改的抗性，从而提升了评估结果的可靠性。\n\n我们对多个EVM兼容区块链（包括以太坊、币安智能链BSC、Polygon、Arbitrum、Optimism和Fantom）上的220个已遭攻击项目和200个未受影响的项目进行了评估，并对这些项目进行了对比风险分析。研究结果表明，在攻击发生前，受攻击项目的风险评分与未受攻击的对照组之间存在统计学意义上的显著差异。我们提前一天成功预判了86%后续遭受攻击的项目，预测精度达到78%。"
  },
  {
    "date": "2026-2-2",
    "title": "Model-based Development for Event-driven and Timer-driven ROS 2 Nodes Considering Parallelization",
    "authors": "Kenshin Obi, Takumi Onozawa, Ryo Yoshinaka, Hiroshi Fujimoto, Takuya Azumi",
    "publish": "IEEE Open Journal of the Industrial Electronics Society",
    "url": "https://doi.org/10.1109/ojies.2026.3659855",
    "source": "IEEE",
    "abstract": "In recent years, the increasing complexity of industrial cyber-physical systems such as autonomous vehicles has tightened real-time constraints, yet conventional <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">model-based development</i> (MBD) does not always exploit embedded multi/many-core processors effectively. Practical obstacles include the need to manually implement ROS 2 I/O and node structure even with a Simulink model, the requirement in ROS 2 to handle execution timing such as event-driven and timer-driven callbacks and multi-input synchronization, and the fact that parallelization often must be repeated for each target hardware configuration. Although <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Model-based Parallelizer</i> (MBP) can generate task-parallel code from Simulink models, its support for MATLAB/Simulink Toolbox blocks (e.g., ROS Toolbox) is limited, and lacking data parallelism, speedup is hard to obtain. This paper proposes a Simulink-to-ROS 2 parallel code generation method that automatically generates parallelized ROS 2 C++ nodes from Simulink models that include Toolbox blocks, eliminating manual node I/O implementation and extra parallelization effort. The proposed method converts Toolbox-dependent portions into an MBP-applicable representation while extracting ROS 2 metadata and applying SHIM-based core allocation. It preserves Toolbox-equivalent functionality while preventing excessive block reduction from degrading parallelism, and generates ROS 2 C++ nodes that support event-driven and timer-driven execution with optional multi-topic time synchronization. Functional correctness is validated through split-merge-based verification and back-to-back tests using identical rosbag2 inputs. Beyond single-node execution time, the method measures end-to-end pipeline execution time across multiple nodes and ROS 2 latency; variability is quantified using empirical WCET (maximum over 1,000 runs), jitter, and variance. Autoware Universe-derived ROS 2 nodes are evaluated on Raspberry Pi 4 and the Kalray MPPA Coolidge 2 platform, demonstrating up to 15.92 times speedup on a 16-core Coolidge configuration. In a WSL2 planning-to-control pipeline evaluation, increasing intra-node parallelism from 1 to 8 threads reduces mean latency from 87.41 ms to 20.67 ms, while ROS 2 communication and scheduling latency remains below 1% of a 100 ms cycle. These results demonstrate practical, reproducible high-performance ROS 2 deployment on embedded platforms using Toolbox-based MBD.",
    "title_zh": "考虑并行化的事件驱动与定时驱动型ROS 2节点的模型驱动开发",
    "abstract_zh": "近年来，随着自动驾驶等工业网络物理系统复杂性的不断提高，实时性约束日益严格，而传统的基于模型开发（Model-based Development, MBD）方法在利用嵌入式多/众核处理器方面往往效率不足。实际应用中面临诸多挑战：即使使用Simulink模型，仍需手动实现ROS 2的I/O接口和节点结构；ROS 2要求处理执行时序问题，如事件驱动和定时器驱动的回调机制，以及多输入同步；此外，通常需要针对每种目标硬件配置重复进行并行化设计。尽管基于模型的并行化工具（Model-based Parallelizer, MBP）能够从Simulink模型生成任务级并行代码，但其对MATLAB/Simulink工具箱模块（如ROS Toolbox）的支持有限，且缺乏数据并行能力，导致难以获得显著加速效果。\n\n本文提出一种从Simulink到ROS 2的并行代码自动生成方法，可自动将包含工具箱模块的Simulink模型转换为并行化的ROS 2 C++节点，从而消除手动编写节点I/O接口和额外并行化工作。所提方法将依赖工具箱的部分转换为MBP可处理的表示形式，同时提取ROS 2元数据，并采用SHIM机制实现核心资源分配。该方法在保持工具箱等效功能的同时，避免因过度简化模块而导致并行度下降，生成的ROS 2 C++节点支持事件驱动与定时器驱动的执行模式，并可选地实现多话题时间同步功能。\n\n功能正确性通过基于分拆-合并的验证方法以及使用相同rosbag2输入的前后端测试进行验证。除单节点执行时间外，本方法还评估了跨多个节点的端到端流水线执行时间及ROS 2通信延迟；通过1000次运行的实测最大执行时间（WCET）、抖动（jitter）和方差等指标量化了执行时间的变异性。\n\n在Raspberry Pi 4和Kalray MPPA Coolidge 2平台上的Autoware Universe衍生ROS 2节点评估表明，在16核Coolidge配置下，性能最高可提升15.92倍。在WSL2环境下的规划-控制流水线测试中，将节点内并行度从1线程提升至8线程，平均延迟由87.41 ms降低至20.67 ms，而ROS 2通信与调度延迟始终低于100 ms周期的1%。\n\n实验结果表明，该方法能够实现基于工具箱的MBD在嵌入式平台上的高效、可复现的高性能ROS 2部署，为复杂工业系统提供了实用且可靠的开发路径。"
  },
  {
    "date": "2026-2-2",
    "title": "Method for Monitoring and Intelligent Fault Repair of Secure Operating Systems for Power Grid Informatization Terminals",
    "authors": "Tong Li, Shuai Ren, Dongyu Li, Jian Chen, Zhanguo Wang, Weiwei Zou",
    "publish": "2025 5th International Conference on Electrical Engineering and Control Science (IC2ECS)",
    "url": "https://doi.org/10.1109/ic2ecs68700.2025.11361767",
    "source": "IEEE",
    "abstract": "For the security operating system of the power grid information innovation terminal, the monitoring system status in the regular inspection mode relies too much on experience. Therefore, this paper studies the monitoring and intelligent fault repair methods for the security operating system of the power grid information innovation terminal. Deploy real-time monitoring architecture, integrate security requirements and potential faults, configure multiple lightweight sensors, and achieve comprehensive monitoring. Detect anomalies through real-time monitoring of information and perform secure operating system fault diagnosis. Carry out fault layered repair, focusing on the key issues of eliminating error states and restoring execution states, following strict standards, and adopting corresponding repair strategies for different fault levels to build a complete fault recovery system and promote the construction of power grid informationization. The experimental results show that in terms of security indicators, the attack interception rate of this method reaches 92.3%, with only 2 data leaks and 0 unauthorized peripheral access, and a compliance rate of 99.7%; The fault monitoring delay experiment showed that all three types of fault monitoring delays were controlled within $\\mathbf{0. 2} \\boldsymbol{\\sim} \\mathbf{0. 9 m s}$. After repair, the fault rates of $\\mathbf{1 2}$ types of power grids were significantly reduced, and this method has practical application value.",
    "title_zh": "电网信息化终端安全操作系统监测与智能故障修复方法",
    "abstract_zh": "针对电网信息创新终端安全操作系统在常规巡检模式下，监控系统状态过度依赖经验的问题，本文研究了该系统的监控与智能故障修复方法。通过部署实时监控架构，融合安全需求与潜在故障，配置多种轻量级传感器，实现全面监控；通过对信息的实时监控检测异常，并进行安全操作系统的故障诊断。采用分层故障修复策略，重点解决消除错误状态和恢复执行状态的关键问题，遵循严格标准，针对不同故障等级采取相应的修复措施，构建完整的故障恢复体系，推动电网信息化建设。实验结果表明：在安全指标方面，该方法的攻击拦截率达到92.3%，仅发生2次数据泄露，0次非法外设访问，合规率达99.7%；故障监控延迟实验显示，三类故障的监控延迟均控制在$\\mathbf{0.2} \\sim \\mathbf{0.9\\,ms}$范围内；修复后，12类电网的故障率显著降低，具有良好的实际应用价值。"
  },
  {
    "date": "2026-2-2",
    "title": "ChatNVD: Advancing Cybersecurity Vulnerability Assessment with Large Language Models",
    "authors": "Shivansh Chopra, Hussain Ahmad, Diksha Goel, Claudia Szabo",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3659205",
    "source": "IEEE",
    "abstract": "The increasing frequency and sophistication of cybersecurity vulnerabilities in software systems underscores the need for robust and reliable vulnerability assessment methods. However, existing approaches often rely on highly technical and abstract frameworks, limiting accessibility for practitioners and increasing the risk of exploitation. In this paper, we introduce ChatNVD, a support tool powered by Large Language Models (LLMs) that leverages the National Vulnerability Database (NVD) to enhance the accessibility of vulnerability information. We develop three variants of ChatNVD using GPT-4o Mini (OpenAI), LLaMA 3 (Meta), and Gemini 1.5 Pro (Google). To evaluate their performance, we design a benchmark of structured queries derived from real CVE records, covering temporal, descriptive, and metric-based attributes. Our results show that GPT-4o Mini consistently outperforms the other models, achieving over 92% exact-match accuracy with lower hallucination and error rates. These findings demonstrate the potential of lightweight, retrieval-augmented LLM workflows for supporting vulnerability management and operational decision-making in cybersecurity contexts.",
    "title_zh": "ChatNVD：利用大语言模型推进网络安全漏洞评估",
    "abstract_zh": "软件系统中网络安全漏洞的频率和复杂性日益增加，凸显了对强大且可靠漏洞评估方法的需求。然而，现有方法通常依赖于高度技术化和抽象的框架，限制了实践者的使用便利性，并增加了被利用的风险。本文提出了一款基于大语言模型（LLMs）的辅助工具——ChatNVD，该工具利用国家漏洞数据库（NVD）来提升漏洞信息的可访问性。我们基于GPT-4o Mini（OpenAI）、LLaMA 3（Meta）和Gemini 1.5 Pro（Google）开发了ChatNVD的三个变体。为评估其性能，我们设计了一个由真实CVE记录衍生的结构化查询基准，涵盖时间、描述性和度量属性。实验结果表明，GPT-4o Mini在各项指标上均显著优于其他模型，实现了超过92%的精确匹配准确率，同时表现出更低的幻觉和错误率。这些发现证明了轻量级、检索增强型大语言模型工作流在支持网络安全漏洞管理及运营决策方面的巨大潜力。"
  },
  {
    "date": "2026-2-2",
    "title": "A Knowledge Assistant for Semiconductor Fault Diagnosis Using an LLM-Enhanced Case-Based Reasoning Framework",
    "authors": "Hyunseop Park, Hyungjae Yoo, Junho Lee, Jaegun Kim, Hyunwoo Cha, Minah Park, Davin Lee, Sungmin Cho, Euisuk Kum",
    "publish": "2025 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)",
    "url": "https://doi.org/10.1109/ieem63636.2025.11357845",
    "source": "IEEE",
    "abstract": "Semiconductor manufacturing is increasingly complex, making defect diagnosis and resolution more challenging. As a result, engineers require extensive domain knowledge and expertise to effectively analyze failures and implement corrective actions. This study proposes an LLM-enhanced Knowledge Assistant based on a Case-Based Reasoning (CBR) framework to improve semiconductor fault diagnosis. The CBR framework systematically accumulates and reuses semiconductor-related question-and-answer (QA) data, while LLMs enhance case retrieval and adaptation for more accurate defect analysis. Experimental evaluations show that our approach improves response accuracy by 27% and increases user satisfaction by 0.94 points on a 5-point scale, compared to the baseline model. This research accelerates defect resolution by enabling real-time knowledge acquisition and reuse, enhancing semiconductor manufacturing efficiency.",
    "title_zh": "基于大语言模型增强的案例推理框架的半导体故障诊断知识助手",
    "abstract_zh": "半导体制造日益复杂，导致缺陷诊断与解决愈发困难。因此，工程师需要具备丰富的领域知识和专业经验，才能有效分析故障并实施纠正措施。本研究提出了一种基于案例推理（Case-Based Reasoning, CBR）框架的LLM增强型知识助手，以提升半导体故障诊断能力。该CBR框架系统性地积累和复用与半导体相关的问答（QA）数据，而大语言模型（LLM）则增强了案例的检索与适应能力，从而实现更精准的缺陷分析。实验评估表明，与基线模型相比，本方法将响应准确率提升了27%，用户满意度在5分制量表上提高了0.94分。该研究通过实现知识的实时获取与复用，加速了缺陷的解决过程，显著提升了半导体制造的效率。"
  },
  {
    "date": "2026-2-2",
    "title": "TrustSciAgent: Towards Rigorous and Trustworthy Agents for Scientific Research",
    "authors": "Yang Li, Meng Wang, Mengting Zhang, Zhixiong Zhang, Guangyin Zhang, Hanyu Li",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00384",
    "source": "IEEE",
    "abstract": "Large language models have enabled automated agents to tackle complex scientific research tasks, yet most existing approaches struggle to deliver scientifically rigorous and verifiable outputs. In this work, we propose a novel agent framework, TrustSciAgent, which introduces a unified evidence–reasoning–validation pipeline explicitly governed by newly formulated scientific research trustworthiness principles. TrustSciAgent structurally organizes the entire research process into pre-research, in-research, and post-research phases, ensuring that each stage strictly adheres to these principles. This design compels the agent to generate transparent, logically sound reasoning chains and deliver auditable scientific conclusions. Comprehensive experiments across four scientific domains and three representative language models demonstrate that TrustSciAgent consistently improves both the structural completeness and the correctness of reasoning outputs, outperforming standard LLM-based agents. Our results provide strong evidence that embedding domain-agnostic trustworthiness principles into the agent workflow is critical for enabling credible, generalizable, and verifiable automated scientific research.",
    "title_zh": "TrustSciAgent：面向严谨可信的科学研究代理",
    "abstract_zh": "大型语言模型已使自动化智能体能够处理复杂的科学研究任务，然而现有大多数方法在生成科学上严谨且可验证的成果方面仍面临挑战。本文提出一种新型智能体框架——TrustSciAgent，该框架引入了一个统一的“证据—推理—验证”流程，并由新提出的科学研究可信性原则明确指导。TrustSciAgent将整个研究过程结构化地划分为研究前、研究中和研究后三个阶段，确保每个阶段均严格遵循这些可信性原则。这一设计促使智能体生成透明、逻辑严密的推理链条，并输出可审计的科学结论。我们在四个科学领域及三种代表性语言模型上开展的全面实验表明，TrustSciAgent在推理输出的结构完整性和正确性方面均显著优于传统的基于大语言模型的智能体。结果有力证明，将领域无关的可信性原则嵌入智能体工作流程，对于实现可信、可泛化且可验证的自动化科学研究至关重要。"
  },
  {
    "date": "2026-2-2",
    "title": "An Auxiliary Inference Method for Electronic Component Failure Causes Based on Neighborhood Aggregation and a OvR-Logistic Regression Framework",
    "authors": "Huixin Liu, Chuanwen Wu, Xiaoli Bao, Zeyu Sun, Yajing Guo, Yang Wang",
    "publish": "2025 5th International Conference on Electrical Engineering and Control Science (IC2ECS)",
    "url": "https://doi.org/10.1109/ic2ecs68700.2025.11361661",
    "source": "IEEE",
    "abstract": "Ensuring the reliability of electronic components is crucial for complex aerospace and defense systems. Traditional failure-cause analysis relies heavily on expert interpretation of textual reports, which limits efficiency and scalability. To address this challenge, this study proposes an auxiliary inference model that integrates Sentence-BERT-based semantic embedding, FAISS-based neighborhood aggregation, and a One-vs-Rest Logistic Regression framework. The model fuses global semantic and local contextual features, enhancing discrimination among semantically similar failure descriptions while maintaining interpretability. Experimental results demonstrate that the proposed method achieves superior performance compared with multiple baseline classifiers, attaining a weighted F1-score of 94.33%. The approach provides a lightweight, extensible, and explainable solution for intelligent failure-cause inference, supporting data-driven reliability assessment and knowledgebased decision-making in component quality management.",
    "title_zh": "一种基于邻域聚合与OvR-逻辑回归框架的电子元器件故障原因辅助推理方法",
    "abstract_zh": "确保电子元器件的可靠性对于复杂的航空航天和国防系统至关重要。传统的故障原因分析严重依赖专家对文本报告的解读，这限制了效率与可扩展性。为应对这一挑战，本研究提出了一种辅助推理模型，该模型融合了基于Sentence-BERT的语义嵌入、基于FAISS的邻域聚合以及One-vs-Rest逻辑回归框架。该模型综合了全局语义特征与局部上下文信息，在保持可解释性的前提下，有效提升了对语义相似故障描述的区分能力。实验结果表明，所提方法在多个基准分类器中表现优异，达到了94.33%的加权F1分数。该方法提供了一种轻量、可扩展且可解释的智能故障原因推断解决方案，支持基于数据的可靠性评估与基于知识的元器件质量管理决策。"
  },
  {
    "date": "2026-2-2",
    "title": "Software-Defined Product Architecture: Status, Challenges, and Future Perspectives",
    "authors": "J. Lee, J. Kim, S. J. Park, J. Lee, B. Song, S. K. Moon",
    "publish": "2025 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)",
    "url": "https://doi.org/10.1109/ieem63636.2025.11357662",
    "source": "IEEE",
    "abstract": "The rise of Software-Defined Products (SDPs) marks a significant shift in product development, where software rather than hardware determines core functionalities, differentiation, and value. This review provides technological insights into the current landscape, challenges and potential direction of SDPs. First, representative applications and trends in automotive, consumer electronics, and medical device sectors are reviewed to illustrate the current status of SDPs. Next, four key technologies including hardware-software decoupling, AI-driven product design and development, modular digital twins and digital manufacturing are investigated and proposed to achieve SDPs. Furthermore, potential challenges in implementing these technologies are examined, along with proposed components of building Software-Defined Product Architecture (SDPA). The review concludes by highlighting future research needs, including advanced hardware abstraction for standardization, adaptive intelligence for transparency, a unified data layer, a redefined product module architecture, and security and governance for system resilience.",
    "title_zh": "软件定义产品架构：现状、挑战与未来展望",
    "abstract_zh": "软件定义产品（SDPs）的兴起标志着产品开发领域的一次重大转变，即软件而非硬件成为决定核心功能、差异化和价值的关键因素。本文综述了当前SDP的技术现状、面临的挑战以及未来的发展方向。首先，文章回顾了汽车、消费电子和医疗设备等领域的代表性应用与发展趋势，以展示SDP的当前发展状况。接着，探讨并提出了四项关键技术，包括软硬件解耦、基于人工智能的产品设计与开发、模块化数字孪生以及数字化制造，这些技术有望推动SDP的实现。此外，文章还分析了实施这些技术可能面临的潜在挑战，并提出了构建软件定义产品架构（SDPA）所需的关键组成部分。最后，文章总结指出未来研究亟需关注的几个方面：先进的硬件抽象以实现标准化、自适应智能以增强透明度、统一的数据层、重新定义的产品模块架构，以及保障系统韧性的安全与治理机制。"
  },
  {
    "date": "2026-2-2",
    "title": "LLM-Assisted IDOR Detection in Hospital Mini-Programs: Risks to PII and PHI",
    "authors": "Jiawen Sun, Rui Tian, Shangru Zhao, Xiangming Zhou, He Wang, Yuqing Zhang",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00242",
    "source": "IEEE",
    "abstract": "Hospital mini-programs have become widely adopted as lightweight portals for medical services, handling large volumes of personally identifiable information (PII) and protected health information (PHI). Among the most critical threats to such systems is the insecure direct object reference (IDOR) vulnerability, which allows unauthorized access to sensitive resources due to improper object–level access control. However, systematic detection of IDOR in the wild, especially within hospital mini-programs, remains underexplored due to restricted server access and stringent ethical regulations. To address this challenge, we propose a black–box detection framework designed for hospital mini-programs operating in sensitive data environments. Our framework introduces a novel token–substitution probing strategy that adheres to ethical standards and pioneers the use of Large Language Models (LLMs) for automated IDOR vulnerability detection in API endpoints, enabling token field identification, request classification and differential response analysis. We evaluated the framework on 80 real-world mini-programs and identified 114 vulnerable endpoints across 38 applications. Among these, 55 involved sensitive data disclosure, and 34 enabled unauthorized execution of sensitive operations. All findings were responsibly disclosed to the CNVD, and 15 cases have been officially confirmed.",
    "title_zh": "基于大语言模型的医院小程序IDOR检测：对个人身份信息与个人健康信息的风险",
    "abstract_zh": "医院小程序已广泛作为轻量级医疗服务平台，处理大量个人身份信息（PII）和受保护的健康信息（PHI）。其中，最严重的安全威胁之一是不安全的直接对象引用（IDOR）漏洞，该漏洞由于对象级别的访问控制不当，导致未经授权的用户可访问敏感资源。然而，由于服务器访问受限及严格的伦理规范，针对实际环境中医院小程序的IDOR漏洞进行系统性检测仍鲜有研究。为应对这一挑战，我们提出了一种专为敏感数据环境下的医院小程序设计的黑盒检测框架。该框架引入了一种新颖的令牌替换探测策略，符合伦理要求，并首次将大型语言模型（LLMs）应用于API端点的自动化IDOR漏洞检测，实现了令牌字段识别、请求分类以及差异响应分析。我们在80个真实世界的小程序中评估了该框架，共发现38个应用中的114个存在漏洞的端点，其中55个涉及敏感数据泄露，34个允许未经授权执行敏感操作。所有发现均已负责任地报告至国家信息安全漏洞共享平台（CNVD），其中15个案例已获官方确认。"
  },
  {
    "date": "2026-2-2",
    "title": "Deep Learning Assisted Reverse Engineering: Recognizing Encryption Loops in Ransomware",
    "authors": "Nanqing Luo, Haizhou Wang, Zhilong Wang, Lan Zhang, Ping Chen, Peng Liu",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00126",
    "source": "IEEE",
    "abstract": "Reverse Engineering (RE) is a critical task performed by security professionals for various purposes. However, the complexity and exertion of malware reverse engineering, particularly for ransomware, have posed significant challenges to experts in the field. In response, this study explores the feasibility of incorporating deep learning techniques to assist the ransomware reverse engineering (RE). To tackle specific challenges of encryption loop recognition, our approach employs two learning strategies. Firstly, we develop code-obfuscation-resilient and encryption-algorithm-agnostic features, including K-complexity and operations that yield equiprobable outputs. Secondly, we carefully select a neural network architecture capable of extracting informative features. The evaluation of our toolchain shows that our toolchain achieves an accuracy of 99% on the test set. Our method exhibits strong generalization capabilities, as it successfully handled common code obfuscation schemes, proprietary and unknown ciphers. When applied to real-world ransomware samples such as WannaCry, Conti, Lockbit, and TeslaCryt, our toolchain effectively identified 205 encryption loops with a low false positive rate of 6.8%. These findings validate the effectiveness of our approach in automatically recognizing encryption code during ransomware reverse engineering.",
    "title_zh": "深度学习辅助逆向工程：识别勒索软件中的加密循环",
    "abstract_zh": "逆向工程（RE）是安全专业人员为多种目的执行的关键任务。然而，恶意软件逆向工程，尤其是勒索软件的逆向工程，其复杂性和工作强度给该领域的专家带来了重大挑战。为此，本研究探讨了将深度学习技术引入勒索软件逆向工程（RE）以提供辅助的可行性。针对加密循环识别中的特定挑战，我们的方法采用了两种学习策略：首先，我们开发了抗代码混淆且与加密算法无关的特征，包括K-复杂度以及产生等概率输出的操作；其次，我们精心选择了一种能够有效提取信息特征的神经网络架构。对我们的工具链进行评估的结果显示，该工具链在测试集上达到了99%的准确率。我们的方法表现出强大的泛化能力，成功应对了常见的代码混淆技术、专有加密算法以及未知加密算法。当应用于WannaCry、Conti、Lockbit和TeslaCryt等真实世界中的勒索软件样本时，我们的工具链成功识别出205个加密循环，且误报率仅为6.8%。这些结果验证了该方法在自动识别勒索软件逆向工程中加密代码方面的有效性。"
  },
  {
    "date": "2026-2-2",
    "title": "ReviewGuard: Enhancing Deficient Peer Review Detection via LLM-Driven Data Augmentation",
    "authors": "Haoxuan Zhang, Ruochi Li, Sarthak Shrestha, Shree Harshini Mamidala, Revanth Putta, Arka Krishan Aggarwal, Ting Xiao, Junhua Ding, Haihua Chen",
    "publish": "2025 ACM/IEEE Joint Conference on Digital Libraries (JCDL)",
    "url": "https://doi.org/10.1109/jcdl67857.2025.00032",
    "source": "IEEE",
    "abstract": "Peer review serves as the gatekeeper of science, yet the surge in submissions and widespread adoption of large language models (LLMs) in scholarly evaluation present unprecedented challenges. While recent work has focused on using LLMs to improve review efficiency, unchecked deficient reviews from both human experts and AI systems threaten to systematically undermine academic integrity. To address this issue, we introduce ReviewGuard, an automated system for detecting and categorizing deficient reviews through a four-stage LLM-driven framework: data collection from ICLR and NeurIPS on OpenReview, GPT-4.1 annotation with human validation, synthetic data augmentation yielding $\\mathbf{6, 6 3 4}$ papers with 24,657 real and 46,438 synthetic reviews, and fine-tuning of encoderbased models and open-source LLMs. Feature analysis reveals that deficient reviews exhibit lower rating scores, higher self-reported confidence, reduced structural complexity, and more negative sentiment than sufficient reviews. AI-generated text detection shows dramatic increases in AI-authored reviews since ChatGPT’s emergence. Mixed training with synthetic and real data substantially improves detection performance-for example, Qwen 3-8B achieves recall of 0.6653 and F1 of 0.7073, up from 0.5499 and 0.5606 respectively. This study presents the first LLMdriven system for detecting deficient peer reviews, providing evidence to inform AI governance in peer review. Code, prompts, and data are available at GitHub Repository.",
    "title_zh": "ReviewGuard：通过大语言模型驱动的数据增强提升缺陷同行评审检测",
    "abstract_zh": "同行评审是科学的守门人，然而投稿量的激增以及大型语言模型（LLMs）在学术评价中的广泛应用，带来了前所未有的挑战。尽管近期研究聚焦于利用LLM提升评审效率，但人类专家与AI系统产生的未经审核的低质量评审，正系统性地威胁着学术诚信。为应对这一问题，我们提出ReviewGuard——一种基于四阶段LLM驱动框架的自动化系统，用于检测并分类低质量评审：从OpenReview平台收集ICLR与NeurIPS的评审数据，使用GPT-4.1进行标注并经人工验证，通过合成数据增强生成了6,634篇论文的24,657条真实评审与46,438条合成评审，并对基于编码器的模型及开源LLM进行微调。特征分析表明，低质量评审相较于充分评审具有更低的评分、更高的自我报告置信度、更弱的结构复杂性以及更强烈的负面情绪。AI生成文本检测结果显示，自ChatGPT发布以来，AI撰写的评审数量显著增加。混合使用合成数据与真实数据进行训练，显著提升了检测性能——例如，Qwen 3-8B模型的召回率提升至0.6653，F1分数达到0.7073，分别较此前的0.5499和0.5606有明显改善。本研究首次构建了基于LLM的低质量同行评审检测系统，为AI在同行评审中的治理提供了实证依据。代码、提示模板及数据集已发布于GitHub仓库。"
  },
  {
    "date": "2026-2-2",
    "title": "DeepLancet: Effectively Detecting Deep Learning Library Bugs via LLM-assisted Testcase Generation",
    "authors": "Zihao Luo, Baojian Hua",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00349",
    "source": "IEEE",
    "abstract": "Deep learning libraries such as PyTorch and TensorFlow are essential for building security-critical downstream deep learning applications. Bugs in these libraries compromise their correctness, robustness, and security, thereby undermining the reliability of downstream applications. Unfortunately, effectively detecting bugs in deep learning library remains challenging, as existing approaches often fail to generate effective test cases due to their inability to synthesize complex input constraints that govern deep learning library functions.In this paper, we present DeepLancet, the first approach for effectively detecting deep learning library bugs by leveraging large language models (LLMs) to systematically parse documentation and thereby assist in the generation of high-quality test cases. Our key observation is that mainstream deep learning libraries typically provide comprehensive and well-structured documentation, which contains detailed descriptions of input constraints that we can effectively synthesize and leverage to generate syntactically valid and semantically correct test cases. Specifically, we first synthesize function constraint descriptions from the documentation by leveraging LLMs. We then generate rigorous constraints which are leveraged to generate test cases through an attribution-based approach in Python. Finally, we employ a differential testing approach on CPU and GPU to detect bugs. We build a software prototype for DeepLancet, and our evaluation results demonstrate that DeepLancet is effective in uncovering previously unknown real-world bugs: it successfully uncovers 20 bugs in the latest release of PyTorch, including 7 previously unknown ones. Moreover, we compare DeepLancet with DocTer, a state-of-the-art technique that also leverages documentation for constraint extraction, and the results indicate that DeepLancet can extract more comprehensive constraints, thereby uncovering 3 more bugs that were missed by DocTer.",
    "title_zh": "DeepLancet：通过LLM辅助的测试用例生成有效检测深度学习库漏洞",
    "abstract_zh": "像PyTorch和TensorFlow这样的深度学习库对于构建安全关键型下游深度学习应用至关重要。这些库中的缺陷会损害其正确性、鲁棒性和安全性，从而削弱下游应用的可靠性。然而，有效检测深度学习库中的缺陷仍然极具挑战性，因为现有方法往往难以生成有效的测试用例，主要原因在于它们无法合成控制深度学习库函数的复杂输入约束。\n\n在本文中，我们提出了DeepLancet，这是首个利用大语言模型（LLMs）系统解析文档，从而有效辅助生成高质量测试用例的深度学习库缺陷检测方法。我们的关键观察是：主流深度学习库通常提供全面且结构清晰的文档，其中包含详细的输入约束信息，这些信息可以被有效提取并用于生成语法正确且语义合理的测试用例。\n\n具体而言，我们首先利用大语言模型从文档中合成函数约束描述；随后，基于这些描述生成严格的约束条件，并通过基于属性的Python方法生成测试用例；最后，采用CPU与GPU上的差异测试方法来检测潜在缺陷。我们构建了DeepLancet的软件原型，评估结果表明，该方法能够有效发现此前未知的真实世界缺陷：在最新版PyTorch中成功发现了20个缺陷，其中包括7个此前未被发现的缺陷。此外，我们将DeepLancet与当前最先进的DocTer方法（同样利用文档进行约束提取）进行了对比，结果表明DeepLancet能够提取更全面的约束信息，从而发现了3个DocTer遗漏的缺陷。"
  },
  {
    "date": "2026-2-2",
    "title": "MLSBOX: Automated Sandbox for Fine-Grained Isolation of Multiple Third-Party Libraries\n                    <sup>*</sup>",
    "authors": "Yuqi Qiu, Juan Wang, Chenjun Ma, Yunfeng Kang, Jie Wang",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00095",
    "source": "IEEE",
    "abstract": "In the development process, utilizing the existing functions and interfaces of third-party libraries can significantly reduce development time and resources. However, the introduction of third-party libraries also brings security risks. These libraries may contain defects or vulnerabilities and can even conceal malicious code. Introducing vulnerable third-party libraries can compromise the security of the entire software system. Although existing solutions can provide sandbox environments for libraries, they require extensive modifications to the source code to implement isolation. Furthermore, current sandboxes cannot support the simultaneous isolation of multiple libraries, including memory and privilege isolation. To address these issues, we propose MLSBOX, the first automated sandboxing framework designed to provide fine-grained isolation for multiple untrusted third-party libraries. This sandbox leverages Attribute Program Dependence Graph (APDG) analysis to identify data dependencies from different libraries. It automatically modifies the program at the compiler level to partition the program into multiple independent isolation domains, enforcing memory and privilege isolation for each domain to enhance overall program security. We have successfully implemented a prototype of MLSBOX on LLVM and conducted rigorous functional and performance evaluations on third-party libraries such as OpenSSL and Zlib. MLSBOX provides the most fine-grained memory and permission isolation currently available. In terms of runtime efficiency, MLSBOX incurs an average overhead of 2.50%. For isolating multi-threaded programs, such as a program with 8 threads, MLSBOX incurs a minimal runtime overhead of just 0.80%, significantly lower than that of the current state-of-the-art solution, Cali (365.70%).",
    "title_zh": "MLSBOX：用于细粒度隔离多个第三方库的自动化沙箱\n                    <sup>*</sup>",
    "abstract_zh": "在开发过程中，利用第三方库现有的功能和接口可以显著减少开发时间和资源消耗。然而，引入第三方库也带来了安全风险：这些库可能包含缺陷或漏洞，甚至可能隐藏恶意代码。引入存在漏洞的第三方库，可能会危及整个软件系统的安全性。尽管现有解决方案能够为库提供沙箱环境，但其通常需要对源代码进行大量修改以实现隔离。此外，当前的沙箱机制无法同时对多个库进行隔离，尤其难以实现内存和权限的双重隔离。为解决上述问题，我们提出了MLSBOX——首个专为多个不受信任的第三方库设计的自动化沙箱框架，可提供细粒度的隔离保护。该沙箱通过属性程序依赖图（APDG）分析技术，识别来自不同库之间的数据依赖关系，并在编译器层面自动修改程序，将程序划分为多个独立的隔离域，对每个域强制实施内存与权限隔离，从而全面提升程序的安全性。我们已在LLVM平台上成功实现了MLSBOX原型，并对OpenSSL、Zlib等第三方库进行了严格的功能性与性能评估。MLSBOX目前提供了最细粒度的内存与权限隔离能力。在运行时效率方面，MLSBOX平均开销仅为2.50%；对于多线程程序（如8个线程的程序），其运行时开销低至0.80%，远低于当前最先进的方案Cali（365.70%）的开销水平。"
  },
  {
    "date": "2026-2-2",
    "title": "FaultSpy: On the Insecurity of SPDM Protocols under Fault Injection",
    "authors": "Peiyao Sun, Qifan Wang, David Oswald, Mark Dermot Ryan, Vladimiro Sassone, Ahmad Atamli",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00252",
    "source": "IEEE",
    "abstract": "The Security Protocol and Data Model (SPDM) establishes device-level trust in hardware platforms through authentication, attestation, and secure session establishment. While prior research has focused on formal analyses and deployment considerations, the impact of implementation-level vulnerabilities, particularly under active physical adversaries, remains largely underexplored. This work presents FaultSpy, the first systematic framework for evaluating SPDM against Fault Injection Attacks (FIAs) and their combination with other prominent attack vectors, such as Man-In-The-Middle (MITM) attacks. Leveraging the fault injection simulation tool, FaultFinder, with our custom SPDM-specific hooks, we uncover nine concrete vulnerabilities spanning both threat models. These include bypassing mutual authentication, suppressing signature generation and verification, downgrading negotiated capabilities, skipping mandatory protocol steps, manipulating key update behavior, transmitting messages intended to be encrypted in plaintext, and extracting session keys. We further validate the feasibility of these attacks through practical voltage glitching experiments on an RP2350 microcontroller. Our findings demonstrate that FIAs-whether in isolation or combined with other attacks-significantly expand the SPDM attack surface, highlighting the need for robust implementation-level countermeasures.",
    "title_zh": "FaultSpy：故障注入下SPDM协议的不安全性",
    "abstract_zh": "安全协议与数据模型（SPDM）通过认证、证明和安全会话建立，在硬件平台层面建立了设备级信任。尽管以往研究主要关注形式化分析与部署考量，但实施层面的漏洞，尤其是在主动物理攻击者威胁下的影响，仍鲜有深入探讨。本文提出FaultSpy，这是首个系统性评估SPDM在故障注入攻击（FIA）及其与其他主流攻击向量（如中间人攻击MITM）结合情况下的框架。我们利用故障注入仿真工具FaultFinder，并结合自定义的SPDM专用钩子，发现了九种具体的漏洞，覆盖了两种威胁模型。这些漏洞包括绕过双向认证、抑制签名生成与验证、降低协商能力、跳过强制协议步骤、操纵密钥更新行为、以明文传输本应加密的消息，以及提取会话密钥。我们还通过在RP2350微控制器上进行实际电压干扰实验，验证了这些攻击的可行性。研究结果表明，无论单独存在还是与其他攻击结合，故障注入攻击都显著扩大了SPDM的攻击面，凸显了实施层面防御措施的重要性。"
  },
  {
    "date": "2026-2-2",
    "title": "Reverse generation of substation logic model method from optical cable data",
    "authors": "Xiaoyan Hu, Xiaojing Zhang, Xiaomin Wang",
    "publish": "2025 5th International Conference on Electrical Engineering and Control Science (IC2ECS)",
    "url": "https://doi.org/10.1109/ic2ecs68700.2025.11362306",
    "source": "IEEE",
    "abstract": "Digital substations are a key development focus in China’s power grid during the 15th Five-Year Plan period. As the core component of secondary digital design for substations, logical models face significant challenges in forward engineering due to their complexity and lengthy development cycles. To address this, this paper proposes a method for reverseengineering substation logical models using optical cable data. By scanning electrical secondary drawings (including terminal block diagrams, schematic diagrams, and file information), OCR technology extracts critical data such as cable numbers, circuit numbers, core function descriptions, and terminal cabinet connections. These data are then integrated with logical model specifications to automatically generate interface (interface), connection point (point), core, and cable elements in the Substation Physical Description (SPD). The developed front-end and back-end separated logical model generation system achieved $95.1 \\%, 95.6 \\%, 91.8 \\%$, and $89.6 \\%$ conversion rates for interface, point, core, and cable respectively, with an overall success rate exceeding 90%. Verification through actual engineering drawings demonstrates that this method effectively reduces design workload and supports substation digitalization. However, it still exhibits certain misjudgments in distinguishing between DI/DO and AI/AO types, requiring manual verification for refinement.",
    "title_zh": "从光缆数据反向生成变电站逻辑模型的方法",
    "abstract_zh": "在“十四五”期间，数字化变电站是中国电网建设的重点发展方向。作为变电站二次系统数字化设计的核心组成部分，逻辑模型在正向工程中因结构复杂、开发周期长而面临严峻挑战。为此，本文提出一种基于光缆数据的变电站逻辑模型逆向工程方法。通过扫描电气二次图纸（包括端子排图、原理图及文件信息），利用OCR技术提取电缆编号、回路编号、芯线功能描述以及端子柜连接等关键信息，并将其与逻辑模型规范相结合，自动在变电站物理描述（SPD）中生成接口（interface）、连接点（point）、芯线（core）和电缆（cable）等元素。所开发的前后端分离的逻辑模型生成系统，实现了接口、连接点、芯线和电缆的转换率分别达到95.1%、95.6%、91.8%和89.6%，整体成功率超过90%。通过实际工程图纸的验证表明，该方法能有效降低设计工作量，有力支撑变电站的数字化转型。然而，该方法在区分DI/DO与AI/AO类型时仍存在一定的误判，需通过人工核查进行优化完善。"
  },
  {
    "date": "2026-2-2",
    "title": "Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization",
    "authors": "Juhyeon Lee, Wonduk Seo, Hyunjin An, Seunghyun Lee, Yi Bu",
    "publish": "2025 ACM/IEEE Joint Conference on Digital Libraries (JCDL)",
    "url": "https://doi.org/10.1109/jcdl67857.2025.00043",
    "source": "IEEE",
    "abstract": "Automatic prompt optimization has recently emerged as a strategy for improving the quality of prompts used in Large Language Models (LLMs), with the goal of generating more accurate and useful responses. However, most prior work focuses on direct prompt refinement or model finetuning, overlooking the potential of leveraging LLMs’ inherent reasoning capability to learn from contrasting examples. In this paper, we present Contrastive Reasoning Prompt Optimization (CRPO), a novel framework that formulates prompt optimization as a retrieval-augmented reasoning process. Our approach retrieves top- k reference prompt-response pairs from the HelpSteer2 dataset, an open-source collection where each response is annotated for helpfulness, correctness, coherence, complexity, and verbosity, and constructs two complementary optimization paradigms: (1) tiered contrastive reasoning, where the LLM compares high-, medium-, and low-quality exemplars (both prompts and responses) to refine its own generation through reflective reasoning, and (2) multi-metric contrastive reasoning, where the LLM analyzes the best exemplars along each evaluation dimension and integrates their strengths into an optimized prompt. By explicitly contrasting high- and lowquality exemplars, CRPO enables the model to deduce why certain prompts succeed while others fail, thereby achieving more robust and interpretable optimization. Experimental results on the HelpSteer2 benchmark demonstrate that CRPO significantly outperforms baselines. Our findings highlight the promise of contrastive, retrieval-augmented reasoning for advancing automatic prompt optimization.<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup><sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>Code is Available at: https://github.com/GitLeo1/CRPO",
    "title_zh": "通过对比优化：用于自动提示优化的检索增强对比推理",
    "abstract_zh": "自动提示优化最近已成为提升大型语言模型（LLMs）提示质量的一种策略，旨在生成更准确、更有用的响应。然而，以往大多数研究主要集中在直接优化提示或模型微调上，忽视了利用LLM固有的推理能力，通过对比示例进行学习的潜力。本文提出了一种名为对比推理提示优化（Contrastive Reasoning Prompt Optimization, CRPO）的新框架，将提示优化建模为一种检索增强型推理过程。我们的方法从HelpSteer2数据集（一个开源数据集）中检索出前k个参考提示-响应对，该数据集中的每个响应均被标注了帮助性、正确性、连贯性、复杂性和冗余度等多个维度。在此基础上，我们构建了两种互补的优化范式：（1）分层对比推理，即LLM通过对比高质量、中等质量和低质量的示例（包括提示和响应），借助反思性推理来优化自身的生成；（2）多维度对比推理，即LLM分析每个评估维度下的最佳示例，并将其优势整合到优化后的提示中。通过显式对比高质量与低质量示例，CRPO使模型能够推断出某些提示成功或失败的原因，从而实现更稳健且可解释的优化。在HelpSteer2基准上的实验结果表明，CRPO显著优于现有基线方法。我们的研究结果凸显了对比性、检索增强型推理在推动自动提示优化方面所具有的巨大潜力。<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup><sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup> 代码获取地址：https://github.com/GitLeo1/CRPO"
  },
  {
    "date": "2026-2-2",
    "title": "A Reinforcement-Learning Logic Synthesis Framework and Its Integration into the EDA Flow",
    "authors": "Yicheng Duan",
    "publish": "2025 5th International Conference on Electrical Engineering and Control Science (IC2ECS)",
    "url": "https://doi.org/10.1109/ic2ecs68700.2025.11361649",
    "source": "IEEE",
    "abstract": "Classical logic synthesis is driven by hand-crafted flows and local heuristics. As circuits scale and constraints tighten, static recipes struggle to balance area, power, and delay while keeping iteration time acceptable. This paper proposes a reinforcement-learning (RL) logic synthesis framework that treats key synthesis steps as decision nodes in a Markov decision process. A deep Q-network (DQN) agent observes netlist/state features and selects transformations such as balance, rewrite, refactor, resub, and $d c 2$. A composite reward turns area, power, delay, and runtime into a single signal. Integrated into a standard Yosys → ABC flow, the agent learns flow policies that adapt to circuit structure. On ISCAS’89, the framework reduces average area by 15.6%, power by 12.8%, delay by 9.2%, and synthesis iteration time by 30.7% over strong baselines. Results show that learning-based flow control can deliver stable multi-objective gains with modest engineering effort.",
    "title_zh": "一种强化学习逻辑综合框架及其在EDA流程中的集成",
    "abstract_zh": "经典逻辑综合依赖于手工设计的流程和局部启发式方法。随着电路规模的扩大和约束条件的收紧，传统的固定流程难以在保持可接受迭代时间的前提下，有效平衡面积、功耗和延迟。本文提出了一种基于强化学习（RL）的逻辑综合框架，将关键综合步骤建模为马尔可夫决策过程中的决策节点。一个深度Q网络（DQN）智能体通过观察网表/状态特征，选择诸如平衡、重写、重构、重子化以及$dc2$等变换操作。复合奖励函数将面积、功耗、延迟和运行时间统一为单一信号。该框架被集成到标准的Yosys → ABC流程中，智能体能够学习适应电路结构的流程策略。在ISCAS’89基准测试中，与强基线方法相比，该框架平均降低了15.6%的面积、12.8%的功耗、9.2%的延迟，并将综合迭代时间减少了30.7%。实验结果表明，基于学习的流程控制能够在投入少量工程成本的情况下，实现稳定且多目标的性能提升。"
  },
  {
    "date": "2026-2-2",
    "title": "From Text to STIX: Reducing Hallucinations through Fine-Tuned LLMs",
    "authors": "Ruoyao Xiao, Yu Luo, Weifeng Xu, Dianxiang Xu",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00119",
    "source": "IEEE",
    "abstract": "The Structured Threat Information Expression (STIX) standard has become essential for representing and sharing cyber threat intelligence (CTI). However, automatically generating valid and semantically consistent STIX objects remains challenging. Large language models (LLMs) often succeed at extracting low-level indicators but struggle with higher-level abstractions, leading to missing fields, invalid properties, and structurally inconsistent outputs. To address these issues, we propose a methodology that integrates instruction fine-tuning with a novel evaluation framework. Specifically, we fine-tune LLMs using curated text–STIX pairs and domain-specific instructions to internalize schema alignment and reduce hallucinations. We further introduce the Object and Properties Similarity Evaluation (OPSE), which measures both structural validity and semantic fidelity of generated STIX objects against expert ground truth. Experimental results show that our fine-tuned model substantially improves object coverage, property completeness, and structural accuracy compared with baseline prompting and existing STIX generation tools.",
    "title_zh": "从文本到STIX：通过微调大语言模型减少幻觉",
    "abstract_zh": "结构化威胁信息表达（STIX）标准已成为表示和共享网络威胁情报（CTI）的关键工具。然而，自动生成有效且语义一致的STIX对象仍面临挑战。大型语言模型（LLMs）虽然在提取低级别指标方面表现良好，但在处理高层次抽象时往往出现字段缺失、属性无效以及结构不一致等问题。为解决上述问题，我们提出了一种结合指令微调与新型评估框架的方法。具体而言，我们利用精心筛选的文本–STIX配对数据及领域特定指令对LLM进行微调，以增强其对数据模式的匹配能力，减少幻觉现象。此外，我们引入了“对象与属性相似性评估”（OPSE）框架，用于衡量生成的STIX对象在结构有效性与语义准确性方面与专家标注真实值的一致性。实验结果表明，相较于基线提示方法及现有STIX生成工具，我们的微调模型在对象覆盖率、属性完整性以及结构准确性方面均有显著提升。"
  },
  {
    "date": "2026-2-2",
    "title": "SCodeGen: A Real-Time Trustworthy Constrained Decoding Framework for Secure Code Generation with LLMs",
    "authors": "Muzi Qu, Jie Liu, Liangyi Kang, Shuyi Ling, Shuai Wang, Dan Ye, Tao Huang",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00061",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) are increasingly integrated into software development workflows to accelerate code generation, but often produce insecure and uncontrollable code due to vulnerable training data and unconstrained decoding strategies. This poses severe risks in security-critical systems, where post-generation vulnerability detection and manual remediation incur significant overhead. While constrained decoding offers a practical mitigation strategy, existing methods suffer from degraded trustworthiness, constraint conflicts, and high latency—especially when enforcing multiple concurrent security constraints.We propose SCodeGen, a real-time constrained decoding framework designed to enforce fine-grained security controls during LLM code generation. To improve trustworthiness and controllability, SCodeGen introduces (1) a matching-length-aware logit modulation strategy that enhances trustworthiness and controllability without semantic disruption, and (2) a two-stage low-latency decoding architecture, which compiles constraint phrases into a runtime-enforceable constraint automaton (RCA) with precomputed logit bias vectors for efficient online decoding. Extensive evaluations on CodeGuard+ show that SCodeGen significantly improves secure pass rates under both single and multi-constraint settings, while maintaining latency comparable to unconstrained decoding. This work demonstrates a practical and scalable solution toward trustworthy LLM-assisted software development under security constraints.",
    "title_zh": "SCodeGen：一种基于大语言模型的安全代码生成实时可信约束解码框架",
    "abstract_zh": "大型语言模型（LLMs）正越来越多地被集成到软件开发流程中，以加速代码生成。然而，由于训练数据存在漏洞以及解码策略缺乏约束，这些模型常常生成不安全且难以控制的代码，这在安全关键系统中带来了严重风险。事后进行漏洞检测并手动修复，成本高昂。尽管约束解码提供了一种可行的缓解策略，但现有方法普遍存在可信度下降、约束冲突以及高延迟等问题，尤其是在同时强制执行多个安全约束时尤为明显。\n\n为此，我们提出了 SCodeGen，一个实时约束解码框架，旨在在 LLM 代码生成过程中实施细粒度的安全控制。为提升可信度与可控性，SCodeGen 引入了两项关键技术：（1）一种基于匹配长度感知的 logits 调制策略，能够在不破坏语义的前提下增强生成结果的可信度与可控性；（2）一种两阶段低延迟解码架构，将约束短语编译为可在运行时强制执行的约束自动机（RCA），并预先计算 logits 偏置向量，以实现高效的在线解码。\n\n在 CodeGuard+ 上的大量实验表明，SCodeGen 在单约束和多约束场景下均显著提升了安全通过率，同时保持了与无约束解码相当的延迟水平。本工作展示了一种面向安全约束下可信 LLM 辅助软件开发的实用且可扩展的解决方案。"
  },
  {
    "date": "2026-2-2",
    "title": "Design of Intelligent Generation System for Power Grid Fault Reports Based on Multi-source Heterogeneous Data Fusion",
    "authors": "Meizi Hou, Baichi Ou, Xuanzhen Chen, Xianzheng Chen, Lijun Mo, Jiaxuan Tang, Ming Gao, Ziyi Li, Yuanfa Cen",
    "publish": "2025 5th International Conference on Electrical Engineering and Control Science (IC2ECS)",
    "url": "https://doi.org/10.1109/ic2ecs68700.2025.11362316",
    "source": "IEEE",
    "abstract": "Aiming at the problems in power grid fault report generation under the “dual carbon” background, such as insufficient fusion of multi-source heterogeneous data, frequent model hallucinations, and heavy reliance on manual work, this paper proposes an intelligent generation system for power grid fault reports based on multimodal fusion and domain knowledge enhancement. The system achieves a key feature extraction error of $\\lt 1 \\mathrm{~ms}$ for fault record graphs by constructing a unified representation model for multi-source data and an “OCR+CNN” dual-channel image parsing algorithm; suppresses model hallucinations and ensures the logical consistency of reports by relying on a domain knowledge-enhanced RAG-LLM collaborative framework; and completes the full-process automation from fault data collection and information retrieval to report generation by combining a multi-level retrieval strategy and standardized templates. Experimental verification shows that the system can improve the fault report generation efficiency to the minute-level, outperforming traditional manual methods in data fusion accuracy, image recognition accuracy, and language logic. It successfully realizes the transformation of fault reports from “manual experience” to “intelligent generation”, providing highly reliable intelligent support for power grid dispatching and operation inspection.",
    "title_zh": "基于多源异构数据融合的电网故障报告智能生成系统设计",
    "abstract_zh": "针对“双碳”背景下电力系统故障报告生成中存在的多源异构数据融合不足、模型幻觉频发以及高度依赖人工等问题，本文提出了一种基于多模态融合与领域知识增强的电力系统故障报告智能生成系统。该系统通过构建多源数据统一表征模型和“OCR+CNN”双通道图像解析算法，实现了对故障录波图的关键特征提取误差小于1 ms；依托领域知识增强的RAG-LLM协同框架，有效抑制了模型幻觉，保障了报告内容的逻辑一致性；结合多层次检索策略与标准化模板，实现了从故障数据采集、信息检索到报告生成的全流程自动化。实验验证表明，该系统可将故障报告生成效率提升至分钟级，在数据融合准确率、图像识别准确率及语言逻辑性等方面均显著优于传统人工方法。系统成功推动故障报告从“人工经验”向“智能生成”的转型，为电力系统调度与运行巡检提供了高度可靠的智能化支撑。"
  },
  {
    "date": "2026-2-2",
    "title": "Hypnos: A Hardware-Software Co-Design Framework for Memory-Efficient Homomorphic Processing",
    "authors": "Haoxuan Wang, Yinghao Yang, Shangjie Pan, Hang Lu, Xiaowei Li",
    "publish": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
    "url": "https://doi.org/10.1109/tcad.2026.3660206",
    "source": "IEEE",
    "abstract": "Fully Homomorphic Encryption (FHE) introduces a novel paradigm in privacy-preserving computation, but operating on encrypted data imposes significant challenges, elevating data transmission, memory access demands, and programming complexity. Consequently, developing an efficient and usable system becomes vital. Conventional FHE accelerators often prioritize computational performance, typically assuming abundant encrypted data resides in accelerator memory. However, this perspective frequently overlooks the inefficiencies of the PCIe bus and main memory, alongside the complexities of optimizing for dedicated hardware in real-world deployments. This paper proposes Hypnos, a hardware/software co-design framework for memory-efficient homomorphic processing. The Hypnos framework pairs a novel processing unit architecture with a dedicated Hypnos Compiler. In architecture, the heterogeneous processing unit based on homomorphic encryption paging memory management system to reduce memory fragmentation and optimize the PCIe traffic. In software, the Hypnos compiler which is able to automatically translate high-level FHE schemes into optimized hardware commands. It schedules the data placement in cooperation with our memory management system to effectively harness the performance of hardware. This co-design of hardware and compiler not only reduces memory access and execution time but also lowers the complexity of deploying FHE applications. Finally, We implement Hypnos on the QianKun FPGA Card and highlight the following results: (1) outperforms SOTA ASIC and FPGA solutions in data-intensive applications by up to 2.75× and 4.72×; (2) the communication overhead is reduced by 4.85× compared to traditional architectures; (3) up to 30.1× and 20.7× energy efficiency improvement compared to ASIC-based ARK and FPGA-based Poseidon for ResNet-20 respectively.",
    "title_zh": "Hypnos：一种面向内存高效同态计算的软硬件协同设计框架",
    "abstract_zh": "全同态加密（FHE）为隐私保护计算引入了一种全新的范式，但对加密数据进行操作带来了显著挑战，导致数据传输、内存访问需求以及编程复杂度大幅增加。因此，开发高效且易用的系统变得至关重要。传统的FHE加速器通常侧重于计算性能，往往假设大量加密数据可驻留在加速器内存中。然而，这种观点常常忽视了PCIe总线和主内存的低效问题，以及在实际部署中针对专用硬件进行优化的复杂性。本文提出Hypnos，一种面向内存高效同态计算的软硬件协同设计框架。Hypnos框架将一种新型处理单元架构与专用的Hypnos编译器相结合。在硬件方面，基于同态加密分页内存管理系统的异构处理单元能够减少内存碎片并优化PCIe通信流量；在软件方面，Hypnos编译器可自动将高层FHE方案转换为优化的硬件指令，并与我们的内存管理机制协同调度数据布局，从而充分挖掘硬件性能。这种软硬件协同设计不仅显著降低了内存访问次数和执行时间，还大幅简化了FHE应用的部署复杂度。最后，我们在千坤FPGA卡上实现了Hypnos，并取得了以下成果：（1）在数据密集型应用中，性能相比最先进ASIC和FPGA方案分别提升最高达2.75倍和4.72倍；（2）通信开销相比传统架构降低4.85倍；（3）与基于ASIC的ARK和基于FPGA的Poseidon相比，ResNet-20模型的能效分别提升最高达30.1倍和20.7倍。"
  },
  {
    "date": "2026-2-2",
    "title": "A Systematic Approach to Predict the Impact of Cybersecurity Vulnerabilities Using LLMs",
    "authors": "Anders Mølmen Høst, Pierre Lison, Leon Moonen",
    "publish": "2025 IEEE 24th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)",
    "url": "https://doi.org/10.1109/trustcom66490.2025.00186",
    "source": "IEEE",
    "abstract": "Vulnerability databases, such as the National Vulnerability Database (NVD), offer detailed descriptions of Common Vulnerabilities and Exposures (CVEs), but often lack information on their real-world impact, such as the tactics, techniques, and procedures (TTPs) that adversaries may use to exploit the vulnerability. However, manually linking CVEs to their corresponding TTPs is a challenging and time-consuming task, and the high volume of new vulnerabilities published annually makes automated support desirable.This paper introduces Triage, a two-pronged automated approach that uses Large Language Models (LLMs) to map CVEs to relevant techniques from the Att&ck knowledge base. We first prompt an LLM with instructions based on MITRE’s CVE Mapping Methodology to predict an initial list of techniques. This list is then combined with the results from a second LLM-based module that uses in-context learning to map a CVE to relevant techniques. This hybrid approach strategically combines rule-based reasoning with data-driven inference. Our evaluation reveals that in-context learning outperforms the individual mapping methods, and the hybrid approach improves recall of exploitation techniques. We also find that GPT-4o-mini performs better than Llama3.3-70B on this task. Overall, our results show that LLMs can be used to automatically predict the impact of cybersecurity vulnerabilities and Triage makes the process of mapping CVEs to Att&ck more efficient.",
    "title_zh": "使用大语言模型系统性预测网络安全漏洞的影响",
    "abstract_zh": "漏洞数据库（如国家漏洞数据库NVD）提供了对通用漏洞与暴露（CVE）的详细描述，但通常缺乏关于其在现实世界中影响的信息，例如攻击者可能利用该漏洞的战术、技术与过程（TTPs）。然而，手动将CVE与相应的TTPs进行关联是一项极具挑战性且耗时的任务，而每年新发布的漏洞数量庞大，因此自动化支持显得尤为必要。本文提出了Triage——一种基于大型语言模型（LLMs）的双管齐下的自动化方法，用于将CVE映射到MITRE Att&ck知识库中的相关技术。我们首先根据MITRE的CVE映射方法论，向一个LLM提供指令，以预测初步的技术列表；随后，通过第二个基于LLM的模块，采用上下文学习（in-context learning）进一步将CVE映射到相关技术。这种混合方法巧妙结合了基于规则的推理与数据驱动的推断。我们的评估结果表明，上下文学习优于单一映射方法，而混合方法显著提升了漏洞利用技术的召回率。此外，我们发现GPT-4o-mini在此任务上的表现优于Llama3.3-70B。总体而言，实验结果表明，LLMs可用于自动预测网络安全漏洞的影响，而Triage则使将CVE映射至Att&ck的过程更加高效。"
  },
  {
    "date": "2026-2-2",
    "title": "Analysis of EM void growth failure time in multiple via structure",
    "authors": "Xiaojing Fan, Ge Gao",
    "publish": "2025 5th International Conference on Electrical Engineering and Control Science (IC2ECS)",
    "url": "https://doi.org/10.1109/ic2ecs68700.2025.11362022",
    "source": "IEEE",
    "abstract": "With the continuous advancement of process nodes, electromigration has become one of the most critical issues affecting the reliability of integrated circuit interconnects. This paper applies a physics-based hydrostatic stress analysis model to perform finite element simulations on common interconnect structures and models the stress distribution. The electromigration analysis model is applied to specific digital integrated circuit layouts for evaluation, and an electromigration correction algorithm and script based on redundant via technology are developed. Ultimately, a electromigration repair method compatible with standard design flows is designed.",
    "title_zh": "多 via 结构中 EM 空洞生长失效时间的分析",
    "abstract_zh": "随着工艺节点的不断演进，电迁移已成为影响集成电路互连可靠性最关键的难题之一。本文采用基于物理的静应力分析模型，对常见的互连结构进行有限元仿真，并对其中的应力分布进行了建模。将电迁移分析模型应用于具体的数字集成电路版图进行评估，并开发了基于冗余通孔技术的电迁移修正算法及相应脚本。最终，设计出一种与标准设计流程兼容的电迁移修复方法。"
  },
  {
    "date": "2026-2-2",
    "title": "A Self-Supervised and Cross-Design Netlist Power Model for Time-Based Layout Power Analysis",
    "authors": "Wenkai Li, Yao Lu, Wenji Fang, Yugao Zhu, Ziyan Guo, Jing Wang, Mengming Li, Qijun Zhang, Zhiyao Xie",
    "publish": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
    "url": "https://doi.org/10.1109/tcad.2026.3660207",
    "source": "IEEE",
    "abstract": "Accurate power prediction in VLSI design is crucial for effective power optimization, especially as designs get transformed from gate-level netlist to layout stages. However, traditional accurate power simulation requires time-consuming back-end processing and simulation steps, which significantly impede design optimization. To address this, we propose ATLAS, which can predict the ultimate time-based layout power for any new design in the gate-level netlist. In addition, we extend ATLAS to support power prediction using only RTL-stage toggle information, further increasing its applicability and efficiency. To the best of our knowledge, ATLAS is the first work that supports both time-based power simulation and general cross-design power modeling. It achieves such general time-based power modeling by proposing a new pre-training and fine-tuning paradigm customized for circuit power. Targeting golden per-cycle layout power from commercial tools, our ATLAS achieves the average mean absolute percentage error (MAPE) of only 5.41%, 3.79%, and 7.51% for the clock tree, register, and combinational power groups, respectively, without any layout information. Overall, the average MAPE for the total power of the entire design is 3.05%, and the inference speed of a workload is significantly faster than the standard flow of commercial tools. Furthermore, ATLAS can bypass the time-consuming signal propagation process, and when using only RTL-stage toggle information, achieves a total power MAPE as low as 5.00%.",
    "title_zh": "基于时间布局的自监督跨设计网表功耗模型",
    "abstract_zh": "在VLSI设计中，精确的功耗预测对于有效的功耗优化至关重要，尤其是在设计从门级网表转换到版图阶段的过程中。然而，传统的高精度功耗仿真需要耗时的后端处理和仿真步骤，严重阻碍了设计优化的进程。为解决这一问题，我们提出了ATLAS，该方法能够针对任意新的门级网表设计，预测其最终的时间相关版图功耗。此外，我们还将ATLAS扩展至仅使用RTL阶段翻转信息即可进行功耗预测，进一步提升了其适用性和效率。据我们所知，ATLAS是首个同时支持时间相关功耗仿真与通用跨设计功耗建模的工作。通过提出一种专为电路功耗定制的预训练与微调范式，ATLAS实现了通用的时间相关功耗建模。以商用工具生成的每周期黄金版图功耗为基准，ATLAS在时钟树、寄存器和组合逻辑功耗组上分别达到了5.41%、3.79%和7.51%的平均绝对百分比误差（MAPE），且无需任何版图信息。总体而言，整个设计总功耗的平均MAPE仅为3.05%，且单个工作负载的推理速度远超商用工具的标准流程。此外，ATLAS可跳过耗时的信号传播过程；当仅使用RTL阶段的翻转信息时，总功耗的MAPE低至5.00%。"
  }
]