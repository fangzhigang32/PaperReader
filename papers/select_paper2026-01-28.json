[
  {
    "date": "2026-01-28",
    "title": "DRAINCODE: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
    "authors": "Yanlin Wang, Jiadong Wu, Tianyue Jiang, Mingwei Liu, Jiachi Chen, Chong Wang, Ensheng Shi, Xilin Liu, Yuchi Ma, Zibin Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20615v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in code generation by leveraging retrieval-augmented generation (RAG) methods. However, the computational costs associated with LLM inference, particularly in terms of latency and energy consumption, have received limited attention in the security context. This paper introduces DrainCode, the first adversarial attack targeting the computational efficiency of RAG-based code generation systems. By strategically poisoning retrieval contexts through a mutation-based approach, DrainCode forces LLMs to produce significantly longer outputs, thereby increasing GPU latency and energy consumption. We evaluate the effectiveness of DrainCode across multiple models. Our experiments show that DrainCode achieves up to an 85% increase in latency, a 49% increase in energy consumption, and more than a 3x increase in output length compared to the baseline. Furthermore, we demonstrate the generalizability of the attack across different prompting strategies and its effectiveness compared to different defenses. The results highlight DrainCode as a potential method for increasing the computational overhead of LLMs, making it useful for evaluating LLM security in resource-constrained environments. We provide code and data at https://github.com/DeepSoftwareAnalytics/DrainCode.",
    "title_zh": "DRAINCODE：通过上下文污染对检索增强型代码生成实施隐蔽的能耗攻击",
    "abstract_zh": "大型语言模型（LLMs）通过采用检索增强生成（RAG）方法，在代码生成方面展现了令人瞩目的能力。然而，与 LLM 推理相关的计算成本，特别是延迟和能耗问题，在安全领域的研究中却鲜有关注。本文提出了 DrainCode，这是首个针对基于 RAG 的代码生成系统计算效率的对抗性攻击。DrainCode 通过基于变异的策略对检索上下文进行恶意污染，迫使 LLM 生成显著更长的输出，从而导致 GPU 延迟和能耗大幅增加。我们在多个模型上评估了 DrainCode 的有效性。实验结果表明，相较于基线，DrainCode 可使延迟最高提升 85%，能耗增加 49%，输出长度超过三倍。此外，我们还验证了该攻击在不同提示策略下的泛化能力，并与多种防御机制进行了对比，证明其有效性。这些结果表明，DrainCode 可能成为一种有效提升 LLM 计算开销的方法，对于在资源受限环境中评估 LLM 安全性具有重要意义。相关代码与数据已发布于 https://github.com/DeepSoftwareAnalytics/DrainCode。"
  },
  {
    "date": "2026-01-28",
    "title": "PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs",
    "authors": "Oguzhan Gungordu, Siheng Xiong, Faramarz Fekri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20539v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (PathWise), which formulates heuristic generation as a sequential decision process over an entailment graph serving as a compact, stateful memory of the search trajectory. This approach allows the system to carry forward past decisions and reuse or avoid derivation information across generations. A policy agent plans evolutionary actions, a world model agent generates heuristic rollouts conditioned on those actions, and critic agents provide routed reflections summarizing lessons from prior steps, shifting LLM-based AHD from trial-and-error evolution toward state-aware planning through reasoning. Experiments across diverse COPs show that PathWise converges faster to better heuristics, generalizes across different LLM backbones, and scales to larger problem sizes.",
    "title_zh": "PathWise：通过世界模型进行路径规划，实现自演化大语言模型的自动化启发式设计",
    "abstract_zh": "大型语言模型（LLMs）已推动组合优化问题（COPs）的自动化启发式设计（AHD），但现有框架依赖固定的进化规则和静态提示模板，常导致启发式生成短视、评估冗余，并且难以深入推理新启发式应如何推导。为此，我们提出一种新颖的多智能体推理框架——基于自演化LLM的通过世界模型进行自动化启发式设计的规划方法（PathWise）。该框架将启发式生成建模为一个在蕴含图上的序贯决策过程，该蕴含图作为搜索轨迹的紧凑、有状态的记忆。这一机制使系统能够保留过往决策，并在不同生成阶段复用或规避已有推导信息。其中，策略智能体负责规划进化动作，世界模型智能体根据这些动作生成启发式演进路径，而批评者智能体则提供定向反馈，总结先前步骤的经验教训。这一设计将基于LLM的AHD从试错式进化转变为基于状态感知的推理式规划。在多种组合优化问题上的实验表明，PathWise能更快收敛至更优启发式，具备跨不同LLM底座的泛化能力，并可扩展至更大规模的问题。"
  },
  {
    "date": "2026-01-28",
    "title": "How do Agents Refactor: An Empirical Study",
    "authors": "Lukas Ottenhof, Daniel Penner, Abram Hindle, Thibaud Lutellier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20160v1",
    "source": "arXiv",
    "abstract": "Software development agents such as Claude Code, GitHub Copilot, Cursor Agent, Devin, and OpenAI Codex are being increasingly integrated into developer workflows. While prior work has evaluated agent capabilities for code completion and task automation, there is little work investigating how these agents perform Java refactoring in practice, the types of changes they make, and their impact on code quality. In this study, we present the first analysis of agentic refactoring pull requests in Java, comparing them to developer refactorings across 86 projects per group. Using RefactoringMiner and DesigniteJava 3.0, we identify refactoring types and detect code smells before and after refactoring commits. Our results show that agent refactorings are dominated by annotation changes (the 5 most common refactoring types done by agents are annotation related), in contrast to the diverse structural improvements typical of developers. Despite these differences in refactoring types, we find Cursor to be the only model to show a statistically significant increase in refactoring smells.",
    "title_zh": "代理重构方法：一项实证研究",
    "abstract_zh": "像Claude Code、GitHub Copilot、Cursor Agent、Devin以及OpenAI Codex这样的软件开发代理正越来越多地被整合进开发者的工作流程中。尽管以往的研究已评估了这些代理在代码补全和任务自动化方面的能力，但关于它们在实际Java重构中的表现、所执行的变更类型及其对代码质量的影响，目前仍缺乏系统性研究。在本研究中，我们首次对Java场景下的代理式重构Pull Request进行了分析，将代理重构与开发者重构在每组86个项目的对比中进行评估。通过使用RefactoringMiner和DesigniteJava 3.0，我们在重构提交前后识别重构类型并检测代码异味。结果表明，代理的重构主要集中在注解修改上（代理最常执行的五种重构类型均与注解相关），而开发者则倾向于进行多样化的结构性改进。尽管重构类型存在显著差异，但我们发现只有Cursor模型表现出重构异味的统计学意义上的显著增加。"
  },
  {
    "date": "2026-01-28",
    "title": "Cascaded Vulnerability Attacks in Software Supply Chains",
    "authors": "Laura Baird, Armin Moin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20158v1",
    "source": "arXiv",
    "abstract": "Most of the current software security analysis tools assess vulnerabilities in isolation. However, sophisticated software supply chain security threats often stem from cascaded vulnerability and security weakness chains that span dependent components. Moreover, although the adoption of Software Bills of Materials (SBOMs) has been accelerating, downstream vulnerability findings vary substantially across SBOM generators and analysis tools. We propose a novel approach to SBOM-driven security analysis methods and tools. We model vulnerability relationships over dependency structure rather than treating scanner outputs as independent records. We represent enriched SBOMs as heterogeneous graphs with nodes being the SBOM components and dependencies, the known software vulnerabilities, and the known software security weaknesses. We then train a Heterogeneous Graph Attention Network (HGAT) to predict whether a component is associated with at least one known vulnerability. Since documented multi-vulnerability chains are scarce, we model cascade discovery as a link prediction problem over CVE pairs using a multi-layer perceptron neural network. This way, we produce ranked candidate links that can be composed into multi-step paths. The HGAT component classifier achieves an Accuracy of 91.03% and an F1-score of 74.02%.",
    "title_zh": "软件供应链中的级联漏洞攻击",
    "abstract_zh": "目前大多数软件安全分析工具都是孤立地评估漏洞。然而，复杂的软件供应链安全威胁往往源于跨越依赖组件的级联漏洞与安全弱点链。此外，尽管软件物料清单（SBOM）的采用正在加速，但不同SBOM生成器和分析工具之间对下游漏洞的发现结果存在显著差异。为此，我们提出一种新型的基于SBOM的安全分析方法与工具。我们不再将扫描结果视为独立记录，而是基于依赖结构建模漏洞之间的关系。我们将增强型SBOM表示为异构图，其中节点包括SBOM中的组件与依赖项、已知的软件漏洞以及已知的软件安全弱点。随后，我们训练一种异构图注意力网络（HGAT），以预测某个组件是否与至少一个已知漏洞相关。由于已记录的多漏洞链数据稀少，我们采用多层感知机神经网络，将级联发现建模为CVE对之间的链接预测问题。通过该方法，我们能够生成按优先级排序的候选链接，并将其组合成多步路径。HGAT组件分类器达到了91.03%的准确率和74.02%的F1分数。"
  },
  {
    "date": "2026-01-28",
    "title": "Trajectory2Task: Training Robust Tool-Calling Agents with Synthesized Yet Verifiable Data for Complex User Intents",
    "authors": "Ziyi Wang, Yuxuan Lu, Yimeng Zhang, Jing Huang, Jiri Gesi, Xianfeng Tang, Chen Luo, Yisi Sang, Hanqing Lu, Manling Li, Dakuo Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20144v1",
    "source": "arXiv",
    "abstract": "Tool-calling agents are increasingly deployed in real-world customer-facing workflows. Yet most studies on tool-calling agents focus on idealized settings with general, fixed, and well-specified tasks. In real-world applications, user requests are often (1) ambiguous, (2) changing over time, or (3) infeasible due to policy constraints, and training and evaluation data that cover these diverse, complex interaction patterns remain under-represented. To bridge the gap, we present Trajectory2Task, a verifiable data generation pipeline for studying tool use at scale under three realistic user scenarios: ambiguous intent, changing intent, and infeasible intents. The pipeline first conducts multi-turn exploration to produce valid tool-call trajectories. It then converts these trajectories into user-facing tasks with controlled intent adaptations. This process yields verifiable task that support closed-loop evaluation and training. We benchmark seven state-of-the-art LLMs on the generated complex user scenario tasks and observe frequent failures. Finally, using successful trajectories obtained from task rollouts, we fine-tune lightweight LLMs and find consistent improvements across all three conditions, along with better generalization to unseen tool-use domains, indicating stronger general tool-calling ability.",
    "title_zh": "Trajectory2Task：通过合成且可验证的数据训练鲁棒的工具调用智能体以应对复杂用户意图",
    "abstract_zh": "工具调用代理正越来越多地部署于实际的客户交互工作流中。然而，目前大多数关于工具调用代理的研究集中于理想化场景，其任务通常具有普遍性、固定性和明确性。在真实应用中，用户请求往往存在（1）意图模糊、（2）随时间变化，或（3）因政策限制而不可行等问题，而涵盖这些复杂多变交互模式的训练与评估数据仍严重不足。为弥合这一差距，我们提出了 Trajectory2Task——一个可验证的数据生成流程，用于在三种现实用户场景下大规模研究工具使用：模糊意图、意图变更以及不可行意图。该流程首先通过多轮探索生成有效的工具调用轨迹，随后将这些轨迹转化为带有可控意图调整的面向用户的任务。这一过程生成了可验证的任务，支持闭环评估与训练。我们在生成的复杂用户场景任务上对七种最先进的大语言模型进行了基准测试，发现它们频繁出现失败。最后，利用任务回放中获得的成功轨迹，我们对轻量级大语言模型进行微调，结果在所有三种条件下均表现出一致的性能提升，并且在未见过的工具使用领域也展现出更强的泛化能力，表明其具备更强大的通用工具调用能力。"
  },
  {
    "date": "2026-01-28",
    "title": "On the Impact of AGENTS.md Files on the Efficiency of AI Coding Agents",
    "authors": "Jai Lal Lulla, Seyedmoein Mohsenimofidi, Matthias Galster, Jie M. Zhang, Sebastian Baltes, Christoph Treude",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20404v1",
    "source": "arXiv",
    "abstract": "AI coding agents such as Codex and Claude Code are increasingly used to autonomously contribute to software repositories. However, little is known about how repository-level configuration artifacts affect operational efficiency of the agents. In this paper, we study the impact of AGENTS.md files on the runtime and token consumption of AI coding agents operating on GitHub pull requests. We analyze 10 repositories and 124 pull requests, executing agents under two conditions: with and without an AGENTS.md file. We measure wall-clock execution time and token usage during agent execution. Our results show that the presence of AGENTS.md is associated with a lower median runtime ($Δ28.64$%) and reduced output token consumption ($Δ16.58$%), while maintaining a comparable task completion behavior. Based on these results, we discuss immediate implications for the configuration and deployment of AI coding agents in practice, and outline a broader research agenda on the role of repository-level instructions in shaping the behavior, efficiency, and integration of AI coding agents in software development workflows.",
    "title_zh": "AGENTS.md 文件对AI编程代理效率的影响",
    "abstract_zh": "像Codex和Claude Code这样的AI编码代理正越来越多地被用于自主贡献代码仓库。然而，关于仓库级别的配置文件如何影响这些代理的运行效率，目前仍知之甚少。本文研究了AGENTS.md文件对GitHub拉取请求（pull requests）中AI编码代理运行时间和令牌消耗的影响。我们分析了10个仓库中的124个拉取请求，在两种条件下执行代理：有和没有AGENTS.md文件。我们测量了代理执行过程中的时钟时间（wall-clock execution time）和令牌使用量。结果表明，存在AGENTS.md文件与更低的中位数运行时间（Δ28.64%）以及更少的输出令牌消耗（Δ16.58%）相关，同时保持了相近的任务完成行为。基于这些发现，我们讨论了在实践中配置和部署AI编码代理的即时意义，并提出了一个更广泛的研究议程，旨在探讨仓库级别指令在塑造AI编码代理的行为、效率及其在软件开发工作流中的集成方面所起的作用。"
  },
  {
    "date": "2026-01-28",
    "title": "Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution",
    "authors": "Zhengbo Jiao, Hongyu Xian, Qinglong Wang, Yunpu Ma, Zhebo Wang, Zifan Zhang, Dezhang Kong, Meng Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20379v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of \"conjectures and refutations,\" we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.",
    "title_zh": "思想政策：通过推理时策略演化实现大语言模型推理的扩展",
    "abstract_zh": "大型语言模型（LLMs）在处理复杂、长时程推理任务时表现不佳，其根源在于“策略冻结”假设所引发的不稳定性。当前的测试时扩展方法仅将执行反馈视为外部信号，用于轨迹筛选或重写，而未将其内化以改进底层的推理策略。受波普尔“猜想与反驳”认识论思想的启发，我们认为智能的本质在于通过从失败尝试中学习，实时演化模型的决策策略。为此，我们提出“思维策略”（Policy of Thoughts, PoT）框架，将推理过程重新定义为一种实例内在线优化机制。PoT 首先通过高效的探索机制生成多样化的候选解决方案，随后利用群体相对策略优化（Group Relative Policy Optimization, GRPO）基于执行反馈更新一个临时的 LoRA 适配器。这种闭环设计实现了模型推理先验的动态、实例化优化。实验表明，PoT 显著提升了模型性能：一个仅 40 亿参数的模型在 LiveCodeBench 上达到了 49.71% 的准确率，超越了 GPT-4o 和 DeepSeek-V3，尽管其规模小了超过 50 倍。"
  },
  {
    "date": "2026-01-28",
    "title": "Improving Diffusion Language Model Decoding through Joint Search in Generation Order and Token Space",
    "authors": "Yangyi Shen, Tianjian Feng, Jiaqi Han, Wen Wang, Tianlang Chen, Chunhua Shen, Jure Leskovec, Stefano Ermon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20339v1",
    "source": "arXiv",
    "abstract": "Diffusion Language Models (DLMs) offer order-agnostic generation that can explore many possible decoding trajectories. However, current decoding methods commit to a single trajectory, limiting exploration in trajectory space. We introduce Order-Token Search to explore this space through jointly searching over generation order and token values. Its core is a likelihood estimator that scores denoising actions, enabling stable pruning and efficient exploration of diverse trajectories. Across mathematical reasoning and coding benchmarks, Order-Token Search consistently outperforms baselines on GSM8K, MATH500, Countdown, and HumanEval (3.1%, 3.8%, 7.9%, and 6.8% absolute over backbone), matching or surpassing diffu-GRPO post-trained d1-LLaDA. Our work establishes joint search as a key component for advancing decoding in DLMs.",
    "title_zh": "通过在生成顺序和词元空间中联合搜索提升扩散语言模型的解码性能",
    "abstract_zh": "扩散语言模型（DLMs）提供了无序生成能力，能够探索多种可能的解码路径。然而，当前的解码方法通常只选择单一路径，限制了在路径空间中的探索能力。我们提出了“顺序-标记搜索”（Order-Token Search），通过联合搜索生成顺序和标记取值来拓展这一空间。其核心是一个似然估计器，用于评估去噪操作的合理性，从而实现稳定的剪枝与高效多样的路径探索。在数学推理和编程基准测试中，Order-Token Search 在 GSM8K、MATH500、Countdown 和 HumanEval 上均显著优于基线模型，绝对性能提升分别为 3.1%、3.8%、7.9% 和 6.8%，达到或超越了经过 diffu-GRPO 微调的 d1-LLaDA 模型的表现。本研究确立了联合搜索作为推动 DLM 解码技术发展的关键组件。"
  },
  {
    "date": "2026-01-28",
    "title": "Context-Augmented Code Generation Using Programming Knowledge Graphs",
    "authors": "Shahd Seddik, Fahd Seddik, Iman Saberi, Fatemeh Fard, Minh Hieu Huynh, Patanamon Thongtanunam",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20810v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) excel at code generation but struggle with complex problems. Retrieval-Augmented Generation (RAG) mitigates this issue by integrating external knowledge, yet retrieval models often miss relevant context, and generation models hallucinate with irrelevant data. We propose Programming Knowledge Graph (PKG) for semantic representation and fine-grained retrieval of code and text. Our approach enhances retrieval precision through tree pruning and mitigates hallucinations via a re-ranking mechanism that integrates non-RAG solutions. Structuring external data into finer-grained nodes improves retrieval granularity. Evaluations on HumanEval and MBPP show up to 20% pass@1 accuracy gains and a 34% improvement over baselines on MBPP. Our findings demonstrate that our proposed PKG approach along with re-ranker effectively address complex problems while maintaining minimal negative impact on solutions that are already correct without RAG. The replication package is published at https://github.com/iamshahd/ProgrammingKnowledgeGraph",
    "title_zh": "基于编程知识图谱的上下文增强代码生成",
    "abstract_zh": "大型语言模型（LLMs）在代码生成方面表现出色，但在处理复杂问题时仍存在困难。检索增强生成（RAG）通过引入外部知识缓解了这一问题，但检索模型常遗漏相关上下文，而生成模型则容易产生与无关数据相关的幻觉。为此，我们提出了编程知识图谱（PKG），用于代码和文本的语义表示及细粒度检索。我们的方法通过树剪枝提升检索精度，并通过融合非RAG解决方案的重排序机制有效减少幻觉现象。将外部数据结构化为更细粒度的节点，显著提升了检索的精细程度。在HumanEval和MBPP基准上的评估显示，我们的方法在pass@1指标上最高可提升20%，并在MBPP上相比基线模型性能提升34%。实验结果表明，所提出的PKG方法结合重排序器能够有效应对复杂问题，同时对原本无需RAG即可正确解决的任务保持最小的负面影响。复现代码包已发布于 https://github.com/iamshahd/ProgrammingKnowledgeGraph"
  },
  {
    "date": "2026-01-28",
    "title": "LogSieve: Task-Aware CI Log Reduction for Sustainable LLM-Based Analysis",
    "authors": "Marcus Emmanuel Barnes, Taher A. Ghaleb, Safwat Hassan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20148v1",
    "source": "arXiv",
    "abstract": "Logs are essential for understanding Continuous Integration (CI) behavior, particularly for diagnosing build failures and performance regressions. Yet their growing volume and verbosity make both manual inspection and automated analysis increasingly costly, time-consuming, and environmentally costly. While prior work has explored log compression, anomaly detection, and LLM-based log analysis, most efforts target structured system logs rather than the unstructured, noisy, and verbose logs typical of CI workflows. We present LogSieve, a lightweight, RCA-aware and semantics-preserving log reduction technique that filters low-information lines while retaining content relevant to downstream reasoning. Evaluated on CI logs from 20 open-source Android projects using GitHub Actions, LogSieve achieves an average 42% reduction in lines and 40% reduction in tokens with minimal semantic loss. This pre-inference reduction lowers computational cost and can proportionally reduce energy use (and associated emissions) by decreasing the volume of data processed during LLM inference. Compared with structure-first baselines (LogZip and random-line removal), LogSieve preserves much higher semantic and categorical fidelity (Cosine = 0.93, GPTScore = 0.93, 80% exact-match accuracy). Embedding-based classifiers automate relevance detection with near-human accuracy (97%), enabling scalable and sustainable integration of semantics-aware filtering into CI workflows. LogSieve thus bridges log management and LLM reasoning, offering a practical path toward greener and more interpretable CI automation.",
    "title_zh": "LogSieve：面向任务的 CI 日志压缩以实现可持续的基于大模型的分析",
    "abstract_zh": "日志对于理解持续集成（CI）行为至关重要，尤其在诊断构建失败和性能退化问题时。然而，日志数量的不断增长及其高度冗余性，使得人工审查和自动化分析的成本越来越高，耗时且对环境造成较大负担。尽管已有研究探索了日志压缩、异常检测以及基于大语言模型（LLM）的日志分析，但大多数方法主要针对结构化系统日志，而非CI工作流中常见的非结构化、嘈杂且冗长的日志。我们提出了LogSieve——一种轻量级、面向根本原因分析（RCA）且语义保持的日志精简技术，能够在保留对下游推理至关重要的内容的同时，过滤掉信息量低的日志行。在使用GitHub Actions从20个开源Android项目收集的CI日志上进行评估，LogSieve实现了平均42%的行数减少和40%的token减少，同时几乎无语义损失。这种预推理阶段的日志精简显著降低了计算成本，并可按比例减少LLM推理过程中处理的数据量，从而降低能源消耗及相应的碳排放。与以结构优先的基线方法（如LogZip和随机行删除）相比，LogSieve在语义和类别保真度方面表现更优（余弦相似度=0.93，GPTScore=0.93，精确匹配准确率达80%）。基于嵌入的分类器实现了接近人类水平的准确性（97%），使语义感知的过滤能够实现可扩展且可持续地集成到CI流程中。因此，LogSieve弥合了日志管理与LLM推理之间的鸿沟，为实现更绿色、更具可解释性的CI自动化提供了一条切实可行的路径。"
  },
  {
    "date": "2026-01-28",
    "title": "TÄMU: Emulating Trusted Applications at the (GlobalPlatform)-API Layer",
    "authors": "Philipp Mao, Li Shi, Marcel Busch, Mathias Payer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20507v1",
    "source": "arXiv",
    "abstract": "Mobile devices rely on Trusted Execution Environments (TEEs) to execute security-critical code and protect sensitive assets. This security-critical code is modularized in components known as Trusted Applications (TAs). Vulnerabilities in TAs can compromise the TEE and, thus, the entire system. However, the closed-source nature and fragmentation of mobile TEEs severely hinder dynamic analysis of TAs, limiting testing efforts to mostly static analyses. This paper presents TÄMU, a rehosting platform enabling dynamic analysis of TAs, specifically fuzzing and debugging, by interposing their execution at the API layer. To scale to many TAs across different TEEs, TÄMU leverages the standardization of TEE APIs, driven by the GlobalPlatform specifications. For the remaining TEE-specific APIs not shared across different TEEs, TÄMU introduces the notion of greedy high-level emulation, a technique that allows prioritizing manual rehosting efforts based on the potential coverage gain during fuzzing. We implement TÄMU and use it to emulate 67 TAs across four TEEs. Our fuzzing campaigns yielded 17 zero-day vulnerabilities across 11 TAs. These results indicate a deficit of dynamic analysis capabilities across the TEE ecosystem, where not even vendors with source code unlocked these capabilities for themselves. TÄMU promises to close this gap by bringing effective and practical dynamic analysis to the mobile TEE domain.",
    "title_zh": "TÄMU：在（GlobalPlatform）API层模拟可信应用",
    "abstract_zh": "移动设备依赖可信执行环境（Trusted Execution Environments, TEEs）来运行安全关键代码并保护敏感资产。这些安全关键代码被模块化为称为可信应用（Trusted Applications, TAs）的组件。TAs 中的漏洞可能危及整个 TEE，进而导致系统整体受损。然而，由于移动 TEE 的闭源特性以及碎片化问题，对 TA 进行动态分析面临严重障碍，测试工作大多局限于静态分析。本文提出 TÄMU，这是一个可重宿主（rehosting）平台，通过在 API 层拦截 TA 的执行，实现对其的动态分析，特别是模糊测试（fuzzing）与调试。为了在不同 TEE 上扩展支持大量 TA，TÄMU 利用了由 GlobalPlatform 规范推动的 TEE API 标准化。对于那些未在不同 TEE 之间共享的 TEE 特定 API，TÄMU 引入了“贪婪高层模拟”（greedy high-level emulation）这一新概念：该技术可根据模糊测试期间预期的覆盖率增益，优先安排手动重宿主工作，从而提升效率。我们已实现 TÄMU，并成功在四个不同的 TEE 上模拟了 67 个 TA。通过开展模糊测试活动，我们发现了 11 个 TA 中共 17 个零日漏洞。这些结果表明，当前 TEE 生态系统中普遍存在动态分析能力的缺失——即使拥有源码的厂商也未能为自己开启此类能力。TÄMU 有望填补这一空白，将高效且实用的动态分析引入移动 TEE 领域。"
  },
  {
    "date": "2026-01-28",
    "title": "Beyond Accuracy: A Cognitive Load Framework for Mapping the Capability Boundaries of Tool-use Agents",
    "authors": "Qihao Wang, Yue Hu, Mingzhe Lu, Jiayue Wu, Yanbing Liu, Yuanmin Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20412v1",
    "source": "arXiv",
    "abstract": "The ability of Large Language Models (LLMs) to use external tools unlocks powerful real-world interactions, making rigorous evaluation essential. However, current benchmarks primarily report final accuracy, revealing what models can do but obscuring the cognitive bottlenecks that define their true capability boundaries. To move from simple performance scoring to a diagnostic tool, we introduce a framework grounded in Cognitive Load Theory. Our framework deconstructs task complexity into two quantifiable components: Intrinsic Load, the inherent structural complexity of the solution path, formalized with a novel Tool Interaction Graph; and Extraneous Load, the difficulty arising from ambiguous task presentation. To enable controlled experiments, we construct ToolLoad-Bench, the first benchmark with parametrically adjustable cognitive load. Our evaluation reveals distinct performance cliffs as cognitive load increases, allowing us to precisely map each model's capability boundary. We validate that our framework's predictions are highly calibrated with empirical results, establishing a principled methodology for understanding an agent's limits and a practical foundation for building more efficient systems.",
    "title_zh": "超越准确性：一种认知负荷框架，用于界定工具使用代理的能力边界",
    "abstract_zh": "大型语言模型（LLM）使用外部工具的能力，使其能够实现强大的现实世界交互，因此进行严谨的评估至关重要。然而，当前的基准测试主要报告最终准确率，仅揭示了模型能做什么，却掩盖了决定其真实能力边界的认知瓶颈。为了从简单的性能评分转向诊断性分析，我们提出了一种基于认知负荷理论的框架。该框架将任务复杂度分解为两个可量化的组成部分：内在负荷（Intrinsic Load），即解决方案路径本身的结构性复杂度，通过一种新颖的工具交互图（Tool Interaction Graph）进行形式化表达；以及外在负荷（Extraneous Load），即由任务表述模糊所引发的难度。为支持可控实验，我们构建了首个具有参数化可调认知负荷的基准测试——ToolLoad-Bench。我们的评估发现，随着认知负荷的增加，模型性能出现明显的断崖式下降，从而能够精确绘制出每种模型的能力边界。我们验证了该框架的预测与实证结果高度一致，确立了一种理解智能体能力极限的系统性方法，并为构建更高效系统提供了切实可行的基础。"
  },
  {
    "date": "2026-01-28",
    "title": "CE-RM: A Pointwise Generative Reward Model Optimized via Two-Stage Rollout and Unified Criteria",
    "authors": "Xinyu Hu, Yancheng He, Weixun Wang, Tao Feng, Li Lin, Jiashun Liu, Wenbo Su, Bo Zheng, Xiaojun Wan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20327v1",
    "source": "arXiv",
    "abstract": "Automatic evaluation is crucial yet challenging for open-ended natural language generation, especially when rule-based metrics are infeasible. Compared with traditional methods, the recent LLM-as-a-Judge paradigms enable better and more flexible evaluation, and show promise as generative reward models for reinforcement learning. However, prior work has revealed a notable gap between their seemingly impressive benchmark performance and actual effectiveness in RL practice. We attribute this issue to some limitations in existing studies, including the dominance of pairwise evaluation and inadequate optimization of evaluation criteria. Therefore, we propose CE-RM-4B, a pointwise generative reward model trained with a dedicated two-stage rollout method, and adopting unified query-based criteria. Using only about 5.7K high-quality data curated from the open-source preference dataset, our CE-RM-4B achieves superior performance on diverse reward model benchmarks, especially in Best-of-N scenarios, and delivers more effective improvements in downstream RL practice.",
    "title_zh": "CE-RM：一种通过两阶段滚动优化的点对点生成式奖励模型及统一标准",
    "abstract_zh": "自动评估对于开放式自然语言生成至关重要，但同时也极具挑战性，尤其是在基于规则的度量方法不可行的情况下。与传统方法相比，近期提出的“大模型作为评判者”（LLM-as-a-Judge）范式能够实现更优且更灵活的评估，展现出作为生成式奖励模型用于强化学习的巨大潜力。然而，先前的研究揭示了其在基准测试中看似出色的性能表现与实际强化学习应用中的有效性之间存在显著差距。我们认为这一问题源于现有研究的一些局限性，包括过度依赖成对评估以及评估标准优化不足。为此，我们提出了CE-RM-4B，一种采用专门设计的两阶段回溯（rollout）方法训练的点式生成式奖励模型，并引入统一的基于查询的评估标准。仅使用约5.7K条从开源偏好数据集中精心筛选的高质量数据，我们的CE-RM-4B在多种奖励模型基准测试中均表现出色，尤其在Best-of-N场景下优势明显，并在下游强化学习实践中带来了更有效的性能提升。"
  },
  {
    "date": "2026-01-28",
    "title": "AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts",
    "authors": "Shicheng Fang, Yuxin Wang, XiaoRan Liu, Jiahao Lu, Chuanyuan Tan, Xinchi Chen, Yining Zheng. Xuanjing Huang, Xipeng Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20730v1",
    "source": "arXiv",
    "abstract": "The evolution of Large Language Models (LLMs) into autonomous agents necessitates the management of extensive, dynamic contexts. Current benchmarks, however, remain largely static, relying on passive retrieval tasks that fail to simulate the complexities of agent-environment interaction, such as non-linear reasoning and iterative feedback. To address this, we introduce \\textbf{AgentLongBench}, which evaluates agents through simulated environment rollouts based on Lateral Thinking Puzzles. This framework generates rigorous interaction trajectories across knowledge-intensive and knowledge-free scenarios. Experiments with state-of-the-art models and memory systems (32K to 4M tokens) expose a critical weakness: while adept at static retrieval, agents struggle with the dynamic information synthesis essential for workflows. Our analysis indicates that this degradation is driven by the minimum number of tokens required to resolve a query. This factor explains why the high information density inherent in massive tool responses poses a significantly greater challenge than the memory fragmentation typical of long-turn dialogues.",
    "title_zh": "AgentLongBench：通过环境滚动实现可控的长上下文代理基准测试",
    "abstract_zh": "大型语言模型（LLMs）向自主智能体的演进，要求对大规模、动态上下文进行有效管理。然而，当前的评估基准仍以静态为主，依赖于被动检索任务，无法模拟智能体与环境交互中的复杂性，例如非线性推理和迭代反馈机制。为解决这一问题，我们提出 \\textbf{AgentLongBench}，该框架通过基于横向思维谜题（Lateral Thinking Puzzles）的环境模拟 rollout 来评估智能体的表现。该框架能够在知识密集型与知识无关型场景中生成严谨的交互轨迹。对前沿模型及记忆系统（支持 32K 到 4M token 的上下文长度）的实验揭示了一个关键弱点：尽管智能体在静态信息检索方面表现优异，但在实现工作流所必需的动态信息整合方面却面临显著挑战。我们的分析表明，这一性能退化主要由解决特定查询所需的最小 token 数量决定。这一因素解释了为何大规模工具返回内容所固有的高信息密度，相较于长对话中常见的内存碎片化问题，带来了更为严峻的挑战。"
  },
  {
    "date": "2026-01-28",
    "title": "ShieldedCode: Learning Robust Representations for Virtual Machine Protected Code",
    "authors": "Mingqiao Mo, Yunlong Tan, Hao Zhang, Heng Zhang, Yangfan He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20679v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have achieved remarkable progress in code generation, yet their potential for software protection remains largely untapped. Reverse engineering continues to threaten software security, while traditional virtual machine protection (VMP) relies on rigid, rule-based transformations that are costly to design and vulnerable to automated analysis. In this work, we present the first protection-aware framework that learns robust representations of VMP-protected code. Our approach builds large-scale paired datasets of source code and normalized VM implementations, and introduces hierarchical dependency modeling at intra-, preceding-, and inter-instruction levels. We jointly optimize language modeling with functionality-aware and protection-aware contrastive objectives to capture both semantic equivalence and protection strength. To further assess resilience, we propose a protection effectiveness optimization task that quantifies and ranks different VM variants derived from the same source. Coupled with a two-stage continual pre-training and fine-tuning pipeline, our method enables models to generate, compare, and reason over protected code. Extensive experiments show that our framework significantly improves robustness across diverse protection levels, opening a new research direction for learning-based software defense. In this work, we present ShieldedCode, the first protection-aware framework that learns robust representations of VMP-protected code. Our method achieves 26.95% Pass@1 on L0 VM code generation compared to 22.58% for GPT-4o., and improves binary similarity detection Recall@1 by 10% over state of art methods like jTrans.",
    "title_zh": "ShieldedCode：面向虚拟机保护代码的鲁棒表示学习",
    "abstract_zh": "大型语言模型（LLMs）在代码生成方面取得了显著进展，但其在软件保护方面的潜力仍远未被充分挖掘。逆向工程持续威胁着软件安全，而传统的虚拟机保护（VMP）依赖于僵化、基于规则的变换方式，不仅设计成本高昂，且容易受到自动化分析的攻击。在本工作中，我们提出了首个面向保护的框架，能够学习VMP保护后代码的鲁棒表示。我们的方法构建了大规模的源代码与标准化虚拟机实现配对数据集，并在指令内部、前后指令之间以及跨指令层级引入了分层依赖建模。通过联合优化语言建模任务与功能感知及保护感知的对比目标，模型能够同时捕捉语义等价性与保护强度。为进一步评估防护能力，我们提出了一项“保护有效性优化”任务，用于量化并排序由同一源代码衍生出的不同虚拟机变体。结合两阶段持续预训练与微调的流程，我们的方法使模型具备生成、比较和推理受保护代码的能力。大量实验表明，该框架在多种保护级别下均显著提升了鲁棒性，为基于学习的软件防御开辟了新的研究方向。\n\n在本研究中，我们提出了ShieldedCode——首个面向保护的框架，能够学习VMP保护代码的鲁棒表示。在L0级虚拟机代码生成任务中，我们的方法在Pass@1指标上达到26.95%，优于GPT-4o的22.58%；同时，在二进制相似性检测的Recall@1性能上，较当前最先进的jTrans方法提升了10%。"
  },
  {
    "date": "2026-01-28",
    "title": "Harnessing Large Language Models for Precision Querying and Retrieval-Augmented Knowledge Extraction in Clinical Data Science",
    "authors": "Juan Jose Rubio Jan, Jack Wu, Julia Ive",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20674v1",
    "source": "arXiv",
    "abstract": "This study applies Large Language Models (LLMs) to two foundational Electronic Health Record (EHR) data science tasks: structured data querying (using programmatic languages, Python/Pandas) and information extraction from unstructured clinical text via a Retrieval Augmented Generation (RAG) pipeline. We test the ability of LLMs to interact accurately with large structured datasets for analytics and the reliability of LLMs in extracting semantically correct information from free text health records when supported by RAG. To this end, we presented a flexible evaluation framework that automatically generates synthetic question and answer pairs tailored to the characteristics of each dataset or task. Experiments were conducted on a curated subset of MIMIC III, (four structured tables and one clinical note type), using a mix of locally hosted and API-based LLMs. Evaluation combined exact-match metrics, semantic similarity, and human judgment. Our findings demonstrate the potential of LLMs to support precise querying and accurate information extraction in clinical workflows.",
    "title_zh": "利用大型语言模型实现临床数据科学中的精准查询与检索增强型知识提取",
    "abstract_zh": "本研究将大型语言模型（LLMs）应用于电子健康记录（EHR）数据科学中的两项基础任务：结构化数据查询（使用编程语言如Python/Pandas）以及通过检索增强生成（RAG）流程从非结构化临床文本中进行信息提取。我们测试了LLM在与大规模结构化数据集交互以支持分析时的准确性，以及在RAG支持下从自由文本健康记录中提取语义正确信息的可靠性。为此，我们提出了一种灵活的评估框架，能够自动生成针对每个数据集或任务特征量身定制的合成问答对。实验基于MIMIC-III数据集的一个精选子集展开（包含四个结构化表格和一种临床笔记类型），并结合本地部署与基于API的LLM进行测试。评估方法融合了精确匹配指标、语义相似性分析以及人工判断。研究结果表明，LLM在临床工作流程中具备支持精准查询和准确信息提取的巨大潜力。"
  },
  {
    "date": "2026-01-28",
    "title": "MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents",
    "authors": "Vishnu Sashank Dorbala, Dinesh Manocha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20831v1",
    "source": "arXiv",
    "abstract": "Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head μthat acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of μ, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on μ-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that μ-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by μ, noting the superior performance of μaugmented MLLMs on long and complex instruction types.",
    "title_zh": "MemCtrl：在具身智能体中使用多模态大语言模型作为主动内存控制器",
    "abstract_zh": "基础模型依赖上下文学习实现个性化决策。然而，受限于上下文窗口的大小，必须采用记忆压缩与检索系统（如RAG）来应对。这些系统通常将记忆视为大型离线存储空间，这并不适合那些在严格内存和计算资源限制下需在线运行的具身智能体。本文提出了一种名为MemCtrl的新框架，利用多模态大语言模型（MLLMs）实现在线记忆剪枝。MemCtrl通过引入一个可训练的记忆头μ，作为门控机制，决定在探索过程中保留、更新或丢弃哪些观察结果或反思内容。我们通过两种方式训练该μ：1）基于离线专家；2）基于在线强化学习，并观察到经μ增强的MLLM在完成具身任务方面表现出显著提升。具体而言，在EmbodiedBench基准测试的多个子集上，对两个表现较差的MLLM进行MemCtrl增强后，其平均任务完成率提升了约16%，在特定指令子集上甚至超过20%。最后，我们对μ收集的记忆片段进行了定性分析，发现μ增强的MLLM在处理长而复杂的指令类型时表现出更优的性能。"
  },
  {
    "date": "2026-01-28",
    "title": "Reinforcement Learning via Self-Distillation",
    "authors": "Jonas Hübotter, Frederike Lübeck, Lejs Behric, Anton Baumann, Marco Bagatella, Daniel Marta, Ido Hakimi, Idan Shenfeld, Thomas Kleine Buening, Carlos Guestrin, Andreas Krause",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20802v1",
    "source": "arXiv",
    "abstract": "Large language models are increasingly post-trained with reinforcement learning in verifiable domains such as code and math. Yet, current methods for reinforcement learning with verifiable rewards (RLVR) learn only from a scalar outcome reward per attempt, creating a severe credit-assignment bottleneck. Many verifiable environments actually provide rich textual feedback, such as runtime errors or judge evaluations, that explain why an attempt failed. We formalize this setting as reinforcement learning with rich feedback and introduce Self-Distillation Policy Optimization (SDPO), which converts tokenized feedback into a dense learning signal without any external teacher or explicit reward model. SDPO treats the current model conditioned on feedback as a self-teacher and distills its feedback-informed next-token predictions back into the policy. In this way, SDPO leverages the model's ability to retrospectively identify its own mistakes in-context. Across scientific reasoning, tool use, and competitive programming on LiveCodeBench v6, SDPO improves sample efficiency and final accuracy over strong RLVR baselines. Notably, SDPO also outperforms baselines in standard RLVR environments that only return scalar feedback by using successful rollouts as implicit feedback for failed attempts. Finally, applying SDPO to individual questions at test time accelerates discovery on difficult binary-reward tasks, achieving the same discovery probability as best-of-k sampling or multi-turn conversations with 3x fewer attempts.",
    "title_zh": "通过自蒸馏进行强化学习",
    "abstract_zh": "大型语言模型正越来越多地在可验证领域（如代码和数学）中通过强化学习进行后续训练。然而，当前的可验证奖励强化学习（RLVR）方法仅从每次尝试的标量结果奖励中学习，导致严重的信用分配瓶颈。实际上，许多可验证环境会提供丰富的文本反馈，例如运行时错误或评分员评估，解释了尝试失败的原因。我们在此背景下形式化了“具有丰富反馈的强化学习”这一设定，并提出自蒸馏策略优化（SDPO），该方法将分词后的反馈转化为密集的学习信号，无需外部教师模型或显式的奖励模型。SDPO将当前模型在反馈条件下的输出视为自教师，将其基于反馈的下一词预测结果反向蒸馏回策略中。通过这种方式，SDPO利用模型在上下文中回溯识别自身错误的能力。在LiveCodeBench v6上的科学推理、工具使用和竞赛编程任务中，SDPO相较于强大的RLVR基线，在样本效率和最终准确率方面均取得显著提升。值得注意的是，即使在仅返回标量反馈的标准RLVR环境中，SDPO也优于现有基线，因为它能利用成功轨迹作为失败尝试的隐式反馈。最后，在测试阶段对单个问题应用SDPO，能够显著加速在困难的二元奖励任务中的探索过程，仅需三倍少的尝试次数即可达到与最佳k次采样或多轮对话相当的发现概率。"
  },
  {
    "date": "2026-01-28",
    "title": "Beyond the Needle's Illusion: Decoupled Evaluation of Evidence Access and Use under Semantic Interference at 326M-Token Scale",
    "authors": "Tianwei Lin, Zuyi Zhou, Xinda Zhao, Chenke Wang, Xiaohong Li, Yu Chen, Chuanrui Hu, Jian Pei, Yafeng Deng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20276v1",
    "source": "arXiv",
    "abstract": "Long-context LLM agents must access the right evidence from large environments and use it faithfully. However, the popular Needle-in-a-Haystack (NIAH) evaluation mostly measures benign span localization. The needle is near-unique, and the haystack is largely irrelevant. We introduce EverMemBench-S (EMB-S), an adversarial NIAH-style benchmark built on a 326M-token MemoryBank. While the full MemoryBank spans 326M tokens for retrieval-based (RAG) evaluation, we evaluate native long-context models only at scales that fit within each model's context window (up to 1M tokens in this work) to ensure a fair comparison. EMB-S pairs queries with collision-tested near-miss hard negatives and gold evidence sets spanning one or more documents, validated via human screening and LLM verification. We also propose a decoupled diagnostic protocol that reports evidence access (document-ID localization) separately from end-to-end QA quality under full-context prompting. This enables consistent diagnosis for both native long-context prompting and retrieval pipelines. Across a reference-corpus ladder from domain-isolated 64K contexts to a globally shared 326M-token environment, we observe a clear reality gap. Systems that saturate benign NIAH degrade sharply in evidence access under semantic interference. These results indicate that semantic discrimination, not context length alone, is the dominant bottleneck for long-context memory at scale.",
    "title_zh": "针尖上的幻象之外：在3260亿标记符规模下，语义干扰条件下证据获取与使用的解耦评估",
    "abstract_zh": "长上下文大语言模型代理必须能够从大规模环境中准确获取正确的证据并忠实使用。然而，目前流行的“针堆找针”（Needle-in-a-Haystack, NIAH）评估方法主要衡量的是良性片段定位能力：针头几乎唯一，而背景信息大多无关。为此，我们提出了EverMemBench-S（EMB-S），一个基于3.26亿token记忆库的对抗性NIAH风格基准测试。尽管整个记忆库包含3.26亿token以用于基于检索的（RAG）评估，但我们仅在每个模型上下文窗口容量范围内评估原生长上下文模型（本研究中最大达100万token），以确保公平比较。EMB-S为每个查询配对经过碰撞检测的近似错误负样本（near-miss hard negatives）以及涵盖一个或多个文档的真实证据集，并通过人工筛选与大模型验证进行确认。此外，我们提出了一种解耦诊断协议，将证据获取（文档ID定位）与全上下文提示下的端到端问答质量分开报告。该方法可一致地诊断原生长上下文提示与检索流水线的表现。在从领域隔离的64K上下文到全局共享的3.26亿token环境的参考语料阶梯中，我们观察到明显的现实差距：在良性NIAH测试中表现饱和的系统，在面临语义干扰时，其证据获取能力急剧下降。这些结果表明，对于大规模长上下文记忆而言，语义区分能力而非单纯的上下文长度，才是主要瓶颈。"
  },
  {
    "date": "2026-01-28",
    "title": "How AI Impacts Skill Formation",
    "authors": "Judy Hanwen Shen, Alex Tamkin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20245v1",
    "source": "arXiv",
    "abstract": "AI assistance produces significant productivity gains across professional domains, particularly for novice workers. Yet how this assistance affects the development of skills required to effectively supervise AI remains unclear. Novice workers who rely heavily on AI to complete unfamiliar tasks may compromise their own skill acquisition in the process. We conduct randomized experiments to study how developers gained mastery of a new asynchronous programming library with and without the assistance of AI. We find that AI use impairs conceptual understanding, code reading, and debugging abilities, without delivering significant efficiency gains on average. Participants who fully delegated coding tasks showed some productivity improvements, but at the cost of learning the library. We identify six distinct AI interaction patterns, three of which involve cognitive engagement and preserve learning outcomes even when participants receive AI assistance. Our findings suggest that AI-enhanced productivity is not a shortcut to competence and AI assistance should be carefully adopted into workflows to preserve skill formation -- particularly in safety-critical domains.",
    "title_zh": "人工智能如何影响技能形成",
    "abstract_zh": "人工智能辅助在专业领域中显著提升了生产力，尤其对新手工作者而言。然而，这种辅助如何影响有效监管人工智能所需技能的发展仍不明确。那些过度依赖人工智能完成陌生任务的新手工作者，可能在过程中损害自身技能的习得。我们通过随机实验研究了开发者在有无人工智能辅助的情况下，掌握一种新的异步编程库的过程。结果发现，使用人工智能会损害概念理解、代码阅读和调试能力，且平均而言并未带来显著的效率提升。完全将编码任务委托给AI的参与者虽在一定程度上提高了生产力，但代价是未能掌握该编程库。我们识别出六种不同的AI交互模式，其中三种涉及认知参与，即使在获得AI辅助的情况下也能保持学习效果。研究结果表明，人工智能带来的生产力提升并非通往熟练能力的捷径，因此应谨慎地将人工智能辅助融入工作流程，以保护技能的形成——尤其是在安全关键领域。"
  },
  {
    "date": "2026-01-28",
    "title": "Who Writes the Docs in SE 3.0? Agent vs. Human Documentation Pull Requests",
    "authors": "Kazuma Yamasaki, Joseph Ayobami Joshua, Tasha Settewong, Mahmoud Alfadel, Kazumasa Shimari, Kenichi Matsumoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20171v1",
    "source": "arXiv",
    "abstract": "As software engineering moves toward SE3.0, AI agents are increasingly used to carry out development tasks and contribute changes to software projects. It is therefore important to understand the extent of these contributions and how human developers review and intervene, since these factors shape the risks of delegating work to AI agents. While recent studies have examined how AI agents support software development tasks (e.g., code generation, issue resolution, and PR automation), their role in documentation tasks remains underexplored-even though documentation is widely consumed and shapes how developers understand and use software. Using the AIDev, we analyze 1,997 documentation-related pull requests (PRs) authored by AI agents and human developers, where documentation PRs are those that create or modify project documentation artifacts. We find that AI agents submit substantially more documentation-related PRs than humans in the studied repositories. We further observe that agent-authored documentation edits are typically integrated with little follow-up modification from humans, raising concerns about review practices and the reliability of agent-generated documentation. Overall, while AI agents already contribute substantially to documentation workflows, our results suggest concerns for emerging challenges for documentation quality assurance and human-AI collaboration in SE3.0.",
    "title_zh": "SE 3.0 中的文档由谁编写？代理与人工文档拉取请求",
    "abstract_zh": "随着软件工程迈向SE3.0时代，AI代理正越来越多地被用于执行开发任务，并对软件项目做出贡献。因此，理解这些贡献的程度以及人类开发者如何审查和干预，显得尤为重要，因为这些因素直接影响将工作委托给AI代理所带来的风险。尽管近期研究已探讨了AI代理在软件开发任务中的支持作用（如代码生成、问题修复和PR自动化），但其在文档编写任务中的角色仍鲜有研究——而文档却广泛被使用，并深刻影响开发者对软件的理解与使用方式。通过AIDev平台，我们分析了由AI代理和人类开发者提交的1,997个与文档相关的拉取请求（PR），其中文档类PR指创建或修改项目文档内容的请求。研究发现，在所考察的仓库中，AI代理提交的文档相关PR数量远超人类开发者。此外，我们观察到，由AI代理撰写的文档修改通常在合并后很少再经过人类后续修改，这引发了对审查流程有效性及代理生成文档可靠性的担忧。总体而言，尽管AI代理已在文档工作流中发挥显著作用，但我们的研究结果也揭示了在SE3.0背景下，文档质量保障以及人机协作方面可能面临的新挑战。"
  },
  {
    "date": "2026-01-28",
    "title": "CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning",
    "authors": "Zhenxuan Fan, Jie Cao, Yang Dai, Zheqi Lv, Wenqiao Zhang, Zhongle Xie, Peng LU, Beng Chin Ooi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20467v1",
    "source": "arXiv",
    "abstract": "Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \\textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.",
    "title_zh": "CtrlCoT：用于可控推理的双粒度思维链压缩",
    "abstract_zh": "思维链（Chain-of-Thought, CoT）提示能够提升大语言模型的推理能力，但其冗长的推理轨迹带来了较高的延迟和内存开销，因此亟需在保持正确性的前提下对CoT进行压缩。现有的方法要么在语义层面缩短CoT，但这通常过于保守；要么激进地删除token，容易遗漏任务关键线索，导致准确率下降。此外，由于存在序列依赖性、任务无关的剪枝策略以及分布不匹配等问题，将两种方法结合极具挑战性。为此，我们提出**CtrlCoT**——一种双粒度的CoT压缩框架，通过三个核心组件协调语义抽象与词元级剪枝：**分层推理抽象**生成多粒度的语义层次推理路径；**逻辑保真蒸馏**训练一个具备逻辑感知能力的剪枝器，在不同剪枝比例下仍能保留关键推理线索（如数字和运算符）；**分布对齐生成**则使压缩后的推理轨迹与推理时流畅的思维风格保持一致，避免碎片化。在MATH-500数据集上使用Qwen2.5-7B-Instruct进行测试，CtrlCoT仅使用比最强基线少30.7%的token，同时取得了高出7.6个百分点的准确率，充分证明了其在推理效率与可靠性上的显著优势。我们的代码将公开发布于 https://github.com/fanzhenxuan/Ctrl-CoT。"
  },
  {
    "date": "2026-01-28",
    "title": "BMAM: Brain-inspired Multi-Agent Memory Framework",
    "authors": "Yang Li, Jiaxiang Liu, Yusong Wang, Yujie Wu, Mingkun Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20465v1",
    "source": "arXiv",
    "abstract": "Language-model-based agents operating over extended interaction horizons face persistent challenges in preserving temporally grounded information and maintaining behavioral consistency across sessions, a failure mode we term soul erosion. We present BMAM (Brain-inspired Multi-Agent Memory), a general-purpose memory architecture that models agent memory as a set of functionally specialized subsystems rather than a single unstructured store. Inspired by cognitive memory systems, BMAM decomposes memory into episodic, semantic, salience-aware, and control-oriented components that operate at complementary time scales. To support long-horizon reasoning, BMAM organizes episodic memories along explicit timelines and retrieves evidence by fusing multiple complementary signals. Experiments on the LoCoMo benchmark show that BMAM achieves 78.45 percent accuracy under the standard long-horizon evaluation setting, and ablation analyses confirm that the hippocampus-inspired episodic memory subsystem plays a critical role in temporal reasoning.",
    "title_zh": "BMAM：类脑多智能体记忆框架",
    "abstract_zh": "基于语言模型的智能体在长时间交互过程中面临持续挑战，难以保持时间相关的上下文信息，并在不同会话间维持行为一致性，这种失效模式我们称之为“灵魂侵蚀”。本文提出BMAM（脑启发式多智能体记忆）——一种通用的记忆架构，将智能体记忆建模为一组功能专门化的子系统，而非单一的非结构化存储。受认知记忆系统的启发，BMAM将记忆分解为情景记忆、语义记忆、显著性感知记忆以及控制导向记忆等组件，各组件在互补的时间尺度上协同运作。为支持长时程推理，BMAM通过显式的时序轴组织情景记忆，并融合多种互补信号进行证据检索。在LoCoMo基准测试中的实验表明，BMAM在标准长时程评估设置下达到了78.45%的准确率，消融分析进一步证实了受海马体启发的情景记忆子系统在时间推理中起着关键作用。"
  },
  {
    "date": "2026-01-28",
    "title": "PEARL: Plan Exploration and Adaptive Reinforcement Learning for Multihop Tool Use",
    "authors": "Qihao Wang, Mingzhe Lu, Jiayue Wu, Yue Hu, Yanbing Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20439v1",
    "source": "arXiv",
    "abstract": "Large Language Models show great potential with external tools, but face significant challenges in complex, multi-turn tool invocation. They often exhibit weak planning, tool hallucination, erroneous parameter generation, and struggle with robust interaction. To tackle these issues, we present PEARL, a novel framework to enhance LLM planning and execution for sophisticated tool use. PEARL adopts a two-stage approach: an offline phase where the agent explores tools to learn valid usage patterns and failure conditions, and an online reinforcement learning phase. In the online phase, a dedicated Planner is trained via group Relative Policy Optimization (GRPO) with a carefully designed reward function that provides distinct signals for planning quality. Experiments on the ToolHop and T-Eval benchmarks show PEARL significantly outperforms existing methods, achieving a new state-of-the-art success rate of \\textbf{56.5\\%} on ToolHop while maintaining a low invocation error rate. Our work marks a key advance in addressing the complex planning challenges of tool use, contributing to the development of more robust and reliable LLM-based agents.",
    "title_zh": "珍珠：用于多跳工具使用的规划探索与自适应强化学习",
    "abstract_zh": "大型语言模型在使用外部工具方面展现出巨大潜力，但在复杂的多轮工具调用任务中仍面临诸多挑战，如规划能力薄弱、工具幻觉、参数生成错误以及难以实现稳健的交互。为解决这些问题，我们提出了PEARL——一种新颖的框架，旨在提升大模型在复杂工具使用中的规划与执行能力。PEARL采用两阶段方法：第一阶段为离线探索阶段，智能体通过主动探索工具来学习有效的使用模式及失败条件；第二阶段为在线强化学习阶段。在在线阶段，通过精心设计的奖励函数，利用群体相对策略优化（GRPO）对专用规划器进行训练，该奖励函数能够提供区分规划质量的明确信号。在ToolHop和T-Eval基准测试上的实验表明，PEARL显著优于现有方法，在ToolHop上取得了**56.5%**的新最优成功率，同时保持了较低的调用错误率。本工作标志着在应对复杂工具使用规划挑战方面取得关键进展，有助于推动更鲁棒、更可靠的基于大模型的智能体的发展。"
  },
  {
    "date": "2026-01-28",
    "title": "SAPO: Self-Adaptive Process Optimization Makes Small Reasoners Stronger",
    "authors": "Kaiyuan Chen, Guangmin Zheng, Jin Wang, Xiaobing Zhou, Xuejie Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20312v1",
    "source": "arXiv",
    "abstract": "Existing self-evolution methods overlook the influence of fine-grained reasoning steps, which leads to the reasoner-verifier gap. The computational inefficiency of Monte Carlo (MC) process supervision further exacerbates the difficulty in mitigating the gap. Motivated by the Error-Related Negativity (ERN), which the reasoner can localize error following incorrect decisions, guiding rapid adjustments, we propose a Self-Adaptive Process Optimization (SAPO) method for self-improvement in Small Language Models (SLMs). SAPO adaptively and efficiently introduces process supervision signals by actively minimizing the reasoner-verifier gap rather than relying on inefficient MC estimations. Extensive experiments demonstrate that the proposed method outperforms most existing self-evolution methods on two challenging task types: mathematics and code. Additionally, to further investigate SAPO's impact on verifier performance, this work introduces two new benchmarks for process reward models in both mathematical and coding tasks.",
    "title_zh": "SAPO：自适应流程优化让小型推理器更强大",
    "abstract_zh": "现有的自我演化方法忽略了细粒度推理步骤的影响，导致推理器与验证器之间存在差距。蒙特卡洛（MC）过程监督的计算低效性进一步加剧了缩小这一差距的难度。受错误相关负波（ERN）的启发——该信号使推理器能够在做出错误决策后定位错误并快速调整——我们提出了一种自适应过程优化（SAPO）方法，用于小型语言模型（SLMs）的自我改进。SAPO通过主动最小化推理器-验证器差距，自适应且高效地引入过程监督信号，而非依赖低效的MC估计。大量实验表明，所提方法在两项具有挑战性的任务类型——数学和代码——上优于大多数现有自我演化方法。此外，为进一步探究SAPO对验证器性能的影响，本文还引入了两个新的基准测试，用于数学和编程任务中的过程奖励模型。"
  },
  {
    "date": "2026-01-28",
    "title": "Audit Trails for Accountability in Large Language Models",
    "authors": "Victor Ojewale, Harini Suresh, Suresh Venkatasubramanian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20727v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly embedded in consequential decisions across healthcare, finance, employment, and public services. Yet accountability remains fragile because process transparency is rarely recorded in a durable and reviewable form. We propose LLM audit trails as a sociotechnical mechanism for continuous accountability. An audit trail is a chronological, tamper-evident, context-rich ledger of lifecycle events and decisions that links technical provenance (models, data, training and evaluation runs, deployments, monitoring) with governance records (approvals, waivers, and attestations), so organizations can reconstruct what changed, when, and who authorized it. This paper contributes: (1) a lifecycle framework that specifies event types, required metadata, and governance rationales; (2) a reference architecture with lightweight emitters, append only audit stores, and an auditor interface supporting cross organizational traceability; and (3) a reusable, open-source Python implementation that instantiates this audit layer in LLM workflows with minimal integration effort. We conclude by discussing limitations and directions for adoption.",
    "title_zh": "大型语言模型中的问责制审计追踪",
    "abstract_zh": "大型语言模型（LLMs）正越来越多地被应用于医疗、金融、就业及公共服务等关键决策领域。然而，由于过程透明性通常未以持久且可审查的形式记录，问责机制依然脆弱。本文提出“LLM审计追踪”作为一种社会技术机制，以实现持续的问责。审计追踪是一种按时间顺序排列、防篡改且富含上下文信息的生命周期事件与决策日志，它将技术溯源（如模型、数据、训练与评估运行、部署、监控）与治理记录（如审批、豁免和确认）相连接，使组织能够重建变更内容、发生时间以及授权人。本文的主要贡献包括：（1）一个生命周期框架，明确事件类型、必需元数据及治理依据；（2）一种参考架构，包含轻量级事件生成器、仅追加的审计存储库，以及支持跨组织追溯的审计员界面；（3）一个可复用、开源的Python实现，可在LLM工作流中以极小集成成本部署该审计层。最后，我们讨论了当前局限性及未来推广方向。"
  },
  {
    "date": "2026-01-28",
    "title": "Understanding npm Developers' Practices, Challenges, and Recommendations for Secure Package Development",
    "authors": "Anthony Peruma, Truman Choy, Gerald Lee, Italo De Oliveira Santos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20240v1",
    "source": "arXiv",
    "abstract": "Background: The Node Package Manager (npm) ecosystem plays a vital role in modern software development by providing a vast repository of packages and tools that developers can use to implement their software systems. However, recent vulnerabilities in third-party packages have led to serious security breaches, compromising the integrity of applications that depend on them. Objective: This study investigates how npm package developers perceive and handle security in their work. We examined developers' understanding of security risks, the practices and tools they use, the barriers to stronger security measures, and their suggestions for improving the npm ecosystem's security. Method: We conducted an online survey with 75 npm package developers and undertook a mixed-methods approach to analyzing their responses. Results: While developers prioritize security, they perceive their packages as only moderately secure, with concerns about supply chain attacks, dependency vulnerabilities, and malicious code. Only 40% are satisfied with the current npm security tools due to issues such as alert fatigue. Automated methods such as two-factor authentication and npm audit are favored over code reviews. Many drop dependencies due to abandonment or vulnerabilities, and typically respond to vulnerabilities in their packages by quickly releasing patches. Key barriers include time constraints and high false-positive rates. To improve npm security, developers seek better detection tools, clearer documentation, stronger account protections, and more education initiatives. Conclusion: Our findings will benefit npm package contributors and maintainers by highlighting prevalent security challenges and promoting discussions on best practices to strengthen security and trustworthiness within the npm landscape.",
    "title_zh": "理解 npm 开发者的实践、挑战及安全包开发的建议",
    "abstract_zh": "背景：Node Package Manager（npm）生态系统在现代软件开发中扮演着至关重要的角色，它提供了一个庞大的包和工具库，使开发者能够利用这些资源构建其软件系统。然而，近期第三方包中的安全漏洞已导致严重的安全事件，威胁到依赖这些包的应用程序的完整性。\n\n目标：本研究旨在探讨npm包开发者对其工作中的安全问题的看法与应对方式。我们考察了开发者对安全风险的理解、所采用的实践与工具、实施更强安全措施时面临的障碍，以及他们对提升npm生态系统安全性的建议。\n\n方法：我们对75名npm包开发者进行了在线调查，并采用混合研究方法分析其反馈数据。\n\n结果：尽管开发者普遍重视安全，但他们认为自身包的安全性仅处于中等水平，主要担忧包括供应链攻击、依赖项漏洞以及恶意代码。仅有40%的开发者对当前npm安全工具表示满意，主要原因在于“警报疲劳”等问题。自动化手段（如双因素认证和npm audit）比代码审查更受青睐。许多开发者因依赖项被弃用或存在漏洞而选择移除相关依赖；当发现自身包存在漏洞时，通常会迅速发布补丁。主要障碍包括时间压力和误报率过高。为改善npm安全，开发者希望获得更精准的检测工具、更清晰的文档、更强的账户保护机制，以及更多的安全教育举措。\n\n结论：本研究的发现将有助于npm包贡献者和维护者识别普遍存在的安全挑战，推动关于最佳实践的讨论，从而增强npm生态系统的安全性与可信度。"
  },
  {
    "date": "2026-01-28",
    "title": "Minimum-Cost Network Flow with Dual Predictions",
    "authors": "Zhiyang Chen, Hailong Yao, Xia Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20203v1",
    "source": "arXiv",
    "abstract": "Recent work has shown that machine-learned predictions can provably improve the performance of classic algorithms. In this work, we propose the first minimum-cost network flow algorithm augmented with a dual prediction. Our method is based on a classic minimum-cost flow algorithm, namely $\\varepsilon$-relaxation. We provide time complexity bounds in terms of the infinity norm prediction error, which is both consistent and robust. We also prove sample complexity bounds for PAC-learning the prediction. We empirically validate our theoretical results on two applications of minimum-cost flow, i.e., traffic networks and chip escape routing, in which we learn a fixed prediction, and a feature-based neural network model to infer the prediction, respectively. Experimental results illustrate $12.74\\times$ and $1.64\\times$ average speedup on two applications.",
    "title_zh": "带对偶预测的最小费用网络流",
    "abstract_zh": "近期的研究表明，机器学习预测可以严格证明地提升经典算法的性能。在本工作中，我们提出了首个基于对偶预测增强的最小费用网络流算法。我们的方法建立在经典的最小费用流算法——ε-松弛法（$\\varepsilon$-relaxation）之上。我们以无穷范数预测误差为依据，给出了时间复杂度的理论界，该界既具一致性又具备鲁棒性。此外，我们还证明了在PAC学习框架下预测模型的样本复杂度边界。我们在两个最小费用流的应用场景中对理论结果进行了实证验证：一是交通网络，二是芯片布线逃逸路由。在前者中，我们学习一个固定的预测模型；在后者中，则采用基于特征的神经网络模型来推断预测。实验结果表明，在这两个应用中分别实现了平均12.74倍和1.64倍的加速效果。"
  },
  {
    "date": "2026-01-28",
    "title": "SERA: Soft-Verified Efficient Repository Agents",
    "authors": "Ethan Shen, Danny Tormoen, Saurabh Shah, Ali Farhadi, Tim Dettmers",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20789v1",
    "source": "arXiv",
    "abstract": "Open-weight coding agents should hold a fundamental advantage over closed-source systems: they can be specialized to private codebases, encoding repository-specific information directly in their weights. Yet the cost and complexity of training has kept this advantage theoretical. We show it is now practical. We present Soft-Verified Efficient Repository Agents (SERA), an efficient method for training coding agents that enables the rapid and cheap creation of agents specialized to private codebases. Using only supervised finetuning (SFT), SERA achieves state-of-the-art results among fully open-source (open data, method, code) models while matching the performance of frontier open-weight models like Devstral-Small-2. Creating SERA models is 26x cheaper than reinforcement learning and 57x cheaper than previous synthetic data methods to reach equivalent performance. Our method, Soft Verified Generation (SVG), generates thousands of trajectories from a single code repository. Combined with cost-efficiency, this enables specialization to private codebases. Beyond repository specialization, we apply SVG to a larger corpus of codebases, generating over 200,000 synthetic trajectories. We use this dataset to provide detailed analysis of scaling laws, ablations, and confounding factors for training coding agents. Overall, we believe our work will greatly accelerate research on open coding agents and showcase the advantage of open-source models that can specialize to private codebases. We release SERA as the first model in Ai2's Open Coding Agents series, along with all our code, data, and Claude Code integration to support the research community.",
    "title_zh": "SERA：软验证高效仓库代理",
    "abstract_zh": "开放权重的编码代理相较于闭源系统具有根本性优势：它们可以针对私有代码库进行定制，将仓库特有的信息直接编码到模型权重中。然而，由于训练成本和复杂性过高，这一优势长期以来仅停留在理论层面。我们证明，如今这一优势已变得切实可行。本文提出了一种名为“软验证高效仓库代理”（SERA）的高效训练方法，可快速且低成本地创建专属于私有代码库的编码代理。仅通过监督微调（SFT），SERA在所有完全开源（数据、方法、代码均开源）模型中达到了当前最佳性能，并与前沿的开放权重模型如 Devstral-Small-2 相当。相比强化学习，构建SERA模型的成本降低了26倍；相比以往的合成数据方法，成本更是降低了57倍，即可达到同等性能。我们的核心方法——软验证生成（SVG），能够从单一代码仓库生成数千条推理轨迹。结合其极高的成本效益，该方法使得对私有代码库的深度定制成为可能。除了仓库级别的专业化外，我们还将SVG应用于更广泛的代码库集合，生成了超过20万条合成轨迹。基于这一数据集，我们开展了详尽的缩放规律分析、消融实验以及对训练过程中各类混淆因素的研究。总体而言，我们认为本工作将极大加速开源编码代理领域的研究进程，并充分展示出可针对私有代码库进行定制的开源模型所具备的独特优势。我们正式发布SERA作为艾伦人工智能研究所（Ai2）“开源编码代理系列”的首款模型，同时公开全部代码、数据及与Claude Code的集成方案，以全面支持研究社区的发展。"
  },
  {
    "date": "2026-01-28",
    "title": "Training Reasoning Models on Saturated Problems via Failure-Prefix Conditioning",
    "authors": "Minwu Kim, Safal Shrestha, Keith Ross",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20829v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has substantially improved the reasoning abilities of large language models (LLMs), yet training often stalls as problems become saturated. We identify the core challenge as the poor accessibility of informative failures: learning signals exist but are rarely encountered during standard rollouts. To address this, we propose failure-prefix conditioning, a simple and effective method for learning from saturated problems. Rather than starting from the original question, our approach reallocates exploration by conditioning training on prefixes derived from rare incorrect reasoning trajectories, thereby exposing the model to failure-prone states. We observe that failure-prefix conditioning yields performance gains matching those of training on medium-difficulty problems, while preserving token efficiency. Furthermore, we analyze the model's robustness, finding that our method reduces performance degradation under misleading failure prefixes, albeit with a mild trade-off in adherence to correct early reasoning. Finally, we demonstrate that an iterative approach, which refreshes failure prefixes during training, unlocks additional gains after performance plateaus. Overall, our results suggest that failure-prefix conditioning offers an effective pathway to extend RLVR training on saturated problems.",
    "title_zh": "通过失败前缀条件化在饱和问题上训练推理模型",
    "abstract_zh": "基于可验证奖励的强化学习（RLVR）显著提升了大型语言模型（LLMs）的推理能力，但随着问题难度的增加，训练过程常因问题饱和而陷入停滞。我们识别出核心挑战在于：富有信息量的失败模式难以被有效获取——尽管学习信号存在，但在标准采样过程中却很少被遇到。为解决这一问题，我们提出“失败前缀条件化”（failure-prefix conditioning）方法，这是一种简单而高效的学习策略，用于从饱和问题中汲取经验。与传统方式从原始问题开始不同，我们的方法通过将训练条件设置在罕见错误推理轨迹所生成的前缀上，重新分配探索方向，从而引导模型暴露于易出错的状态中。我们发现，该方法带来的性能提升相当于在中等难度问题上进行训练的效果，同时保持了极高的词元效率。此外，我们对模型鲁棒性进行了分析，发现该方法虽在一定程度上降低了误导性失败前缀带来的性能下降，但也带来了早期正确推理路径遵循度略有降低的轻微权衡。最后，我们展示了迭代式方法的潜力：在训练过程中动态更新失败前缀，可在性能达到平台期后进一步实现增益。总体而言，我们的研究结果表明，失败前缀条件化为扩展RLVR在饱和问题上的训练提供了一条有效路径。"
  },
  {
    "date": "2026-01-28",
    "title": "Can We Improve Educational Diagram Generation with In-Context Examples? Not if a Hallucination Spoils the Bunch",
    "authors": "Evanfiya Logacheva, Arto Hellas, Tsvetomila Mihaylova, Juha Sorva, Ava Heinonen, Juho Leinonen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20476v1",
    "source": "arXiv",
    "abstract": "Generative artificial intelligence (AI) has found a widespread use in computing education; at the same time, quality of generated materials raises concerns among educators and students. This study addresses this issue by introducing a novel method for diagram code generation with in-context examples based on the Rhetorical Structure Theory (RST), which aims to improve diagram generation by aligning models' output with user expectations. Our approach is evaluated by computer science educators, who assessed 150 diagrams generated with large language models (LLMs) for logical organization, connectivity, layout aesthetic, and AI hallucination. The assessment dataset is additionally investigated for its utility in automated diagram evaluation. The preliminary results suggest that our method decreases the rate of factual hallucination and improves diagram faithfulness to provided context; however, due to LLMs' stochasticity, the quality of the generated diagrams varies. Additionally, we present an in-depth analysis and discussion on the connection between AI hallucination and the quality of generated diagrams, which reveals that text contexts of higher complexity lead to higher rates of hallucination and LLMs often fail to detect mistakes in their output.",
    "title_zh": "我们能通过上下文示例来提升教育图表的生成吗？如果一个幻觉就毁了一切，那就不行。",
    "abstract_zh": "生成式人工智能（AI）在计算教育领域已得到广泛应用，但其生成内容的质量引发了教育工作者和学生们的担忧。本研究针对这一问题，提出了一种基于修辞结构理论（Rhetorical Structure Theory, RST）的新型图示代码生成方法，该方法通过引入上下文示例来提升图示生成效果，旨在使模型输出更符合用户预期。我们邀请计算机科学教育者对使用大语言模型（LLMs）生成的150幅图示进行了评估，评估维度包括逻辑组织性、连通性、布局美观度以及AI幻觉情况。此外，该评估数据集还被进一步分析，以探讨其在自动化图示评价中的应用潜力。初步结果表明，所提方法能够有效降低事实性幻觉的发生率，并提高图示对所提供上下文的忠实度；然而，由于大语言模型固有的随机性，生成图示的质量仍存在波动。此外，本文还深入分析并讨论了AI幻觉与生成图示质量之间的关联，发现文本上下文越复杂，幻觉发生率越高，且大语言模型往往难以识别自身输出中的错误。"
  },
  {
    "date": "2026-01-28",
    "title": "HE-SNR: Uncovering Latent Logic via Entropy for Guiding Mid-Training on SWE-BENCH",
    "authors": "Yueyang Wang, Jiawei Fu, Baolong Bi, Xili Wang, Xiaoqing Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20255v1",
    "source": "arXiv",
    "abstract": "SWE-bench has emerged as the premier benchmark for evaluating Large Language Models on complex software engineering tasks. While these capabilities are fundamentally acquired during the mid-training phase and subsequently elicited during Supervised Fine-Tuning (SFT), there remains a critical deficit in metrics capable of guiding mid-training effectively. Standard metrics such as Perplexity (PPL) are compromised by the \"Long-Context Tax\" and exhibit weak correlation with downstream SWE performance. In this paper, we bridge this gap by first introducing a rigorous data filtering strategy. Crucially, we propose the Entropy Compression Hypothesis, redefining intelligence not by scalar Top-1 compression, but by the capacity to structure uncertainty into Entropy-Compressed States of low orders (\"reasonable hesitation\"). Grounded in this fine-grained entropy analysis, we formulate a novel metric, HE-SNR (High-Entropy Signal-to-Noise Ratio). Validated on industrial-scale Mixture-of-Experts (MoE) models across varying context windows (32K/128K), our approach demonstrates superior robustness and predictive power. This work provides both the theoretical foundation and practical tools for optimizing the latent potential of LLMs in complex engineering domains.",
    "title_zh": "HE-SNR：通过熵揭示潜在逻辑以指导SWE-BENCH的中期训练",
    "abstract_zh": "SWE-bench 已成为评估大语言模型在复杂软件工程任务中表现的首选基准。尽管这些能力本质上是在训练中期获得，并在监督微调（SFT）阶段被激发，但目前仍缺乏能够有效指导训练中期进展的关键指标。标准指标如困惑度（PPL）受到“长上下文税”的影响，且与下游 SWE 性能的相关性较弱。本文通过首先引入一种严格的数据过滤策略，弥补了这一差距。关键的是，我们提出了“熵压缩假说”，重新定义智能：不再以标量 Top-1 压缩为衡量标准，而是以将不确定性结构化为低阶熵压缩状态（即“合理的犹豫”）的能力为核心。基于这一精细的熵分析，我们提出了一种新型指标——HE-SNR（高熵信噪比）。该方法在工业级混合专家（MoE）模型上进行了验证，覆盖不同上下文窗口（32K/128K），展现出卓越的鲁棒性和预测能力。本研究不仅为复杂工程领域中大语言模型潜在能力的优化提供了理论基础，也提供了切实可行的工具。"
  },
  {
    "date": "2026-01-28",
    "title": "Control Models for In-IDE Code Completion",
    "authors": "Aral de Moor, Yana Hrynevich, Hleb Badzeika, Vladyslav Furda, Marko Kojic, Artem Savelev, Kostadin Cvejoski, Darya Rovdo, Ekaterina Garanina",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20223v1",
    "source": "arXiv",
    "abstract": "We introduce control models for LLM-powered code completion in JetBrains IDEs: ML classifiers which trigger inference and filter the generated suggestions to better align them with users and reduce unnecessary requests. To this end, we evaluate boosting- and transformer-based architectures on an offline dataset of real code completions with n=98 users. We further evaluate the offline classification performance of our boosting-based approach on a range of syntactically diverse languages; and perform an A/B study in a production environment where they improve completion efficiency and quality metrics. With this study, we hope to demonstrate the potential in using auxiliary models for smarter in-IDE integration of LLM-driven features, highlight fruitful future directions, and open problems.",
    "title_zh": "IDE内代码补全的控制模型",
    "abstract_zh": "我们为 JetBrains IDE 中基于大语言模型（LLM）的代码补全引入了控制模型：通过机器学习分类器来触发推理并过滤生成的建议，使其更符合用户需求，同时减少不必要的请求。为此，我们在一个包含 98 名用户的实际代码补全离线数据集上，评估了基于提升（boosting）和 Transformer 的架构。此外，我们还对基于提升的方法在多种语法差异较大的编程语言上的离线分类性能进行了评估，并在生产环境中开展了一项 A/B 测试，结果表明该方法显著提升了代码补全的效率与质量指标。通过这项研究，我们希望展示利用辅助模型实现更智能的 IDE 内 LLM 功能集成的潜力，指出富有前景的未来方向，并揭示当前仍待解决的关键问题。"
  },
  {
    "date": "2026-01-28",
    "title": "Not All Tokens Matter: Data-Centric Optimization for Efficient Code Summarization",
    "authors": "Saima Afrin, Zaiyu Cheng, Tushar Sharma, Alexander Serebrenik, Massimiliano Di Penta, Antonio Mastropaolo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20147v1",
    "source": "arXiv",
    "abstract": "Instruction-tuned Language Models ILMs have become essential components of modern AI systems, demonstrating exceptional versatility across a wide range of natural language and reasoning tasks. Among their most impactful applications is code generation, where ILMs--commonly referred to as Code Language Models CLMs--have demonstrated remarkable capability. This strength stems from their defining feature: the use of explicit task instructions during fine-tuning, which enables them to bridge natural language and code by translating human intent into executable code. While much of their progress has been driven by advances in scaling laws and training methodologies, one critical aspect remains underexplored--the impact of system prompts on the performance of both general-purpose ILMs and specialized CLMs when instantiated to assist users with code generation activities. In this study, we take a first step toward bridging this gap by systematically evaluating how system prompts of varying instructional detail, along with model scale, prompting strategy, and programming language, affect ILMs and CLMs in code generation tasks. Our evaluation framework, spanning 120 model configurations, reveals that (1) the influence of system prompts increases with model scale; (2) few-shot prompting reduces this effect compared to zero-shot; and (3) programming language matters, with Java showing greater sensitivity to system prompt variations than Python.",
    "title_zh": "并非所有标记都重要：面向数据的高效代码摘要优化",
    "abstract_zh": "指令微调语言模型（Instruction-tuned Language Models, ILMs）已成为现代人工智能系统中不可或缺的组成部分，在自然语言处理和推理任务中展现出卓越的通用性。其中最具影响力的应用之一是代码生成，而ILMs——通常被称为代码语言模型（Code Language Models, CLMs）——在此领域表现出非凡的能力。这种优势源于其核心特征：在微调过程中使用明确的任务指令，使其能够通过将人类意图转化为可执行代码，有效连接自然语言与编程语言。尽管其进展主要得益于规模定律和训练方法的演进，但一个关键方面仍鲜有研究——系统提示（system prompts）对通用ILMs及专用CLMs在代码生成任务中性能的影响。本研究首次尝试填补这一空白，系统评估了不同指令详细程度的系统提示，以及模型规模、提示策略和编程语言等因素如何影响ILMs和CLMs在代码生成任务中的表现。我们的评估框架涵盖120种模型配置，结果表明：（1）系统提示的影响随模型规模增大而增强；（2）与零样本提示相比，少样本提示会减弱该影响；（3）编程语言具有显著差异，Java对系统提示的变化比Python更为敏感。"
  },
  {
    "date": "2026-01-28",
    "title": "A Dialectic Pipeline for Improving LLM Robustness",
    "authors": "Sara Candussio",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20659v1",
    "source": "arXiv",
    "abstract": "Assessing ways in which Language Models can reduce their hallucinations and improve the outputs' quality is crucial to ensure their large-scale use. However, methods such as fine-tuning on domain-specific data or the training of a separate \\textit{ad hoc} verifier require demanding computational resources (not feasible for many user applications) and constrain the models to specific fields of knowledge. In this thesis, we propose a dialectic pipeline that preserves LLMs' generalization abilities while improving the quality of its answer via self-dialogue, enabling it to reflect upon and correct tentative wrong answers. We experimented with different pipeline settings, testing our proposed method on different datasets and on different families of models. All the pipeline stages are enriched with the relevant context (in an oracle-RAG setting) and a study on the impact of its summarization or its filtering is conducted. We find that our proposed dialectic pipeline is able to outperform by significative margins the standard model answers and that it consistently achieves higher performances than Chain-of-Thought only prompting.",
    "title_zh": "一种用于提升大语言模型鲁棒性的辩证流水线",
    "abstract_zh": "评估如何减少语言模型的幻觉并提升输出质量，对于确保其大规模应用至关重要。然而，诸如在特定领域数据上进行微调或训练独立的“临时”验证器等方法，需要大量计算资源（对许多用户应用而言不可行），且将模型限制在特定知识领域内。在本论文中，我们提出了一种辩证式流程（dialectic pipeline），在保持语言模型泛化能力的同时，通过自我对话机制提升其回答质量，使其能够反思并修正初步的错误答案。我们测试了多种流程设置，在不同数据集和不同模型家族上验证了所提方法的有效性。所有流程阶段均在“理想RAG”（oracle-RAG）设定下融入相关上下文，并进一步研究了上下文摘要或过滤对其效果的影响。实验结果表明，所提出的辩证式流程显著优于标准模型的回答，且在各项指标上 consistently 高于仅采用思维链（Chain-of-Thought）提示的方法。"
  },
  {
    "date": "2026-01-28",
    "title": "Meeting SLOs, Slashing Hours: Automated Enterprise LLM Optimization with OptiKIT",
    "authors": "Nicholas Santavas, Kareem Eissa, Patrycja Cieplicka, Piotr Florek, Matteo Nulli, Stefan Vasilev, Seyyed Hadi Hashemi, Antonios Gasteratos, Shahram Khadivi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20408v1",
    "source": "arXiv",
    "abstract": "Enterprise LLM deployment faces a critical scalability challenge: organizations must optimize models systematically to scale AI initiatives within constrained compute budgets, yet the specialized expertise required for manual optimization remains a niche and scarce skillset. This challenge is particularly evident in managing GPU utilization across heterogeneous infrastructure while enabling teams with diverse workloads and limited LLM optimization experience to deploy models efficiently. We present OptiKIT, a distributed LLM optimization framework that democratizes model compression and tuning by automating complex optimization workflows for non-expert teams. OptiKIT provides dynamic resource allocation, staged pipeline execution with automatic cleanup, and seamless enterprise integration. In production, it delivers more than 2x GPU throughput improvement while empowering application teams to achieve consistent performance improvements without deep LLM optimization expertise. We share both the platform design and key engineering insights into resource allocation algorithms, pipeline orchestration, and integration patterns that enable large-scale, production-grade democratization of model optimization. Finally, we open-source the system to enable external contributions and broader reproducibility.",
    "title_zh": "达成SLO，减少耗时：使用OptiKIT实现企业级大模型的自动化优化",
    "abstract_zh": "企业级大语言模型（LLM）部署面临一个关键的可扩展性挑战：组织必须系统性地优化模型，以在有限的计算预算内推动AI项目的规模化发展。然而，实现手动优化所需的专门知识属于小众且稀缺的技能，难以普及。这一挑战在异构基础设施环境下尤为突出——如何高效管理GPU资源，同时支持具有不同工作负载、缺乏LLM优化经验的团队实现模型的高效部署。为此，我们提出OptiKIT，一个分布式LLM优化框架，通过自动化复杂的优化流程，将模型压缩与调优能力 democratize（普惠化），赋能非专业团队快速上手。OptiKIT具备动态资源分配、分阶段流水线执行及自动清理机制，并支持无缝集成到企业生产环境。在实际应用中，该系统实现了超过2倍的GPU吞吐量提升，使应用团队无需深入掌握LLM优化专业知识，即可持续获得性能改进。本文不仅分享了平台的整体设计，还深入剖析了资源分配算法、流水线编排机制以及集成模式等关键技术洞见，为大规模、生产级的模型优化普惠化提供了可行路径。最后，我们开源了该系统，以促进外部贡献和更广泛的可复现性。"
  },
  {
    "date": "2026-01-28",
    "title": "AMA: Adaptive Memory via Multi-Agent Collaboration",
    "authors": "Weiquan Huang, Zixuan Wang, Hehai Lin, Sudong Wang, Bo Xu, Qian Li, Beier Zhu, Linyi Yang, Chengwei Qin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.20352v1",
    "source": "arXiv",
    "abstract": "The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.",
    "title_zh": "AMA：通过多智能体协作实现自适应记忆",
    "abstract_zh": "大型语言模型（LLM）代理的快速发展，对支持连贯的长期交互与复杂推理的稳健记忆系统提出了迫切需求。得益于LLM的强大能力，近期研究重点已从简单的上下文扩展转向专用代理记忆系统的设计。然而，现有方法通常依赖于固定的检索粒度、高累积性的维护策略以及粗粒度的更新机制。这些设计选择导致存储信息与任务特定推理需求之间持续存在不匹配，同时引发逻辑矛盾的不断积累。为应对这些挑战，我们提出了一种基于多智能体协作的自适应记忆框架——AMA（Adaptive Memory via Multi-Agent Collaboration）。AMA通过协调多个智能体，在多种粒度层级上实现对记忆的有效管理。该框架采用分层记忆设计，能够根据任务复杂度动态调整检索粒度。具体而言，构造者（Constructor）与检索器（Retriever）协同完成多粒度记忆构建与自适应查询路由；评判者（Judge）负责验证所检索内容的相关性与一致性，当证据不足时触发迭代检索，或在检测到逻辑冲突时调用刷新者（Refresher）；后者则通过针对性更新或清除过时条目来确保记忆的一致性。在具有挑战性的长上下文基准测试中进行的大量实验表明，AMA显著优于当前最先进的基线方法，同时相比完整上下文方法将token消耗降低了约80%，充分证明了其在保持检索精度和长期记忆一致性方面的有效性。"
  },
  {
    "date": "2026-1-28",
    "title": "CPerfSmith: A Randomized C Program Generator for Performance-Oriented Compiler Testing",
    "authors": "Yashwanth Boda, Abhijit Chunduri, Ruchi Kumari, Awanish Pandey",
    "publish": "Proceedings of the 35th ACM SIGPLAN International Conference on Compiler Construction",
    "url": "https://doi.org/10.1145/3771775.3786271",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "CPerfSmith：一种面向性能优化编译器测试的随机C程序生成器",
    "abstract_zh": "None"
  },
  {
    "date": "2026-1-28",
    "title": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
    "authors": "Xiaoxue Ren, Jun Wan, Yun Peng, Zhongxin Liu, Ming Liang, Dajun Chen, Wei Jiang, Yong Li",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00153",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) have demonstrated significant capability in code generation, but their potential in code efficiency optimization remains underexplored. Previous LLM-based code efficiency optimization approaches exclusively focus on function-level optimization and overlook interaction between functions, failing to generalize to real-world development scenarios. Code editing techniques show great potential for conducting project-level optimization, yet they face challenges associated with invalid edits and suboptimal internal functions. To address these gaps, we propose PEACE, a novel hybrid framework for Project-Level code Efficiency optimization through Automatic Code Editing, which also ensures the overall correctness and integrity of the project. PEACE integrates three key phases: dependency-aware optimizing function sequence construction, valid associated edits identification, and efficiency optimization editing iteration. To rigorously evaluate the effectiveness of PEACE, we construct PEACEXEC, the first benchmark comprising 146 real-world optimization tasks from 47 high-impact GitHub Python projects, along with highly qualified test cases and executable environments. Extensive experiments demonstrate PEACE’s superiority over the state-of-the-art baselines, achieving a 69.2% correctness rate (pass@1), +46.9% opt rate, and 0.840 speedup in execution efficiency. Notably, our PEACE outperforms all baselines by significant margins, particularly in complex optimization tasks with multiple functions. Moreover, extensive experiments are also conducted to validate the contributions of each component in PEACE, as well as the rationale and effectiveness of our hybrid framework design.",
    "title_zh": "PEACE：通过混合代码编辑实现高效的项目级效率优化",
    "abstract_zh": "大型语言模型（LLMs）在代码生成方面已展现出显著能力，但其在代码效率优化方面的潜力仍鲜被探索。以往基于LLM的代码效率优化方法仅关注函数级优化，忽视了函数间的交互关系，难以推广至真实开发场景。代码编辑技术在实现项目级优化方面具有巨大潜力，然而其面临无效编辑和内部函数性能不佳等挑战。为弥补这些不足，我们提出PEACE——一种新型的混合框架，通过自动代码编辑实现项目级代码效率优化，同时确保项目的整体正确性与完整性。PEACE包含三个关键阶段：依赖感知的优化函数序列构建、有效关联编辑识别以及效率优化编辑迭代。为严格评估PEACE的有效性，我们构建了PEACEXEC，这是首个基准测试集，涵盖来自47个高影响力GitHub Python项目的146个真实世界优化任务，并配有高质量的测试用例与可执行环境。大量实验表明，PEACE在各项指标上均优于现有最先进基线方法，达到69.2%的正确率（pass@1）、+46.9%的优化率，以及0.840倍的执行效率提升。尤为突出的是，PEACE在涉及多个函数的复杂优化任务中表现远超所有基线，优势显著。此外，我们还进行了广泛实验，验证了PEACE各组件的贡献，以及该混合框架设计的合理性与有效性。"
  },
  {
    "date": "2026-1-28",
    "title": "IncrFuzz: LLM-Driven Incremental Fuzz Driver Generation for Library APIs",
    "authors": "Xiao Feng, Taotao Gu, Shuaibing Lu, Xiaohui Kuang",
    "publish": "2025 IEEE 10th International Conference on Data Science in Cyberspace (DSC)",
    "url": "https://doi.org/10.1109/dsc67331.2025.00093",
    "source": "IEEE",
    "abstract": "Library fuzzing requires a fuzz driver (or harness) to convert fuzzer-generated bytes into valid API calls with correct ordering and resource handling. However, writing such drivers is time-consuming, error-prone, and difficult to scale, often becoming a bottleneck in applying fuzzing to new libraries. This paper presents IncrFuzz, an incremental driver-generation framework that couples multi-dimensional function prioritization with large language model (LLM)-based iterative repair. The framework begins by ranking functions with a composite score derived from coverage data and code attributes to pinpoint high-value targets. It then enriches LLM prompts with project-specific test context to synthesize semantically correct libFuzzer drivers, and employs a compile-feedback “generate-validate-repair” loop to improve buildability. Experiments on 6 OSS-Fuzz libraries demonstrate that IncrFuzz elevates the average compilation success rate to 65.75%, produces 1.4 to over <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$25 \\times$</tex> more newly covered lines than a random baseline, and uncovers 623 and 2,140 additional lines in cJSON and libpcap, respectively. These results indicate that IncrFuzz can significantly extend existing driver coverage without manual effort, providing a practical path toward LLM-enabled large-scale library fuzzing.",
    "title_zh": "IncrFuzz：基于大语言模型的库API增量式模糊测试驱动生成",
    "abstract_zh": "库模糊测试需要一个模糊测试驱动程序（或称“测试 harness”），将模糊测试生成的字节序列转换为具有正确调用顺序和资源管理的有效 API 调用。然而，编写此类驱动程序耗时费力、容易出错且难以扩展，常常成为将模糊测试应用于新库时的瓶颈。本文提出 IncrFuzz——一种增量式驱动生成框架，该框架结合了多维度函数优先级排序与基于大语言模型（LLM）的迭代修复机制。该框架首先利用由覆盖率数据和代码属性综合得出的评分，对函数进行排序，以识别高价值的目标函数；随后通过引入项目特定的测试上下文来丰富 LLM 的提示信息，从而合成语义正确的 libFuzzer 驱动程序；并采用编译反馈的“生成-验证-修复”循环来提升构建成功率。在 6 个 OSS-Fuzz 开源库上的实验表明，IncrFuzz 将平均编译成功率达到 65.75%，生成的新覆盖代码行数比随机基线高出 1.4 倍至超过 25 倍，并在 cJSON 和 libpcap 中分别发现了额外的 623 行和 2,140 行代码覆盖。这些结果表明，IncrFuzz 能够在无需人工干预的情况下显著扩展现有驱动程序的覆盖范围，为实现基于大语言模型的大规模库模糊测试提供了一条切实可行的路径。"
  },
  {
    "date": "2026-1-28",
    "title": "How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance",
    "authors": "Xianhao Jin, Yifei Feng, Yufei Gao, Yongning Hu, Jie Huang, Kun Xia, Luchuan Guo",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00256",
    "source": "IEEE",
    "abstract": "Software companies are establishing new data centers to enhance software performance with lower response times as well as meet security requirements for storing local user data. ByteDance also has a strong need to deploy its services to new data centers worldwide quickly and with minimal error. Unfortunately, this process can also be time-consuming and error-prone, e.g., services often have dependencies on one another, requiring a strict deployment execution order. Moreover, the high similarity between resources in the new and the old data centers enables minimal modifications and maximizes the reuse of existing infrastructure configurations while providing the ability of global resource management. Additionally, manual migration across data centers often requires multiple confirmation check-points, which can significantly slow down the process. Therefore, to accelerate the new data center bring-ups, we adopt the idea of Infrastructure as code (IaC) which is a practice to automatically configure system dependencies and to provision local and remote instances [41]. In this work, we propose ByteRollout, an automatic intent-based software resource deployment system that is able to take customized infrastructure configurations as input and actuate deployments accordingly. We also assess ByteRollout in the following events of new data centers creations driven by site reliability engineering (SRE) teams. The evaluation results demonstrate that ByteRollout significantly accelerates the data center bring-up process, saving months of human effort and reducing costs by millions of USD simultaneously. The results also highlight that the Infrastructure as Code practice can be leveraged in the context of data center setups, offering benefits such as reduced process time and minimized errors throughout the deployment.",
    "title_zh": "基础设施即代码如何加速数据中心的启动？字节跳动案例研究",
    "abstract_zh": "软件公司正在建立新的数据中心，以提升软件性能、降低响应时间，并满足本地用户数据存储的安全要求。字节跳动同样迫切需要快速、低错误率地将其服务部署到全球各地的新数据中心。然而，这一过程往往耗时且容易出错，例如，服务之间通常存在依赖关系，必须按照严格的顺序进行部署。此外，新旧数据中心之间的资源高度相似，这使得只需进行最小程度的修改，即可最大限度复用现有的基础设施配置，同时实现全局资源管理。另外，传统的跨数据中心手动迁移通常需要多个确认检查点，这会显著拖慢整个流程。因此，为了加速新数据中心的上线，我们采用了“基础设施即代码”（Infrastructure as Code, IaC）的理念——这是一种通过自动化方式配置系统依赖关系并部署本地与远程实例的实践[41]。在本研究中，我们提出了 ByteRollout，一个基于意图的自动软件资源部署系统，能够接收自定义的基础设施配置作为输入，并据此自动执行部署操作。我们还在由站点可靠性工程（SRE）团队主导的新数据中心创建过程中对 ByteRollout 进行了评估。评估结果表明，ByteRollout 显著加快了数据中心的上线进程，节省了数月的人力投入，并同时降低了数百万美元的成本。结果还表明，“基础设施即代码”这一实践在数据中心部署场景中具有重要价值，能够有效缩短流程时间，并在整个部署过程中最大限度减少错误。"
  },
  {
    "date": "2026-1-28",
    "title": "Automated Prompt Generation for Code Intelligence: An Empirical study and Experience in WeChat",
    "authors": "Kexing Ji, Shiyun Fu, Cuiyun Gao, Yujia Chen, Zezhou Yang, Chaozheng Wang, Yuetang Deng",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00285",
    "source": "IEEE",
    "abstract": "Large Code Models (LCMs) have demonstrated potential in advancing various code intelligence tasks. However, their effectiveness can be greatly influenced by the quality of the prompts. Current prompt design strategies in code intelligence studies are mostly manually generated, which could be time-consuming and extremely rely on the base LCMs and tasks. Although automated prompt generation (APG) has been investigated in the natural language processing field, it has not attracted sufficient attention and been well explored in the code intelligence tasks. Considering the various tasks and black-box nature of LCMs faced by developers in practice, it is essential to automate the prompt generation process.To mitigate the gap, we empirically investigate the two important parts in APG, including Instruction Generation (IG) and Muti-Step Reasoning (MSR). The instruction generation part aims at providing a task-related description for instructing LCMs to effectively accomplish specific tasks; while the multistep reasoning part aims at guiding LCMs to produce a series of logical steps before arriving at the final answer. For each part, we evaluate the widely-used APG methods on four open-source LCMs and three code intelligence tasks, i.e., code translation (PL-PL), code summarization (PL-NL) and API recommendation (NL-PL). Experimental results indicate that the two parts in APG can dramatically enhance the performance of the code intelligence tasks compared with the basic prompts. Based on the results, we further propose a novel APG approach by combining the best methods of the two studied parts of APG. Experiments show that the proposed APG approach achieves an average improvement of 28.38% with respect to CodeBLEU for the code translation, 58.11% in terms of ROUGE-L for the code summarization and 84.53% in SuccessRate@1 for the API recommendation over the basic prompts, respectively. To validate the effectiveness in industrial scenario, we further evaluate our approach on WeChat-Bench, a proprietary dataset from the WeChat Group in Tencent for API recommendation, achieving an average improvement of 148.89% in MRR.",
    "title_zh": "微信中的代码智能自动化提示生成：一项实证研究与实践经验",
    "abstract_zh": "大型代码模型（LCMs）在推动各类代码智能任务方面展现出巨大潜力。然而，其性能在很大程度上受到提示词（prompt）质量的影响。当前代码智能研究中的提示词设计策略大多依赖人工生成，不仅耗时费力，且高度依赖基础LCM和具体任务。尽管自动化提示词生成（APG）已在自然语言处理领域得到一定研究，但在代码智能任务中尚未获得足够关注，也未被充分探索。考虑到开发者在实际应用中面临的多样化任务以及LCM的黑箱特性，自动化提示词生成过程显得尤为必要。\n\n为弥合这一差距，我们通过实证研究深入探讨了APG中的两个关键环节：指令生成（IG）与多步推理（MSR）。其中，指令生成旨在为LCM提供与任务相关的描述，以指导其有效完成特定任务；而多步推理则旨在引导LCM在得出最终答案前，生成一系列逻辑连贯的推理步骤。针对每一部分，我们在四个开源LCM上，对三种典型的代码智能任务——代码翻译（PL-PL）、代码摘要生成（PL-NL）和API推荐（NL-PL）进行了广泛评估。实验结果表明，相较于基础提示词，APG中的这两部分能够显著提升代码智能任务的性能。\n\n基于上述发现，我们进一步提出了一种新型APG方法，该方法融合了两部分中表现最佳的技术方案。实验结果显示，所提出的APG方法在代码翻译任务上相对于基础提示词平均提升了28.38%的CodeBLEU得分，在代码摘要任务上ROUGE-L指标提升58.11%，在API推荐任务上的SuccessRate@1提升达84.53%。为进一步验证该方法在工业场景下的有效性，我们在腾讯微信团队内部的专有数据集WeChat-Bench上进行了测试，该数据集专注于API推荐任务。结果表明，我们的方法在MRR指标上实现了平均148.89%的显著提升。"
  },
  {
    "date": "2026-1-28",
    "title": "LitterBox\n                    <sup>+</sup>\n                    : An Extensible Framework for LLM-enhanced Scratch Static Code Analysis",
    "authors": "Benedikt Fein, Florian Obermüller, Gordon Fraser",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00357",
    "source": "IEEE",
    "abstract": "Large language models (LLMS) have become an essential tool to support developers using traditional text-based programming languages, but the graphical notation of the block-based Scratch programming environment inhibits the use of LLMs. To overcome this limitation, we propose the LitterBox<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup> framework that extends the Scratch static code analysis tool LitterBox with the generative abilities of LLMs. By converting block-based code to a textual representation suitable for LLMs, LitterBox<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>allows users to query LLMs about their programs, about quality issues reported by LitterBox, and it allows generating code fixes. Besides offering a programmatic API for these functionalities, LitterBox<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup> also extends the Scratch user interface to make these functionalities available directly in the environment familiar to learners. The framework is designed to be easily extensible with other prompts, LLM providers, and new features combining the program analysis capabilities of LitterBox with the generative features of LLMs. We provide a screencast demonstrating the tool at https://youtu.be/RZ6E0xgrIgQ.",
    "title_zh": "LitterBox<sup>+</sup>：一种用于增强型大语言模型的Scratch静态代码分析的可扩展框架",
    "abstract_zh": "大型语言模型（LLMs）已成为支持开发者使用传统文本编程语言的重要工具，但积木式编程环境Scratch所采用的图形化表示方式限制了LLM的应用。为克服这一局限，我们提出了LitterBox<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>框架，该框架在Scratch静态代码分析工具LitterBox的基础上，引入了LLM的生成能力。通过将积木式代码转换为适合LLM处理的文本表示形式，LitterBox<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>使用户能够向LLM查询其程序相关问题、针对LitterBox报告的质量问题进行咨询，并自动生成代码修复方案。除了提供程序化API实现这些功能外，LitterBox<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>还扩展了Scratch的用户界面，使这些功能可直接在学习者熟悉的开发环境中使用。该框架设计具有高度可扩展性，支持集成其他提示模板、LLM服务提供商以及结合LitterBox的程序分析能力与LLM生成能力的新功能。我们提供了演示视频，可通过以下链接观看：https://youtu.be/RZ6E0xgrIgQ。"
  },
  {
    "date": "2026-1-28",
    "title": "The Chamber Assistant: A Language-Model Approach to Industrial Fault Correction and Documentation",
    "authors": "Nandan Shrinivas Chebbi, Roshan Balaji Mahashabde, K.R Usha Rani, Pratik Barve",
    "publish": "2025 IEEE International Conference on Intelligent Signal Processing and Effective Communication Technologies (INSPECT)",
    "url": "https://doi.org/10.1109/inspect67393.2025.11350352",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) are transforming industrial R&D labs to handle complex problem-solving, documentation, and data analysis. This paper introduces the Chamber Assistant, a smart assistant tailored for research labs. It leverages small and large language models that are trained on equipment manuals to answer technical queries and automate routine documentation. This system supports both online and offline use and features a browser-based interface for ease of use. LLMs such as LLaMA 3 and TinyLLaMA were fine-tuned on a custom industrial equipment dataset. The validation loss for both models was less than 10%, and the BLEU (Bilingual Evaluation Understudy) score was 0.91 and 0.95 for TinyLLaMA and LLaMA 3. Our results show high accuracy on test questions and demonstrate strong alignment with real-world documentation and fault correction, making this approach practical, costeffective, and privacy-friendly for sensitive lab environments.",
    "title_zh": "机房助手：一种基于语言模型的工业故障修正与文档化方法",
    "abstract_zh": "大型语言模型（LLMs）正在改变工业研发实验室，使其能够应对复杂的问题解决、文档编写和数据分析任务。本文介绍了一款专为科研实验室设计的智能助手——Chamber Assistant。该系统结合了小型和大型语言模型，并基于设备手册进行训练，可回答技术问题并自动化日常文档工作。该系统支持在线与离线使用，配备基于浏览器的用户界面，操作便捷。我们对LLaMA 3和TinyLLaMA等大模型在自定义工业设备数据集上进行了微调，两种模型的验证损失均低于10%，BLEU（双语评估替补）得分分别为0.91（TinyLLaMA）和0.95（LLaMA 3）。实验结果表明，该系统在测试问题上表现出高准确率，且与实际文档内容及故障修复高度一致，证明了该方法在敏感实验室环境中具有实用性、成本效益和良好的隐私保护能力。"
  },
  {
    "date": "2026-1-28",
    "title": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
    "authors": "Chen Yang, Lin Yang, Ziqi Wang, Dong Wang, Jianyi Zhou, Junjie Chen",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00250",
    "source": "IEEE",
    "abstract": "Recent advances in large language models (LLMs) have enabled promising performance in unit test generation through in-context learning (ICL). However, the quality of in-context examples significantly influences the effectiveness of generated tests—poorly structured or semantically unclear test examples often lead to suboptimal outputs. In this paper, we propose CLAST, a novel technique that systematically refines unit tests to improve their semantic clarity, thereby enhancing their utility as in-context examples. The approach decomposes complex tests into logically clearer ones and improves semantic clarity through a combination of program analysis and LLM-based rewriting. We evaluated CLAST on four open-source and three industrial projects. The results demonstrate that CLAST largely outperforms UTgen, the state-of-the-art refinement technique, in both preserving test effectiveness and enhancing semantic clarity. Specifically, CLAST fully retains the original effectiveness of unit tests, while UTgen reduces compilation success rate (CSR), pass rate (PR), test coverage (Cov), and mutation score (MS) by an average of 12.90%, 35.82%, 4.65%, and 5.07%, respectively. Over 85.33% of participants in our user study preferred the semantic clarity of CLAST-refined tests. Notably, incorporating CLAST-refined tests as examples effectively improves ICL-based unit test generation approaches such as RAGGen and TELPA, resulting in an average increase of 25.97% in CSR, 28.22% in PR, and 45.99% in Cov for generated tests, compared to incorporating UTgen-refined tests. The insights from the follow-up user study not only reinforce CLAST’s potential impact in software testing practice but also illuminate avenues for future research.",
    "title_zh": "用于单元测试生成的上下文示例语义澄清",
    "abstract_zh": "近年来，大型语言模型（LLMs）的进展使得通过上下文学习（In-Context Learning, ICL）生成单元测试展现出令人瞩目的性能。然而，上下文示例的质量显著影响生成测试的有效性——结构混乱或语义不清的测试示例往往导致次优输出。本文提出了一种名为CLAST的新技术，系统性地优化单元测试，以提升其语义清晰度，从而增强其作为上下文示例的实用性。该方法通过程序分析与基于LLM的重写相结合，将复杂的测试用例分解为逻辑更清晰的形式，进而提高其语义表达的明确性。我们在四个开源项目和三个工业级项目上对CLAST进行了评估。结果表明，CLAST在保持测试有效性的同时，显著优于当前最先进的优化技术UTgen，在语义清晰度方面表现尤为突出。具体而言，CLAST完全保留了原始测试的有效性，而UTgen则使编译成功率（CSR）、通过率（PR）、测试覆盖率（Cov）和突变分数（MS）平均下降12.90%、35.82%、4.65%和5.07%。在我们的用户研究中，超过85.33%的参与者更倾向于CLAST优化后的测试在语义清晰度上的表现。值得注意的是，将CLAST优化后的测试用作示例，能够有效提升基于ICL的单元测试生成方法（如RAGGen和TELPA），相比使用UTgen优化的示例，生成测试的CSR平均提升25.97%，PR提升28.22%，Cov提升45.99%。后续用户研究所得的洞察不仅进一步证实了CLAST在软件测试实践中的巨大潜力，也为未来的研究方向提供了重要启示。"
  },
  {
    "date": "2026-1-28",
    "title": "Design and Verification of a 16-Bit Multi-Slave SPI Protocol in System Verilog",
    "authors": "S Priyadarshini, Neha. S. Hosamath, Subodh Kumar Panda, D Smitha Gayathri, S Bindu, P Rekha",
    "publish": "2025 5th International Conference on Mobile Networks and Wireless Communications (ICMNWC)",
    "url": "https://doi.org/10.1109/icmnwc66779.2025.11354444",
    "source": "IEEE",
    "abstract": "For high-performance embedded and System-onChip (SoC) platforms that interact with peripherals like sensors, memory devices, and data converters, reliable serial communication is crucial. The design, cycle-accurate modeling, and functional verification of a 16-bit, multi-slave System Verilog Serial Peripheral Interface (SPI) controller are presented in this work. Full-duplex communication, variable clock polarity (CPOL) and phase (CPHA), and the ability to choose up to three slave devices are all supported by the design. Power, area, gate count, and initial timing behavior could all be quantitatively analyzed thanks to the design's synthesis using Cadence Genus and simulation in the Cadence RTL environment. To ensure proper master-slave data transfer, a guided System Verilog testbench was created, and functional validation for SPI Mode-0 operation was shown. The implementation offers a comprehensive RTL-to-synthesis design path appropriate for incorporation into embedded subsystems, even though the current verification does not cover all SPI modes or corner-case scenarios. The study lays the groundwork for future upgrades incorporating more sophisticated verification and wider protocol support while highlighting useful factors in SPI controller development.",
    "title_zh": "基于System Verilog的16位多从机SPI协议设计与验证",
    "abstract_zh": "对于需要与传感器、存储设备和数据转换器等外设交互的高性能嵌入式系统及片上系统（SoC）平台，可靠的串行通信至关重要。本文提出了一种16位、多从机的System Verilog串行外设接口（SPI）控制器的设计、周期精确建模及功能验证。该设计支持全双工通信、可变时钟极性（CPOL）和相位（CPHA），并能够选择最多三个从机设备。通过使用Cadence Genus进行综合，并在Cadence RTL环境中进行仿真，实现了对功耗、面积、门数以及初始时序行为的定量分析。为确保主从设备间的数据传输正确性，设计了指导性的System Verilog测试平台，并展示了SPI模式0下的功能验证结果。尽管当前的验证未涵盖所有SPI模式或边界情况，但该实现提供了一条完整的RTL至综合的设计流程，适用于嵌入式子系统的集成。本研究为未来引入更复杂的验证方法和更广泛的协议支持奠定了基础，同时突出了SPI控制器开发中的关键考量因素。"
  },
  {
    "date": "2026-1-28",
    "title": "Programmers’ Visual Attention on Function Call Graphs During Code Summarization",
    "authors": "Samantha McLoughlin, Zachary Karas, Robert Wallace, Aakash Bansal, Collin McMillan, Yu Huang",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00089",
    "source": "IEEE",
    "abstract": "This paper studies programmer visual attention on code as it relates to underlying function call graphs during code summarization. Programmer visual attention refers to where people look when performing a software engineering task, and code summarization is the task of writing a natural language description about a section of source code. Prior work has studied programmers’ visual attention during code summarization, with the vast majority of research effort placed on details in single functional units of code. There have not been any techniques developed to understand code comprehension at the project level due to the difficulty of this task, despite the nature of most real-world methods as embedded within complex project context. This paper focuses on the visual attention paid to the call graph context in which a method sits. We analyze visual attention coverage of call graphs with graph-based metrics, such as the depth that programmers traverse or the amount of coverage they attain. We use these metrics, among other means, to reevaluate an existing dataset from a previous eye-tracking study of programmers (n = 10) that considered basic properties of programmer visual attention in a project context. We then created a new dataset (n = 12) using the same procedures specifically for this paper, resulting in a total of 88 hours of recorded visual behavior on source code. We used our proposed metrics to analyze how participants’ visual strategies correlated with their code summary quality, and confidence in their summaries. Interestingly, we found that higher coverage of the call graph was associated with decreases in both summary quality and participants’ confidence.",
    "title_zh": "程序员在代码摘要过程中对函数调用图的视觉注意力研究",
    "abstract_zh": "本文研究了程序员在进行代码摘要任务时，对代码背后函数调用图的视觉注意力。所谓程序员的视觉注意力，指的是人们在执行软件工程任务时目光停留的位置；而代码摘要则是指为一段源代码编写自然语言描述的任务。以往的研究已探讨过程序员在代码摘要过程中的视觉注意力，但绝大多数研究都集中于单个功能单元代码的细节。由于该任务本身的复杂性，目前尚无有效技术能够理解项目层面的代码理解情况，尽管大多数实际工作都是嵌入在复杂的项目上下文中的。本文聚焦于程序员对方法所处调用图上下文的视觉注意力。我们采用基于图的度量指标（如程序员遍历的深度或覆盖范围）来分析调用图的视觉注意力覆盖情况。利用这些度量指标及其他手段，我们重新评估了先前一项眼动追踪研究（n = 10）中已有的数据集，该研究曾关注程序员在项目上下文中视觉注意力的基本特征。随后，我们按照相同流程专门为此研究创建了一个新的数据集（n = 12），总计记录了88小时的程序员源代码视觉行为数据。通过使用我们提出的度量指标，分析了参与者视觉策略与其代码摘要质量以及对摘要信心之间的相关性。有趣的是，我们发现调用图的更高覆盖率反而与摘要质量下降及参与者信心降低相关。"
  },
  {
    "date": "2026-1-28",
    "title": "Training-Control-as-Code: Towards a declarative solution to control training",
    "authors": "Padmanabha V. Seshadri, Harikrishnan Balagopal, Mehant Kammakomati, Ashok Pon Kumar, Dushyant Behl",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00384",
    "source": "IEEE",
    "abstract": "Training-as-a-service platforms facilitate users to deploy pre-configured Generative AI training jobs as batch workloads. The immutability of configuration offers minimal flexibility to dynamically adapt to training progress. Existing approaches invariably involve manually monitoring training progress on a dashboard, and the stop-reconfigure-restart of training does not scale well with number of experiments. Relying on pre-configuration, wastes computational resources and makes debugging of training jobs difficult. We address this gap through our training-control-as-code paradigm, which allows users to run user-defined code to analyze the training state and intervene to flag anomalies and save resource wastage. Our framework TrAC offers a declarative interface to allow for declaring desired control and for reusing it at scale. Using real-world open-source data and models we provide estimates on the savings in time and resource due to TrAC. We also provide demo video: https://youtu.be/RmhBfFjd1oA and code: https://github.com/foundation-model-stack/fms-hf-tuning/blob/main/examples/trainercontroller_configs/Readme.md",
    "title_zh": "训练-控制即代码：迈向控制训练的声明式解决方案",
    "abstract_zh": "训练即服务（Training-as-a-Service）平台使用户能够将预配置的生成式AI训练任务作为批处理作业进行部署。然而，由于配置的不可变性，这类平台在动态适应训练进展方面灵活性极低。现有的方法通常需要手动在仪表板上监控训练进度，而通过“停止-重新配置-重启”方式来调整训练过程，难以随着实验数量的增加而有效扩展。依赖于预先配置的方式不仅浪费计算资源，还使得训练任务的调试变得困难。为此，我们提出了“训练控制即代码”（Training-Control-as-Code）范式，允许用户运行自定义代码来分析训练状态，并主动干预以识别异常，从而避免资源浪费。我们的框架TrAC提供了一种声明式接口，支持用户声明期望的控制逻辑，并可大规模复用。基于真实世界开源数据和模型，我们估算了TrAC在时间和资源节省方面的实际收益。此外，我们还提供了演示视频：https://youtu.be/RmhBfFjd1oA 和代码示例：https://github.com/foundation-model-stack/fms-hf-tuning/blob/main/examples/trainercontroller_configs/Readme.md"
  },
  {
    "date": "2026-1-28",
    "title": "VulSCS: A Source Code Vulnerability Detection System Using Secondary Code Slicing",
    "authors": "Yong Zhong, Bin Liu, Wenyin Yang, Junxian Ye, Jihui Liand Fen Liu",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11343244",
    "source": "IEEE",
    "abstract": "In the context of the information age, the frequent occurrence of software vulnerabilities has emerged as a critical issue demanding immediate resolution. Traditional vulnerability detection methods have struggled to keep pace with the escalating security demands, while the advent of deep learning technology has introduced novel solutions to software vulnerability detection. Deep learning not only facilitates the automatic extraction of features, thereby reducing the cost of manual intervention, but also demonstrates remarkable advantages across various domains. In recent years, research on vulnerability detection based on deep learning has achieved notable progress, yet it still faces several limitations. This study focuses on C/C++ program vulnerability detection and proposes an enhanced approach, VulSCS, based on secondary slicing. By performing secondary slicing on source code exhibiting vulnerable behaviors, this method extracts code segments with higher representational value, thereby capturing richer vulnerability-related features. Experimental results indicate that, compared to state-of-the-art vulnerability detection tools, VulSCS improves detection accuracy by 3.2% and enhances detection efficiency by approximately threefold. This research offers new perspectives and methodologies for deep learningbased software vulnerability detection.",
    "title_zh": "VulSCS：一种基于二次代码切片的源代码漏洞检测系统",
    "abstract_zh": "在信息时代背景下，软件漏洞的频繁出现已成为亟待解决的关键问题。传统漏洞检测方法难以跟上日益增长的安全需求，而深度学习技术的兴起为软件漏洞检测带来了新的解决方案。深度学习不仅能够实现特征的自动提取，降低人工干预成本，还在多个领域展现出显著优势。近年来，基于深度学习的漏洞检测研究取得了显著进展，但仍面临诸多局限性。本研究聚焦于C/C++程序的漏洞检测，提出了一种基于二次切片的改进方法——VulSCS。通过对表现出漏洞行为的源代码进行二次切片，该方法提取出具有更高表征价值的代码片段，从而捕捉更丰富的漏洞相关特征。实验结果表明，与当前最先进的漏洞检测工具相比，VulSCS在检测准确率上提升了3.2%，检测效率提高了约三倍。本研究为基于深度学习的软件漏洞检测提供了新的视角与方法论。"
  },
  {
    "date": "2026-1-28",
    "title": "Demystifying OpenZeppelin’s Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
    "authors": "Han Liu, Daoyuan Wu, Yuqiang Sun, Shuai Wang, Yang Liu, Yixiang Chen",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00083",
    "source": "IEEE",
    "abstract": "OpenZeppelin is a building block for many smart contracts on Ethereum-compatible blockchains. It provides mod-ular and reusable libraries for various Ethereum standards (e.g., ERC20 and ERC721) and common functionalities such as upgradeable contracts. Little research has been done on Open-Zeppelin security except for a recent study, which focused only on the misuse of OpenZeppelin code, assuming OpenZeppelin itself is secure but contract developers may not follow OpenZeppelin’s function checks appropriately. We argue that, despite appearing robust, OpenZeppelin itself could have many vulnerabilities, and these library-level vulnerabilities could inadvertently affect third-party smart contracts, even without misuse from developers.We present ZepCompare, the first end-to-end system for demystifying OpenZeppelin’s own vulnerabilities and analyzing their propagation in third-party smart contracts. ZepCompare incorporates a manual analysis stage where we review OpenZeppelin’s 64 historical releases, identifying 109 vulnerable-fixed code pairs, exposing flaws in cryptographic utilities, access control, etc. Leveraging these pairs, ZepCompare introduces facts of changes, a novel structure capturing vulnerable and fixed code contexts for flexible matching. Evaluated across 88,605 contracts from three Ethereum-compatible chains, ZepCompare detects 4,708 instances of OpenZeppelin-derived vulnerabilities. Manual sampling and a ground-truth experiment confirm that ZepCompare achieves 86.7% precision and 77.1% recall. Our findings reveal significant security risks in both historical and the latest versions of OpenZeppelin libraries, underscoring the urgent need for systematic auditing of foundational contracts components.",
    "title_zh": "揭秘 OpenZeppelin 自身的漏洞及其在智能合约中的传播分析",
    "abstract_zh": "OpenZeppelin 是以太坊兼容区块链上众多智能合约的构建基石，提供模块化且可复用的库，涵盖各种以太坊标准（如 ERC20 和 ERC721）以及升级合约等常见功能。然而，针对 OpenZeppelin 安全性的研究却十分有限，仅有的近期研究也仅关注开发者对 OpenZeppelin 代码的误用问题，假设 OpenZeppelin 本身是安全的，而开发者可能未能正确遵循其函数检查机制。我们认为，尽管 OpenZeppelin 表面看起来稳健，但其自身仍可能存在大量漏洞，这些库级别的漏洞可能在未被开发者误用的情况下，意外影响第三方智能合约。\n\n为此，我们提出了 ZepCompare——首个用于揭示 OpenZeppelin 自身漏洞并分析其在第三方合约中传播情况的端到端系统。ZepCompare 包含一个手动分析阶段，我们审查了 OpenZeppelin 的 64 个历史版本，识别出 109 对存在漏洞与修复的代码变更，暴露出加密工具、访问控制等方面的设计缺陷。基于这些代码对，ZepCompare 引入了一种名为“变更事实”（Facts of Changes）的新结构，能够灵活捕捉漏洞代码与修复代码的上下文信息，实现高效匹配。在三个以太坊兼容链上的 88,605 个智能合约中进行评估，ZepCompare 共检测到 4,708 个由 OpenZeppelin 派生的漏洞实例。通过人工抽样和真实数据验证实验，结果表明 ZepCompare 达到了 86.7% 的精确率和 77.1% 的召回率。\n\n我们的研究发现，无论是历史版本还是最新版本的 OpenZeppelin 库，均存在显著的安全风险，凸显了对基础合约组件进行系统性审计的紧迫性。"
  },
  {
    "date": "2026-1-28",
    "title": "VERT: Polyglot Verified Equivalent Rust Transpilation with Large Language Models",
    "authors": "Aidan Z.H. Yang, Yoshiki Takashima, Brandon Paulsen, Josiah Dodds, Daniel Kroening",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00123",
    "source": "IEEE",
    "abstract": "Rust is a programming language that combines memory safety and low-level control, providing C-like performance while guaranteeing the absence of undefined behaviors by default. Rust’s growing popularity has prompted research on correct and idiomatic transpiling of existing code-bases to Rust. Existing work falls into two categories: rule-based and large language model (LLM)-based. While rule-based approaches are theoretically sound, they often yield unidiomatic and unsafe Rust code, and are limited to few source languages, which hinders maintainability and industrial application. By contrast, LLM-based approaches, while providing no guarantees, are polyglot and typically produce more idiomatic and safe Rust code. In this work, we present VERT, a formally correct, polyglot Rust translator with more idiomatic outputs. VERT supports any language that compiles to Web Assembly. Using the Web Assembly compiler, VERT obtains an oracle Rust program. Leveraging the LLM, VERT generates an idiomatic candidate Rust program. This candidate is verified against the oracle with model-checking to ensure equivalence.",
    "title_zh": "VERT：基于大语言模型的多语言验证等效 Rust 代码转译",
    "abstract_zh": "Rust 是一种结合了内存安全性和底层控制能力的编程语言，能够在提供类似 C 语言性能的同时，默认保证不存在未定义行为。随着 Rust 的日益流行，将现有代码库正确且符合习惯地转换为 Rust 的研究也逐渐增多。现有的工作主要分为两类：基于规则的方法和基于大语言模型（LLM）的方法。虽然基于规则的方法在理论上是可靠的，但通常生成的 Rust 代码既不自然也不安全，且仅支持少数源语言，这限制了其可维护性与工业应用。相比之下，基于 LLM 的方法虽无法提供形式化保证，却具有多语言支持能力，通常能生成更符合习惯、更安全的 Rust 代码。在本工作中，我们提出了 VERT——一个形式上正确、支持多语言的 Rust 转换器，能够生成更加符合习惯的输出。VERT 支持任何可编译为 WebAssembly 的语言。通过 WebAssembly 编译器，VERT 获得一个“标准” Rust 程序（即 oracle 程序）。同时，借助大语言模型，VERT 生成一个符合习惯的候选 Rust 程序。随后，该候选程序通过模型检测技术与 oracle 程序进行验证，以确保两者等价。"
  },
  {
    "date": "2026-1-28",
    "title": "Polyglot: An Extensible Framework to Benchmark Code Translation with LLMs",
    "authors": "Marco Vieira, Priyam Ashish Shah, Bhavain Shah, Rrezarta Krasniqi",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00195",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) show great potential for automating code-related tasks. However, sound assessments are necessary to understand their true capabilities, particularly in code translation, where reliability is crucial. We introduce Polyglot, an automated, multi-language framework for evaluating the translation quality of LLMs between different programming languages. Leveraging the IBM CodeNet Project, an extensive collection of coding problems in multiple languages, we assess translation quality using syntactic correctness, execution reliability, semantic preservation, and static code metrics. Our evaluation focuses on translating C to Java, Python, and Rust, languages that follow distinct paradigms and represent alternatives to modernize C-based systems. We evaluate open-source LLMs using three prompting strategies to understand the impact on translation performance. Our findings highlight that while LLMs show promising results for simple code translation, their limitations regarding complex logic and distinct language paradigms require further analysis.",
    "title_zh": "多语言：一种可扩展的框架，用于评估大语言模型的代码翻译能力",
    "abstract_zh": "大型语言模型（LLMs）在自动化代码相关任务方面展现出巨大潜力。然而，为了准确理解其真实能力，尤其是代码翻译这一对可靠性要求极高的任务，必须进行严谨的评估。我们提出了Polyglot——一个自动化的多语言框架，用于评估LLMs在不同编程语言之间的翻译质量。依托IBM CodeNet项目这一涵盖多种编程语言的海量编码问题数据集，我们通过语法正确性、执行可靠性、语义保真度以及静态代码度量等维度来评估翻译质量。我们的研究重点在于将C语言代码翻译为Java、Python和Rust，这些语言具有截然不同的编程范式，是现代化C语言系统的重要替代方案。我们采用三种不同的提示策略，对开源LLMs进行了评估，以探究提示方式对翻译性能的影响。研究结果表明，尽管LLMs在简单代码翻译任务中表现令人鼓舞，但在处理复杂逻辑及跨语言范式差异时仍存在明显局限，亟需进一步深入分析。"
  },
  {
    "date": "2026-1-28",
    "title": "Evaluating Program Coverage for Code-Model Training",
    "authors": "Nandakishore Menon, Diptikalyan Saha",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00379",
    "source": "IEEE",
    "abstract": "In recent years, CodeLLMs have revolutionized the way developers interact with code. One notable application has been program translation, such as converting COBOL to Java or C to Rust. A critical challenge in this domain is ensuring that CodeLLMs are trained on programs that cover all syntactic features of the target language. This issue is especially pronounced for legacy languages like COBOL and ABAP, which are syntactically rich and have limited availability of open-source programs. In this paper, we present a tool for evaluating the syntactic coverage of COBOL programs. At the core of our approach is a representation called the Coverage Tree, which compactly and intuitively captures the syntactic constructs covered by a set of programs. Additionally, the tool can generate code statements to address uncovered syntactic gaps. Experimental results with COBOL benchmarks demonstrate the effectiveness of the tool. Screencast URL: https://youtu.be/lM0KHzcvllY.",
    "title_zh": "评估程序覆盖以用于代码模型训练",
    "abstract_zh": "近年来，CodeLLMs（代码大语言模型）彻底改变了开发者与代码交互的方式。其中一个显著的应用是程序翻译，例如将COBOL代码转换为Java，或将C语言代码转换为Rust。该领域面临的一个关键挑战是如何确保CodeLLMs在涵盖目标语言所有语法特性的程序上进行训练。这一问题在像COBOL和ABAP这样的遗留语言中尤为突出，因为它们语法结构复杂，且开源可用的程序资源极为有限。本文提出了一种用于评估COBOL程序语法覆盖度的工具。我们方法的核心是一种称为“覆盖率树”（Coverage Tree）的表示形式，它能够紧凑而直观地捕捉一组程序所覆盖的语法构造。此外，该工具还能生成代码语句，以填补未被覆盖的语法空白。在COBOL基准测试上的实验结果证明了该工具的有效性。视频演示链接：https://youtu.be/lM0KHzcvllY。"
  },
  {
    "date": "2026-1-28",
    "title": "ArchERL: Evolutionary Reinforcement Learning Framework for Efficient Hardware Architecture Design without Domain Knowledge",
    "authors": "Yuwei Huang, Yuhui Shi",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11343361",
    "source": "IEEE",
    "abstract": "With the stagnation of Moore’s Law scaling, efficient hardware architectures employing compute-in-memory paradigms have become increasingly crucial to sustain AI innovations. This motivates the development of high-throughput architectures with balanced energy-latency profiles through machine learning algorithms. However, for human-in-the-loop optimization methods, human labor is involved in most of the iterations, whereas for automated methods, either expert domain knowledge is required in the design or the search space is relatively small. To address these challenges, we propose ArchERL, an evolutionary reinforcement learning (ERL) framework that represents the first application of ERL to general hardware architecture design. Specifically, ArchERL tightly couples population-based evolutionary algorithm for global exploration with an actor-critic reinforcement learning module for prior-light policy refinement, and ArchERL employs periodic weight synchronization and gradient feedback between the two modules to achieve efficient collaborative search and rapid convergence. To evaluate the proposed method, extensive experiments are conducted in multiple simulated hardware environments, including the DRAM controller and DNN mapping. The results demonstrate that ArchERL achieves leading performance and outperforms widely used baselines in both efficiency and effectiveness.",
    "title_zh": "ArchERL：一种无需领域知识的高效硬件架构设计进化强化学习框架",
    "abstract_zh": "随着摩尔定律的放缓，采用存内计算范式的高效硬件架构在维持人工智能创新方面变得日益关键。这推动了通过机器学习算法开发高吞吐量、能量-延迟性能均衡的硬件架构。然而，对于人机协同优化方法，大多数迭代过程都依赖人工参与；而对于自动化方法，要么需要专家领域知识进行设计，要么搜索空间相对较小。为应对这些挑战，我们提出了 ArchERL——一种进化强化学习（ERL）框架，这是首次将 ERL 应用于通用硬件架构设计。具体而言，ArchERL 将基于种群的进化算法（用于全局探索）与基于演员-评论家的强化学习模块（用于低先验策略优化）紧密结合，并通过两个模块之间的周期性权重同步和梯度反馈，实现高效的协同搜索与快速收敛。为评估所提方法，我们在多个模拟硬件环境中进行了大量实验，包括 DRAM 控制器和深度神经网络（DNN）映射。结果表明，ArchERL 在效率和有效性方面均表现出领先性能，显著优于广泛使用的基线方法。"
  },
  {
    "date": "2026-1-28",
    "title": "PAT-Agent: Autoformalization for Model Checking",
    "authors": "Xinyue Zuo, Yifan Zhang, Hongshu Wang, Yufan Cai, Zhe Hou, Jing Sun, Jin Song Dong",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00176",
    "source": "IEEE",
    "abstract": "Recent advances in large language models (LLMs) offer promising potential for automating formal methods. However, applying them to formal verification remains challenging due to the complexity of specification languages, the risk of hallucinated output, and the semantic gap between natural language and formal logic. We introduce PAT-Agent, an end-to-end framework for natural language autoformalization and formal model repair that combines the generative capabilities of LLMs with the rigor of formal verification to automate the construction of verifiable formal models. In PAT-Agent, a Planning LLM first extracts key modeling elements and generates a detailed plan using semantic prompts, which then guides a Code Generation LLM to synthesize syntactically correct and semantically faithful formal models. The resulting code is verified using the Process Anal y sis Toolkit (PAT) model checker against user-specified properties, and when discrepancies occur, a Repair Loop is triggered to iteratively correct the model using counterexamples. To improve flexibility, we built a web-based interface that enables users, particularly non-FM-experts, to describe, customize, and verify system behaviors through user-LLM interactions. Experimental results on 40 systems show that PAT-Agent consistently outperforms baselines, achieving high verification success with superior efficiency. The ablation studies confirm the importance of both planning and repair components, and the user study demonstrates that our interface is accessible and supports effective formal modeling, even for users with limited formal methods experience.",
    "title_zh": "PAT-Agent：面向模型检测的自动形式化",
    "abstract_zh": "大型语言模型（LLM）的最新进展为自动化形式化方法带来了广阔前景。然而，将这些模型应用于形式化验证仍面临诸多挑战，包括规格语言的复杂性、生成内容“幻觉”风险，以及自然语言与形式逻辑之间的语义鸿沟。为此，我们提出了PAT-Agent——一个端到端的自然语言自动形式化与形式化模型修复框架。该框架结合了大语言模型的生成能力与形式化验证的严谨性，旨在自动化构建可验证的形式化模型。\n\n在PAT-Agent中，首先由一个规划型LLM通过语义提示提取关键建模元素，并生成详细的建模计划；该计划随后指导代码生成型LLM合成语法正确且语义忠实的形式化模型。生成的代码会使用过程分析工具包（Process Analysis Toolkit, PAT）模型检查器，针对用户指定的性质进行验证。当发现不一致时，系统将触发修复循环，利用反例迭代修正模型，直至满足要求。\n\n为提升灵活性，我们开发了一个基于Web的交互界面，使用户（尤其是非形式化方法专家）能够通过与LLM的互动，描述、定制并验证系统行为。实验结果表明，在40个系统上的测试中，PAT-Agent始终优于基线方法，不仅实现了高成功率的验证，还展现出卓越的效率。消融实验验证了规划与修复两个核心组件的重要性；用户研究进一步证明，该界面具有良好的可用性，即使对于形式化方法经验有限的用户也能有效支持其完成形式化建模任务。"
  },
  {
    "date": "2026-1-28",
    "title": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
    "authors": "Zhengshu Wang, Peng He, Fuchen Ma, Yuanliang Chen, Shuoshuo Duan, Yiyuan Bai, Yu Jiang",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00052",
    "source": "IEEE",
    "abstract": "USB is a widely used interface standard in modern operating systems for connecting computers to various external devices. External devices can launch attacks by injecting random data into the host via USB, causing memory errors or even system-level crashes. Fuzzing has been proven to be an effective method to detect USB driver vulnerabilities. However, existing fuzzing methods generate testing inputs without considering the format and semantics of USB descriptors, which define device functionality. As a result, many test cases fail to pass the host’s input validation mechanism, leading to ineffective testing.In this paper, we propose DNAFuzz, a USB driver fuzzer that generates descriptor-aware payloads. First, it utilizes USB specifications to parse the field definitions and item types of USB descriptors for modeling. Then, based on the field description list and semantic information, DNAFuzz designs mutation strategies to guide the generation of payloads. This approach improves the quality of test cases and the fuzzing effectiveness. Currently, we evaluated DNAFuzz on multiple versions of Linux kernel USB drivers and compared it with state-of-the-art fuzzers, including USBFuzz and Syzkaller. Results show that DNAFuzz significantly improves input quality, successfully increasing the proportion of tests with execution times exceeding 2 seconds by 358% and 65%. In addition, DNAFuzz detected 15 bugs, 11 of which have been fixed or confirmed by the corresponding maintainers.",
    "title_zh": "DNAFuzz：面向USB驱动程序的描述符感知模糊测试",
    "abstract_zh": "USB 是现代操作系统中广泛使用的接口标准，用于连接计算机与各种外部设备。攻击者可通过 USB 接口向主机注入随机数据，从而引发内存错误甚至系统级崩溃。模糊测试（Fuzzing）已被证明是检测 USB 驱动漏洞的有效方法。然而，现有的模糊测试方法在生成测试输入时未考虑 USB 描述符的格式和语义，而这些描述符定义了设备的功能。因此，许多测试用例无法通过主机的输入验证机制，导致测试效率低下。\n\n本文提出了一种名为 DNAFuzz 的 USB 驱动模糊测试工具，能够生成具有描述符感知能力的测试载荷。首先，DNAFuzz 利用 USB 规范解析 USB 描述符的字段定义和项类型，并据此建立模型；随后，基于字段描述列表和语义信息，设计针对性的变异策略以指导载荷生成。该方法显著提升了测试用例的质量和模糊测试的效率。目前，我们在多个版本的 Linux 内核 USB 驱动上对 DNAFuzz 进行了评估，并与当前最先进的模糊测试工具（包括 USBFuzz 和 Syzkaller）进行了对比。实验结果表明，DNAFuzz 显著提升了输入质量，使执行时间超过 2 秒的测试用例比例分别提高了 358% 和 65%。此外，DNAFuzz 共发现了 15 个漏洞，其中 11 个已由相关维护者修复或确认。"
  },
  {
    "date": "2026-1-28",
    "title": "Twin Prompt: An End-to-End Framework Inspired by Human Cognition for Navigating Language Model Reasoning",
    "authors": "Ren Zhuang, Ben Wang, Shuifa Sun",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11343657",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) provide essential capabilities for smart systems, yet navigating complex reasoning frontiers reliably remains challenging, hindering deployment in dynamic environments. Existing prompting methods often lack robustness or demand costly multi-step interaction. We introduce Twin Prompt, a novel automated framework inspired by human cognition, operationalizing structured problem reformulation and answer refinement within a single, end-to-end interaction requiring no manual examples. This cognitively grounded structure guides the LLM’s internal reasoning, enhancing analysis and leveraging latent self-correction capabilities to improve accuracy and reliability. Evaluations on challenging mathematical and general reasoning benchmarks (GSM8K, MATH, MMLU, BBH) demonstrate Twin Prompt significantly boosts performance over standard baselines across diverse LLMs. These findings highlight the potential of structured, single-pass prompting to advance LLM reasoning, enabling more capable and dependable AI components for navigating a dynamic world.",
    "title_zh": "双提示：一种受人类认知启发的端到端框架，用于导航语言模型推理",
    "abstract_zh": "大型语言模型（LLMs）为智能系统提供了关键能力，然而在复杂推理领域实现可靠导航仍具挑战性，这限制了其在动态环境中的部署。现有的提示方法往往缺乏鲁棒性，或需要代价高昂的多步交互。我们提出了一种名为 Twin Prompt 的新型自动化框架，该框架受人类认知启发，通过单一、端到端的交互即可实现结构化问题重构与答案优化，无需人工示例。这一基于认知的结构引导大模型内部推理过程，提升分析能力，并利用其潜在的自我修正机制，从而提高准确性和可靠性。在具有挑战性的数学与通用推理基准测试（GSM8K、MATH、MMLU、BBH）上的评估表明，Twin Prompt 在多种大模型上均显著优于标准基线。这些发现凸显了结构化单次提示在推动大模型推理能力方面的潜力，有助于构建更强大且可靠的AI组件，以应对动态世界中的复杂挑战。"
  },
  {
    "date": "2026-1-28",
    "title": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
    "authors": "Juantao Zhong, Daoyuan Wu, Ye Liu, Maoyi Xie, Yang Liu, Yi Li, Ning Liu",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00149",
    "source": "IEEE",
    "abstract": "DeFi (Decentralized Finance) is one of the most important applications of today’s cryptocurrencies and smart contracts. It manages hundreds of billions in Total Value Locked (TVL) on-chain, yet it remains susceptible to common DeFi price manipulation attacks. Despite state-of-the-art (SOTA) systems like DeFiRanger and DeFort, we found that they are less effective to non-standard price models in custom DeFi protocols, which account for 44.2% of the 95 DeFi price manipulation attacks reported over the past three years.In this paper, we introduce the first LLM-based approach, DeFiScope, for detecting DeFi price manipulation attacks in both standard and custom price models. Our insight is that large language models (LLMs) have certain intelligence to abstract price calculation from smart contract source code and infer the trend of token price changes based on the extracted price models. To further strengthen LLMs in this aspect, we leverage Foundry to synthesize on-chain data and use it to fine-tune a DeFi price-specific LLM. Together with the high-level DeFi operations recovered from low-level transaction data, DeFiScope detects various DeFi price manipulations according to systematically mined patterns. Experimental results show that DeFiScope achieves a high recall of 80% on real-world attacks, a precision of 96% on suspicious transactions, and zero false alarms on benign transactions, significantly outperforming SOTA approaches. Moreover, we evaluate DeFiScope’s cost-effectiveness and demonstrate its practicality by helping our industry partner confirm 147 real-world price manipulation attacks, including discovering 81 previously unknown historical incidents.",
    "title_zh": "利用大语言模型推理检测各种DeFi价格操纵行为",
    "abstract_zh": "去中心化金融（DeFi）是当今加密货币与智能合约最重要的应用之一。它在链上管理着数千亿美元的总锁仓价值（TVL），但仍容易受到常见的DeFi价格操纵攻击。尽管已有最先进的系统如DeFiRanger和DeFort，但我们发现它们在应对自定义DeFi协议中非标准价格模型时效果有限，而这类模型正是过去三年中95起DeFi价格操纵攻击中的44.2%所采用的。本文提出首个基于大语言模型（LLM）的检测方法——DeFiScope，用于识别标准及自定义价格模型下的DeFi价格操纵攻击。我们的核心洞察是：大语言模型具备一定的抽象能力，能够从智能合约源代码中提取价格计算逻辑，并基于所解析出的价格模型推断代币价格的变化趋势。为进一步增强LLM在此任务上的表现，我们利用Foundry生成链上数据，并以此对专为DeFi价格场景定制的LLM进行微调。结合从低层交易数据中恢复的高层DeFi操作行为，DeFiScope能够根据系统性挖掘出的模式，有效检测各类DeFi价格操纵行为。实验结果表明，DeFiScope在真实攻击事件中实现了80%的高召回率，在可疑交易中达到96%的精确率，且在正常交易中零误报，显著优于现有最先进方法。此外，我们评估了DeFiScope的成本效益，并通过帮助行业合作伙伴确认147起真实世界的价格操纵攻击，验证了其实际应用价值，其中包括发现了81起此前未知的历史攻击事件。"
  },
  {
    "date": "2026-1-28",
    "title": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
    "authors": "Ruowei Fu, Yang Zhang, Zeyu Che, Xin Wu, Zhenyu Zhong, Zhiqiang Ren, Shenglin Zhang, Feng Wang, Yongqian Sun, Xiaozhou Liu, Kexin Liu, Yu Zhang",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00184",
    "source": "IEEE",
    "abstract": "In large-scale enterprises, on-call engineers (OCEs) are critical for ensuring service availability and reliability. However, as incidents grow in volume and complexity, traditional manual on-call processes are becoming increasingly inadequate. Recent advances in large language models (LLMs) have demonstrated remarkable capabilities in reasoning and multi-agent collaboration, presenting new opportunities for automation. We propose OncallX, an end-to-end automated on-call system designed for real-world industrial scenarios that integrates LLMs with multi-agent cooperation to enable intelligent and efficient incident management. OncallX first enhances user queries by leveraging external knowledge bases and multi-turn dialogue interactions. Subsequently, multiple expert agents collaborate through tree-search-based mechanisms to generate effective responses and solutions. When incidents cannot be resolved automatically, OncallX accurately assigns them to the most appropriate teams. Comprehensive experiments conducted in the real-world production environment of a top-tier global online video service provider demonstrate that OncallX efficiently responds to incidents and accurately triages tickets, significantly outperforming existing methods in both automated metrics and human evaluations. Furthermore, OncallX has been successfully deployed in production for two months, during which it has substantially enhanced on-call efficiency, reducing average incident response time to just 21 seconds and average triage time to 4 seconds—representing a transformative improvement in operational excellence.",
    "title_zh": "基于大模型的多智能体协作在工业智能值守自动化中的应用",
    "abstract_zh": "在大型企业中，值班工程师（OCEs）对于保障服务的可用性和可靠性至关重要。然而，随着事件数量和复杂性的不断增加，传统的手动值班流程正变得日益不足。近年来，大语言模型（LLMs）在推理能力和多智能体协作方面取得了显著进展，为自动化带来了新的机遇。我们提出了OncallX——一个面向真实工业场景的端到端自动化值班系统，该系统将大语言模型与多智能体协作相结合，实现智能化、高效的事件管理。OncallX首先通过外部知识库和多轮对话交互增强用户查询，随后多个专家智能体通过基于树搜索的机制协同工作，生成有效响应与解决方案。当事件无法自动解决时，OncallX能够精准地将其分配给最合适的团队。在一家全球顶级在线视频服务提供商的真实生产环境中开展的全面实验表明，OncallX在事件响应和工单分诊方面表现高效且准确，无论是自动化指标还是人工评估，均显著优于现有方法。此外，OncallX已在生产环境成功部署两个月，显著提升了值班效率，平均事件响应时间缩短至21秒，平均分诊时间降至4秒，实现了运营卓越性的根本性提升。"
  },
  {
    "date": "2026-1-28",
    "title": "Tron: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
    "authors": "Qiang Zhang, Yifei Chu, Yuheng Shen, Jianzhong Liu, Heyuan Shi, Yu Jiang, Wanli Chang",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00266",
    "source": "IEEE",
    "abstract": "The Linux kernel network stack is a critical component of modern operating systems, widely deployed across platforms and often exposed to untrusted inputs. Its complex and stateful nature makes it a frequent target of security vulnerabilities, particularly those triggered by subtle protocol interactions. While existing fuzzers like syzkaller have demonstrated strong capabilities in discovering kernel bugs, they face challenges in exercising deep protocol logic due to the lack of coordinated inputs and protocol awareness. In this paper, we present Tron, a tool designed for fuzzing the Linux kernel network stack. By synthesizing syscall–packet input sequences based on protocol structure and incorporating runtime feedback, Tron enables the exploration of protocol-dependent state transitions and deep execution paths. Our approach addresses the fundamental challenges in dual-input fuzzing by integrating protocol knowledge with execution feedback. We evaluate Tron on four recent Linux kernel versions and compare it against syzkaller and kernelGPT. The results show that Tron improves branch coverage by 22.9% and 12.1% over syzkaller and kernelGPT, respectively, and discovers 25 previously unknown bugs, 7 of which have been fixed. These results demonstrate the effectiveness of protocol–system call input synthesis in enhancing network stack fuzzing and uncovering hard-to-reach bugs in kernel protocol implementations.",
    "title_zh": "特龙：通过协议-系统调用载荷合成对Linux网络栈进行模糊测试",
    "abstract_zh": "Linux内核网络栈是现代操作系统中一个至关重要的组件，广泛部署于各类平台，并经常面临不可信输入的威胁。由于其复杂且具有状态性的特点，该组件常常成为安全漏洞的攻击目标，尤其是由微妙的协议交互所触发的漏洞。尽管现有的模糊测试工具（如 syzkaller）在发现内核缺陷方面已展现出强大的能力，但它们在深入执行协议逻辑时仍面临挑战，主要原因是缺乏协调的输入和对协议语义的理解。本文提出 Tron，一种专为 Linux 内核网络栈模糊测试设计的工具。Tron 基于协议结构生成系统调用与数据包输入序列，并结合运行时反馈机制，能够有效探索依赖协议的状态转换及深层执行路径。我们的方法通过将协议知识与执行反馈相结合，解决了双输入模糊测试中的根本性难题。我们在四个近期版本的 Linux 内核上评估了 Tron，并与 syzkaller 和 kernelGPT 进行对比。实验结果表明，Tron 在分支覆盖率方面分别比 syzkaller 和 kernelGPT 提高了 22.9% 和 12.1%，并成功发现了 25 个此前未知的漏洞，其中 7 个已被修复。这些结果充分证明，基于协议与系统调用的输入合成策略能显著提升网络栈模糊测试的效果，有效挖掘出传统方法难以触及的内核协议实现中的隐蔽缺陷。"
  },
  {
    "date": "2026-1-28",
    "title": "Generalizable Secure Code Generation Framework for Robust Software Development Practices",
    "authors": "Sandana Karuppan. A, Sanjay Shanmugasundaram, Jithesh Mouriya, J Sanjeeth",
    "publish": "2025 5th International Conference on Mobile Networks and Wireless Communications (ICMNWC)",
    "url": "https://doi.org/10.1109/icmnwc66779.2025.11354349",
    "source": "IEEE",
    "abstract": "The large language models, and AI-assisted programming tools have made software development easier, particularly through the rapid growth of automated code generation, however, have also presented a significant security risk simultaneously. The code generated by such systems is more likely to be functional correctness and overlook certain vital protection against vulnerability (such as injection attacks, memory corruption and unsafe use of libraries). In order to address this gap, the present paper proposes a universal framework of producing secure codes with the objective of facilitating valid principles of software development. The architecture is a union of security aware training policies, multistage pipelines of code generated and automated vulnerability detection algorithms, such that the generated code adheres to the specified guidelines of security. It has been demonstrated by the benchmark testing of different programming languages and a wide array of datasets that the framework has the capacity to extrapolate beyond the small scale and the insecurity rates of insecure code pattern is reduced significantly with both correctness and efficiency maintained. The publication will be one of the steps to achieving the balance between the productivity gained through the assistance of AI-based coding and the necessity to possess the trustful and secure software engineering.",
    "title_zh": "可泛化的安全代码生成框架，用于构建稳健的软件开发实践",
    "abstract_zh": "大型语言模型及AI辅助编程工具虽使软件开发变得更加便捷，尤其得益于自动化代码生成的迅猛发展，但同时也带来了显著的安全风险。这类系统生成的代码往往更注重功能正确性，却容易忽视对关键漏洞（如注入攻击、内存破坏及不安全的库使用）的有效防护。为弥补这一差距，本文提出了一种通用框架，旨在生成符合安全规范的代码，推动软件开发中有效安全原则的落实。该框架融合了具备安全意识的训练策略、多阶段代码生成流程以及自动化的漏洞检测算法，确保生成的代码严格遵循既定的安全准则。通过在多种编程语言和广泛数据集上的基准测试验证，该框架展现出超越小规模应用的能力，显著降低了不安全代码模式的出现率，同时保持了代码的正确性与效率。本研究将为实现基于AI编程带来的开发效率提升与构建可信、安全的软件工程之间的平衡迈出重要一步。"
  },
  {
    "date": "2026-1-28",
    "title": "The AI-Cybersecurity Nexus: How Large Language Models Are Reshaping Threat Intelligence and Digital Defense",
    "authors": "Recep Özbay, Merve Çelebi, Uraz Yavanoğlu",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3658308",
    "source": "IEEE",
    "abstract": "As cybersecurity threats become more sophisticated, the integration of Large Language Models (LLMs) into defensive and analytical systems is transforming the field. This paper presents a PRISMA-guided bibliometric and thematic review of 149 studies published between 2015 and 2025, including 117 peer-reviewed journal and conference articles, examining publication trends and dominant research themes in LLM-enabled cybersecurity, organized around five research questions: (i) secure incorporation of LLMs into cyber threat intelligence workflows; (ii) hybrid architectures for privacy-preserving and real-time threat detection; (iii) LLM-enabled secure code remediation; (iv) adversarial misuse and dual-use risks; and (v) multi-layer defense strategies addressing prompt injection, model inversion, and data poisoning. Drawing on over 100 primary studies, the analysis highlights key trends, methodological innovations, and recurring vulnerabilities. Notable developments include decentralized trust-enhanced frameworks, context-aware remediation systems, and simulation-based red teaming. However, gaps persist in adversarial robustness, standardization of evaluation, and ethical governance. By mapping research across technical, operational, and policy dimensions, this review provides a structured basis for advancing trustworthy, resilient, and secure LLMs deployments in high-stakes cybersecurity contexts.",
    "title_zh": "人工智能与网络安全的交汇：大语言模型如何重塑威胁情报与数字防御",
    "abstract_zh": "随着网络攻击手段日益复杂，大型语言模型（LLMs）在防御与分析系统中的集成正深刻改变着网络安全领域。本文基于PRISMA指南，对2015年至2025年间发表的149项研究（包括117篇经过同行评审的期刊与会议论文）进行了文献计量与主题综述，围绕五个核心研究问题展开：（i）LLM在网络安全威胁情报工作流中的安全集成；（ii）兼顾隐私保护与实时性要求的混合架构；（iii）基于LLM的代码安全修复；（iv）对抗性滥用与双重用途风险；（v）应对提示注入、模型反演和数据污染等威胁的多层防御策略。基于超过100项原始研究的分析，本文揭示了主要发展趋势、方法学创新以及反复出现的安全漏洞。显著进展包括去中心化信任增强框架、上下文感知的修复系统，以及基于仿真的红队测试方法。然而，在对抗鲁棒性、评估标准统一性以及伦理治理方面仍存在明显空白。通过从技术、操作与政策三个维度全面映射研究现状，本综述为推动高风险网络安全场景中可信、稳健且安全的LLM部署提供了系统性基础。"
  },
  {
    "date": "2026-1-28",
    "title": "Using Active Learning to Train Predictive Mutation Testing with Minimal Data",
    "authors": "Miklós Borsi",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00217",
    "source": "IEEE",
    "abstract": "Mutation testing is a powerful method of evaluating test suite adequacy. Despite growing industry attention, wide-scale application is frequently limited by the high runtime cost of mutation testing. A set of predictive models have been proposed to mitigate this cost issue, intending to replace the actual execution of a mutated program’s test suite with a predicted result of the tests’ outcome. These predictive models ingest static code features, dynamic execution features, or code and documentation text to produce the predictions. Feature-based models can require a large amount of training data and mutants executed by test cases to become operational. We propose active learning-based predictive mutation testing (AL-PMT) as a way to dramatically reduce the amount of training data needed for a performant model. We conduct experiments to compare AL-PMT’s performance with a non-active learning model and find that AL-PMT quickly converges to improved or on-par performance compared to the baseline of the foundational PMT. AL-PMT achieves 98% of its best possible performance in over 80% of examined projects, while observing only 10% of each project’s mutant set kill status. In addition to training in a fraction of the data required for previous models, AL-PMT is organized in a way that is more amenable to a potential industry application scenario. Besides not requiring the building, running and full mutation testing of several other projects or versions for training data, AL-PMT is able to identify challenging mutants and select them for execution. As such, we expand on the coverage metric provided by basic predictive mutation testing with the ability to guide the targeted execution of important mutants and guiding attention of developers to remaining survived ones. This addresses the rarely mentioned cost of human developer time on fixing the findings of mutation testing, rather than just the computational time spent producing the mutants.",
    "title_zh": "使用主动学习以最少数据训练预测性突变测试",
    "abstract_zh": "变异测试是一种评估测试套件充分性的强大方法。尽管工业界对其关注日益增加，但其广泛应用常受限于变异测试带来的高昂运行成本。为缓解这一问题，已有研究提出一系列预测模型，旨在用预测结果替代对变异程序测试套件的实际执行。这些预测模型利用静态代码特征、动态执行特征或代码与文档文本生成预测结果。然而，基于特征的模型通常需要大量训练数据以及由测试用例执行的变异体，才能达到可用状态。\n\n本文提出一种基于主动学习的预测变异测试（AL-PMT）方法，以显著减少高性能模型所需的训练数据量。我们通过实验对比了AL-PMT与非主动学习模型的性能，发现AL-PMT能够快速收敛至优于或等同于基础预测变异测试（PMT）基线的性能。在所考察的项目中，AL-PMT在仅观察每个项目10%的变异体存活状态的情况下，便达到了其最佳性能的98%以上。此外，与以往模型相比，AL-PMT仅需极小部分的训练数据即可完成训练，且其设计更适用于潜在的工业应用场景。它无需构建、运行并进行全面变异测试多个其他项目或版本以获取训练数据，同时还能识别出具有挑战性的变异体，并主动选择它们进行执行。\n\n因此，AL-PMT不仅扩展了基础预测变异测试所提供的覆盖率指标，还具备引导针对性执行关键变异体的能力，并帮助开发人员聚焦于仍存活的变异体。这解决了极少被提及的问题：即修复变异测试结果所耗费的人力开发者时间成本，而不仅仅是生成变异体所消耗的计算时间。"
  },
  {
    "date": "2026-1-28",
    "title": "MIDAS: An Energy-Efficient Microscaling Digital Compute-In-Memory-Based Accelerator with Spatio-Temporal Cyclic Alignment for Generative AI Inference",
    "authors": "Jiwon Choi, Seongyon Hong, Wooyoung Jo, Wonhoon Park, Sunjoo Whang, Sangjin Kim, Hoi-Jun Yoo",
    "publish": "2025 IEEE Asian Solid-State Circuits Conference (A-SSCC)",
    "url": "https://doi.org/10.1109/a-sscc67472.2025.11349585",
    "source": "IEEE",
    "abstract": "Generative AI (GenAI), including large language models (LLMs) and diffusion models, is rapidly advancing with substantial deployment demand. However, their large memory footprints and high computational costs constrain deployment on edge devices. Digital compute-in-memory (DCIM) accelerators have emerged as a promising solution for energy-efficient GenAl processing [1–4]. Meanwhile, various low bit-width data formats have been proposed for GenAI. However, outliers in weights and activations pose significant quantization challenges. Microscaling (MX) format, a standardized sub-8-bit representation, constrains the quantization range within each block, thereby mitigating the impact of outliers while maintaining accuracy with reduced bit-width [5, 6].",
    "title_zh": "MIDAS：一种面向生成式AI推理的节能微缩数字存内计算加速器，具备时空循环对齐特性",
    "abstract_zh": "生成式人工智能（GenAI），包括大语言模型（LLMs）和扩散模型，正迅速发展，并面临巨大的部署需求。然而，其庞大的内存占用和高昂的计算成本限制了在边缘设备上的部署。数字存内计算（DCIM）加速器作为一种节能高效的GenAI处理方案应运而生[1–4]。与此同时，针对GenAI提出了多种低比特宽数据格式。然而，权重和激活值中的异常值给量化带来了重大挑战。微缩放（MX）格式作为一种标准化的低于8比特的表示方法，通过将每个块内的量化范围进行约束，有效缓解了异常值的影响，同时在降低比特宽度的同时保持了较高的精度[5, 6]。"
  },
  {
    "date": "2026-1-28",
    "title": "HybridSIMD: A Super C++ SIMD Library with Integrated Auto-tuning Capabilities",
    "authors": "Haolin Pan, Xulin Zhou, Mingjie Xing, Yanjun Wu",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00147",
    "source": "IEEE",
    "abstract": "Single Instruction, Multiple Data (SIMD) technology is crucial for enhancing computational efficiency in High-Performance Computing (HPC). While C++ SIMD libraries abstract away low-level complexities, their proliferation has led to a fragmented set of libraries, creating significant challenges in both performance and usability for developers. To overcome these library-level limitations, this paper introduces a new collaborative concept for SIMD library design. We present HybridSIMD, a C++ library to embody this principle, resolving fragmentation through a unified interface and an operator-level collaborative back-end that leverages the collective strengths of existing libraries. A built-in auto-tuning engine, featuring a hierarchical search strategy, automatically navigates the rich optimization space created by this collaborative approach to deliver maximum performance without manual intervention. Experimental results across six real-world HPC benchmarks on AVX2, AVX512, and NEON architectures demonstrate HybridSIMD’s superiority. Notably, the highest speedups achieved are 185.34× on AVX2, 97.80× on AVX512, and 71.32× on NEON, showcasing its effectiveness in resolving fragmentation while delivering state-of-the-art performance. Our artifact is available at https://github.com/Panhaolin2001/HybridSIMD.",
    "title_zh": "HybridSIMD：一个集成自动调优功能的超C++ SIMD库",
    "abstract_zh": "单指令多数据（SIMD）技术对于提升高性能计算（HPC）中的计算效率至关重要。尽管C++ SIMD库抽象了底层复杂性，但其数量的激增导致了库生态的碎片化，给开发者带来了性能和可用性方面的重大挑战。为克服这些库级限制，本文提出了一种新的SIMD库设计协同理念。我们介绍了HybridSIMD——一个实现该理念的C++库，通过统一接口与操作级协同后端，整合现有库的优势，有效解决碎片化问题。该库内置自动调优引擎，采用分层搜索策略，能够自动探索由协同机制带来的丰富优化空间，在无需人工干预的情况下实现最佳性能。在AVX2、AVX512和NEON架构上对六个真实世界HPC基准测试的实验结果表明，HybridSIMD表现出显著优势。其中，最高加速比分别达到AVX2上的185.34×、AVX512上的97.80×以及NEON上的71.32×，充分展示了其在缓解库碎片化问题的同时，实现顶尖性能的能力。我们的研究成果可于 https://github.com/Panhaolin2001/HybridSIMD 获取。"
  },
  {
    "date": "2026-1-28",
    "title": "TD4ITG: A Test Data Generation Method for Issue Title Generation Models",
    "authors": "Jingjing Chen, Jun Yang, Qifan He, Zhanqi Cui, Zheng Zeng",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11343653",
    "source": "IEEE",
    "abstract": "In open-source software platforms, users utilize issues to report software bugs or request new features. To improve the quality of issues, researchers have proposed several methods for issue title generation. It is widely recognized that deep learning models often suffer from robustness limitations, as minor input perturbations can lead to incorrect or significantly altered outputs. In this paper, we investigate the robustness of issue title generation models and propose a corresponding test data generation method, TD4ITG. This method leverages large language models in combination with chain-of-thought prompting to automatically generate test data to evaluate robustness. Experimental results demonstrate that both iTAPE and iTiger, two issue title generation models, exhibit robustness problems. Specifically, the test data generated by TD4ITG leads to a performance degradation of 21.73% for iTAPE, reducing its score to 75.00%, and a degradation of 17.34% for iTiger, reducing its score to 45.98%. Compared to MATS, a recently proposed testing method for text summarization models, TD4ITG is more effective in revealing the robustness limitations of the models.",
    "title_zh": "TD4ITG：一种用于问题标题生成模型的测试数据生成方法",
    "abstract_zh": "在开源软件平台中，用户通过提交问题（issues）来报告软件漏洞或请求新功能。为了提升问题的质量，研究人员提出了多种自动生成问题标题的方法。然而，人们普遍认识到，深度学习模型往往存在鲁棒性不足的问题，微小的输入扰动就可能导致输出错误或发生显著变化。本文研究了问题标题生成模型的鲁棒性，并提出了一种相应的测试数据生成方法——TD4ITG。该方法结合大型语言模型与思维链（chain-of-thought）提示技术，自动构建测试数据以评估模型的鲁棒性。实验结果表明，两种问题标题生成模型 iTAPE 和 iTiger 均存在鲁棒性缺陷。具体而言，TD4ITG 生成的测试数据导致 iTAPE 的性能下降 21.73%，其得分降至 75.00%；而 iTiger 的性能下降 17.34%，得分降至 45.98%。与近期提出的用于文本摘要模型测试的 MATS 方法相比，TD4ITG 在揭示模型鲁棒性缺陷方面表现更为有效。"
  },
  {
    "date": "2026-1-28",
    "title": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
    "authors": "Tianyue Jiang, Yanli Wang, Yanlin Wang, Daya Guo, Ensheng Shi, Yuchi Ma, Jiachi Chen, Zibin Zheng",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00085",
    "source": "IEEE",
    "abstract": "Repository-level code completion remains a challenging task for existing code large language models (code LLMs) due to their limited understanding of repository-specific context and domain knowledge. While retrieval-augmented generation (RAG) approaches have shown promise by retrieving relevant code snippets as cross-file context, they suffer from two fundamental problems: misalignment between the query and the target code in the retrieval process, and the inability of existing retrieval methods to effectively utilize the inference information. To address these challenges, we propose AlignCoder, a repository-level code completion framework that introduces a query enhancement mechanism and a reinforcement learning based retriever training method. Our approach generates multiple candidate completions to construct an enhanced query that bridges the semantic gap between the initial query and the target code. Additionally, we employ reinforcement learning to train an AlignRetriever that learns to leverage inference information in the enhanced query for more accurate retrieval. We evaluate AlignCoder on two widely-used benchmarks (CrossCodeEval and RepoEval) across five backbone code LLMs, demonstrating an 18.1% improvement in EM score compared to baselines on the CrossCodeEval benchmark. The results show that our framework achieves superior performance and exhibits high generalizability across various code LLMs and programming languages.",
    "title_zh": "AlignCoder：面向仓库级代码补全的检索与目标意图对齐",
    "abstract_zh": "由于现有代码大语言模型（code LLMs）对仓库特定上下文和领域知识的理解有限，仓库级代码补全仍然是一个具有挑战性的任务。尽管检索增强生成（RAG）方法通过检索相关代码片段作为跨文件上下文展现出了潜力，但其仍存在两个根本性问题：检索过程中查询与目标代码之间的语义错位，以及现有检索方法无法有效利用推理信息。为解决这些挑战，我们提出了AlignCoder，一种面向仓库级代码补全的框架，引入了查询增强机制和基于强化学习的检索器训练方法。我们的方法生成多个候选补全结果，以构建一个增强后的查询，从而弥合初始查询与目标代码之间的语义鸿沟。此外，我们采用强化学习训练一个AlignRetriever，使其能够利用增强查询中的推理信息，实现更精准的检索。我们在两个广泛使用的基准测试（CrossCodeEval 和 RepoEval）上，针对五种不同的骨干代码LLM进行了评估，结果显示在CrossCodeEval基准上，相比基线模型，EM得分提升了18.1%。实验结果表明，我们的框架不仅性能优越，而且在多种代码LLM和编程语言之间展现出良好的泛化能力。"
  },
  {
    "date": "2026-1-28",
    "title": "AI-Based Resource Scheduling in 5G NOMA Cellular Networks",
    "authors": "Mincheng Zhao, Mingqing Han, Ligang Du, Jiyuan Pan, Yongfeng Yan, Fuqiang Li",
    "publish": "2025 Seventeenth International Conference on Wireless Communications and Signal Processing (WCSP)",
    "url": "https://doi.org/10.1109/wcsp68525.2025.1010655",
    "source": "IEEE",
    "abstract": "The deployment of 5G networks has introduced advanced multiple access technology such as Sparse Code Multiple Access (SCMA) to meet the growing demand for high spectral efficiency and massive connectivity. SCMA, a nonorthogonal multiple access (NOMA) technique, allows multiple users to share the same time-frequency resources through sparse codebook-based multiplexing. However, efficient scheduling in SCMA networks presents significant challenge due to the complexities of dynamic resource allocation. In this paper, we propose two Artificial Intelligence (AI)-based methods, corresponding a Multi-Agent Deep Reinforcement Learning (MARL) approach and a Large Language Model (LLM)-empowered approach, for resource scheduling in 5G SCMA networks. we study the AI methods to solve optimal resource scheduling policies that adapt to varying network conditions. Through extensive simulations, we demonstrate that the AI-based schedulers can effectively learn the scheduling strategies and achieve better performance as genieaided methods compared with traditional scheduling algorithms in terms of throughput, and user fairness.",
    "title_zh": "基于人工智能的5G非正交多址（NOMA）蜂窝网络资源调度",
    "abstract_zh": "5G网络的部署引入了稀疏码多址接入（SCMA）等先进多址技术，以满足日益增长的高谱效率和海量连接需求。SCMA作为一种非正交多址（NOMA）技术，通过基于稀疏码本的复用方式，允许多个用户共享相同的时频资源。然而，由于动态资源分配的复杂性，SCMA网络中的高效调度仍面临重大挑战。本文提出两种基于人工智能（AI）的方法：一种是多智能体深度强化学习（MARL）方法，另一种是大语言模型（LLM）赋能的方法，用于5G SCMA网络中的资源调度。我们研究了这些AI方法在不同网络条件下求解最优资源调度策略的能力。通过大量仿真验证，结果表明，基于AI的调度器能够有效学习调度策略，在吞吐量和用户公平性方面均优于传统调度算法，且接近理想情况下的“神谕辅助”方法性能。"
  },
  {
    "date": "2026-1-28",
    "title": "Efficient Micro-Segmentation Generation for Wireless Network Zero-Trust Security: A Graph Diffusion-Based Approach",
    "authors": "Yinqiu Liu, Guangyuan Liu, Tianwen Zhu, Jingjing Wang, Qiuming Zhu, Hongyang Du, Dusit Niyato",
    "publish": "2025 Seventeenth International Conference on Wireless Communications and Signal Processing (WCSP)",
    "url": "https://doi.org/10.1109/wcsp68525.2025.1010901",
    "source": "IEEE",
    "abstract": "Zero-trust security has emerged as a critical form for addressing the unique vulnerabilities of wireless networks, but its implementation faces significant practical challenges. First, realizing zero-trust requires partitioning the network into multiple isolated, application-specific micro-segmentations with customized security policies. Second, to accommodate increasingly complex service demands, service provisioning within micro-segmentations should utilize Service Function Chains (SFCs) that distribute services across heterogeneous devices. Therefore, this paper proposes an efficient micro-segmentation generation approach called LLM-enhanced Graph Diffusion (LGD). Specifically, we model zero-trust wireless networks as a hierarchical graph structure that captures both physical characteristics and trustworthiness relationships, and formulate the micro-segmentation generation problem as a controllable generation problem. Additionally, we present LGD based on graph diffusion models that optimize micro-segmentation through a progressive denoising process. Furthermore, LGD leverages the cognitive capabilities of Large Language Models (LLMs) to reduce action space dimensions through intelligent filtering and heuristic guidance, thereby accelerating convergence and improving solution quality. Extensive experiments demonstrate that LGD-generated micro-segmentations achieve 40% higher service provisioning efficiency compared to existing baseline approaches. Moreover, comprehensive evaluations across various network scenarios showcase the scalability and robustness of the proposed approach.",
    "title_zh": "基于图扩散的高效微段生成方法用于无线网络零信任安全",
    "abstract_zh": "零信任安全已成为应对无线网络独特漏洞的关键范式，但其实施面临显著的实际挑战。首先，实现零信任需要将网络划分为多个隔离的、面向特定应用的微段，并为每个微段配置定制化的安全策略。其次，为了满足日益复杂的服务需求，微段内的服务部署应采用服务功能链（SFC），将服务分布于异构设备上。因此，本文提出一种高效的微段生成方法——基于大语言模型增强的图扩散（LLM-enhanced Graph Diffusion, LGD）。具体而言，我们将零信任无线网络建模为一种分层图结构，以捕捉物理特性与可信度关系，并将微段生成问题形式化为一个可控制的生成任务。此外，我们提出的LGD基于图扩散模型，通过渐进式的去噪过程优化微段划分。同时，LGD利用大语言模型（LLMs）的认知能力，通过智能过滤和启发式引导降低动作空间维度，从而加速收敛并提升解的质量。大量实验表明，LGD生成的微段在服务部署效率上比现有基线方法高出40%。此外，在多种网络场景下的综合评估充分展示了该方法的可扩展性与鲁棒性。"
  },
  {
    "date": "2026-1-28",
    "title": "Experimental Evaluation of AI-Augmented Cybersecurity Requirements Generation Leveraging LLMs’ Capabilities",
    "authors": "Juan C. Yelmo, Yod-Samuel Martín, Santiago Perez-Acuna",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3658339",
    "source": "IEEE",
    "abstract": "When it comes to cybersecurity requirements, catalogs of standard controls are a double-edged sword: they offer reusable resources applicable anywhere, yet they entail tedious, error-prone manual instantiation work. As the definitions of these cybersecurity controls are written in natural language, we analyze whether large language models (LLMs) may help automate that process. We ran an empirical evaluation where frontier versions of LLaMa, Qwen, Mixtral, and GPT were asked, leveraging best prompting practice, to generate cybersecurity requirements for a realistic system, departing from its functional specification plus definitions of abstract cybersecurity controls extracted from ISO/IEC 27002. We compared the results to a ground truth created by human experts, and a gold standard pooled from the aggregation of all human- and LLM-produced results, considering phenomena such as hallucinations, new requirements discovered by LLMs, or partial overlaps. Results show that open-weights LLMs can parallel human experts in coverage and help uncover additional requirements when used under human-in-the-loop curation. Relative F2 score against the gold standard (prioritizing recall over precision) reached 1.14× in the best LLM configuration (in comparison to human experts): a LLaMa 3.1 405B model, prompted with an explicit chain-of-thought pipeline made of three sequential steps and four parallel and coalesced runs, and moderate values for hyperparameters that balance diversity and determinism. Our work contributes a benchmark of applied capabilities of LLMs for security by design in non-code artifacts. Although recall values leave room for improvement as LLMs advance, results provide initial evidence that this approach is feasible in our case study.",
    "title_zh": "基于大语言模型能力的AI增强型网络安全需求生成技术实验评估",
    "abstract_zh": "在网络安全需求方面，标准控制清单是一把双刃剑：它们提供了可广泛复用的资源，但同时也带来了繁琐且易出错的手动实例化工作。由于这些网络安全控制的定义以自然语言形式书写，我们探讨了大型语言模型（LLMs）是否能够帮助自动化这一过程。我们开展了一项实证评估，使用前沿版本的LLaMa、Qwen、Mixtral和GPT，在采用最佳提示工程实践的前提下，基于一个真实系统的功能规格，以及从ISO/IEC 27002中提取的抽象网络安全控制定义，生成相应的网络安全需求。我们将生成结果与人类专家构建的基准（ground truth）进行对比，并与由所有人工及LLM生成结果聚合而成的“黄金标准”进行比较，考察诸如幻觉现象、LLM发现的新需求或部分重叠等问题。结果显示，开源权重的LLM在覆盖率上可与人类专家相媲美，并在人机协同的监督下有助于发现额外的需求。在最佳LLM配置下，相对于黄金标准的相对F2分数（侧重召回率而非精确率）达到1.14倍，优于人类专家的表现——该配置为LLaMa 3.1 405B模型，采用包含三个顺序步骤的显式思维链提示流程，配合四次并行且合并执行的运行，同时设置适度的超参数以平衡多样性与确定性。本研究为LLM在非代码类安全设计产物中的实际应用能力提供了一个基准。尽管随着LLM技术的进步，召回率仍有提升空间，但当前结果已初步证明该方法在本案例研究中的可行性。"
  },
  {
    "date": "2026-1-28",
    "title": "IPv6 Target Generation Driven by Fine-tuned Large Language Model",
    "authors": "Xingqi Cheng, Shan Jing, Liang Jiao, Chuan Zhao, Hongjuan Yang",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11343556",
    "source": "IEEE",
    "abstract": "The rapid advancement of the Internet has brought the exploration and management of the IPv6 address space to the forefront of network research. With its 128-bit addressing scheme, IPv6 provides approximately 340 undecillion addresses, effectively mitigating the address exhaustion issue inherent in IPv4. The immense address space of IPv6 renders traditional brute-force scanning, once effective for IPv4, no longer feasible. This challenge calls for the development of efficient and precise IPv6 address generation methods to ensure the stability and security of the Internet. To tackle this challenge, this study introduces an innovative IPv6 address generation method leveraging a fine-tuned Large Language Model (LLM), enhanced by the vLLM inference framework to improve generation efficiency. This approach leverages the strong learning and generalization capabilities of LLMs to effectively handle the complexities of IPv6 address generation. We begin with an initial classification of IPv6 addresses to reduce the model’s learning complexity. Next, we curate a fine-tuning dataset and apply the LoRA technique to fine-tune the Qwen-7B-chat model. The results show that the fine-tuned LLM outperforms existing methods in generating IPv6 addresses, especially in terms of generation speed and accuracy.",
    "title_zh": "由微调大语言模型驱动的IPv6目标生成",
    "abstract_zh": "互联网的迅猛发展使得IPv6地址空间的探索与管理成为网络研究的前沿课题。凭借其128位的寻址方案，IPv6提供了约340万亿亿亿亿个地址，有效解决了IPv4固有的地址耗尽问题。IPv6庞大的地址空间使得过去在IPv4中行之有效的暴力扫描方法不再可行。这一挑战促使人们亟需开发高效且精准的IPv6地址生成方法，以保障互联网的稳定与安全。为应对这一挑战，本研究提出了一种创新的IPv6地址生成方法，该方法基于经过微调的大语言模型（LLM），并结合vLLM推理框架以提升生成效率。该方法充分利用大语言模型强大的学习与泛化能力，有效应对IPv6地址生成中的复杂性问题。我们首先对IPv6地址进行初步分类，以降低模型的学习复杂度；随后构建了专门的微调数据集，并采用LoRA技术对Qwen-7B-chat模型进行微调。实验结果表明，经过微调的LLM在生成IPv6地址方面显著优于现有方法，尤其在生成速度和准确性方面表现突出。"
  },
  {
    "date": "2026-1-28",
    "title": "BF-WeakWeb-2025: A Novel Dataset and LLM Benchmark for Web Vulnerability Detection in Burkina Faso",
    "authors": "Sidwendluian Romaric Nana, Didier Bassolé, Désiré Guel, Oumarou Sié",
    "publish": "2025 8th International Conference on Advanced Communication Technologies and Networking (CommNet)",
    "url": "https://doi.org/10.1109/commnet68224.2025.11288830",
    "source": "IEEE",
    "abstract": "In a context of increasing digitalisation of administrative processes, cybersecurity has become a strategic issue for states, particularly Burkina Faso. Unfortunately, there is a lack of research into cybersecurity in Burkina Faso. In this article, we present an approach for identifying vulnerabilities in applications and websites from Burkina Faso’s cyberspace according to the OWASP Top 10 2021. Implementing this approach enabled us to collect 241 websites and web applications from various fields. Analysing the security risks of a sample of 20 websites and web applications identified 18,521 web vulnerabilities, forming the basis of a dataset called \"BF-WeakWeb-2025\". Six of the CWE identifiers found are listed among the 2024 CWE Top 25 most dangerous Software Weaknesses. To the best of our knowledge, this is the first study of web vulnerability analysis based on the OWASP Top 10 in Burkina Faso’s cyberspace. This dataset addresses the inadequacy and obsolescence of existing datasets in the field of cybersecurity. The dataset was used to fine-tune three Large Language Models (LLMs) — BERT, Llama, and Flan-T5 — to detect and classify the six CWE identifiers: CWE-693, CWE-79, CWE-1021, CWE-352, CWE-264, and CWE-89. Analysis of the results shows that the fine-tuned models correctly classify CWE identifiers with an accuracy rate of 98%, and are also robust against unbalanced data. This demonstrates the quality of the dataset.",
    "title_zh": "BF-WeakWeb-2025：布基纳法索网络漏洞检测的新型数据集与大模型基准",
    "abstract_zh": "在行政流程日益数字化的背景下，网络安全已成为各国，尤其是布基纳法索的战略性议题。然而，目前针对布基纳法索网络安全的研究仍十分匮乏。本文提出一种基于OWASP Top 10 2021标准识别布基纳法索网络空间中应用程序和网站漏洞的方法。通过实施该方法，我们共收集到241个来自不同领域的网站和Web应用。对其中20个样本进行安全风险分析，共发现18,521个Web漏洞，由此构建了一个名为“BF-WeakWeb-2025”的数据集。其中六项CWE标识符被列入2024年CWE Top 25最危险软件缺陷榜单。据我们所知，这是首个基于OWASP Top 10对布基纳法索网络空间开展的Web漏洞分析研究。该数据集弥补了现有网络安全数据集在数量和时效性方面的不足。我们利用该数据集对三种大型语言模型（LLM）——BERT、Llama和Flan-T5——进行了微调，以检测并分类六个特定的CWE标识符：CWE-693、CWE-79、CWE-1021、CWE-352、CWE-264和CWE-89。结果分析表明，经过微调的模型在识别CWE标识符方面准确率达到98%，且对数据不平衡问题具有较强的鲁棒性，充分体现了该数据集的高质量。"
  },
  {
    "date": "2026-1-28",
    "title": "Bin2Vec: Interpretable and Auditable Multi-View Binary Analysis for Code Plagiarism Detection",
    "authors": "Moussa Moussaoui, Tarik Houichime, Abdelalim Sadiq",
    "publish": "2025 8th International Conference on Advanced Communication Technologies and Networking (CommNet)",
    "url": "https://doi.org/10.1109/commnet68224.2025.11288883",
    "source": "IEEE",
    "abstract": "We introduce Bin2Vec, a new framework that helps compare software programs in a clear and explainable way. Instead of focusing only on one type of information, Bin2Vec combines what a program looks like (its built-in functions, imports, and exports) with how it behaves when it runs (its instructions and memory usage). This gives a more complete picture when deciding whether two programs are similar or not. Bin2Vec represents these different types of information as views that can be inspected separately using easy-to-read charts, and then brings them together into an overall similarity score. Bin2Vec acts as a bridge between binary representations and machine learning techniques by generating feature representations that can be efficiently processed by machine-learning models. We tested Bin2Vec on multiple versions of two well-known Windows programs, PuTTY and 7-Zip. The primary results strongly confirmed that our method compute an optimal and visualization-friendly representation of the analyzed software. For example, PuTTY versions showed more complex behavior and memory activity, while 7-Zip versions focused more on performance-related patterns. Overall, Bin2Vec provides decisions that are both reliable and explainable to humans. Because it is modular and easy to extend, it can be applied to tasks like auditing, verifying software origins, or quickly screening large numbers of programs in cybersecurity and reverse-engineering work.",
    "title_zh": "Bin2Vec：可解释且可审计的多视角二进制代码抄袭检测分析方法",
    "abstract_zh": "我们介绍了Bin2Vec，这是一种全新的框架，能够以清晰且可解释的方式比较软件程序。与仅关注单一类型信息的方法不同，Bin2Vec将程序的外观特征（如内置函数、导入和导出）与其运行时的行为特征（如指令序列和内存使用情况）相结合，从而在判断两个程序是否相似时提供更全面的视角。Bin2Vec将这些不同类型的信息表示为可独立检查的“视图”，并通过易于理解的图表进行可视化展示，随后将各视图整合为一个综合的相似性评分。Bin2Vec通过生成可被机器学习模型高效处理的特征表示，架起了二进制表示与机器学习技术之间的桥梁。我们在两个著名的Windows程序——PuTTY和7-Zip的多个版本上测试了Bin2Vec。主要结果有力地证实，我们的方法能够计算出最优且适合可视化的软件表征。例如，PuTTY的不同版本表现出更复杂的运行行为和更高的内存活动，而7-Zip版本则更多呈现出与性能相关的模式。总体而言，Bin2Vec提供的决策既可靠又对人类具有可解释性。由于其模块化设计且易于扩展，该方法可广泛应用于审计、验证软件来源，或在网络安全和逆向工程中快速筛查大量程序等任务。"
  },
  {
    "date": "2026-1-28",
    "title": "Latra: A Template-Based Language-Agnostic Transformation Framework for Effective Program Reduction",
    "authors": "Zhenyang Xu, Yiran Wang, Yongqiang Tian, Mengxiao Zhang, Chengnian Sun",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00188",
    "source": "IEEE",
    "abstract": "Essential for debugging compilers and interpreters, existing reduction tools face a fundamental trade-off. Language-Specific reducers, such as C-Reduce and ddSMT, offer highly effective reductions but require substantial engineering effort for each target language. Conversely, language-agnostic reducers, like Vulcan, sacrifice effectiveness for broad applicability.To bridge this gap, we present Latra, a novel template-based framework that balances both aspects, enabling general, effective, targeted program reduction. Latra combines language-agnostic reduction with user-defined, language-specific transformations. It facilitates user-defined transformations through a user-friendly domain-specific language based on simple matching and rewriting templates. This minimizes the need for deep formal grammar knowledge. Latra empowers users to tailor reductions to specific languages with reduced implementation overhead.Our evaluation shows that Latra significantly outperforms Vulcan. On average, it reduces 33.77% more tokens in C and 9.17% more tokens in SMT-LIB, with 32.27% faster execution in SMT-LIB. Notably, Latra closely matches the effectiveness of language-specific reducers, i.e., C-Reduce and ddSMT (89 vs. 85, 103 vs. 109 tokens on average), while significantly reducing engineering effort (167 vs. 5,685, 62 vs. 118 lines of code). We strongly believe that Latra provides a practical and cost-efficient approach to program reduction, effectively balancing language-specific effectiveness with language-agnostic generality.",
    "title_zh": "Latra：一种基于模板的、与语言无关的程序简化框架",
    "abstract_zh": "对于调试编译器和解释器而言，程序简化（reduction）至关重要。然而，现有的简化工具面临一个根本性的权衡：语言特定的简化器（如 C-Reduce 和 ddSMT）虽然能实现高效的简化，但为每种目标语言开发都需要大量工程投入；而语言无关的简化器（如 Vulcan）则为了广泛适用性牺牲了简化效果。为弥合这一差距，我们提出了 Latra——一种基于模板的新颖框架，能够在通用性与有效性之间取得良好平衡，实现高效、精准的程序简化。\n\nLatra 将语言无关的简化方法与用户自定义的语言特定变换相结合。它通过一种用户友好的领域特定语言（DSL）来支持用户定义的变换，该语言基于简单的匹配与重写模板，无需用户掌握复杂的正式语法知识，从而显著降低了使用门槛。借助 Latra，用户可以以较低的实现成本，针对特定编程语言定制高效的简化策略。\n\n我们的评估表明，Latra 显著优于 Vulcan：在 C 语言上平均多减少了 33.77% 的标记（tokens），在 SMT-LIB 上多减少了 9.17% 的标记，且在 SMT-LIB 上执行速度加快了 32.27%。尤为关键的是，Latra 的简化效果几乎媲美专门针对语言的优化工具——C-Reduce 和 ddSMT（平均分别减少 89 vs. 85，103 vs. 109 个标记），同时大幅降低工程开销（代码量分别为 167 vs. 5,685 行，62 vs. 118 行）。我们坚信，Latra 提供了一种实用且成本效益极高的程序简化方案，成功实现了语言特定高效性与语言无关普适性之间的理想平衡。"
  },
  {
    "date": "2026-1-28",
    "title": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
    "authors": "Jingkun Zhang, Jingzheng Wu, Xiang Ling, Tianyue Luo, Bolin Zhou, Mutian Yang",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00294",
    "source": "IEEE",
    "abstract": "Managing third-party libraries is a costly and critical task for enterprises, essential for both vulnerability assessment and license compliance. Existing android software composition analysis tools focus on mitigating code obfuscation but neglect the impact of code optimization, which is deeply integrated into build pipelines and disrupts library structure.To tackle these challenges, we developed LibSleuth, a detection tool designed to be resilient to code shrinking and obfuscation. It is based on the observation that even after shrinking, the remaining code still retains functional completeness. LibSleuth adopts two novel strategies: (1) Method level functional module matching: We break down feature matching to method level and define a functional module as related methods that represent used functionality. This allows us to detect libraries based on functional module completeness to address code shrinking. (2) Context-enhanced multi-level filtering: To improve robustness against obfuscation and reduce the cost of pairing, LibSleuth leverages contextual relationships to enhance feature stability and adopts a coarse-to-fine progressive matching process.We evaluated LibSleuth on datasets containing obfuscated and optimized Android apps. LibSleuth outperforms state-of-the-art academic and commercial tools in both scenarios. Under combined code shrinking and obfuscation, LibSleuth achieves an average 27.74% higher version level F1-score. Moreover, our analysis of 10,000 real world Android apps shows that 20.35% still depend on vulnerable library, demonstrating the practical utility of LibSleuth for downstream tasks.",
    "title_zh": "缩小但完整：抗代码压缩的Android第三方库检测",
    "abstract_zh": "管理第三方库对企事业单位而言是一项成本高昂且至关重要的任务，对于漏洞评估和许可证合规性均至关重要。现有的Android软件成分分析工具主要关注代码混淆问题，却忽视了深度集成于构建流程中的代码优化所带来的影响，而这种优化会严重破坏库的结构。为应对这些挑战，我们开发了LibSleuth——一种能够抵御代码压缩与混淆的检测工具。其核心思想是：即使经过代码压缩，剩余代码仍保持功能完整性。LibSleuth采用两种创新策略：（1）方法级功能模块匹配：我们将特征匹配细化至方法级别，并将一组表示实际使用功能的相关方法定义为“功能模块”。通过检测功能模块的完整性，有效应对代码压缩带来的挑战；（2）上下文增强的多级过滤机制：为提升对混淆的鲁棒性并降低匹配开销，LibSleuth利用上下文关系增强特征稳定性，并采用由粗到细的渐进式匹配流程。我们在包含混淆与优化的Android应用数据集上对LibSleuth进行了评估，结果表明，在两种场景下，其性能均优于当前最先进的学术及商业工具。在同时存在代码压缩与混淆的情况下，LibSleuth的版本级F1分数平均高出27.74%。此外，通过对10,000个真实世界Android应用的分析发现，仍有20.35%的应用依赖于存在漏洞的第三方库，这充分体现了LibSleuth在下游任务中的实际应用价值。"
  },
  {
    "date": "2026-1-28",
    "title": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
    "authors": "Defang Bo, Jie Lu, Feng Li, Jingting Chen, Jinchen Wang, Chendong Yu, Yeting Li, Wei Huo",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00220",
    "source": "IEEE",
    "abstract": "Cloud-native technologies have revolutionized application development, with Kubernetes emerging as the de facto standard platform for containerization and orchestration. Kubernetes manages applications through API objects called resources, where users declare desired states via resource definitions that are processed by controllers to reconcile system discrepancies. However, this resource-based architecture introduces resource injection vulnerabilities, where controllers perform privileged operations using user-controllable fields without adequate validation. Attackers can exploit these weaknesses by injecting malicious content into resource fields to achieve unauthorized access and privilege escalation.In this paper, we conduct the first comprehensive study on 125 resource injection vulnerabilities from 8,306 Kubernetes-related vulnerabilities across common databases. For all studied vulnerabilities, we investigate their vulnerable fields, root causes, privileged operations, exploitation conditions, and fixing strategies. Our study reveals many interesting findings that can guide the detection and mitigation of resource injection vulnerabilities, as well as the development of more secure cloud-native applications.",
    "title_zh": "理解 Kubernetes 生态系统中的资源注入漏洞",
    "abstract_zh": "云原生技术彻底改变了应用程序的开发方式，其中Kubernetes已成为容器化和编排的事实标准平台。Kubernetes通过称为“资源”的API对象来管理应用，用户通过资源定义声明期望状态，由控制器处理这些定义以纠正系统中的不一致。然而，这种基于资源的架构引入了资源注入漏洞，即控制器在执行特权操作时使用了用户可控制的字段，而缺乏充分的验证。攻击者可以利用这些弱点，将恶意内容注入资源字段，从而实现未授权访问和权限提升。\n\n本文首次对来自8,306个与Kubernetes相关的漏洞、涵盖125个资源注入漏洞进行了全面研究。针对所有研究的漏洞，我们深入分析了其受影响的字段、根本原因、执行的特权操作、利用条件以及修复策略。我们的研究揭示了许多有趣的发现，这些发现能够指导资源注入漏洞的检测与缓解，并为开发更安全的云原生应用提供重要参考。"
  },
  {
    "date": "2026-1-28",
    "title": "Semantic SZZ: Mitigating the Impact of Misclassified Corrective Changes in Just-in-Time Software Defect Prediction",
    "authors": "Ronaldo C. Veras, George G. Cabral, Adriano L. I. Oliveira",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11342537",
    "source": "IEEE",
    "abstract": "In the evolving landscape of software engineering, accurate identification of defect-inducing commits is critical to improving software quality and reducing development costs. This paper revisits the widely adopted SZZ algorithm, which is utilized for labeling commits as clean or defect-inducing, to address one of its main limitations, i.e., its reliance on outdated corrective commits identification strategies. We propose an innovative approach that integrates the semantic understanding capability of the GPT OpenAI model into the SZZ flow to better interpret commit messages. Our experiments reveal, for some projects, a large number of commits incorrectly interpreted as defect-fixing, consequently, leading to the misclassification of commits as defect-inducing. As an example, for the Postgresql dataset, the number of defect-inducing commits was reduced in 21% when compared to the original SZZ. Furthermore, results of our experiments strongly suggest that, as a result of the proposed SZZ labeling process, the JIT-SDP problem has been shown to be more challenging than originally reported by previous works.",
    "title_zh": "语义SZZ：减轻误分类修正变更对即时软件缺陷预测的影响",
    "abstract_zh": "在不断发展的软件工程领域，准确识别引发缺陷的提交（commit）对于提升软件质量、降低开发成本至关重要。本文重新审视了广泛采用的SZZ算法——该算法用于将提交标记为“干净”或“引发缺陷”——以解决其主要局限之一：依赖过时的修复提交识别策略。为此，我们提出了一种创新方法，将GPT OpenAI模型的语义理解能力融入SZZ流程中，以更准确地解析提交信息。实验结果表明，在某些项目中，大量本应被正确识别为非缺陷修复的提交被错误地视为修复类提交，从而导致提交被误标为缺陷引发型。例如，在PostgreSQL数据集上，与原始SZZ算法相比，缺陷引发型提交数量减少了21%。此外，实验结果强烈表明，由于所提出的SZZ标注流程，JIT-SDP问题的实际挑战性比以往研究报道的更为严峻。"
  },
  {
    "date": "2026-1-28",
    "title": "A Large Scale Study of AI-based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
    "authors": "Jingyi Shi, Yufeng Chen, Yang Xiao, Yuekang Li, Zhengzi Xu, Sihao Qiu, Chi Zhang, Keyu Qi, Yeting Li, Xingchu Chen, Yanyan Zou, Yang Liu, Wei Huo",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00093",
    "source": "IEEE",
    "abstract": "Binary Function Similarity Detection (BFSD) is a foundational technique in software security, underpinning a wide range of applications including vulnerability detection, malware analysis. Recent advances in AI-based BFSD tools have led to significant performance improvements. However, existing evaluations of these tools suffer from three key limitations: a lack of in-depth analysis of performance-influencing factors, an absence of realistic application analysis, and reliance on small-scale or low-quality datasets.In this paper, we present the first large-scale empirical study of AI-based BFSD tools to address these gaps. We construct two high-quality and diverse datasets: BinAtlas, comprising 12,453 binaries and over 7 million functions for capability evaluation; and BinAres, containing 12,291 binaries and 54 real-world 1-day vulnerabilities for evaluating vulnerability detection performance in practical IoT firmware settings. Using these datasets, we evaluate nine representative BFSD tools, analyze the challenges and limitations of existing BFSD tools, and investigate the consistency among BFSD tools. We also propose an actionable strategy for combining BFSD tools to enhance overall performance (an improvement of 13.4%). Our study not only advances the practical adoption of BFSD tools but also provides valuable resources and insights to guide future research in scalable and automated binary similarity detection.",
    "title_zh": "面向安全研究人员与实践者的基于AI的二进制函数相似性检测技术大规模研究",
    "abstract_zh": "二进制函数相似性检测（BFSD）是软件安全领域的一项基础技术，广泛应用于漏洞检测、恶意软件分析等场景。近年来，基于人工智能的BFSD工具取得了显著性能提升。然而，现有对这些工具的评估仍存在三大关键局限：缺乏对影响性能因素的深入分析、缺少真实应用场景的评估，以及依赖小规模或低质量的数据集。本文首次开展了大规模实证研究，以弥补上述不足。我们构建了两个高质量且多样化的数据集：BinAtlas，包含12,453个二进制文件和超过700万函数，用于评估工具的能力；BinAres，包含12,291个二进制文件及54个真实世界中的1天漏洞实例，用于在实际物联网固件环境中评估漏洞检测性能。基于这两个数据集，我们评估了九种具有代表性的BFSD工具，深入分析了现有工具面临的挑战与局限，并探讨了不同BFSD工具之间的一致性。此外，我们提出了一种可操作的工具融合策略，通过组合多个BFSD工具显著提升了整体性能（提升达13.4%）。本研究不仅推动了BFSD工具的实际应用，还为未来可扩展、自动化的二进制相似性检测研究提供了宝贵资源与重要洞见。"
  },
  {
    "date": "2026-1-28",
    "title": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
    "authors": "Karine Even-Mendoza, Alexander Brownlee, Alina Geiger, Carol Hanna, Justyna Petke, Federica Sarro, Dominik Sobania",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00339",
    "source": "IEEE",
    "abstract": "Genetic Improvement (GI) of software automatically creates alternative software versions that are improved according to certain properties of interests (e.g., running-time). Search-based GI excels at navigating large program spaces, but operates primarily at the syntactic level. In contrast, Large Language Models (LLMs) offer semantic-aware edits, yet lack goal-directed feedback and control (which is instead a strength of GI).As such, we propose the investigation of a new research line on AI-powered GI aimed at incorporating semantic aware search. We take a first step at it by augmenting GI with the use of automated clustering of LLM edits.We provide initial empirical evidence that our proposal, dubbed PatchCat, allows us to automatically and effectively categorize LLM-suggested patches. PatchCat identified 18 different types of software patches and categorized newly suggested patches with high accuracy. It also enabled detecting NoOp edits in advance and, prospectively, to skip test suite execution to save resources in many cases. These results, coupled with the fact that PatchCat works with small, local LLMs, are a promising step toward interpretable, efficient, and green GI.We outline a rich agenda of future work and call for the community to join our vision of building a principled understanding of LLM-driven mutations, guiding the GI search process with semantic signals.",
    "title_zh": "基于大语言模型引导的遗传改进：展望语义感知的自动化软件演化",
    "abstract_zh": "软件的遗传改进（Genetic Improvement, GI）能够自动创建在特定属性（如运行时间）上有所提升的软件替代版本。基于搜索的GI在探索庞大的程序空间方面表现出色，但主要局限于语法层面的操作。相比之下，大型语言模型（LLMs）能够进行语义感知的代码修改，却缺乏目标导向的反馈与控制能力——而这正是GI的优势所在。因此，我们提出开展一项新的研究方向：以人工智能驱动的GI，旨在融合语义感知的搜索机制。为此，我们迈出第一步，通过引入LLM生成补丁的自动化聚类来增强GI。我们提供了初步的实证证据表明，所提出的方案PatchCat能够自动且高效地对LLM建议的补丁进行分类。PatchCat识别出18种不同类型的软件补丁，并以高准确率对新提出的补丁进行了归类。此外，该方法还能提前检测出“无操作”（NoOp）型修改，在未来可据此跳过测试套件执行，从而节省大量资源。这些成果结合PatchCat可使用小型本地LLM运行的事实，为实现可解释性、高效且环保的GI迈出了富有前景的一步。我们勾勒出一系列丰富的未来研究方向，并呼吁学术界共同参与，致力于建立对LLM驱动突变的系统性理解，利用语义信号指导GI的搜索过程。"
  },
  {
    "date": "2026-1-28",
    "title": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
    "authors": "Rui Yang, Michael Fu, Chakkrit Tantithamthavorn, Chetan Arora, Gunel Gulmammadova, Joey Chua",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00279",
    "source": "IEEE",
    "abstract": "Guardrails are critical for the safe deployment of Large Language Models (LLMs)-powered software. Unlike traditional rule-based systems with limited, predefined input-output spaces that inherently constrain unsafe behavior, LLMs enable open-ended, intelligent interactions—opening the door to jailbreak attacks through user inputs. Guardrails serve as a protective layer, filtering unsafe prompts before they reach the LLM. However, prior research shows that jailbreak attacks can still succeed over 70% of the time, even against advanced models like GPT-4o. While guardrails such as LlamaGuard report up to 95% accuracy, our preliminary analysis shows their performance can drop sharply—to as low as 12%—when confronted with unseen attacks. This highlights a growing software engineering challenge: how to build a post-deployment guardrail that adapts dynamically to emerging threats? To address this, we propose AdaptiveGuard, an adaptive guardrail that detects novel jailbreak attacks as out-of-distribution (OOD) inputs and learns to defend against them through a continual learning framework. Through empirical evaluation, AdaptiveGuard achieves 96% OOD detection accuracy, adapts to new attacks in just two update steps, and retains over 85% F1-score on in-distribution data post-adaptation, outperforming other baselines. These results demonstrate that AdaptiveGuard is a guardrail capable of evolving in response to emerging jailbreak strategies post deployment. We release our AdaptiveGuard and studied datasets at https://github.com/awsm-research/AdaptiveGuard to support further research.",
    "title_zh": "AdaptiveGuard：面向大语言模型驱动软件的自适应运行时安全",
    "abstract_zh": "护栏对于大型语言模型（LLMs）驱动软件的安全部署至关重要。与传统基于规则的系统不同，后者由于输入输出空间有限且预先定义，天然地限制了不安全行为；而LLMs则支持开放式的智能交互，这为通过用户输入实施“越狱攻击”敞开了大门。护栏作为一道保护层，在提示信息到达LLM之前对其进行过滤，以防止不安全内容的传播。然而，先前的研究表明，即使面对GPT-4o等先进模型，越狱攻击仍能成功超过70%的次数。尽管像LlamaGuard这样的护栏系统报告最高可达95%的准确率，但我们的初步分析显示，当遭遇未见过的攻击时，其性能可能急剧下降至仅12%。这一现象凸显了一个日益严峻的软件工程挑战：如何构建一种能够在部署后动态适应新兴威胁的护栏机制？\n\n为此，我们提出了AdaptiveGuard——一种自适应护栏机制，能够将新型越狱攻击识别为分布外（OOD）输入，并通过持续学习框架不断学习并增强防御能力。在实证评估中，AdaptiveGuard实现了96%的OOD检测准确率，仅需两次更新步骤即可适应新攻击，并在适应后仍保持超过85%的F1分数（针对分布内数据），显著优于其他基线方法。这些结果表明，AdaptiveGuard是一种能够在部署后随新兴越狱策略动态演进的防护机制。\n\n我们已将AdaptiveGuard及其研究数据集开源发布于 https://github.com/awsm-research/AdaptiveGuard，以支持后续相关研究。"
  },
  {
    "date": "2026-1-28",
    "title": "Measuring LLM Code Generation Stability via Structural Entropy",
    "authors": "Yewei Song, Tiezhu Sun, Xunzhu Tang, Prateek Kumar Rajput, Tegawendé F. Bissyandé, Jacques Klein",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00343",
    "source": "IEEE",
    "abstract": "Assessing the stability of code generation from large language models (LLMs) is essential for judging their reliability in real-world development. We extend prior \"structural-entropy\" concepts to the program domain by pairing entropy with abstract-syntax-tree (AST) analysis. For any fixed prompt, we collect the multiset of depth-bounded subtrees of AST in each generated program and treat their relative frequencies as a probability distribution. We then measure stability in two complementary ways: (i) Jensen–Shannon divergence, a symmetric, bounded indicator of structural overlap, and (ii) a Structural Cross-Entropy ratio that highlights missing high-probability patterns. Both metrics admit structural-only and token-aware variants, enabling separate views on control-flow shape and identifier-level variability. Unlike pass@k, BLEU, or CodeBLEU, our metrics are reference-free, language-agnostic, and execution-independent. We benchmark several leading LLMs on standard code generation tasks, demonstrating that AST-driven structural entropy reveals nuances in model consistency and robustness. The method runs in O(n,d) time with no external tests, providing a lightweight addition to the code-generation evaluation toolkit.",
    "title_zh": "通过结构熵衡量大语言模型代码生成的稳定性",
    "abstract_zh": "评估大型语言模型（LLMs）生成代码的稳定性对于判断其在真实开发场景中的可靠性至关重要。我们通过将“结构熵”概念拓展至程序领域，结合信息熵与抽象语法树（AST）分析，实现了对代码稳定性的有效衡量。针对任意固定提示（prompt），我们收集每个生成程序中深度受限的子树构成的多重集，并将其相对频率视为概率分布。随后，我们从两个互补的角度度量稳定性：(i) Jensen–Shannon 散度，一种对称且有界的结构重叠指标；(ii) 结构交叉熵比率，用于揭示缺失的高概率模式。这两种度量均提供仅基于结构和兼顾标记（token）感知两种变体，从而分别呈现控制流形态与标识符层面的变异情况。与 pass@k、BLEU 或 CodeBLEU 等传统指标不同，我们的方法无需参考答案、不依赖特定编程语言、且与程序执行无关。我们在多个主流 LLM 上对标准代码生成任务进行了基准测试，结果表明，基于 AST 的结构熵能够揭示模型在一致性与鲁棒性方面的细微差异。该方法时间复杂度为 O(n, d)，无需外部测试，可作为代码生成评估工具包中轻量高效的补充手段。"
  },
  {
    "date": "2026-1-28",
    "title": "A Hierarchical Verification Framework for Power Engineering Design Based on LLM-Driven Rule and Knowledge Base Integration",
    "authors": "Hongqin Yang, Jian Jiang, Qinghui Huang, Yao Li, Juanjuan Tian",
    "publish": "2025 5th IEEE International Conference on Energy Engineering and Power Systems (EEPS)",
    "url": "https://doi.org/10.1109/eeps68057.2025.11351591",
    "source": "IEEE",
    "abstract": "This paper presents a hierarchical design verification framework that integrates Large Language Models with structured engineering knowledge to automate power system design validation. The framework employs a three-layer architecture: rule-based compliance checking, technical consistency analysis, and completeness assessment. The system leverages formalized rules from IEEE/IEC standards and maintains citation-backed rationales linking verification decisions to authoritative sources. A case study on a real-world 220 kV substation design project demonstrates the framework's practical applicability, achieving expert-validated 92% accuracy in issue identification across 156 pages of design documentation. The system successfully detected all major compliance issues including protection coordination violations and equipment rating inconsistencies, while identifying additional optimization opportunities.",
    "title_zh": "基于大语言模型驱动的规则与知识库融合的电力工程设计分层验证框架",
    "abstract_zh": "本文提出了一种分层设计验证框架，该框架将大型语言模型与结构化工程知识相结合，实现了电力系统设计验证的自动化。该框架采用三层架构：基于规则的合规性检查、技术一致性分析以及完整性评估。系统利用来自IEEE/IEC标准的规范化规则，并建立基于引用的论证链条，将验证决策与权威来源相联系。通过对一个实际220 kV变电站设计项目进行案例研究，验证了该框架的实际应用价值，在156页的设计文档中实现了专家验证的92%问题识别准确率。系统成功检测出所有重大合规性问题，包括保护配合违规和设备额定值不一致等问题，同时还发现了其他优化改进机会。"
  },
  {
    "date": "2026-1-28",
    "title": "Leveraging Long Method Decomposition to Improve Large Language Model-Based Test Case Generation",
    "authors": "Rongzhi Qi, Zhiyu Shen, Yadi Li",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11343523",
    "source": "IEEE",
    "abstract": "Recent studies have demonstrated the potential of large language models (LLMs) in test case generation. However, LLMs often struggle to achieve high levels of test coverage when generating test cases for long methods. Long methods are one of the typical manifestations of code smells, characterized by excessive lines of code, complex control flows, deep nesting levels, and numerous variables. These characteristics make it difficult for traditional testing tools to cover most of the lines and branches of focal methods. To address this issue, this paper proposes a novel approach, DecoTest, to generate unit test cases for long methods based on LLMs. The proposed method leverages LLM and automated validation based on static analysis to derive high-quality decomposition and refactoring plans. After refactoring the long methods, test cases are generated, iteratively verified and repaired to produce the final test case suite. This paper also presents an experimental analysis of DecoTest. The results indicate that the proposed method outperforms existing LLM-based test case generation methods in terms of line coverage, branch coverage, and test execution pass rate.",
    "title_zh": "利用长方法分解提升基于大语言模型的测试用例生成",
    "abstract_zh": "最近的研究表明，大型语言模型（LLMs）在测试用例生成方面具有巨大潜力。然而，当用于生成长方法的测试用例时，LLMs往往难以实现较高的测试覆盖率。长方法是代码异味的典型表现之一，其特征包括代码行数过多、控制流复杂、嵌套层级深以及变量数量众多。这些特性使得传统测试工具很难覆盖目标方法中的大部分语句和分支。为解决这一问题，本文提出了一种名为DecoTest的新方法，基于大型语言模型自动生成长方法的单元测试用例。该方法结合大型语言模型与基于静态分析的自动化验证，以生成高质量的代码分解与重构方案。在对长方法完成重构后，系统将迭代生成、验证并修复测试用例，最终形成完整的测试用例集。本文还对DecoTest进行了实验分析。结果表明，所提出的方法在语句覆盖率、分支覆盖率以及测试执行通过率方面均优于现有的基于LLM的测试用例生成方法。"
  },
  {
    "date": "2026-1-28",
    "title": "Neuro-Symbolic Compliance-as-Code: Toward Explainable, Adaptive, and Self-Evolving Governance Systems",
    "authors": "Sajal Nigam, Sagar Patel",
    "publish": "2025 IEEE International Conference on Data and Software Engineering (ICoDSE)",
    "url": "https://doi.org/10.1109/icodse68111.2025.11351734",
    "source": "IEEE",
    "abstract": "Compliance-as-Code (CaC) has emerged as a critical paradigm for translating regulatory mandates into enforceable machine-executable rules. While existing approaches enable automation of compliance verification, they often struggle with explainability, adaptability, and evolution in response to regulatory and system changes. In this paper, we propose Neuro-Symbolic Compliance-as-Code (NS-CaC), a hybrid governance framework that combines symbolic reasoning with neural adaptability to create self-evolving, auditable compliance systems. Unlike existing models, NS-CaC ingests regulatory updates through natural language processing (NLP) and large language models (LLMs), enforces them via symbolic formalism, adapts through neural drift detection, and continuously evolves policies via governance loops. Auditor feedback and system telemetry serve as dynamic external inputs, enabling continuous compliance assurance. The architecture also emphasizes explainability, ensuring that compliance decisions remain transparent to regulators and enterprises alike. By integrating explainable AI, closed-loop feedback, and hybrid neuro-symbolic reasoning, NS-CaC bridges the gap between rigid compliance automation and adaptive governance, offering a pathway toward self-explaining, self-adapting, and resilient compliance systems.",
    "title_zh": "神经符号合规即代码：迈向可解释、自适应与自我演进的治理系统",
    "abstract_zh": "合规即代码（Compliance-as-Code, CaC）已成为将监管要求转化为可执行机器规则的关键范式。尽管现有方法实现了合规验证的自动化，但在可解释性、适应性以及应对监管和系统变化时的演进能力方面仍面临挑战。本文提出了一种神经符号合规即代码（Neuro-Symbolic Compliance-as-Code, NS-CaC）的混合治理框架，通过结合符号推理与神经网络的自适应能力，构建能够自我演进且可审计的合规系统。与现有模型不同，NS-CaC利用自然语言处理（NLP）和大语言模型（LLM）接收监管更新，通过符号形式化机制实施规则，借助神经漂移检测实现动态适应，并通过治理闭环持续演化策略。审计反馈与系统遥测数据作为动态外部输入，支持持续的合规保障。该架构还强调可解释性，确保合规决策对监管机构和企业均保持透明。通过融合可解释人工智能、闭环反馈机制与混合神经符号推理，NS-CaC弥合了刚性合规自动化与动态治理之间的鸿沟，为实现自我解释、自我适应且具备韧性的合规系统提供了可行路径。"
  },
  {
    "date": "2026-1-28",
    "title": "A Retrieval Filtering and Thought Enhancement Framework for Function-Level Code Generation Based on Large Language Model",
    "authors": "Chao Wu, Pusheng Zhang, Xuesong Jiang, Song Liu",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11343122",
    "source": "IEEE",
    "abstract": "The function-level code generation is an important task in the combination of software engineering and artificial intelligence, which aims to improve the productivity of software development by automatically generating function-level code based on task descriptions. However, this task currently suffers from several problems: 1) in the fine-tuning phase, current large language models cannot sufficiently capture the detailed syntactic structure of the code dataset; 2) previous retrieval-augmented methods cannot adequately consider the complex dependencies between code snippets in external code repositories; 3) existing large language models introducing self-repair mechanism tend to overfocus on previously generated erroneous code during the self-repair process. To solve these problems, we propose a retrieval filtering and thought enhancement framework for function-level code generation based on large language model. In our model, we design an abstract syntax tree mapping preprocessing module to preprocess the dataset and help large language models learn the detailed syntax information of the dataset. Furthermore, we design a retrieval filtering and thought enhancement module to retrieve the most relevant snippets of code for the task and to enhance the chain-of-thought of our model. In addition, we design a self-repair mechanism to prevent large language models from overfocusing on generated erroneous code, helping them explore more solutions to repair the erroneous code. We experimented and evaluated our model on HumanEval, MBPP, and MultiPLE benchmarks to compare with other baseline models.",
    "title_zh": "基于大语言模型的函数级代码生成检索过滤与思维增强框架",
    "abstract_zh": "函数级代码生成是软件工程与人工智能结合中的一个重要任务，旨在通过根据任务描述自动生成函数级别的代码来提升软件开发的生产效率。然而，当前该任务仍面临多个问题：1）在微调阶段，现有的大语言模型无法充分捕捉代码数据集的详细语法结构；2）以往的检索增强方法未能充分考虑外部代码仓库中代码片段之间的复杂依赖关系；3）现有引入自修复机制的大语言模型在自修复过程中往往过度关注先前生成的错误代码。为解决上述问题，我们提出了一种基于大语言模型的检索过滤与思维增强框架，用于函数级代码生成。在我们的模型中，设计了一个抽象语法树映射预处理模块，对数据集进行预处理，帮助大语言模型学习数据集中详细的语法信息。此外，我们设计了检索过滤与思维增强模块，用于为任务检索最相关的代码片段，并增强模型的思维链（chain-of-thought）。同时，我们还设计了一种自修复机制，防止大语言模型在修复过程中过度聚焦于已生成的错误代码，从而帮助模型探索更多修复错误代码的解决方案。我们在HumanEval、MBPP和MultiPLE基准测试上进行了实验与评估，将本模型与其他基线模型进行了对比。"
  },
  {
    "date": "2026-1-28",
    "title": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
    "authors": "Tangzhi Xu, Jianhan Liu, Yuan Yao, Cong Li, Feng Xu, Xiaoxing Ma",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00046",
    "source": "IEEE",
    "abstract": "Software testing plays a crucial role in software engineering, ensuring the reliability and correctness of evolving systems. Well-maintained test suites are essential for ensuring software quality. However, in modern development cycles that emphasize rapid feature iteration, the co-evolution of test suites often lags behind, leading to more appearance of obsolete tests. To this end, automated approaches for updating obsolete test code have been proposed, and recent approaches have achieved the state-of-the-art performance with the support of large language models (LLMs). This paper presents COMMITUP, a new approach that leverages LLMs to effectively automate method-level obsolete test code updates. COMMITUP mimics how humans solve the problem, first comprehending the code modifications, searching for similar examples to imitate, and finally performing the update. We evaluate COMMITUP on a curated dataset from real-world Java projects. The results demonstrate the superior performance of COMMITUP, achieving 96.4%, 94.4%, 93.1% success rates for generating compilable, runtime failure-free, and full coverage updates, respectively. We believe our study can provide new insight into LLM-based test code update. The dataset and code are available at https://github.com/SoftWiser-group/CommitUp.",
    "title_zh": "理解、模仿，然后更新：释放大语言模型在测试用例集演化中的潜能",
    "abstract_zh": "软件测试在软件工程中扮演着至关重要的角色，确保了不断演进的系统的可靠性与正确性。维护良好的测试套件对于保障软件质量至关重要。然而，在强调快速功能迭代的现代开发周期中，测试套件的协同演化往往滞后，导致过时测试代码大量出现。为此，研究人员提出了自动化更新过时测试代码的方法，近年来基于大语言模型（LLMs）的最新方法已取得了最先进的性能。本文提出了一种名为COMMITUP的新方法，利用大语言模型有效实现方法级别的过时测试代码自动更新。COMMITUP模仿人类解决问题的方式：首先理解代码修改内容，接着搜索相似示例进行模仿，最后完成更新操作。我们在来自真实世界Java项目的精选数据集上对COMMITUP进行了评估，结果表明其性能优越，生成可编译、运行时无错误以及实现完整覆盖的更新代码的成功率分别达到96.4%、94.4%和93.1%。我们认为本研究为基于大语言模型的测试代码更新提供了新的视角。相关数据集与代码已公开于 https://github.com/SoftWiser-group/CommitUp。"
  },
  {
    "date": "2026-1-28",
    "title": "Repairing Leaks in Resource Wrappers",
    "authors": "Sanjay Malakar, Michael D. Ernst, Martin Kellogg, Manu Sridharan",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00074",
    "source": "IEEE",
    "abstract": "A resource leak occurs when a program fails to release a finite resource like a socket, file descriptor or database connection. While sound static analysis tools can detect all leaks, automatically repairing them remains challenging. Prior work took the output of a detection tool and attempted to repair only leaks from a hard-coded list of library resource types. That approach limits the scope of repairable leaks: real-world code uses resource wrappers that store a resource in a field and must themselves be closed.This paper makes four key contributions to improve resource leak repair in the presence of wrappers. (1) It integrates inference of resource management specifications into the repair pipeline, enabling extant fixing approaches to reason about wrappers. (2) It transforms programs into variants that are easier to analyze, making inference, detection, and fixing tools more effective; for instance, it makes detection tools report problems closer to the root cause, often in a client of a resource wrapper rather than within the wrapper class itself. (3) A novel field containment analysis reasons about resource lifetimes, enabling repair of more leaks involving resources stored in fields. (4) It introduces a new repair pattern and more precise reasoning to better handle resources stored in non-final fields.Prior work fixed 41% of resource leak warnings in the NJR benchmark suite; our implementation Arodnap fixes 68%.",
    "title_zh": "修复资源包装器中的漏洞",
    "abstract_zh": "当程序未能释放有限资源（如套接字、文件描述符或数据库连接）时，就会发生资源泄漏。尽管可靠的静态分析工具能够检测出所有泄漏问题，但自动修复仍面临挑战。以往的工作仅基于检测工具的输出，尝试修复硬编码的特定库资源类型所引发的泄漏，这种做法限制了可修复泄漏的范围：实际代码中广泛使用资源包装器，这些包装器将资源存储在字段中，并且自身也需要被关闭。\n\n本文针对存在包装器情况下的资源泄漏修复问题，做出了四项关键贡献：  \n(1) 将资源管理规范的推断集成到修复流程中，使现有的修复方法能够理解并处理包装器；  \n(2) 将程序转换为更易于分析的变体，从而提升推断、检测和修复工具的效果；例如，使检测工具能将问题报告得更接近根本原因，通常定位在资源包装器的客户端而非包装器类本身；  \n(3) 提出一种新颖的字段包含性分析方法，用于推理资源生命周期，从而支持修复更多涉及字段中存储资源的泄漏问题；  \n(4) 引入一种新的修复模式以及更精确的推理机制，以更好地处理存储在非final字段中的资源。\n\n以往的工作在NJR基准测试套件中仅修复了41%的资源泄漏警告；而我们的实现Arodnap成功修复了68%。"
  },
  {
    "date": "2026-1-28",
    "title": "Enhancing Software Vulnerability Analysis via Large Language Models: A Systematic Review",
    "authors": "Lin Wang, Jin Li, Zhaojie Li, Shuaibing Lu, Guanghua Yang",
    "publish": "2025 IEEE 10th International Conference on Data Science in Cyberspace (DSC)",
    "url": "https://doi.org/10.1109/dsc67331.2025.00092",
    "source": "IEEE",
    "abstract": "In the current era of AI advancement, large language models (LLMs) have achieved remarkable breakthroughs in natural language understanding and code generation, and have been rapidly adopted in the field of software security analysis. This paper presents a systematic review of the research advancements in applying LLMs to vulnerability analysis tasks such as binary code analysis, static and dynamic vulnerability detection, and vulnerability validation. Studies show that the strong contextual understanding capabilities of LLMs enable the identification of common vulnerability types across multiple programming languages. Moreover, LLMs can act as intelligent attack agents to perform end-to-end penetration testing. The integration of LLMs with traditional static analysis techniques—such as symbolic execution and taint analysis—also demonstrates significant potential for improving the accuracy of security analysis. However, the application of LLMs in software security still faces several challenges, including high false positive rates, severe hallucination issues, limited context modeling capacity, and substantial resource consumption. This survey aims to provide researchers with a comprehensive technical overview, summarizing the latest achievements in leveraging LLMs for software security analysis, discussing their strengths and limitations, and outlining future research directions.",
    "title_zh": "基于大语言模型的软件漏洞分析增强：一项系统性综述",
    "abstract_zh": "在当前人工智能快速发展的时代，大型语言模型（LLMs）在自然语言理解与代码生成方面取得了显著突破，并迅速被应用于软件安全分析领域。本文系统性地综述了将大型语言模型应用于漏洞分析任务的研究进展，包括二进制代码分析、静态与动态漏洞检测以及漏洞验证等。研究表明，LLMs强大的上下文理解能力使其能够跨多种编程语言识别常见漏洞类型；此外，LLMs还可作为智能攻击代理，实现端到端的渗透测试。将LLMs与传统静态分析技术（如符号执行和污点分析）相结合，也展现出显著提升安全分析准确性的潜力。然而，LLMs在软件安全应用中仍面临诸多挑战，包括误报率高、严重幻觉问题、上下文建模能力有限以及资源消耗巨大等问题。本综述旨在为研究人员提供全面的技术概览，总结利用LLMs进行软件安全分析的最新成果，探讨其优势与局限性，并展望未来的研究方向。"
  },
  {
    "date": "2026-1-28",
    "title": "LLM-based Dynamic Differential Testing for Database Connectors with Reinforcement Learning-Guided Prompt Selection",
    "authors": "Ce Lyu, Yanhao Wang, Jie Liang, Minghao Zhao",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00322",
    "source": "IEEE",
    "abstract": "Database connectors are critical components that enable applications to interact with database management systems (DBMS) but their security vulnerabilities are often neglected. Unlike traditional software defects, connector vulnerabilities exhibit subtle behavioral patterns and are inherently challenging to detect. Moreover, non-standardized implementation of connectors leaves potential risks (i.e., unsafe implementations) but is more elusive. As a result, existing fuzzing methods are ineffective in finding such vulnerabilities. Even large language model (LLM)-based methods are still incapable of generating test cases that can invoke all the interface and internal logic of database connectors due to a lack of domain knowledge.In this paper, we propose a new LLM-based test case generation method guided by reinforcement learning (RL) for database connector testing. Specifically, to equip the LLM with sufficient and appropriate domain knowledge, a parameterized template is composed for prompt construction. The LLM then generates test cases instructed by the constructed prompts, which are dynamically evaluated through differential testing across multiple connectors. The testing process is carried out iteratively, where RL is adopted to select the optimal prompt in each round based on behavioral feedback from the previous rounds, to maximize the efficiency of discovering inconsistencies. Finally, we implement and evaluate the aforementioned methodology on two widely used JDBC connectors, namely MySQL Connector/J and OceanBase Connector/J. In the preliminary results, we have reported 16 bugs, among which 10 are officially confirmed, and the rest are acknowledged as unsafe implementations.",
    "title_zh": "基于大语言模型的数据库连接器动态差异测试：强化学习引导的提示选择",
    "abstract_zh": "数据库连接器是使应用程序能够与数据库管理系统（DBMS）交互的关键组件，但其安全漏洞常常被忽视。与传统软件缺陷不同，连接器漏洞表现出细微的行为特征，且本身具有较高的检测难度。此外，由于连接器实现缺乏标准化，存在潜在风险（即不安全的实现方式），这些风险更加隐蔽难测。因此，现有的模糊测试方法在发现此类漏洞方面效果不佳。即使基于大语言模型（LLM）的方法，也因缺乏领域知识而难以生成能够触发数据库连接器所有接口和内部逻辑的测试用例。\n\n本文提出了一种基于强化学习（RL）引导的新型LLM测试用例生成方法，用于数据库连接器的测试。具体而言，为使LLM具备充分且恰当的领域知识，我们设计了一个参数化模板以构建提示（prompt）。随后，LLM根据构造好的提示生成测试用例，并通过在多个连接器之间进行差异测试对生成结果进行动态评估。该测试过程采用迭代方式进行，强化学习机制根据前一轮的运行行为反馈，在每轮中选择最优提示，从而最大化发现不一致性的效率。\n\n最后，我们将上述方法应用于两种广泛使用的JDBC连接器——MySQL Connector/J 和 OceanBase Connector/J 进行实现与评估。初步结果表明，共发现了16个漏洞，其中10个已获官方确认，其余则被认定为不安全的实现方式。"
  },
  {
    "date": "2026-1-28",
    "title": "Towards Autonomous Design of UAV Path Planning Algorithms via DeepSeek",
    "authors": "Wenhong Wei, Mingzhou Li, Qingxia Li",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11342439",
    "source": "IEEE",
    "abstract": "Path planning is a critical component in UAV mission execution. While traditional optimization algorithms are mature and effective, they typically rely on expert knowledge and manual tuning, resulting in high development barriers and limited adaptability. With the growing capabilities of large language models (LLMs) in natural language understanding and code generation, we explore the autonomous generation of UAV path planning algorithms using DeepSeek, a general-purpose LLM developed in China. We propose a prompt-driven framework that guides DeepSeek to generate both structural descriptions and implementation code for optimization algorithms. A simulation environment is built to evaluate the generated strategies in terms of feasibility, logical consistency, and baseline performance, with comparisons to classical approaches. Experimental results show that DeepSeek is capable of producing executable and modular optimization strategies, demonstrating strong potential for intelligent algorithm design. Instead of aiming to surpass existing state-of-the-art methods, this work focuses on reducing development costs and enhancing accessibility in control-oriented algorithm design. Our study presents a novel perspective on automated algorithm generation and highlights the practical applicability of LLMs in robotics and intelligent control.",
    "title_zh": "通过 DeepSeek 实现无人机路径规划算法的自主设计",
    "abstract_zh": "路径规划是无人机任务执行中的关键环节。尽管传统优化算法成熟且高效，但通常依赖专家知识和人工调参，导致开发门槛高、适应性有限。随着大型语言模型（LLM）在自然语言理解与代码生成方面能力的不断提升，本文探索利用中国自主研发的通用大模型DeepSeek，实现无人机路径规划算法的自主生成。我们提出一种基于提示（prompt）驱动的框架，引导DeepSeek生成优化算法的结构化描述及可执行代码。通过构建仿真环境，对生成策略的可行性、逻辑一致性以及基准性能进行评估，并与经典方法进行对比。实验结果表明，DeepSeek能够生成可执行且模块化的优化策略，展现出在智能算法设计方面的巨大潜力。本研究并非旨在超越现有最先进方法，而是聚焦于降低开发成本、提升控制导向算法设计的可及性。我们的工作为自动化算法生成提供了新视角，凸显了大语言模型在机器人与智能控制领域的实际应用价值。"
  },
  {
    "date": "2026-1-28",
    "title": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost",
    "authors": "Daisuke Kikuta, Hiroki Ikeuchi, Kengo Tajiri",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00331",
    "source": "IEEE",
    "abstract": "Chaos Engineering (CE) is an engineering technique aimed at improving the resilience of distributed systems. It involves intentionally injecting faults into a system to test its resilience, uncover weaknesses, and address them before they cause failures in production. Recent CE tools automate the execution of predefined CE experiments. However, planning such experiments and improving the system based on the experimental results still remain manual. These processes are labor-intensive and require multi-domain expertise. To address these challenges and enable anyone to build resilient systems at low cost, this paper proposes ChaosEater, a system that automates the entire CE cycle with Large Language Models (LLMs). It predefines an agentic workflow according to a systematic CE cycle and assigns subdivided processes within the workflow to LLMs. ChaosEater targets CE for software systems built on Kubernetes. Therefore, the LLMs in ChaosEater complete CE cycles through software engineering tasks, including requirement definition, code generation, testing, and debugging. We evaluate ChaosEater through case studies on small- and large-scale Kubernetes systems. The results demonstrate that it consistently completes reasonable CE cycles with significantly low time and monetary costs. Its cycles are also qualitatively validated by human engineers and LLMs.",
    "title_zh": "基于大语言模型的全自动化混沌工程：迈向人人皆可低成本构建弹性软件系统的未来",
    "abstract_zh": "混沌工程（Chaos Engineering, CE）是一种旨在提升分布式系统弹性的工程技术。它通过有意识地向系统注入故障，来测试系统的容错能力，发现潜在弱点，并在生产环境中发生故障之前加以修复。近年来，混沌工程工具已实现对预定义混沌实验的自动化执行。然而，实验的设计规划以及基于实验结果改进系统的过程仍需人工完成，这些环节耗时耗力，且需要跨领域的专业知识。为应对上述挑战，使任何人都能以低成本构建高弹性系统，本文提出了一种名为 ChaosEater 的系统，该系统利用大型语言模型（LLMs）自动化整个混沌工程周期。ChaosEater 根据系统化的混沌工程流程预先定义了一个智能体工作流，并将工作流中的细分任务分配给不同的 LLM 执行。ChaosEater 针对基于 Kubernetes 构建的软件系统设计，因此其中的 LLM 通过软件工程任务（如需求定义、代码生成、测试与调试）完成完整的混沌工程循环。我们通过在中小型和大型 Kubernetes 系统上的案例研究对 ChaosEater 进行评估，结果表明，该系统能够以极低的时间和经济成本持续完成合理有效的混沌工程循环。其生成的循环过程也经过人类工程师和 LLM 的定性验证，证明了其有效性与可靠性。"
  },
  {
    "date": "2026-1-28",
    "title": "Unlocking Reproducibility: Automating re-Build Process for Open-Source Software",
    "authors": "Behnaz Hassanshahi, Trong Nhan Mai, Benjamin Selwyn Smith, Nicholas Allen",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00280",
    "source": "IEEE",
    "abstract": "Software ecosystems like Maven Central play a crucial role in modern software supply chains by providing repositories for libraries and build plugins. However, the separation between binaries and their corresponding source code in Maven Central presents a significant challenge, particularly when it comes to linking binaries back to their original build environment. This lack of transparency poses security risks, as approximately 84% of the top 1200 commonly used artifacts are not built using a transparent CI/CD pipeline. Consequently, users must place a significant amount of trust not only in the source code but also in the environment in which these artifacts are built.Rebuilding software artifacts from source provides a robust solution to improve supply chain security. This approach allows for a deeper review of code, verification of binary-source equivalence, and control over dependencies. However, challenges arise due to variations in build environments, such as JDK versions and build commands, which can lead to build failures. Additionally, ensuring that all dependencies are rebuilt from source across large and complex dependency graphs further complicates the process. In this paper, we introduce an extension to Macaron, an industry-grade open-source supply chain security framework, to automate the rebuilding of Maven artifacts from source. Our approach improves upon existing tools, by offering better performance in source code detection and automating the extraction of build specifications from GitHub Actions workflows. We also present a comprehensive root cause analysis of build failures in Java projects and propose a scalable solution to automate the rebuilding of artifacts, ultimately enhancing security and transparency in the open-source supply chain. While we demonstrate our approach for Java, our solution is easily extensible to other languages and ecosystems like Python and npm packages.",
    "title_zh": "实现可重现性：自动化开源软件的重新构建流程",
    "abstract_zh": "像Maven Central这样的软件生态系统在现代软件供应链中扮演着至关重要的角色，它们为库和构建插件提供了仓库。然而，Maven Central中二进制文件与其对应源代码之间的分离带来了显著挑战，尤其是在将二进制文件追溯到其原始构建环境方面。这种透明度的缺失带来了安全风险：约84%的最常用前1200个构件并非通过透明的CI/CD流水线构建。因此，用户不仅需要信任源代码本身，还需信任这些构件所处的构建环境。\n\n从源代码重新构建软件构件是提升供应链安全性的有力解决方案。该方法能够实现对代码的深入审查、验证二进制与源码的一致性，并对依赖项进行有效控制。然而，由于构建环境的差异（如JDK版本和构建命令）可能导致构建失败，这一过程面临诸多挑战。此外，在大型且复杂的依赖图谱中，确保所有依赖项均从源码重新构建也进一步增加了复杂性。\n\n本文提出对Macaron——一个工业级开源供应链安全框架——进行扩展，以实现Maven构件从源码自动重建。我们的方法在现有工具基础上有所改进，具备更优的源码检测性能，并能自动化地从GitHub Actions工作流中提取构建规范。我们还对Java项目中构建失败的根本原因进行了全面分析，并提出了一个可扩展的解决方案，用于自动化重构构件。最终，该方案显著提升了开源供应链的安全性与透明度。尽管本文以Java为例展示该方法，但我们的解决方案易于扩展至其他语言及生态，如Python和npm包。"
  },
  {
    "date": "2026-1-28",
    "title": "From Characters to Structure: Rethinking Real-Time Collaborative Programming Models",
    "authors": "Leon Freudenthaler, Bernhard Taufner, Karl Michael Göschka",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00221",
    "source": "IEEE",
    "abstract": "Multiple programming tasks require synchronous collaboration between developers, giving rise to real-time collaborative programming tools that enable simultaneous editing of shared source code. However, most existing tools operate at the text level, propagating every keystroke–including syntactically invalid ones–without considering program structure. This results in excessive communication overhead, frequent propagation of build-breaking states, and poor synchronization. A major consequence is noticeable lag, especially under unstable network conditions, as collaborators are overwhelmed with unnecessary updates that disrupt their workflow and degrade the shared coding experience. In this paper, we introduce a novel structure-aware propagation model that transmits only syntactically valid code changes. For evaluation we implemented our tool as an IntelliJ plugin and evaluate it against three industry-standard tools–VS Code Live Share, Code With Me, and Replit–across eight representative programming scenarios. Our results show that it significantly lowers the number and size of propagated messages while maintaining consistent, buildable program states. Our findings demonstrate the potential of structure-aware propagation as a foundation for the next generation of real-time collaborative programming environments.",
    "title_zh": "从角色到结构：重新思考实时协同编程模型",
    "abstract_zh": "多个编程任务需要开发者之间的同步协作，从而催生了实时协同编程工具，这些工具支持对共享源代码进行同时编辑。然而，大多数现有工具仅在文本层面操作，会传播每一个按键输入——包括语法上无效的修改——而未考虑程序的结构。这导致通信开销过大，频繁传播破坏编译的状态，且同步效果不佳。一个主要后果是明显的延迟，尤其是在网络不稳定的情况下：协作者被大量不必要的更新所干扰，打乱了工作流程，降低了共享编码体验。本文提出一种新型的结构感知传播模型，仅传输语法上有效的代码变更。为评估该方法，我们实现了一个基于IntelliJ的插件，并在八个典型的编程场景中将其与三个行业标准工具（VS Code Live Share、Code With Me 和 Replit）进行了对比测试。实验结果表明，我们的方法显著减少了传播消息的数量和大小，同时保持了稳定且可编译的程序状态。研究结果证明，结构感知传播具有成为下一代实时协同编程环境基础的巨大潜力。"
  },
  {
    "date": "2026-1-28",
    "title": "ConfuseTaint: Exploiting Vulnerabilities to Bypass Dynamic Taint Analysis",
    "authors": "Yufei Wu, Alexandre Bartel",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00340",
    "source": "IEEE",
    "abstract": "Dynamic taint analysis (DTA) tracks how sensitive data flows through a program at runtime, enabling the detection of security violations such as information leaks and injection attacks. However, most DTA systems assume that memory layouts are type-safe and structurally consistent—an assumption that can be violated by vulnerabilities such as type confusion. While type confusion has been studied in the context of sandbox escape, its ability to silently bypass taint tracking without altering program behavior remains unexplored. In this paper, we present ConfuseTaint, a technique that leverages type confusion vulnerabilities to corrupt taint metadata without modifying program semantics or the analysis tool. ConfuseTaint uses wide memory overwrites enabled by type confusion to corrupt taint tags, breaking the assumptions of taint tracking mechanisms that rely on shadow memory.We evaluate ConfuseTaint on two widely used taint tracking frameworks: Phosphor for the JVM and TaintDroid for Android. In both cases, ConfuseTaint successfully bypasses taint tracking, allowing sensitive data to reach designated sinks without detection. These results reveal a structural weakness in current DTA designs: their reliance on type-safe memory layouts leaves them vulnerable to low-level reinterpretation. Overall, our work reveals that runtime-level memory reinterpretation is an overlooked threat, calling for taint tracking architectures that do not rely on fragile assumptions about type and memory layout.",
    "title_zh": "混淆污点：利用漏洞绕过动态污点分析",
    "abstract_zh": "动态污点分析（DTA）在程序运行时追踪敏感数据的流动，从而检测信息泄露、注入攻击等安全违规行为。然而，大多数DTA系统假设内存布局是类型安全且结构一致的——这一假设可能被诸如类型混淆之类的漏洞所破坏。尽管类型混淆在沙箱逃逸场景中已有研究，但其能够无声绕过污点跟踪而无需改变程序行为的能力仍未被充分探索。本文提出了一种名为ConfuseTaint的技术，该技术利用类型混淆漏洞，在不修改程序语义或分析工具的前提下，破坏污点元数据。ConfuseTaint通过类型混淆引发的宽范围内存覆盖，篡改污点标签，从而破坏依赖于影子内存的污点跟踪机制的假设。\n\n我们在两个广泛使用的污点跟踪框架上评估了ConfuseTaint：面向JVM的Phosphor和面向Android的TaintDroid。实验结果表明，ConfuseTaint均成功绕过了污点跟踪，使得敏感数据到达指定的数据接收端而未被检测到。这些结果揭示了当前DTA设计中的一个结构性缺陷：其对类型安全内存布局的依赖，使其容易受到底层内存重解释攻击的影响。总体而言，我们的工作揭示了运行时内存重解释是一种被忽视的安全威胁，呼吁开发不依赖于脆弱类型与内存布局假设的新型污点跟踪架构。"
  },
  {
    "date": "2026-1-28",
    "title": "Design and Deployment of An LLM Framework for Duplicate Request Early Warning",
    "authors": "Yanan Zhang, Xiang Gao, Ting Ye, Junwei Wang, Yinqing Zhu, Minqian Pu",
    "publish": "2025 2nd International Symposium on AI and Cybersecurity (ISAICS)",
    "url": "https://doi.org/10.1109/isaics66888.2025.11349762",
    "source": "IEEE",
    "abstract": "The efficient identification of duplicate content from unstructured text streams presents a significant technical challenge. Traditional methods relying on keyword matching or textual similarity often fail to capture core semantic meaning, leading to low accuracy. This paper proposes a novel LLM-powered framework for the early warning of duplicate entries. Our key innovation is a two-stage LLM strategy: it first standardizes raw, unstructured text into concise, canonical descriptions, then performs a deep semantic analysis to determine if new entries constitute a repeated issue and assigns a corresponding risk level. Experimental results on a real-world dataset demonstrate that our method significantly outperforms embedding-based and keyword-retrieval baselines. Furthermore, the framework has been successfully deployed as a scalable API service in a live production environment, where it automatically generates analytical reports to assist operators in identifying and prioritizing recurrent issues.",
    "title_zh": "一种用于重复请求早期预警的大型语言模型框架的设计与部署",
    "abstract_zh": "从非结构化文本流中高效识别重复内容是一项重大的技术挑战。传统的基于关键词匹配或文本相似性的方法往往难以捕捉核心语义，导致准确率较低。本文提出了一种基于大语言模型（LLM）的新型框架，用于重复条目预警。我们的关键创新在于采用两阶段LLM策略：首先将原始、非结构化的文本标准化为简洁、规范的描述，然后进行深层次的语义分析，以判断新条目是否构成重复问题，并据此分配相应的风险等级。在真实世界数据集上的实验结果表明，该方法显著优于基于嵌入（embedding）和关键词检索的基线模型。此外，该框架已成功部署为可扩展的API服务，应用于实际生产环境，能够自动生成分析报告，协助操作人员识别并优先处理重复性问题。"
  },
  {
    "date": "2026-1-28",
    "title": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
    "authors": "Yuanpeng Li, Qi Long, Zhiyuan Yao, Jian Xu, Lintao Xie, Xu He, Lu Geng, Xin Han, Yueyan Chen, Wenbo Duan",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00288",
    "source": "IEEE",
    "abstract": "As enterprise codebases continue to grow in scale and complexity, the volume of lint errors far exceeds engineers' manual remediation capacity, leading to continuous accumulation of technical debt and hindered development efficiency. This paper presents BitsAI-Fix, an automated lint error remediation workflow based on Large Language Models (LLMs), designed to address this critical challenge in industrial-scale environments. BitsAI-Fix employs tree-sitter for context expansion and generates search-and-replace format patches through specially trained LLMs, followed by lint scan re-verification to output final remediation results. Additionally, our approach introduces an innovative progressive reinforcement learning (RL) training strategy that can automatically acquire verifiable training data during the project cold-start phase and continuously iterate the model by collecting online samples through feedback after system deployment. Furthermore, we designed a targeted rule-based reward mechanism that combines format rewards and correctness rewards while penalizing redundant modifications. We also propose a \"code diff matching\" methodology to continuously track online effectiveness. In production deployment at ByteDance, our solution has supported over 5,000 engineers, resolved more than 12,000 static analysis issues, achieved approximately 85% remediation accuracy, with around 1,000 weekly active adopters. This work demonstrates the practical feasibility of LLM-based code remediation solutions in enterprise environments and serves as a reference for automated code fix in large-scale industrial scenarios.",
    "title_zh": "BitsAI-Fix：一种基于大语言模型的实践性自动Lint错误修复方法",
    "abstract_zh": "随着企业代码库规模与复杂度的持续增长，lint错误的数量远远超出了工程师手动修复的能力，导致技术债务不断累积，开发效率受到严重制约。本文提出BitsAI-Fix，一种基于大语言模型（LLM）的自动化lint错误修复流程，旨在解决工业级环境中这一关键挑战。BitsAI-Fix采用Tree-sitter进行上下文扩展，并通过经过专项训练的LLM生成搜索-替换格式的补丁，随后通过lint扫描重新验证，输出最终的修复结果。此外，我们的方法引入了一种创新的渐进式强化学习（RL）训练策略：在项目冷启动阶段即可自动获取可验证的训练数据，并在系统上线后通过收集在线反馈样本持续迭代模型。我们还设计了一种针对性的基于规则的奖励机制，综合考虑格式奖励与正确性奖励，同时对冗余修改进行惩罚。同时，我们提出了“代码差异匹配”方法，以持续追踪线上修复效果。在字节跳动的实际生产部署中，该方案已支持超过5,000名工程师，成功修复了12,000多个静态分析问题，修复准确率约为85%，每周活跃使用人数达约1,000人。本工作证明了基于大语言模型的代码修复方案在企业环境中的实际可行性，为大规模工业场景下的自动化代码修复提供了重要参考。"
  },
  {
    "date": "2026-1-28",
    "title": "A Multi-Structural Graph Fusion Approach for Code Representation in Code Search",
    "authors": "Longhao Ao, Rongzhi Qi, Haoxuan Li",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11342508",
    "source": "IEEE",
    "abstract": "Code search aims to retrieve semantically relevant code snippets on the basis of natural language queries. With the rapid expansion of public code repositories such as GitHub and Gitee, the efficient understanding and matching of relevant code have become critical challenges. Most existing deep learning-based code search approaches rely on feature extraction from code but often fail to account for its structural integrity. They neglect the complex hierarchical structure of the code, resulting in insufficient representational capacity for semantic matching. To address these challenges, we propose an innovative code search method, AcbertGraphC, which constructs a multi-relational graph representation by combining abstract syntax tree (AST), data dependency graph (DDG), and control flow graph (CFG) through a functional program graph and early fusion strategy. Additionally, we utilize meta-path aggregated graph neural networks (MAGNN) to extract complex relation-ships from the multi-relational graph, and leverage a graph attention mechanism to dynamically adjust meta-path selection, thereby enhancing the model’s search capability. The experi-mental results demonstrate that AcbertGraphC can accurately retrieve target code snippets and outperforms existing baseline methods in terms of matching precision.",
    "title_zh": "一种用于代码搜索中代码表示的多结构图融合方法",
    "abstract_zh": "代码搜索旨在根据自然语言查询检索语义相关的代码片段。随着GitHub、Gitee等公共代码仓库的迅速扩展，高效理解并匹配相关代码已成为一项关键挑战。现有的大多数基于深度学习的代码搜索方法依赖于对代码特征的提取，但往往忽视了代码的结构完整性，未能充分考虑代码复杂的层次化结构，导致在语义匹配方面的表征能力不足。为解决这一问题，本文提出一种创新的代码搜索方法——AcbertGraphC。该方法通过功能程序图与早期融合策略，将抽象语法树（AST）、数据依赖图（DDG）和控制流图（CFG）整合为一个多关系图表示。此外，我们采用元路径聚合图神经网络（MAGNN）从多关系图中提取复杂关系，并引入图注意力机制动态调整元路径的选择，从而显著提升模型的搜索性能。实验结果表明，AcbertGraphC能够准确地检索出目标代码片段，在匹配精度方面优于现有的基线方法。"
  },
  {
    "date": "2026-1-28",
    "title": "VUSC: An Extensible Research Platform for Java-Based Static Analysis",
    "authors": "Marc Miltenberger, Steven Arzt",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00354",
    "source": "IEEE",
    "abstract": "Detecting security vulnerabilities in backend Web applications as well as mobile apps is extremely important. Static analysis for vulnerability analysis has subsequently developed as an important field of research. Researchers need extensible frameworks to avoid starting from scratch with every new research project. Compared to commercially available scanners, open-source frameworks often only provide basic functionality. This limits the ability of researchers to evaluate novel algorithms. Lacking access to full code scanners, new building blocks are often tested in isolation. In this paper, we present VUSC, a fast, precise and extensible vulnerability scanner for Android and Java bytecode. It features a plugin architecture for commonly used static analyses such as call graph, taint and value analyses, allowing researchers to build upon our work and using VUSC as a reference platform. We show that VUSC achieves a precision of around 90% on benchmarks. Video: https://youtu.be/QpXs9hv5zGc, Dataset: https://github.com/Fraunhofer-SIT/ASE2025-StaticAnalysisInfrastructure/",
    "title_zh": "VUSC：一个可扩展的基于Java的静态分析研究平台",
    "abstract_zh": "在后端Web应用及移动应用程序中检测安全漏洞至关重要。为此，漏洞分析的静态分析技术随之发展成为一项重要的研究领域。研究人员需要可扩展的框架，以避免在每个新研究项目中从零开始。与商业扫描工具相比，开源框架通常仅提供基础功能，这限制了研究人员对新型算法的评估能力。由于无法获得完整的代码扫描器，新的构建模块往往只能孤立地进行测试。本文提出VUSC——一种针对Android和Java字节码的快速、精确且可扩展的漏洞扫描工具。它采用插件式架构，支持常用的静态分析技术，如调用图分析、污点分析和值分析，使研究人员能够基于我们的工作进行开发，并将VUSC作为参考平台。实验表明，VUSC在基准测试中的准确率约为90%。视频演示：https://youtu.be/QpXs9hv5zGc，数据集：https://github.com/Fraunhofer-SIT/ASE2025-StaticAnalysisInfrastructure/"
  },
  {
    "date": "2026-1-28",
    "title": "Reverse-Engineering and Automating BDD for Modern Software Development with LLMs",
    "authors": "Sagar B. Patel, Sajal Nigam, Shrikanth Mahale",
    "publish": "2025 IEEE International Conference on Data and Software Engineering (ICoDSE)",
    "url": "https://doi.org/10.1109/icodse68111.2025.11351772",
    "source": "IEEE",
    "abstract": "Behavior-Driven Development (BDD) frameworks like Cucumber and Behave align business requirements with executable tests but remain costly to author and maintain, especially for legacy or evolving systems [1], [2]. We present a novel LLM-driven approach, leveraging LLaMA to reverse-engineer requirements from schemas, API payloads, and partial tests to automatically generate Gherkin feature files with corresponding step definitions. Generated artifacts are drafted into automated pull requests and merged into the repositories via human review [3]. Our proposed method when tested across two enterprise systems, over six sprints, reduced authoring time by about 75%, expanded negative test coverage by 30%, and achieved cost savings ranging from $7,725 in conservative adoption to over $40,000 in high-volume adoption, maintaining infrastructure overhead costs below 3%. Beyond efficiency gains, the approach lowers barriers for teams new to BDD and demonstrates a practical, cost-effective path for industry adoption while opening avenues for research in adaptive prompting, coverage-aware generation, and retrieval-augmented workflows. [3].",
    "title_zh": "利用大语言模型实现现代软件开发中BDD的逆向工程与自动化",
    "abstract_zh": "行为驱动开发（BDD）框架如Cucumber和Behave能够将业务需求与可执行测试对齐，但其编写和维护成本较高，尤其是在遗留系统或持续演进的系统中[1]，[2]。本文提出一种创新的基于大语言模型（LLM）的方法，利用LLaMA从数据模式、API请求体及部分测试用例中逆向推导出需求，自动生成功能明确的Gherkin特性文件及其对应的步骤定义。生成的代码片段通过自动化拉取请求提交，并经人工评审后合并至代码仓库[3]。在两个企业级系统上经过六轮迭代测试，该方法使需求编写时间减少了约75%，负面测试覆盖率提升了30%，在保守采用场景下节省成本达7,725美元，在高使用量场景下超过40,000美元，且基础设施开销始终低于3%。除了显著提升效率外，该方法降低了团队初涉BDD的门槛，为行业推广提供了一条切实可行且经济高效的路径，同时为自适应提示工程、覆盖感知生成以及检索增强型工作流等研究方向开辟了新空间[3]。"
  },
  {
    "date": "2026-1-28",
    "title": "TrustPKBG: Trustworthy Protocol Knowledge Blueprints Generation via LLM for Low-Altitude UAV Networks",
    "authors": "Fan Wu, Yuxin Zhang, Gaolei Li, Jianhua Li, Jin Ma",
    "publish": "IEEE Transactions on Cognitive Communications and Networking",
    "url": "https://doi.org/10.1109/tccn.2026.3658765",
    "source": "IEEE",
    "abstract": "In low-altitude networks, reliable and lightweight flight interconnection among UAVs mainly depends on protocols like Message Queuing Telemetry Transport (MQTT). However, existing protocol analysis methods often fail to adapt to unknown program functions caused by version updates due to a lack of protocol knowledge blueprints (PKB). Moreover, due to the lack of multiple rounds of verification in terms of grammar semantics and execution logic representation, the correctness, validity and credibility of the generated PKB in practical scenarios remain questionable. To address these challenges, this paper proposes a novel trust-worthy protocol knowledge blueprints generation (TrustPKBG) framework for low-altitude UAV networks by large language model (LLM). In TrustPKBG, a Hierarchical Chain-of-Thought (HCoT) strategy is designated to automatically transform technical specifications into a structured, objective, and consistent PKB draft against the bias of human construction. Moreover, to enhance the abstract semantic similarity between PKB drafts and RFC documents, a memory-aware multi-agent collaboration mechanism is also presented, which enables closed-loop error detection and knowledge updating. To demonstrate the superiority of TrustPKBG, we also implement a Fuzzing-based PKB Verifier over MQTT/CoAP. Experimental results demonstrate that fuzzing with TrustPKBG can achieve an average code coverage rate of 33.71% for MQTT and 33.5% for CoAP, which is 50.83% higher than the baseline average coverage rate of 22.35% for MQTT and 27.6% for CoAP, with a valid test ratio of 74.57% for MQTT and 62.3% for CoAP. Furthermore, we explore PKB’s application in protocol code auditing by evaluating open-source MQTT and CoAP implementations for compliance verification, which demonstrate the effectiveness of the proposed methods.",
    "title_zh": "TrustPKBG：基于大语言模型的低空无人机网络可信协议知识蓝图生成",
    "abstract_zh": "在低空无人机网络中，无人机之间的可靠且轻量级飞行互联主要依赖于诸如消息队列遥测传输（MQTT）等协议。然而，现有的协议分析方法往往难以适应因版本更新导致的未知程序功能，其根本原因在于缺乏协议知识蓝图（Protocol Knowledge Blueprint, PKB）的标准化参考框架。此外，由于在语法语义和执行逻辑表示方面缺乏多轮验证，生成的PKB在实际应用场景中的正确性、有效性和可信度仍存疑。为应对上述挑战，本文提出一种基于大语言模型（LLM）的可信协议知识蓝图生成框架（TrustPKBG），专用于低空无人机网络。在TrustPKBG中，设计了分层思维链（Hierarchical Chain-of-Thought, HCoT）策略，能够自动将技术规范转化为结构化、客观且一致的PKB初稿，有效规避人工构建带来的主观偏差。同时，为进一步提升PKB初稿与RFC文档之间的抽象语义相似度，本文还提出一种具备记忆能力的多智能体协同机制，支持闭环错误检测与知识迭代更新。为验证TrustPKBG的优越性，我们基于Fuzzing技术实现了针对MQTT/CoAP协议的PKB验证器。实验结果表明，采用TrustPKBG进行Fuzzing测试时，MQTT协议平均代码覆盖率可达33.71%，CoAP协议达33.5%，分别较基线平均覆盖率（MQTT为22.35%，CoAP为27.6%）提升了50.83%；同时，MQTT的有效测试用例比例达到74.57%，CoAP为62.3%。此外，我们进一步探索了PKB在协议代码审计中的应用，通过评估开源MQTT与CoAP实现的合规性，验证了所提方法的有效性。"
  },
  {
    "date": "2026-1-28",
    "title": "Detecting Vulnerabilities from Issue Reports for Internet-of-Things",
    "authors": "Sogol Masoumzadeh",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00394",
    "source": "IEEE",
    "abstract": "Timely identification of issue reports reflecting software vulnerabilities is crucial, particularly for Internet-of-Things (IoT) where analysis is slower than non-IoT systems. While Machine Learning (ML) and Large Language Models (LLMs) detect vulnerability-indicating issues in non-IoT systems, their IoT use remains unexplored. We are the first to tackle this problem by proposing two approaches: (1) combining ML and LLMs with Natural Language Processing (NLP) techniques to detect vulnerability-indicating issues of 21 Eclipse IoT projects and (2) fine-tuning a pre-trained BERT Masked Language Model (MLM) on 11,000 GitHub issues for classifying vulnerability-indicating issues. Our best performance belongs to a Support Vector Machine (SVM) trained on BERT NLP features, achieving an Area Under the receiver operator characteristic Curve (AUC) of 0.65. The fine-tuned BERT achieves 0.26 accuracy, emphasizing the importance of exposing all data during training. Our contributions set the stage for accurately detecting IoT vulnerabilities from issue reports, similar to non-IoT systems.",
    "title_zh": "从物联网问题报告中检测漏洞",
    "abstract_zh": "及时识别反映软件漏洞的问题报告对于物联网（IoT）系统尤为重要，因为其分析速度通常慢于非IoT系统。尽管机器学习（ML）和大语言模型（LLMs）已在非IoT系统中用于检测具有漏洞指示特征的问题，但其在IoT领域的应用仍处于空白状态。我们首次针对这一问题提出两种方法：（1）结合机器学习、大语言模型与自然语言处理（NLP）技术，对21个Eclipse IoT项目中的漏洞指示性问题进行检测；（2）基于11,000个GitHub问题对预训练的BERT掩码语言模型（MLM）进行微调，以实现对漏洞指示性问题的分类。其中表现最佳的是基于BERT NLP特征训练的支持向量机（SVM），其受试者工作特征曲线下面积（AUC）达到0.65。而微调后的BERT模型仅获得0.26的准确率，凸显了在训练过程中充分暴露数据的重要性。我们的研究为从问题报告中准确检测IoT漏洞奠定了基础，使其实现与非IoT系统相当的检测能力。"
  },
  {
    "date": "2026-1-28",
    "title": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution",
    "authors": "Yibo Wang, Zhihao Peng, Ying Wang, Zhao Wei, Hai Yu, Zhiliang Zhu",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00154",
    "source": "IEEE",
    "abstract": "LLMs demonstrate strong performance in automated software engineering, particularly for code generation and issue resolution. While proprietary models like GPT-4o achieve high benchmarks scores on SWE-bench, their API dependence, cost, and privacy concerns limit adoption. Open-source alternatives offer transparency but underperform in complex tasks, especially sub-100B parameter models. Although quality Chain-of-Thought (CoT) data can enhance reasoning, current methods face two critical flaws: (1) weak rejection sampling reduces data quality, and (2) inadequate step validation causes error accumulation. These limitations lead to flawed reasoning chains that impair LLMs’ ability to learn reliable issue resolution.The paper proposes MCTS-REFINE, an enhanced Monte Carlo Tree Search (MCTS)-based algorithm that dynamically validates and optimizes intermediate reasoning steps through a rigorous rejection sampling strategy, generating high-quality CoT data to improve LLM performance in issue resolution tasks. Key innovations include: (1) augmenting MCTS with a reflection mechanism that corrects errors via rejection sampling and refinement, (2) decomposing issue resolution into three subtasks—File Localization, Fault Localization, and Patch Generation—each with clear ground-truth criteria, and (3) enforcing a strict sampling protocol where intermediate outputs must exactly match verified developer patches, ensuring correctness across reasoning paths.Experiments on SWE-bench Lite and SWE-bench Verified demonstrate that LLMs fine-tuned with our CoT dataset achieve substantial improvements over baselines. Notably, Qwen2.5-72B-Instruct achieves 28.3%(Lite) and 35.0%(Verified) resolution rates, surpassing SOTA baseline SWE-Fixer-Qwen-72B with the same parameter scale, which only reached 24.7%(Lite) and 32.8%(Verified). Given precise issue locations as input, our fine-tuned Qwen2.5-72B-Instruct model achieves an impressive issue resolution rate of 43.8%(Verified), comparable to the performance of Deepseek-v3. We open-source our MCTS-REFINE framework, CoT dataset, and fine-tuned models to advance research in AI-driven software engineering.",
    "title_zh": "MCTS-精炼的思维链：用于基于大语言模型的仓库问题解决的高质量微调数据",
    "abstract_zh": "大型语言模型（LLMs）在自动化软件工程领域表现出色，尤其在代码生成和问题修复方面。尽管专有模型如GPT-4o在SWE-bench基准测试中取得了优异成绩，但其对API的依赖、高昂成本以及隐私顾虑限制了实际应用。开源替代方案虽具备透明性优势，但在复杂任务上表现欠佳，尤其是参数量低于100B的模型。虽然高质量的思维链（Chain-of-Thought, CoT）数据能够提升模型推理能力，但现有方法存在两个关键缺陷：（1）弱化的拒绝采样机制降低了数据质量；（2）中间步骤验证不足导致错误累积。这些局限性使得推理链条存在缺陷，进而削弱了LLM学习可靠问题修复能力的效果。\n\n本文提出MCTS-REFINE——一种基于蒙特卡洛树搜索（MCTS）的增强型算法，通过严格的拒绝采样策略动态验证并优化中间推理步骤，生成高质量的CoT数据，从而提升LLM在问题修复任务中的表现。主要创新点包括：（1）在MCTS中引入反思机制，利用拒绝采样与修正手段主动纠正错误；（2）将问题修复过程分解为三个子任务——文件定位、故障定位与补丁生成，并为每个任务设定明确的真实标签标准；（3）实施严格的采样协议，要求中间输出必须与经验证的开发者补丁完全一致，确保所有推理路径的正确性。\n\n在SWE-bench Lite和SWE-bench Verified上的实验表明，使用我们生成的CoT数据进行微调的LLM相比基线模型有显著提升。特别地，Qwen2.5-72B-Instruct在Lite和Verified基准上分别达到28.3%和35.0%的问题修复率，超越同参数规模的最先进基线SWE-Fixer-Qwen-72B（分别为24.7%和32.8%）。当提供精确的问题位置作为输入时，微调后的Qwen2.5-72B-Instruct模型在Verified基准上实现了高达43.8%的修复率，接近Deepseek-v3的表现水平。\n\n我们已将MCTS-REFINE框架、CoT数据集及微调模型全部开源，以推动人工智能驱动的软件工程研究发展。"
  },
  {
    "date": "2026-1-28",
    "title": "Multi-Stage Testing for Open Source IoT Frameworks",
    "authors": "Ulrich Norbisrath, Bruno Rossi, Ruben Jubeh, Araz Heydarov",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11343478",
    "source": "IEEE",
    "abstract": "The Internet of Things (IoT) has rapidly evolved, integrating networked intelligence into a web of things, servers, and cloudlets. Although there are various tools and approaches for software testing, the broader field of IoT testing presents unique challenges due to the heterogeneity of devices, large-scale deployments, dynamic environments, and real-time needs. This paper presents our approach to developing a multi-stage testing framework for the IoTempower framework, addressing the challenges of testing a versatile and evolving open-source Internet-of-Things framework used extensively in educational settings and beyond. The framework incorporates compilation testing, integration testing, and system testing with a focus on regression testing. This multi-stage testing approach allows us to validate the framework’s functionality at various granularities, from the correct compilation of individual drivers to the seamless interaction of deployed hardware. This approach aims to proactively identify and prevent regressions, facilitating the integration of new features and enhancements without losing our scope of providing a real hands-on IoT experience in the classroom.",
    "title_zh": "开源物联网框架的多阶段测试",
    "abstract_zh": "物联网（IoT）已迅速发展，将网络化智能融入由各类设备、服务器和云边缘节点构成的复杂网络中。尽管软件测试领域已有多种工具和方法，但物联网测试由于设备异构性、大规模部署、动态环境以及实时性需求等特性，仍面临独特挑战。本文介绍了我们为IoTempower框架开发多阶段测试框架的方法，旨在应对一个广泛应用于教育领域及其他场景的多功能且持续演进的开源物联网框架所面临的测试难题。该框架融合了编译测试、集成测试与系统测试，并特别强调回归测试。这种多阶段测试方法使我们能够在不同粒度上验证框架的功能，从单个驱动程序的正确编译，到已部署硬件间的无缝协同工作。该方法旨在主动发现并预防潜在的回归问题，从而在不牺牲课堂中真实动手实践体验的前提下，顺利集成新功能与改进。"
  },
  {
    "date": "2026-1-28",
    "title": "AI-Empowered Smart Contract Vulnerability Detection for Decentralized Blockchain Systems",
    "authors": "Chi Jiang, Caixing Shao, Xiaoyan Huang, Ming Tao, Yin Zhang, Yan Zhang",
    "publish": "IEEE Transactions on Network Science and Engineering",
    "url": "https://doi.org/10.1109/tnse.2026.3658785",
    "source": "IEEE",
    "abstract": "Blockchain technology is evolving toward next-generation blockchain systems, where AI-empowered optimization plays a key role in enhancing scalability, efficiency, and security. However, in the context of smart contract vulnerability detection, however, most vulnerabilities originate from a few critical code fragments, resulting in a severe signal-to-noise imbalance. This imbalance introduces representation noise and redundant information in complex contract code, obscuring the true vulnerability semantics and hindering the effectiveness of AI-based models such as graph neural networks (GNNs). To address this challenge, we propose CoTA, a feature augmentation framework that leverages two easily obtainable signals: code-cohort feature and task-shared feature. Code-cohort features capture the observation that contracts with similar structural/behavioral patterns often implement similar business functions, and thus share vulnerability priors (e.g., higher reentrancy risk in fund-transfer-heavy cohorts). Task-shared feature, on the other hand, learned via a multi-task setup that jointly trains coarse contract-level multi-label classification and fine-grained function-level labeling to distill shared representations. Extensive experiments on real-world dataset show that CoTA achieves consistent improvements in detection accuracy, offering a practical and effective solution for smart contract security analysis.",
    "title_zh": "人工智能赋能的去中心化区块链系统智能合约漏洞检测",
    "abstract_zh": "区块链技术正朝着下一代区块链系统演进，其中人工智能赋能的优化在提升可扩展性、效率和安全性方面发挥着关键作用。然而，在智能合约漏洞检测的背景下，大多数漏洞往往源自少数关键代码片段，导致严重的信号-噪声失衡问题。这种失衡在复杂的合约代码中引入了表示噪声和冗余信息，掩盖了真实的漏洞语义，从而阻碍了图神经网络（GNN）等基于人工智能模型的有效性。为应对这一挑战，我们提出 CoTA——一种特征增强框架，该框架利用两种易于获取的信号：代码同群特征（code-cohort feature）和任务共享特征（task-shared feature）。代码同群特征捕捉到具有相似结构或行为模式的合约通常实现类似的业务功能，因而共享特定的漏洞先验知识（例如，以资金转账为主的合约群体具有更高的重入攻击风险）。而任务共享特征则通过多任务学习机制获得，即联合训练粗粒度的合约级多标签分类与细粒度的函数级标注任务，以提炼出共享的表征。在真实世界数据集上的大量实验表明，CoTA 在漏洞检测准确率上实现了持续提升，为智能合约安全分析提供了一种实用且高效的新解决方案。"
  },
  {
    "date": "2026-1-28",
    "title": "CLMN: Concept based Language Models via Neural Symbolic Reasoning",
    "authors": "Yibo Yang",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11342496",
    "source": "IEEE",
    "abstract": "Deep learning’s remarkable performance in natural language processing (NLP) faces critical interpretability challenges, particularly in high-stakes domains like healthcare and finance where model transparency is essential. While concept bottleneck models (CBMs) have enhanced interpretability in computer vision by linking predictions to human-understandable concepts, their adaptation to NLP remains understudied with persistent limitations. Existing approaches either enforce rigid binary concept activations that degrade textual representation quality or obscure semantic interpretability through latent concept embeddings, while failing to capture dynamic concept interactions crucial for understanding linguistic nuances like negation or contextual modification. This paper proposes the Concept Language Model Network (CLMN), a novel neural-symbolic framework that reconciles performance and interpretability through continuous concept embeddings enhanced by fuzzy logic-based reasoning. CLMN addresses the information loss in traditional CBMs by projecting concepts into an interpretable embedding space while preserving human-readable semantics, and introduces adaptive concept interaction modeling through learnable neural-symbolic rules that explicitly represent how concepts influence each other and final pre-dictions. By supplementing original text features with concept-aware representations and enabling automatic derivation of interpretable logic rules, our framework achieves superior performance on multiple NLP benchmarks while providing transparent explanations. Extensive experiments across various pre-trained language models and datasets demonstrate that CLMN outperforms existing concept-based methods in both accuracy and explanation quality, establishing a new paradigm for developing high-performance yet interpretable NLP systems through synergistic integration of neural representations and symbolic reasoning in a unified concept space.",
    "title_zh": "基于概念的神经符号推理语言模型",
    "abstract_zh": "深度学习在自然语言处理（NLP）领域取得了显著成果，但在高风险领域（如医疗和金融）中，其模型的可解释性面临严峻挑战，透明性至关重要。尽管概念瓶颈模型（CBMs）通过将预测与人类可理解的概念关联，在计算机视觉领域提升了可解释性，但其在自然语言处理中的应用仍研究不足，且存在持续性的局限。现有方法要么强制采用刚性的二值化概念激活机制，导致文本表征质量下降；要么通过潜在概念嵌入模糊了语义可解释性，同时未能捕捉对理解语言细微差别（如否定或上下文修饰）至关重要的动态概念交互。本文提出一种新型神经符号框架——概念语言模型网络（CLMN），通过融合基于模糊逻辑推理的连续概念嵌入，实现性能与可解释性的统一。CLMN通过将概念投影到可解释的嵌入空间，有效缓解了传统CBMs中的信息损失，同时保留了人类可读的语义含义；并引入可学习的神经符号规则，实现自适应的概念交互建模，明确表达概念之间的相互影响及其对最终预测的作用。通过在原始文本特征基础上补充概念感知的表示，并支持可解释逻辑规则的自动推导，本框架在多个NLP基准测试中均展现出卓越性能，同时提供清晰透明的解释。大量实验结果表明，无论在预训练语言模型还是不同数据集上，CLMN在准确率和解释质量方面均优于现有的基于概念的方法，为构建高性能且可解释的NLP系统树立了新范式——即通过在统一的概念空间中协同整合神经表征与符号推理，实现智能系统的深度融合与高效演进。"
  },
  {
    "date": "2026-1-28",
    "title": "PerturbGen: A Population Based Perturbation Method for Processor Test Generation",
    "authors": "Jingkai Wang, Renzhi Chen, Lei Wang",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11343428",
    "source": "IEEE",
    "abstract": "The increasing complexity of processor design demands higher requirements for simulation-based verification, particularly in test case generation. Existing random test generators often struggle to thoroughly validate the deep processor states or fail to provide sufficient coverage diversity. In this paper, we propose PerturbGen, an evolutionary algorithm-inspired population-based perturbation test generation method, designed to enhance traditional random test generators. Per-turbGen introduces crossover and mutation operators from evolutionary algorithm, applying perturbations at both the population and member levels to generate high-quality tests. Our approach also includes a coverage-guided feedback loop for iteratively filtering members to guide the exploration of uncovered areas in the processor. We evaluated PerturbGen on an open-source RISC-V processor and compared it with two widely-used random test generators. Our method achieves relative improvements of 3.56%, 5.70%, and 14.01% in three key coverage metrics, respectively, proving the superiority of PerturbGen. Our code is open-sourced at the anonymous link: https://anonymous.4open.science/r/PerturbGen-2B07.",
    "title_zh": "PerturbGen：一种基于种群的处理器测试生成扰动方法",
    "abstract_zh": "处理器设计日益复杂，对基于仿真的验证提出了更高要求，尤其是在测试用例生成方面。现有的随机测试生成器往往难以充分验证处理器的深层状态，或无法提供足够的覆盖多样性。本文提出了一种受进化算法启发的、基于种群的扰动测试生成方法——PerturbGen，旨在提升传统随机测试生成器的能力。PerturbGen引入了进化算法中的交叉与变异算子，在种群层面及个体层面施加扰动，以生成高质量的测试用例。此外，我们的方法还包含一个覆盖引导的反馈循环，通过迭代筛选种群成员，引导对处理器中未覆盖区域的探索。我们在一款开源RISC-V处理器上对PerturbGen进行了评估，并与两种广泛使用的随机测试生成器进行了对比。实验结果表明，PerturbGen在三个关键覆盖率指标上分别实现了3.56%、5.70%和14.01%的相对提升，充分证明了其优越性。相关代码已开源，地址为：https://anonymous.4open.science/r/PerturbGen-2B07。"
  },
  {
    "date": "2026-1-28",
    "title": "CLUG: Contrastive Learning Unified Retrieval with Graph-Ranked Demonstrations for Enhanced In-Context Learning*",
    "authors": "Xiantao Xu, Minghao Hu, ShiLong Liu, Wei Luo, Yushan Tan, Zhunchen Luo",
    "publish": "2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
    "url": "https://doi.org/10.1109/smc58881.2025.11342581",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) have demonstrated the ability to perform in-context learning (ICL) with only a few demostrations, achieving remarkable performance across various downstream tasks. The selection of demonstrations plays a critical role in shaping the performance of ICL due to its high sensitivity. However, previous researchers have primarily focused on either the tricks for selecting demonstrations or the sequencing of demonstrations, thereby neglecting the critical role of retrieval models in ICL. The rigid structures and parameters employed in these studies often fail to align with the specific requirements of downstream tasks. To address this problem, we propose CLUG: contrastive learning unified retrieval with graph-ranked demonstrations for enhanced in-context learning, integrating demonstrations retrieval selection and demonstrations order to establish semantically coherent sequences of demonstrations, thereby ensuring enhanced semantic alignment and consistency. Experimental results across multiple datasets demonstrate consistent improvements with our method. Additional analyses further validate and explain the effectiveness and generalizability of our approach.",
    "title_zh": "CLUG：基于图排名示范的对比学习统一检索以增强上下文学习*",
    "abstract_zh": "大型语言模型（LLMs）已展现出仅需少量示例即可实现上下文学习（ICL），并在多种下游任务中取得卓越表现。由于ICL对示例选择高度敏感，因此示例的选取在很大程度上决定了其性能表现。然而，以往的研究主要聚焦于示例选择技巧或示例排序策略，忽视了检索模型在ICL中的关键作用。这些研究普遍采用固定结构和参数，难以适配具体下游任务的需求。为解决这一问题，我们提出CLUG：一种基于对比学习的统一检索框架，结合图排序机制以优化示例选择与顺序，从而构建语义连贯的示例序列，确保更强的语义对齐与一致性。在多个数据集上的实验结果表明，我们的方法持续提升了性能。进一步的分析也验证并解释了该方法的有效性与泛化能力。"
  },
  {
    "date": "2026-1-28",
    "title": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
    "authors": "Xin Zhou, Kisub Kim, Ting Zhang, Martin Weyssow, Luís F. Gomes, Guang Yang, Kui Liu, Xin Xia, David Lo",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00214",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) and other automated techniques have been increasingly used to support software developers by generating software artifacts such as code snippets, patches, and comments. However, accurately assessing the correctness of these generated artifacts remains a significant challenge. On one hand, human evaluation provides high accuracy but is labor-intensive and lacks scalability. On the other hand, many automatic evaluation metrics are scalable and require minimal human effort, but they often fail to accurately reflect the actual correctness of generated software artifacts.In this paper, we present SE-Jury, the first evaluation metric for LLM-as-Ensemble-Judge specifically designed to accurately assess the correctness of generated software artifacts. SE-Jury first defines five distinct evaluation strategies, each implemented as an independent judge. A dynamic team selection mechanism then identifies the most appropriate subset of judges as a team to produce a final correctness score through ensembling. We evaluate SE-Jury across a diverse set of software engineering (SE) benchmarks that span three popular SE tasks: code generation, automated program repair, and code summarization. Results demonstrate that SE-Jury consistently achieves a higher correlation with human judgments, with improvements ranging from 29.6%–140.8% over existing automatic metrics. SE-Jury reaches agreement levels with human annotators that are close to inter-annotator agreement in code generation and program repair. These findings underscore SE-Jury’s potential as a scalable and reliable alternative to human evaluation in these SE tasks.",
    "title_zh": "SE-Jury：一种基于大模型集成裁判的度量方法，用于缩小与人类评估之间的差距",
    "abstract_zh": "大型语言模型（LLMs）及其他自动化技术正越来越多地被用于支持软件开发人员生成代码片段、补丁和注释等软件制品。然而，准确评估这些生成制品的正确性仍然是一个重大挑战。一方面，人工评估虽然具有较高的准确性，但耗时费力且难以扩展；另一方面，尽管许多自动评估指标具备可扩展性且几乎无需人工参与，却往往无法准确反映生成软件制品的实际正确性。\n\n在本文中，我们提出了SE-Jury，这是首个专为“大模型作为集成裁判”（LLM-as-Ensemble-Judge）设计的评估指标，旨在精确评估生成软件制品的正确性。SE-Jury首先定义了五种不同的评估策略，每种策略均以独立的“裁判”形式实现。随后，一种动态团队选择机制会从这些裁判中识别出最合适的子集，组成一个团队，通过集成方式生成最终的正确性评分。\n\n我们在涵盖三个主流软件工程（SE）任务——代码生成、自动化程序修复和代码摘要——的多样化基准数据集上对SE-Jury进行了评估。结果表明，SE-Jury在与人工判断的相关性方面表现优异，相较于现有自动指标，相关性提升幅度达29.6%至140.8%。在代码生成和程序修复任务中，SE-Jury与人工标注者的一致性水平接近于人工标注者之间的互评一致性。这些发现充分证明了SE-Jury在这些软件工程任务中，作为可扩展且可靠的替代人工评估方法的巨大潜力。"
  },
  {
    "date": "2026-1-28",
    "title": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
    "authors": "Benjamin Rombaut, Sogol Masoumzadeh, Kirill Vasilevski, Dayi Lin, Ahmed E. Hassan",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00067",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) are increasingly integrated into autonomous systems, giving rise to a new class of software known as Agentware, where LLM-powered agents perform complex, open-ended tasks in domains such as software engineering, customer service, and data analysis. However, their high autonomy and opaque reasoning processes pose significant challenges for traditional software observability methods. To address this, we introduce the concept of cognitive observability—the ability to recover and inspect the implicit reasoning behind agent decisions. We present Watson, a general-purpose framework for observing the reasoning processes of fast-thinking LLM agents without altering their behavior. Watson retroactively infers reasoning traces using prompt attribution techniques. We evaluate Watson in both manual debugging and automated correction scenarios across the MMLU benchmark and the AutoCodeRover and OpenHands agents on the SWE-bench-lite dataset. In both static and dynamic settings, Watson surfaces actionable reasoning insights and supports targeted interventions, demonstrating its practical utility for improving transparency and reliability in Agentware systems.",
    "title_zh": "沃森：一种用于大语言模型驱动智能体推理的认知可观测性框架",
    "abstract_zh": "大型语言模型（LLMs）正越来越多地被集成到自主系统中，催生了一类新型软件——Agentware。在该类系统中，由LLM驱动的智能体能够执行软件工程、客户服务和数据分析等领域的复杂且开放式的任务。然而，这些智能体具有高度自主性以及难以理解的推理过程，给传统的软件可观测性方法带来了重大挑战。为应对这一问题，我们提出了“认知可观测性”（cognitive observability）的概念，即恢复并检查智能体决策背后隐含推理的能力。我们提出Watson——一个通用的框架，能够在不改变智能体行为的前提下，观测快速思考型LLM智能体的推理过程。Watson通过提示词归因技术，事后推断出推理轨迹。我们在MMLU基准测试，以及SWE-bench-lite数据集上的AutoCodeRover和OpenHands智能体上，对Watson进行了人工调试和自动化修复两种场景的评估。无论在静态还是动态环境下，Watson均能揭示可操作的推理洞察，并支持针对性干预，充分展示了其在提升Agentware系统透明度与可靠性方面的实际价值。"
  },
  {
    "date": "2026-1-28",
    "title": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
    "authors": "Wei Liu, Zhenhua Li, Feng Qian, Feiyu Jin, Hao Lin, Yannan Zheng, Bo Xiao, Xiaokang Qin, Tianyin Xu",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00040",
    "source": "IEEE",
    "abstract": "Democracy is crucial to a cryptocurrency ecosystem, as the diversity of miners (farms, personal computers, web clients, or even cloud functions) underlays the credibility of the cryptocurrency. Among miners, web clients used to be the vast majority, e.g., 50M+ as of March 2018. As time went on, however, cryptomining was gradually monopolized by mining farms with dedicated hardware (e.g., ASICs), and web clients scaled down to ∼0.1M. To suppress mining farms, certain cryptocurrencies (like Monero) adopted new mining algorithms such as RandomX whose execution relies on general-purpose hardware architectures. Unfortunately, this further impairs web-based cryptomining as web clients cannot provide the desired architecture support to these algorithms. This paper explores how to revive software democracy of efficient web-based crypto-mining, using a novel program transformation technique termed Vectra. Vectra employs just-in-time (JIT) transformations of mining programs for web architectures; it effectively identifies and merges isomorphic instructions upon execution. Vectra ensures correct transformations based on symbolic constraints of the instructions. Real-world deployments show that Vectra reduces WASM instructions by about 7× and achieves a 3× –16× speedup for web cryptomining in diverse execution environments like PCs, mobile phones, and serverless platforms, which translates to a high (69%–274%) return-on-investment (ROI) for common users.",
    "title_zh": "通过即时转换挖矿程序实现加密货币生态系统的民主化",
    "abstract_zh": "民主对于加密货币生态系统至关重要，因为矿工的多样性——包括矿场、个人电脑、网页客户端，甚至云函数——构成了加密货币可信度的基础。在早期，网页客户端曾是矿工中的绝对多数，例如截至2018年3月，其数量超过5000万。然而随着时间推移，加密挖矿逐渐被配备专用硬件（如ASIC）的矿场所垄断，网页客户端的数量则锐减至约10万。为抑制矿场的主导地位，某些加密货币（如门罗币）采用了新的挖矿算法（如RandomX），这些算法依赖通用硬件架构。但不幸的是，这反而削弱了基于网页的挖矿能力，因为网页客户端无法提供这些算法所需的架构支持。本文提出一种名为Vectra的新程序转换技术，旨在重振高效网页端加密挖矿的软件民主。Vectra采用即时（JIT）方式对网页架构上的挖矿程序进行转换；它能在执行过程中有效识别并合并同构指令。Vectra通过指令的符号约束确保转换的正确性。实际部署结果表明，Vectra可将WASM指令数量减少约7倍，并在个人电脑、移动设备及无服务器平台等多种执行环境中实现3至16倍的速度提升，为普通用户带来高达69%至274%的投资回报率（ROI）。"
  },
  {
    "date": "2026-1-28",
    "title": "Unified Artificial Intelligence and Formal Reasoning Approach to Software Security",
    "authors": "Arif Muhammed, R Shekhar",
    "publish": "2025 5th International Conference on Mobile Networks and Wireless Communications (ICMNWC)",
    "url": "https://doi.org/10.1109/icmnwc66779.2025.11354207",
    "source": "IEEE",
    "abstract": "Software vulnerabilities represent serious security concerns; every year, over 25,000 Common Vulnerabilities and Exposures (CVEs) are issued, and cybercrime spending is estimated to be USD 23.82 trillion by 2027. Traditional static analysis tools achieve only 60-70% detection accuracy with 3040% false positives, while recent large language model approaches lack strong validation controls. This paper proposes an integrated framework incorporating machine learning-driven vulnerability analysis, automated patch generation, and formal verification methods. It has semantic extraction based on BERT on CVE descriptions, a SecureFalcon-inspired multi-class severity classifier, a context-aware LLM patch generator with chain-ofthought reasoning, and a verification of bounded model checking. Evaluation on 15,247 real-world vulnerabilities demonstrates 96.2% detection accuracy, 76.4% end-to-end remediation success, and 68.7% false-positive reduction compared to LLM-only approaches, with average processing time of 3.2 minutes per CVE. The framework provides mathematically verified corrections with dynamic software-defined networking protection during remediation phases.",
    "title_zh": "统一的人工智能与形式化推理方法在软件安全中的应用",
    "abstract_zh": "软件漏洞构成了严重的安全威胁；每年发布的通用漏洞与暴露（CVE）数量超过25,000个，而网络犯罪支出预计到2027年将达到23.82万亿美元。传统的静态分析工具的检测准确率仅为60%-70%，且误报率高达30%-40%；而近期基于大语言模型的方法则缺乏强有力的验证控制机制。本文提出了一种集成框架，融合了机器学习驱动的漏洞分析、自动化补丁生成以及形式化验证方法。该框架包含基于BERT的CVE描述语义提取模块、受SecureFalcon启发的多类别严重性分类器、具备思维链推理能力的上下文感知LLM补丁生成器，以及有界模型检查的验证机制。在15,247个真实世界漏洞上的评估表明，该框架实现了96.2%的检测准确率，端到端修复成功率达76.4%，相比仅使用LLM的方法误报率降低68.7%，平均每条CVE处理时间为3.2分钟。该框架在修复阶段提供数学上可验证的修正方案，并结合动态软件定义网络（SDN）实现防护，显著提升了整体安全性与可靠性。"
  },
  {
    "date": "2026-1-28",
    "title": "FastCoder: Accelerating Repository-level Code Generation via Efficient Retrieval and Verification",
    "authors": "Qianhui Zhao, Li Zhang, Fang Liu, Xiaoli Lian, Qiaoyuanhe Meng, Ziqian Jiao, Zetong Zhou, Jia Li, Lin Shi",
    "publish": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "url": "https://doi.org/10.1109/ase63991.2025.00190",
    "source": "IEEE",
    "abstract": "Code generation is a latency-sensitive task that demands high timeliness. However, with the growing interest and inherent difficulty in repository-level code generation, most existing code generation studies focus on improving the correctness of generated code while overlooking the inference efficiency, which is substantially affected by the overhead during LLM generation. Although there has been work on accelerating LLM inference, these approaches are not tailored to the specific characteristics of code generation; instead, they treat code the same as natural language sequences and ignore its unique syntax and semantic characteristics, which are also crucial for improving efficiency. Consequently, these approaches exhibit limited effectiveness in code generation tasks, particularly for repository-level scenarios with considerable complexity and difficulty. To alleviate this issue, following draft-verification paradigm, we propose FastCoder, a simple yet highly efficient inference acceleration approach specifically designed for code generation, without compromising the quality of the output. FastCoder constructs a multi-source datastore, providing access to both general and project-specific knowledge, facilitating the retrieval of high-quality draft sequences. Moreover, FastCoder reduces the retrieval cost by controlling retrieval timing, and enhances efficiency through parallel retrieval and a context- and LLM preference-aware cache. Experimental results show that FastCoder can reach up to 2.53× and 2.54× speedup compared to autoregressive decoding in repository-level and standalone code generation tasks, respectively, outperforming state-of-the-art inference acceleration approaches by up to 88%. FastCoder can also be integrated with existing correctness-focused code generation approaches to accelerate the LLM generation process, and reach a speedup exceeding 2.6×.",
    "title_zh": "FastCoder：通过高效检索与验证加速仓库级代码生成",
    "abstract_zh": "代码生成是一项对延迟敏感的任务，要求具备高度的实时性。然而，随着对仓库级代码生成兴趣的增加以及其固有的复杂性，现有大多数代码生成研究主要关注提升生成代码的正确性，而忽视了推理效率，而推理效率在很大程度上受到大语言模型（LLM）生成过程开销的影响。尽管已有工作致力于加速LLM推理，但这些方法并未针对代码生成的独特特性进行优化；相反，它们将代码视为与自然语言序列相同的数据，忽略了代码特有的语法和语义特征，而这些特征对于提升生成效率同样至关重要。因此，这些方法在代码生成任务中表现有限，尤其是在复杂度较高的仓库级场景下。为缓解这一问题，我们基于“草稿-验证”范式，提出FastCoder——一种专为代码生成设计的简单但高效且不牺牲输出质量的推理加速方法。FastCoder构建了一个多源数据存储系统，能够访问通用知识和项目特定知识，从而支持高质量草稿序列的检索。此外，FastCoder通过控制检索时机来降低检索成本，并借助并行检索以及上下文和LLM偏好感知的缓存机制进一步提升效率。实验结果表明，在仓库级和独立代码生成任务中，FastCoder相较于自回归解码分别实现了最高2.53倍和2.54倍的加速比，相比当前最先进的推理加速方法性能提升高达88%。FastCoder还可与现有的以正确性为导向的代码生成方法无缝集成，显著加速LLM生成过程，实现超过2.6倍的加速效果。"
  }
]