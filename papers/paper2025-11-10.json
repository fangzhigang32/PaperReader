[
  {
    "date": "2025-11-10",
    "title": "Chatbot Framework for Power Quality Measurement Data and Documentation Using LLM and RAG",
    "authors": "Aadharsh Aadhithya A, Surya Santoso",
    "publish": "2025 IEEE Power &amp;amp; Energy Society General Meeting (PESGM)",
    "url": "https://doi.org/10.1109/pesgm52009.2025.11225681",
    "source": "IEEE",
    "abstract": "Analyzing three-phase voltage and current waveforms to identify the root causes of power quality disturbances is a complex task. It requires expert knowledge and often involves referencing external resources. Recent advances in large language models (LLMs) and retrieval-augmented generation (RAG) offer a promising solution for enhancing this process. This paper proposes and implements a framework for developing a domain-specific chatbot enabled by LLMs and RAG models to analyze power quality disturbance waveforms. The experimental bot, demonstrated and tailored for incipient cable faults, can detect and analyze fault events while facilitating user interaction with datasets and discussions on user-specified documentation. This proof-of-concept framework can be generalized to other power quality disturbance data and documentation, paving the way for more efficient and enhanced analysis of power quality disturbances."
  },
  {
    "date": "2025-11-10",
    "title": "LLM-Based Data Augmentation Method in Reinforcement Learning With Machine-Unlearning and Fine-Tuning",
    "authors": "Yunjiao Lei, Dayong Ye, Tianqing Zhu, Wanlei Zhou, Philip S. Yu.",
    "publish": "IEEE Transactions on Big Data",
    "url": "https://doi.org/10.1109/tbdata.2025.3630807",
    "source": "IEEE",
    "abstract": "Data augmentation in reinforcement learning (RL) aims to generate diverse and extensive datasets to enhance the learning process. Most existing studies on RL augmentation employ sample-based approaches that modify existing samples. However, many of these methods directly adopt augmentation strategies from other domains, which may present limitations when applied to RL. For instance, approaches derived from computer vision techniques are often not well-suited for general RL applications that do not involve visual inputs. Moreover, such sample-based methods frequently overlook the broader characteristics of the training environment, rendering the augmented data potentially less effective in complex scenarios, such as intelligent transportation systems. In addition, these methods can introduce significant risks to critical and sensitive data. For example, introducing noise to samples as a method of augmentation can precipitate adversarial attacks. Thus, a reliable and stable method of augmentation is necessary. To address these concerns, we propose a novel large language model (LLM)-based augmentation strategy in RL with machine unlearning and fine-tuning. This method utilizes LLMs for data augmentation, ensuring the reliability of the augmented data by tailoring it to specific environmental contexts. Additionally, it enhances the quality of augmentation by mitigating the impact on critical samples through the proposed novel machine unlearning method, while simultaneously fine-tuning the model to improve overall performance. Our experimental results indicate that this innovative approach significantly surpasses traditional augmentation methods in learning performance. By mitigating the impact on critical samples, our strategy not only generates more reliable augmented data but also enhances the effectiveness of RL models."
  }
]