[
  {
    "date": "2026-01-22",
    "title": "Co-Constructing Alignment: A Participatory Approach to Situate AI Values",
    "authors": "Anne Arzberger, Enrico Liscio, Maria Luce Lupetti, Inigo Martinez de Rituerto de Troya, Jie Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15895v1",
    "source": "arXiv",
    "abstract": "As AI systems become embedded in everyday practice, value misalignment has emerged as a pressing concern. Yet, dominant alignment approaches remain model centric, treating users as passive recipients of prespecified values rather than as epistemic agents who encounter and respond to misalignment during interactions. Drawing on situated perspectives, we frame alignment as an interactional practice co-constructed during human AI interaction. We investigate how users understand and wish to contribute to this process through a participatory workshop that combines misalignment diaries with generative design activities. We surface how misalignments materialise in practice and how users envision acting on them, grounded in the context of researchers using Large Language Models as research assistants. Our findings show that misalignments are experienced less as abstract ethical violations than as unexpected responses, and task or social breakdowns. Participants articulated roles ranging from adjusting and interpreting model behaviour to deliberate non-engagement as an alignment strategy. We conclude with implications for designing systems that support alignment as an ongoing, situated, and shared practice.",
    "title_zh": "共同建构一致性：一种参与式方法以定位人工智能的价值",
    "abstract_zh": "随着人工智能系统日益融入日常实践，价值错位问题已成为一个紧迫的关切。然而，当前主流的对齐方法仍以模型为中心，将用户视为被动接受预设价值观的个体，而非在互动过程中主动察觉并回应错位的认知主体。基于情境化视角，我们将对齐视为人类与AI互动过程中共同建构的一种交互实践。通过结合错位日记与生成性设计活动的参与式工作坊，我们探究了用户如何理解这一过程，并希望如何参与其中。研究揭示了错位在实际使用中的具体表现形式，以及用户设想如何应对这些错位，其背景是研究人员将大型语言模型用作科研助手的情境。研究发现，错位更多被体验为意外的响应、任务失败或社交失序，而非抽象的伦理违规。参与者提出了多种角色定位，包括调整和解释模型行为，甚至有意选择不参与作为对齐策略。最后，我们提出相关启示：未来系统设计应支持对齐作为一个持续发生、情境化且共享的实践过程。"
  },
  {
    "date": "2026-01-22",
    "title": "Towards Automated Kernel Generation in the Era of LLMs",
    "authors": "Yang Yu, Peiyu Zang, Chi Hsu Tsai, Haiming Wu, Yixin Shen, Jialing Zhang, Haoyu Wang, Zhiyou Xiao, Jingze Shi, Yuyu Luo, Wentao Zhang, Chunlei Men, Guang Liu, Yonghua Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15727v1",
    "source": "arXiv",
    "abstract": "The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.",
    "title_zh": "大模型时代下的自动化内核生成",
    "abstract_zh": "现代人工智能系统的表现从根本上受限于其底层内核的质量，这些内核负责将高层算法语义转化为低层硬件操作。实现接近最优的内核需要对硬件架构和编程模型具备专家级的理解，因此内核工程虽至关重要，却历来耗时且难以扩展。近年来，大型语言模型（LLMs）及其基于代理的系统取得了显著进展，为自动化内核生成与优化开辟了新路径。LLMs擅长压缩那些难以形式化的专家级内核知识，而基于代理的系统则通过将内核开发视为一个迭代、反馈驱动的循环，进一步实现了可扩展的优化。该领域已取得快速进展。然而，当前研究仍较为分散，缺乏对 LLM 驱动内核生成的系统性视角。本文综述旨在填补这一空白，系统梳理现有方法，涵盖基于 LLM 的技术方案与代理式优化工作流，并全面整理支撑该领域学习与评估的数据集与基准测试。此外，本文还深入探讨了关键的开放挑战与未来研究方向，旨在为下一代自动化内核优化提供一份全面的参考指南。为持续追踪该领域的最新动态，我们维护了一个开源 GitHub 仓库：https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation。"
  },
  {
    "date": "2026-01-22",
    "title": "FARM: Field-Aware Resolution Model for Intelligent Trigger-Action Automation",
    "authors": "Khusrav Badalov, Young Yoon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15687v1",
    "source": "arXiv",
    "abstract": "Trigger-Action Programming (TAP) platforms such as IFTTT and Zapier enable Web of Things (WoT) automation by composing event-driven rules across heterogeneous services. A TAP applet links a trigger to an action and must bind trigger outputs (ingredients) to action inputs (fields) to be executable. Prior work largely treats TAP as service-level prediction from natural language, which often yields non-executable applets that still require manual configuration. We study the function-level configuration problem: generating complete applets with correct ingredient-to-field bindings. We propose FARM (Field-Aware Resolution Model), a two-stage architecture for automated applet generation with full configuration. Stage 1 trains contrastive dual encoders with selective layer freezing over schema-enriched representations, retrieving candidates from 1,724 trigger functions and 1,287 action functions (2.2M possible trigger-action pairs). Stage 2 performs selection and configuration using an LLM-based multi-agent pipeline. It includes intent analysis, trigger selection, action selection via cross-schema scoring, and configuration verification. Agents coordinate through shared state and agreement-based selection. FARM achieves 81% joint accuracy on Gold (62% Noisy, 70% One-shot) at the function level, where both trigger and action functions must match the ground truth. For comparison with service-level baselines, we map functions to their parent services and evaluate at the service level. FARM reaches 81% joint accuracy and improves over TARGE by 23 percentage points. FARM also generates ingredient-to-field bindings, producing executable automation configurations.",
    "title_zh": "FARM：面向场景的智能触发-动作自动化解析模型",
    "abstract_zh": "触发-动作编程（TAP）平台如IFTTT和Zapier通过在异构服务间组合事件驱动规则，实现了物联网（WoT）的自动化。一个TAP应用（applet）将触发器与动作关联起来，必须将触发器的输出（原料）正确绑定到动作的输入（字段），才能被执行。以往的研究大多将TAP视为从自然语言进行服务级预测，这常常导致生成非可执行的应用，仍需人工配置。本文研究的是函数级配置问题：生成具备正确“原料-字段”绑定的完整可执行应用。\n\n我们提出了FARM（Field-Aware Resolution Model），一种两阶段架构，用于实现全自动、全配置的应用生成。第一阶段采用对比双编码器结构，并在基于模式增强的表示上实施选择性层冻结，从1,724个触发函数和1,287个动作函数中检索候选组合（共220万个可能的触发-动作配对）。第二阶段通过基于大语言模型（LLM）的多智能体流水线完成选择与配置，包括意图分析、触发器选择、基于跨模式评分的动作选择，以及配置验证。各智能体通过共享状态和基于共识的选择机制进行协同。\n\nFARM在函数级别达到81%的联合准确率（Gold数据集为62%，Noisy数据集为70%，One-shot场景为70%），要求触发器和动作函数均与真实目标完全匹配。为与服务级基线方法进行比较，我们将函数映射至其所属的服务，并在服务级别进行评估。FARM在该层级也达到了81%的联合准确率，相比TARGE基准提升23个百分点。此外，FARM还能生成正确的“原料-字段”绑定，从而输出可直接执行的自动化配置。"
  },
  {
    "date": "2026-01-22",
    "title": "Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow",
    "authors": "Yangyang Zhong, Yanmei Gu, Zhengqing Zang, Xiaomeng Li, Yuqi Ding, Xibei Jia, Yuting Shen, Zhenzhong Lan, Liwang Zhu, Weiping Liu, Junlin Zhou, Haisheng Liu, Zhong Xin Yu, Pengxin Luo, Donglian Qi, Yunfeng Yan, Junbo Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15593v1",
    "source": "arXiv",
    "abstract": "Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100B parameters) on 58 benchmarks spanning knowledge, reasoning, and programming. The results show that MDLMs still lag behind comparably sized autoregressive models, mainly because parallel probabilistic modeling weakens inter-token dependencies. Meanwhile, MDLMs exhibit adaptive decoding behavior: their parallelism and generation order vary significantly with the task domain, the stage of reasoning, and whether the output is correct. On tasks that require \"backward information\" (e.g., Sudoku), MDLMs adopt a solution order that tends to fill easier Sudoku blanks first, highlighting their advantages. Finally, we provide theoretical motivation and design insights supporting a Generate-then-Edit paradigm, which mitigates dependency loss while retaining the efficiency of parallel decoding.",
    "title_zh": "掩码扩散语言模型中的并行性与生成顺序：今日的局限，明日的潜力",
    "abstract_zh": "掩码扩散语言模型（MDLMs）承诺实现并行标记生成和任意顺序解码，然而目前尚不清楚现有模型在多大程度上真正实现了这些能力。我们通过平均完成并行度（AFP）和肯德尔tau相关系数，从两个维度——并行强度与生成顺序——对MDLM的行为进行了刻画。我们在涵盖知识、推理和编程等领域的58个基准测试中评估了八种主流MDLMs（参数规模达100B）。结果表明，MDLMs相较于同等规模的自回归模型仍有差距，主要原因在于并行概率建模削弱了标记间的依赖关系。与此同时，MDLMs表现出自适应解码行为：其并行性与生成顺序会显著随任务领域、推理阶段以及输出是否正确而变化。在需要“向后信息”（如数独）的任务中，MDLMs倾向于优先填充较简单的空格，凸显了其优势。最后，我们提供了理论依据和设计洞见，支持一种“先生成再编辑”的范式，该范式在保留并行解码效率的同时，有效缓解了依赖关系丢失的问题。"
  },
  {
    "date": "2026-01-22",
    "title": "YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models",
    "authors": "Junyu Lin, Meizhen Liu, Xiufeng Huang, Jinfeng Li, Haiwen Hong, Xiaohan Yuan, Yuefeng Chen, Longtao Huang, Hui Xue, Ranjie Duan, Zhikai Chen, Yuchuan Fu, Defeng Li, Lingyao Gao, Yitong Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15588v1",
    "source": "arXiv",
    "abstract": "As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or post-hoc rules, resulting in limited transparency, inflexible policies, or prohibitive inference costs. To this end, we present YuFeng-XGuard, a reasoning-centric guardrail model family designed to perform multi-dimensional risk perception for LLM interactions. Instead of producing opaque binary judgments, YuFeng-XGuard generates structured risk predictions, including explicit risk categories and configurable confidence scores, accompanied by natural language explanations that expose the underlying reasoning process. This formulation enables safety decisions that are both actionable and interpretable. To balance decision latency and explanatory depth, we adopt a tiered inference paradigm that performs an initial risk decision based on the first decoded token, while preserving ondemand explanatory reasoning when required. In addition, we introduce a dynamic policy mechanism that decouples risk perception from policy enforcement, allowing safety policies to be adjusted without model retraining. Extensive experiments on a diverse set of public safety benchmarks demonstrate that YuFeng-XGuard achieves stateof-the-art performance while maintaining strong efficiency-efficacy trade-offs. We release YuFeng-XGuard as an open model family, including both a full-capacity variant and a lightweight version, to support a wide range of deployment scenarios.",
    "title_zh": "YuFeng-XGuard：一种以推理为核心、可解释且灵活的大型语言模型防护模型",
    "abstract_zh": "随着大型语言模型（LLMs）在现实应用中日益普及，安全防护机制需要超越粗粒度的过滤方式，实现细粒度、可解释且可适应的风险评估。然而，现有方案通常依赖快速分类机制或事后规则，导致透明度有限、策略僵化或推理成本过高。为此，我们提出 YuFeng-XGuard——一个以推理为核心的防护模型系列，旨在对大语言模型交互进行多维度风险感知。与生成模糊二元判断不同，YuFeng-XGuard 会输出结构化的风险预测，包括明确的风险类别、可配置的置信度分数，并附带自然语言解释，揭示其背后的推理过程。这种设计使得安全决策既具备可操作性，又具有高度可解释性。为平衡决策延迟与解释深度，我们采用分层推理范式：基于首个解码 token 进行初步风险判断，同时在需要时按需提供深入的解释性推理。此外，我们引入动态策略机制，将风险感知与策略执行解耦，使安全策略可在不重新训练模型的前提下灵活调整。在多个公开的安全基准测试上的大量实验表明，YuFeng-XGuard 在保持高效-有效权衡的同时，达到了当前最先进的性能水平。我们已将 YuFeng-XGuard 作为开源模型系列发布，包含全容量版本和轻量级版本，以支持多样化的部署场景。"
  },
  {
    "date": "2026-01-22",
    "title": "LLM-in-Sandbox Elicits General Agentic Intelligence",
    "authors": "Daixuan Cheng, Shaohan Huang, Yuxian Gu, Huatong Song, Guoxin Chen, Li Dong, Wayne Xin Zhao, Ji-Rong Wen, Furu Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.16206v1",
    "source": "arXiv",
    "abstract": "We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.",
    "title_zh": "沙盒中的大语言模型激发通用代理智能",
    "abstract_zh": "我们提出了 LLM-in-Sandbox，使大型语言模型（LLM）能够在代码沙箱（即虚拟计算机）中进行探索，从而在非代码领域激发通用智能。我们首先证明，无需额外训练，强大的 LLM 已具备利用代码沙箱完成非代码任务的泛化能力。例如，LLM 能自发地访问外部资源以获取新知识，利用文件系统处理长上下文，并执行脚本以满足格式要求。此外，我们进一步展示了通过 LLM-in-Sandbox 强化学习（LLM-in-Sandbox-RL）可以增强这些代理式能力，该方法仅使用非代理数据来训练模型，使其更好地探索沙箱环境。实验表明，无论是在无需训练还是经过后训练的设置下，LLM-in-Sandbox 均展现出在数学、物理、化学、生物医学、长上下文理解以及指令遵循等多个领域的稳健泛化能力。最后，我们从计算和系统两个角度分析了 LLM-in-Sandbox 的效率，并将其开源为一个 Python 包，以促进其在现实场景中的部署应用。"
  },
  {
    "date": "2026-01-22",
    "title": "FlexLLM: Composable HLS Library for Flexible Hybrid LLM Accelerator Design",
    "authors": "Jiahao Zhang, Zifan He, Nicholas Fraser, Michaela Blott, Yizhou Sun, Jason Cong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15710v1",
    "source": "arXiv",
    "abstract": "We present FlexLLM, a composable High-Level Synthesis (HLS) library for rapid development of domain-specific LLM accelerators. FlexLLM exposes key architectural degrees of freedom for stage-customized inference, enabling hybrid designs that tailor temporal reuse and spatial dataflow differently for prefill and decode, and provides a comprehensive quantization suite to support accurate low-bit deployment. Using FlexLLM, we build a complete inference system for the Llama-3.2 1B model in under two months with only 1K lines of code. The system includes: (1) a stage-customized accelerator with hardware-efficient quantization (12.68 WikiText-2 PPL) surpassing SpinQuant baseline, and (2) a Hierarchical Memory Transformer (HMT) plug-in for efficient long-context processing. On the AMD U280 FPGA at 16nm, the accelerator achieves 1.29$\\times$ end-to-end speedup, 1.64$\\times$ higher decode throughput, and 3.14$\\times$ better energy efficiency than an NVIDIA A100 GPU (7nm) running BF16 inference; projected results on the V80 FPGA at 7nm reach 4.71$\\times$, 6.55$\\times$, and 4.13$\\times$, respectively. In long-context scenarios, integrating the HMT plug-in reduces prefill latency by 23.23$\\times$ and extends the context window by 64$\\times$, delivering 1.10$\\times$/4.86$\\times$ lower end-to-end latency and 5.21$\\times$/6.27$\\times$ higher energy efficiency on the U280/V80 compared to the A100 baseline. FlexLLM thus bridges algorithmic innovation in LLM inference and high-performance accelerators with minimal manual effort.",
    "title_zh": "FlexLLM：用于灵活混合大模型加速器设计的可组合HLS库",
    "abstract_zh": "我们提出 FlexLLM，这是一个用于快速开发特定领域大语言模型（LLM）加速器的可组合式高层次综合（HLS）库。FlexLLM 暴露了关键的架构灵活性，支持针对不同阶段的定制化推理，能够为预填充（prefill）和解码（decode）阶段分别优化时间重用与空间数据流策略，并提供全面的量化工具链，以支持高精度的低比特部署。借助 FlexLLM，我们仅用 1,000 行代码，在不到两个月的时间内构建了一个完整的 Llama-3.2 1B 模型推理系统。该系统包含：(1) 一种阶段定制化的加速器，结合硬件高效的量化技术（在 WikiText-2 上达到 12.68 的 PPL），性能超越 SpinQuant 基线；(2) 一个用于高效长上下文处理的分层内存 Transformer（HMT）插件。在 AMD U280 FPGA（16nm 工艺）上，该加速器实现了 1.29× 的端到端加速比、1.64× 更高的解码吞吐量，以及 3.14× 更优的能效，相比运行 BF16 推理的 NVIDIA A100 GPU（7nm 工艺）表现更佳；在 V80 FPGA（7nm 工艺）上的预测结果进一步提升至 4.71×、6.55× 和 4.13×。在长上下文场景中，集成 HMT 插件后，预填充延迟降低 23.23×，上下文窗口扩展达 64×，在 U280/V80 上分别实现 1.10×/4.86× 的更低端到端延迟，以及 5.21×/6.27× 的更高能效，相较 A100 基线显著领先。因此，FlexLLM 在大语言模型推理的算法创新与高性能加速器之间架起桥梁，仅需极少的人工干预即可实现高效部署。"
  },
  {
    "date": "2026-01-22",
    "title": "Autonomous Business System via Neuro-symbolic AI",
    "authors": "Cecil Pang, Hiroki Sayama",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15599v1",
    "source": "arXiv",
    "abstract": "Current business environments require organizations to continuously reconfigure cross-functional processes, yet enterprise systems are still organized around siloed departments, rigid workflows, and hard-coded automation. Meanwhile large language models (LLMs) excel at interpreting natural language and unstructured data but lack deterministic, verifiable execution of complex business logic. To address this gap, here we introduce AUTOBUS, an Autonomous Business System that integrates LLM-based AI agents, predicate-logic programming, and business-semantics-centric enterprise data into a coherent neuro-symbolic AI architecture for orchestrating end-to-end business initiatives. AUTOBUS models an initiative as a network of tasks with explicit pre/post conditions, required data, evaluation rules, and API-level actions. Enterprise data is organized as a knowledge graph whose entities, relationships, and constraints are translated into logic facts and foundational rules, providing the semantic grounding for task reasoning. Core AI agents synthesize task instructions, enterprise semantics, and available tools into task-specific logic programs, which are executed by a logic engine that enforces constraints, coordinates auxiliary tools, and orchestrate execution of actions and outcomes. Humans define and maintain the semantics, policies and task instructions, curate tools, and supervise high-impact or ambiguous decisions, ensuring accountability and adaptability. We detail the AUTOBUS architecture, the anatomy of the AI agent generated logic programs, and the role of humans and auxiliary tools in the lifecycle of a business initiative.",
    "title_zh": "通过神经符号人工智能实现的自主业务系统",
    "abstract_zh": "当前的商业环境要求组织持续重构跨职能流程，然而企业系统仍围绕孤立的部门、僵化的流程以及硬编码的自动化机制构建。与此同时，大型语言模型（LLM）在理解自然语言和非结构化数据方面表现出色，但在执行复杂业务逻辑时缺乏确定性和可验证性。为弥合这一差距，本文提出AUTOBUS——一种自主式业务系统，该系统将基于大语言模型的AI代理、谓词逻辑编程与以业务语义为核心的企事业数据整合进一个统一的神经符号人工智能架构中，实现对端到端业务举措的协调管理。\n\nAUTOBUS将一项业务倡议建模为一个任务网络，其中每个任务均明确包含前置条件与后置条件、所需数据、评估规则以及API级操作。企业数据被组织成知识图谱，其上的实体、关系与约束被转化为逻辑事实和基础规则，为任务推理提供语义基础。核心AI代理将任务指令、企业语义与可用工具融合，生成特定于任务的逻辑程序，这些程序由逻辑引擎执行，该引擎负责强制实施约束、协调辅助工具，并编排动作与结果的执行。人类负责定义和维护语义、政策及任务指令，筛选并管理工具，监督高影响或模糊决策，从而确保系统的可问责性与适应性。\n\n本文详细阐述了AUTOBUS的架构设计、AI代理生成的逻辑程序的构成要素，以及人类与辅助工具在业务倡议全生命周期中的作用。"
  },
  {
    "date": "2026-01-22",
    "title": "Agentic Confidence Calibration",
    "authors": "Jiaxin Zhang, Caiming Xiong, Chien-Sheng Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15778v1",
    "source": "arXiv",
    "abstract": "AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents.",
    "title_zh": "代理自信校准",
    "abstract_zh": "AI代理正迅速从被动的语言模型演变为能够执行复杂多步骤任务的自主系统。然而，其在失败时的过度自信仍是其在高风险场景中部署的根本障碍。现有的校准方法主要针对静态的单轮输出设计，无法应对代理系统特有的挑战，例如轨迹中误差的累积、外部工具带来的不确定性以及难以察觉的故障模式。为解决这些问题，我们首次提出了“代理置信度校准”这一问题，并提出了一种全新的诊断框架——整体轨迹校准（Holistic Trajectory Calibration, HTC）。HTC 能够从宏观动态到微观稳定性等多个层面，提取代理整个行为轨迹中的丰富过程级特征。依托一个简单且可解释的模型，HTC 在八个基准测试、多种大语言模型及多样化的代理框架中，均显著优于现有强基线，在校准精度和判别能力方面表现卓越。除了性能优势外，HTC 还实现了三大关键进展：它通过揭示失败背后的信号，提供了可解释性；通过无需重新训练即可跨领域应用，具备良好的可迁移性；并通过引入通用代理校准器（General Agent Calibrator, GAC），在域外的 GAIA 基准测试中实现了最低的 ECE（期望校准误差），展现出出色的泛化能力。这些贡献共同建立了一个以过程为中心的新一代置信度校准范式，为诊断和提升AI代理的可靠性提供了一个坚实而全面的框架。"
  },
  {
    "date": "2026-01-22",
    "title": "When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL with Verifiable Rewards",
    "authors": "Mingyuan Fan, Weiguang Han, Daixin Wang, Cen Chen, Zhiqiang Zhang, Jun Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15609v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) is a central paradigm for turning large language models (LLMs) into reliable problem solvers, especially in logic-heavy domains. Despite its empirical success, it remains unclear whether RLVR elicits novel capabilities or merely sharpens the distribution over existing knowledge. We study this by formalizing over-sharpening, a phenomenon where the policy collapses onto limited modes, suppressing valid alternatives. At a high level, we discover finite-batch updates intrinsically bias learning toward sampled modes, triggering a collapse that propagates globally via semantic coupling. To mitigate this, we propose inverse-success advantage calibration to prioritize difficult queries and distribution-level calibration to diversify sampling via a memory network. Empirical evaluations validate that our strategies can effectively improve generalization.",
    "title_zh": "当锐化变为坍塌：强化学习中可验证奖励的采样偏差与语义耦合",
    "abstract_zh": "强化学习与可验证奖励（RLVR）是将大型语言模型（LLMs）转化为可靠问题求解器的核心范式，尤其在逻辑密集型领域表现突出。尽管其在实践中取得了成功，但尚不明确RLVR是否真正激发了新的能力，还是仅仅对已有知识分布进行了精细化调整。为此，我们通过形式化“过度锐化”这一现象展开研究——即策略收敛到有限的模式上，从而抑制了其他有效的备选方案。总体而言，我们发现有限批次的更新会内在地偏向于采样到的模式，进而通过语义耦合引发全局性的坍缩。为缓解此问题，我们提出了反向成功优势校准方法，以优先处理困难查询；同时引入基于记忆网络的分布级校准机制，以增强采样的多样性。实证评估表明，所提策略能够有效提升模型的泛化能力。"
  },
  {
    "date": "2026-01-22",
    "title": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model",
    "authors": "Chenghao Fan, Wen Heng, Bo Li, Sichen Liu, Yuxuan Song, Jing Su, Xiaoye Qu, Kai Shen, Wei Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15892v1",
    "source": "arXiv",
    "abstract": "Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \\~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.",
    "title_zh": "Stable-DiffCoder：推动代码扩散大型语言模型的前沿发展",
    "abstract_zh": "基于扩散的文本模型（DLLMs）相较于自回归（AR）模型，具备非序列化、分块生成以及更丰富的数据复用优势。然而，现有的代码类DLLMs在相同预算下仍落后于强大的AR基线模型。本文在受控实验中重新审视这一问题，并提出Stable-DiffCoder——一种基于Seed-Coder架构、数据集和训练流程的分块扩散式代码生成模型。为实现高效的知识学习与稳定训练，我们引入了一种经过定制优化的分块扩散持续预训练（CPT）阶段，该阶段结合了特定的预热策略与分块裁剪噪声调度机制。在相同的数据与架构条件下，Stable-DiffCoder在广泛的代码基准测试中整体表现优于其对应的AR模型。此外，仅依赖CPT与监督微调两个阶段，Stable-DiffCoder的表现超越了众多约80亿参数规模的AR模型及DLLMs，证明了基于扩散的训练方式能够显著提升代码建模质量，超越单纯依赖自回归训练的效果。同时，基于扩散的任意顺序建模在代码编辑与推理任务中展现出更强的结构化代码理解能力，且通过数据增强进一步提升了低资源编程语言的建模效果。"
  },
  {
    "date": "2026-01-22",
    "title": "ErrorMap and ErrorAtlas: Charting the Failure Landscape of Large Language Models",
    "authors": "Shir Ashury-Tahan, Yifan Mai, Elron Bandel, Michal Shmueli-Scheuer, Leshem Choshen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15812v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLM) benchmarks tell us when models fail, but not why they fail. A wrong answer on a reasoning dataset may stem from formatting issues, calculation errors, or dataset noise rather than weak reasoning. Without disentangling such causes, benchmarks remain incomplete and cannot reliably guide model improvement. We introduce ErrorMap, the first method to chart the sources of LLM failure. It extracts a model's unique \"failure signature\", clarifies what benchmarks measure, and broadens error identification to reduce blind spots. This helps developers debug models, aligns benchmark goals with outcomes, and supports informed model selection. ErrorMap works on any model or dataset with the same logic. Applying our method to 35 datasets and 83 models we generate ErrorAtlas, a taxonomy of model errors, revealing recurring failure patterns. ErrorAtlas highlights error types that are currently underexplored in LLM research, such as omissions of required details in the output and question misinterpretation. By shifting focus from where models succeed to why they fail, ErrorMap and ErrorAtlas enable advanced evaluation - one that exposes hidden weaknesses and directs progress. Unlike success, typically measured by task-level metrics, our approach introduces a deeper evaluation layer that can be applied globally across models and tasks, offering richer insights into model behavior and limitations. We make the taxonomy and code publicly available with plans to periodically update ErrorAtlas as new benchmarks and models emerge.",
    "title_zh": "ErrorMap 与 ErrorAtlas：描绘大型语言模型的失败图谱",
    "abstract_zh": "大型语言模型（LLM）的基准测试告诉我们模型在何时失败，却无法揭示失败的原因。一个在推理数据集上给出错误答案的情况，可能源于格式问题、计算错误或数据集噪声，而非推理能力薄弱。若不将这些因素逐一剥离，基准测试便始终不完整，也无法可靠地指导模型改进。我们提出了ErrorMap——首个能够绘制LLM失败根源的方法。它能提取模型独特的“失败特征”，明确基准测试所衡量的内容，并扩展错误识别范围，减少盲点。这一方法帮助开发者调试模型，使基准目标与实际结果对齐，并支持更明智的模型选择。ErrorMap适用于任何模型和数据集，逻辑一致。我们将该方法应用于35个数据集和83个模型，生成了ErrorAtlas——一份模型错误的分类体系，揭示了反复出现的失败模式。ErrorAtlas突出了当前LLM研究中被忽视的错误类型，例如输出中遗漏必要细节，以及对问题的误解。通过将关注点从“模型在何处成功”转向“为何失败”，ErrorMap与ErrorAtlas实现了更高级别的评估——能够暴露隐藏的弱点，并引导研究进展。与通常以任务级指标衡量成功的传统方式不同，我们的方法引入了一层更深入的评估维度，可在全球范围内应用于各类模型和任务，为理解模型行为与局限性提供更丰富的洞见。我们已将该分类体系及代码公开，并计划随着新基准和新模型的出现，持续更新ErrorAtlas。"
  },
  {
    "date": "2026-01-22",
    "title": "Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification",
    "authors": "Yuxuan Wan, Tianqing Fang, Zaitang Li, Yintong Huo, Wenxuan Wang, Haitao Mi, Dong Yu, Michael R. Lyu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15808v1",
    "source": "arXiv",
    "abstract": "Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.",
    "title_zh": "推理时的验证扩展：通过测试时评分标准引导的验证实现自我演化的深度研究代理",
    "abstract_zh": "深度研究代理（Deep Research Agents, DRAs）的最新进展正在重塑自动化知识发现与问题求解的格局。尽管现有大多数研究集中于通过后训练提升策略能力，我们提出了一种替代范式：通过迭代验证策略模型的输出，并依据精心设计的评分标准，实现对代理能力的自我演化。这一方法催生了推理时的验证扩展机制，即代理通过评估自身生成的答案，获得迭代反馈并持续优化。我们基于自动构建的DRA失败分类体系来制定评分标准，该体系系统性地将代理失败划分为五大类别和十三个子类别。我们提出了DeepVerifier——一种基于评分标准的成果奖励验证器，利用验证过程中的不对称性，在元评估F1分数上比原始的“代理作为裁判”和LLM裁判基线方法提升了12%-48%。为支持实际的自我演化，DeepVerifier以即插即用模块的形式集成于测试阶段的推理流程中，能够生成详细的、基于评分标准的反馈，并将其回传给代理，实现无需额外训练的迭代自举与响应优化。这种推理时的扩展机制在使用高性能闭源大模型时，使GAIA和XBench-DeepResearch中具有挑战性的子集上的准确率提升了8%-11%。最后，为推动开源生态的发展，我们发布了DeepVerifier-4K——一个经过筛选的监督微调数据集，包含4,646个高质量的代理步骤，专注于DRA验证任务。这些示例强调反思与自我批判，使开源模型能够发展出稳健的验证能力。"
  },
  {
    "date": "2026-01-22",
    "title": "Next Generation Active Learning: Mixture of LLMs in the Loop",
    "authors": "Yuanyuan Qi, Xiaohao Yang, Jueqing Lu, Guoxiang Guo, Joanne Enticott, Gang Liu, Lan Du",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15773v1",
    "source": "arXiv",
    "abstract": "With the rapid advancement and strong generalization capabilities of large language models (LLMs), they have been increasingly incorporated into the active learning pipelines as annotators to reduce annotation costs. However, considering the annotation quality, labels generated by LLMs often fall short of real-world applicability. To address this, we propose a novel active learning framework, Mixture of LLMs in the Loop Active Learning, replacing human annotators with labels generated through a Mixture-of-LLMs-based annotation model, aimed at enhancing LLM-based annotation robustness by aggregating the strengths of multiple LLMs. To further mitigate the impact of the noisy labels, we introduce annotation discrepancy and negative learning to identify the unreliable annotations and enhance learning effectiveness. Extensive experiments demonstrate that our framework achieves performance comparable to human annotation and consistently outperforms single-LLM baselines and other LLM-ensemble-based approaches. Moreover, our framework is built on lightweight LLMs, enabling it to operate fully on local machines in real-world applications.",
    "title_zh": "下一代主动学习：大语言模型混合体在循环中",
    "abstract_zh": "随着大型语言模型（LLMs）的快速发展及其强大的泛化能力，它们正被越来越多地引入主动学习流程中作为标注工具，以降低标注成本。然而，考虑到标注质量，LLMs生成的标签往往难以满足实际应用需求。为解决这一问题，我们提出了一种新颖的主动学习框架——“基于LLM混合体的闭环主动学习”（Mixture of LLMs in the Loop Active Learning），该框架用基于多LLM混合的标注模型生成的标签替代人工标注，通过融合多个LLM的优势来提升基于LLM标注的鲁棒性。为进一步缓解噪声标签的影响，我们引入了标注差异检测与负向学习机制，用于识别不可靠的标注并增强模型的学习效率。大量实验表明，我们的框架在性能上可媲美人工标注，并持续优于单一LLM基线方法及其他基于LLM集成的方法。此外，本框架基于轻量级LLM构建，能够在真实应用场景中完全部署于本地设备上运行。"
  },
  {
    "date": "2026-01-22",
    "title": "LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling",
    "authors": "Junhao Qiu, Haoyang Zhuang, Fei Liu, Jianjun Liu, Qingfu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15738v1",
    "source": "arXiv",
    "abstract": "Dynamic multi-product delivery environments demand rapid coordination of part completion and product-level kitting within hybrid processing and assembly systems to satisfy strict hierarchical supply constraints. The flexible assembly flow shop scheduling problem formally defines dependencies for multi-stage kitting, yet dynamic variants make designing integrated scheduling rules under multi-level time coupling highly challenging. Existing automated heuristic design methods, particularly genetic programming constrained to fixed terminal symbol sets, struggle to capture and leverage dynamic uncertainties and hierarchical dependency information under transient decision states. This study develops an LLM-assisted Dynamic Rule Design framework (LLM4DRD) that automatically evolves integrated online scheduling rules adapted to scheduling features. Firstly, multi-stage processing and assembly supply decisions are transformed into feasible directed edge orderings based on heterogeneous graph. Then, an elite knowledge guided initialization embeds advanced design expertise into initial rules to enhance initial quality. Additionally, a dual-expert mechanism is introduced in which LLM-A evolutionary code to generate candidate rules and LLM-S conducts scheduling evaluation, while dynamic feature-fitting rule evolution combined with hybrid evaluation enables continuous improvement and extracts adaptive rules with strong generalization capability. A series of experiments are conducted to validate the effectiveness of the method. The average tardiness of LLM4DRD is 3.17-12.39% higher than state-of-the-art methods in 20 practical instances used for training and testing, respectively. In 24 scenarios with different resource configurations, order loads, and disturbance levels totaling 480 instances, it achieves 11.10% higher performance than the second best competitor, exhibiting excellent robustness.",
    "title_zh": "基于大语言模型的动态柔性装配流水线调度自动派工规则设计",
    "abstract_zh": "动态多产品配送环境要求在混合加工与装配系统中快速协调零部件完成与产品级配套组装，以满足严格的层级供应约束。尽管柔性装配流水线调度问题已对多阶段配套流程中的依赖关系进行了形式化定义，但其动态变体使得在多层次时间耦合条件下设计集成调度规则极具挑战性。现有的自动化启发式设计方法，尤其是受限于固定终结符集合的遗传编程，难以在瞬时决策状态下捕捉并利用动态不确定性及层级依赖信息。本研究提出一种基于大语言模型的动态规则设计框架（LLM4DRD），可自动演化出适应调度特征的集成在线调度规则。首先，将多阶段加工与装配供应决策转化为基于异构图的可行有向边排序；其次，引入精英知识引导的初始化机制，将先进设计经验嵌入初始规则，以提升初始质量；此外，提出双专家机制：LLM-A负责生成候选规则的进化代码，LLM-S则执行调度评估，结合动态特征拟合的规则演化与混合评估策略，实现持续优化，并提取具备强泛化能力的自适应规则。通过一系列实验验证了该方法的有效性。在用于训练和测试的20个实际实例中，LLM4DRD的平均延迟比当前最优方法高出3.17%至12.39%；在包含480个实例的24种不同资源配置、订单负载及扰动水平的场景下，其性能优于第二佳竞争者11.10%，展现出优异的鲁棒性。"
  },
  {
    "date": "2026-01-22",
    "title": "Learning to Discover at Test Time",
    "authors": "Mert Yuksekgonul, Daniel Koceja, Xinhao Li, Federico Bianchi, Jed McCaleb, Xiaolong Wang, Jan Kautz, Yejin Choi, James Zou, Carlos Guestrin, Yu Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.16175v1",
    "source": "arXiv",
    "abstract": "How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.",
    "title_zh": "在测试时学会发现",
    "abstract_zh": "我们如何利用人工智能来发现科学问题的新前沿？以往在测试时扩展（test-time scaling）方面的研究，如 AlphaEvolve，通过提示一个冻结的大型语言模型（LLM）来进行搜索。而我们则在测试时进行强化学习，使 LLM 能够持续训练，但此时的训练经验是针对具体测试问题量身定制的。这种持续学习形式非常特殊，因为其目标不是平均产生多个优秀解，而是专注于找到一个极为出色的解决方案；它解决的是特定问题本身，而非泛化到其他问题。因此，我们的学习目标和搜索子程序被设计为优先关注最有希望的解。我们将这种方法称为“测试时训练以发现”（Test-Time Training to Discover, TTT-Discover）。\n\n沿用先前的研究范式，我们聚焦于具有连续奖励的问题。我们在数学、GPU 内核工程、算法设计以及生物学等多个领域中尝试了各种问题，并报告了所有实验的结果。TTT-Discover 在几乎所有问题上都达到了新的最先进水平：  \n(i) 埃尔德什最小重叠问题与一个自相关不等式；  \n(ii) GPU 模式内核竞赛（速度比之前最佳方案快达 2 倍）；  \n(iii) 过去 AtCoder 算法竞赛中的难题；  \n(iv) 单细胞分析中的去噪问题。\n\n我们的解决方案已由领域专家或赛事组织方评审确认。所有结果均使用开源模型 OpenAI gpt-oss-120b 完成，且可通过我们公开发布的代码复现。这与以往需要依赖封闭前沿模型才能取得的最佳成果形成鲜明对比。我们的测试时训练运行基于 Thinking Machines 公司开发的 Tinker API 实现，每项问题的花费仅需几百美元。"
  },
  {
    "date": "2026-01-22",
    "title": "Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs",
    "authors": "Ryoma Sato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15714v1",
    "source": "arXiv",
    "abstract": "We propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.",
    "title_zh": "连GPT-5.2都数不到五：可信大语言模型中零错误边界的必要性",
    "abstract_zh": "我们提出了零错误范围（Zero-Error Horizon, ZEH），用于构建值得信赖的大语言模型（LLM）。ZEH代表模型在不出现任何错误的情况下能够解决的最大问题范围。尽管ZEH本身概念简单，但我们发现对当前最先进的大语言模型进行ZEH评估，能揭示大量深刻见解。例如，通过对GPT-5.2的ZEH进行评估，我们发现它甚至无法计算一个如“11000”这样的短字符串的奇偶性，也无法判断“((((()))))”中的括号是否平衡。这一结果令人震惊，因为GPT-5.2在其他任务上表现出色。然而，大语言模型在如此基础的问题上仍会出错，这为将其应用于安全关键领域时敲响了警钟。通过对Qwen2.5应用ZEH并进行深入分析，我们发现虽然ZEH与整体准确率存在相关性，但具体行为模式却有显著差异，且ZEH为算法能力的涌现提供了重要线索。最后，尽管计算ZEH需要巨大的计算开销，但我们探讨了通过采用树状结构和在线Softmax方法，可实现高达一个数量级的速度提升，从而有效缓解这一问题。"
  },
  {
    "date": "2026-01-22",
    "title": "Benchmarking Text-to-Python against Text-to-SQL: The Impact of Explicit Logic and Ambiguity",
    "authors": "Hangle Hu, Chenyu Hou, Bin Cao, Ruizhe Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15728v1",
    "source": "arXiv",
    "abstract": "While Text-to-SQL remains the dominant approach for database interaction, real-world analytics increasingly require the flexibility of general-purpose programming languages such as Python or Pandas to manage file-based data and complex analytical workflows. Despite this growing need, the reliability of Text-to-Python in core data retrieval remains underexplored relative to the mature SQL ecosystem. To address this gap, we introduce BIRD-Python, a benchmark designed for cross-paradigm evaluation. We systematically refined the original dataset to reduce annotation noise and align execution semantics, thereby establishing a consistent and standardized baseline for comparison. Our analysis reveals a fundamental paradigmatic divergence: whereas SQL leverages implicit DBMS behaviors through its declarative structure, Python requires explicit procedural logic, making it highly sensitive to underspecified user intent. To mitigate this challenge, we propose the Logic Completion Framework (LCF), which resolves ambiguity by incorporating latent domain knowledge into the generation process. Experimental results show that (1) performance differences primarily stem from missing domain context rather than inherent limitations in code generation, and (2) when these gaps are addressed, Text-to-Python achieves performance parity with Text-to-SQL. These findings establish Python as a viable foundation for analytical agents-provided that systems effectively ground ambiguous natural language inputs in executable logical specifications. Resources are available at https://anonymous.4open.science/r/Bird-Python-43B7/.",
    "title_zh": "文本到Python与文本到SQL的基准对比：显式逻辑与模糊性的影响",
    "abstract_zh": "尽管文本到SQL仍是数据库交互的主流方法，但现实世界中的数据分析日益需要通用编程语言（如Python或Pandas）所具备的灵活性，以处理基于文件的数据和复杂的分析工作流。然而，尽管这一需求不断增长，文本转Python在核心数据检索任务中的可靠性研究仍远落后于成熟的SQL生态系统。为填补这一空白，我们提出了BIRD-Python，一个用于跨范式评估的基准测试。我们系统性地优化了原始数据集，减少了注释噪声并统一了执行语义，从而建立了一个一致且标准化的比较基准。我们的分析揭示了一个根本性的范式差异：SQL通过其声明式结构利用数据库管理系统（DBMS）的隐式行为，而Python则要求显式的程序逻辑，因此对用户意图的不完整描述极为敏感。为应对这一挑战，我们提出了一种逻辑补全框架（Logic Completion Framework, LCF），通过将潜在的领域知识融入生成过程来消除歧义。实验结果表明：（1）性能差异主要源于缺失的领域上下文，而非代码生成能力本身的局限；（2）当这些上下文缺口得到弥补后，文本转Python的性能可与文本转SQL达到相当水平。这些发现表明，只要系统能够有效地将模糊的自然语言输入转化为可执行的逻辑规范，Python便可以成为分析型智能体的可行基础。相关资源可在 https://anonymous.4open.science/r/Bird-Python-43B7/ 获取。"
  },
  {
    "date": "2026-01-22",
    "title": "Low-altitude Multi-UAV-assisted Data Collection and Semantic Forwarding for Post-Disaster Relief",
    "authors": "Xiaoya Zheng, Geng Sun, Jiahui Li, Jiacheng Wang, Weijie Yuan, Qingqing Wu, Dusit Niyato, Abbas Jamalipour",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.16146v1",
    "source": "arXiv",
    "abstract": "The low-altitude economy (LAE) is an emerging economic paradigm which fosters integrated development across multiple fields. As a pivotal component of the LAE, low-altitude uncrewed aerial vehicles (UAVs) can restore communication by serving as aerial relays between the post-disaster areas and remote base stations (BSs). However, conventional approaches face challenges from vulnerable long-distance links between the UAVs and remote BSs, and data bottlenecks arising from massive data volumes and limited onboard UAV resources. In this work, we investigate a low-altitude multi-UAV-assisted data collection and semantic forwarding network, in which multiple UAVs collect data from ground users, form clusters, perform intra-cluster data aggregation with semantic extraction, and then cooperate as virtual antenna array (VAAs) to transmit the extracted semantic information to a remote BS via collaborative beamforming (CB). We formulate a data collection and semantic forwarding multi-objective optimization problem (DCSFMOP) that jointly maximizes both the user and semantic transmission rates while minimizing UAV energy consumption. The formulated DCSFMOP is a mixed-integer nonlinear programming (MINLP) problem that is inherently NP-hard and characterized by dynamically varying decision variable dimensionality. To address these challenges, we propose a large language model-enabled alternating optimization approach (LLM-AOA), which effectively handles the complex search space and variable dimensionality by optimizing different subsets of decision variables through tailored optimization strategies. Simulation results demonstrate that LLM-AOA outperforms AOA by approximately 26.8\\% and 22.9\\% in transmission rate and semantic rate, respectively.",
    "title_zh": "低空多无人机辅助灾后救援数据采集与语义转发",
    "abstract_zh": "低空经济（LAE）是一种新兴的经济范式，旨在推动多个领域的融合发展。作为LAE的关键组成部分，低空无人飞行器（UAV）可作为灾后区域与远端基站（BS）之间的空中中继，恢复通信链路。然而，传统方法面临UAV与远端基站之间脆弱的长距离通信链路问题，以及海量数据量与UAV有限机载资源导致的数据瓶颈。本文研究了一种低空多UAV辅助的数据采集与语义转发网络：多个UAV从地面用户采集数据，形成集群，在集群内部执行数据聚合与语义提取，并协同构成虚拟天线阵列（VAAs），通过协作波束成形（CB）将提取的语义信息传输至远端基站。我们提出了一个数据采集与语义转发多目标优化问题（DCSFMOP），旨在联合最大化用户传输速率与语义传输速率，同时最小化UAV能耗。该DCSFMOP是一个混合整数非线性规划（MINLP）问题，具有固有的NP难特性，且决策变量维度动态变化。为应对这些挑战，我们提出了一种基于大语言模型的交替优化方法（LLM-AOA），通过针对不同决策变量子集采用定制化的优化策略，有效处理复杂的搜索空间和可变的维度问题。仿真结果表明，与传统AOA相比，LLM-AOA在传输速率和语义速率上分别提升了约26.8%和22.9%。"
  },
  {
    "date": "2026-01-22",
    "title": "Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging",
    "authors": "Alphaeus Dmonte, Vidhi Gupta, Daniel J Perry, Mark Arehart",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.16127v1",
    "source": "arXiv",
    "abstract": "Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.",
    "title_zh": "通过语言特定的模型合并提升训练效率并降低维护成本",
    "abstract_zh": "微调一个特定任务的多语言大型语言模型（LLM）需要在包含所有所需语言示例的多语言数据集上训练该模型。当需要为一个或多个已支持的语言添加额外数据，或新增对一种新语言的支持时，通常需要重新训练整个模型，这不仅计算成本高昂，还带来了严重的维护瓶颈。尽管近期关于合并多语言多任务模型的研究显示出质量提升的潜力，但其在计算效率和维护效率方面的表现仍缺乏研究。在本项工作中，我们首次从效率角度对这种合并策略进行了深入分析，并在三个独立任务上进行了评估。结果表明，该方法在保持质量相当的前提下实现了显著的效率提升：初始训练时间最多可减少50%。此外，我们还证明，通过仅更新某一语言并重新合并的方式进行模型维护，相比重新训练整个多语言模型，可将训练成本降低超过60%。这一成果在公开数据集和专有行业数据集上均得到验证，证实该方法不仅适用于学术研究场景，也具备良好的工业应用前景。"
  },
  {
    "date": "2026-01-22",
    "title": "Prioritizing Configuration Relevance via Compiler-Based Refined Feature Ranking",
    "authors": "Federico Bruzzone, Walter Cazzola, Luca Favini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.16008v1",
    "source": "arXiv",
    "abstract": "Modern programming languages, most notably Rust, offer advanced linguistic constructs for building highly configurable software systems as aggregation of features -- identified by a configuration. However, they pose substantial challenges for program analysis, optimization, and testing, as the combinatorial explosion of configurations often makes exhaustive exploration infeasible. In this manuscript, we present the first compiler-based method for prioritizing configurations. Our approach consists of four main steps: 1. extracting a tailored intermediate representation from the Rust compiler, 2. constructing two complementary graph-based data structures, 3. using centrality measures to rank features, and 4. refining the ranking by considering the extent of code they impact. A fixed number of most relevant configurations are generated based on the achieved feature ranking. The validity of the generated configurations is guaranteed by using a SAT solver that takes a representation of this graph in conjunctive normal form. We formalized this approach and implemented it in a prototype, RustyEx, by instrumenting the Rust compiler. An empirical evaluation on higher-ranked open source Rust projects shows that RustyEx efficiently generates user-specified sets of configurations within bounded resources, while ensuring soundness by construction. The results demonstrate that centrality-guided configuration prioritization enables effective and practical exploration of large configuration spaces, paving the way for future research in configuration-aware analysis and optimization.",
    "title_zh": "通过基于编译器的特征精炼排序实现配置相关性的优先级排序",
    "abstract_zh": "现代编程语言，尤其是 Rust，提供了先进的语言构造，可用于构建高度可配置的软件系统——这些系统由一组以配置标识的功能组合而成。然而，这类系统在程序分析、优化和测试方面带来了巨大挑战，因为配置的组合爆炸往往使得全面探索变得不可行。本文提出了一种基于编译器的配置优先级排序方法，这是该领域的首个相关工作。我们的方法包含四个主要步骤：1. 从 Rust 编译器中提取定制化的中间表示；2. 构建两种互补的基于图的数据结构；3. 利用中心性度量对功能进行排序；4. 通过考虑各功能所影响的代码范围来进一步优化排序结果。基于最终的功能排序，生成固定数量的最相关配置。我们使用 SAT 求解器验证所生成配置的有效性，该求解器将图结构表示为合取范式（CNF）形式。我们对该方法进行了形式化，并通过在 Rust 编译器中进行插桩，实现了一个原型系统 RustyEx。对排名靠前的开源 Rust 项目的实证评估表明，RustyEx 能够在有限资源约束下高效生成用户指定的配置集合，且其正确性通过构造过程得到保证。实验结果表明，基于中心性的配置优先级排序能够实现对大规模配置空间的有效且实用的探索，为未来面向配置感知的分析与优化研究奠定了基础。"
  },
  {
    "date": "2026-01-22",
    "title": "Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors",
    "authors": "Zhiwei Zhang, Fei Zhao, Rui Wang, Zezhong Wang, Bin Liang, Jiakang Wang, Yao Hu, Shaosheng Cao, Kam-Fai Wong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15625v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution: following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO, a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator, then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.",
    "title_zh": "通过裂变-GRPO实现鲁棒的工具使用：学习从执行错误中恢复",
    "abstract_zh": "大型语言模型（LLMs）能够有效调用工具，但在多轮执行过程中仍显脆弱：一旦工具调用出错，小型模型往往陷入重复的无效重试，无法理解错误反馈，也无法自我修正。这种脆弱性阻碍了其在真实场景中的可靠部署，因为在与工具交互的过程中，执行错误本就是不可避免的。我们识别出当前方法的一个关键局限：标准强化学习（RL）将错误视为稀疏的负奖励，无法提供具体的恢复指导；而预先收集的合成纠错数据集又存在分布偏差，难以匹配模型在实际运行中产生的错误模式。为弥合这一差距，我们提出 Fission-GRPO 框架，该框架在强化学习训练循环中将执行错误转化为可纠正的监督信号。其核心机制是：通过一个微调过的错误模拟器生成诊断反馈，将每条失败的轨迹“分裂”为新的训练实例，并在策略上重新采样恢复过程的 rollout。这使得模型能够从自身探索过程中产生的精确错误中学习，而非依赖静态、预设的错误案例。在 BFCL v4 多轮任务测试中，Fission-GRPO 将 Qwen3-8B 的错误恢复率提升了 5.7 个百分点，更重要的是，整体准确率相比 GRPO 提升了 4%（从 42.75% 提高到 46.75%），并优于专门设计的工具使用代理。"
  },
  {
    "date": "2026-01-22",
    "title": "Evaluating and Achieving Controllable Code Completion in Code LLM",
    "authors": "Jiajun Zhang, Zeyu Cui, Lei Zhang, Jian Yang, Jiaxi Yang, Qiang Liu, Zilei Wang, Binyuan Hui, Liang Wang, Junyang Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15879v1",
    "source": "arXiv",
    "abstract": "Code completion has become a central task, gaining significant attention with the rise of large language model (LLM)-based tools in software engineering. Although recent advances have greatly improved LLMs' code completion abilities, evaluation methods have not advanced equally. Most current benchmarks focus solely on functional correctness of code completions based on given context, overlooking models' ability to follow user instructions during completion-a common scenario in LLM-assisted programming. To address this limitation, we present the first instruction-guided code completion benchmark, Controllable Code Completion Benchmark (C3-Bench), comprising 2,195 carefully designed completion tasks. Through comprehensive evaluation of over 40 mainstream LLMs across C3-Bench and conventional benchmarks, we reveal substantial gaps in instruction-following capabilities between open-source and advanced proprietary models during code completion tasks. Moreover, we develop a straightforward data synthesis pipeline that leverages Qwen2.5-Coder to generate high-quality instruction-completion pairs for supervised fine-tuning (SFT). The resulting model, Qwen2.5-Coder-C3, achieves state-of-the-art performance on C3-Bench. Our findings provide valuable insights for enhancing LLMs' code completion and instruction-following capabilities, establishing new directions for future research in code LLMs. To facilitate reproducibility and foster further research in code LLMs, we open-source all code, datasets, and models.",
    "title_zh": "评估与实现代码大模型中的可控代码补全",
    "abstract_zh": "代码补全已成为软件工程领域中一个核心任务，随着基于大语言模型（LLM）的工具兴起，其重要性日益凸显。尽管近期进展显著提升了LLM在代码补全方面的能力，但评估方法却未能同步发展。目前大多数基准测试仅关注代码补全结果在给定上下文下的功能正确性，忽略了模型在补全过程中遵循用户指令的能力——而这正是LLM辅助编程中的常见场景。为解决这一局限，我们提出了首个面向指令引导的代码补全基准测试：可控代码补全基准（Controllable Code Completion Benchmark, C3-Bench），包含2,195个精心设计的补全任务。通过对40多个主流LLM在C3-Bench及传统基准上的全面评估，我们揭示了开源模型与先进专有模型在代码补全任务中指令遵循能力之间存在显著差距。此外，我们开发了一种简单高效的数据合成流程，利用Qwen2.5-Coder生成高质量的指令-补全配对数据，用于监督微调（SFT）。由此训练出的模型Qwen2.5-Coder-C3在C3-Bench上取得了当前最佳性能。我们的研究发现为提升LLM的代码补全与指令遵循能力提供了宝贵洞见，并为未来代码类大语言模型的研究指明了新方向。为促进可复现性并推动该领域进一步研究，我们已开源全部代码、数据集和模型。"
  },
  {
    "date": "2026-01-22",
    "title": "Large-scale real-time signal processing in physics experiments: The ALICE TPC FPGA pipeline",
    "authors": "J. Alme, T. Alt, C. Andrei, V. Anguelov, H. Appelshäuser, M. Arslandok, R. Averbeck, M. Ball, G. G. Barnaföldi, P. Becht, R. Bellwied, A. Berdnikova, B. Blidaru, L. Boldizsár, L. Bratrud, P. Braun-Munzinger, M. Bregant, C. L. Britton, H. Büsching, H. Caines, P. Chatzidaki, P. Christiansen, T. M. Cormier, L. Döpper, R. Ehlers, L. Fabbietti, F. Flor, J. J. Gaardhøje, M. G. Munhoz, C. Garabatos, P. Gasik, Á. Gera, P. Glässel, N. Grünwald, T. Gündem, T. Gunji, H. Hamagaki, J. W. Harris, P. Hauer, E. Hellbär, H. Helstrup, A. Herghelegiu, H. D. Hernandez Herrera, Y. Hou, C. Hughes, M. Ivanov, J. Jäger, Y. Ji, J. Jung, M. Jung, B. Ketzer, S. Kirsch, M. Kleiner, A. G. Knospe, M. Korwieser, M. Kowalski, L. Lautner, M. Lesch, C. Lippmann, G. Mantzaridis, R. D. Majka, A. Marin, C. Markert, S. Masciocchi, A. Matyja, M. Meres, D. L. Mihaylov, D. Miśkowiec, R. H. Munzer, H. Murakami, K. Münning, A. Nassirpour, C. Nattrass, B. S. Nielsen, W. A. V. Noije, A. C. Oliveira Da Silva, A. Oskarsson, K. Oyama, L. Österman, Y. Pachmayer, G. Paić, M. Petris, M. Petrovici, M. Planinic, J. Rasson, K. F. Read, A. Rehman, R. Renfordt, A. Riedel, K. Røed, D. Röhrich, E. Rubio, A. Rusu, S. Sadhu, B. C. S. Sanches, J. Schambach, A. Schmah, C. Schmidt, A. Schmier, K. Schweda, D. Sekihata, D. Silvermyr, B. Sitar, N. Smirnov, H. K. Soltveit, C. Sonnabend, S. P. Sorensen, J. Stachel, L. Šerkšnytė, G. Tambave, K. Ullaland, B. Ulukutlu, D. Varga, O. Vazquez Rueda, B. Voss, J. Wiechula, B. Windelband, J. Wilkinson, J. Witte, A. Yadav, F. Zanone, S. Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15868v1",
    "source": "arXiv",
    "abstract": "For LHC Run 3, the ALICE Time Projection Chamber was upgraded to operate in continuous readout mode. Interaction rates of up to 50 kHz in Pb-Pb collisions require real-time processing of more than 3 TB/s of raw detector data. This requirement is met by a custom FPGA-based processing pipeline that performs the complete front-end data treatment fully in-stream, including common-mode correction, pedestal subtraction, ion-tail filtering, zero suppression, and dense data packing. A central element of the design is a highly parallel common-mode correction algorithm operating directly on the streaming data. It robustly identifies signal-free readout channels on a time-bin basis and applies pad-dependent scaling to compensate for local variations in capacitive coupling in the GEM readout. In combination with pedestal subtraction and ion-tail filtering, this enables accurate baseline restoration under extreme high-occupancy conditions, preventing signal loss while efficiently suppressing noise prior to zero suppression. The pipeline operates continuously at the full detector bandwidth and reduces the raw input rate to about 900 GB/s for Pb-Pb collisions at the target interaction rate. Overall, it represents a large-scale FPGA-based real-time signal-processing implementation for high-energy physics detector readout.",
    "title_zh": "物理学实验中的大规模实时信号处理：ALICE TPC FPGA流水线",
    "abstract_zh": "在LHC Run 3期间，ALICE时间投影室（Time Projection Chamber）升级为连续读出模式。在Pb-Pb碰撞中，高达50 kHz的相互作用率要求对超过3 TB/s的原始探测器数据进行实时处理。这一需求通过一种基于定制FPGA的处理流水线得以满足，该流水线在数据流中完全实现前端数据处理，包括共模抑制、基线扣除、离子尾滤波、零值压缩以及高密度数据打包。设计中的核心部分是一种高度并行的共模抑制算法，可直接在流式数据上运行。该算法能够以时间帧为基础，稳健地识别无信号的读出通道，并对每个探测单元应用依赖于位置的缩放系数，以补偿GEM读出系统中因电容耦合引起的局部差异。结合基线扣除和离子尾滤波，该方法可在极端高事例密度条件下实现精确的基线恢复，在有效抑制噪声的同时防止信号丢失，为后续的零值压缩提供了高质量输入。该流水线以全探测器带宽持续运行，将Pb-Pb碰撞在目标相互作用率下的原始数据速率降低至约900 GB/s。总体而言，这是一项大规模、基于FPGA的实时信号处理实现，适用于高能物理探测器读出系统。"
  },
  {
    "date": "2026-01-22",
    "title": "FirmReBugger: A Benchmark Framework for Monolithic Firmware Fuzzers",
    "authors": "Mathew Duong, Michael Chesser, Guy Farrelly, Surya Nepal, Damith C. Ranasinghe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15774v1",
    "source": "arXiv",
    "abstract": "Monolithic Firmware is widespread. Unsurprisingly, fuzz testing firmware is an active research field with new advances addressing the unique challenges in the domain. However, understanding and evaluating improvements by deriving metrics such as code coverage and unique crashes are problematic, leading to a desire for a reliable bug-based benchmark. To address the need, we design and build FirmReBugger, a holistic framework for fairly assessing monolithic firmware fuzzers with a realistic, diverse, bug-based benchmark. FirmReBugger proposes using bug oracles--C syntax expressions of bug descriptors--with an interpreter to automate analysis and accurately report on bugs discovered, discriminating between states of detected, triggered, reached and not reached. Importantly, our idea of benchmarking does not modify the target binary and simply replays fuzzing seeds to isolate the benchmark implementation from the fuzzer while providing a simple means to extend with new bug oracles. Further, analyzing fuzzing roadblocks, we created FirmBench, a set of diverse, real-world binary targets with 313 software bug oracles. Incorporating our analysis of roadblocks challenging monolithic firmware fuzzing, the bench provides for rapid evaluation of future advances. We implement FirmReBugger in a FuzzBench-for-Firmware type service and use FirmBench to evaluate 9 state-of-the art monolithic firmware fuzzers in the style of a reproducibility study, using a 10 CPU-year effort, to report our findings.",
    "title_zh": "FirmReBugger：一个用于单体固件模糊测试工具的基准测试框架",
    "abstract_zh": "单体固件（Monolithic Firmware）应用广泛。因此，对固件进行模糊测试（fuzz testing）成为一个活跃的研究领域，不断涌现出解决该领域独特挑战的新进展。然而，要通过代码覆盖率、唯一崩溃数等指标来理解和评估这些改进却存在困难，这促使研究者们迫切需要一个可靠的基于漏洞的基准测试工具。为应对这一需求，我们设计并构建了FirmReBugger——一个全面的框架，用于公平评估单体固件模糊测试器，并提供一个真实、多样化的基于漏洞的基准测试集。FirmReBugger提出使用“漏洞断言”（bug oracles）——即用C语言语法表达的漏洞描述——并配备解释器，以实现自动化分析，准确报告所发现的漏洞状态，能够区分“已检测到”、“已触发”、“已到达”和“未到达”等不同状态。尤为重要的是，我们的基准测试方法不修改目标二进制文件，仅通过重放模糊测试种子，从而将基准测试实现与模糊测试器本身隔离，同时提供一种简便的方式以扩展新的漏洞断言。此外，通过对模糊测试中常见障碍的分析，我们创建了FirmBench，一组包含313个真实世界软件漏洞断言的多样化、实际二进制目标集合。结合对单体固件模糊测试关键障碍的深入分析，该基准测试集可支持对未来技术进步的快速评估。我们实现了FirmReBugger作为类似FuzzBench-for-Firmware的服务，并利用FirmBench对9个当前最先进的单体固件模糊测试器进行了评估，采用10 CPU年的计算资源，以可复现性研究的方式报告了我们的发现。"
  },
  {
    "date": "2026-1-22",
    "title": "Explainable AI-Guided Genetic Algorithms for Efficient Software Automatic Tuning",
    "authors": "Toshinobu Katayama, Masatoshi Kawai, Yoichi Shimomura, Keichi Takahashi, Hiroyuki Takizawa",
    "publish": "Proceedings of the Supercomputing Asia and International Conference on High Performance Computing in Asia Pacific Region Workshops",
    "url": "https://doi.org/10.1145/3784828.3785252",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "可解释的人工智能引导的遗传算法在高效软件自动调优中的应用",
    "abstract_zh": "None"
  },
  {
    "date": "2026-1-22",
    "title": "Evaluating Claude Code’s Coding and Test Automation for GPU Acceleration ofa Legacy Fortran Application: A GeoFEM Case Study",
    "authors": "Tetsuya Hoshino, Shun-ichiro Hayashi, Daichi Mukunoki, Takahiro Katagiri, Toshihiro Hanawa",
    "publish": "Proceedings of the Supercomputing Asia and International Conference on High Performance Computing in Asia Pacific Region Workshops",
    "url": "https://doi.org/10.1145/3784828.3785335",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "评估Claude Code在GPU加速遗留Fortran应用程序中的编码与测试自动化：一个GeoFEM案例研究",
    "abstract_zh": "None"
  },
  {
    "date": "2026-1-22",
    "title": "Semantic Equivalence Verification of HPC Codes Using LLMs",
    "authors": "Yuta Tanizawa, Masatoshi Kawai, Keichi Takahashi, Hiroyuki Takizawa",
    "publish": "Proceedings of the Supercomputing Asia and International Conference on High Performance Computing in Asia Pacific Region Workshops",
    "url": "https://doi.org/10.1145/3784828.3785337",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "使用大语言模型验证高性能计算代码的语义等价性",
    "abstract_zh": "None"
  }
]