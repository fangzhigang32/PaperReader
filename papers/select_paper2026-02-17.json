[
  {
    "date": "2026-02-17",
    "title": "ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns",
    "authors": "Ziyu Zhao, Tong Zhu, Zhi Zhang, Tiantian Fan, Jinluan Yang, Kun Kuang, Zhongyu Wei, Fei Wu, Yu Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15521v1",
    "source": "arXiv",
    "abstract": "Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \\textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \\textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.",
    "title_zh": "专家编织者：通过GLU激活模式解锁密集型大语言模型中的内在混合专家机制",
    "abstract_zh": "混合专家（Mixture-of-Experts, MoE）通过稀疏专家激活，能够在保持计算效率的同时有效扩展模型容量。然而，从零开始训练高质量的MoE模型成本极高。一种有前景的替代方案是将预训练的密集模型转换为稀疏MoE模型。现有的密集模型转MoE方法主要分为两类：\\textbf{动态结构剪枝}，将密集模型转换为具有中等稀疏度的MoE架构，以在性能与推理效率之间取得平衡；以及 \\textbf{降级回用}（downcycling）方法，利用预训练的密集模型来初始化高度稀疏的MoE架构。然而，现有方法会破坏密集模型内部固有的激活模式，导致专家构建效果不佳。在本工作中，我们提出，门控线性单元（Gated Linear Unit, GLU）机制为密集模型到MoE的转换提供了一个天然的蓝图。我们发现，GLU所具有的细粒度神经元级激活模式中隐藏着粗粒度的结构，揭示出一种内在的MoE架构：由始终活跃的通用神经元和动态激活的专用神经元组成。基于这一发现，我们提出了ExpertWeaver——一种无需训练的框架，根据神经元的激活模式进行划分，并构建具有层自适应配置的共享专家与路由专用专家。实验结果表明，ExpertWeaver在作为无训练动态结构剪枝技术以及作为更优MoE初始化的降级回用策略时，均显著优于现有方法。"
  },
  {
    "date": "2026-02-17",
    "title": "Social Life of Code: Modeling Evolution through Code Embedding and Opinion Dynamics",
    "authors": "Yulong He, Nikita Verbin, Sergey Kovalchuk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15412v1",
    "source": "arXiv",
    "abstract": "Software repositories provide a detailed record of software evolution by capturing developer interactions through code-related activities such as pull requests and modifications. To better understand the underlying dynamics of codebase evolution, we introduce a novel approach that integrates semantic code embeddings with opinion dynamics theory, offering a quantitative framework to analyze collaborative development processes. Our approach begins by encoding code snippets into high-dimensional vector representations using state-of-the-art code embedding models, preserving both syntactic and semantic features. These embeddings are then processed using Principal Component Analysis (PCA) for dimensionality reduction, with data normalized to ensure comparability. We model temporal evolution using the Expressed-Private Opinion (EPO) model to derive trust matrices and track opinion trajectories across development cycles. These opinion trajectories reflect the underlying dynamics of consensus formation, influence propagation, and evolving alignment (or divergence) within developer communities -- revealing implicit collaboration patterns and knowledge-sharing mechanisms that are otherwise difficult to observe. By bridging software engineering and computational social science, our method provides a principled way to quantify software evolution, offering new insights into developer influence, consensus formation, and project sustainability. We evaluate our approach on data from three prominent open-source GitHub repositories, demonstrating its ability to reveal interpretable behavioral trends and variations in developer interactions. The results highlight the utility of our framework in improving open-source project maintenance through data-driven analysis of collaboration dynamics.",
    "title_zh": "代码的社会生活：通过代码嵌入与意见动态建模演化",
    "abstract_zh": "软件仓库通过捕获与代码相关的活动（如拉取请求和代码修改）来记录开发者的互动，从而提供软件演化的详细历史。为了更深入理解代码库演化的内在机制，我们提出一种新颖的方法，将语义代码嵌入与意见动力学理论相结合，构建了一个定量分析协作开发过程的框架。该方法首先利用先进的代码嵌入模型，将代码片段编码为高维向量表示，以保留其语法和语义特征。随后，通过主成分分析（PCA）对嵌入向量进行降维处理，并对数据进行归一化，以确保不同维度间的可比性。我们采用“表达-私有意见”（EPO）模型来建模时间演化过程，推导出信任矩阵，并追踪开发周期中意见的演变轨迹。这些意见轨迹反映了开发者社区中共识形成、影响力传播以及观点趋同或分歧的内在动态，揭示了难以直接观测的隐性协作模式与知识共享机制。通过融合软件工程与计算社会科学，我们的方法为量化软件演化提供了系统性路径，为理解开发者影响力、共识形成机制以及项目可持续性提供了新视角。我们在三个知名开源GitHub仓库的数据上验证了该方法，结果表明其能够有效揭示可解释的行为趋势及开发者互动的差异性。研究结果凸显了该框架在通过数据驱动分析协作动态来提升开源项目维护质量方面的实用价值。"
  },
  {
    "date": "2026-02-17",
    "title": "Improving LLM Reliability through Hybrid Abstention and Adaptive Detection",
    "authors": "Ankit Sharma, Nachiket Tapas, Jyotiprakash Patra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15391v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.",
    "title_zh": "通过混合弃权与自适应检测提升大语言模型的可靠性",
    "abstract_zh": "在生产环境中部署的大规模语言模型（LLMs）面临一个根本性的安全与实用性权衡：严格的过滤机制虽能防止有害输出，却常误拦无害查询；而过于宽松的控制则可能导致不安全内容的生成。传统的基于静态规则或固定置信度阈值的防护机制通常缺乏上下文感知能力，且计算开销大，导致延迟高，用户体验下降。为解决上述局限，我们提出一种自适应拒答系统，能够根据实时上下文信号（如领域信息和用户历史）动态调整安全阈值。该框架采用由五个并行检测器构成的多维度检测架构，并通过分层级联机制进行整合，以在速度与精度之间实现最优平衡。级联设计通过逐步过滤查询，避免了不必要的计算，相较于非级联模型及外部防护系统，显著降低了延迟。在混合任务与特定领域任务上的大量评估表明，该系统在医疗建议、创意写作等敏感领域显著减少了误报率。在严格运行模式下，系统仍能保持高安全精度和近乎完美的召回率。总体而言，我们的上下文感知拒答框架在保障安全的同时有效提升了实用性，且不牺牲性能，为大规模语言模型的可靠部署提供了一种可扩展的解决方案。"
  },
  {
    "date": "2026-02-17",
    "title": "Automated Multi-Source Debugging and Natural Language Error Explanation for Dashboard Applications",
    "authors": "Devendra Tata, Mona Rajhans",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15362v1",
    "source": "arXiv",
    "abstract": "Modern web dashboards and enterprise applications increasingly rely on complex, distributed microservices architectures. While these architectures offer scalability, they introduce significant challenges in debugging and observability. When failures occur, they often manifest as opaque error messages to the end-user such as Something went wrong. This masks the underlying root cause which may reside in browser side exceptions, API contract violations, or server side logic failures. Existing monitoring tools capture these events in isolation but fail to correlate them effectively or provide intelligible explanations to non technical users. This paper proposes a novel system for Automated Multi Source Debugging and Natural Language Error Explanation. The proposed framework automatically collects and correlates error data from disparate sources such as browser, API, server logs and validates API contracts in real time, and utilizes Large Language Models to generate natural language explanations. This approach significantly reduces Mean Time to Resolution for support engineers and improves the user experience by transforming cryptic error codes into actionable insights.",
    "title_zh": "仪表板应用的自动化多源调试与自然语言错误解释",
    "abstract_zh": "现代网络仪表板和企业级应用越来越多地依赖于复杂且分布式的微服务架构。尽管这类架构具备良好的可扩展性，但也带来了调试和可观测性方面的重大挑战。当出现故障时，用户通常只能看到诸如“发生了一些错误”之类的模糊提示，这掩盖了潜在的根本原因——这些原因可能存在于浏览器端异常、API契约违规或服务器端逻辑错误中。现有的监控工具虽然能够孤立地捕获这些事件，却难以有效关联它们，也无法为非技术人员提供清晰易懂的解释。本文提出了一种新型的自动化多源调试与自然语言错误解释系统。该框架能够自动收集并关联来自不同来源（如浏览器、API、服务器日志）的错误数据，并实时验证API契约，同时利用大语言模型生成自然语言形式的错误解释。该方法显著缩短了支持工程师的平均故障修复时间，同时通过将晦涩的错误代码转化为可操作的洞察，极大地提升了用户体验。"
  },
  {
    "date": "2026-02-17",
    "title": "*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation",
    "authors": "Quentin Lemesle, Léane Jourdan, Daisy Munson, Pierre Alain, Jonathan Chevelu, Arnaud Delhay, Damien Lolive",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15778v1",
    "source": "arXiv",
    "abstract": "Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.",
    "title_zh": "*-PLUIE：基于大语言模型的可个性化指标，用于提升评估效果",
    "abstract_zh": "评估自动生成文本的质量通常依赖于大语言模型作为评判者（LLM-judge）的方法。尽管这些方法效果显著，但计算成本较高，且需要后续处理。为解决这些局限性，我们基于ParaPLUIE——一种基于困惑度的LLM-judge指标——进行改进，该指标能够在不生成文本的情况下，对“是/否”类答案估计置信度。我们提出了*-PLUIE，即ParaPLUIE的任务特定提示变体，并评估了其与人类判断的一致性。实验结果表明，个性化后的*-PLUIE在保持低计算成本的同时，与人类评分的相关性更强。"
  },
  {
    "date": "2026-02-17",
    "title": "Algorithmic differentiation for domain specific languages in C++ with expression templates",
    "authors": "Max Sagebaum, Nicolas R. Gauger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15613v1",
    "source": "arXiv",
    "abstract": "The application of operator overloading algorithmic differentiation (AD) to computer programs in order to compute the derivative is quite common. But, the replacement of the underlying computational floating point type with the specialized type of an AD tool has two problems. First, the memory structure of the program is changed and floating-point data is interleaved with identifiers from AD. This prevents the compiler from performing optimizations such as SIMD optimizations. Second, the AD tool does not see any domain-specific operations, e.,g. linear algebra operations, that the program uses. This prevents the AD tool from using specialized algorithms in such places. We propose a new AD tool that is tailored to such situations. The memory structure of the primal data is retained by associating an identifier with each entity, e.,g. matrix, and not with each floating point value, e.,g. element of the matrix. Operations on such entities can then be annotated and a generator is used to create the AD overloads. We demonstrate that this approach provides performance comparable to that of other specializations. In addition, the run-time factor is below the theoretical 4.5 of reverse AD for programs that are written purely with linear algebra entities and operations.",
    "title_zh": "使用表达式模板在C++中实现特定领域语言的算法微分",
    "abstract_zh": "将操作符重载的算法微分（AD）应用于计算机程序以计算导数的方法非常普遍。然而，将底层计算的浮点类型替换为AD工具的专用类型存在两个问题。首先，程序的内存结构被改变，浮点数据与AD的标识符交错在一起，这使得编译器无法执行诸如SIMD优化等优化操作。其次，AD工具无法识别程序中使用的任何领域特定操作，例如线性代数运算，从而无法在这些位置使用专门的优化算法。为此，我们提出了一种专为这类情况设计的新AD工具。该工具通过为每个实体（如矩阵）关联一个标识符，而非为每个浮点数值（如矩阵元素）关联标识符，从而保留了原始数据的内存结构。随后，对这些实体上的操作进行注释，并使用生成器自动生成AD重载。我们证明，该方法的性能可与其它专门化方法相媲美。此外，对于完全使用线性代数实体和操作编写的程序，其运行时开销低于反向AD的理论下限4.5。"
  },
  {
    "date": "2026-02-17",
    "title": "AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents",
    "authors": "Zhixing Zhang, Jesen Zhang, Hao Liu, Qinhan Lv, Jing Yang, Kaitong Cai, Keze Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15325v1",
    "source": "arXiv",
    "abstract": "Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual \"what-if\" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.",
    "title_zh": "AgriWorld：一种用于可验证农业推理的代码执行大语言模型代理的全球工具协议框架",
    "abstract_zh": "用于农业领域的基础模型正越来越多地基于大规模时空数据（如多光谱遥感数据、土壤网格数据以及田间管理日志）进行训练，并在预测与监测任务中展现出优异的性能。然而，这些模型缺乏基于语言的推理和交互能力，限制了其在实际农艺工作流程中的应用价值。与此同时，大型语言模型（LLM）在文本理解与生成方面表现出色，却无法直接对高维、异构的农业数据进行推理。为此，我们提出了一种面向农业科学的智能体框架，通过提供一个Python执行环境——AgriWorld，统一暴露多种工具，支持对田块的地理空间查询、遥感时序数据分析、作物生长模拟以及特定任务的预测器（如产量、胁迫和病害风险预测）。在此环境之上，我们设计了一个多轮交互的LLM智能体——Agro-Reflective，它通过“执行-观察-反思”循环，迭代地编写代码、观察执行结果，并不断优化分析过程。我们还构建了AgroBench基准测试平台，支持可扩展的数据生成，涵盖多样化的农业问答任务，包括数据查询、预测分析、异常检测以及反事实“如果……会怎样”情景分析。实验结果表明，该方法显著优于仅依赖文本或直接调用工具的基线模型，验证了以执行驱动的反思机制在实现可靠农业推理方面的有效性。"
  },
  {
    "date": "2026-02-17",
    "title": "Quantifying construct validity in large language model evaluations",
    "authors": "Ryan Othniel Kearns",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15532v1",
    "source": "arXiv",
    "abstract": "The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance. Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks. This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.",
    "title_zh": "大型语言模型评估中构念效度的量化",
    "abstract_zh": "大语言模型（LLM）社区常常将基准测试结果视为模型通用能力的同义词。然而，基准测试本身可能存在一些问题，导致性能评估失真，例如测试集污染和标注者错误。我们如何才能确定某个基准测试是衡量我们所关心能力的可靠指标？这个问题涉及LLM基准测试的“构念效度”（construct validity），要求我们在建模和预测LLM性能时，将基准测试结果与实际能力区分开来。\n\n社会科学家和计算机科学家都提出了形式化模型来识别支撑基准分数背后的能力：潜在因子模型和缩放定律（scaling laws）。然而，这两种方法在构念效度方面均存在不足。潜在因子模型忽略了缩放定律，因此所提取的能力往往只是模型规模的代理变量；而缩放定律则忽略了测量误差，导致所提取的能力既难以解释，又过度拟合于已观测到的基准测试。\n\n本文提出了“结构化能力模型”（structured capabilities model），这是首个能够从大量LLM基准测试结果中提取出可解释且具有泛化能力的能力的模型。我将该模型及其两种替代方案应用于来自OpenLLM Leaderboard的大量测试结果。结果显示，结构化能力模型在简约性拟合指标上优于潜在因子模型，并且在分布外基准测试预测方面显著优于缩放定律。\n\n这些改进之所以成为可能，是因为现有方法均未能以恰当的方式将模型规模与能力分离。正确的做法应是：模型规模应影响能力（如缩放定律所体现的），而这些能力又应在考虑测量误差的前提下影响观测到的基准结果（如潜在因子模型所体现的）。通过整合这两项关键洞见，结构化能力模型在量化LLM评估中构念效度方面展现出更强的解释力和预测能力。"
  },
  {
    "date": "2026-02-17",
    "title": "Memory Reallocation with Polylogarithmic Overhead",
    "authors": "Ce Jin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15417v1",
    "source": "arXiv",
    "abstract": "The Memory Reallocation problem asks to dynamically maintain an assignment of given objects of various sizes to non-overlapping contiguous chunks of memory, while supporting updates (insertions/deletions) in an online fashion. The total size of live objects at any time is guaranteed to be at most a $1-ε$ fraction of the total memory. To handle an online update, the allocator may rearrange the objects in memory to make space, and the overhead for this update is defined as the total size of moved objects divided by the size of the object being inserted/deleted. Our main result is an allocator with worst-case expected overhead $\\mathrm{polylog}(ε^{-1})$. This exponentially improves the previous worst-case expected overhead $\\tilde O(ε^{-1/2})$ achieved by Farach-Colton, Kuszmaul, Sheffield, and Westover (2024), narrowing the gap towards the $Ω(\\logε^{-1})$ lower bound. Our improvement is based on an application of the sunflower lemma previously used by Erdős and Sárközy (1992) in the context of subset sums. Our allocator achieves polylogarithmic overhead only in expectation, and sometimes performs expensive rebuilds. Our second technical result shows that this is necessary: it is impossible to achieve subpolynomial overhead with high probability.",
    "title_zh": "具有亚对数开销的内存重分配",
    "abstract_zh": "内存重分配问题要求动态维护一组不同大小的对象在非重叠连续内存块中的分配，同时以在线方式支持插入和删除等更新操作。在任意时刻，活跃对象的总大小被保证不超过总内存的 $1 - \\varepsilon$ 分数。为了处理在线更新，分配器可以重新排列内存中的对象以腾出空间，而此次更新的开销定义为被移动对象的总大小与被插入或删除对象大小的比值。我们的主要结果是提出了一种分配器，其最坏情况下的期望开销为 $\\mathrm{polylog}(\\varepsilon^{-1})$。这一结果相比 Farach-Colton、Kuszmaul、Sheffield 和 Westover（2024）所实现的 $\\tilde O(\\varepsilon^{-1/2})$ 的最坏情况期望开销实现了指数级的改进，从而显著缩小了与 $\\Omega(\\log \\varepsilon^{-1})$ 理论下界之间的差距。我们的改进基于对“花形引理”（sunflower lemma）的应用，该引理此前由 Erdős 和 Sárközy（1992）用于子集和问题的研究中。我们的分配器仅在期望意义下实现对数多对数级别的开销，但有时会执行代价高昂的重建操作。我们的第二个技术性结果表明：这是不可避免的——不可能以高概率实现亚多项式级别的开销。"
  },
  {
    "date": "2026-02-17",
    "title": "CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing",
    "authors": "Zarif Ikram, Arad Firouzkouhi, Stephen Tu, Mahdi Soltanolkotabi, Paria Rashidinejad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15823v1",
    "source": "arXiv",
    "abstract": "A central challenge in large language model (LLM) editing is capability preservation: methods that successfully change targeted behavior can quietly game the editing proxy and corrupt general capabilities, producing degenerate behaviors reminiscent of proxy/reward hacking. We present CrispEdit, a scalable and principled second-order editing algorithm that treats capability preservation as an explicit constraint, unifying and generalizing several existing editing approaches. CrispEdit formulates editing as constrained optimization and enforces the constraint by projecting edit updates onto the low-curvature subspace of the capability-loss landscape. At the crux of CrispEdit is expressing capability constraint via Bregman divergence, whose quadratic form yields the Gauss-Newton Hessian exactly and even when the base model is not trained to convergence. We make this second-order procedure efficient at the LLM scale using Kronecker-factored approximate curvature (K-FAC) and a novel matrix-free projector that exploits Kronecker structure to avoid constructing massive projection matrices. Across standard model-editing benchmarks, CrispEdit achieves high edit success while keeping capability degradation below 1% on average across datasets, significantly improving over prior editors.",
    "title_zh": "CrispEdit：用于可扩展非破坏性大语言模型编辑的低曲率投影",
    "abstract_zh": "大型语言模型（LLM）编辑中的一个核心挑战是能力保持：一些能够成功修改目标行为的方法，可能会通过操纵编辑代理（proxy）来“绕过”约束，从而破坏模型的通用能力，导致退化行为，类似于代理/奖励劫持（proxy/reward hacking）现象。我们提出了CrispEdit，一种可扩展且具有理论基础的二阶编辑算法，将能力保持明确作为约束条件，统一并推广了多种现有的编辑方法。CrispEdit将编辑过程建模为带约束的优化问题，并通过将编辑更新投影到能力损失曲面的低曲率子空间来强制执行该约束。CrispEdit的核心在于利用Bregman散度表达能力约束，其二次形式能够精确地得到Gauss-Newton Hessian矩阵，即使基础模型未完全收敛训练也依然有效。我们通过采用Kronecker分解近似曲率（K-FAC）以及一种新颖的无矩阵投影算子，充分利用Kronecker结构，避免构建庞大的投影矩阵，从而在大模型规模下高效实现这一二阶过程。在标准的模型编辑基准测试中，CrispEdit不仅实现了高编辑成功率，同时在各数据集上平均能力退化低于1%，显著优于以往的编辑方法。"
  },
  {
    "date": "2026-02-17",
    "title": "Developing AI Agents with Simulated Data: Why, what, and how?",
    "authors": "Xiaoran Liu, Istvan David",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15816v1",
    "source": "arXiv",
    "abstract": "As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.",
    "title_zh": "使用模拟数据开发人工智能代理：为何、何为、如何？",
    "abstract_zh": "由于数据量不足和数据质量差仍是制约现代非符号化人工智能应用的主要障碍，合成数据生成技术的需求日益迫切。仿真提供了一种恰当且系统化的方法，用于生成多样化的合成数据。本章将向读者介绍基于仿真的合成数据生成在人工智能训练中的核心概念、优势与挑战，并提出一个参考框架，用于描述、设计和分析基于数字孪生的人工智能仿真解决方案。"
  },
  {
    "date": "2026-02-17",
    "title": "Req2Road: A GenAI Pipeline for SDV Test Artifact Generation and On-Vehicle Execution",
    "authors": "Denesa Zyberaj, Lukasz Mazur, Pascal Hirmer, Nenad Petrovic, Marco Aiello, Alois Knoll",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15591v1",
    "source": "arXiv",
    "abstract": "Testing functionality in Software-Defined Vehicles is challenging because requirements are written in natural language, specifications combine text, tables, and diagrams, while test assets are scattered across heterogeneous toolchains. Large Language Models and Vision-Language Models are used to extract signals and behavioral logic to automatically generate Gherkin scenarios, which are then converted into runnable test scripts. The Vehicle Signal Specification (VSS) integration standardizes signal references, supporting portability across subsystems and test benches. The pipeline uses retrieval-augmented generation to preselect candidate VSS signals before mapping. We evaluate the approach on the safety-relevant Child Presence Detection System, executing the generated tests in a virtual environment and on an actual vehicle. Our evaluation covers Gherkin validity, VSS mapping quality, and end-to-end executability. Results show that 32 of 36 requirements (89\\%) can be transformed into executable scenarios in our setting, while human review and targeted substitutions remain necessary. This paper is a feasibility and architectural demonstration of an end-to-end requirements-to-test pipeline for SDV subsystems, evaluated on a CPDS case in simulation and Vehicle-in-the-Loop settings.",
    "title_zh": "Req2Road：一种用于SDV测试用例生成与车载执行的生成式AI流水线",
    "abstract_zh": "在软件定义车辆（SDV）中测试功能具有挑战性，因为需求以自然语言编写，规范包含文本、表格和图表等多种形式，而测试资产则分散在异构工具链中。大型语言模型（LLM）和视觉-语言模型被用于提取信号和行为逻辑，以自动生成Gherkin场景，随后将这些场景转换为可执行的测试脚本。车辆信号规范（VSS）集成标准统一了信号引用，支持跨子系统和测试平台的可移植性。该流程采用检索增强生成（RAG）技术，在映射前预先筛选候选VSS信号。我们在一个与安全相关的儿童存在检测系统（CPDS）上评估了该方法，在虚拟环境和实际车辆上执行生成的测试。评估涵盖Gherkin的有效性、VSS映射质量以及端到端可执行性。结果表明，在当前设置下，36个需求中有32个（89%）可成功转化为可执行场景，但仍需人工审查和针对性修正。本文展示了面向SDV子系统的端到端需求到测试流程的可行性与架构设计，基于CPDS案例在仿真环境和“车辆在环”（Vehicle-in-the-Loop）场景中进行了验证。"
  },
  {
    "date": "2026-02-17",
    "title": "SecCodeBench-V2 Technical Report",
    "authors": "Longfei Chen, Ji Zhao, Lanxiao Cui, Tong Su, Xingbo Pan, Ziyang Li, Yongxing Wu, Qijiang Cao, Qiyao Cai, Jing Zhang, Yuandong Ni, Junyao He, Zeyu Zhang, Chao Ge, Xuhuai Lu, Zeyu Gao, Yuxin Cui, Weisen Chen, Yuxuan Peng, Shengping Wang, Qi Li, Yukai Huang, Yukun Liu, Tuo Zhou, Terry Yue Zhuo, Junyang Lin, Chao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15485v1",
    "source": "arXiv",
    "abstract": "We introduce SecCodeBench-V2, a publicly released benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating secure code. SecCodeBench-V2 comprises 98 generation and fix scenarios derived from Alibaba Group's industrial productions, where the underlying security issues span 22 common CWE (Common Weakness Enumeration) categories across five programming languages: Java, C, Python, Go, and Node.js. SecCodeBench-V2 adopts a function-level task formulation: each scenario provides a complete project scaffold and requires the model to implement or patch a designated target function under fixed interfaces and dependencies. For each scenario, SecCodeBench-V2 provides executable proof-of-concept (PoC) test cases for both functional validation and security verification. All test cases are authored and double-reviewed by security experts, ensuring high fidelity, broad coverage, and reliable ground truth. Beyond the benchmark itself, we build a unified evaluation pipeline that assesses models primarily via dynamic execution. For most scenarios, we compile and run model-generated artifacts in isolated environments and execute PoC test cases to validate both functional correctness and security properties. For scenarios where security issues cannot be adjudicated with deterministic test cases, we additionally employ an LLM-as-a-judge oracle. To summarize performance across heterogeneous scenarios and difficulty levels, we design a Pass@K-based scoring protocol with principled aggregation over scenarios and severity, enabling holistic and comparable evaluation across models. Overall, SecCodeBench-V2 provides a rigorous and reproducible foundation for assessing the security posture of AI coding assistants, with results and artifacts released at https://alibaba.github.io/sec-code-bench. The benchmark is publicly available at https://github.com/alibaba/sec-code-bench.",
    "title_zh": "SecCodeBench-V2 技术报告",
    "abstract_zh": "我们推出了SecCodeBench-V2，这是一个公开发布的基准测试，用于评估大型语言模型（LLM）编程助手生成安全代码的能力。SecCodeBench-V2包含98个生成与修复场景，这些场景源自阿里巴巴集团的工业生产实践，其底层安全问题覆盖了五大编程语言（Java、C、Python、Go和Node.js）中的22类常见CWE（通用弱点枚举）类别。SecCodeBench-V2采用函数级任务设计：每个场景提供完整的项目框架，要求模型在固定接口和依赖条件下实现或修补指定的目标函数。针对每个场景，SecCodeBench-V2均提供可执行的原型验证（PoC）测试用例，用于功能验证和安全验证。所有测试用例均由安全专家编写并经过双重审核，确保高保真度、广泛覆盖以及可靠的基准真值。除了基准测试本身，我们还构建了一个统一的评估流程，主要通过动态执行来评估模型表现。对于大多数场景，我们将在隔离环境中编译并运行模型生成的代码，执行PoC测试用例，以验证其功能正确性与安全属性。对于无法通过确定性测试用例判定安全问题的场景，我们额外引入了“大模型作为裁判”（LLM-as-a-judge）的评估机制。为在异构场景和不同难度级别之间实现综合且可比的性能评估，我们设计了一种基于Pass@K的评分协议，对场景和严重性级别进行合理聚合，从而实现全面、一致的模型比较。总体而言，SecCodeBench-V2为评估AI编程助手的安全能力提供了严谨且可复现的基础，相关结果与实验资源已发布于 https://alibaba.github.io/sec-code-bench，基准测试数据集也已公开在 https://github.com/alibaba/sec-code-bench。"
  },
  {
    "date": "2026-02-17",
    "title": "Operationalising the Superficial Alignment Hypothesis via Task Complexity",
    "authors": "Tomás Vergara-Browne, Darshan Patil, Ivan Titov, Siva Reddy, Tiago Pimentel, Marius Mosbach",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15829v1",
    "source": "arXiv",
    "abstract": "The superficial alignment hypothesis (SAH) posits that large language models learn most of their knowledge during pre-training, and that post-training merely surfaces this knowledge. The SAH, however, lacks a precise definition, which has led to (i) different and seemingly orthogonal arguments supporting it, and (ii) important critiques to it. We propose a new metric called task complexity: the length of the shortest program that achieves a target performance on a task. In this framework, the SAH simply claims that pre-trained models drastically reduce the complexity of achieving high performance on many tasks. Our definition unifies prior arguments supporting the SAH, interpreting them as different strategies to find such short programs. Experimentally, we estimate the task complexity of mathematical reasoning, machine translation, and instruction following; we then show that these complexities can be remarkably low when conditioned on a pre-trained model. Further, we find that pre-training enables access to strong performances on our tasks, but it can require programs of gigabytes of length to access them. Post-training, on the other hand, collapses the complexity of reaching this same performance by several orders of magnitude. Overall, our results highlight that task adaptation often requires surprisingly little information -- often just a few kilobytes.",
    "title_zh": "通过任务复杂性实现表面一致假设的可操作化",
    "abstract_zh": "表层对齐假说（SAH）认为，大型语言模型在其预训练阶段学习了大部分知识，而后续训练仅是将这些知识“显现”出来。然而，SAH 缺乏精确的定义，这导致了（i）支持该假说的多种看似相互独立的论点，以及（ii）对其的重要批评。为此，我们提出了一种新度量标准——任务复杂度：在某项任务上达到目标性能所需的最短程序长度。在此框架下，SAH 仅主张预训练模型显著降低了在众多任务上实现高性能所需的任务复杂度。我们的定义统一了此前支持SAH的各种论点，将其解释为寻找此类简短程序的不同策略。实验上，我们估算了数学推理、机器翻译和指令遵循等任务的任务复杂度，结果表明，当以预训练模型为条件时，这些复杂度可低得惊人。此外，我们发现预训练使模型能够访问高性能表现，但要实现这些表现，可能需要长度达千兆字节的程序。相比之下，后续训练则将达到相同性能所需复杂度降低了数个数量级。总体而言，我们的研究结果表明，任务适应通常只需极少量信息——往往仅需几KB。"
  },
  {
    "date": "2026-02-17",
    "title": "GLM-5: from Vibe Coding to Agentic Engineering",
    "authors": "GLM-5 Team, :, Aohan Zeng, Xin Lv, Zhenyu Hou, Zhengxiao Du, Qinkai Zheng, Bin Chen, Da Yin, Chendi Ge, Chengxing Xie, Cunxiang Wang, Gengzheng Pan, Hao Zeng, Haoke Zhang, Haoran Wang, Huilong Chen, Jiajie Zhang, Jian Jiao, Jiaqi Guo, Jingsen Wang, Jingzhao Du, Jinzhu Wu, Kedong Wang, Lei Li, Lin Fan, Lucen Zhong, Mingdao Liu, Mingming Zhao, Pengfan Du, Qian Dong, Rui Lu, Shuang-Li, Shulin Cao, Song Liu, Ting Jiang, Xiaodong Chen, Xiaohan Zhang, Xuancheng Huang, Xuezhen Dong, Yabo Xu, Yao Wei, Yifan An, Yilin Niu, Yitong Zhu, Yuanhao Wen, Yukuo Cen, Yushi Bai, Zhongpei Qiao, Zihan Wang, Zikang Wang, Zilin Zhu, Ziqiang Liu, Zixuan Li, Bojie Wang, Bosi Wen, Can Huang, Changpeng Cai, Chao Yu, Chen Li, Chen Li, Chenghua Huang, Chengwei Hu, Chenhui Zhang, Chenzheng Zhu, Congfeng Yin, Daoyan Lin, Dayong Yang, Di Wang, Ding Ai, Erle Zhu, Fangzhou Yi, Feiyu Chen, Guohong Wen, Hailong Sun, Haisha Zhao, Haiyi Hu, Hanchen Zhang, Hanrui Liu, Hanyu Zhang, Hao Peng, Hao Tai, Haobo Zhang, He Liu, Hongwei Wang, Hongxi Yan, Hongyu Ge, Huan Liu, Huan Liu, Huanpeng Chu, Jia'ni Zhao, Jiachen Wang, Jiajing Zhao, Jiamin Ren, Jiapeng Wang, Jiaxin Zhang, Jiayi Gui, Jiayue Zhao, Jijie Li, Jing An, Jing Li, Jingwei Yuan, Jinhua Du, Jinxin Liu, Junkai Zhi, Junwen Duan, Kaiyue Zhou, Kangjian Wei, Ke Wang, Keyun Luo, Laiqiang Zhang, Leigang Sha, Liang Xu, Lindong Wu, Lintao Ding, Lu Chen, Minghao Li, Nianyi Lin, Pan Ta, Qiang Zou, Rongjun Song, Ruiqi Yang, Shangqing Tu, Shangtong Yang, Shaoxiang Wu, Shengyan Zhang, Shijie Li, Shuang Li, Shuyi Fan, Wei Qin, Wei Tian, Weining Zhang, Wenbo Yu, Wenjie Liang, Xiang Kuang, Xiangmeng Cheng, Xiangyang Li, Xiaoquan Yan, Xiaowei Hu, Xiaoying Ling, Xing Fan, Xingye Xia, Xinyuan Zhang, Xinze Zhang, Xirui Pan, Xunkai Zhang, Yandong Wu, Yanfu Li, Yidong Wang, Yifan Zhu, Yijun Tan, Yilin Zhou, Yiming Pan, Ying Zhang, Yinpei Su, Yipeng Geng, Yipeng Geng, Yong Yan, Yonglin Tan, Yuean Bi, Yuhan Shen, Yuhao Yang, Yujiang Li, Yunan Liu, Yunqing Wang, Yuntao Li, Yurong Wu, Yutao Zhang, Yuxi Duan, Yuxuan Zhang, Zezhen Liu, Zhengtao Jiang, Zhenhe Yan, Zheyu Zhang, Zhixiang Wei, Zhuo Chen, Zhuoer Feng, Zijun Yao, Ziwei Chai, Ziyuan Wang, Zuzhou Zhang, Bin Xu, Minlie Huang, Hongning Wang, Juanzi Li, Yuxiao Dong, Jie Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15763v1",
    "source": "arXiv",
    "abstract": "We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.",
    "title_zh": "GLM-5：从Vibe Coding到智能体工程",
    "abstract_zh": "我们推出了GLM-5，这是一个下一代基础模型，旨在推动“氛围编程”（vibe coding）范式向自主工程（agentic engineering）的转型。在继承前代模型GLM-5所具备的自主性、推理能力和代码生成（ARC）优势的基础上，GLM-5引入了DSA技术，在显著降低训练与推理成本的同时，保持了长上下文的高保真度。为提升模型对齐性与自主性，我们构建了一套全新的异步强化学习基础设施，通过将生成过程与训练过程解耦，大幅提升了后训练阶段的效率。此外，我们提出了一种新型的异步智能体强化学习算法，进一步优化了强化学习的质量，使模型能够更高效地从复杂且长周期的交互中学习。凭借这些创新，GLM-5在多个主流开源基准测试中达到了当前最先进水平。尤为重要的是，GLM-5在真实世界编程任务中展现出前所未有的能力，显著超越以往基线模型，在端到端软件工程挑战中表现卓越。代码、模型及相关信息可访问 https://github.com/zai-org/GLM-5 获取。"
  },
  {
    "date": "2026-02-17",
    "title": "Iterative LLM-Based Assertion Generation Using Syntax-Semantic Representations for Functional Coverage-Guided Verification",
    "authors": "Yonghao Wang, Jiaxin Zhou, Yang Yin, Hongqin Lyu, Zhiteng Chao, Wenchao Ding, Jing Ye, Tiancheng Wang, Huawei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15388v1",
    "source": "arXiv",
    "abstract": "While leveraging LLMs to automatically generate SystemVerilog assertions (SVAs) from natural language specifications holds great potential, existing techniques face a key challenge: LLMs often lack sufficient understanding of IC design, leading to poor assertion quality in a single pass. Therefore, verifying whether the generated assertions effectively cover the functional specifications and designing feedback mechanisms based on this coverage remain significant hurdles. To address these limitations, this paper introduces CoverAssert, a novel iterative framework for optimizing SVA generation with LLMs. The core contribution is a lightweight mechanism for matching generated assertions with specific functional descriptions in the specifications. CoverAssert achieves this by clustering the joint representations of semantic features of LLM-generated assertions and structural features extracted from abstract syntax trees (ASTs) about signals related to assertions, and then mapping them back to the specifications to analyze functional coverage quality. Leveraging this capability, CoverAssert constructs a feedback loop based on functional coverage to guide LLMs in prioritizing uncovered functional points, thereby iteratively improving assertion quality. Experimental evaluations on four open-source designs demonstrate that integrating CoverAssert with state-of-the-art generators, AssertLLM and Spec2Assertion, achieves average improvements of 9.57 % in branch coverage, 9.64 % in statement coverage, and 15.69 % in toggle coverage.",
    "title_zh": "基于语法-语义表示的迭代式LLM断言生成方法用于功能覆盖率引导的验证",
    "abstract_zh": "尽管利用大语言模型（LLMs）从自然语言规范中自动生成SystemVerilog断言（SVAs）具有巨大潜力，但现有技术面临一个关键挑战：LLMs往往对集成电路（IC）设计理解不足，导致单次生成的断言质量较差。因此，验证生成的断言是否有效覆盖了功能规范，以及基于覆盖情况设计反馈机制，仍是重大难题。为解决这些局限，本文提出了一种名为CoverAssert的新颖迭代框架，用于优化基于LLMs的SVA生成。其核心贡献是一种轻量级机制，用于将生成的断言与规范中的具体功能描述进行匹配。CoverAssert通过聚类LLM生成断言的语义特征与关于断言相关信号的抽象语法树（AST）结构特征的联合表示，再将这些聚类结果映射回原始规范，以分析功能覆盖质量。基于此能力，CoverAssert构建了一个基于功能覆盖的反馈循环，引导LLMs优先关注未被覆盖的功能点，从而迭代提升断言质量。在四个开源设计上的实验评估表明，将CoverAssert与当前最先进的生成器AssertLLM和Spec2Assertion结合使用，平均可提升分支覆盖9.57%、语句覆盖9.64%以及翻转覆盖15.69%。"
  },
  {
    "date": "2026-02-17",
    "title": "Human-AI Interaction: Evaluating LLM Reasoning on Digital Logic Circuit included Graph Problems, in terms of creativity in design and analysis",
    "authors": "Yogeswar Reddy Thota, Setareh Rafatirad, Homayoun Houman, Tooraj Nikoubin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15336v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly used by undergraduate students as on-demand tutors, yet their reliability on circuit- and diagram-based digital logic problems remains unclear. We present a human- AI study evaluating three widely used LLMs (GPT, Gemini, and Claude) on 10 undergraduate-level digital logic questions spanning non-standard counters, JK-based state transitions, timing diagrams, frequency division, and finite-state machines. Twenty-four students performed pairwise model comparisons, providing per-question judgments on (i) preferred model, (ii) perceived correctness, (iii) consistency, (iv) verbosity, and (v) confidence, along with global ratings of overall model quality, satisfaction across multiple dimensions (e.g., accuracy and clarity), and perceived mental effort required to verify answers. To benchmark technical validity, we applied an independent judge-based evaluation against official solutions for all ten questions, using strict correctness criteria. Results reveal a consistent gap between perceived helpfulness and formal correctness: for the most sequentially demanding problems (Q1- Q7), none of the evaluated LLMs matched the official answers, despite producing confident, well-structured explanations that students often rated favorably. Error analysis indicates that models frequently default to canonical textbook templates (e.g., standard ripple counters) and struggle to translate circuit structure into exact state evolution and timing behavior. These findings suggest that, without verification scaffolds, LLMs may be unreliable for core digital logic topics and can inadvertently reinforce misconceptions in undergraduate instruction.",
    "title_zh": "人机交互：评估大语言模型在数字逻辑电路（含图论问题）中的推理能力，及其在设计与分析中的创造力",
    "abstract_zh": "大型语言模型（LLMs）正越来越多地被本科生用作按需辅导工具，但其在电路与图示类数字逻辑问题上的可靠性仍不明确。本文通过一项人机结合研究，评估了三种广泛使用的LLM（GPT、Gemini和Claude）在10道本科水平数字逻辑题目上的表现，涵盖非标准计数器、基于JK触发器的状态转换、时序图、频率分频以及有限状态机等主题。24名学生进行了模型间的两两比较，针对每道题目提供了五项判断：（i）首选模型，（ii）感知正确性，（iii）一致性，（iv）冗长程度，（v）信心水平，并给出了整体评价，包括模型综合质量、在准确性、清晰度等多个维度的满意度，以及验证答案所需的心理努力程度。\n\n为基准测试技术准确性，我们采用独立评审员对所有十道题目的答案与官方标准答案进行比对，使用严格的正确性标准。结果表明，感知帮助性与正式正确性之间存在持续差距：在对序列逻辑要求最高的问题（Q1–Q7）中，所有被评估的LLM均未能给出与官方答案一致的结果，尽管它们生成了自信且结构清晰的解释，学生往往对此给予较高评价。错误分析显示，这些模型常常依赖教科书中的标准模板（如标准的级联计数器），难以准确将电路结构转化为精确的状态演变和时序行为。\n\n研究结果表明，在缺乏验证支持机制的情况下，LLM在核心数字逻辑内容上可能不可靠，甚至可能在本科教学中无意间强化学生的错误理解。"
  },
  {
    "date": "2026-02-17",
    "title": "Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory",
    "authors": "Zihao Tang, Xin Yu, Ziyu Xiao, Zengxuan Wen, Zelin Li, Jiaxi Zhou, Hualei Wang, Haohua Wang, Haizhen Huang, Weiwei Deng, Feng Sun, Qi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15313v1",
    "source": "arXiv",
    "abstract": "AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.",
    "title_zh": "Mnemis：面向长期大语言模型记忆的分路检索层次图方法",
    "abstract_zh": "AI记忆，特别是模型如何组织和检索历史信息，对大型语言模型（LLMs）的重要性日益凸显。然而，现有的方法（如RAG和Graph-RAG）主要依赖基于相似性的检索机制。尽管高效，这种类似系统1（System-1）的检索方式在需要全局推理或全面覆盖所有相关信息的场景中表现不佳。本文提出了一种名为Mnemis的新颖记忆框架，该框架将系统1的相似性搜索与一种互补的系统2机制——“全局选择”（Global Selection）相结合。Mnemis将记忆组织为一个基础图以支持相似性检索，并构建了一个分层图，实现自上而下的、有意识的语义层次遍历。通过融合两种检索路径的互补优势，Mnemis能够检索出在语义和结构上均相关的记忆项。在长期记忆基准测试中，Mnemis在所有对比方法中均达到最先进水平，使用GPT-4.1-mini时在LoCoMo上得分93.9，在LongMemEval-S上得分为91.6。"
  },
  {
    "date": "2026-02-17",
    "title": "Enabling Low-Latency Machine learning on Radiation-Hard FPGAs with hls4ml",
    "authors": "Katya Govorkova, Julian Garcia Pardinas, Vladimir Loncar, Victoria Nguyen, Sebastian Schmitt, Marco Pizzichemi, Loris Martinazzoli, Eluned Anne Smith",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15751v1",
    "source": "arXiv",
    "abstract": "This paper presents the first demonstration of a viable, ultra-fast, radiation-hard machine learning (ML) application on FPGAs, which could be used in future high-energy physics experiments. We present a three-fold contribution, with the PicoCal calorimeter, planned for the LHCb Upgrade II experiment, used as a test case. First, we develop a lightweight autoencoder to compress a 32-sample timing readout, representative of that of the PicoCal, into a two-dimensional latent space. Second, we introduce a systematic, hardware-aware quantization strategy and show that the model can be reduced to 10-bit weights with minimal performance loss. Third, as a barrier to the adoption of on-detector ML is the lack of support for radiation-hard FPGAs in the High-Energy Physics community's standard ML synthesis tool, hls4ml, we develop a new backend for this library. This new back-end enables the automatic translation of ML models into High-Level Synthesis (HLS) projects for the Microchip PolarFire family of FPGAs, one of the few commercially available and radiation hard FPGAs. We present the synthesis of the autoencoder on a target PolarFire FPGA, which indicates that a latency of 25 ns can be achieved. We show that the resources utilized are low enough that the model can be placed within the inherently protected logic of the FPGA. Our extension to hls4ml is a significant contribution, paving the way for broader adoption of ML on FPGAs in high-radiation environments.",
    "title_zh": "在抗辐射FPGA上通过hls4ml实现低延迟机器学习",
    "abstract_zh": "本文首次展示了在FPGA上实现的可行、超高速且抗辐射的机器学习（ML）应用，该技术可应用于未来的高能物理实验。我们提出了三项主要贡献，并以计划用于LHCb升级二期实验的PicoCal量能器作为测试案例。首先，我们开发了一种轻量级自编码器，将代表PicoCal特性的32个采样时间读出数据压缩至二维潜在空间。其次，我们提出了一种系统性的、硬件感知的量化策略，证明模型权重可降至10位，同时仅带来极小的性能损失。第三，由于高能物理领域标准的ML综合工具hls4ml目前缺乏对抗辐射FPGA的支持，成为在探测器上部署ML的主要障碍，我们为此库开发了一个新的后端。该新后端能够将机器学习模型自动转换为Microchip PolarFire系列FPGA的高层次综合（HLS）项目，而PolarFire是目前少数可商用且具备抗辐射能力的FPGA之一。我们展示了该自编码器在目标PolarFire FPGA上的综合结果，表明可实现25纳秒的延迟。结果显示，所用资源足够少，使得该模型可部署于FPGA内部固有的保护逻辑区域中。我们对hls4ml的扩展是一项重要贡献，为在高辐射环境下更广泛地采用FPGA上的机器学习铺平了道路。"
  },
  {
    "date": "2026-02-17",
    "title": "SACS: A Code Smell Dataset using Semi-automatic Generation Approach",
    "authors": "Hanyu Zhang, Tomoji Kishi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15342v1",
    "source": "arXiv",
    "abstract": "Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past of decades, the research on code smell has received extensive attention. Especially the researches applied machine learning-technique have become a popular topic in recent studies. However, one of the biggest challenges to apply machine learning-technique is the lack of high-quality code smell datasets. Manually constructing such datasets is extremely labor-intensive, as identifying code smells requires substantial development expertise and considerable time investment. In contrast, automatically generated datasets, while scalable, frequently exhibit reduced label reliability and compromised data quality. To overcome this challenge, in this study, we explore a semi-automatic approach to generate a code smell dataset with high quality data samples. Specifically, we first applied a set of automatic generation rules to produce candidate smelly samples. We then employed multiple metrics to group the data samples into an automatically accepted group and a manually reviewed group, enabling reviewers to concentrate their efforts on ambiguous samples. Furthermore, we established structured review guidelines and developed a annotation tool to support the manual validation process. Based on the proposed semi-automatic generation approach, we created an open-source code smell dataset, SACS, covering three widely studied code smells: Long Method, Large Class, and Feature Envy. Each code smell category includes over 10,000 labeled samples. This dataset could provide a large-scale and publicly available benchmark to facilitate future studies on code smell detection and automated refactoring.",
    "title_zh": "SACS：一种基于半自动生成方法的代码异味数据集",
    "abstract_zh": "代码异味是软件重构中的一大挑战，它表明了潜在的设计或实现缺陷，可能降低软件的可维护性和可演化性。过去几十年间，代码异味的研究受到了广泛关注。尤其是近年来，将机器学习技术应用于代码异味研究已成为热门话题。然而，应用机器学习技术面临的一个最大挑战是高质量代码异味数据集的缺乏。手动构建此类数据集极为耗时费力，因为识别代码异味需要丰富的开发经验以及大量的时间投入。相比之下，自动生成的数据集虽然具有良好的可扩展性，但其标签可靠性通常较低，数据质量也难以保证。为应对这一挑战，本研究探索了一种半自动方法，以生成高质量的代码异味数据集。具体而言，我们首先应用一组自动生成规则，生成候选的异味样本。随后，通过多种度量指标将数据样本划分为自动接受组和人工审核组，使评审人员能够将精力集中于模糊或不确定的样本上。此外，我们制定了结构化的评审指南，并开发了标注工具以支持人工验证过程。基于所提出的半自动生成方法，我们构建了一个开源代码异味数据集 SACS，涵盖三种广泛研究的代码异味：长方法（Long Method）、大类（Large Class）和特征依恋（Feature Envy）。每个代码异味类别均包含超过10,000个已标注样本。该数据集可为未来代码异味检测与自动化重构研究提供大规模、公开可用的基准。"
  },
  {
    "date": "2026-02-17",
    "title": "A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings",
    "authors": "Simantika Bhattacharjee Dristi, Matthew B. Dwyer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15761v1",
    "source": "arXiv",
    "abstract": "With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation becomes critical. While prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in LLM-generated code refactorings. Unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. In a large-scale evaluation of six LLMs (CodeLlama, Codestral, StarChat2, Qwen-2.5, Olmo-3, and GPT-4o) across three datasets and two refactoring types, we find that LLMs show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. Our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. Collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in LLM-generated code refactorings, which remain prone to semantic divergence.",
    "title_zh": "基于差分模糊测试的大型语言模型生成代码重构功能等价性评估",
    "abstract_zh": "随着大型语言模型（LLMs）在自动化代码重构中的快速应用，评估并确保LLM生成的重构代码与原始实现之间的功能等价性变得至关重要。以往的研究通常依赖预定义的测试用例来评估正确性，而本文则采用差分模糊测试（differential fuzzing）来检测LLM生成代码重构的功能等价性。与基于测试用例的评估方法不同，基于差分模糊测试的等价性检查器无需预先设定测试用例，能够通过执行和比较数千个自动生成的测试输入，探索更大范围的输入空间。在对六种LLM（CodeLlama、Codestral、StarChat2、Qwen-2.5、Olmo-3和GPT-4o）在三个数据集和两种重构类型上的大规模评估中，我们发现LLM存在显著的改变程序语义的倾向，导致19%至35%的重构结果在功能上不等价。实验进一步表明，约21%的此类功能不等价重构未被所评估的三个数据集现有的测试套件所发现。总体而言，本研究的结果表明，依赖现有测试用例可能会高估LLM生成代码重构的功能等价性，而这些重构仍容易出现语义偏差。"
  },
  {
    "date": "2026-02-17",
    "title": "ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models",
    "authors": "Manav Nitin Kapadnis, Lawanya Baghel, Atharva Naik, Carolyn Rosé",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15758v1",
    "source": "arXiv",
    "abstract": "While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.",
    "title_zh": "ChartEditBench：评估多模态语言模型中的基于事实的多轮图表编辑",
    "abstract_zh": "尽管多模态大语言模型（MLLMs）在单轮图表生成任务中表现优异，但其在真实世界探索性数据分析中支持多轮交互的能力仍缺乏深入研究。在实际应用中，用户通过多轮交互逐步优化可视化效果，这一过程需要维持共同认知基础、追踪先前的修改记录，并适应不断变化的偏好。为此，我们提出了ChartEditBench，一个基于代码的增量式、视觉引导图表编辑基准，包含5,000条难度可控的修改链，以及经过严格人工验证的子集。与以往的一次性评估基准不同，ChartEditBench专注于评估模型在持续交互中保持上下文感知能力的编辑表现。我们进一步提出了一套稳健的评估框架，通过引入基于执行结果的准确性验证、像素级视觉相似性比对以及逻辑代码正确性检查，有效克服了传统“大语言模型作为裁判”（LLM-as-a-Judge）指标的局限性。对当前最先进的MLLMs进行的实验表明，在多轮交互场景下，由于错误累积和共享上下文的失效，模型性能显著下降，尽管在风格类修改上表现良好，但在数据驱动的变换操作中频繁出现执行失败。ChartEditBench为基于视觉语境、意图感知的多模态编程提供了一个极具挑战性的测试平台。"
  },
  {
    "date": "2026-02-17",
    "title": "TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models",
    "authors": "Chansung Park, Juyong Jiang, Fan Wang, Sayak Paul, Jiasi Shen, Jing Tang, Jianguo Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15449v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.",
    "title_zh": "TAROT：面向大语言模型代码生成的测试驱动与能力自适应课程强化微调",
    "abstract_zh": "大型语言模型（LLMs）正在改变编程范式，即所谓的“氛围编程”（vibe coding），但生成算法复杂且稳健的代码依然是一个关键挑战。激发LLMs的深度推理能力对于克服这一障碍至关重要。强化微调（Reinforcement Fine-Tuning, RFT）已成为应对这一需求的有前景策略。然而，现有大多数方法忽视了测试用例固有的异质性难度与粒度差异，导致奖励信号分布失衡，进而造成训练过程中的梯度更新偏差。为解决这一问题，我们提出了**测试驱动且能力自适应的课程强化微调**（Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning, TAROT）。TAROT为每个问题系统地构建了一个四层测试套件（基础、中级、复杂、边缘），为课程设计与评估提供受控的难度梯度。关键在于，TAROT将课程推进过程与原始奖励分数解耦，实现了基于模型能力的评估，并从一组课程策略中进行有原则的选择，而非依赖偶然的测试用例难度组合。这一设计促进了优化过程的稳定性，并提升了能力获取的效率。大量实验结果表明，RFT在代码生成中的最优课程与模型的内在能力密切相关：能力较弱的模型在“由易到难”的课程中获益更大，而能力较强的模型则在“由难到易”的课程中表现更优。TAROT提供了一种可复现的方法，能够根据模型能力自适应地调整课程设计，从而持续提升生成代码的功能正确性与鲁棒性。所有代码与数据均已公开，以促进复现并推动社区研究，详见：https://github.com/deep-diver/TAROT。"
  },
  {
    "date": "2026-02-17",
    "title": "What makes an Expert? Comparing Problem-solving Practices in Data Science Notebooks",
    "authors": "Manuel Valle Torre, Marcus Specht, Catharine Oertel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15428v1",
    "source": "arXiv",
    "abstract": "The development of data science expertise requires tacit, process-oriented skills that are difficult to teach directly. This study addresses the resulting challenge of empirically understanding how the problem-solving processes of experts and novices differ. We apply a multi-level sequence analysis to 440 Jupyter notebooks from a public dataset, mapping low-level coding actions to higher-level problem-solving practices. Our findings reveal that experts do not follow fundamentally different transitions between data science phases than novices (e.g., Data Import, EDA, Model Training, Visualization). Instead, expertise is distinguished by the overall workflow structure from a problem-solving perspective and cell-level, fine-grained action patterns. Novices tend to follow long, linear processes, whereas experts employ shorter, more iterative strategies enacted through efficient, context-specific action sequences. These results provide data science educators with empirical insights for curriculum design and assessment, shifting the focus from final products toward the development of the flexible, iterative thinking that defines expertise-a priority in a field increasingly shaped by AI tools.",
    "title_zh": "什么是专家？比较数据科学笔记本中的问题解决实践",
    "abstract_zh": "数据科学能力的培养需要掌握难以直接传授的隐性、过程导向型技能。本研究针对这一挑战，探讨了如何通过实证方法理解专家与新手在解决问题过程中的差异。我们对来自公开数据集的440个Jupyter笔记本进行了多层次序列分析，将底层编码行为映射到更高层次的问题解决实践。研究发现，专家与新手在数据科学各阶段（如数据导入、探索性数据分析、模型训练、可视化）之间的转换模式并无根本性差异。真正区分专家与新手的，是从问题解决视角出发的整体工作流程结构，以及在代码单元层面的精细动作模式。新手倾向于采用冗长、线性的流程，而专家则运用更短、更具迭代性的策略，通过高效且情境特定的动作序列来实现目标。这些结果为数据科学教育者提供了实证依据，有助于课程设计与评估，促使教学重点从最终成果转向培养灵活、迭代的思维方式——这正是在人工智能工具日益影响该领域的背景下，专家能力的核心特征。"
  },
  {
    "date": "2026-02-17",
    "title": "Fine-Tuning LLMs to Generate Economical and Reliable Actions for the Power Grid",
    "authors": "Mohamad Chehade, Hao Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.15350v1",
    "source": "arXiv",
    "abstract": "Public Safety Power Shutoffs (PSPS) force rapid topology changes that can render standard operating points infeasible, requiring operators to quickly identify corrective transmission switching actions that reduce load shedding while maintaining acceptable voltage behavior. We present a verifiable, multi-stage adaptation pipeline that fine-tunes an instruction-tuned large language model (LLM) to generate \\emph{open-only} corrective switching plans from compact PSPS scenario summaries under an explicit switching budget. First, supervised fine-tuning distills a DC-OPF MILP oracle into a constrained action grammar that enables reliable parsing and feasibility checks. Second, direct preference optimization refines the policy using AC-evaluated preference pairs ranked by a voltage-penalty metric, injecting voltage-awareness beyond DC imitation. Finally, best-of-$N$ selection provides an inference-time addition by choosing the best feasible candidate under the target metric. On IEEE 118-bus PSPS scenarios, fine-tuning substantially improves DC objective values versus zero-shot generation, reduces AC power-flow failure from 50\\% to single digits, and improves voltage-penalty outcomes on the common-success set. Code and data-generation scripts are released to support reproducibility.",
    "title_zh": "微调大语言模型以生成电力系统经济可靠的操作策略",
    "abstract_zh": "公共安全电力切断（PSPS）导致快速的网络拓扑变化，可能使标准运行点变得不可行，迫使运行人员迅速识别出能够减少负荷切除并维持可接受电压特性的纠正性输电切换操作。本文提出了一种可验证的多阶段适应流程，通过微调一个指令调优的大语言模型（LLM），从紧凑的PSPS场景摘要中生成仅包含“开断”操作的纠正性切换方案，并在明确的切换预算约束下进行优化。首先，监督微调将一个直流最优潮流混合整数线性规划（DC-OPF MILP）的“oracle”知识提炼为一种约束性动作语法，从而实现可靠解析与可行性验证。其次，直接偏好优化利用基于电压惩罚指标排序的交流潮流评估偏好对，进一步优化策略，引入超越直流模仿的电压感知能力。最后，采用“最佳N选一”（best-of-$N$）选择机制，在推理阶段通过选取目标指标下最优的可行候选方案，进一步提升性能。在IEEE 118节点PSPS场景测试中，微调显著提升了DC目标值，相比零样本生成，交流潮流失败率从50%降至个位数，并在常见成功集上改善了电压惩罚结果。代码与数据生成脚本已公开发布，以支持研究的可复现性。"
  },
  {
    "date": "2026-2-17",
    "title": "LLM and AI Agents for Autonomous Systems: A Survey of Applications, Datasets, and Security Challenges",
    "authors": "Mohamed Amine Ferrag, Abderrahmane Lakas, Norbert Tihanyi, Merouane Debbah",
    "publish": "IEEE Open Journal of Intelligent Transportation Systems",
    "url": "https://doi.org/10.1109/ojits.2026.3665677",
    "source": "IEEE",
    "abstract": "The rapid integration of Large Language Models (LLMs) into autonomous systems marks a significant transition from modular, rule-based approaches to reasoning-driven, agent-based, and multimodal intelligence. LLM reasoning enables adaptive decision-making, context-aware planning, and human-aligned interaction, while AI agents extend these capabilities into structured autonomy pipelines that coordinate perception, reasoning, and control. These advancements are particularly critical in safety-sensitive domains such as autonomous driving (AD) and unmanned aerial vehicles (UAVs). This survey provides a comprehensive review of LLM reasoning and AI agents across scenario generation, decision-making, multimodal perception, cooperative V2X interactions, and UAV swarm autonomy. We examine the role of simulation platforms and datasets, including CARLA, Apollo ADS, AirSim, nuScenes, DriveLM, and emerging synthetic environments, in supporting reproducible evaluation and benchmarking. In addition, we analyze pressing security and robustness challenges, including adversarial prompt injection, data poisoning, multimodal perturbations, privacy leakage, and vulnerabilities in cooperative agent communication. Finally, we propose future research directions including adversarially robust pipelines, hybrid symbolic LLM planning, secure multimodal fusion, privacy-preserving human alignment, distributed trust mechanisms for swarm autonomy, and optimized Drone-LLM deployment across on-drone, edge, and cloud environments. By unifying applications, datasets, benchmarks, reasoning, agents, and security, this survey establishes a roadmap for developing robust, trustworthy, and secure LLM-enabled autonomous systems.",
    "title_zh": "大语言模型与人工智能代理在自主系统中的应用：综述、数据集与安全挑战",
    "abstract_zh": "大型语言模型（LLM）在自主系统中的快速融合，标志着从模块化、基于规则的方法向以推理驱动、代理式及多模态智能的显著转变。LLM的推理能力实现了自适应决策、上下文感知规划以及与人类目标对齐的交互，而人工智能代理（AI agents）则将这些能力扩展为结构化的自主性流程，协调感知、推理与控制。这些进展在安全敏感领域（如自动驾驶（AD）和无人飞行器（UAV））尤为重要。本综述全面回顾了LLM推理与AI代理在场景生成、决策制定、多模态感知、协同V2X交互以及UAV集群自主性等方面的研究进展。我们探讨了仿真平台与数据集（包括CARLA、Apollo ADS、AirSim、nuScenes、DriveLM以及新兴的合成环境）在支持可复现评估与基准测试中的作用。此外，我们分析了当前紧迫的安全与鲁棒性挑战，包括对抗性提示注入、数据投毒、多模态扰动、隐私泄露以及协同代理通信中的漏洞。最后，我们提出了未来的研究方向，包括对抗鲁棒性流程、符号化与LLM融合的混合规划、安全的多模态融合、隐私保护的人类对齐机制、用于集群自主的分布式信任机制，以及在机载、边缘与云端环境之间优化的无人机-LLM部署方案。通过整合应用、数据集、基准测试、推理、代理与安全，本综述为构建稳健、可信且安全的LLM赋能自主系统提供了清晰的发展路线图。"
  },
  {
    "date": "2026-2-17",
    "title": "Enhance Tool Invocation with Large Language Models through Cluster-Augmented Demonstration Sampling",
    "authors": "Guoliang Hu, Liang Qian, Houlong Xiong",
    "publish": "2025 IEEE 4th International Conference on Computing, Communication, Perception and Quantum Technology (CCPQT)",
    "url": "https://doi.org/10.1109/ccpqt66408.2025.11383431",
    "source": "IEEE",
    "abstract": "With the rapid development of large language models (LLMs), their integration with external tools has become a key research area, greatly enhancing their applicability in real-world scenarios. However, a core challenge lies in enabling LLMs to accurately and efficiently invoke these tools while adhering to precise structured output formats. Prevailing approaches, which predominantly depend on instruction tuning and reinforcement learning, often overlook the potential of in-context learning and exhibit limited generalization across diverse tools and contexts, underscoring the demand for more adaptable and robust solutions. To tackle this issue, we propose a novel framework that enhances tool invocation by combining clustering and retrieval strategy, namely cluster-augmented demonstration retrieval (CA-DR) mechanism that significantly improves the tool invocation accuracy, leading to an average 25.8% improvement in coarse-grained accuracy over baselines on ToolACE and BFCL benchmarks. By considering both the relevance and diversity of demonstrations, our approach effectively improves the few-shot capabilities of LLMs. Evaluation across multiple different types and scales of LLMs show that our method achieves relatively high tool invocation accuracy while maintaining high efficiency.",
    "title_zh": "通过聚类增强的示范采样提升大型语言模型的工具调用能力",
    "abstract_zh": "随着大型语言模型（LLMs）的快速发展，其与外部工具的集成已成为一个关键研究方向，极大地提升了模型在现实场景中的应用能力。然而，一个核心挑战在于如何使LLMs在遵循精确结构化输出格式的前提下，准确且高效地调用这些工具。现有的主流方法主要依赖指令微调和强化学习，往往忽视了上下文学习（in-context learning）的潜力，且在不同工具和场景下的泛化能力有限，凸显出对更灵活、更鲁棒解决方案的迫切需求。为应对这一问题，我们提出了一种新颖的框架，通过结合聚类与检索策略，引入了聚类增强型示范检索（Cluster-Augmented Demonstration Retrieval, CA-DR）机制，显著提升了工具调用的准确性。在ToolACE和BFCL基准测试中，该方法相较于基线模型平均提升了25.8%的粗粒度准确率。通过同时考虑示范样本的相关性与多样性，我们的方法有效增强了LLMs的少样本学习能力。在多种不同类型和规模的LLMs上的评估结果表明，该方法在保持高效率的同时，实现了相对较高的工具调用准确率。"
  },
  {
    "date": "2026-2-17",
    "title": "Bayesian Network-Based Anomaly Detection for SQL Injection Attacks in HTTP Payloads",
    "authors": "Nurul Afifah, Deni Danuarta, Deris Stiawan, Dendi Renaldo Permana, Tri Wanda Septian, Ika Putri Aprilia",
    "publish": "2025 International Conference on Artificial Intelligence and Technological Solutions (ICAITech)",
    "url": "https://doi.org/10.1109/icaitech66481.2025.11387505",
    "source": "IEEE",
    "abstract": "SQL Injection (SQLi) is one of the most critical cyberattacks that exploits vulnerabilities in the web application layer, particularly through database query manipulation. Preventing these attacks is crucial for resilient digital infrastructure, a key target in the Sustainable Development Goals (SDGs), particularly SDG 9. This attack can result in data theft, authentication bypass, and even system takeover. SQLi attack techniques continue to evolve, requiring accurate and adaptive detection methods. One promising approach is the use of Bayesian Networks, which can model probabilistic relationships between attack patterns and normal traffic. SQL Injection attack patterns are analyzed through HTTP payloads at the application layer, resulting in two main categories: query character-based patterns and percent encoding patterns. Bayesian Networks are implemented by calculating the probability of URI character occurrence using the Python programming language. Test results demonstrate high detection performance, with a True Positive Rate (TPR) of 99.3% in optimal testing and a False Positive Rate (FPR) of $0 \\%$. The confusion matrix reveals system accuracy ranging from $82.7 \\%$ to $99.7 \\%$, with precision at $100 \\%$. However, variations in TPR occur due to differences in query complexity, such as in the seventh test ($64.4 \\%$) which included all types of attacks. This finding demonstrates the effectiveness of Bayesian Networks in detecting SQL Injection by leveraging dependencies between variables, although challenges remain with certain queries that resemble normal traffic.",
    "title_zh": "基于贝叶斯网络的HTTP载荷中SQL注入攻击异常检测",
    "abstract_zh": "SQL注入（SQLi）是利用Web应用层漏洞，特别是通过操纵数据库查询而引发的最严重的网络攻击之一。防范此类攻击对于构建稳健的数字基础设施至关重要，而这一目标正是可持续发展目标（SDGs）中的关键内容，尤其是SDG 9。SQL注入攻击可能导致数据窃取、身份认证绕过，甚至系统完全被控制。随着攻击技术的不断演进，需要采用准确且具备适应性的检测方法。一种有前景的解决方案是使用贝叶斯网络（Bayesian Networks），其能够建模攻击模式与正常流量之间的概率关系。通过对应用层HTTP载荷中的SQL注入攻击模式进行分析，可将其分为两大类：基于查询字符的模式和百分号编码（percent encoding）模式。本研究采用Python编程语言实现贝叶斯网络，通过计算URI字符出现的概率来识别异常行为。测试结果表明，系统在最优条件下具有极高的检测性能，真阳性率（TPR）达到99.3%，误报率（FPR）为0%。混淆矩阵显示系统整体准确率在82.7%至99.7%之间，且精确率（precision）达到100%。然而，由于查询复杂度的差异，真阳性率在不同测试中有所波动，例如第七次测试中因包含所有类型的攻击，TPR降至64.4%。这一发现表明，贝叶斯网络通过利用变量间的依赖关系，在检测SQL注入攻击方面具有显著有效性，但对某些与正常流量高度相似的查询仍存在检测挑战。"
  },
  {
    "date": "2026-2-17",
    "title": "Innovative Embedded System Architecture for Secure Voting Machines Built on the Blockchain: Capabilities for Real-Time Verification and Difficulty Detection",
    "authors": "Anand Raj I, Dhandapani Samiappan, D. Kalaiyarasi, Riham Alkabbji, G. John Samuel Babu, G. Karthikeyan",
    "publish": "2025 IEEE Pune Section International Conference (PuneCon)",
    "url": "https://doi.org/10.1109/punecon67554.2025.11378616",
    "source": "IEEE",
    "abstract": "- In a time of increased focus on the integrity of elections, the intersection of embedded technology and blockchain algorithms provides a powerful new means of implementing transparent, secure and resilient voting systems. This paper is dedicated towards the design of a novel embedded system structure for the secure EVM (Electronic Voting Machine) system, using a blockchain for non-repudiation of data and distributed entity verification. The design approach includes a multi-tiered security posture from hardware level tamper suppression, on the fly vote verification, and dynamic anomaly detection with embedded intelligence. At the heart of the system, a light-weight high-performance embedded controller combined with a secure element and cryptographical co-processor guarantees secure data processing, identity authentication and system integrity. Votes are tokenized and represented as transactions on a blockchain, which preserves end-to-end verification while preserving individual voter secrecy. Its underlying architecture leverages a hybrid consensus mechanism especially adjusted for private or consortium blockchain network to scale out the trustful voting recording and counting. Instant verification is secured with smart contracts and Merkle proof verification and every validated vote is consistently recorded and immutable. Moreover, the machine learning module is contained in the firmware for detecting hardness. This module observes and learns user behavior pattern, user reviewing behavior pattern and packet processing performance over time in order to raise alerts about potential threats such as hardware breakdowns, unauthorized entry attempts or nonconforming voting behaviors, etc., and take actions in order to prevent it. The in-built AI also learns and evolves with regional/ jurisdictional voting patterns, to reduce false positives and increase sensitivity to electoral irregularities. It was experimentally validated in a prototype deployed in an ARM Cortex-M7 embedded board connected with Hyperledger Fabric, displaying real-time transaction throughput fit out for medium-sized election scale.",
    "title_zh": "基于区块链的创新型嵌入式系统架构：用于安全投票机，具备实时验证与困难检测能力",
    "abstract_zh": "在选举诚信日益受到关注的时代，嵌入式技术与区块链算法的结合为构建透明、安全且具有韧性的投票系统提供了强大的新手段。本文致力于设计一种新型嵌入式系统架构，用于安全的电子投票机（EVM）系统，利用区块链实现数据不可否认性及分布式实体验证。该设计采用多层次安全策略，涵盖硬件级防篡改、实时投票验证以及嵌入式智能驱动的动态异常检测。系统核心由轻量级高性能嵌入式控制器、安全元件及密码协处理器组成，确保数据处理安全、身份认证可靠以及系统完整性。选票被转化为代币，并以交易形式记录在区块链上，既保障端到端可验证性，又维护选民个人隐私。其底层架构采用专为私有链或联盟链网络优化的混合共识机制，实现可扩展的信任投票记录与计票功能。通过智能合约与默克尔证明验证，系统实现即时验证，所有经验证的选票均被一致记录且不可篡改。此外，固件中集成的机器学习模块用于检测异常行为，该模块可长期观察并学习用户行为模式、用户审查行为模式以及数据包处理性能，从而对潜在威胁（如硬件故障、非法访问尝试或非正常投票行为等）发出预警，并采取相应措施予以防范。内置人工智能还能根据区域或管辖范围的投票模式持续学习与进化，有效降低误报率，同时提升对选举异常情况的敏感度。该系统已在基于ARM Cortex-M7嵌入式平台、连接Hyperledger Fabric的原型系统上完成实验验证，展现出适用于中等规模选举场景的实时交易吞吐能力。"
  },
  {
    "date": "2026-2-17",
    "title": "A Hierarchical Address Decomposition Method for Multidimensional Array Access Optimization",
    "authors": "Jingming Gou, Xianbo He",
    "publish": "2025 6th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)",
    "url": "https://doi.org/10.1109/icaice68195.2025.11382376",
    "source": "IEEE",
    "abstract": "Multidimensional array access is a primary performance bottleneck in High-Performance Computing (HPC). Modern compilers typically flatten multi-dimensional index computations into a single offset expression, thereby obscuring the hierarchical invariance inherent in the address calculation that corresponds to the loop nesting structure. This flattening prevents standard optimizations like Loop-Invariant Code Motion (LICM) from being effective. This paper proposes a Hierarchical Address Decomposition (HAD) method, which reconstructs address computations in LLVM into a chained intermediate representation that is isomorphic to the loop nest. This transformation explicitly exposes pointer-level invariants, enabling them to be automatically hoisted by the standard LICM pass. Furthermore, this paper introduces a model-guided promotion strategy that leverages a cost model to balance the benefits of optimization against the overhead of the transformation. Experimental results on SPEC CPU bench-marks (481.wrf and 621.wrf_s) demonstrate that HAD achieves up to a 1.08x speedup, validating its effectiveness and portability for multidimensional array access optimization.",
    "title_zh": "一种用于多维数组访问优化的分层地址分解方法",
    "abstract_zh": "多维数组访问是高性能计算（HPC）中的主要性能瓶颈。现代编译器通常将多维索引计算展开为单一偏移表达式，从而掩盖了地址计算中与循环嵌套结构相对应的层次不变性。这种展开使得标准优化技术（如循环不变代码外提，LICM）难以发挥作用。本文提出了一种层次化地址分解（Hierarchical Address Decomposition, HAD）方法，该方法在LLVM中将地址计算重构为一种链式中间表示，其结构与循环嵌套同构。该转换显式暴露了指针级别的不变量，使得标准LICM优化能够自动将其提升。此外，本文还引入了一种基于模型的提升策略，利用成本模型在优化收益与转换开销之间取得平衡。在SPEC CPU基准测试（481.wrf 和 621.wrf_s）上的实验结果表明，HAD方法最高可实现1.08倍的加速，验证了其在多维数组访问优化中的有效性与可移植性。"
  },
  {
    "date": "2026-2-17",
    "title": "Mineuron: Minimal Neuron Realization For Fast Fpga Snn Inference Using Logic Optimization",
    "authors": "Daniel Windhager, Lothar Ratschbacher, Bernhard A. Moser, Michael Lunglmayr",
    "publish": "2025 IEEE International Conference on Image Processing Workshops (ICIPW)",
    "url": "https://doi.org/10.1109/icipw68931.2025.11385869",
    "source": "IEEE",
    "abstract": "We introduce MiNeuron as a solution for achieving efficient inference of Spiking Neural Networks (SNNs) on FPGA platforms. Built upon the Leaky Integrate-and-Fire neuron model and incorporating sparse optimization during training, MiNeuron enables efficient use of an FPGA’s on-board lookup tables. An SNN is implemented in Python using the PyTorch library, with custom modifications designed to support sparse learning. The learned weights are mapped to logic tables by using logic optimization at synthesis time. Our findings show that this approach enables the FPGAs used in the “Digit Recognition Low Power and Speed Challenge” of this conference to achieve approximately 3.9 million inferences per second per Watt, all while satisfying the required accuracy target of 97.5%.",
    "title_zh": "Mineuron：基于逻辑优化的极简神经元实现，用于FPGA上快速SNN推理",
    "abstract_zh": "我们提出MiNeuron作为在FPGA平台上实现脉冲神经网络（SNN）高效推理的解决方案。MiNeuron基于漏电积分-发放（Leaky Integrate-and-Fire）神经元模型，并在训练过程中引入稀疏优化，从而高效利用FPGA片上查找表资源。我们使用PyTorch库以Python实现SNN，并设计了定制化修改以支持稀疏学习。通过在综合阶段进行逻辑优化，将学习得到的权重映射至逻辑表。实验结果表明，该方法使本会议“低功耗与高速度数字识别挑战”所用FPGA实现了每瓦特约390万次推理，同时满足97.5%的准确率要求。"
  },
  {
    "date": "2026-2-17",
    "title": "DSVA: An Iterative Refinement Multi-Agent Framework for NL-to-MTL Translation",
    "authors": "Jinhui Lyu, Ye Wu, Yong Cai",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3665806",
    "source": "IEEE",
    "abstract": "Safety-critical cyber-physical systems require rigorously verifiable specifications, yet natural language (NL) requirements introduce ambiguity and defects. While Metric Temporal Logic (MTL) expresses complex real-time constraints, manual NL-to-MTL translation is labor-intensive and error-prone. Existing single-agent LLM approaches like TR2MTL struggle with semantic ambiguity and lack automated refinement mechanisms. This paper proposes DSVA (Deconstruct-Synthesize-Verify-Analyze), a multi-agent framework with diagnostic-driven iterative refinement. DSVA deploys specialized agents: Deconstruct parses NL into semantic sketches; Synthesize generates MTL formulae; Verify controls iteration via back-translation and similarity checking; and Analyze diagnoses failures to guide refinement. A phase-specific Retrieval-Augmented Generation (RAG) mechanism enhances contextual understanding. Evaluation on the TR2MTL dataset across four LLMs shows DSVA achieves 85.6% mean accuracy, with GPT-4 reaching 90.9%, a 17.99 percentage point improvement over the TR2MTL baseline (72.91%). Comprehensive ablation studies reveal synergistic component interactions: RAG contributes +15.1% when combined with iteration, iterative refinement contributes +14.4% when combined with RAG, yielding a +7.6pp synergy bonus beyond additive effects (14.3pp→21.9pp). Even the weakest full DSVA configuration (Gemini-2.5-flash: 75.8%) surpasses the baseline. The framework’s consistent cross-model performance gains validate its architectural benefits: specialized agent division of labor, automated iteration control, and diagnostic refinement, providing a potentially more reliable solution for automated requirements formalization in safety-critical systems.",
    "title_zh": "DSVA：一种用于自然语言到多时序逻辑翻译的迭代精炼多智能体框架",
    "abstract_zh": "安全关键的网络物理系统需要严格可验证的规范，然而自然语言（NL）需求容易引入歧义和缺陷。尽管度量时序逻辑（MTL）能够表达复杂的实时约束，但手动将自然语言转换为MTL既费时又容易出错。现有的单智能体大语言模型（LLM）方法，如TR2MTL，在处理语义歧义方面表现不佳，且缺乏自动化的优化机制。本文提出DSVA（解构-合成-验证-分析）框架，一种基于诊断驱动的多智能体迭代优化架构。DSVA部署了多个专用智能体：解构（Deconstruct）将自然语言解析为语义草图；合成（Synthesize）生成MTL公式；验证（Verify）通过反向翻译和相似性检查控制迭代过程；分析（Analyze）诊断失败原因，指导后续优化。该框架采用面向各阶段的检索增强生成（RAG）机制，以提升上下文理解能力。在TR2MTL数据集上对四种LLM的评估表明，DSVA平均准确率达到85.6%，其中GPT-4达到90.9%，相比TR2MTL基线（72.91%）提升了17.99个百分点。全面的消融实验揭示了各组件间的协同效应：RAG与迭代结合带来+15.1%的性能提升，迭代与RAG结合贡献+14.4%，二者共同作用产生+7.6个百分点的协同增益（从加法效应的14.3个百分点提升至21.9个百分点）。即使是最弱的DSVA配置（Gemini-2.5-flash：75.8%）也优于基线。该框架在不同模型间表现出一致的性能提升，验证了其架构优势：专用智能体的分工协作、自动化的迭代控制以及基于诊断的优化机制，为安全关键系统中的自动化需求形式化提供了一种更具可靠性与可扩展性的解决方案。"
  },
  {
    "date": "2026-2-17",
    "title": "Blockchain-Based Smart Contracts in Insurance: Enhancing Transparency, Security, and Efficiency in Policy Management",
    "authors": "B. Jeyaprabha, Anthony Rose, Rachit Jain, Animesh Pratap Singh, Roshna Ravindran, L.S. Swasthimathi",
    "publish": "2025 2nd International Conference on Artificial Intelligence and Knowledge Discovery in Concurrent Engineering (ICECONF)",
    "url": "https://doi.org/10.1109/iceconf65644.2025.11379384",
    "source": "IEEE",
    "abstract": "The paper discusses the use of smart contracts based on blockchain in the insurance sector in terms of improving transparency, security, and efficiency in the process of policy management. In the case of the automated claims processing through the application of smart contracts, the study shows how blockchain technology can simplify the claims verification and approval procedure with the involvement of humans and mistakes minimized. The presence of smart contracts with set conditions makes smart contract transparent as everyone can be able to access unchangeable terms of the contract and the blockchain is decentralized, preventing fraud and data integrity. The study utilizes the Ethereum smart contracts, which are created with the help of Solidity program language, as the main instrument of automatizing and insuring processes. It is this example of a combination of blockchain technology and automated processes that will result in faster claims processing, reduced administrative expenses, and increased customer satisfaction. Generally, and throughout the paper, the challenges that blockchain-based solutions can address have the capacity to enhance the insurance industry in the context of enhancing the efficiency of the operations, as well as increasing trust due to transparency and security of the processes involved.",
    "title_zh": "基于区块链的智能合约在保险业的应用：提升保单管理的透明度、安全性和效率",
    "abstract_zh": "本文探讨了基于区块链的智能合约在保险行业中的应用，旨在提升保单管理过程中的透明度、安全性和效率。在通过智能合约实现自动理赔处理的案例中，研究展示了区块链技术如何在减少人为参与和降低错误率的情况下，简化理赔审核与审批流程。智能合约通过预设条件运行，使合约内容透明可查，所有参与者均可访问不可篡改的合同条款，而区块链的去中心化特性则有效防止欺诈行为，保障数据完整性。本研究主要采用以太坊智能合约，借助Solidity编程语言进行开发，作为实现流程自动化与保险保障的核心工具。这一区块链技术与自动化流程相结合的实例，将显著加快理赔处理速度，降低行政成本，并提升客户满意度。总体而言，本文强调了基于区块链的解决方案在提升保险行业运营效率、增强信任度方面所具备的巨大潜力，其核心优势在于流程的透明性与安全性。"
  },
  {
    "date": "2026-2-17",
    "title": "Design of a Secure Systolic Array matrix multiplication Accelerator for Neural Network Based on Merkle Tree Verification",
    "authors": "Qiuyan Xu, Xiang Wu, Xiang Li, Junyu Tang, Hao Guo, Wentao Xu",
    "publish": "2025 6th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)",
    "url": "https://doi.org/10.1109/icaice68195.2025.11382429",
    "source": "IEEE",
    "abstract": "Systolic array accelerators, a key implementation platform for modern neural networks, are vulnerable to malicious attacks such as directed bit flips and fault injections. These attacks compromise model weights and computation processes, causing severe degradation in model accuracy. To address this security risk, a secure systolic array architecture is proposed, integrating a Merkle-tree-based verification mechanism. The architecture incorporates hardware-level cryptographic techniques, to ensure the real-time integrity of input data, model weights, and all intermediate and final computation results. The proposed design maintains robust security while achieving acceptable performance and hardware costs. Compared with a baseline architecture lacking security features, computational latency increases by 3.68%, while hardware area and power consumption increases remain within 62.9% and 23%, respectively. This design provides a hardware foundation for building Trustworthy Artificial Intelligence systems.",
    "title_zh": "基于默克尔树验证的神经网络安全流水线阵列矩阵乘法加速器设计",
    "abstract_zh": "脉动阵列加速器作为现代神经网络的关键实现平台，易受到定向位翻转和故障注入等恶意攻击。这些攻击会破坏模型权重和计算过程，导致模型精度严重下降。为应对这一安全风险，本文提出一种安全的脉动阵列架构，集成了基于Merkle树的验证机制。该架构融合了硬件级密码学技术，确保输入数据、模型权重以及所有中间和最终计算结果的实时完整性。所提出的方案在保持强大安全性的同时，实现了可接受的性能和硬件开销。与缺乏安全特性的基线架构相比，计算延迟仅增加3.68%，而硬件面积和功耗的增加分别控制在62.9%和23%以内。该设计为构建可信人工智能系统提供了坚实的硬件基础。"
  },
  {
    "date": "2026-2-17",
    "title": "Two Hardware Trojan Detection Algorithms: Based on Image Features or Erosion",
    "authors": "Chao Yu, Chen Sun, Liwei Wang",
    "publish": "2025 5th International Conference on Measurement Control and Instrumentation (MCAI)",
    "url": "https://doi.org/10.1109/mcai66356.2025.11381963",
    "source": "IEEE",
    "abstract": "Hardware Trojans covertly implanted in chip supply chains pose significant security threats to critical systems. Addressing the limitations of existing methods that rely on golden chips and complex testing environments, this paper proposes two image processing-based algorithms for comparing layout and SEM images. The first method uses connected region feature extraction with Hungarian algorithm matching to identify structural anomalies. The second method applies iterative morphological erosion to difference images to expose suspicious regions. Experiments on 20,000 image pairs from the REFICS dataset (90nm node) demonstrate that both algorithms achieve high detection accuracy (96.85% and 94.2%) with strong batch processing capabilities. The feature extraction method offers superior accuracy and speed, while the erosion-based method provides better noise resistance. This work enables practical, large-scale hardware Trojan screening for engineering applications.",
    "title_zh": "两种硬件木马检测算法：基于图像特征或腐蚀方法",
    "abstract_zh": "嵌入在芯片供应链中的硬件木马对关键系统构成重大安全威胁。针对现有依赖于“金片”和复杂测试环境的方法所存在的局限性，本文提出两种基于图像处理的布局图与扫描电子显微镜（SEM）图像比对算法。第一种方法采用连通区域特征提取结合匈牙利算法匹配，以识别结构异常；第二种方法则对差分图像进行迭代形态学腐蚀，以暴露可疑区域。在REFICS数据集（90nm工艺节点）的20,000对图像上进行的实验表明，两种算法均实现了较高的检测准确率（分别为96.85%和94.2%），并具备强大的批量处理能力。特征提取方法在准确率和处理速度方面表现更优，而基于腐蚀的方法则展现出更强的抗噪能力。本研究为工程应用提供了切实可行、可大规模实施的硬件木马筛查方案。"
  },
  {
    "date": "2026-2-17",
    "title": "GARNETT: Graph-based Fast yet Accurate Post-Placement Toggle Rate Prediction Model from RTL without Technology-dependent Logic Synthesis and Placement",
    "authors": "M B Rakesh, Anant Terkar, Pabitra Das, Amit Acharyya",
    "publish": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
    "url": "https://doi.org/10.1109/tcad.2026.3665686",
    "source": "IEEE",
    "abstract": "We propose a novel high-speed yet accurate GrAph-assisted post-placement prediction model that predicts the average Toggle rate of ASIC Design from RTL, skipping placEmenT, logic syNthesis and gate-level simulation. We present an efficient graph representation learning solution by sufficiently training the proposed GARNETT using a custom features-assisted graph neural network (GNN) architecture on the unbiased distribution of logic cells in translated technology-independent (TTI) netlist, achieved by bypassing technology-dependent logic synthesis and placement. This unbiased training ensures GARNETT’s efficient learning to propagate the toggle rates with our GNN by effectively embedding the feature values as vectors on each logic cell, unlike the biased training with post-synthesized netlist files in state-of-the-art (SoA) architectures, GRANNITE, Method, and GRIPT. The proposed GARNETT achieves a mean improvement in accuracy of 23.31%, 4.47%, 2.1% and 2.74% higher than the commercial RTL toggle rate estimation tool, GRANNITE, SoA Method, and GRIPT in predicting the average toggle rate, respectively. The proposed GARNETT is faster than the commercial placement-level toggle rate estimation tool, GRANNITE, SoA Method, and GRIPT, in inference latency, with a mean improvement of 6.08X, 4.05X, 4.09X, and 4.03X, respectively.",
    "title_zh": "GARNETT：一种基于图的快速且准确的RTL级后布局切换率预测模型，无需依赖工艺相关的逻辑综合与布局",
    "abstract_zh": "我们提出了一种新颖的高速且高精度的图辅助（GrAph-assisted）布局后切换率预测模型，该模型能够直接从RTL层面预测ASIC设计的平均切换率，跳过了布局（placement）、逻辑综合（logic synthesis）和门级仿真（gate-level simulation）等传统步骤。我们通过在转换后的与工艺无关（TTI）网表中逻辑单元的无偏分布上，利用一种定制特征辅助的图神经网络（GNN）架构，充分训练所提出的GARNETT模型，从而实现高效的图表示学习。该无偏训练方式避免了依赖工艺的逻辑综合与布局过程，使GARNETT能够通过GNN有效将各逻辑单元的特征值嵌入为向量，从而实现切换率的准确传播。这与现有先进（SoA）架构（如GRANNITE、Method和GRIPT）中使用布局后综合网表进行有偏训练的方式形成鲜明对比。实验结果表明，所提出的GARNETT在预测平均切换率方面，相较于商用RTL切换率估算工具GRANNITE、SoA Method和GRIPT，分别实现了23.31%、4.47%、2.1%和2.74%的平均精度提升。此外，在推理延迟方面，GARNETT比商用布局级切换率估算工具GRANNITE、SoA Method和GRIPT分别快6.08倍、4.05倍、4.09倍和4.03倍，展现出显著的性能优势。"
  },
  {
    "date": "2026-2-17",
    "title": "Agentic AI-Driven Decision Orchestration System for Real-Time Project Coordination",
    "authors": "P. Harini, Bhavani Thota, Shamim, Banitamani Mallik, V.S. Prasad Kandi, Maddikera Kalyan Chakravarthi",
    "publish": "2025 2nd International Conference on Artificial Intelligence and Knowledge Discovery in Concurrent Engineering (ICECONF)",
    "url": "https://doi.org/10.1109/iceconf65644.2025.11379478",
    "source": "IEEE",
    "abstract": "With a recent development in the technology field for artificial intelligence (AI) speed and optimization, agentic software capable of autonomous decision, and self-determining and auto-coordinating (or at least similarly supposed) software have been made capable of being statistically possible. The scope of this research is to present project coordination Agentic AI for project management Decision Orchestration System (dynamic and complex project triangulation in real-time environment). The hybrid decision intelligence (DDI) of system includes deep reinforcement learning for the optimizer; transformer-based adaptive communication for mobile agents, knowledge graph for being aware of and mapping algorithm for centralized neural network system, prediction of sub-system of digital twins, GNNs and expert; sub-system prediction. The solution offers proactive risk management - remote control scheduling and live remote operations of distributed personnel and loT-based infrastructure. The reason depends partly on this solution being explained, and the fact that it is fully transparent and incredibly scalable thanks to its continuous learning system. Specifically, the orchestration platform creates a fundamental shift in how projects are being executed because it is built upon efficiency, agility, and intelligent automation for more mature organizations",
    "title_zh": "面向实时项目协调的智能代理AI驱动决策编排系统",
    "abstract_zh": "随着人工智能（AI）技术在速度与优化方面的最新进展，具备自主决策、自我确定及自动协调能力（或至少具备类似功能）的代理型软件已具备了统计上的可行性。本研究的范围旨在提出一种项目协调型代理AI，用于项目管理决策编排系统（在实时环境中实现动态且复杂的项目三角化）。该系统的混合决策智能（DDI）包括：用于优化器的深度强化学习；基于Transformer的移动代理自适应通信；用于感知与映射的知识图谱及集中式神经网络系统的算法；数字孪生子系统的预测功能；图神经网络（GNNs）与专家系统的子系统预测。该解决方案提供主动式风险管理，支持对分布式人员及基于物联网（IoT）的基础设施进行远程调度与实时远程操作。其优势部分源于该方案的透明性，以及得益于持续学习系统所带来的惊人可扩展性。具体而言，该编排平台从根本上改变了项目执行方式，因为它建立在效率、敏捷性与智能自动化基础之上，为更为成熟的组织提供了强有力的支持。"
  },
  {
    "date": "2026-2-17",
    "title": "DeepSeek Models in STEM Education: Capabilities, Applications, and Challenges",
    "authors": "Fnu Neha, Deepshikha Bhati",
    "publish": "2025 International Workshop on Artificial Intelligence and Education (WAIE)",
    "url": "https://doi.org/10.1109/waie67422.2025.11381083",
    "source": "IEEE",
    "abstract": "The application of artificial intelligence (AI) in STEM education has introduced new capabilities for enhancing structured reasoning, mathematical problem-solving, and programming instruction. General-purpose large language models (LLMs) lack domain-specific precision and pedagogical alignment. This paper explores the applications of DeepSeek models (DeepSeek R1, DeepSeek Math, and DeepSeek Coder) in addressing these limitations by integrating structured logic, stepwise reasoning, and contextualized programming guidance. DeepSeek models support learning by offering adaptive feedback, iterative guidance, and human-like reasoning. This study evaluates their capabilities in improving educational outcomes while addressing key challenges such as overreliance, algorithmic bias, and skill fragmentation. Additionally, it discusses policies for responsible AI integration and explores future directions, including AIdriven personalization, collaborative AI-human instruction, and interdisciplinary applications.",
    "title_zh": "深度求索模型在STEM教育中的能力、应用与挑战",
    "abstract_zh": "人工智能（AI）在STEM教育中的应用为提升结构化推理、数学问题解决和编程教学带来了新的能力。通用型大语言模型（LLMs）缺乏领域特定的精确性与教学上的契合度。本文探讨了DeepSeek系列模型（DeepSeek R1、DeepSeek Math 和 DeepSeek Coder）在克服这些局限性方面的应用，通过整合结构化逻辑、分步推理以及情境化的编程指导，有效提升学习效果。DeepSeek模型通过提供自适应反馈、迭代式引导和类人推理能力，支持个性化学习。本研究评估了这些模型在改善教育成果方面的能力，同时针对过度依赖、算法偏见和技能碎片化等关键挑战进行了讨论。此外，文章还探讨了负责任的AI整合政策，并展望了未来发展方向，包括AI驱动的个性化学习、人机协同教学以及跨学科应用。"
  },
  {
    "date": "2026-2-17",
    "title": "Smart Contract Security - A Comprehensive Evaluation of Deep Learning based Mechanisms for Smart Contract Vulnerability Detection",
    "authors": "Deepa Mishra, Shraddha Phansalkar",
    "publish": "2025 IEEE International Conference on Blockchain and Distributed Systems Security (ICBDS)",
    "url": "https://doi.org/10.1109/icbds67396.2025.11377305",
    "source": "IEEE",
    "abstract": "Widespread adoption of Blockchain Technology has emphasized smart contracts as vital units of digital transactions. In the brief history of smart contracts, significant losses have occurred owing to unexplained vulnerabilities in blockchain-loaded contracts. Smart contract vulnerabilities endanger blockchain technology's viability and confidence. Blockchain-based applications rely on smart contracts to automate and trustlessly execute agreements. Their immutable and self-executing nature leaves them vulnerable to security vulnerabilities, which have caused major financial losses in decentralized platforms. Traditional static and symbolic analysis tools often miss sophisticated or obfuscated vulnerabilities, resulting in insufficient coverage or excessive false positives. These restrictions led the investigation of Deep Learning (DL) algorithms for detecting vulnerabilities in smart contract crucial since they can learn complicated patterns from code representations without manual feature engineering. Deep learning based methods for detecting vulnerabilities in smart contracts are thoroughly evaluated. We rigorously assess state-of-the-art DL models including BiLSTM, BiGRU, CNNLSTM, GCN, and CodeBERT using publicly available dataset. We provide a taxonomy of DL-based detection techniques and standardize performance criteria including accuracy, F1-score, and detection latency. Experimental results show model architecture trade-offs in detection, computational efficiency, and generalization.",
    "title_zh": "智能合约安全——基于深度学习的智能合约漏洞检测机制综合评估",
    "abstract_zh": "区块链技术的广泛采用凸显了智能合约作为数字交易核心单元的重要性。在智能合约短暂的发展历史中，由于区块链加载的合约中存在难以解释的漏洞，已造成重大损失。智能合约中的漏洞威胁着区块链技术的可行性与可信度。基于区块链的应用依赖智能合约来自动化且无需信任地执行协议。其不可篡改和自动执行的特性使其容易受到安全漏洞的影响，已在去中心化平台中引发重大财务损失。传统的静态分析和符号执行工具往往无法发现复杂或经过混淆的漏洞，导致检测覆盖率不足或误报率过高。这些局限性促使研究者将深度学习（DL）算法应用于智能合约漏洞检测，因为深度学习能够从代码表示中自动学习复杂模式，而无需人工特征工程。本文对基于深度学习的智能合约漏洞检测方法进行了全面评估，使用公开数据集对最先进的DL模型（包括BiLSTM、BiGRU、CNNLSTM、GCN和CodeBERT）进行了严格测试。我们提出了基于深度学习的检测技术分类体系，并统一了性能评估标准，包括准确率、F1分数和检测延迟。实验结果表明，不同模型架构在漏洞检测能力、计算效率和泛化性能之间存在权衡。"
  },
  {
    "date": "2026-2-17",
    "title": "FPGA-Optimized VHDL Implementation of an ITU-T G. 707 STM-1 Multiplexer/Demultiplexer With Comparative Performance Analysis",
    "authors": "Alaa Elshafey, Hatem Zakaria, Abdelhady Mhmoud",
    "publish": "2025 International Conference on Future Telecommunications and Artificial Intelligence (IC-FTAI)",
    "url": "https://doi.org/10.1109/ic-ftai67960.2025.11384440",
    "source": "IEEE",
    "abstract": "The growing demand for high-capacity and reliable backbone networks has reinforced the importance of Synchronous Digital Hierarchy (SDH) as a standardized and robust transport technology. While STM-1 framer/deframer designs have been studied, most implementations either focus on partial subsystems or lack benchmarking against FPGA platforms and ITU-T standards. This paper presents a complete VHDL-based implementation of an STM-1 multiplexer and demultiplexer fully compliant with ITU-T G.707. The design introduces a hierarchical coding methodology to improve portability across FPGA/ASIC platforms and integrates faultresilient synchronization to enhance reliability. Functional verification is performed using a pseudo-random binary sequence (PRBS) testbench, enabling end-to-end bit error monitoring across regenerator, multiplex, and path layers. The architecture was synthesized on an Xilinx Artix-7 FPGA, achieving the ITU-T line rate of 155.52 Mbps while utilizing only 25.03% LUTs and 16.48% FFs. Comparative benchmarking against state-of-the-art designs demonstrates superior logic efficiency, competitive throughput, and robust error detection. Although FPGA-based power estimation was higher than ASIC counterparts, this is attributed to prototyping artifacts and can be mitigated through low-power design techniques in future hardware migrations.",
    "title_zh": "面向FPGA优化的ITU-T G.707 STM-1复用器/解复用器VHDL实现及性能对比分析",
    "abstract_zh": "对高容量、高可靠性骨干网络日益增长的需求，进一步凸显了同步数字体系（SDH）作为标准化且稳健传输技术的重要性。尽管STM-1帧器/解帧器的设计已有研究，但多数实现仅聚焦于部分子系统，或缺乏在FPGA平台及ITU-T标准下的基准对比。本文提出了一种基于VHDL的完整STM-1复用器与解复用器实现方案，完全符合ITU-T G.707标准。该设计采用分层编码方法，提升了在FPGA/ASIC平台间的可移植性，并集成了故障容错同步机制，以增强系统可靠性。通过伪随机二进制序列（PRBS）测试平台进行功能验证，实现了再生段、复用段和路径层的端到端比特误码监测。该架构在Xilinx Artix-7 FPGA上完成综合，成功达到ITU-T规定的155.52 Mbps线路速率，仅使用了25.03%的LUTs和16.48%的FFs。与现有先进设计的对比基准测试表明，本方案在逻辑资源效率方面表现更优，吞吐量具有竞争力，且具备强大的误码检测能力。尽管基于FPGA的功耗估算高于ASIC方案，但这一差异主要归因于原型开发过程中的固有因素，未来在硬件迁移过程中可通过低功耗设计技术加以缓解。"
  },
  {
    "date": "2026-2-17",
    "title": "Automated Software Flaw Estimation and Detection using Deep Learning",
    "authors": "C. Karthikeyan, V. Karthi, K. Vinoth, V. Adhithya, M. Ponkarthikeyan, D. Yogeshwaran",
    "publish": "2025 2nd International Conference on Artificial Intelligence and Knowledge Discovery in Concurrent Engineering (ICECONF)",
    "url": "https://doi.org/10.1109/iceconf65644.2025.11379532",
    "source": "IEEE",
    "abstract": "This research develops an automated system for deep learning-based estimation and detection of software flaws that enhance reliability and minimize vulnerabilities. It compares LSTM (Group 1) with Random Forest Regression (Group 2), where LSTM achieved 73.5 % accuracy with 45 samples, while RF attained 94.4 % accuracy with 56 samples. The dataset contains diverse software projects with annotated flaws. RF outperformed LSTM in terms of accuracy (91.40 %-94.40 % vs. <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$73.50 \\%-78.30 \\%$</tex>) and training time (315-330s vs. 400-430s) at a significance value of 0.000. The model proposed uses convolution layers for feature extraction purposes and fully connected layers for classification. RF also proves more effective in detecting flaws; it reduces its deployment risks and surpasses LSTM in terms of accuracy, efficiency, and adaptability. Thus, it has taken the position of the benchmark method in the real world.",
    "title_zh": "基于深度学习的自动化软件缺陷估算与检测",
    "abstract_zh": "本研究开发了一种基于深度学习的自动化系统，用于软件缺陷的估计与检测，以提升系统可靠性并减少漏洞。研究对比了LSTM（第一组）与随机森林回归（第二组），其中LSTM在45个样本下达到73.5%的准确率，而随机森林在56个样本下达到94.4%的准确率。数据集包含多个带有缺陷标注的软件项目。在显著性水平为0.000的情况下，随机森林在准确率（91.40%–94.40% vs. 73.50%–78.30%）和训练时间（315–330秒 vs. 400–430秒）方面均优于LSTM。所提出的模型采用卷积层进行特征提取，全连接层用于分类。此外，随机森林在缺陷检测方面也表现出更强的有效性，显著降低了部署风险，并在准确率、效率和适应性方面超越LSTM。因此，随机森林已成为实际应用中的基准方法。"
  },
  {
    "date": "2026-2-17",
    "title": "ML2++: A Model-Driven Blended Framework for Automated Machine Learning, Time Series Forecasting, and Data Visualization in IoT Applications",
    "authors": "Zahra Mardani Korani, Thimoty Smet, Moharram Challenger, Armin Moin, Joao Carlos Ferreira, Alberto Rodrigues da Silva, Gonçalo Vitorino Jesus",
    "publish": "2025 ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)",
    "url": "https://doi.org/10.1109/models-c68889.2025.11389122",
    "source": "IEEE",
    "abstract": "Intelligent Internet of Things applications must seamlessly combine established software engineering practices with various machine learning (ML) and time series forecasting techniques. However, most pipelines today rely on handwritten code, which is error-prone and imposes a steep barrier for domain specialists. Domain-specific modeling languages (DSMLs), the backbone of model-driven engineering (MDE), address this complexity by allowing developers to describe systems at a high level, while tooling generates the executable code. To this end, we introduce the ML2 family of DSML frameworks. ML2 converts concise Textula models into complete Python pipelines for classification and regression ML models, autogenerating every preprocessing, training, and prediction script. Building on that foundation, ML2+ adds declarative, end-to-end support for time series forecasting: users can select any statistical (e.g., ARIMA or ETS), machine learning (e.g., SVR or XGBoost), deep learning (e.g., LSTM or Transformer), or hybrid (e.g., Prophet) algorithms and specify key settings, such as lag length or seasonality, without writing a single line of code. In addition, ML2++ enhances both textual and graphical workflows by providing an improved Textula editor alongside Sirius Web, an IDE drag-and-drop graphical modeling environment, and realtime dashboards; ML2++ automatically generates all relevant plots, including loss curves, autocorrelation functions, and forecast versus actual charts during preprocessing, training, and prediction for both ML models and time series forecasters. We validated the framework on two real-world cases, river flow forecasting and server crash prediction, showing faster development, fewer errors, and interpretable results compared to hand-coded workflows.",
    "title_zh": "ML2++：一种面向物联网应用的模型驱动混合框架，用于自动化机器学习、时间序列预测与数据可视化",
    "abstract_zh": "智能物联网应用必须无缝融合成熟的软件工程实践与多种机器学习（ML）及时间序列预测技术。然而，当前大多数数据处理流程仍依赖手工编写的代码，这不仅容易出错，还为领域专家设置了较高的技术门槛。领域特定建模语言（DSMLs）作为模型驱动工程（MDE）的核心，通过允许开发者以高层次的方式描述系统，由工具自动生成可执行代码，有效应对了这一复杂性。为此，我们提出了ML2系列领域特定建模语言框架。ML2能够将简洁的Textula模型自动转换为完整的Python机器学习流水线，用于分类与回归任务，自动生成所有预处理、训练和预测脚本。在此基础上，ML2+进一步提供了声明式、端到端的时间序列预测支持：用户可自由选择任意统计方法（如ARIMA或ETS）、机器学习方法（如SVR或XGBoost）、深度学习方法（如LSTM或Transformer）或混合模型（如Prophet），并仅通过配置关键参数（如滞后长度或季节性）即可完成建模，无需编写任何代码。此外，ML2++通过增强文本与图形化工作流，引入了改进版的Textula编辑器，以及Sirius Web——一个支持拖拽操作的IDE式图形化建模环境，配合实时仪表盘；ML2++还能自动在预处理、训练和预测阶段生成所有相关图表，包括损失曲线、自相关函数图、预测值与实际值对比图，适用于机器学习模型和时间序列预测器。我们在两个真实世界案例中验证了该框架的有效性：河流流量预测与服务器崩溃预测，结果表明，相较于手工编码流程，ML2框架显著提升了开发速度，减少了错误，并提供了更具可解释性的输出。"
  },
  {
    "date": "2026-2-17",
    "title": "SLIM: A Simplified LLVM IR Abstraction for Pointer Analysis",
    "authors": "Aditi Raste, Swati Jaiswal, Uday Khedker",
    "publish": "2025 IEEE Pune Section International Conference (PuneCon)",
    "url": "https://doi.org/10.1109/punecon67554.2025.11377611",
    "source": "IEEE",
    "abstract": "Pointer analysis is a static code analysis technique that derives points-to information of the pointers used in a program. This information can be used to enhance the precision and reasoning capability of LLMs when dealing with program semantics, to detect bugs in the program, identify security vulnerabilities, program verification, etc. LLVM (Low-Level Virtual Machine) is a widely used compiler framework that has gained significant popularity in industry as well as in academia for the ease of adding passes to it due to its well-designed IR. However, it is observed that program analysts when performing pointer analysis often encounter significant challenges in understanding the LLVM IR because (a) it employs a low-level, load-storebased memory abstraction instead of the higher-level, namebased abstraction used in three-address code (b) and includes numerous low-level details within its instructions. Hence, there exists a pressing demand, particularly for pointer analysis for an abstraction layer over the LLVM IR that will extract only the relevant information from the IR while ignoring the rest. To address this, we present SLIM (Simplified LLVM IR Modelling), an open-source tool engineered as a high-level abstraction over LLVM IR. SLIM employs a name-based memory abstraction and conceals low-level details, producing a clean intermediate representation that is ideal for pointer analysis. We observe that (a) With SLIM there is a reduction in the instruction count for performing pointer analysis as compared to LLVM IR by an average reduction of 52% on the programs analyzed from SPEC CPU 2017 benchmark suite. (b) SLIM provides an easy framework for implementing an analysis as per the scaffolded study conducted at IIT Bombay and VNIT, Nagpur.",
    "title_zh": "SLIM：一种用于指针分析的简化LLVM IR抽象",
    "abstract_zh": "指针分析是一种静态代码分析技术，用于推导程序中指针所指向的内容信息。这种信息可用于提升大型语言模型（LLM）在处理程序语义时的精度与推理能力，检测程序中的错误、识别安全漏洞、进行程序验证等。LLVM（低级虚拟机）是一个广泛使用的编译器框架，因其精心设计的中间表示（IR）结构，使得在其上添加分析或优化阶段变得十分便捷，因此在工业界和学术界都获得了广泛应用。然而，研究发现，程序分析人员在进行指针分析时，常常面临理解LLVM IR的显著挑战，原因在于：（a）LLVM IR采用低级别的基于加载-存储的内存抽象，而非三地址码中常见的高级别基于名称的抽象；（b）其指令中包含大量低级别细节。因此，迫切需要一种针对LLVM IR的抽象层，能够从中提取与分析相关的必要信息，同时忽略无关的冗余细节。\n\n为解决这一问题，我们提出了SLIM（Simplified LLVM IR Modelling），一个开源工具，作为LLVM IR之上的高级抽象层。SLIM采用基于名称的内存抽象机制，隐藏了底层细节，生成一种简洁明了的中间表示形式，特别适合用于指针分析。我们观察到：（a）与直接使用LLVM IR相比，使用SLIM进行指针分析时，所处理的指令数量平均减少了52%（基于SPEC CPU 2017基准测试套件中分析的程序）；（b）SLIM为分析实现提供了简便的框架，这一优势在印度理工学院（IIT Bombay）与那格浦尔文理学院（VNIT, Nagpur）联合开展的示范性研究中得到了验证。"
  },
  {
    "date": "2026-2-17",
    "title": "A Threat Modeling Approach for Securing Blockchain Framework",
    "authors": "Neelkumar K. Shah, Sachin Nandurkar, Mayur Lilhare, Mohammad Aziz Maalik, Indraveni Chebolu, Niteshkumar Harne, Manoj Kumar Khare",
    "publish": "2025 IEEE International Conference on Blockchain and Distributed Systems Security (ICBDS)",
    "url": "https://doi.org/10.1109/icbds67396.2025.11378344",
    "source": "IEEE",
    "abstract": "Blockchain technology is gaining popularity across various industries due to its decentralised, transparent, and immutable nature. However, as blockchain-based frameworks evolve to support large-scale services and applications, they are increasingly vulnerable to complex security threats. This study presents a STRIDE-based approach to detect and mitigate potential vulnerabilities in blockchain systems. The framework provides methods to enhance security across smart contracts, communication protocols, and databases by analysing vulnerabilities, including spoofing, tampering, repudiation, information disclosure, denial-of-service attacks, and elevation of privilege. The objective of this paper is to assist users in building secure blockchain applications in industries such as education, healthcare, and finance.",
    "title_zh": "一种用于保护区块链框架的威胁建模方法",
    "abstract_zh": "区块链技术因其去中心化、透明性和不可篡改的特性，正在各个行业中日益流行。然而，随着基于区块链的框架不断发展以支持大规模服务和应用，它们也面临着日益复杂的网络安全威胁。本研究提出了一种基于STRIDE的漏洞检测与缓解方法，用于识别和应对区块链系统中的潜在安全漏洞。该框架通过分析欺骗、篡改、抵赖、信息泄露、拒绝服务攻击以及权限提升等常见漏洞，提供了一系列增强智能合约、通信协议和数据库安全性的方法。本文旨在帮助教育、医疗和金融等行业用户构建更加安全的区块链应用。"
  },
  {
    "date": "2026-2-17",
    "title": "A Comparative Study of Bug Triage Classification Approaches from FastText to LLMs",
    "authors": "Erick Costa Bezerra, Victor da Silva Dantas, Paulo Henrique Barros Diniz, Diego Falcao de Souza",
    "publish": "2025 6th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)",
    "url": "https://doi.org/10.1109/icaice68195.2025.11382491",
    "source": "IEEE",
    "abstract": "Bug triage involves assigning newly reported bugs to the appropriate developers or teams for resolution. It is a critical aspect of software maintenance, directly influencing time and resource allocation, which impact the efficiency and effectiveness of the software process. Globally, the extensive number of teams and developers presents a challenge for bug triage. Traditional methods for assigning bugs often fail to address the complexity of the issue. This study conducts a comparative evaluation of various text classification methods for automated bug report triage in an industrial context, integrating large language models into the classification pipeline. FastText serves as the baseline when compared with large language enhanced models across accuracy metric. The findings suggest that integrating large language models into existing workflows could enhance triage accuracy for textual classification.",
    "title_zh": "从FastText到大语言模型的缺陷分类方法比较研究",
    "abstract_zh": "缺陷分类（Bug triage）是指将新报告的缺陷分配给合适的开发人员或团队进行修复，是软件维护中的关键环节，直接影响时间与资源的分配，进而影响软件开发过程的效率与效果。在全球范围内，由于开发团队和开发人员数量庞大，缺陷分类面临巨大挑战。传统的缺陷分配方法往往难以应对这一问题的复杂性。本研究在工业场景下对多种文本分类方法进行了对比评估，旨在实现自动化缺陷报告分类，并将大型语言模型整合到分类流程中。以FastText作为基准模型，与增强型大型语言模型在准确率等指标上进行对比。研究结果表明，将大型语言模型融入现有工作流程，能够有效提升文本分类的准确性，从而改善缺陷分类的效果。"
  },
  {
    "date": "2026-2-17",
    "title": "Human-Robot Interaction-Integrated Code Review Interface for Collaborative Development",
    "authors": "Sharmila Zope, Aashish A. Gadgil, Avishek Bhattacharjee, T. Manjula, Lakshmi Narasimhan Srinivasagopalan, L. Karthick",
    "publish": "2025 2nd International Conference on Artificial Intelligence and Knowledge Discovery in Concurrent Engineering (ICECONF)",
    "url": "https://doi.org/10.1109/iceconf65644.2025.11379568",
    "source": "IEEE",
    "abstract": "Human-Robot Interaction (HRI) has become a potent paradigm to enhance collaborative software development environments through the incorporation of intelligent support systems. This study presents a HumanRobot Interaction-Integrated Code Review Interface that is aimed at improving team-based development processes. The system uses Natural Language Processing (NLP) as the main tool to process developer feedback and suggestions, and uses PyTorch as the tool to implement deep learning-based models to analyze semantic code. The interface enables a robotic assistant to give contextsensitive review comments, point out possible problems, and support interactive conversations between developers. The proposed system will promote better accuracy, efficiency, and inclusivity in the code review processes by integrating automation with human insights. The experimental findings show that there are considerable enhancements in error detection and knowledge sharing, which highlights the potential of HRI-based solutions in contemporary software engineering.",
    "title_zh": "人机交互集成式代码审查界面，用于协同开发",
    "abstract_zh": "人机交互（HRI）已成为通过引入智能支持系统来增强协作式软件开发环境的有力范式。本研究提出了一种集成人机交互的代码审查界面，旨在优化团队协作开发流程。该系统主要采用自然语言处理（NLP）技术来处理开发者的反馈与建议，并利用PyTorch实现基于深度学习的模型以分析代码语义。该界面使机器人助手能够提供上下文相关的审查意见，指出潜在问题，并支持开发者之间的互动交流。通过将自动化与人类洞察力相结合，所提出的系统有望显著提升代码审查过程的准确性、效率与包容性。实验结果表明，系统在错误检测与知识共享方面均有显著提升，凸显了基于人机交互的解决方案在现代软件工程中的巨大潜力。"
  },
  {
    "date": "2026-2-17",
    "title": "A Novel Synthetic Dataset for JavaScript Malware Detection",
    "authors": "Hind Ikni, Alaa Eddine Belfedhal",
    "publish": "2025 International Conference on Artificial Intelligence and Innovative Applications (AIIA)",
    "url": "https://doi.org/10.1109/aiia68273.2025.11383680",
    "source": "IEEE",
    "abstract": "The development of efficient AI-based methods for malware detection is significantly limited by the lack of high-quality datasets, as real-world scripts are often imbalanced and may include sensitive information. This scarcity of curated data poses major challenges for cybersecurity researchers, particularly regarding reproducibility and ethical compliance. In this paper, we introduce a novel synthetic dataset of JavaScript snippets that are programmatically labeled and balanced. Fine-tuning a CodeBERT-based classifier on the generated samples shows promising performance when evaluated on real-world scripts.",
    "title_zh": "一种用于JavaScript恶意软件检测的新颖合成数据集",
    "abstract_zh": "基于人工智能的恶意软件检测方法的高效发展，受到高质量数据集缺乏的严重制约，因为真实世界中的脚本通常存在数据不平衡问题，且可能包含敏感信息。这种经过精心整理的数据稀缺性给网络安全研究人员带来了重大挑战，尤其是在可复现性和伦理合规性方面。本文提出了一种新型的合成JavaScript代码片段数据集，该数据集通过程序化方式实现标签标注并保持数据平衡。将基于CodeBERT的分类器在生成的样本上进行微调后，在真实世界脚本上的评估表现出良好的性能。"
  },
  {
    "date": "2026-2-17",
    "title": "Multi-Criteria Evaluation of Large Language Models (LLMs): Balancing Performance and Security",
    "authors": "Daniel Mendonça Colares, Plácido Rogério Pinheiro, Raimir Holanda Filho",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3665546",
    "source": "IEEE",
    "abstract": "Because of its functionality and practicality, Large Language Models (LLMs) have been widely discussed, with a large number of benchmarking being done to evaluate them, especially their efficiency. But despite their numerous applications and the significant benefits they offer, LLMs have proven to be extremely susceptible to attacks of various natures due to their, often unknown, large number of vulnerabilities, characteristics often ignored by benchmarking. Given that, this paper aims to develop a multi-criteria method to assist stakeholders in selecting the most suitable Large Language Model taking into account based on both its efficiency in carrying out tasks of various natures, such as math and reasoning, and its capability to resist a large range of security vulnerabilities, such as prompt injection and jailbreaking. This study utilized the Analytic Hierarchy Process (AHP) along with tools developed to evaluate the capabilities of LLMs in multi-interaction dialogues and LLM vulnerability scanner applied in open source models. The analysis showed that an more efficient model does not mean that it is safer. In addition, it reveals an efficient method for analyzing both model performance and security issues.",
    "title_zh": "大型语言模型（LLMs）的多准则评估：平衡性能与安全",
    "abstract_zh": "由于其功能性和实用性，大型语言模型（LLMs）受到了广泛关注，大量基准测试被用于评估其性能，尤其是效率方面。然而，尽管LLMs应用广泛且带来了显著优势，它们却因存在大量未知的漏洞而极易受到各种攻击，而这些特性往往在基准测试中被忽视。鉴于此，本文旨在提出一种多准则方法，帮助利益相关者在选择最合适的大型语言模型时，综合考虑其在执行各类任务（如数学计算和推理）方面的效率，以及其抵御多种安全漏洞（如提示注入和越狱攻击）的能力。本研究采用层次分析法（AHP），并结合用于评估LLMs在多轮对话中表现的工具，以及应用于开源模型的LLM漏洞扫描器。分析结果表明，模型效率高并不意味着其安全性更强。此外，该研究还揭示了一种有效分析模型性能与安全问题的综合方法。"
  },
  {
    "date": "2026-2-17",
    "title": "Comprehensive Analysis of Mitigation Strategies for Denial-of-Service Attacks on Smart Contracts",
    "authors": "Purnima Ahirao, Yogita Borse, Deepti Patole, Shreshtha Agarwal, Mehek Abhyankar, Kaustubh Nair",
    "publish": "2025 IEEE International Conference on Blockchain and Distributed Systems Security (ICBDS)",
    "url": "https://doi.org/10.1109/icbds67396.2025.11376964",
    "source": "IEEE",
    "abstract": "The Denial-of-service (DoS) attacks pose a significant risk in smart contracts. They often arise from unexpected failures in external calls. This papers thoroughly examines DoS vulnerabilities in smart contracts and looks at effective ways to reduce these risks. The authors explore contract scenarios that are vulnerable to refund-failure DoS attacks. In these cases, bad actors can disrupt contract operations. The experiments show that some methods completely defend against these attacks, but they might some with a cost and hamper overall user experience. Other methods find a middle ground, improving security and usability by improving DoS and re-entrancy risks without interfering with single interaction flows. The research provides a solid evaluation for DoS mitigation strategies and offers practical advice for developing secure smart contracts.",
    "title_zh": "智能合约拒绝服务攻击的缓解策略综合分析",
    "abstract_zh": "拒绝服务（DoS）攻击对智能合约构成了重大风险，通常源于外部调用中的意外失败。本文深入探讨了智能合约中的DoS漏洞，并研究了有效降低此类风险的方法。作者分析了容易受到退款失败型DoS攻击的合约场景，在这些情况下，恶意行为者可能干扰合约的正常运行。实验结果表明，某些方法能够完全抵御此类攻击，但可能伴随一定的代价，影响整体用户体验；而其他方法则在安全性和可用性之间取得平衡，通过改善DoS和重入攻击风险，同时不干扰单一交互流程，从而提升合约的安全性与用户体验。本研究为DoS防护策略提供了扎实的评估，并为开发安全的智能合约提供了实用建议。"
  },
  {
    "date": "2026-2-17",
    "title": "MCLF: Smart Contract Vulnerability Detection Based on Multimodal and Contrastive Learning",
    "authors": "Feixiao Zhang, Yongli Wang, Dongmei Liu",
    "publish": "2025 6th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)",
    "url": "https://doi.org/10.1109/icaice68195.2025.11382305",
    "source": "IEEE",
    "abstract": "Security vulnerabilities in smart contracts pose a serious threat to the blockchain ecosystem. Traditional detection methods heavily rely on expert-defined rules, leading to issues such as high false positives, false negatives, and poor scalability. Although recent deep learning-based approaches have shown promise, most focus on a single code modality, which limits their ability to capture the multi-dimensional characteristics of complex vulnerabilities. To address these limitations, this paper proposes MCLF, a novel smart contract vulnerability detection framework based on multimodal feature fusion and contrastive learning. The approach simultaneously extracts a Data Flow Graph and code semantic sequences from smart contracts to capture structural dependencies and contextual semantic information, respectively. A dual-branch Transformer architecture is designed to encode each type of feature, while contrastive learning is applied to optimize vector space alignment and enhance intra-class consistency. A masked language modeling task is further incorporated to improve semantic reasoning through multi-task joint training. Finally, transfer learning is employed to fine-tune the model for downstream vulnerability classification. Experimental results on a public benchmark dataset demonstrate that the proposed method achieves precision, recall, and F1score of 91.90%, 92.53% and 92.21%, respectively, significantly outperforming the most advanced vulnerability detection tools and validating the effectiveness of multimodal feature fusion and the contrastive learning mechanism.",
    "title_zh": "MCLF：基于多模态与对比学习的智能合约漏洞检测",
    "abstract_zh": "智能合约中的安全漏洞对区块链生态系统构成了严重威胁。传统的检测方法严重依赖专家定义的规则，导致误报率高、漏报率高且可扩展性差。尽管近年来基于深度学习的方法展现出一定潜力，但大多数方法仅关注单一代码模态，难以充分捕捉复杂漏洞的多维特征。为解决上述问题，本文提出一种基于多模态特征融合与对比学习的新型智能合约漏洞检测框架——MCLF。该方法同时从智能合约中提取数据流图和代码语义序列，分别捕获结构依赖关系和上下文语义信息。设计了双分支Transformer架构来分别编码两类特征，并引入对比学习优化向量空间对齐，增强类内一致性。此外，通过引入掩码语言建模任务，结合多任务联合训练以提升语义推理能力。最后，采用迁移学习对模型进行微调，以适应下游漏洞分类任务。在公开基准数据集上的实验结果表明，所提方法在精确率、召回率和F1分数上分别达到91.90%、92.53%和92.21%，显著优于当前最先进的漏洞检测工具，验证了多模态特征融合与对比学习机制的有效性。"
  },
  {
    "date": "2026-2-17",
    "title": "Custom VLSI Framework for Real-Time Video Background Adaptation",
    "authors": "Veerabhadraswamy K M, D V Manjunatha",
    "publish": "2025 5th International Conference on Evolutionary Computing and Mobile Sustainable Networks (ICECMSN)",
    "url": "https://doi.org/10.1109/icecmsn68058.2025.11382851",
    "source": "IEEE",
    "abstract": "Real-time background subtraction is essential in video usage such as video surveillance, object tracking, and intelligent vision systems. However, while many implementations are software-based and can deliver on the performance, most implementations struggle to provide the required energy efficiency in moving video scenarios. In this work, demonstrated an example of a custom VLSI framework for real-time background adaptation that achieves performance throughputs, latency, and extensibility using minimum hardware resources. The proposed design has a parallelized adaptive background modeling unit with a hardware-compressed update mechanism to accurately perform background modeling on a foreground object in a complex and dynamic environment. However, accounting for illumination variation, motion blur, and background evolution requires a light-weight adaptive thresholding method combined with morphological filtering modules. The framework was developed and implemented on an FPGA, and then synthesized for ASIC purposes, but allows for real-time processing at full-HD resolution, optimally using less memory and performing at lower power levels than existing hardware and software implementations. Evaluation of the method has been performed, through extensive experimentation, with real-time detection demonstrating significantly improved detection accuracy, and resource utilization compared to existing processes, including but not limited to a reduction of latency up to XX% and energy utilized up to YY% in comparison to our conventional designs. This means advancing the use of custom VLSI methods will continue to provide the frameworks required to realize real-time intelligent video analytics, paving the way forward toward uses of intelligent video analytics in surveillance, autonomous analytics, and edge-based vision applications.",
    "title_zh": "用于实时视频背景自适应的定制VLSI框架",
    "abstract_zh": "实时背景减除在视频监控、目标跟踪和智能视觉系统等视频应用中至关重要。然而，尽管许多现有实现基于软件，能够在性能上满足需求，但在移动视频场景下，大多数方案难以实现所需的能效。本文展示了一种定制的VLSI框架实例，用于实时背景自适应，该框架在最小硬件资源下实现了高性能吞吐量、低延迟和良好的可扩展性。所提出的架构包含一个并行化的自适应背景建模单元，并采用硬件压缩更新机制，能够在复杂动态环境中准确完成前景物体的背景建模。同时，为应对光照变化、运动模糊和背景演化等问题，设计引入了一种轻量级自适应阈值方法，并结合形态学滤波模块，进一步提升鲁棒性。该框架在FPGA上完成开发与实现，并已进行ASIC综合，支持全高清分辨率下的实时处理，相比现有软硬件实现，显著降低了内存占用和功耗。通过大量实验验证，该方法在实时检测中表现出显著提升的检测准确率和资源利用率，与现有技术相比，延迟降低最高达XX%，能耗减少最高达YY%。这表明，持续推进定制化VLSI方法的发展，将为实现实时智能视频分析提供必要的技术框架，为智能视频分析在监控、自主分析及边缘视觉应用等领域的广泛应用铺平道路。"
  },
  {
    "date": "2026-2-17",
    "title": "Visionary Code: An AI-Driven Platform for Blind and Visually Impaired Programmers",
    "authors": "Permanki Guthu Rithesh Pakkala, R Akhila Thejaswi, Bellipady Shamantha Rai, Sudheer Shetty, Pv Vasudeva Rao, Shrinidhi Upadhyaya",
    "publish": "2025 Second International Conference on Computing, Semiconductor, Mechatronics, Intelligent Systems and Communications (COSMIC)",
    "url": "https://doi.org/10.1109/cosmic67569.2025.11380982",
    "source": "IEEE",
    "abstract": "Visually impaired and blind students face significant barriers in programming and IT education due to the reliance on visual elements in traditional tools, which limits their ability to engage with coding environments. While Braille remains a vital accessibility tool, the lack of adaptive programming resources further complicates the learning process. To address these challenges, we developed a platform that integrates Natural Language Processing (NLP) technology using the BERT (Bidirectional Encoder Representations from Transformers) algorithm to enable automated code verification and real-time error detection. The system is designed to offer audio-based feedback along with theoretical programming concepts, ensuring that visually impaired learners can access and interact with coding environments independently. The platform’s performance was evaluated using Python and HTML error detection. It achieved 92% accuracy and 90% precision for Python code detection and 82% accuracy and 80% precision for HTML code detection. These results demonstrate the platform’s reliability and its potential to enhance programming accessibility. By combining NLP-based code analysis with audio-assisted learning, the platform empowers visually impaired students to navigate programming concepts confidently and participate fully in IT education. Furthermore, the platform’s adaptability allows it to support various programming languages, offering flexibility for students to explore diverse coding environments. The integration of realtime error detection and corrective feedback ensures that learners can efficiently progress through their coding exercises with minimal external assistance.",
    "title_zh": "远见代码：面向盲人和视障程序员的AI驱动平台",
    "abstract_zh": "视障和盲人学生在编程与信息技术教育中面临重大障碍，这主要是因为传统工具高度依赖视觉元素，限制了他们参与编程环境的能力。尽管盲文仍是重要的无障碍工具，但缺乏适应性编程资源进一步加剧了学习难度。为解决这些问题，我们开发了一个平台，该平台利用自然语言处理（NLP）技术，基于BERT（双向编码器表示从变换器）算法，实现代码的自动验证与实时错误检测。系统设计为提供基于音频的反馈以及理论编程概念讲解，确保视障学习者能够独立访问并互动于编程环境。平台通过Python和HTML的错误检测进行了性能评估，结果显示：在Python代码检测中，准确率达到92%，精确度为90%；在HTML代码检测中，准确率为82%，精确度为80%。这些结果表明该平台具有高度可靠性，具备显著提升编程可访问性的潜力。通过结合基于NLP的代码分析与音频辅助学习，该平台使视障学生能够自信地掌握编程概念，并充分参与信息技术教育。此外，平台具备良好的可扩展性，能够支持多种编程语言，为学生探索多样化的编程环境提供了灵活性。实时错误检测与纠正反馈的集成，使学习者能够高效完成编程练习，最大限度减少对外部帮助的依赖。"
  },
  {
    "date": "2026-2-17",
    "title": "Exploring the Role of AI in Transforming Programming Education at Universities: Qualitative and Quantitative Insights",
    "authors": "Heng-Wei Chao, Allen Y. Chang",
    "publish": "2025 International Workshop on Artificial Intelligence and Education (WAIE)",
    "url": "https://doi.org/10.1109/waie67422.2025.11381160",
    "source": "IEEE",
    "abstract": "As generative AI tools like ChatGPT gain prominence, their role in higher education—particularly in programming instruction—has attracted growing attention. This study explores the practical impact of ChatGPT on introductory programming education in Taiwanese universities. A mixed-methods design was adopted, involving both a quantitative experiment and qualitative survey. First-year computer science students were divided into an AI-assisted group and a traditional group. After a guided reading phase, both groups completed a closed-book test evaluating four learning dimensions: syntax comprehension, logical reasoning, creative design, and error detection. Results show the AI group significantly outperformed the traditional group in syntax, creativity, and debugging, though no notable difference was found in logical reasoning. Survey responses revealed positive perceptions of AI’s usefulness, alongside a growing trend of frequent reliance on such tools. This study concludes that while ChatGPT can enhance learning in specific domains, educators must guide students in responsible usage to avoid overdependence and preserve academic integrity.",
    "title_zh": "探讨人工智能在大学编程教育变革中的作用：定性与定量分析",
    "abstract_zh": "随着生成式AI工具（如ChatGPT）日益受到关注，其在高等教育领域——尤其是编程教学中的作用也引发了越来越多的讨论。本研究探讨了ChatGPT在台湾高校入门级编程教育中的实际影响。研究采用混合方法设计，结合定量实验与定性调查。将一年级计算机科学专业学生分为AI辅助组与传统教学组。在完成引导性阅读后，两组学生均参加了一场闭卷测试，评估四个学习维度：语法理解、逻辑推理、创造性设计和错误检测。结果显示，AI辅助组在语法理解、创造性设计和调试能力方面显著优于传统教学组，但在逻辑推理方面未发现显著差异。问卷调查结果表明，学生普遍认为AI工具具有实用价值，同时对这类工具的依赖程度呈上升趋势。研究结论指出，尽管ChatGPT能在特定学习领域提升学习效果，但教育工作者必须引导学生负责任地使用AI工具，避免过度依赖，以维护学术诚信。"
  },
  {
    "date": "2026-2-17",
    "title": "Hybrid Graph-Transformer Framework for Intelligent Pseudocode to Source Code Synthesis",
    "authors": "Hari Krishnan R, Philomina Simon, Gokul Krishna S, Deepak V M",
    "publish": "2025 IEEE Pune Section International Conference (PuneCon)",
    "url": "https://doi.org/10.1109/punecon67554.2025.11379299",
    "source": "IEEE",
    "abstract": "In software engineering pseudocode to source code generation plays a vital role in acting as a bridge between the complex algorithmic descriptions to the program for execution. This paper mainly provides a hybrid architecture that mainly combines the Graph Attention Networks (GAT) with the transformer model. The pseudocode contains the sequential textual information as well as the structural algorithm relationships that requires dual modality processing. A three-layer GAT encoder with multi-head attention mechanism captures the important features such as type encoding and positional information are used. These are integrated with the T5 encoder. Then, the T5 decoder utilizes the enhanced representation for conditional code generation. The model is evaluated using the BLEU metrics and thus demonstrates the improvements over the baseline approaches and projects the performance in the proposed hybrid model.",
    "title_zh": "用于智能伪代码到源代码合成的混合图-Transformer框架",
    "abstract_zh": "在软件工程中，从伪代码到源代码的自动生成在算法描述与可执行程序之间起到了至关重要的桥梁作用。本文提出了一种混合架构，主要结合了图注意力网络（Graph Attention Networks, GAT）与Transformer模型。伪代码不仅包含序列化的文本信息，还蕴含了结构化的算法关系，因此需要双模态处理。本文采用三层GAT编码器，结合多头注意力机制，以捕捉诸如类型编码和位置信息等关键特征。这些特征随后与T5编码器进行融合，再由T5解码器基于增强后的表示进行条件化代码生成。模型通过BLEU指标进行评估，结果表明其在性能上优于基线方法，充分展示了所提出混合模型的有效性。"
  },
  {
    "date": "2026-2-17",
    "title": "Decentralized Voting System Using Blockchain",
    "authors": "Swapnil Shinde, Anand Sharma, Riya Shete, Kalyani Bonde",
    "publish": "2025 IEEE Pune Section International Conference (PuneCon)",
    "url": "https://doi.org/10.1109/punecon67554.2025.11378473",
    "source": "IEEE",
    "abstract": "A secure voting system using blockchain leverages decentralized ledger technology to improve the integrity, transparency, and security of the electoral process. Using smart contracts coded in Solidity, the system performs such critical functions as candidate enrollment, voter registration, vote casting, and result aggregation automatically. Each vote is recorded safely on the blockchain, making it almost impossible to tamper with and guaranteeing that each user votes only once. The integration of tools such as HardHat streamlines smart contract testing and deployment, while MetaMask provides secure authentication and transaction signing. The frontend, which is developed using React.js, offers real-time updates and an interactive user interface. Automating vote management and providing public verifiability through blockchain-based voting systems enhances trust, minimizes fraud, and simplifies operations, providing a cost-efficient and future-proofed solution for electoral management.",
    "title_zh": "基于区块链的去中心化投票系统",
    "abstract_zh": "基于区块链的安全投票系统利用去中心化账本技术，提升了选举过程的完整性、透明度和安全性。通过使用Solidity编写的智能合约，系统可自动执行候选人注册、选民登记、投票提交及结果汇总等关键功能。每票均安全记录在区块链上，几乎无法被篡改，确保每位用户仅能投票一次。借助HardHat等工具，智能合约的测试与部署得以高效进行，而MetaMask则提供安全的身份验证和交易签名功能。前端采用React.js开发，支持实时更新和交互式用户界面。通过自动化投票管理，并利用基于区块链的投票系统实现公开可验证性，该系统显著增强了信任度，减少了欺诈行为，简化了操作流程，为选举管理提供了一种成本效益高且面向未来的解决方案。"
  }
]