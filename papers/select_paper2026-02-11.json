[
  {
    "date": "2026-02-11",
    "title": "Fine-Tuning GPT-5 for GPU Kernel Generation",
    "authors": "Ali Tehrani, Yahya Emara, Essam Wissam, Wojciech Paluch, Waleed Atallah, Łukasz Dudziak, Mohamed S. Abdelfattah",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11000v1",
    "source": "arXiv",
    "abstract": "Developing efficient GPU kernels is essential for scaling modern AI systems, yet it remains a complex task due to intricate hardware architectures and the need for specialized optimization expertise. Although Large Language Models (LLMs) demonstrate strong capabilities in general sequential code generation, they face significant challenges in GPU code generation because of the scarcity of high-quality labeled training data, compiler biases when generating synthetic solutions, and limited generalization across hardware generations. This precludes supervised fine-tuning (SFT) as a scalable methodology for improving current LLMs. In contrast, reinforcement learning (RL) offers a data-efficient and adaptive alternative but requires access to relevant tools, careful selection of training problems, and a robust evaluation environment. We present Makora's environment and tools for reinforcement learning finetuning of frontier models and report our results from fine-tuning GPT-5 for Triton code generation. In the single-attempt setting, our fine-tuned model improves kernel correctness from 43.7% to 77.0% (+33.3 percentage points) and increases the fraction of problems outperforming TorchInductor from 14.8% to 21.8% (+7 percentage points) compared to baseline GPT-5, while exceeding prior state-of-the-art models on KernelBench. When integrated into a full coding agent, it is able to solve up to 97.4% of problems in an expanded KernelBench suite, outperforming the PyTorch TorchInductor compiler on 72.9% of problems with a geometric mean speedup of 2.12x. Our work demonstrates that targeted post-training with reinforcement learning can unlock LLM capabilities in highly specialized technical domains where traditional supervised learning is limited by data availability, opening new pathways for AI-assisted accelerator programming.",
    "title_zh": "为GPU内核生成微调GPT-5",
    "abstract_zh": "高效GPU内核的开发对于现代人工智能系统的扩展至关重要，但由于硬件架构复杂以及需要专门的优化专业知识，这一任务依然十分困难。尽管大型语言模型（LLMs）在通用顺序代码生成方面表现出强大能力，但在GPU代码生成方面仍面临诸多挑战：高质量标注训练数据稀缺、生成合成解决方案时编译器存在偏差，以及在不同硬件代际间泛化能力有限。这些因素使得监督微调（SFT）难以成为提升当前LLMs的可扩展方法。相比之下，强化学习（RL）提供了一种数据高效且具备适应性的替代方案，但其实施需要访问相关工具、精心选择训练问题，并构建稳健的评估环境。\n\n本文介绍了Makora的环境与工具，用于前沿模型的强化学习微调，并报告了我们对GPT-5进行Triton代码生成微调的结果。在单次尝试设置下，微调后的模型将内核正确率从基线GPT-5的43.7%提升至77.0%（提升33.3个百分点），同时使优于TorchInductor的题目比例从14.8%提高到21.8%（提升7个百分点），在KernelBench基准上超越了先前的最先进模型。当集成到完整的编程代理系统中时，该模型在扩展版KernelBench测试集上可解决高达97.4%的问题，在72.9%的问题上表现优于PyTorch的TorchInductor编译器，并实现了2.12倍的几何平均加速比。\n\n我们的工作表明，通过针对性的后训练强化学习，可以充分释放LLM在高度专业化技术领域（如传统监督学习受限于数据可用性）中的潜力，为AI辅助加速器编程开辟了全新的路径。"
  },
  {
    "date": "2026-02-11",
    "title": "Search or Accelerate: Confidence-Switched Position Beam Search for Diffusion Language Models",
    "authors": "Mingyu Cao, Alvaro Correia, Christos Louizos, Shiwei Liu, Lu Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10953v1",
    "source": "arXiv",
    "abstract": "Diffusion Language Models (DLMs) generate text by iteratively denoising a masked sequence, repeatedly deciding which positions to commit at each step. Standard decoding follows a greedy rule: unmask the most confident positions, yet this local choice can lock the model into a suboptimal unmasking order, especially on reasoning-heavy prompts. We present SOAR, a training-free decoding algorithm that adapts its behavior to the model's uncertainty. When confidence is low, SOAR briefly widens the search over alternative unmasking decisions to avoid premature commitments; when confidence is high, it collapses the search and decodes many positions in parallel to reduce the number of denoising iterations. Across mathematical reasoning and code generation benchmarks (GSM8K, MBPP, HumanEval) on Dream-7B and LLaDA-8B, SOAR improves generation quality while maintaining competitive inference speed, offering a practical way to balance quality and efficiency in DLM decoding.",
    "title_zh": "搜索或加速：用于扩散语言模型的置信度切换位置束搜索",
    "abstract_zh": "扩散语言模型（DLMs）通过迭代去噪一个被掩码的序列来生成文本，每一步都反复决定哪些位置应被解码。标准解码采用贪心策略：优先解码置信度最高的位置。然而，这种局部决策可能导致模型陷入次优的解码顺序，尤其是在处理需要推理的提示时。我们提出SOAR——一种无需训练的解码算法，能够根据模型的不确定性动态调整行为：当置信度较低时，SOAR会短暂扩大对替代解码决策的搜索范围，避免过早做出不可逆的决定；当置信度较高时，它则收缩搜索空间，以并行方式解码多个位置，从而减少去噪迭代次数。在Dream-7B和LLaDA-8B模型上，针对数学推理和代码生成基准（GSM8K、MBPP、HumanEval），SOAR在保持高效推理速度的同时显著提升了生成质量，为DLM解码中的质量与效率平衡提供了一种实用有效的解决方案。"
  },
  {
    "date": "2026-02-11",
    "title": "VulReaD: Knowledge-Graph-guided Software Vulnerability Reasoning and Detection",
    "authors": "Samal Mukhtar, Yinghua Yao, Zhu Sun, Mustafa Mustafa, Yew Soon Ong, Youcheng Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10787v1",
    "source": "arXiv",
    "abstract": "Software vulnerability detection (SVD) is a critical challenge in modern systems. Large language models (LLMs) offer natural-language explanations alongside predictions, but most work focuses on binary evaluation, and explanations often lack semantic consistency with Common Weakness Enumeration (CWE) categories. We propose VulReaD, a knowledge-graph-guided approach for vulnerability reasoning and detection that moves beyond binary classification toward CWE-level reasoning. VulReaD leverages a security knowledge graph (KG) as a semantic backbone and uses a strong teacher LLM to generate CWE-consistent contrastive reasoning supervision, enabling student model training without manual annotations. Students are fine-tuned with Odds Ratio Preference Optimization (ORPO) to encourage taxonomy-aligned reasoning while suppressing unsupported explanations. Across three real-world datasets, VulReaD improves binary F1 by 8-10% and multi-class classification by 30% Macro-F1 and 18% Micro-F1 compared to state-of-the-art baselines. Results show that LLMs outperform deep learning baselines in binary detection and that KG-guided reasoning enhances CWE coverage and interpretability.",
    "title_zh": "VulReaD：基于知识图谱的软件漏洞推理与检测",
    "abstract_zh": "软件漏洞检测（SVD）是现代系统中的一项关键挑战。大型语言模型（LLMs）在提供预测结果的同时，能够生成自然语言解释，但现有研究大多集中于二元分类任务，且生成的解释往往与通用弱点枚举（CWE）分类缺乏语义一致性。为此，我们提出 VulReaD——一种基于知识图谱引导的漏洞推理与检测方法，该方法突破了传统的二元分类范式，迈向 CWE 级别的推理。VulReaD 以安全知识图谱（KG）作为语义核心，利用强大的教师型 LLM 生成与 CWE 一致的对比推理监督信号，从而在无需人工标注的情况下实现学生模型的训练。学生模型通过奇偶比偏好优化（ORPO）进行微调，以促进与分类体系对齐的推理过程，同时抑制缺乏支持的解释。在三个真实世界数据集上的实验表明，VulReaD 在二元分类任务中 F1 分数提升 8-10%，在多分类任务中宏平均 F1 提升 30%，微平均 F1 提升 18%，显著优于当前最先进基线方法。实验结果表明，LLM 在二元检测任务中优于深度学习基线，而基于知识图谱的推理机制显著提升了 CWE 覆盖率与模型可解释性。"
  },
  {
    "date": "2026-02-11",
    "title": "When Skills Lie: Hidden-Comment Injection in LLM Agents",
    "authors": "Qianli Wang, Boyang Ma, Minghui Xu, Yue Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10498v1",
    "source": "arXiv",
    "abstract": "LLM agents often rely on Skills to describe available tools and recommended procedures. We study a hidden-comment prompt injection risk in this documentation layer: when a Markdown Skill is rendered to HTML, HTML comment blocks can become invisible to human reviewers, yet the raw text may still be supplied verbatim to the model. In experiments, we find that DeepSeek-V3.2 and GLM-4.5-Air can be influenced by malicious instructions embedded in a hidden comment appended to an otherwise legitimate Skill, yielding outputs that contain sensitive tool intentions. A short defensive system prompt that treats Skills as untrusted and forbids sensitive actions prevents these malicious tool calls and instead surfaces the suspicious hidden instructions.",
    "title_zh": "当技能隐藏时：大型语言模型代理中的隐藏注释注入",
    "abstract_zh": "大型语言模型代理通常依赖“技能”（Skills）来描述可用工具及推荐操作流程。本文研究了该文档层中一种隐蔽的注释型提示注入风险：当Markdown格式的技能被渲染为HTML时，HTML注释块对人工审查者而言可能完全不可见，但其原始文本仍可能原封不动地传递给模型。实验表明，DeepSeek-V3.2和GLM-4.5-Air等模型会受到附加在合法技能末尾的恶意指令影响，生成包含敏感工具意图的输出。通过引入一个简短的防御性系统提示，将技能视为不可信来源并禁止敏感操作，可有效阻止此类恶意工具调用，同时暴露可疑的隐藏指令。"
  },
  {
    "date": "2026-02-11",
    "title": "Canvas-of-Thought: Grounding Reasoning via Mutable Structured States",
    "authors": "Lingzhuang Sun, Yuxia Zhu, Ruitong Liu, Hao Liang, Zheng Sun, Caijun Jia, Honghao He, Yuchen Wu, Siyuan Li, Jingxuan Wei, Xiangxiang Zhang, Bihui Yu, Wentao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10494v1",
    "source": "arXiv",
    "abstract": "While Chain-of-Thought (CoT) prompting has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), relying solely on linear text sequences remains a bottleneck for complex tasks. We observe that even when auxiliary visual elements are interleaved, they are often treated as static snapshots within a one-dimensional, unstructured reasoning chain. We argue that such approaches treat reasoning history as an immutable stream: correcting a local error necessitates either generating verbose downstream corrections or regenerating the entire context. This forces the model to implicitly maintain and track state updates, significantly increasing token consumption and cognitive load. This limitation is particularly acute in high-dimensional domains, such as geometry and SVG design, where the textual expression of CoT lacks explicit visual guidance, further constraining the model's reasoning precision. To bridge this gap, we introduce \\textbf{Canvas-of-Thought (Canvas-CoT)}. By leveraging a HTML Canvas as an external reasoning substrate, Canvas-CoT empowers the model to perform atomic, DOM-based CRUD operations. This architecture enables in-place state revisions without disrupting the surrounding context, allowing the model to explicitly maintain the \"ground truth\". Furthermore, we integrate a rendering-based critique loop that serves as a hard constraint validator, providing explicit visual feedback to resolve complex tasks that are difficult to articulate through text alone. Extensive experiments on VCode, RBench-V, and MathVista demonstrate that Canvas-CoT significantly outperforms existing baselines, establishing a new paradigm for context-efficient multimodal reasoning.",
    "title_zh": "思维画布：通过可变结构状态实现推理的具象化",
    "abstract_zh": "尽管思维链（Chain-of-Thought, CoT）提示在提升多模态大语言模型（MLLMs）的推理能力方面取得了显著进展，但仅依赖线性文本序列仍成为复杂任务中的瓶颈。我们观察到，即使辅助的视觉元素被交错插入，它们通常仍被视为一维、非结构化推理链中的静态快照。我们认为，这类方法将推理历史视为不可变的流：一旦出现局部错误，模型要么生成冗长的下游修正，要么必须重新生成整个上下文。这迫使模型隐式地维护并追踪状态更新，显著增加了令牌消耗和认知负担。这一局限在高维领域（如几何学和SVG设计）尤为突出，因为CoT的文本表达缺乏明确的视觉引导，进一步限制了模型的推理精度。\n\n为弥合这一差距，我们提出**思维画布（Canvas-of-Thought, Canvas-CoT）**。通过利用HTML Canvas作为外部推理载体，Canvas-CoT使模型能够执行原子级的、基于DOM的增删改查（CRUD）操作。该架构支持原地状态修改，而无需破坏周围上下文，从而让模型能够显式维护“真实状态”。此外，我们引入了一种基于渲染的批判性反馈循环，作为硬性约束验证器，提供明确的视觉反馈，以解决仅靠文本难以表达的复杂任务。\n\n在VCode、RBench-V和MathVista等多个基准上的大量实验表明，Canvas-CoT显著优于现有基线方法，为高效上下文的多模态推理树立了新范式。"
  },
  {
    "date": "2026-02-11",
    "title": "Protecting Context and Prompts: Deterministic Security for Non-Deterministic AI",
    "authors": "Mohan Rajagopalan, Vinay Rao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10481v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM) applications are vulnerable to prompt injection and context manipulation attacks that traditional security models cannot prevent. We introduce two novel primitives--authenticated prompts and authenticated context--that provide cryptographically verifiable provenance across LLM workflows. Authenticated prompts enable self-contained lineage verification, while authenticated context uses tamper-evident hash chains to ensure integrity of dynamic inputs. Building on these primitives, we formalize a policy algebra with four proven theorems providing protocol-level Byzantine resistance--even adversarial agents cannot violate organizational policies. Five complementary defenses--from lightweight resource controls to LLM-based semantic validation--deliver layered, preventative security with formal guarantees. Evaluation against representative attacks spanning 6 exhaustive categories achieves 100% detection with zero false positives and nominal overhead. We demonstrate the first approach combining cryptographically enforced prompt lineage, tamper-evident context, and provable policy reasoning--shifting LLM security from reactive detection to preventative guarantees.",
    "title_zh": "保护上下文与提示：面向非确定性人工智能的确定性安全",
    "abstract_zh": "大型语言模型（LLM）应用易受提示注入和上下文操纵攻击的威胁，而传统安全模型无法有效防范此类攻击。我们提出两种新型基础构件——认证提示（authenticated prompts）和认证上下文（authenticated context），它们能够在整个LLM工作流中提供密码学可验证的来源追溯性。认证提示支持自包含的溯源验证，而认证上下文则利用抗篡改的哈希链确保动态输入的完整性。基于这些基础构件，我们形式化了一种策略代数，并证明了四个定理，实现了协议级别的拜占庭容错能力——即使存在恶意代理，也无法违反组织策略。我们进一步设计了五种互补的防御机制，涵盖轻量级资源控制到基于LLM的语义验证，构建了具有形式化保障的分层预防性安全体系。在针对六类代表性攻击的全面评估中，系统实现了100%的检测率，零误报率，且开销极低。我们首次提出一种结合密码学强制提示溯源、抗篡改上下文与可证明策略推理的综合方案，推动LLM安全从被动检测向主动预防保障的范式转变。"
  },
  {
    "date": "2026-02-11",
    "title": "GPU-Fuzz: Finding Memory Errors in Deep Learning Frameworks",
    "authors": "Zihao Li, Hongyi Lu, Yanan Guo, Zhenkai Zhang, Shuai Wang, Fengwei Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10478v1",
    "source": "arXiv",
    "abstract": "GPU memory errors are a critical threat to deep learning (DL) frameworks, leading to crashes or even security issues. We introduce GPU-Fuzz, a fuzzer locating these issues efficiently by modeling operator parameters as formal constraints. GPU-Fuzz utilizes a constraint solver to generate test cases that systematically probe error-prone boundary conditions in GPU kernels. Applied to PyTorch, TensorFlow, and PaddlePaddle, we uncovered 13 unknown bugs, demonstrating the effectiveness of GPU-Fuzz in finding memory errors.",
    "title_zh": "GPU-Fuzz：在深度学习框架中发现内存错误",
    "abstract_zh": "GPU内存错误对深度学习（DL）框架构成严重威胁，可能导致程序崩溃甚至引发安全问题。我们提出了GPU-Fuzz，这是一种高效的模糊测试工具，通过将算子参数建模为形式化约束来定位此类问题。GPU-Fuzz利用约束求解器生成测试用例，系统性地探测GPU内核中易出错的边界条件。该方法已应用于PyTorch、TensorFlow和PaddlePaddle，成功发现了13个未知漏洞，充分证明了GPU-Fuzz在发现内存错误方面的有效性。"
  },
  {
    "date": "2026-02-11",
    "title": "SecCodePRM: A Process Reward Model for Code Security",
    "authors": "Weichen Yu, Ravi Mangal, Yinyi Luo, Kai Hu, Jingxuan He, Corina S. Pasareanu, Matt Fredrikson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10418v1",
    "source": "arXiv",
    "abstract": "Large Language Models are rapidly becoming core components of modern software development workflows, yet ensuring code security remains challenging. Existing vulnerability detection pipelines either rely on static analyzers or use LLM/GNN-based detectors trained with coarse program-level supervision. Both families often require complete context, provide sparse end-of-completion feedback, and can degrade as code length grows, making them ill-suited for real-time, prefix-level assessment during interactive coding and streaming generation. We propose SecCodePRM, a security-oriented process reward model that assigns a context-aware, step-level security score along a code trajectory. To train the model, we derive step-level supervision labels from static analyzers and expert annotations, allowing the model to attend more precisely to fine-grained regions associated with inter-procedural vulnerabilities. SecCodePRM has three applications: full-code vulnerability detection (VD), partial-code VD, and secure code generation (CG). For VD, SecCodePRM uses risk-sensitive aggregation that emphasizes high-risk steps; for CG, SecCodePRM supports inference-time scaling by ranking candidate continuations and favoring higher cumulative reward. This design yields dense, real-time feedback that scales to long-horizon generation. Empirically, SecCodePRM outperforms prior approaches in all three settings, while preserving code functional correctness, suggesting improved security without a safety-utility tradeoff.",
    "title_zh": "SecCodePRM：一种用于代码安全的流程奖励模型",
    "abstract_zh": "大型语言模型正迅速成为现代软件开发工作流的核心组成部分，但保障代码安全仍面临挑战。现有的漏洞检测流程要么依赖静态分析工具，要么使用基于大语言模型（LLM）或图神经网络（GNN）的检测器，这些检测器通常以粗粒度的程序级监督进行训练。然而，这两类方法通常需要完整的上下文信息，仅提供稀疏的代码生成末尾反馈，并且随着代码长度增加而性能下降，因此难以适用于交互式编程和流式生成过程中的实时、前缀级安全评估。\n\n我们提出了 SecCodePRM，一种面向安全的流程奖励模型（Process Reward Model），能够在代码生成轨迹中为每个步骤分配上下文感知的、细粒度的安全评分。为训练该模型，我们从静态分析工具和专家标注中提取了步骤级的监督标签，使模型能够更精准地关注与跨过程漏洞相关的细粒度代码区域。SecCodePRM 具有三大应用：完整代码漏洞检测（VD）、部分代码漏洞检测（Partial VD）以及安全代码生成（CG）。\n\n在漏洞检测任务中，SecCodePRM 采用风险敏感的聚合策略，突出高风险步骤的影响；在代码生成任务中，SecCodePRM 支持推理阶段的可扩展性，通过排名候选续写内容并优先选择累积奖励更高的选项，实现更安全的生成路径。这种设计能够提供密集且实时的反馈，支持长序列生成任务。\n\n实验结果表明，SecCodePRM 在三种应用场景下均显著优于现有方法，同时保持了代码的功能正确性，表明其在不牺牲实用性的情况下有效提升了安全性，实现了安全与效率的双赢。"
  },
  {
    "date": "2026-02-11",
    "title": "GameDevBench: Evaluating Agentic Capabilities Through Game Development",
    "authors": "Wayne Chi, Yixiong Fang, Arnav Yayavaram, Siddharth Yayavaram, Seth Karten, Qiuhong Anna Wei, Runkun Chen, Alexander Wang, Valerie Chen, Ameet Talwalkar, Chris Donahue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11103v1",
    "source": "arXiv",
    "abstract": "Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials. Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development, with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity, with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development.",
    "title_zh": "GameDevBench：通过游戏开发评估智能体能力",
    "abstract_zh": "尽管在编码代理方面取得了快速进展，其多模态版本的发展却相对滞后。一个关键挑战在于缺乏能够同时融合软件开发复杂性与深层多模态理解需求的评估测试平台。游戏开发恰好提供了这样一个理想的测试环境：代理不仅需要在庞大而复杂的代码库中导航，还需在视觉游戏场景中操作内在多模态的资源，如着色器、精灵图和动画。为此，我们提出了GameDevBench——首个用于评估代理在游戏开发任务中表现的基准测试平台。GameDevBench包含132个任务，均源自网络教程和视频教学内容。这些任务要求高度的多模态理解能力，且整体复杂度显著更高——平均解决方案所需的代码行数和文件修改量是以往软件开发基准的三倍以上。目前，代理在游戏开发任务中仍表现不佳，最佳代理仅能完成54.5%的任务。我们发现，任务感知难度与多模态复杂度之间存在强烈相关性：在以游戏玩法为导向的任务上，成功率可达46.9%，而在2D图形类任务上则下降至31.6%。为提升代理的多模态能力，我们引入了两种简单但有效的基于图像和视频的反馈机制。尽管方法简洁，但它们能持续提升性能，其中最显著的效果体现在Claude Sonnet 4.5上，其表现从33.3%提升至47.7%。我们已将GameDevBench公开发布，以推动智能体在游戏开发领域的进一步研究。"
  },
  {
    "date": "2026-02-11",
    "title": "Hidden Licensing Risks in the LLMware Ecosystem",
    "authors": "Bo Wang, Yueyang Chen, Jieke Shi, Minghui Li, Yunbo Lyu, Yinan Wu, Youfang Lin, Zhou Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10758v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly integrated into software systems, giving rise to a new class of systems referred to as LLMware. Beyond traditional source-code components, LLMware embeds or interacts with LLMs that depend on other models and datasets, forming complex supply chains across open-source software (OSS), models, and datasets. However, licensing issues emerging from these intertwined dependencies remain largely unexplored. Leveraging GitHub and Hugging Face, we curate a large-scale dataset capturing LLMware supply chains, including 12,180 OSS repositories, 3,988 LLMs, and 708 datasets. Our analysis reveals that license distributions in LLMware differ substantially from traditional OSS ecosystems. We further examine license-related discussions and find that license selection and maintenance are the dominant concerns, accounting for 84% of cases. To understand incompatibility risks, we analyze license conflicts along supply chains and evaluate state-of-the-art detection approaches, which achieve only 58% and 76% F1 scores in this setting. Motivated by these limitations, we propose LiAgent, an LLM-based agent framework for ecosystem-level license compatibility analysis. LiAgent achieves an F1 score of 87%, improving performance by 14 percentage points over prior methods. We reported 60 incompatibility issues detected by LiAgent, 11 of which have been confirmed by developers. Notably, two conflicted LLMs have over 107 million and 5 million downloads on Hugging Face, respectively, indicating potentially widespread downstream impact. We conclude with implications and recommendations to support the sustainable growth of the LLMware ecosystem.",
    "title_zh": "LLMware 生态系统中的隐藏许可风险",
    "abstract_zh": "大型语言模型（LLMs）正越来越多地被集成到软件系统中，催生了一类新型系统，称为LLMware。与传统软件系统仅依赖源代码组件不同，LLMware不仅嵌入或与大型语言模型交互，还依赖于其他模型和数据集，从而在开源软件（OSS）、模型和数据集之间形成了复杂的供应链。然而，这些相互交织的依赖关系所引发的许可问题目前仍缺乏深入研究。我们基于GitHub和Hugging Face构建了一个大规模数据集，全面捕捉LLMware的供应链信息，涵盖12,180个开源软件仓库、3,988个大型语言模型以及708个数据集。我们的分析发现，LLMware中的许可证分布与传统开源生态系统存在显著差异。进一步对许可证相关讨论的分析表明，许可证的选择与维护是主要关注点，占所有案例的84%。为评估许可不兼容风险，我们分析了供应链中的许可证冲突，并评估了当前最先进的检测方法，结果发现其F1分数仅为58%和76%。针对这些局限性，我们提出了LiAgent——一种基于大型语言模型的代理框架，用于生态系统级别的许可证兼容性分析。LiAgent在该任务中取得了87%的F1分数，相比先前方法提升了14个百分点。我们通过LiAgent报告了60个发现的许可证不兼容问题，其中11个已得到开发者的确认。值得注意的是，其中两个存在冲突的模型在Hugging Face上的下载量分别超过1.07亿次和500万次，表明其潜在的下游影响范围广泛。最后，我们总结了相关启示与建议，以支持LLMware生态系统的可持续发展。"
  },
  {
    "date": "2026-02-11",
    "title": "Drawing Your Programs: Exploring the Applications of Visual-Prompting with GenAI for Teaching and Assessment",
    "authors": "David H. Smith, S. Moonwara A. Monisha, Annapurna Vadaparty, Leo Porter, Daniel Zingaro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10529v1",
    "source": "arXiv",
    "abstract": "When designing a program, both novice programmers and seasoned developers alike often sketch out -- or, perhaps more famously, whiteboard -- their ideas. Yet despite the introduction of natively multimodal Generative AI models, work on Human-GenAI collaborative coding has remained overwhelmingly focused on textual prompts -- largely ignoring the visual and spatial representations that programmers naturally use to reason about and communicate their designs. In this proposal and position paper, we argue and provide tentative evidence that this text-centric focus overlooks other forms of prompting GenAI models, such as problem decomposition diagrams functioning as prompts for code generation in their own right enabling new types of programming activities and assessments. To support this position, we present findings from a large introductory Python programming course, where students constructed decomposition diagrams that were used to prompt GPT-4.1 for code generation. We demonstrate that current models are very successful in their ability to generate code from student-constructed diagrams. We conclude by exploring the implications of embracing multimodal prompting for computing education, particularly in the context of assessment.",
    "title_zh": "绘制你的程序：探索生成式人工智能中视觉提示在教学与评估中的应用",
    "abstract_zh": "在设计程序时，无论是新手程序员还是经验丰富的开发者，常常会勾画出——或更广为人知的是，在白板上绘制——他们的想法。然而，尽管原生多模态生成式人工智能（GenAI）模型已经出现，关于人与GenAI协作编程的研究仍主要集中在文本提示上，很大程度上忽视了程序员在推理和交流设计时自然使用的视觉和空间表达方式。在本文的提案与立场论文中，我们主张并提供初步证据，表明这种以文本为中心的研究取向忽略了其他形式的GenAI提示方式，例如作为代码生成独立提示的问题分解图。这类图示能够开启新型编程活动与评估方式。为支持这一观点，我们呈现了一项大型初级Python编程课程的研究发现：学生绘制的分解图被用作GPT-4.1的提示，以生成代码。我们证明，当前模型在根据学生构建的图表生成代码方面表现出极高的成功率。最后，我们探讨了在计算教育中采纳多模态提示所带来的深远影响，尤其是在评估方面的意义。"
  },
  {
    "date": "2026-02-11",
    "title": "Consistency Meets Verification: Enhancing Test Generation Quality in Large Language Models Without Ground-Truth Solutions",
    "authors": "Hamed Taherkhani, Alireza DaghighFarsoodeh, Mohammad Chowdhury, Hung Viet Pham, Hadi Hemmati",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10522v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have significantly advanced automated test generation, yet existing methods often rely on ground-truth code for verification, risking bug propagation and limiting applicability in test-driven development. We present ConVerTest, a novel two-stage pipeline for synthesizing reliable tests without requiring prior code implementations. ConVerTest integrates three core strategies: (i) Self-Consistency(SC) to generate convergent test cases via majority voting; (ii) Chain-of-Verification (CoVe) for iterative, reasoning-guided code refinement; and (iii) a Dual Execution Agreement to crossvalidate code and tests through consensus. Experiments on BIGCODEBENCH and LESS BASIC PYTHON PROBLEMS (LBPP) benchmarks demonstrate that ConVerTest improves test validity, line coverage, and mutation scores by up to 39%, 28%, and 18% respectively over baselines. Our findings highlight ConVerTest as a robust solution for mitigating hallucinations and enhancing the reliability of autonomous software testing agents.",
    "title_zh": "一致性与验证的结合：在无真实答案的情况下提升大型语言模型测试生成质量",
    "abstract_zh": "大型语言模型（LLMs）在自动化测试生成方面取得了显著进展，但现有方法通常依赖于真实代码进行验证，存在漏洞传播的风险，并限制了其在测试驱动开发中的应用。我们提出了ConVerTest，一种新颖的两阶段测试合成框架，能够在无需预先提供代码实现的情况下生成可靠的测试用例。ConVerTest融合了三种核心策略：(i) 自我一致性（Self-Consistency, SC），通过多数投票机制生成收敛的测试用例；(ii) 验证链（Chain-of-Verification, CoVe），实现基于推理引导的迭代式代码优化；(iii) 双执行一致性机制，通过共识方式交叉验证代码与测试。在BIGCODEBENCH和LESS BASIC PYTHON PROBLEMS（LBPP）基准上的实验表明，相较于基线方法，ConVerTest在测试有效性、行覆盖率和突变得分方面分别提升了最高达39%、28%和18%。研究结果表明，ConVerTest是一种有效缓解幻觉问题、提升自主软件测试代理可靠性的稳健解决方案。"
  },
  {
    "date": "2026-02-11",
    "title": "Following Dragons: Code Review-Guided Fuzzing",
    "authors": "Viet Hoang Luu, Amirmohammad Pasdar, Wachiraphan Charoenwet, Toby Murray, Shaanan Cohney, Van-Thuan Pham",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10487v1",
    "source": "arXiv",
    "abstract": "Modern fuzzers scale to large, real-world software but often fail to exercise the program states developers consider most fragile or security-critical. Such states are typically deep in the execution space, gated by preconditions, or overshadowed by lower-value paths that consume limited fuzzing budgets. Meanwhile, developers routinely surface risk-relevant insights during code review, yet this information is largely ignored by automated testing tools. We present EyeQ, a system that leverages developer intelligence from code reviews to guide fuzzing. EyeQ extracts security-relevant signals from review discussions, localizes the implicated program regions, and translates these insights into annotation-based guidance for fuzzing. The approach operates atop existing annotation-aware fuzzing, requiring no changes to program semantics or developer workflows. We first validate EyeQ through a human-guided feasibility study on a security-focused dataset of PHP code reviews, establishing a strong baseline for review-guided fuzzing. We then automate the workflow using a large language model with carefully designed prompts. EyeQ significantly improves vulnerability discovery over standard fuzzing configurations, uncovering more than 40 previously unknown bugs in the security-critical PHP codebase.",
    "title_zh": "追龙：基于代码审查的模糊测试",
    "abstract_zh": "现代模糊测试工具能够扩展至大型真实软件，但往往无法有效触发开发者认为最脆弱或安全关键的程序状态。这些状态通常深藏于执行空间之中，受制于前置条件，或被消耗有限模糊测试预算的低价值路径所掩盖。与此同时，开发人员在代码审查过程中经常揭示出与风险相关的重要见解，但这些信息却大多被自动化测试工具忽视。我们提出了EyeQ系统，该系统利用代码审查中的开发者智慧来引导模糊测试。EyeQ从审查讨论中提取与安全相关的信号，定位受影响的程序区域，并将这些洞察转化为基于注释的模糊测试指导。该方法可直接运行在现有的注释感知模糊测试框架之上，无需修改程序语义或开发人员的工作流程。我们首先通过一项由人工引导的可行性研究，在一个聚焦安全性的PHP代码审查数据集上验证了EyeQ的有效性，建立了审查引导模糊测试的坚实基准。随后，我们采用经过精心设计提示词的大语言模型自动化整个工作流程。实验结果表明，EyeQ显著提升了漏洞发现能力，相较于标准模糊测试配置，在关键安全的PHP代码库中发现了40多个此前未知的漏洞。"
  },
  {
    "date": "2026-02-11",
    "title": "Authenticated Workflows: A Systems Approach to Protecting Agentic AI",
    "authors": "Mohan Rajagopalan, Vinay Rao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10465v1",
    "source": "arXiv",
    "abstract": "Agentic AI systems automate enterprise workflows but existing defenses--guardrails, semantic filters--are probabilistic and routinely bypassed. We introduce authenticated workflows, the first complete trust layer for enterprise agentic AI. Security reduces to protecting four fundamental boundaries: prompts, tools, data, and context. We enforce intent (operations satisfy organizational policies) and integrity (operations are cryptographically authentic) at every boundary crossing, combining cryptographic elimination of attack classes with runtime policy enforcement. This delivers deterministic security--operations either carry valid cryptographic proof or are rejected. We introduce MAPL, an AI-native policy language that expresses agentic constraints dynamically as agents evolve and invocation context changes, scaling as O(log M + N) policies versus O(M x N) rules through hierarchical composition with cryptographic attestations for workflow dependencies. We prove practicality through a universal security runtime integrating nine leading frameworks (MCP, A2A, OpenAI, Claude, LangChain, CrewAI, AutoGen, LlamaIndex, Haystack) through thin adapters requiring zero protocol modifications. Formal proofs establish completeness and soundness. Empirical validation shows 100% recall with zero false positives across 174 test cases, protection against 9 of 10 OWASP Top 10 risks, and complete mitigation of two high impact production CVEs.",
    "title_zh": "可信工作流：一种系统化方法保护代理型人工智能",
    "abstract_zh": "智能代理AI系统能够自动化企业工作流程，但现有的防御机制——如护栏机制、语义过滤器——具有概率性，且经常被绕过。我们提出了“认证工作流”（authenticated workflows），这是首个面向企业级智能代理AI的完整信任层。安全的核心简化为保护四个基本边界：提示（prompts）、工具（tools）、数据（data）和上下文（context）。我们在每个边界跨越处强制执行意图（操作符合组织策略）和完整性（操作具有密码学上的真实性），结合密码学手段消除攻击类别与运行时策略执行，实现确定性安全——即操作要么携带有效的密码学证明，要么被直接拒绝。\n\n我们引入了MAPL（Machine-Authored Policy Language），一种面向AI的策略语言，能够动态表达智能代理在演化过程中及调用上下文变化时的约束条件。通过分层组合与工作流依赖关系的密码学证明，其策略扩展性达到O(log M + N)，远优于传统方法中O(M × N)的规则数量。我们通过一个通用安全运行时验证了其实用性，该运行时通过轻量级适配器无缝集成九个主流框架（MCP、A2A、OpenAI、Claude、LangChain、CrewAI、AutoGen、LlamaIndex、Haystack），且无需修改任何协议。形式化证明确保了系统的完备性与正确性。实证验证表明，在174个测试用例中实现了100%的召回率且零误报，有效防护了OWASP Top 10中9项风险，并完全缓解了两项高危生产环境CVE。"
  },
  {
    "date": "2026-02-11",
    "title": "Constructing Industrial-Scale Optimization Modeling Benchmark",
    "authors": "Zhong Li, Hongliang Lu, Tao Wei, Wenyu Liu, Yuxuan Chen, Yuan Lan, Fan Zhang, Zaiwen Wen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10450v1",
    "source": "arXiv",
    "abstract": "Optimization modeling underpins decision-making in logistics, manufacturing, energy, and finance, yet translating natural-language requirements into correct optimization formulations and solver-executable code remains labor-intensive. Although large language models (LLMs) have been explored for this task, evaluation is still dominated by toy-sized or synthetic benchmarks, masking the difficulty of industrial problems with $10^{3}$--$10^{6}$ (or more) variables and constraints. A key bottleneck is the lack of benchmarks that align natural-language specifications with reference formulations/solver code grounded in real optimization models. To fill in this gap, we introduce MIPLIB-NL, built via a structure-aware reverse construction methodology from real mixed-integer linear programs in MIPLIB~2017. Our pipeline (i) recovers compact, reusable model structure from flat solver formulations, (ii) reverse-generates natural-language specifications explicitly tied to this recovered structure under a unified model--data separation format, and (iii) performs iterative semantic validation through expert review and human--LLM interaction with independent reconstruction checks. This yields 223 one-to-one reconstructions that preserve the mathematical content of the original instances while enabling realistic natural-language-to-optimization evaluation. Experiments show substantial performance degradation on MIPLIB-NL for systems that perform strongly on existing benchmarks, exposing failure modes invisible at toy scale.",
    "title_zh": "构建工业规模优化建模基准",
    "abstract_zh": "优化建模支撑着物流、制造、能源和金融等领域的决策，然而将自然语言需求转化为正确的优化公式和可由求解器执行的代码，仍然是一项耗时费力的工作。尽管大型语言模型（LLMs）已被探索用于此任务，但当前的评估仍主要依赖于小型或合成的基准测试，掩盖了工业级问题中变量和约束数量高达 $10^{3}$ 到 $10^{6}$（甚至更多）所带来的实际挑战。一个关键瓶颈在于缺乏能够将自然语言规范与基于真实优化模型的参考公式/求解器代码对齐的基准数据集。为填补这一空白，我们提出了 MIPLIB-NL，该数据集通过从 MIPLIB~2017 中真实混合整数线性规划实例出发，采用结构感知的逆向构建方法生成。我们的流程包括：(i) 从扁平化的求解器公式中恢复出紧凑且可复用的模型结构；(ii) 在统一的“模型-数据”分离格式下，逆向生成与该恢复结构明确关联的自然语言描述；(iii) 通过专家评审以及人与LLM的交互式迭代语义验证，并结合独立重建检查，确保生成质量。最终我们获得了223个一对一的重建实例，在完整保留原始实例数学内容的同时，实现了真实场景下的自然语言到优化建模的评估。实验表明，那些在现有基准上表现优异的系统在 MIPLIB-NL 上出现了显著性能下降，暴露出在小规模玩具问题中无法察觉的失败模式。"
  },
  {
    "date": "2026-02-11",
    "title": "Control Reinforcement Learning: Token-Level Mechanistic Analysis via Learned SAE Feature Steering",
    "authors": "Seonglae Cho, Zekun Wu, Adriano Koshiyama",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10437v1",
    "source": "arXiv",
    "abstract": "Sparse autoencoders (SAEs) decompose language model activations into interpretable features, but existing methods reveal only which features activate, not which change model outputs when amplified. We introduce Control Reinforcement Learning (CRL), which trains a policy to select SAE features for steering at each token, producing interpretable intervention logs: the learned policy identifies features that change model outputs when amplified. Adaptive Feature Masking encourages diverse feature discovery while preserving singlefeature interpretability. The framework yields new analysis capabilities: branch point tracking locates tokens where feature choice determines output correctness; critic trajectory analysis separates policy limitations from value estimation errors; layer-wise comparison reveals syntactic features in early layers and semantic features in later layers. On Gemma-2 2B across MMLU, BBQ, GSM8K, HarmBench, and XSTest, CRL achieves improvements while providing per-token intervention logs. These results establish learned feature steering as a mechanistic interpretability tool that complements static feature analysis with dynamic intervention probes",
    "title_zh": "控制强化学习：通过学习的SAE特征操控实现标记级机制分析",
    "abstract_zh": "稀疏自编码器（SAEs）将语言模型的激活分解为可解释的特征，但现有方法仅能揭示哪些特征被激活，而无法说明哪些特征在被放大时会改变模型输出。我们提出了控制强化学习（Control Reinforcement Learning, CRL），该方法训练一个策略，在每个标记（token）处选择SAE特征以实现模型引导，从而生成可解释的干预日志：所学习的策略能够识别出在被放大时会改变模型输出的特征。自适应特征掩码（Adaptive Feature Masking）在保持单特征可解释性的前提下，促进多样化特征的发现。该框架带来了新的分析能力：分支点追踪可定位决定输出正确性的关键token；批评者轨迹分析能够区分策略局限性与价值估计误差；分层比较揭示了早期层中存在句法特征，而后期层中则出现语义特征。在Gemma-2 2B模型上，针对MMLU、BBQ、GSM8K、HarmBench和XSTest等多个基准测试，CRL不仅实现了性能提升，还提供了逐token的干预日志。这些结果确立了学习到的特征引导作为一种机制可解释性工具，通过动态干预探针，补充了静态特征分析的不足。"
  },
  {
    "date": "2026-02-11",
    "title": "CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion",
    "authors": "Yusong Lin, Haiyang Wang, Shuzhe Wu, Lue Fan, Feiyang Pan, Sanyuan Zhao, Dandan Tu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10999v1",
    "source": "arXiv",
    "abstract": "Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to enhance agents' capabilities. To address this, based on an analogy between the Dockerfile and the agentic task, we propose to employ agents to simulate and explore environment histories, guided by execution feedback. By tracing histories of a healthy environment, its state can be inverted to an earlier one with runtime failures, from which a task can be derived by packing the buggy state and the corresponding error messages. With our method, named CLI-Gym, a total of 1,655 environment-intensive tasks are derived, being the largest collection of its kind. Moreover, with curated successful trajectories, our fine-tuned model, named LiberCoder, achieves substantial absolute improvements of +21.1% (to 46.1%) on Terminal-Bench, outperforming various strong baselines. To our knowledge, this is the first public pipeline for scalable derivation of environment-intensive tasks.",
    "title_zh": "CLI-Gym：通过代理环境反演实现可扩展的CLI任务生成",
    "abstract_zh": "代理编程要求智能体能够有效与运行时环境（如命令行界面CLI）进行交互，以完成诸如解决依赖问题、修复系统故障等任务。然而，目前尚缺乏对如何大规模获取这类环境密集型任务的研究，以提升智能体的能力。为解决这一问题，我们基于Dockerfile与代理任务之间的类比，提出利用智能体模拟并探索环境的历史状态，同时借助执行反馈进行引导。通过追踪健康环境的历史轨迹，可以反向推导出存在运行时故障的早期状态，并通过打包有缺陷的状态及其对应的错误信息，生成相应的任务。基于该方法，我们提出了名为CLI-Gym的框架，共生成了1,655个环境密集型任务，成为目前同类任务中规模最大的集合。此外，结合精心筛选的成功轨迹进行微调后，我们的模型LiberCoder在Terminal-Bench测试集上取得了46.1%的准确率，相比基线模型实现了21.1%的绝对提升，表现优于多种强基线方法。据我们所知，这是首个公开的、可扩展地生成环境密集型任务的完整流水线。"
  },
  {
    "date": "2026-02-11",
    "title": "TVCACHE: A Stateful Tool-Value Cache for Post-Training LLM Agents",
    "authors": "Abhishek Vijaya Kumar, Bhaskar Kataria, Byungsoo Oh, Emaad Manzoor, Rachee Singh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10986v1",
    "source": "arXiv",
    "abstract": "In RL post-training of LLM agents, calls to external tools take several seconds or even minutes, leaving allocated GPUs idle and inflating post-training time and cost. While many tool invocations repeat across parallel rollouts and could in principle be cached, naively caching their outputs for reuse is incorrect since tool outputs depend on the environment state induced by prior agent interactions. We present TVCACHE, a stateful tool-value cache for LLM agent post-training. TVCACHE maintains a tree of observed tool-call sequences and performs longest-prefix matching for cache lookups: a hit occurs only when the agent's full tool history matches a previously executed sequence, guaranteeing identical environment state. On three diverse workloads-terminal-based tasks, SQL generation, and video understanding. TVCACHE achieves cache hit rates of up to 70% and reduces median tool call execution time by up to 6.9X, with no degradation in post-training reward accumulation.",
    "title_zh": "TVCACHE：一种用于训练后大语言模型代理的状态化工具-价值缓存",
    "abstract_zh": "在大语言模型（LLM）智能体的强化学习（RL）后训练过程中，调用外部工具通常需要数秒甚至数分钟，导致分配的GPU处于空闲状态，显著增加了后训练的时间和成本。尽管在并行的轨迹采集中，许多工具调用会重复出现，理论上可以进行缓存，但若简单地缓存输出以供重用，则是不正确的，因为工具的输出依赖于先前智能体交互所引发的环境状态。为此，我们提出了 TVCACHE，一种面向LLM智能体后训练的有状态工具-值缓存机制。TCACHE通过维护一个已观测到的工具调用序列的树结构，并在缓存查找时执行最长前缀匹配：只有当智能体的完整工具调用历史与之前执行过的序列完全匹配时，才视为缓存命中，从而确保环境状态完全一致。在三个不同类型的负载上——基于终端的任务、SQL生成以及视频理解——TCACHE实现了高达70%的缓存命中率，并将工具调用的中位执行时间减少最多6.9倍，同时未对后训练过程中的奖励累积造成任何负面影响。"
  },
  {
    "date": "2026-02-11",
    "title": "SimuScene: Training and Benchmarking Code Generation to Simulate Physical Scenarios",
    "authors": "Yanan Wang, Renxi Wang, Yongxin Wang, Xuezhi Liang, Fajri Koto, Timothy Baldwin, Xiaodan Liang, Haonan Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10840v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have been extensively studied for tasks like math competitions, complex coding, and scientific reasoning, yet their ability to accurately represent and simulate physical scenarios via code remains underexplored. We propose SimuScene, the first systematic study that trains and evaluates LLMs on simulating physical scenarios across five physics domains and 52 physical concepts. We build an automatic pipeline to collect data, with human verification to ensure quality. The final dataset contains 7,659 physical scenarios with 334 human-verified examples as the test set. We evaluated 10 contemporary LLMs and found that even the strongest model achieves only a 21.5% pass rate, demonstrating the difficulty of the task. Finally, we introduce a reinforcement learning pipeline with visual rewards that uses a vision-language model as a judge to train textual models. Experiments show that training with our data improves physical simulation via code while substantially enhancing general code generation performance.",
    "title_zh": "SimuScene：用于模拟物理场景的代码生成训练与基准测试",
    "abstract_zh": "大型语言模型（LLMs）在数学竞赛、复杂编程和科学推理等任务上已得到广泛研究，但其通过代码准确表征与模拟物理场景的能力仍鲜有探索。我们提出了SimuScene，这是首个系统性地训练和评估LLMs在五个物理领域及52个物理概念上模拟物理场景的研究。我们构建了一个自动化的数据收集流程，并辅以人工验证以确保数据质量。最终的数据集包含7,659个物理场景，其中334个经过人工验证的样本作为测试集。我们评估了10个主流LLM，发现即使是表现最强的模型，其通过率也仅为21.5%，充分体现了该任务的难度。最后，我们引入了一种基于视觉奖励的强化学习流程，利用视觉-语言模型作为评判者来训练文本模型。实验表明，使用我们的数据进行训练不仅显著提升了代码对物理场景的模拟能力，还大幅增强了模型的一般代码生成性能。"
  },
  {
    "date": "2026-02-11",
    "title": "Learning to Compose for Cross-domain Agentic Workflow Generation",
    "authors": "Jialiang Wang, Shengxiang Xu, Hanmo Liu, Jiachuan Wang, Yuyu Luo, Shimin Di, Min-Ling Zhang, Lei Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11114v1",
    "source": "arXiv",
    "abstract": "Automatically generating agentic workflows -- executable operator graphs or codes that orchestrate reasoning, verification, and repair -- has become a practical way to solve complex tasks beyond what single-pass LLM generation can reliably handle. Yet what constitutes a good workflow depends heavily on the task distribution and the available operators. Under domain shift, current systems typically rely on iterative workflow refinement to discover a feasible workflow from a large workflow space, incurring high iteration costs and yielding unstable, domain-specific behavior. In response, we internalize a decompose-recompose-decide mechanism into an open-source LLM for cross-domain workflow generation. To decompose, we learn a compact set of reusable workflow capabilities across diverse domains. To recompose, we map each input task to a sparse composition over these bases to generate a task-specific workflow in a single pass. To decide, we attribute the success or failure of workflow generation to counterfactual contributions from learned capabilities, thereby capturing which capabilities actually drive success by their marginal effects. Across stringent multi-domain, cross-domain, and unseen-domain evaluations, our 1-pass generator surpasses SOTA refinement baselines that consume 20 iterations, while substantially reducing generation latency and cost.",
    "title_zh": "学习跨域代理工作流生成的组合方法",
    "abstract_zh": "自动生成智能体工作流——可执行的操作符图或代码，用于协调推理、验证与修复——已成为解决复杂任务的有效方法，这些任务超出了单次生成的大型语言模型（LLM）所能可靠处理的范围。然而，一个优质工作流的构成在很大程度上取决于任务分布和可用操作符。当面临领域迁移时，现有系统通常依赖迭代式工作流优化，从庞大的工作流空间中逐步发现可行方案，这导致迭代成本高昂，并产生不稳定且高度依赖特定领域的行为。针对这一问题，我们提出将“分解-重构-决策”机制内化至一个开源大语言模型中，以实现跨领域的高效工作流生成。在“分解”阶段，我们学习了一组紧凑且可在多种领域复用的工作流能力；在“重构”阶段，我们将每个输入任务映射为这些基础能力的稀疏组合，从而在单次通过中生成特定任务的工作流；在“决策”阶段，我们通过反事实分析，评估所学能力对工作流生成成败的贡献，从而捕捉到真正驱动成功的关键能力及其边际效应。在严格的多领域、跨领域及未见领域评估中，我们的单次生成器在性能上超越了需消耗20次迭代的最先进优化基线，同时显著降低了生成延迟与成本。"
  },
  {
    "date": "2026-02-11",
    "title": "Why Human Guidance Matters in Collaborative Vibe Coding",
    "authors": "Haoyu Hu, Raja Marjieh, Katherine M Collins, Chenyi Li, Thomas L. Griffiths, Ilia Sucholutsky, Nori Jacoby",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10473v1",
    "source": "arXiv",
    "abstract": "Writing code has been one of the most transformative ways for human societies to translate abstract ideas into tangible technologies. Modern AI is transforming this process by enabling experts and non-experts alike to generate code without actually writing code, but instead, through natural language instructions, or \"vibe coding\". While increasingly popular, the cumulative impact of vibe coding on productivity and collaboration, as well as the role of humans in this process, remains unclear. Here, we introduce a controlled experimental framework for studying collaborative vibe coding and use it to compare human-led, AI-led, and hybrid groups. Across 16 experiments involving 604 human participants, we show that people provide uniquely effective high-level instructions for vibe coding across iterations, whereas AI-provided instructions often result in performance collapse. We further demonstrate that hybrid systems perform best when humans retain directional control (providing the instructions), while evaluation is delegated to AI.",
    "title_zh": "为什么人类指导在协作式氛围编码中至关重要",
    "abstract_zh": "编写代码是人类社会将抽象思想转化为具体技术的最具变革性的方式之一。现代人工智能正在改变这一过程，使专家和非专家都能通过自然语言指令——即“氛围编程”（vibe coding）——生成代码，而无需实际编写代码。尽管这种模式日益流行，但其对生产力和协作的累积影响，以及人类在这一过程中的角色，仍不明确。本文提出了一种受控的实验框架，用于研究协作式氛围编程，并在此基础上比较由人类主导、AI主导以及人机混合的团队。在涉及604名人类参与者的16项实验中，我们发现：在多轮迭代中，人类能够提供独特而高效的高层级指令，而AI生成的指令往往导致性能急剧下降。此外，我们进一步证明，当人类保持方向性控制（即提供指令），而将评估工作交由AI时，人机混合系统的表现最佳。"
  },
  {
    "date": "2026-02-11",
    "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters",
    "authors": "Ailin Huang, Ang Li, Aobo Kong, Bin Wang, Binxing Jiao, Bo Dong, Bojun Wang, Boyu Chen, Brian Li, Buyun Ma, Chang Su, Changxin Miao, Changyi Wan, Chao Lou, Chen Hu, Chen Xu, Chenfeng Yu, Chengting Feng, Chengyuan Yao, Chunrui Han, Dan Ma, Dapeng Shi, Daxin Jiang, Dehua Ma, Deshan Sun, Di Qi, Enle Liu, Fajie Zhang, Fanqi Wan, Guanzhe Huang, Gulin Yan, Guoliang Cao, Guopeng Li, Han Cheng, Hangyu Guo, Hanshan Zhang, Hao Nie, Haonan Jia, Haoran Lv, Hebin Zhou, Hekun Lv, Heng Wang, Heung-Yeung Shum, Hongbo Huang, Hongbo Peng, Hongyu Zhou, Hongyuan Wang, Houyong Chen, Huangxi Zhu, Huimin Wu, Huiyong Guo, Jia Wang, Jian Zhou, Jianjian Sun, Jiaoren Wu, Jiaran Zhang, Jiashu Lv, Jiashuo Liu, Jiayi Fu, Jiayu Liu, Jie Cheng, Jie Luo, Jie Yang, Jie Zhou, Jieyi Hou, Jing Bai, Jingcheng Hu, Jingjing Xie, Jingwei Wu, Jingyang Zhang, Jishi Zhou, Junfeng Liu, Junzhe Lin, Ka Man Lo, Kai Liang, Kaibo Liu, Kaijun Tan, Kaiwen Yan, Kaixiang Li, Kang An, Kangheng Lin, Lei Yang, Liang Lv, Liang Zhao, Liangyu Chen, Lieyu Shi, Liguo Tan, Lin Lin, Lina Chen, Luck Ma, Mengqiang Ren, Michael Li, Ming Li, Mingliang Li, Mingming Zhang, Mingrui Chen, Mitt Huang, Na Wang, Peng Liu, Qi Han, Qian Zhao, Qinglin He, Qinxin Du, Qiuping Wu, Quan Sun, Rongqiu Yang, Ruihang Miao, Ruixin Han, Ruosi Wan, Ruyan Guo, Shan Wang, Shaoliang Pang, Shaowen Yang, Shengjie Fan, Shijie Shang, Shiliang Yang, Shiwei Li, Shuangshuang Tian, Siqi Liu, Siye Wu, Siyu Chen, Song Yuan, Tiancheng Cao, Tianchi Yue, Tianhao Cheng, Tianning Li, Tingdan Luo, Wang You, Wei Ji, Wei Yuan, Wei Zhang, Weibo Wu, Weihao Xie, Wen Sun, Wenjin Deng, Wenzhen Zheng, Wuxun Xie, Xiangfeng Wang, Xiangwen Kong, Xiangyu Liu, Xiangyu Zhang, Xiaobo Yang, Xiaojia Liu, Xiaolan Yuan, Xiaoran Jiao, Xiaoxiao Ren, Xiaoyun Zhang, Xin Li, Xin Liu, Xin Wu, Xing Chen, Xingping Yang, Xinran Wang, Xu Zhao, Xuan He, Xuanti Feng, Xuedan Cai, Xuqiang Zhou, Yanbo Yu, Yang Li, Yang Xu, Yanlin Lai, Yanming Xu, Yaoyu Wang, Yeqing Shen, Yibo Zhu, Yichen Lv, Yicheng Cao, Yifeng Gong, Yijing Yang, Yikun Yang, Yin Zhao, Yingxiu Zhao, Yinmin Zhang, Yitong Zhang, Yixuan Zhang, Yiyang Chen, Yongchi Zhao, Yongshen Long, Yongyao Wang, Yousong Guan, Yu Zhou, Yuang Peng, Yuanhao Ding, Yuantao Fan, Yuanzhen Yang, Yuchu Luo, Yudi Zhao, Yue Peng, Yueqiang Lin, Yufan Lu, Yuling Zhao, Yunzhou Ju, Yurong Zhang, Yusheng Li, Yuxiang Yang, Yuyang Chen, Yuzhu Cai, Zejia Weng, Zetao Hong, Zexi Li, Zhe Xie, Zheng Ge, Zheng Gong, Zheng Zeng, Zhenyi Lu, Zhewei Huang, Zhichao Chang, Zhiguo Huang, Zhiheng Hu, Zidong Yang, Zili Wang, Ziqi Ren, Zixin Zhang, Zixuan Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10604v1",
    "source": "arXiv",
    "abstract": "We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.",
    "title_zh": "步骤3.5 快闪：以110亿个活跃参数开启前沿级智能",
    "abstract_zh": "我们推出 Step 3.5 Flash，这是一款稀疏的混合专家（MoE）模型，成功实现了前沿级智能代理与计算效率之间的平衡。在构建智能体时，我们聚焦于最关键的因素：精准的推理能力与快速、可靠的执行性能。Step 3.5 Flash 采用一个 1960 亿参数的基础模型，仅激活 110 亿参数以实现高效的推理。通过引入交错的 3:1 滑动窗口/全注意力机制以及多标记预测（MTP-3），显著降低了多轮智能体交互中的延迟与成本。为达到前沿级智能水平，我们设计了一套可扩展的强化学习框架，结合可验证信号与偏好反馈，在大规模离策略训练下仍保持稳定，从而在数学、编程和工具使用等任务中实现持续的自我优化。Step 3.5 Flash 在各类智能体、编程和数学任务中均表现出色，具体表现如下：IMO-AnswerBench 达到 85.4%，LiveCodeBench-v6（2024.08–2025.05）达 86.4%，tau2-Bench 达 88.2%，BrowseComp（具备上下文管理能力）达 69.0%，Terminal-Bench 2.0 达 51.0%，性能与 GPT-5.2 xHigh 和 Gemini 3.0 Pro 等前沿模型相当。通过重新定义效率边界，Step 3.5 Flash 为在真实工业环境中部署复杂智能体提供了高密度的基础支撑。"
  },
  {
    "date": "2026-02-11",
    "title": "Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets",
    "authors": "Bo Xue, Yunchong Song, Fanghao Shao, Xuekai Zhu, Lin Chen, Luoyi Fu, Xinbing Wang, Zhouhan Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10583v1",
    "source": "arXiv",
    "abstract": "Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic vocabulary by sampling retrieved text spans but overlooks that the same sentence can be composed of spans of varying lengths, lacking explicit modeling of the directed acyclic graph (DAG) state space. This leads to restricted exploration of compositional paths and is biased toward the chosen path. Generative Flow Networks (GFlowNets) are powerful for efficient exploring and generalizing over state spaces, particularly those with a DAG structure. However, prior GFlowNets-based language models operate at the token level and remain confined to tree-structured spaces, limiting their potential. In this work, we propose Flow of SpanS (FOSS), a principled GFlowNets framework for span generation. FoSS constructs a dynamic span vocabulary by segmenting the retrieved text flexibly, ensuring a DAG-structured state space, which allows GFlowNets to explore diverse compositional paths and improve generalization. With specialized reward models, FoSS generates diverse, high-quality text. Empirically, FoSS improves MAUVE scores by up to 12.5% over Transformer on text generation and achieves 3.5% gains on knowledge-intensive tasks, consistently outperforming state-of-the-art methods. Scaling experiments further demonstrate FoSS benefits from larger models, more data, and richer retrieval corpora, retaining its advantage over strong baselines.",
    "title_zh": "跨度流：通过GFlowNets将语言模型推广到动态跨度词汇",
    "abstract_zh": "标准的自回归语言模型以固定词汇表逐标记生成文本，将标记采样视为一种动作时，其状态空间呈现树状结构，这限制了模型的灵活性与表达能力。近期研究通过采样检索到的文本片段引入了动态词汇表，但忽略了同一句子可由不同长度的片段构成这一事实，未能显式建模有向无环图（DAG）状的状态空间。这导致组合路径探索受限，并倾向于固定选择某一条路径。生成流网络（GFlowNets）在高效探索和泛化状态空间方面表现出强大能力，尤其适用于具有DAG结构的状态空间。然而，先前基于GFlowNets的语言模型仍局限于标记级操作，状态空间仍被限制在树状结构中，未能充分发挥其潜力。本文提出Flow of SpanS（FOSS），一种用于片段生成的原理性GFlowNets框架。FOSS通过灵活分割检索到的文本，构建动态片段词汇表，确保状态空间具有DAG结构，使GFlowNets能够探索多样化的组合路径，提升泛化能力。结合专门设计的奖励模型，FOSS可生成多样且高质量的文本。实验结果表明，FOSS在文本生成任务上相比Transformer模型，MAUVE得分最高提升12.5%；在知识密集型任务上，性能提升达3.5%，持续优于当前最先进方法。扩展实验进一步证明，FOSS在更大模型、更多数据和更丰富的检索语料下均能获益，始终优于强基线模型。"
  },
  {
    "date": "2026-02-11",
    "title": "PELLI: Framework to effectively integrate LLMs for quality software generation",
    "authors": "Rasmus Krebs, Somnath Mazumdar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10808v1",
    "source": "arXiv",
    "abstract": "Recent studies have revealed that when LLMs are appropriately prompted and configured, they demonstrate mixed results. Such results often meet or exceed the baseline performance. However, these comparisons have two primary issues. First, they mostly considered only reliability as a comparison metric and selected a few LLMs (such as Codex and ChatGPT) for comparision. This paper proposes a comprehensive code quality assessment framework called Programmatic Excellence via LLM Iteration (PELLI). PELLI is an iterative analysis-based process that upholds high-quality code changes. We extended the state-of-the-art by performing a comprehensive evaluation that generates quantitative metrics for analyzing three primary nonfunctional requirements (such as maintainability, performance, and reliability) while selecting five popular LLMs. For PELLI's applicability, we selected three application domains while following Python coding standards. Following this framework, practitioners can ensure harmonious integration between LLMs and human developers, ensuring that their potential is fully realized. PELLI can serve as a practical guide for developers aiming to leverage LLMs while adhering to recognized quality standards. This study's outcomes are crucial for advancing LLM technologies in real-world applications, providing stakeholders with a clear understanding of where these LLMs excel and where they require further refinement. Overall, based on three nonfunctional requirements, we have found that GPT-4T and Gemini performed slightly better. We also found that prompt design can influence the overall code quality. In addition, each application domain demonstrated high and low scores across various metrics, and even within the same metrics across different prompts.",
    "title_zh": "PELLI：用于有效整合大语言模型以生成高质量软件的框架",
    "abstract_zh": "最近的研究表明，当大型语言模型（LLMs）得到恰当的提示和配置时，其表现结果参差不齐。这些结果通常能够达到甚至超过基线性能。然而，此类比较存在两个主要问题：首先，它们大多仅以可靠性作为对比指标，并且只选取了少数几个LLM（如Codex和ChatGPT）进行比较。本文提出了一种名为“基于LLM迭代的程序卓越性”（Programmatic Excellence via LLM Iteration, PELLI）的综合性代码质量评估框架。PELLI是一种基于迭代分析的过程，旨在确保高质量的代码改进。我们通过全面评估，超越了现有技术水平，生成了定量指标，用于分析三个主要非功能性需求（如可维护性、性能和可靠性），同时涵盖了五种流行的LLM。为验证PELLI的适用性，我们选择了三个应用领域，并严格遵循Python编码规范。依据该框架，实践者可以确保LLM与人类开发者之间的和谐集成，从而充分释放其潜力。PELLI可为希望利用LLM技术但又遵守公认质量标准的开发者提供实用指导。本研究的结果对于推动LLM技术在实际应用中的发展至关重要，使利益相关方能够清晰了解这些LLM的优势所在以及需要进一步优化的方面。总体而言，基于三项非功能性需求的评估发现，GPT-4T和Gemini的表现略优。我们还发现，提示设计对整体代码质量具有显著影响。此外，不同应用领域在各项指标上表现出高低不一的成绩，甚至在同一指标下，不同提示也会导致显著差异。"
  },
  {
    "date": "2026-02-11",
    "title": "Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act",
    "authors": "Da-Lun Chen, Prasasthy Balasubramanian, Lauri Lovén, Susanna Pirttikangas, Jaakko Sauvola, Panagiotis Kostakos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10802v1",
    "source": "arXiv",
    "abstract": "Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure regulatory compliance when deploying cognitive systems. These developments highlight the need for institutions to engage stakeholders and tailor GenAI integration to their needs while addressing concerns. This study investigates how GenAI is perceived within the disciplines of Information Technology and Electrical Engineering (ITEE). Using a mixed-method approach, we surveyed 61 staff and 37 students at the Faculty of ITEE, University of Oulu. The results reveal both shared and discipline-specific themes, including strong interest in programming support from GenAI and concerns over response quality, privacy, and academic integrity. Drawing from these insights, the study identifies a set of high-level requirements and proposes a conceptual framework for responsible GenAI integration. Disciplinary-specific requirements reinforce the importance of stakeholder engagement when integrating GenAI into higher education. The high-level requirements and the framework provide practical guidance for universities aiming to harness GenAI while addressing stakeholder concerns and ensuring regulatory compliance.",
    "title_zh": "将生成式人工智能增强的认知系统融入高等教育：从利益相关者认知到考虑欧盟《人工智能法案》的概念框架",
    "abstract_zh": "高等教育机构中的许多教职员工和学生已将生成式人工智能（GenAI）工具应用于工作与学习中。GenAI有望通过实现个性化学习和优化教育服务，提升认知系统的能力。然而，利益相关者对GenAI在高等教育中的应用看法仍存在分歧，这种分歧受到文化、学科及机构背景的影响。此外，欧盟《人工智能法案》要求高校在部署认知系统时确保符合监管要求。这些发展凸显出高校必须积极与利益相关者沟通，并根据自身需求定制GenAI的整合策略，同时回应各类关切。\n\n本研究聚焦于信息与电气工程（ITEE）学科领域，探讨GenAI的感知情况。采用混合研究方法，对奥卢大学ITEE学院的61名教职员工和37名学生进行了调查。研究结果揭示了共性主题与学科特异性主题并存的现象，包括对GenAI在编程支持方面的强烈兴趣，以及对响应质量、隐私保护和学术诚信的担忧。\n\n基于上述发现，本研究提炼出一组高层级需求，并提出一个负责任的GenAI整合概念框架。学科特定的需求进一步强调了在高等教育中引入GenAI时开展利益相关者参与的重要性。该高层级需求与概念框架为高校在利用GenAI的同时应对利益相关者关切、保障合规性提供了切实可行的指导。"
  },
  {
    "date": "2026-02-11",
    "title": "PRISM: Parallel Residual Iterative Sequence Model",
    "authors": "Jie Jiang, Ke Cheng, Xin Xu, Mengyang Pang, Tianhao Lu, Jiaheng Li, Yue Liu, Yuan Wang, Jun Zhang, Huan Yu, Zhouchen Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10796v1",
    "source": "arXiv",
    "abstract": "Generative sequence modeling faces a fundamental tension between the expressivity of Transformers and the efficiency of linear sequence models. Existing efficient architectures are theoretically bounded by shallow, single-step linear updates, while powerful iterative methods like Test-Time Training (TTT) break hardware parallelism due to state-dependent gradients. We propose PRISM (Parallel Residual Iterative Sequence Model) to resolve this tension. PRISM introduces a solver-inspired inductive bias that captures key structural properties of multi-step refinement in a parallelizable form. We employ a Write-Forget Decoupling strategy that isolates non-linearity within the injection operator. To bypass the serial dependency of explicit solvers, PRISM utilizes a two-stage proxy architecture: a short-convolution anchors the initial residual using local history energy, while a learned predictor estimates the refinement updates directly from the input. This design distills structural patterns associated with iterative correction into a parallelizable feedforward operator. Theoretically, we prove that this formulation achieves Rank-$L$ accumulation, structurally expanding the update manifold beyond the single-step Rank-$1$ bottleneck. Empirically, it achieves comparable performance to explicit optimization methods while achieving 174x higher throughput.",
    "title_zh": "PRISM：并行残差迭代序列模型",
    "abstract_zh": "生成式序列建模面临着Transformer表达能力与线性序列模型效率之间的根本性矛盾。现有的高效架构在理论上受限于浅层、单步的线性更新，而强大的迭代方法（如测试时训练，TTT）则因依赖状态的梯度破坏了硬件并行性。为此，我们提出了PRISM（并行残差迭代序列模型），以解决这一矛盾。PRISM引入了一种求解器启发的归纳偏置，将多步精炼的关键结构特性以可并行化的方式进行捕捉。我们采用“写-遗忘解耦”策略，将非线性限制在注入算子内部。为克服显式求解器的串行依赖，PRISM设计了一种两阶段代理架构：短卷积通过局部历史能量锚定初始残差，而一个可学习的预测器则直接从输入估计精炼更新。该设计将迭代修正相关的结构模式提炼为一种可并行化的前馈算子。理论上，我们证明该形式实现了Rank-$L$累积，结构性地扩展了更新流形，突破了单步Rank-$1$的瓶颈。实验上，PRISM在性能上可媲美显式优化方法，同时实现了高达174倍的吞吐量提升。"
  },
  {
    "date": "2026-02-11",
    "title": "GoodVibe: Security-by-Vibe for LLM-Based Code Generation",
    "authors": "Maximilian Thang, Lichao Wu, Sasha Behrouzi, Mohamadreza Rostami, Jona te Lintelo, Stjepan Picek, Ahmad-Reza Sadeghi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10778v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly used for code generation in fast, informal development workflows, often referred to as vibe coding, where speed and convenience are prioritized, and security requirements are rarely made explicit. In this setting, models frequently produce functionally correct but insecure code, creating a growing security risk. Existing approaches to improving code security rely on full-parameter fine-tuning or parameter-efficient adaptations, which are either costly and prone to catastrophic forgetting or operate at coarse granularity with limited interpretability and control. We present GoodVibe, a neuron-level framework for improving the security of code language models by default. GoodVibe is based on the key insight that security-relevant reasoning is localized to a small subset of neurons. We identify these neurons using gradient-based attribution from a supervised security task and perform neuron-selective fine-tuning that updates only this security-critical subspace. To further reduce training cost, we introduce activation-driven neuron clustering, enabling structured updates with minimal overhead. We evaluate GoodVibe on six LLMs across security-critical programming languages, including C++, Java, Swift, and Go. GoodVibe substantially improves the security of generated code while preserving general model utility, achieving up to a 2.5x improvement over base models, matching or exceeding full fine-tuning with over 4,700x fewer trainable parameters, and reducing training computation by more than 3.6x compared to the parameter-efficient baseline (LoRA). Our results demonstrate that neuron-level optimization offers an effective and scalable approach to securing code generation without sacrificing efficiency or generality.",
    "title_zh": "GoodVibe：基于“氛围”的安全机制用于基于大语言模型的代码生成",
    "abstract_zh": "大型语言模型（LLMs）在快速、非正式的开发流程中被越来越多地用于代码生成，这类开发方式常被称为“ vibe 编码”——以速度和便捷性为优先，安全要求往往未被明确提出。在这种场景下，模型经常生成功能正确但存在安全隐患的代码，从而带来日益增长的安全风险。现有提升代码安全性的方法主要依赖于全参数微调或参数高效适配技术，但前者成本高昂且易导致灾难性遗忘，后者则通常在粗粒度层面操作，缺乏可解释性和可控性。\n\n我们提出了 GoodVibe，一种基于神经元层级的框架，旨在默认提升代码语言模型的安全性。GoodVibe 的核心洞察是：与安全相关的推理仅集中在一小部分神经元中。我们通过监督式安全任务的梯度归因方法识别出这些关键神经元，并对这些安全敏感的子空间进行选择性微调，仅更新特定神经元。为进一步降低训练成本，我们引入了基于激活的神经元聚类机制，实现结构化更新，同时保持极低的额外开销。\n\n我们在六种大型语言模型上对 GoodVibe 进行了评估，涵盖 C++、Java、Swift 和 Go 等安全关键型编程语言。实验结果表明，GoodVibe 显著提升了生成代码的安全性，同时保持了模型的通用能力：相比基础模型，安全性能最高提升达 2.5 倍；在性能上达到甚至超过全参数微调的效果，但所需的可训练参数少于其 4,700 倍；与参数高效基线方法 LoRA 相比，训练计算量减少超过 3.6 倍。\n\n我们的研究结果表明，神经元层级的优化为代码生成的安全保障提供了一种高效且可扩展的解决方案，在不牺牲效率或通用性的前提下，有效应对安全挑战。"
  },
  {
    "date": "2026-02-11",
    "title": "AI-rithmetic",
    "authors": "Alex Bie, Travis Dick, Alex Kulesza, Prabhakar Raghavan, Vinod Raman, Sergei Vassilvitskii",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10416v1",
    "source": "arXiv",
    "abstract": "Modern AI systems have been successfully deployed to win medals at international math competitions, assist with research workflows, and prove novel technical lemmas. However, despite their progress at advanced levels of mathematics, they remain stubbornly bad at basic arithmetic, consistently failing on the simple task of adding two numbers. We present a systematic investigation of this phenomenon. We demonstrate empirically that all frontier models suffer significantly degraded accuracy for integer addition as the number of digits increases. Furthermore, we show that most errors made by these models are highly interpretable and can be attributed to either operand misalignment or a failure to correctly carry; these two error classes explain 87.9%, 62.9%, and 92.4% of Claude Opus 4.1, GPT-5, and Gemini 2.5 Pro errors, respectively. Finally, we show that misalignment errors are frequently related to tokenization, and that carrying errors appear largely as independent random failures.",
    "title_zh": "AI算术",
    "abstract_zh": "现代人工智能系统已成功应用于国际数学竞赛并赢得奖牌，协助科研工作流程，甚至证明新的技术引理。然而，尽管在高等数学领域取得了显著进展，它们在基础算术方面却依然表现糟糕，常常在简单的加法运算——如两个数字相加——上出错。本文对这一现象进行了系统性研究。我们通过实证发现，所有前沿模型在整数加法任务中的准确率随着数字位数的增加而显著下降。此外，我们发现这些模型所犯的大多数错误具有高度可解释性，主要归因于操作数对齐错误或未能正确进位；这两类错误分别解释了Claude Opus 4.1、GPT-5和Gemini 2.5 Pro模型错误的87.9%、62.9%和92.4%。最后，我们发现对齐错误通常与分词（tokenization）机制密切相关，而进位错误则大多表现为独立的随机性失败。"
  },
  {
    "date": "2026-02-11",
    "title": "A Weakest Precondition Calculus for Programs and Linear Temporal Specifications",
    "authors": "Gidon Ernst",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10746v1",
    "source": "arXiv",
    "abstract": "Auto-active program verification rests on the ability to effectively the translation from annotated programs into verification conditions that are then discharged by automated theorem provers in the background. Characteristic such tools, e.g., Why3, Dafny, and Viper, is that this process does not involve user interaction, expecting all guiding hints like invariants to be given upfront. For sequential correctness, this paradigm is well established, thanks to approaches like weakest precondition generation and symbolic execution. However, to capture temporal properties, the specification language of choice for a broader system perspective, additional concerns and challenges are introduced into the translation and proof. Approaches based on symbolic model-checking can verify such properties on system models, e.g., using automata constructions. However, ascribing temporal properties to structured and data-intensive programs is more difficult. Several program calculi have been proposed in the literature, each of which on their own falls short in some regard of supporting an auto-active workflow. However, all essential ideas, while perhaps some are not widely acknowledged, are in fact found in the literature. In this paper, we demonstrate how to assemble these ideas into a weakest-precondition calculus for linear temporal properties and demonstrate it with examples.",
    "title_zh": "程序与线性时序规范的最弱前置条件演算",
    "abstract_zh": "自动主动程序验证依赖于将带注释的程序有效转换为验证条件的能力，这些条件随后由后台的自动化定理证明器进行消解。诸如Why3、Dafny和Viper等典型工具的共同特点是该过程无需用户交互，要求所有指导性信息（如不变式）在前期就已给出。对于顺序正确性而言，这一范式已经非常成熟，这得益于最弱前置条件生成和符号执行等方法。然而，为了捕捉时序性质——即从更广泛系统视角出发所选择的规范语言——在转换和证明过程中引入了额外的考虑与挑战。基于符号模型检测的方法可以在系统模型上验证此类性质，例如通过构造自动机来实现。然而，将时序性质赋予结构化且数据密集型的程序则更为困难。文献中已提出多种程序演算，但每种都各自在支持自动主动工作流方面存在不足。尽管如此，所有关键思想实际上早已存在于已有文献中，只是某些思想可能未被广泛认可。本文展示了如何将这些思想整合成一个用于线性时序性质的最弱前置条件演算，并通过具体示例加以演示。"
  },
  {
    "date": "2026-02-11",
    "title": "When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning",
    "authors": "Leheng Sheng, Yongtao Zhang, Wenchang Ma, Yaorui Shi, Ting Huang, Xiang Wang, An Zhang, Ke Shen, Tat-Seng Chua",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10560v1",
    "source": "arXiv",
    "abstract": "While reasoning over long context is crucial for various real-world applications, it remains challenging for large language models (LLMs) as they suffer from performance degradation as the context length grows. Recent work MemAgent has tried to tackle this by processing context chunk-by-chunk in an RNN-like loop and updating a textual memory for final answering. However, this naive recurrent memory update faces two crucial drawbacks: (i) memory can quickly explode because it can update indiscriminately, even on evidence-free chunks; and (ii) the loop lacks an exit mechanism, leading to unnecessary computation after even sufficient evidence is collected. To address these issues, we propose GRU-Mem, which incorporates two text-controlled gates for more stable and efficient long-context reasoning. Specifically, in GRU-Mem, the memory only updates when the update gate is open and the recurrent loop will exit immediately once the exit gate is open. To endow the model with such capabilities, we introduce two reward signals $r^{\\text{update}}$ and $r^{\\text{exit}}$ within end-to-end RL, rewarding the correct updating and exiting behaviors respectively. Experiments on various long-context reasoning tasks demonstrate the effectiveness and efficiency of GRU-Mem, which generally outperforms the vanilla MemAgent with up to 400\\% times inference speed acceleration.",
    "title_zh": "何时记忆，何时停止：用于长上下文推理的门控循环记忆",
    "abstract_zh": "尽管在长上下文推理方面具有重要意义，但大型语言模型（LLMs）在处理长文本时仍面临挑战，因为其性能会随着上下文长度的增加而下降。近期的工作 MemAgent 尝试通过类似循环神经网络（RNN）的循环方式，逐块处理上下文，并更新一个文本记忆以用于最终回答。然而，这种简单的循环记忆更新机制存在两个关键缺陷：（i）记忆可能迅速膨胀，因为即使在缺乏证据的文本块上也会无差别地更新；（ii）循环缺乏退出机制，导致即使已收集到足够证据，仍会进行不必要的计算。为解决这些问题，我们提出 GRU-Mem，引入两个受文本控制的门控机制，以实现更稳定、高效的长上下文推理。具体而言，在 GRU-Mem 中，只有当更新门开启时，记忆才会更新；而一旦退出门开启，循环将立即终止。为赋予模型上述能力，我们在端到端强化学习中引入两个奖励信号 $r^{\\text{update}}$ 和 $r^{\\text{exit}}$，分别奖励正确的更新与退出行为。在多种长上下文推理任务上的实验表明，GRU-Mem 具有显著的有效性和效率优势，其推理速度相比原始的 MemAgent 最高可提升 400%。"
  },
  {
    "date": "2026-02-11",
    "title": "FeatureBench: Benchmarking Agentic Coding for Complex Feature Development",
    "authors": "Qixing Zhou, Jiacheng Zhang, Haiyang Wang, Rui Hao, Jiahe Wang, Minghao Han, Yuxue Yang, Shuzhe Wu, Feiyang Pan, Lue Fan, Dandan Tu, Zhaoxiang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10975v1",
    "source": "arXiv",
    "abstract": "Agents powered by large language models (LLMs) are increasingly adopted in the software industry, contributing code as collaborators or even autonomous developers. As their presence grows, it becomes important to assess the current boundaries of their coding abilities. Existing agentic coding benchmarks, however, cover a limited task scope, e.g., bug fixing within a single pull request (PR), and often rely on non-executable evaluations or lack an automated approach for continually updating the evaluation coverage. To address such issues, we propose FeatureBench, a benchmark designed to evaluate agentic coding performance in end-to-end, feature-oriented software development. FeatureBench incorporates an execution-based evaluation protocol and a scalable test-driven method that automatically derives tasks from code repositories with minimal human effort. By tracing from unit tests along a dependency graph, our approach can identify feature-level coding tasks spanning multiple commits and PRs scattered across the development timeline, while ensuring the proper functioning of other features after the separation. Using this framework, we curated 200 challenging evaluation tasks and 3825 executable environments from 24 open-source repositories in the first version of our benchmark. Empirical evaluation reveals that the state-of-the-art agentic model, such as Claude 4.5 Opus, which achieves a 74.4% resolved rate on SWE-bench, succeeds on only 11.0% of tasks, opening new opportunities for advancing agentic coding. Moreover, benefiting from our automated task collection toolkit, FeatureBench can be easily scaled and updated over time to mitigate data leakage. The inherent verifiability of constructed environments also makes our method potentially valuable for agent training.",
    "title_zh": "FeatureBench：面向复杂功能开发的智能体编程基准测试",
    "abstract_zh": "由大型语言模型（LLM）驱动的智能体（Agents）在软件行业中日益普及，作为代码合作者甚至自主开发者参与开发。随着其应用范围的扩大，评估其当前编码能力边界变得愈发重要。然而，现有的智能体编程基准测试覆盖的任务范围有限，例如仅限于单个拉取请求（PR）内的缺陷修复，并且常常依赖不可执行的评估方式，或缺乏自动更新评估覆盖范围的机制。为解决这些问题，我们提出了FeatureBench——一个旨在评估智能体在端到端、以功能为导向的软件开发中表现的基准测试框架。\n\nFeatureBench采用基于执行的评估协议，并结合可扩展的测试驱动方法，能够以极小的人工投入从代码仓库中自动提取任务。通过沿着依赖图追溯单元测试，我们的方法可以识别跨越多个提交和拉取请求、分散在整个开发时间线上的功能级编码任务，同时确保在任务分离后其他功能仍能正常运行。基于这一框架，我们在首个版本中从24个开源仓库中构建了200个具有挑战性的评估任务以及3825个可执行环境。\n\n实证评估显示，当前最先进的智能体模型（如Claude 4.5 Opus）在SWE-bench上达到74.4%的解决率，但在FeatureBench上仅能完成11.0%的任务，这揭示了智能体编程能力的巨大提升空间，也为进一步推动智能体编程发展提供了新的机遇。此外，得益于我们自动化任务收集工具包，FeatureBench可轻松扩展和持续更新，有效缓解数据泄露问题。所构建环境的固有可验证性也使其在智能体训练方面具备潜在价值。"
  },
  {
    "date": "2026-02-11",
    "title": "C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution",
    "authors": "Binwei Yan, Yifei Fu, Mingjian Zhu, Hanting Chen, Mingxuan Yuan, Yunhe Wang, Hailin Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10874v1",
    "source": "arXiv",
    "abstract": "Automatic prompt optimization is a promising direction to boost the performance of Large Language Models (LLMs). However, existing methods often suffer from noisy and conflicting update signals. In this research, we propose C-MOP (Cluster-based Momentum Optimized Prompting), a framework that stabilizes optimization via Boundary-Aware Contrastive Sampling (BACS) and Momentum-Guided Semantic Clustering (MGSC). Specifically, BACS utilizes batch-level information to mine tripartite features--Hard Negatives, Anchors, and Boundary Pairs--to precisely characterize the typical representation and decision boundaries of positive and negative prompt samples. To resolve semantic conflicts, MGSC introduces a textual momentum mechanism with temporal decay that distills persistent consensus from fluctuating gradients across iterations. Extensive experiments demonstrate that C-MOP consistently outperforms SOTA baselines like PromptWizard and ProTeGi, yielding average gains of 1.58% and 3.35%. Notably, C-MOP enables a general LLM with 3B activated parameters to surpass a 70B domain-specific dense LLM, highlighting its effectiveness in driving precise prompt evolution. The code is available at https://github.com/huawei-noah/noah-research/tree/master/C-MOP.",
    "title_zh": "C-MOP：融合动量与边界感知聚类的增强型提示进化方法",
    "abstract_zh": "自动提示优化是提升大语言模型（LLM）性能的一个有前景方向。然而，现有方法通常面临更新信号噪声大、冲突多的问题。在本研究中，我们提出了C-MOP（基于聚类的动量优化提示框架），通过边界感知对比采样（BACS）和动量引导语义聚类（MGSC）来稳定优化过程。具体而言，BACS利用批次级信息挖掘三元组特征——难负样本、锚点样本和边界样本，以精确刻画正负提示样本的典型表征及决策边界。为解决语义冲突问题，MGSC引入了一种具有时间衰减特性的文本动量机制，从迭代过程中波动的梯度中提炼出持续一致的共识。大量实验表明，C-MOP在性能上持续优于当前最优基线方法（如PromptWizard和ProTeGi），平均提升分别达到1.58%和3.35%。值得注意的是，C-MOP使一个仅激活30亿参数的通用大模型超越了700亿参数的领域专用密集模型，充分展现了其在推动精准提示演进方面的有效性。代码已开源，地址为：https://github.com/huawei-noah/noah-research/tree/master/C-MOP。"
  },
  {
    "date": "2026-02-11",
    "title": "Agentic Knowledge Distillation: Autonomous Training of Small Language Models for SMS Threat Detection",
    "authors": "Adel ElZemity, Joshua Sylvester, Budi Arief, Rogério De Lemos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10869v1",
    "source": "arXiv",
    "abstract": "SMS-based phishing (smishing) attacks have surged, yet training effective on-device detectors requires labelled threat data that quickly becomes outdated. To deal with this issue, we present Agentic Knowledge Distillation, which consists of a powerful LLM acts as an autonomous teacher that fine-tunes a smaller student SLM, deployable for security tasks without human intervention. The teacher LLM autonomously generates synthetic data and iteratively refines a smaller on-device student model until performance plateaus. We compare four LLMs in this teacher role (Claude Opus 4.5, GPT 5.2 Codex, Gemini 3 Pro, and DeepSeek V3.2) on SMS spam/smishing detection with two student SLMs (Qwen2.5-0.5B and SmolLM2-135M). Our results show that performance varies substantially depending on the teacher LLM, with the best configuration achieving 94.31% accuracy and 96.25% recall. We also compare against a Direct Preference Optimisation (DPO) baseline that uses the same synthetic knowledge and LoRA setup but without iterative feedback or targeted refinement; agentic knowledge distillation substantially outperforms it (e.g. 86-94% vs 50-80% accuracy), showing that closed-loop feedback and targeted refinement are critical. These findings demonstrate that agentic knowledge distillation can rapidly yield effective security classifiers for edge deployment, but outcomes depend strongly on which teacher LLM is used.",
    "title_zh": "智能体知识蒸馏：小型语言模型在短信威胁检测中的自主训练",
    "abstract_zh": "基于短信的网络钓鱼攻击（短信钓鱼，smishing）数量急剧上升，然而训练有效的设备端检测器需要标注的威胁数据，而这类数据极易过时。为应对这一挑战，我们提出了一种**代理式知识蒸馏**（Agentic Knowledge Distillation）方法：由一个强大的大语言模型（LLM）作为自主教师，持续微调一个更小的可部署学生模型（SLM），用于安全任务，整个过程无需人工干预。该教师LLM能够自主生成合成数据，并迭代优化小型设备端学生模型，直至性能达到稳定。我们评估了四种LLM作为教师模型的表现（Claude Opus 4.5、GPT 5.2 Codex、Gemini 3 Pro 和 DeepSeek V3.2），在两种学生模型（Qwen2.5-0.5B 和 SmolLM2-135M）上进行短信垃圾信息/短信钓鱼检测任务。实验结果表明，不同教师LLM带来的性能差异显著，最佳配置下达到94.31%的准确率和96.25%的召回率。我们还将该方法与一个直接偏好优化（DPO）基线进行对比，该基线使用相同的合成知识和LoRA设置，但缺乏闭环反馈与针对性优化。结果表明，代理式知识蒸馏显著优于DPO基线（准确率从86–94% vs 50–80%），证明闭环反馈与针对性优化至关重要。这些发现表明，代理式知识蒸馏能够快速生成适用于边缘部署的有效安全分类器，但最终效果高度依赖于所选用的教师LLM。"
  },
  {
    "date": "2026-02-11",
    "title": "Diffusion-Pretrained Dense and Contextual Embeddings",
    "authors": "Sedigheh Eslami, Maksim Gaiduk, Markus Krimmel, Louis Milliken, Bo Wang, Denis Bykov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11151v1",
    "source": "arXiv",
    "abstract": "In this report, we introduce pplx-embed, a family of multilingual embedding models that employ multi-stage contrastive learning on a diffusion-pretrained language model backbone for web-scale retrieval. By leveraging bidirectional attention through diffusion-based pretraining, our models capture comprehensive bidirectional context within passages, enabling the use of mean pooling and a late chunking strategy to better preserve global context across long documents. We release two model types: pplx-embed-v1 for standard retrieval, and pplx-embed-context-v1 for contextualized embeddings that incorporate global document context into passage representations. pplx-embed-v1 achieves competitive performance on the MTEB(Multilingual, v2), MTEB(Code), MIRACL, BERGEN, and ToolRet retrieval benchmarks, while pplx-embed-context-v1 sets new records on the ConTEB benchmark. Beyond public benchmarks, pplx-embed-v1 demonstrates strong performance on our internal evaluation suite, which focuses on real-world, large-scale search scenarios over tens of millions of documents. These results validate the models' effectiveness in production environments where retrieval quality and efficiency are critical at scale.",
    "title_zh": "扩散预训练的密集上下文嵌入",
    "abstract_zh": "在本报告中，我们介绍了 pplx-embed，这是一系列多语言嵌入模型，其基于扩散预训练语言模型主干，采用多阶段对比学习方法，适用于网络规模的检索任务。通过利用基于扩散的预训练实现双向注意力机制，我们的模型能够捕捉段落内部的全面双向上下文信息，从而支持使用均值池化和后期分块策略，更好地保留长文档中的全局上下文。我们发布了两种模型类型：pplx-embed-v1 用于标准检索任务，pplx-embed-context-v1 用于生成融合全局文档上下文信息的上下文化嵌入表示。pplx-embed-v1 在 MTEB（多语言，v2）、MTEB（代码）、MIRACL、BERGEN 和 ToolRet 等检索基准测试中表现出具有竞争力的性能；而 pplx-embed-context-v1 在 ConTEB 基准测试中创造了新的记录。除了公开基准测试外，pplx-embed-v1 在我们内部的评估套件中也展现出优异的表现，该套件专注于数十亿文档规模下的真实世界大规模搜索场景。这些结果验证了这些模型在生产环境中应用的有效性，尤其是在检索质量与效率对大规模系统至关重要的场景下。"
  },
  {
    "date": "2026-02-11",
    "title": "FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight",
    "authors": "Jiayi Zhou, Yang Sheng, Hantao Lou, Yaodong Yang, Jie Fu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11136v1",
    "source": "arXiv",
    "abstract": "As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing , a neuro-symbolic framework that employs a bidirectional Formal-of-Thought architecture: LLMs serve as specification compilers that top-down decompose high-level human intent into atomic, verifiable constraints, then bottom-up prove compliance using Dafny specifications and Z3 Satisfiability modulo theories solving, which produces mathematical guarantees rather than probabilistic scores. We validate across three benchmarks spanning behavioral safety, multi-domain constraint adherence, and agentic upward deception detection. Experiments on 7 agent models demonstrate that achieves an average improvement of 16.6% over LLM-as-a-Judge baselines, enables weak-to-strong generalization where a 7B judge achieves over 90% accuracy detecting deception from 72B agents, and provides near-linear safety improvement through iterative refinement.",
    "title_zh": "FormalJudge：一种用于代理监督的神经符号范式",
    "abstract_zh": "随着基于大语言模型（LLM）的智能体在高风险领域中日益广泛应用并产生真实世界的影响，确保其行为安全变得至关重要。当前主流的监督范式——“LLM作为裁判”（LLM-as-a-Judge）面临一个根本性困境：如何让具有概率性质的系统可靠地监督另一套概率系统，同时避免继承其固有的失效模式？我们主张，形式化验证提供了一种原则性的解决方案，然而其实际应用一直受到一个关键瓶颈的制约——即从自然语言需求到形式化规范的转换难题。本文通过提出一种神经符号框架，成功弥合了这一鸿沟。该框架采用双向“形式化思维”（Formal-of-Thought）架构：大语言模型作为规范编译器，自顶向下将高层次的人类意图分解为原子化、可验证的约束条件；随后，系统自底向上利用Dafny形式规范与Z3基于理论的可满足性求解（SMT solving）技术，证明系统对规范的合规性，从而提供数学意义上的保证，而非概率性评分。我们在三个基准测试中进行了验证，涵盖行为安全、多领域约束遵守以及智能体向上欺骗行为的检测。在7个智能体模型上的实验表明，该方法相比传统的LLM-as-a-Judge基线平均提升16.6%；实现了从弱判别器到强判别器的泛化能力——一个70亿参数的判别器能够以超过90%的准确率检测出720亿参数智能体的欺骗行为；同时，通过迭代优化，系统展现出近乎线性的安全性能提升。"
  },
  {
    "date": "2026-02-11",
    "title": "GraphSeek: Next-Generation Graph Analytics with LLMs",
    "authors": "Maciej Besta, Łukasz Jarmocik, Orest Hrycyna, Shachar Klaiman, Konrad Mączka, Robert Gerstenberger, Jürgen Müller, Piotr Nyczyk, Hubert Niewiadomski, Torsten Hoefler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11052v1",
    "source": "arXiv",
    "abstract": "Graphs are foundational across domains but remain hard to use without deep expertise. LLMs promise accessible natural language (NL) graph analytics, yet they fail to process industry-scale property graphs effectively and efficiently: such datasets are large, highly heterogeneous, structurally complex, and evolve dynamically. To address this, we devise a novel abstraction for complex multi-query analytics over such graphs. Its key idea is to replace brittle generation of graph queries directly from NL with planning over a Semantic Catalog that describes both the graph schema and the graph operations. Concretely, this induces a clean separation between a Semantic Plane for LLM planning and broader reasoning, and an Execution Plane for deterministic, database-grade query execution over the full dataset and tool implementations. This design yields substantial gains in both token efficiency and task effectiveness even with small-context LLMs. We use this abstraction as the basis of the first LLM-enhanced graph analytics framework called GraphSeek. GraphSeek achieves substantially higher success rates (e.g., 86% over enhanced LangChain) and points toward the next generation of affordable and accessible graph analytics that unify LLM reasoning with database-grade execution over large and complex property graphs.",
    "title_zh": "GraphSeek：下一代基于大语言模型的图分析",
    "abstract_zh": "图在各个领域中都具有基础性作用，但若缺乏深厚的专业知识，使用起来仍然十分困难。大型语言模型（LLMs）承诺通过自然语言（NL）实现更易访问的图数据分析，然而它们在处理工业级属性图时仍存在效率和效果上的不足：这类数据集规模庞大、高度异构、结构复杂，并且动态演化。为解决这一问题，我们提出了一种针对复杂多查询分析的新颖抽象方法。其核心思想是：不再直接从自然语言生成脆弱的图查询，而是基于一个语义目录进行规划，该目录同时描述了图的模式（schema）和图操作。具体而言，这种方法在语义平面（Semantic Plane）与执行平面（Execution Plane）之间建立了清晰的分离——前者用于LLM的规划与广泛推理，后者则负责对全量数据集及工具实现进行确定性的、数据库级别的查询执行。这种设计即使在小上下文LLM的情况下，也能显著提升令牌（token）使用效率和任务完成效果。我们以此抽象为基础，构建了首个增强型LLM的图分析框架——GraphSeek。GraphSeek在成功率上表现卓越（例如，相比增强版LangChain达到86%），并指向下一代经济高效、易于使用的图分析技术的发展方向：即融合LLM推理能力与数据库级别执行性能，实现对大规模、复杂属性图的有效分析。"
  },
  {
    "date": "2026-02-11",
    "title": "Blind Gods and Broken Screens: Architecting a Secure, Intent-Centric Mobile Agent Operating System",
    "authors": "Zhenhua Zou, Sheng Guo, Qiuyang Zhan, Lepeng Zhao, Shuo Li, Qi Li, Ke Xu, Mingwei Xu, Zhuotao Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10915v1",
    "source": "arXiv",
    "abstract": "The evolution of Large Language Models (LLMs) has shifted mobile computing from App-centric interactions to system-level autonomous agents. Current implementations predominantly rely on a \"Screen-as-Interface\" paradigm, which inherits structural vulnerabilities and conflicts with the mobile ecosystem's economic foundations. In this paper, we conduct a systematic security analysis of state-of-the-art mobile agents using Doubao Mobile Assistant as a representative case. We decompose the threat landscape into four dimensions - Agent Identity, External Interface, Internal Reasoning, and Action Execution - revealing critical flaws such as fake App identity, visual spoofing, indirect prompt injection, and unauthorized privilege escalation stemming from a reliance on unstructured visual data. To address these challenges, we propose Aura, an Agent Universal Runtime Architecture for a clean-slate secure agent OS. Aura replaces brittle GUI scraping with a structured, agent-native interaction model. It adopts a Hub-and-Spoke topology where a privileged System Agent orchestrates intent, sandboxed App Agents execute domain-specific tasks, and the Agent Kernel mediates all communication. The Agent Kernel enforces four defense pillars: (i) cryptographic identity binding via a Global Agent Registry; (ii) semantic input sanitization through a multilayer Semantic Firewall; (iii) cognitive integrity via taint-aware memory and plan-trajectory alignment; and (iv) granular access control with non-deniable auditing. Evaluation on MobileSafetyBench shows that, compared to Doubao, Aura improves low-risk Task Success Rate from roughly 75% to 94.3%, reduces high-risk Attack Success Rate from roughly 40% to 4.4%, and achieves near-order-of-magnitude latency gains. These results demonstrate Aura as a viable, secure alternative to the \"Screen-as-Interface\" paradigm.",
    "title_zh": "盲目的神明与破碎的屏幕：构建一个以意图为中心的安全移动代理操作系统",
    "abstract_zh": "大型语言模型（LLM）的发展推动移动计算从以应用为中心的交互模式，转向系统级的自主智能体。当前的实现大多依赖于“屏幕即接口”（Screen-as-Interface）范式，这一模式继承了结构性漏洞，并与移动生态系统的经济基础存在根本冲突。本文以通义灵码移动助手（Doubao Mobile Assistant）为典型代表，对前沿移动智能体进行了系统的安全分析。我们从四个维度剖析威胁图景：智能体身份、外部接口、内部推理与动作执行，揭示出一系列关键缺陷，包括虚假应用身份、视觉欺骗、间接提示注入以及因依赖非结构化视觉数据而导致的未授权权限提升。\n\n为应对上述挑战，我们提出 Aura——一种面向安全智能体操作系统的通用运行时架构（Agent Universal Runtime Architecture），旨在从零开始构建一个安全可信的智能体操作系统。Aura 以结构化、原生智能体交互模型取代脆弱的 GUI 抓取机制。其采用“中心-辐条”（Hub-and-Spoke）拓扑结构：由一个特权系统智能体（System Agent）负责意图协调，多个沙箱化的应用智能体（App Agents）执行特定领域任务，而智能体内核（Agent Kernel）则统一管理所有通信。智能体内核通过四大防御支柱实现安全防护：（i）通过全球智能体注册表（Global Agent Registry）实现基于密码学的身份绑定；（ii）通过多层语义防火墙（Multilayer Semantic Firewall）实现语义级输入净化；（iii）通过污染感知内存与计划轨迹对齐机制保障认知完整性；（iv）通过细粒度访问控制与不可否认的审计机制实现安全管控。\n\n在 MobileSafetyBench 上的评估表明，相较于 Doubao，Aura 将低风险任务成功率从约 75% 提升至 94.3%，高风险攻击成功率从约 40% 降低至 4.4%，并实现了近一个数量级的延迟优化。这些结果证明，Aura 是“屏幕即接口”范式的一种可行且安全的替代方案。"
  },
  {
    "date": "2026-02-11",
    "title": "Chart Specification: Structural Representations for Incentivizing VLM Reasoning in Chart-to-Code Generation",
    "authors": "Minggui He, Mingchen Dai, Jian Zhang, Yilun Liu, Shimin Tao, Pufan Zeng, Osamu Yoshie, Yuya Ieiri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10880v1",
    "source": "arXiv",
    "abstract": "Vision-Language Models (VLMs) have shown promise in generating plotting code from chart images, yet achieving structural fidelity remains challenging. Existing approaches largely rely on supervised fine-tuning, encouraging surface-level token imitation rather than faithful modeling of underlying chart structure, which often leads to hallucinated or semantically inconsistent outputs. We propose Chart Specification, a structured intermediate representation that shifts training from text imitation to semantically grounded supervision. Chart Specification filters syntactic noise to construct a structurally balanced training set and supports a Spec-Align Reward that provides fine-grained, verifiable feedback on structural correctness, enabling reinforcement learning to enforce consistent plotting logic. Experiments on three public benchmarks show that our method consistently outperforms prior approaches. With only 3K training samples, we achieve strong data efficiency, surpassing leading baselines by up to 61.7% on complex benchmarks, and scaling to 4K samples establishes new state-of-the-art results across all evaluated metrics. Overall, our results demonstrate that precise structural supervision offers an efficient pathway to high-fidelity chart-to-code generation. Code and dataset are available at: https://github.com/Mighten/chart-specification-paper",
    "title_zh": "图表规范：用于激励视觉语言模型在图表到代码生成中进行推理的结构化表示",
    "abstract_zh": "视觉-语言模型（VLMs）在从图表图像生成绘图代码方面展现出巨大潜力，但实现结构上的精确性仍面临挑战。现有方法主要依赖监督微调，倾向于表面层次的标记模仿，而非对底层图表结构进行忠实建模，这常常导致生成结果出现幻觉或语义不一致的问题。为此，我们提出了一种名为“图表规范”（Chart Specification）的结构化中间表示，将训练目标从文本模仿转向语义基础的监督。该方法通过过滤语法噪声，构建出结构均衡的训练数据集，并支持一种“规范对齐奖励”（Spec-Align Reward），提供细粒度且可验证的结构正确性反馈，从而使得强化学习能够有效约束绘图逻辑的一致性。在三个公开基准上的实验表明，我们的方法始终优于先前的方法。仅使用3K训练样本，即展现出强大的数据效率，在复杂基准上性能超越领先基线高达61.7%；当扩展至4K样本时，更在所有评估指标上建立了新的最先进水平。总体而言，我们的结果表明，精确的结构化监督为实现高保真度的图表到代码生成提供了一条高效路径。代码与数据集已公开：https://github.com/Mighten/chart-specification-paper"
  },
  {
    "date": "2026-02-11",
    "title": "Beyond Permissions: An Empirical Static Analysis of Privacy and Security Risks in Children-Oriented and General-Audience Mobile Apps for Gaming",
    "authors": "Bakheet Aljedaani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10877v1",
    "source": "arXiv",
    "abstract": "Mobile gaming applications (apps) have become increasingly pervasive, including a growing number of games designed for children. Despite their popularity, these apps often integrate complex analytics, advertising, and attribution infrastructures that may introduce privacy and security risks. Existing research has primarily focused on tracking behaviors or monetization models, leaving configuration-level privacy exposure and children-oriented apps underexplored. In this study, we conducted a comparative static analysis of Android mobile games to investigate privacy and security risks beyond permission usage. The analysis follows a three-phase methodology comprising (i) designing study protocol, (ii) Android Package Kit (APK) collection and static inspection, and (iii) data analysis. We examined permissions, manifest-level configuration properties (e.g., backup settings, cleartext network traffic, and exported components), and embedded third-party Software Development Kit (SDK) ecosystems across children-oriented and general-audience mobile games. The extracted indicators are synthesized into qualitative privacy-risk categories to support comparative reporting. The results showed that while children-oriented games often request fewer permissions, they frequently exhibit configuration-level risks and embed third-party tracking SDKs similar to general-audience games. Architectural and configuration decisions play a critical role in shaping privacy risks, particularly for apps targeting children. This study contributes a holistic static assessment of privacy exposure in mobile games and provides actionable insights for developers, platform providers, and researchers seeking to improve privacy-by-design practices in mobile applications.",
    "title_zh": "超越权限：面向儿童与大众受众的移动游戏应用中隐私与安全风险的实证静态分析",
    "abstract_zh": "移动游戏应用（App）日益普及，其中专为儿童设计的游戏数量也在不断增长。尽管这些应用广受欢迎，但它们通常集成了复杂的分析、广告和归因基础设施，可能带来隐私和安全风险。现有研究主要关注用户行为追踪或盈利模式，而对配置层面的隐私暴露以及面向儿童的应用则研究不足。在本研究中，我们采用对比静态分析方法，对Android平台上的移动游戏进行了深入分析，以探究超出权限使用范围的隐私与安全风险。分析过程遵循三阶段方法论，包括：（i）设计研究方案，（ii）Android程序包（APK）的收集与静态检查，以及（iii）数据分析。我们考察了权限使用情况、清单文件级别的配置属性（如备份设置、明文网络通信、可导出组件等），以及嵌入的第三方软件开发工具包（SDK）生态系统，比较了面向儿童的游戏与面向大众的游戏之间的差异。提取出的各项指标被整合为定性隐私风险类别，以支持对比性报告。研究结果表明，尽管面向儿童的游戏通常请求的权限较少，但它们在配置层面存在较高的风险，并且与大众向游戏一样，普遍嵌入第三方追踪SDK。架构设计与配置决策在塑造隐私风险方面起着关键作用，尤其在面向儿童的应用中更为显著。本研究为移动游戏中的隐私暴露提供了全面的静态评估，为开发者、平台提供商及研究人员改善移动应用的“隐私设计”实践提供了切实可行的洞见。"
  },
  {
    "date": "2026-02-11",
    "title": "See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch",
    "authors": "Xingyi Zhang, Yulei Ye, Kaifeng Huang, Wenhao Li, Xiangfeng Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10814v1",
    "source": "arXiv",
    "abstract": "Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debug, Extend, and Compute. To rigorously diagnose the source of agent failures, the benchmark employs two complementary interaction modes: primitive mode requires fine-grained drag-and-drop manipulation to directly assess visuomotor control, while composite mode uses high-level semantic APIs to disentangle program reasoning from GUI execution. To ensure reliable assessment, we propose an execution-based evaluation protocol that validates the functional correctness of the constructed Scratch programs through runtime tests within the browser environment. Extensive experiments across state-of-the-art multimodal language models and GUI agents reveal a substantial reasoning--acting gap, highlighting persistent challenges in fine-grained GUI manipulation despite strong planning capabilities.",
    "title_zh": "看、规划、捕捉：在Scratch中评估多模态GUI智能体",
    "abstract_zh": "基于积木块的编程环境（如Scratch）在低代码教育中扮演着核心角色，然而，评估人工智能代理通过图形用户界面（GUI）构建程序的能力仍处于探索阶段。为此，我们提出了ScratchWorld，这是一个用于评估多模态GUI代理在Scratch中完成程序构建任务的基准测试。ScratchWorld基于“使用-修改-创造”（Use-Modify-Create）的教学框架，包含83个精心设计的任务，涵盖四个不同的问题类别：创建（Create）、调试（Debug）、扩展（Extend）和计算（Compute）。为精确诊断代理失败的原因，该基准测试采用两种互补的交互模式：基础模式要求进行细粒度的拖拽操作，以直接评估代理的视觉-运动控制能力；复合模式则使用高层次的语义API，将程序推理与GUI执行过程分离，从而更清晰地分析智能体的决策能力。为确保评估的可靠性，我们提出了一种基于执行的评估协议，通过在浏览器环境中运行测试来验证所构建的Scratch程序的功能正确性。对前沿多模态语言模型和GUI代理的广泛实验表明，存在显著的“推理—执行”差距，尽管这些代理具备较强的规划能力，但在细粒度GUI操作方面仍面临持续挑战。"
  },
  {
    "date": "2026-02-11",
    "title": "SnapMLA: Efficient Long-Context MLA Decoding via Hardware-Aware FP8 Quantized Pipelining",
    "authors": "Yifan Zhang, Zunhai Su, Shuhao Hu, Rui Yang, Wei Wu, Yulei Qian, Yuchen Xie, Xunliang Cai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10718v1",
    "source": "arXiv",
    "abstract": "While FP8 attention has shown substantial promise in innovations like FlashAttention-3, its integration into the decoding phase of the DeepSeek Multi-head Latent Attention (MLA) architecture presents notable challenges. These challenges include numerical heterogeneity arising from the decoupling of positional embeddings, misalignment of quantization scales in FP8 PV GEMM, and the need for optimized system-level support. In this paper, we introduce SnapMLA, an FP8 MLA decoding framework optimized to improve long-context efficiency through the following hardware-aware algorithm-kernel co-optimization techniques: (i) RoPE-Aware Per-Token KV Quantization, where the RoPE part is maintained in high precision, motivated by our comprehensive analysis of the heterogeneous quantization sensitivity inherent to the MLA KV cache. Furthermore, per-token granularity is employed to align with the autoregressive decoding process and maintain quantization accuracy. (ii) Quantized PV Computation Pipeline Reconstruction, which resolves the misalignment of quantization scale in FP8 PV computation stemming from the shared KV structure of the MLA KV cache. (iii) End-to-End Dataflow Optimization, where we establish an efficient data read-and-write workflow using specialized kernels, ensuring efficient data flow and performance gains. Extensive experiments on state-of-the-art MLA LLMs show that SnapMLA achieves up to a 1.91x improvement in throughput, with negligible risk of performance degradation in challenging long-context tasks, including mathematical reasoning and code generation benchmarks. Code is available at https://github.com/meituan-longcat/SGLang-FluentLLM.",
    "title_zh": "SnapMLA：通过硬件感知的FP8量化流水线实现高效长上下文MLA解码",
    "abstract_zh": "尽管FP8注意力机制在FlashAttention-3等创新技术中展现出巨大潜力，但将其集成到DeepSeek多头潜在注意力（MLA）架构的解码阶段仍面临显著挑战。这些挑战包括：由于位置嵌入解耦导致的数值异质性、FP8 PV GEMM中量化尺度的错位，以及对优化的系统级支持的需求。本文提出SnapMLA，一种面向FP8 MLA解码的优化框架，通过以下硬件感知的算法-内核协同优化技术，显著提升长上下文场景下的效率：(i) RoPE感知的逐token KV量化，其中RoPE部分保持高精度，这一设计基于我们对MLA KV缓存中固有异质量化敏感性的全面分析。同时，采用逐token粒度的量化策略，以匹配自回归解码过程，从而维持量化精度。(ii) 量化PV计算流水线重构，有效解决了因MLA KV缓存共享结构导致的FP8 PV计算中量化尺度错位问题。(iii) 端到端数据流优化，通过专用内核构建高效的读写数据流工作流程，保障数据流动的高效性并带来性能提升。在先进MLA大语言模型上的大量实验表明，SnapMLA在吞吐量上最高可提升1.91倍，且在数学推理和代码生成等复杂长上下文任务中，几乎不带来性能下降风险。代码已开源至：https://github.com/meituan-longcat/SGLang-FluentLLM。"
  },
  {
    "date": "2026-02-11",
    "title": "Evaluating Numerical Accuracy in Mixed-Precision Computing by Dual-Delta Testing",
    "authors": "Peichen Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10605v1",
    "source": "arXiv",
    "abstract": "Mixed-precision computing has become increasingly important in modern high-performance computing and machine learning applications. When implementing custom mixed-precision functions -- such as fused operators, optimized GPU kernels, or quantized inference paths -- it is critical to verify their numerical accuracy. Traditional approaches typically compare the custom implementation against a reference using a single error metric. However, this single-delta approach provides limited insight into whether the observed errors are inherent to the precision level or specific to the implementation. This paper introduces \\textit{Dual-Delta Testing}, a systematic methodology that evaluates two error distributions against a high-precision oracle, enabling rigorous comparison between a custom implementation and a baseline reference. We present the mathematical framework, algorithmic formulation, statistical analysis techniques, and practical examples demonstrating the methodology's effectiveness in evaluating numerical accuracy.",
    "title_zh": "通过双差分测试评估混合精度计算中的数值精度",
    "abstract_zh": "混合精度计算在现代高性能计算和机器学习应用中变得日益重要。在实现自定义的混合精度函数（如融合算子、优化的GPU内核或量化推理路径）时，验证其数值精度至关重要。传统的做法通常仅使用单一误差指标将自定义实现与参考实现进行比较。然而，这种单一误差值的方法难以判断所观察到的误差是精度级别固有的，还是特定于实现方式的。本文提出了**双误差测试**（Dual-Delta Testing）这一系统性方法，通过将两个误差分布与高精度基准进行对比，实现对自定义实现与基准参考之间的严格比较。我们阐述了该方法的数学框架、算法设计、统计分析技术，并通过实际案例展示了其在评估数值精度方面的有效性。"
  },
  {
    "date": "2026-02-11",
    "title": "Predictive-State Communication: Innovation Coding and Reconciliation under Delay",
    "authors": "Ozgur Ercetin, Mohaned Chraiti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10542v1",
    "source": "arXiv",
    "abstract": "Shannon theory models communication as the reliable transfer of symbol sequences, with performance governed by capacity and rate-distortion limits. When both endpoints possess strong predictors -- as in modern large language models and related generative priors -- literal symbol transport is no longer the only operational regime. We propose predictive-state communication (PSC), in which the transmitter and receiver maintain an explicit shared predictive state, and the physical channel is used primarily to convey innovations, i.e., corrective information that reconciles the receiver's provisional trajectory with the transmitter's realized trajectory. This viewpoint replaces entropy-rate accounting by cross-entropy accounting under model mismatch, and it introduces feasibility constraints that depend jointly on capacity, delay, and perceptual continuity requirements; the resulting operating set is typically a bounded perception-capacity band rather than a one-sided threshold. We outline the protocol and architectural implications (state identifiers, anchors, bounded rollback, and patch-based updates) and provide a stylized illustrative example to visualize the induced feasibility region and its dependence on predictive quality.",
    "title_zh": "预测状态通信：延迟下的创新编码与协调",
    "abstract_zh": "香农理论将通信建模为符号序列的可靠传输，其性能由容量和率失真极限所决定。当通信两端都具备强大的预测能力时——如现代大型语言模型及相关生成先验——单纯的符号传输已不再是唯一的有效通信模式。我们提出一种预测状态通信（Predictive-State Communication, PSC）机制：发送端与接收端共同维护一个显式的共享预测状态，物理信道主要用来传输“创新”信息，即用于修正接收端的预测轨迹，使其与发送端的实际轨迹相一致。这一视角在模型不匹配的情况下，以交叉熵核算取代传统的熵率核算，并引入了同时依赖于容量、延迟和感知连续性要求的可行性约束；由此产生的工作区域通常是一个有界感知-容量带，而非单侧阈值。我们概述了该协议及其架构含义（如状态标识符、锚点、有限回滚和基于补丁的更新），并通过一个简化的示例，直观展示所诱导的可行性区域及其对预测质量的依赖关系。"
  },
  {
    "date": "2026-02-11",
    "title": "LUCID: Attention with Preconditioned Representations",
    "authors": "Sai Surya Duvvuri, Nirmal Patel, Nilesh Gupta, Inderjit S. Dhillon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10410v1",
    "source": "arXiv",
    "abstract": "Softmax-based dot-product attention is a cornerstone of Transformer architectures, enabling remarkable capabilities such as in-context learning. However, as context lengths increase, a fundamental limitation of the softmax function emerges: it tends to diffuse probability mass to irrelevant tokens degrading performance in long-sequence scenarios. Furthermore, attempts to sharpen focus by lowering softmax temperature hinder learnability due to vanishing gradients. We introduce LUCID Attention, an architectural modification that applies a preconditioner to the attention probabilities. This preconditioner, derived from exponentiated key-key similarities, minimizes overlap between the keys in a Reproducing Kernel Hilbert Space, thus allowing the query to focus on important keys among large number of keys accurately with same computational complexity as standard attention. Additionally, LUCID's preconditioning-based approach to retrieval bypasses the need for low temperature and the learnability problems associated with it. We validate our approach by training ~1 billion parameter language models evaluated on up to 128K tokens. Our results demonstrate significant gains on long-context retrieval tasks, specifically retrieval tasks from BABILong, RULER, SCROLLS and LongBench. For instance, LUCID achieves up to 18% improvement in BABILong and 14% improvement in RULER multi-needle performance compared to standard attention.",
    "title_zh": "LUCID：带有预条件表示的注意力机制",
    "abstract_zh": "基于Softmax的点积注意力是Transformer架构的核心，赋予了模型诸如上下文学习等卓越能力。然而，随着上下文长度的增加，Softmax函数的一个根本性局限逐渐显现：它倾向于将概率质量分散到无关的标记上，从而在长序列场景下降低性能。此外，通过降低Softmax温度来增强注意力聚焦的做法，又会因梯度消失问题而损害模型的可学习性。为此，我们提出LUCID Attention——一种对注意力机制的结构改进方法，该方法在注意力概率上施加一个预处理算子（preconditioner）。这一预处理算子源自键向量之间相似性的指数形式，能够最小化在再生核希尔伯特空间（Reproducing Kernel Hilbert Space）中键之间的重叠，从而使查询能够准确地聚焦于大量键中的关键信息，且计算复杂度与标准注意力保持一致。此外，LUCID通过预处理机制实现检索，无需依赖低温参数，从而规避了低温带来的可学习性难题。我们在最多包含128K个标记的长上下文任务上，训练并评估了约10亿参数的语言模型。实验结果表明，LUCID在多个长上下文检索任务中均取得显著提升，特别是在BABILong、RULER、SCROLLS和LongBench等数据集上的表现尤为突出。例如，在BABILong任务中，LUCID相较标准注意力最高提升了18%；在RULER的多针头检索任务中，性能提升达14%。"
  },
  {
    "date": "2026-02-11",
    "title": "Making Databases Faster with LLM Evolutionary Sampling",
    "authors": "Mehmet Hamza Erol, Xiangpeng Hao, Federico Bianchi, Ciro Greco, Jacopo Tagliabue, James Zou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10387v1",
    "source": "arXiv",
    "abstract": "Traditional query optimization relies on cost-based optimizers that estimate execution cost (e.g., runtime, memory, and I/O) using predefined heuristics and statistical models. Improving these heuristics requires substantial engineering effort, and even when implemented, these heuristics often cannot take into account semantic correlations in queries and schemas that could enable better physical plans. Using our DBPlanBench harness for the DataFusion engine, we expose the physical plan through a compact serialized representation and let the LLM propose localized edits that can be applied and executed. We then apply an evolutionary search over these edits to refine candidates across iterations. Our key insight is that LLMs can leverage semantic knowledge to identify and apply non-obvious optimizations, such as join orderings that minimize intermediate cardinalities. We obtain up to 4.78$\\times$ speedups on some queries and we demonstrate a small-to-large workflow in which optimizations found on small databases transfer effectively to larger databases.",
    "title_zh": "通过LLM进化采样提升数据库性能",
    "abstract_zh": "传统查询优化依赖于基于成本的优化器，这些优化器通过预定义的启发式规则和统计模型来估算执行成本（如运行时间、内存使用量和I/O开销）。改进这些启发式规则需要大量的工程投入，即便实现后，它们往往也无法考虑查询与模式之间的语义关联，而这些关联本可以促成更优的物理执行计划。我们利用为DataFusion引擎设计的DBPlanBench工具框架，通过一种紧凑的序列化表示暴露物理执行计划，并让大语言模型（LLM）提出可应用并执行的局部修改建议。随后，我们对这些修改建议进行进化式搜索，在多轮迭代中不断优化候选方案。我们的核心洞察是：LLMs能够利用其语义知识识别并应用一些非显而易见的优化策略，例如通过调整连接顺序以最小化中间结果的基数。实验结果显示，部分查询的性能提升最高可达4.78倍；同时，我们还展示了从小型数据库到大型数据库的“小规模至大规模”优化迁移流程，证明在小数据集上发现的优化策略能有效推广至更大规模的数据环境。"
  },
  {
    "date": "2026-02-11",
    "title": "From Prompt-Response to Goal-Directed Systems: The Evolution of Agentic AI Software Architecture",
    "authors": "Mamdouh Alenezi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10479v1",
    "source": "arXiv",
    "abstract": "Agentic AI denotes an architectural transition from stateless, prompt-driven generative models toward goal-directed systems capable of autonomous perception, planning, action, and adaptation through iterative control loops. This paper examines this transition by connecting foundational intelligent agent theories, including reactive, deliberative, and Belief-Desire-Intention models, with contemporary LLM-centric approaches such as tool invocation, memory-augmented reasoning, and multi-agent coordination. The paper presents three primary contributions: (i) a reference architecture for production-grade LLM agents that separates cognitive reasoning from execution using typed tool interfaces; (ii) a taxonomy of multi-agent topologies, together with their associated failure modes and mitigation approaches; and (iii) an enterprise hardening checklist that incorporates governance, observability, and reproducibility considerations. Through an analysis of emerging industry platforms, including Kore.ai, Salesforce Agentforce, TrueFoundry, ZenML, and LangChain, the study identifies a convergence toward standardized agent loops, registries, and auditable control mechanisms. It is argued that the subsequent phase of agentic AI development will parallel the maturation of web services, relying on shared protocols, typed contracts, and layered governance structures to support scalable and composable autonomy. The persistent challenges related to verifiability, interoperability, and safe autonomy remain key areas for future research and practical deployment.",
    "title_zh": "从提示-响应到目标导向系统：代理型人工智能软件架构的演进",
    "abstract_zh": "代理型人工智能（Agentic AI）标志着一种架构范式的转变：从无状态、以提示驱动的生成模型，转向能够通过迭代控制回路实现自主感知、规划、行动与适应的目标导向系统。本文通过将基础智能体理论（包括反应式、推理式以及信念-欲望-意图模型）与当代以大语言模型（LLM）为中心的方法（如工具调用、记忆增强推理、多智能体协作）相连接，探讨了这一转变过程。本文提出三大主要贡献：（i）一个面向生产级LLM智能体的参考架构，通过类型化工具接口将认知推理与执行过程分离；（ii）一种多智能体拓扑结构的分类体系，以及相应的故障模式与缓解策略；（iii）一份企业级强化检查清单，涵盖治理、可观测性与可复现性等关键考量。通过对Kore.ai、Salesforce Agentforce、TrueFoundry、ZenML和LangChain等新兴行业平台的分析，研究发现业界正朝着标准化的智能体循环、注册机制和可审计的控制手段趋同。文章认为，代理型人工智能的下一阶段发展将类似于网络服务的成熟过程，依赖于共享协议、类型化契约和分层治理结构，以支持可扩展且可组合的自主性。然而，可验证性、互操作性与安全自主性等持续存在的挑战，仍是未来研究与实际部署中的关键领域。"
  },
  {
    "date": "2026-02-11",
    "title": "TestExplora: Benchmarking LLMs for Proactive Bug Discovery via Repository-Level Test Generation",
    "authors": "Steven Liu, Jane Luo, Xin Zhang, Aofan Liu, Hao Liu, Jie Wu, Ziyang Huang, Yangyu Huang, Yu Kang, Scarlett Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10471v1",
    "source": "arXiv",
    "abstract": "Given that Large Language Models (LLMs) are increasingly applied to automate software development, comprehensive software assurance spans three distinct goals: regression prevention, reactive reproduction, and proactive discovery. Current evaluations systematically overlook the third goal. Specifically, they either treat existing code as ground truth (a compliance trap) for regression prevention, or depend on post-failure artifacts (e.g., issue reports) for bug reproduction-so they rarely surface defects before failures. To bridge this gap, we present TestExplora, a benchmark designed to evaluate LLMs as proactive testers within full-scale, realistic repository environments. TestExplora contains 2,389 tasks from 482 repositories and hides all defect-related signals. Models must proactively find bugs by comparing implementations against documentation-derived intent, using documentation as the oracle. Furthermore, to keep evaluation sustainable and reduce leakage, we propose continuous, time-aware data collection. Our evaluation reveals a significant capability gap: state-of-the-art models achieve a maximum Fail-to-Pass (F2P) rate of only 16.06%. Further analysis indicates that navigating complex cross-module interactions and leveraging agentic exploration are critical to advancing LLMs toward autonomous software quality assurance. Consistent with this, SWEAgent instantiated with GPT-5-mini achieves an F2P of 17.27% and an F2P@5 of 29.7%, highlighting the effectiveness and promise of agentic exploration in proactive bug discovery tasks.",
    "title_zh": "TestExplora：通过仓库级测试生成对大语言模型进行主动漏洞发现的基准测试",
    "abstract_zh": "随着大型语言模型（LLMs）在软件开发自动化中的应用日益广泛，全面的软件保障涵盖三个不同目标：防止回归、反应式复现以及主动发现缺陷。然而，当前的评估体系系统性地忽略了第三个目标。具体而言，现有方法要么将现有代码视为真实基准（即“合规陷阱”）用于回归预防，要么依赖失败后的产物（如问题报告）进行缺陷复现——这导致它们极少能在故障发生前发现缺陷。为弥合这一差距，我们提出了TestExplora，一个旨在评估LLMs在真实、大规模代码库环境中作为主动测试者的基准。TestExplora包含来自482个代码仓库的2,389个任务，并隐藏了所有与缺陷相关的信号。模型必须通过将实现与基于文档推导出的意图进行对比，主动发现缺陷，其中文档作为判断正确性的“权威”依据。此外，为确保评估的可持续性并减少数据泄露，我们提出了持续、时间感知的数据收集机制。我们的评估结果揭示了显著的能力差距：当前最先进模型的最高“失败到通过”（Fail-to-Pass, F2P）率仅为16.06%。进一步分析表明，有效应对复杂的跨模块交互以及利用代理式探索（agentic exploration）是推动LLMs迈向自主软件质量保障的关键。与此一致，使用GPT-5-mini实例化的SWEAgent实现了17.27%的F2P率和29.7%的F2P@5率，充分证明了代理式探索在主动缺陷发现任务中的有效性与潜力。"
  },
  {
    "date": "2026-02-11",
    "title": "Asymmetric Prompt Weighting for Reinforcement Learning with Verifiable Rewards",
    "authors": "Reinhard Heckel, Mahdi Soltanolkotabi, Christos Thramboulidis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11128v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning with verifiable rewards has driven recent advances in LLM post-training, in particular for reasoning. Policy optimization algorithms generate a number of responses for a given prompt and then effectively weight the corresponding gradients depending on the rewards. The most popular algorithms including GRPO, DAPO, and RLOO focus on ambiguous prompts, i.e., prompts with intermediate success probability, while downgrading gradients with very easy and very hard prompts. In this paper, we consider asymmetric prompt weightings that assign higher weights to prompts with low, or even zero, empirical success probability. We find that asymmetric weighting particularly benefits from-scratch RL (as in R1-Zero), where training traverses a wide accuracy range, and less so in post-SFT RL where the model already starts at high accuracy. We also provide theory that characterizes prompt weights which minimize the time needed to raise success probability from an initial level to a target accuracy under a fixed update budget. In low-success regimes, where informative responses are rare and response cost dominates, these optimal weights become asymmetric, upweighting low success probabilities and thereby accelerating effective-time convergence.",
    "title_zh": "用于可验证奖励强化学习的非对称提示加权",
    "abstract_zh": "具有可验证奖励的强化学习推动了大语言模型后训练的最新进展，尤其是在推理能力方面。策略优化算法会为给定的提示生成多个响应，然后根据奖励对相应的梯度进行有效加权。目前最流行的算法，如GRPO、DAPO和RLOO，主要关注具有中等成功概率的模糊提示，同时降低对过于简单或过于困难提示的梯度权重。本文提出了一种非对称的提示加权方法，即对那些实际成功概率较低甚至为零的提示赋予更高的权重。我们发现，这种非对称加权在从零开始的强化学习（如R1-Zero）中特别有效，因为训练过程会经历广泛的准确率范围；而在后SFT的强化学习中效果较弱，因为模型初始时已具备较高的准确率。此外，我们还提供了理论分析，刻画了在固定更新预算下，能够将成功概率从初始水平提升至目标准确率所需时间最短的提示权重。在低成功率场景下，由于有信息量的响应极为稀少，且响应成本占主导地位，最优权重呈现出非对称特性，即提高低成功率提示的权重，从而加速有效时间上的收敛。"
  },
  {
    "date": "2026-02-11",
    "title": "Token-Efficient Change Detection in LLM APIs",
    "authors": "Timothée Chauvin, Clément Lalanne, Erwan Le Merrer, Jean-Michel Loubes, François Taïani, Gilles Tredan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11083v1",
    "source": "arXiv",
    "abstract": "Remote change detection in LLMs is a difficult problem. Existing methods are either too expensive for deployment at scale, or require initial white-box access to model weights or grey-box access to log probabilities. We aim to achieve both low cost and strict black-box operation, observing only output tokens. Our approach hinges on specific inputs we call Border Inputs, for which there exists more than one output top token. From a statistical perspective, optimal change detection depends on the model's Jacobian and the Fisher information of the output distribution. Analyzing these quantities in low-temperature regimes shows that border inputs enable powerful change detection tests. Building on this insight, we propose the Black-Box Border Input Tracking (B3IT) scheme. Extensive in-vivo and in-vitro experiments show that border inputs are easily found for non-reasoning tested endpoints, and achieve performance on par with the best available grey-box approaches. B3IT reduces costs by $30\\times$ compared to existing methods, while operating in a strict black-box setting.",
    "title_zh": "基于令牌的高效变化检测在大语言模型API中的应用",
    "abstract_zh": "在大语言模型（LLM）中实现远程变化检测是一项极具挑战性的问题。现有方法要么部署成本过高，难以大规模应用；要么需要初始的白盒访问模型权重，或需要灰盒访问输出的对数概率。我们旨在实现低成本且严格的黑盒操作，仅通过观察输出的标记（tokens）来完成检测。我们的方法基于一类特殊的输入，称为“边界输入”（Border Inputs），其特点是存在多个输出的最高概率标记（top token）。从统计学角度看，最优的变化检测依赖于模型的雅可比矩阵（Jacobian）以及输出分布的费舍尔信息（Fisher information）。在低温度（low-temperature）条件下分析这些量表明，边界输入能够支持强大的变化检测测试。基于这一发现，我们提出了“黑盒边界输入追踪”（Black-Box Border Input Tracking, B3IT）方案。大量在体（in-vivo）和离体（in-vitro）实验表明，对于非推理类测试端点，边界输入很容易被找到，并且其检测性能可与当前最优的灰盒方法相媲美。与现有方法相比，B3IT将成本降低了30倍，同时保持严格的黑盒操作模式。"
  },
  {
    "date": "2026-02-11",
    "title": "Embedding Inversion via Conditional Masked Diffusion Language Models",
    "authors": "Han Xiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11047v1",
    "source": "arXiv",
    "abstract": "We frame embedding inversion as conditional masked diffusion, recovering all tokens in parallel through iterative denoising rather than sequential autoregressive generation. A masked diffusion language model is conditioned on the target embedding via adaptive layer normalization, requiring only 8 forward passes through a 78M parameter model with no access to the target encoder. On 32-token sequences across three embedding models, the method achieves 81.3% token accuracy and 0.87 cosine similarity.",
    "title_zh": "通过条件掩码扩散语言模型进行嵌入反演",
    "abstract_zh": "我们将嵌入反演问题建模为条件掩码扩散过程，通过迭代去噪而非顺序自回归生成，以并行方式恢复所有标记。一种基于掩码扩散的语言模型通过自适应层归一化对目标嵌入进行条件约束，仅需对一个7800万参数的模型进行8次前向传播，且无需访问目标编码器。在三个嵌入模型上针对32个标记的序列，该方法实现了81.3%的标记准确率和0.87的余弦相似度。"
  },
  {
    "date": "2026-2-11",
    "title": "AegisGuard: A Context-Aware Framework for Semantic Vulnerability Detection and Risk Stratification",
    "authors": "Pin-Chieh Huang, Ching-Hao Mao, Chun-Ming Lai",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3663577",
    "source": "IEEE",
    "abstract": "The growing complexity of cyber threats has exposed the limitations of traditional vulnerability assessment tools, which primarily rely on static scanning and CVSS-based scoring. These approaches often fail to capture dynamic configurations and evolving threat surfaces in enterprise environments. To address this gap, we present AegisGuard, a context-aware framework for automated vulnerability detection and adaptive risk stratification. AegisGuard integrates structured system telemetry, semantic threat intelligence through retrieval-augmented generation (RAG), and a specialized large language model (LLM) to infer CVE applicability and assign five-level risk labels (L0–L4) that reflect both technical severity and environmental context. Unlike conventional scanners, AegisGuard dynamically adjusts its reasoning to system-specific privilege settings, exposure levels, and service criticality, enabling the identification of both critical exploits and subtle misconfigurations often missed by static tools. Our evaluation spans heterogeneous Linux and Windows platforms and leverages a dual-layer ground truth methodology: Core Ground Truth (C-GT) for verified vulnerabilities and Extended Ground Truth (E-GT) for semantically related threats. Results show that AegisGuard achieves an F1 score of up to 0.79 in CVE detection and exceeds 90% classification accuracy within a ±1 risk margin. Complementary ablation and prompt sensitivity analyses confirm the importance of RAG-based enrichment and structured input design in maximizing LLM effectiveness. Overall, these findings demonstrate that semantic, context-aware modeling is essential for accurate, scalable, and operationally relevant vulnerability management.",
    "title_zh": "AegisGuard：一种上下文感知的语义漏洞检测与风险分层框架",
    "abstract_zh": "日益复杂的网络威胁暴露了传统漏洞评估工具的局限性，这些工具主要依赖静态扫描和基于CVSS的评分方法。此类方法往往无法捕捉企业环境中动态的配置变化和不断演化的威胁面。为弥补这一差距，本文提出AegisGuard——一种上下文感知的自动化漏洞检测与自适应风险分级框架。AegisGuard融合了结构化系统遥测数据、通过检索增强生成（RAG）获取的语义威胁情报，以及专用大语言模型（LLM），以推断CVE的适用性，并分配五级风险标签（L0–L4），综合反映技术严重性与环境上下文。与传统扫描工具不同，AegisGuard能够根据系统特定的权限设置、暴露程度和服务关键性动态调整其推理过程，从而识别出关键利用漏洞以及静态工具常遗漏的细微配置错误。我们的评估覆盖了异构的Linux与Windows平台，并采用双层真实标签（Ground Truth）方法：核心真实标签（C-GT）用于验证漏洞，扩展真实标签（E-GT）用于捕捉语义相关的威胁。实验结果表明，AegisGuard在CVE检测中F1得分最高达0.79，且在±1风险等级范围内分类准确率超过90%。补充的消融实验与提示敏感性分析进一步证实，基于RAG的增强机制和结构化输入设计对于最大化LLM效能至关重要。总体而言，这些发现表明，语义化、上下文感知的建模方法对于实现准确、可扩展且具备实际操作价值的漏洞管理至关重要。"
  },
  {
    "date": "2026-2-11",
    "title": "From Bugs to Benchmarks: A Comprehensive Survey of Software Defect Datasets",
    "authors": "Hao-Nan Zhu, Robert Furth, Michael Pradel, Cindy Rubio-González",
    "publish": "ACM Computing Surveys",
    "url": "https://doi.org/10.1145/3797033",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "从缺陷到基准：软件缺陷数据集的全面综述",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-11",
    "title": "No HDL, No Problem: HLS-Generated Power Wasters for Fault Injection in Cloud FPGAs",
    "authors": "Zeynep Gülbeyaz Demirdag, Hassan Nassar, Lars Bauer, Jörg Henkel",
    "publish": "IEEE Embedded Systems Letters",
    "url": "https://doi.org/10.1109/les.2026.3663634",
    "source": "IEEE",
    "abstract": "Power wasters are a critical threat to cloud FPGAs. They induce voltage drops that lead to timing faults or complete denial of service. Previous methods for generating power wasters rely on low-level RTL modifications, including primitive-level structures and constraint manipulation. However, newer FPGA platforms such as Xilinx Versal restrict access to such low-level features, preventing traditional attack methods. In this work, we are the first to show that power wasters can still be created using only High-Level Synthesis (HLS), which is a standard development flow for cloud FPGAs. We demonstrate HLS-generated power wasters that can inject faults or crash the FPGA by applying overclocking and selected input patterns.",
    "title_zh": "无需HDL，亦无问题：用于云FPGA故障注入的HLS生成功耗“杀手”",
    "abstract_zh": "功耗攻击者对云FPGA构成严重威胁，它们会引发电压下降，导致时序故障甚至完全的服务中断。以往生成功耗攻击者的方法依赖于底层的RTL修改，包括原语级结构和约束调整。然而，像Xilinx Versal这样的新型FPGA平台限制了对这些底层特性的访问，使得传统攻击方法无法实施。在本研究中，我们首次证明，仅通过高层次综合（HLS）即可创建功耗攻击者，而HLS正是云FPGA的标准开发流程。我们展示了由HLS生成的功耗攻击者，能够通过超频及特定输入模式注入故障或使FPGA崩溃。"
  },
  {
    "date": "2026-2-11",
    "title": "FPGA-Accelerated SPHINCS+: An Area-Optimized and High-Throughput Design",
    "authors": "Yanfeng Bai, Bei Wang, Jiansheng Chen, Chenghua Wang, Yijun Cui, Weiqiang Liu",
    "publish": "2025 Asian Hardware Oriented Security and Trust Symposium (AsianHOST)",
    "url": "https://doi.org/10.1109/asianhost68425.2025.11370338",
    "source": "IEEE",
    "abstract": "Hardware implementations of SLH-DSA-compliant digital signatures encounter significant challenges related to computational latency and area due to the algorithm’s reliance on extensive hash computations. To address these issues, this paper introduces a novel signature architecture that leverages layer-aware parallel scheduling (LAS). This approach accelerates signing speeds while only minimally increasing resource usage in lightweight standard implementations. Additionally, we optimize the hardware implementation for six cryptographic hash functions to enhance signature generation speed. Subtree optimization further facilitates a more compact signature generation process, reducing resource requirements. Experimental results on the AMD Artix-7 FPGA demonstrate that the proposed design achieves signing speed that is $\\mathbf{2. 3 3} \\times$ faster, with $\\mathbf{6 5 \\%}$ improvement in area efficiency, and verification speed that is $2.97 \\times$ faster, accompanied by 111% increase in area efficiency compared to the latest standard-compliant implementation.",
    "title_zh": "FPGA加速的SPHINCS+：一种面积优化且高吞吐量的设计",
    "abstract_zh": "SLH-DSA兼容数字签名的硬件实现面临显著的计算延迟和面积开销问题，这主要源于该算法对大量哈希计算的依赖。为解决这些问题，本文提出了一种新颖的签名架构，采用层感知并行调度（Layer-Aware Parallel Scheduling, LAS）技术。该方法在仅轻微增加资源消耗的前提下，显著提升了签名速度，尤其适用于轻量级标准实现。此外，我们对六种密码学哈希函数的硬件实现进行了优化，进一步提升了签名生成速度。子树优化技术则使签名生成过程更加紧凑，有效降低了资源需求。在AMD Artix-7 FPGA上的实验结果表明，所提出的方案相比最新的标准合规实现，签名速度提升了$\\mathbf{2.33}\\times$，面积效率提高$\\mathbf{65\\%}$；验证速度提升$2.97\\times$，面积效率提升111%。"
  },
  {
    "date": "2026-2-11",
    "title": "Automated EARS-Based Requirements Generation with Lightweight Large Language Models",
    "authors": "Muhammad Huzaifa Imran, Touseef Tahir, Bilal Hassan, Hamid Jahankhani",
    "publish": "2025 IEEE International Conference on Technology Management, Operations and Decisions (ICTMOD)",
    "url": "https://doi.org/10.1109/ictmod66732.2025.11371998",
    "source": "IEEE",
    "abstract": "Software requirements are typically written in natural language, which is prone to issues such as ambiguity, wordiness, and vagueness. These requirements issues cause faults in software development processes. In the past, a well-known EARS (easy approach to requirements syntax) template has been proposed to mitigate these issues by specifying the requirements in semiformal format. The requirements specification in the EARS format requires an understanding of the EARS and requirement engineering domain. This requires manual labor, where each requirement needs to be manually transformed, looked at, rewritten, and transcribed by a requirement engineer. We propose a novel framework for fine-tuning light-weight LLMs that can automatically rewrite the requirements from scratch. We designed and implemented a pipeline that transforms the raw requirements to EARS format by fine-tuning four LLMs, that is, BART, DistillGPT2, GPT2, T5-Small with BART using data set of 9141 raw requirements. The BART-base provides the lowest score BLEU Score (0.405) and average BLEU score (0.708) as well as the lowest final training loss (0.34), indicating strong performance in transforming the EARS requirement.",
    "title_zh": "基于自动化EARS的需求生成方法及其轻量级大语言模型应用",
    "abstract_zh": "软件需求通常以自然语言编写，容易出现歧义、冗长和模糊等问题。这些需求问题会导致软件开发过程中的缺陷。过去，曾提出一种著名的EARS（需求语法的简易方法）模板，通过将需求以半形式化格式进行规范，以缓解上述问题。然而，使用EARS格式编写需求需要对EARS及需求工程领域有深入理解，因此需要大量人工操作，每个需求都需由需求工程师手动转换、审阅、重写和转录。为此，我们提出了一种新颖的框架，通过微调轻量级大语言模型（LLM），实现从零开始自动重写需求。我们设计并实现了一个流水线，通过微调四种LLM——BART、DistillGPT2、GPT2和T5-Small（以BART为基础）——将原始需求自动转换为EARS格式，所使用的数据集包含9141条原始需求。实验结果表明，BART-base模型在BLEU分数上表现最佳，其最低BLEU分数为0.405，平均BLEU分数为0.708，同时最终训练损失最低（0.34），表明其在将需求转换为EARS格式方面具有较强的性能。"
  },
  {
    "date": "2026-2-11",
    "title": "Bug Hunting in the RISC-V SoC: The 1\n                    <sup>st</sup>\n                    Integrated Circuit Security Challenge",
    "authors": "Lei Peng, Jiacheng Zhu, Qizhi Zhang, Shibo Tang, Xingxin Wang, Xinyu Zheng, Yaxuan Zhao, Aijiao Cui, Wei Hu, Jiaji He, Peng Fei Qiu",
    "publish": "2025 Asian Hardware Oriented Security and Trust Symposium (AsianHOST)",
    "url": "https://doi.org/10.1109/asianhost68425.2025.11370364",
    "source": "IEEE",
    "abstract": "Hardware security vulnerabilities pose a critical threat to modern system-on-chip (SoC) designs, yet their detection remains challenging due to low-level semantics and limited runtime observability. To address this gap, we organized the 1st Integrated Circuit Security Challenge (ICSC) in 2024, leveraging the open-source OpenPiton SoC platform. We introduced SecRisBen, a novel benchmark suite featuring realistic Register Transfer Level (RTL)-vulnerabilities systematically injected into the processor core and peripheral modules using five structured strategies. A multidimensional evaluation framework was developed to rigorously assess competing analysis tools. Two leading teams demonstrated state-of-the-art detection capabilities, employing information flow-based formal verification and semantic-driven property generation to uncover multiple high-impact vulnerabilities. The challenge successfully fostered collaboration and advancement in hardware security tools. Building on this momentum, we plan to hold subsequent competitions to further accelerate the progress in hardware security research and tool development.",
    "title_zh": "RISC-V SoC中的漏洞挖掘：首届集成电路安全挑战赛",
    "abstract_zh": "硬件安全漏洞对现代片上系统（SoC）设计构成严重威胁，但其检测仍面临挑战，主要由于底层语义复杂以及运行时可观测性有限。为弥补这一空白，我们在2024年举办了首届集成电路安全挑战赛（ICSC），并基于开源的OpenPiton SoC平台开展。我们提出了SecRisBen——一种新型基准测试套件，通过五种结构化策略，在处理器核心和外设模块中系统性地注入了真实的寄存器传输级（RTL）漏洞。同时，我们构建了一个多维度评估框架，以严格检验各参赛分析工具的性能。两个领先团队展示了业界顶尖的漏洞检测能力，他们采用基于信息流的形式化验证方法以及语义驱动的属性生成技术，成功发现多个高影响性漏洞。本次挑战赛有效促进了硬件安全领域工具研发的协作与进步。在此基础上，我们将继续举办后续赛事，进一步推动硬件安全研究与工具开发的快速发展。"
  },
  {
    "date": "2026-2-11",
    "title": "Resilience-by-Design: Challenges and Practitioner Needs in the Design of Resilient Automotive Systems Architectures – Findings from a Qualitative Interview Study",
    "authors": "Isaac Mpidi Bita, Aschot Hovemann, Roman Dumitrescu",
    "publish": "2025 IEEE International Conference on Technology Management, Operations and Decisions (ICTMOD)",
    "url": "https://doi.org/10.1109/ictmod66732.2025.11371881",
    "source": "IEEE",
    "abstract": "This qualitative study explores the challenges and practitioner needs in designing resilient automotive system architectures, addressing the growing complexity and vulnerability of connected and automated vehicles. Based on a semi-structured qualitative interview with experts across systems engineering, safety, and cybersecurity domains, the study identifies key challenges and expectations for implementing Resilience-by-Design in industrial practice. The findings reveal five critical themes: (1) the lack of standardized process models for the consideration of resilience in the early design phase, (2) limited methods for disruption identification using the systems architecture during early design phase, (3) insufficient evaluation metrics and methodology, like a maturity model, and (4) the absence of integrated toolchains to support resilience measures. These insights are synthesized into four major action fields that define the strategic priorities for enabling Resilience-by-Design: (1) structured development processes, (2) disruption analysis and resilience evaluation methods, and (3) AI-and model-based design tools.",
    "title_zh": "基于设计的韧性：汽车系统架构韧性设计中的挑战与从业者需求——来自定性访谈研究的发现",
    "abstract_zh": "本项定性研究探讨了在设计具有韧性的汽车系统架构过程中所面临的挑战及从业者需求，重点关注互联与自动驾驶车辆日益增长的复杂性与脆弱性问题。基于对系统工程、安全及网络安全领域专家的半结构化深度访谈，研究识别出工业实践中实施“韧性设计”（Resilience-by-Design）的关键挑战与期望。研究发现归纳出五个核心主题：（1）在早期设计阶段缺乏用于考虑韧性的标准化流程模型；（2）在早期设计阶段利用系统架构进行扰动识别的方法有限；（3）评估指标与方法不足，例如缺乏成熟度模型；（4）缺少集成化的工具链以支持韧性措施的实施。这些发现被整合为四大关键行动领域，明确了推动“韧性设计”落地的战略优先事项：（1）结构化开发流程；（2）扰动分析与韧性评估方法；（3）基于人工智能与模型驱动的设计工具。"
  },
  {
    "date": "2026-2-11",
    "title": "Self-Adaptive Defect Prediction in Software Systems Using Deep and Reinforcement Learning",
    "authors": "N. Nagalakshmi, G. L. Anand Babu, J. Durga Rani, Hari Priya G S, R. Srividya, S. Vineel Krishna",
    "publish": "2025 2nd International Conference on Integration of Computational Intelligent System (ICICIS)",
    "url": "https://doi.org/10.1109/icicis65613.2025.11371238",
    "source": "IEEE",
    "abstract": "Good quality code is required in contemporary software development to prevent defects and maintain systems stable. Rules and guesses are not effective for intricate projects. In this research, a new approach is proposed through the application of Deep Learning (DL), Reinforcement Learning (RL), and BERT for enhancing defect prediction. DL studies past data like code changes, bug reports, and complexity. RL helps improve accuracy by adjusting strategies and picking key code areas to check or fix. The system learns over time and becomes smarter. Tests show better results in quality and fewer bugs with this smart approach.",
    "title_zh": "基于深度学习与强化学习的软件系统自适应缺陷预测",
    "abstract_zh": "在现代软件开发中，高质量的代码对于防止缺陷、保持系统稳定至关重要。对于复杂的项目，仅靠规则和猜测是无效的。本研究提出了一种新方法，通过应用深度学习（DL）、强化学习（RL）和BERT技术来提升缺陷预测能力。深度学习分析历史数据，如代码变更、缺陷报告和复杂度信息；强化学习通过调整策略并选择关键代码区域进行检查或修复，从而提高预测准确性。该系统能够持续学习，不断优化自身性能。实验结果表明，采用这种智能方法后，软件质量显著提升，缺陷数量明显减少。"
  },
  {
    "date": "2026-2-11",
    "title": "A Context-Aware Gray Box Framework for Hybrid Mobile Application Testing",
    "authors": "Peeyush Pareek, Mahipal Singh Deora",
    "publish": "2025 2nd International Conference on Integration of Computational Intelligent System (ICICIS)",
    "url": "https://doi.org/10.1109/icicis65613.2025.11371270",
    "source": "IEEE",
    "abstract": "Mobile app ecosystems have changed rapidly to serve a variety of platforms, devices, and runtime environments. Traditional software testing solutions are unable to track the changes in complexity when testing hybrid mobile applications that interface with both native and web components. In this paper, we present an approach for a Context-Aware Gray Box Framework (GBF) for hybrid mobile application testing that attempts to merge 'structural analysis' with behavioral modeling. Partial access to the source code and a simulated dynamic user interface (UI) at runtime are considered as part of the GBF in order to produce optimized test cases providing a blend of code-level precision and user-level coverage. Since the framework converges both white-box and black-box approach strategies, our approach improves automation and efficiency when testing hybrid mobile applications for error detection. Studies that were experimental found that the GBF had up to 94 % accuracy when studying bugs and up to 89 % coverage in buggy hybrid mobile applications using the Android ecosystem, and produced better results than existing tools such as Monkey Runner and Robolectric.",
    "title_zh": "一种上下文感知的灰盒框架用于混合移动应用测试",
    "abstract_zh": "移动应用生态系统迅速发展，以适应各种平台、设备和运行时环境。传统的软件测试解决方案在测试同时包含原生和Web组件的混合移动应用时，难以应对复杂性的变化。本文提出了一种上下文感知的灰盒测试框架（Context-Aware Gray Box Framework, GBF），旨在融合“结构分析”与行为建模。该框架通过部分访问源代码，并在运行时模拟动态用户界面（UI），生成优化的测试用例，从而在代码级精度与用户级覆盖之间取得平衡。由于该框架结合了白盒与黑盒测试策略，我们的方法显著提升了混合移动应用测试的自动化水平和效率，有助于更有效地发现错误。实验研究表明，在Android生态系统中，GBF在检测缺陷时准确率最高可达94%，在存在缺陷的混合移动应用中覆盖率最高达89%，其表现优于现有的工具如Monkey Runner和Robolectric。"
  },
  {
    "date": "2026-2-11",
    "title": "Efficient Regression-Based Verification Methodology for Hardware-in-the-Loop Simulation Models",
    "authors": "David Schlatzer, Nick Schade, Jürgen Pannek",
    "publish": "2025 IEEE International Conference on Vehicular Electronics and Safety (ICVES)",
    "url": "https://doi.org/10.1109/icves65691.2025.11375963",
    "source": "IEEE",
    "abstract": "Hardware-in-the-Loop (HiL) simulation is a well-established technique for system validation in automotive development. As autonomous vehicles become more prevalent, the ability to demonstrate the credibility of these HiL systems becomes increasingly important. A key factor influencing this credibility is the verification of the simulation models used as a subsystem within the HiL environment. The increasing complexity of vehicle software leads to more complex simulation models, which in turn significantly raises the effort required for their verification. At the same time, with the shift towards software-defined vehicles, the demand for faster and more frequent incremental software updates is growing. This trend presents a substantial challenge for providers of HiL simulation models, who must keep pace without impairing the ability to demonstrate and document the credibility of the simulation models for every release. In this context, regression testing plays a crucial role in incremental development processes of simulation models, as it ensures that newly introduced changes do not negatively impact existing system behavior. To address this, this paper introduces a regression-based test case selection method to increase the efficiency of the verification of HiL simulation models. The approach performs graph-based signal flow analysis, identifies differences between consecutive simulation model releases, and selects reusable vehicle-level test cases for regression testing of a new simulation model increment.",
    "title_zh": "基于高效回归分析的硬件在环仿真模型验证方法",
    "abstract_zh": "硬件在环（HiL）仿真技术是汽车开发中系统验证的成熟方法。随着自动驾驶汽车的日益普及，证明这些HiL系统可信度的能力变得愈发重要。影响这一可信度的一个关键因素，是作为HiL环境内子系统所使用的仿真模型的验证。车辆软件的复杂性不断增加，导致仿真模型也日趋复杂，从而显著增加了其验证所需的工作量。与此同时，随着汽车向软件定义模式转变，对更快、更频繁的增量软件更新的需求也在持续增长。这一趋势给HiL仿真模型的提供者带来了巨大挑战：他们必须在不损害每一轮发布中仿真模型可信度的可证明性和可追溯性的前提下，保持快速迭代的步伐。在此背景下，回归测试在仿真模型的增量开发过程中发挥着至关重要的作用，它确保新引入的变更不会对现有系统行为产生负面影响。为此，本文提出了一种基于回归的测试用例选择方法，以提高HiL仿真模型验证的效率。该方法通过基于图的信号流分析，识别连续仿真模型版本之间的差异，并为新仿真模型增量的回归测试选择可复用的整车级测试用例。"
  },
  {
    "date": "2026-2-11",
    "title": "eSavior: An AI-Driven Framework for Sustainable E-Waste Management",
    "authors": "Aditya Shrivastav, Sunil Sankathala, Kashvi Chaturvedi, Atharva Saraf, Krutika Patre, Susanta Das, Ayushi Godiya, Khushbu Trivedi",
    "publish": "2025 2nd International Conference on Integration of Computational Intelligent System (ICICIS)",
    "url": "https://doi.org/10.1109/icicis65613.2025.11371048",
    "source": "IEEE",
    "abstract": "E-waste production is increasing significantly, with 62 million metric tonnes (Mt) generated worldwide in 2022 and less than a quarter being handled through formal recycling channels. Some of the greatest sources of e-waste come from schools, hospitals and IT firms but they're also the least equipped to handle these problems because of fast-paced advancements, scattered disposal systems and few chances for reprocessing. The eSavior system enables users to quickly and wisely decide when to upgrade devices, keep them functioning longer and choose the best way to recycle their old technology. The system relies on sophisticated machine learning algorithms, predictive analytics and its very own Chat Repair Assistant to streamline the handling of electronic devices throughout their entire lifespan. The solution draws upon the ideals of the UNSDGs and integrates data analysis, ethical decision-making and affordable strategies to effectively manage electronic devices throughout their lifecycles.",
    "title_zh": "eSavior：一种由人工智能驱动的可持续电子废弃物管理框架",
    "abstract_zh": "电子废弃物的产生量正在显著增加，2022年全球产生的电子废弃物高达6200万吨，但不到四分之一通过正规回收渠道处理。学校、医院和IT公司是电子废弃物的主要来源，但由于技术更新迅速、回收体系分散以及再利用机会有限，它们恰恰是最缺乏应对能力的机构。eSavior系统使用户能够快速而明智地决定何时升级设备、延长设备使用寿命，并选择最合适的旧设备回收方式。该系统依托先进的机器学习算法、预测分析技术以及其独有的“Chat Repair Assistant”（聊天维修助手），全面优化电子设备在其整个生命周期中的管理流程。该解决方案秉承联合国可持续发展目标（UNSDGs）的理念，融合数据分析、伦理决策与经济可行的策略，有效实现电子设备全生命周期的管理。"
  },
  {
    "date": "2026-2-11",
    "title": "GROOT: GPT-based Human-RObOT Interface",
    "authors": "Shobhit Maniar, Gilbert Tang, Marco Chacin",
    "publish": "2025 7th International Conference on Control and Robotics (ICCR)",
    "url": "https://doi.org/10.1109/iccr67607.2025.11372068",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) have revolutionized the realm of Natural Language Processing (NLP). Their proficiency in planning and reasoning, combined with code generation capabilities, presents a novel avenue for robotics applications. This work introduces GROOT, a novel speech-based language-agnostic middleware that uses instructions and code examples as grounding principle to leverage Generative Pre-Trained Transformer’s ability to produce code for new and unseen tasks. Unlike methods based on language-conditioned robot policies, GROOT capitalises on auto-regressive code generation inspired by Code-as-Policy (CaP) and ProgPrompt. The aim is to create a human-robot interface using GROOT that enables the embodiment of an LLM to take user instructions like ’move in a square’, ’move 20 cm in front’, ’go to position ’X’ on the grid’ and return policy code based on robot API. In this paper, GROOT was used in a number of experiments to assess its performance to few-shot learning against spatial reasoning, logical reasoning and compound simulated tasks. This work reflects the potential of prompting code-based examples and API-based instructions as a grounding method to integrate large-language models with robotic platforms, envisioning seamless and intuitive human-robot interactions.",
    "title_zh": "GROOT：基于GPT的人机交互机器人",
    "abstract_zh": "大型语言模型（LLMs）彻底改变了自然语言处理（NLP）领域。它们在规划与推理方面的卓越能力，以及代码生成的潜力，为机器人应用开辟了全新的途径。本文提出了一种名为GROOT的新颖语音驱动、语言无关的中间件，该系统以指令和代码示例作为基础，利用生成式预训练变换器（Generative Pre-Trained Transformer）生成新任务和未见任务代码的能力。与基于语言条件的机器人策略方法不同，GROOT借鉴了“代码即策略”（Code-as-Policy, CaP）和ProgPrompt的思想，采用自回归代码生成机制。其目标是通过GROOT构建一个人机交互接口，使大型语言模型能够理解用户指令，如“沿方形移动”、“向前移动20厘米”、“前往网格上的位置X”，并基于机器人API返回相应的策略代码。本文在多项实验中应用GROOT，评估其在少量样本学习场景下对空间推理、逻辑推理以及复合模拟任务的表现。本研究展示了以代码示例和API指令作为引导方式，将大型语言模型与机器人平台融合的巨大潜力，展望了实现无缝且直观的人机交互的未来。"
  },
  {
    "date": "2026-2-11",
    "title": "A Portable and Hybrid Verification Framework Using C and UVM for Secure RISC-V SoCs",
    "authors": "Muhammad Yasir Farooq, Haroon Waris, Chenghua Wang, Muhammad Usman Akram, Jiatong Tian, Jiang Li, Weiqiang Liu",
    "publish": "2025 Asian Hardware Oriented Security and Trust Symposium (AsianHOST)",
    "url": "https://doi.org/10.1109/asianhost68425.2025.11370371",
    "source": "IEEE",
    "abstract": "Comprehensive functional verification at the System-on-Chip (SoC) level is a critical and time-consuming task. The growing adoption of open source RISC-V based cores with safety and security features has introduced new verification challenges that require scalable and reusable solutions. This paper presents a portable and hybrid verification framework using C and UVM for secure RISC-V SoCs. The proposed UVM based verification framework is designed to support both C/assembly level test cases and SystemVerilog based verification components, enabling a dual test strategy that enhances coverage and debugging capabilities. The VE includes verification components for core, cache and peripheral interfaces such as agents, predictors and scoreboards, making it applicable to a wide range of RISC-V standard extension cores. It also supports third-party VIP integration, regression analysis and functional coverage tracking for integer, multiplication, compressed and floating-point instruction sets of RISC-V core. As a case study, the framework is applied to a customized open source RISCV SoC enhanced with AES security features. The experimental results demonstrate that the framework achieves 90% functional coverage, 85% code coverage and 91% instruction coverage. The indigenously developed hybrid C/UVM test suites for UART, SPI and AES are easily configurable and reusable. In general, the proposed framework provides an automated, portable and extensible solution to verify secure RISC-V SoCs with reduced engineering effort and faster coverage closure. This work emphasizes practical integration of hybrid C/UVM testing across RISCV cores and peripherals and includes a comparative evaluation with existing platforms to highlight portability and reuse.",
    "title_zh": "一种基于C语言和UVM的便携式混合验证框架用于安全的RISC-V片上系统",
    "abstract_zh": "系统级芯片（SoC）层面的全面功能验证是一项关键且耗时的任务。随着基于开源RISC-V架构、具备安全与防护特性的核心日益普及，验证工作面临新的挑战，亟需可扩展且可复用的解决方案。本文提出一种基于C语言与UVM（Universal Verification Methodology）的便携式混合验证框架，用于保障RISC-V SoC的安全性。所提出的UVM验证框架支持C/汇编级测试用例以及SystemVerilog验证组件，实现双层测试策略，显著提升覆盖率和调试能力。该验证环境（VE）包含针对核心、缓存及外设接口（如UART、SPI等）的验证组件，例如代理（agents）、预测器（predictors）和记分板（scoreboards），适用于多种RISC-V标准扩展核心。同时，该框架支持第三方VIP集成、回归分析以及对RISC-V核心中整数、乘法、压缩指令和浮点指令集的功能覆盖追踪。\n\n作为案例研究，该框架被应用于一个定制化的开源RISC-V SoC，其增强了AES安全功能。实验结果表明，该框架实现了90%的功能覆盖率、85%的代码覆盖率和91%的指令覆盖率。自主开发的UART、SPI和AES混合C/UVM测试套件具有良好的可配置性和可复用性。总体而言，所提出的框架提供了一种自动化、可移植且可扩展的解决方案，能够有效降低工程投入，加速覆盖率收敛，从而高效验证安全型RISC-V SoC。本研究强调了在RISC-V核心与外设间实现混合C/UVM测试的实际集成，并通过与现有平台的对比评估，凸显了该框架在可移植性与复用性方面的优势。"
  },
  {
    "date": "2026-2-11",
    "title": "GNΩSIS: Lessons Learned in Generating a High-Level Synthesis Dataset",
    "authors": "Aggelos Ferikoglou, Despoina Tomkou, Dimosthenis Masouros, Dimitrios Soudris, Sotirios Xydis",
    "publish": "ACM Transactions on Architecture and Code Optimization",
    "url": "https://doi.org/10.1145/3797035",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "GNΩSIS：生成高层次综合数据集的经验教训",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-11",
    "title": "LLMs’ Hallucination Mitigation Mechanism Used for Task Planning for NAO Humanoid Robot",
    "authors": "Shadi Abpeikar, Matt Garratt, Kathryn Kasmarik, Sreenatha Anavatti",
    "publish": "2025 7th International Conference on Control and Robotics (ICCR)",
    "url": "https://doi.org/10.1109/iccr67607.2025.11372067",
    "source": "IEEE",
    "abstract": "The rapid growth and development of Large Language Models (LLMs) have made them suitable for solving a wide range of problems, including those in robotics. However, despite their popularity and capabilities, LLMs face critical challenges that undermine trust in their efficiency and accuracy. One of the most significant challenges is hallucination, which stems from their strong generalisation abilities. This issue results in LLMs generating responses that lack evidence of correctness in reality.This paper analyses hallucinations in responses generated for robotic task planning. The NAO humanoid robot is selected as the platform for task planning experiments, and GPT-3.5, Llama 3.1, Gemma 3, and CodeX are used as the LLMs for response generation. The generated responses include YAML representations and Python 2 code. We introduce specific metrics to measure hallucinations in the context of robotic task planning.The core objective of this paper is to investigate how prompt engineering can mitigate hallucinations using these metrics. Experimental results demonstrate that incorporating prompt engineering—by providing additional context and information to the LLMs—reduces the occurrence of hallucinations in task planning responses.",
    "title_zh": "用于NAO人形机器人的任务规划的大型语言模型幻觉缓解机制",
    "abstract_zh": "大型语言模型（LLMs）的快速发展使其能够解决广泛的问题，包括机器人领域中的任务。然而，尽管LLMs广受欢迎且功能强大，它们仍面临一些关键挑战，这些挑战削弱了人们对它们效率和准确性的信任。其中最显著的问题是“幻觉”（hallucination），这一问题源于其强大的泛化能力，导致模型生成的回应在现实中缺乏事实依据。本文分析了在机器人任务规划中LLMs生成回应时出现的幻觉现象。实验以NAO人形机器人作为任务规划平台，选用GPT-3.5、Llama 3.1、Gemma 3和CodeX作为生成回应的LLMs，生成的内容包括YAML格式的表示和Python 2代码。本文提出了特定的度量指标，用于评估机器人任务规划场景下的幻觉程度。本文的核心目标是研究提示工程（prompt engineering）在减少幻觉方面的有效性，通过上述指标进行评估。实验结果表明，通过提示工程为LLMs提供额外的上下文和信息，能够有效降低任务规划回应中幻觉的发生率。"
  },
  {
    "date": "2026-2-11",
    "title": "Graphical Interface of an Intellegent Support System for the AUV Operator’s Activities",
    "authors": "Andrey Pugachev, Alexey Borovik, Konstantin Shilin",
    "publish": "2025 International Conference on Ocean Studies (ICOS)",
    "url": "https://doi.org/10.1109/icos67841.2025.11371661",
    "source": "IEEE",
    "abstract": "This article describes in detail the new graphical user interface (GUI) for the operator support system when planning mission of an autonomous underwater vehicle (AUV), developed at IMTP FEB RAS. It solves complex tasks using a multimodal approach combining natural language data processing (NLP), visual task mapping, and automated code generation in a specialized underwater research programming language (URPL). The graphical user interface consists of interconnected modules: a central control panel with a query history, a workspace for displaying and editing the mission code, and a mapping module for graphical route design. An important component is an intelligent conversational interface based on neural network models. This assistant allows operators to set and edit mission programs through voice interaction. The proposed interface option simplifies the process of assigning missions to the vehicle, which significantly reduces the time needed to prepare for deployment and reduces the likelihood of human error. The system reduces the level of operators' specialized programming knowledge, increasing the availability and efficiency of AUV mission settings.",
    "title_zh": "智能支持系统在AUV操作员活动中的图形界面",
    "abstract_zh": "本文详细介绍了由俄罗斯科学院远东分院海洋地质与地球物理研究所（IMTP FEB RAS）开发的自主水下航行器（AUV）任务规划操作支持系统的新图形用户界面（GUI）。该系统采用多模态方法，结合自然语言处理（NLP）、视觉任务映射以及专用海底科研编程语言（URPL）的自动化代码生成，以解决复杂的任务规划问题。图形用户界面由多个相互关联的模块组成：中央控制面板（包含查询历史记录）、用于显示和编辑任务代码的工作区，以及用于图形化路径设计的地图模块。其中一个重要组成部分是基于神经网络模型的智能对话式接口。该助手允许操作员通过语音交互方式设定和修改任务程序。所提出的界面方案简化了向航行器分配任务的过程，显著缩短了部署前的准备时间，并降低了人为错误的发生概率。该系统降低了操作人员对专业编程知识的要求，提升了AUV任务设置的可及性与效率。"
  },
  {
    "date": "2026-2-11",
    "title": "Leveraging Large Language Models for Secure Hardware Verification and Analysis",
    "authors": "Yifang Zhao, Weimin Fu, Yi-Xiang Hu, Shijie Li, Xiaolong Guo, Yier Jin",
    "publish": "2025 Asian Hardware Oriented Security and Trust Symposium (AsianHOST)",
    "url": "https://doi.org/10.1109/asianhost68425.2025.11370389",
    "source": "IEEE",
    "abstract": "The increasing complexity of modern system-on-chip development and its distributed design workflows introduces significant security challenges. However, traditional verification techniques face limitations in scalability and automation. Recent advancements in Large Language Models (LLMs) offer promising opportunities for automating hardware security verification. This paper presents a comprehensive survey of emerging research that applies LLMs to secure hardware design analysis. Through objective evaluation, we find that current LLM-driven approaches are often developed under overly simplified scenarios and demonstrate unstable performance across diverse hardware designs. To address these issues, we outline three key directions for future research: developing standardized security-oriented benchmarks, advancing domain-specific semantic reasoning capabilities, and facilitating tighter integration with verification tools. This study provides essential insights for building scalable and fully automated LLM-driven hardware security verification.",
    "title_zh": "利用大型语言模型进行安全硬件验证与分析",
    "abstract_zh": "现代片上系统（SoC）开发的复杂性日益增加，其分布式设计流程也带来了显著的安全挑战。然而，传统的验证技术在可扩展性和自动化方面面临局限。近年来，大型语言模型（LLMs）的发展为自动化硬件安全验证提供了令人期待的新机遇。本文全面综述了将LLMs应用于安全硬件设计分析的新兴研究。通过客观评估，我们发现当前基于LLM的方法大多在过于简化的场景下开发，且在不同硬件设计之间表现出性能不稳定的问题。为解决这些问题，本文提出了未来研究的三个关键方向：构建标准化的安全导向基准测试、提升面向特定领域的语义推理能力，以及促进与验证工具的更紧密集成。本研究为构建可扩展且完全自动化的LLM驱动硬件安全验证体系提供了重要洞见。"
  },
  {
    "date": "2026-2-11",
    "title": "A Comparison of Large Language Models in a Retrieval-Augmented Generation (RAG) System for Machine Repair and Maintenance Prompts",
    "authors": "Shane Tikasingh, Patrick Hosein",
    "publish": "2025 IEEE International Conference on Technology Management, Operations and Decisions (ICTMOD)",
    "url": "https://doi.org/10.1109/ictmod66732.2025.11371897",
    "source": "IEEE",
    "abstract": "We constructed a Retrieval Augmented Generation (RAG) system for industrial machine manuals to quantify the performance of various open-source Large Language Models (LLMs). Using technical manuals from a flour mill, textual data was extracted using MinerU. The data was processed using Natural Language Processing (NLP), embedded with \"Qwen3-Embedding-0.6B\" and entered into a PostgreSQL database using LangChain’s pgVector API. Our RAG pipeline integrated a tag extractor, three query expansion techniques (Multiquery, Decomposition, Step back) and one scoring algorithm (BM25), a PostgreSQL Database, a Reranker (mxbai-rerank-xsmall-v1), a Prompt template, and an LLM. We evaluated the BERTScore performance of five open-source LLMs (Gemma3:1B, Gemma3:4B, Llama3.1:8B, Llama3.2:1B, Llama3.2:3B) in this RAG pipeline. One key finding is that model performance is task-dependent: Llama3.1:8B excelled in precision, while Gemma3:4B excelled in recall. Smaller models can also outperform larger ones in specific cases—for example, Llama3.2:3B was more effective at identifying unanswerable questions, a crucial safety feature, and offered greater consistency, though with some trade-off in overall performance. This study provides a framework for selecting cost-effective, task-appropriate open-source LLMs in industrial applications and highlights the practical value of smaller parameter models, especially for compute-constrained businesses.",
    "title_zh": "基于检索增强生成（RAG）系统的大型语言模型在机器维修与维护提示中的比较研究",
    "abstract_zh": "我们构建了一个检索增强生成（RAG）系统，用于工业机械手册，以量化不同开源大语言模型（LLM）的性能表现。利用一家面粉厂的技术手册，通过MinerU提取文本数据，再使用自然语言处理（NLP）技术进行处理，采用“Qwen3-Embedding-0.6B”模型进行文本嵌入，并通过LangChain的pgVector API将数据存入PostgreSQL数据库。我们的RAG流水线集成了标签提取器、三种查询扩展技术（Multiquery、Decomposition、Step back）、一种评分算法（BM25）、PostgreSQL数据库、一个重排序模型（mxbai-rerank-xsmall-v1）、一个提示模板以及一个大语言模型。\n\n我们在此RAG系统中评估了五种开源LLM（Gemma3:1B、Gemma3:4B、Llama3.1:8B、Llama3.2:1B、Llama3.2:3B）的BERTScore表现。一个关键发现是：模型性能具有任务依赖性——Llama3.1:8B在精确率方面表现优异，而Gemma3:4B在召回率方面表现更佳。在特定场景下，小型模型甚至可以超越大型模型：例如，Llama3.2:3B在识别无法回答的问题方面更为有效，这一特性对安全性至关重要，同时表现出更高的稳定性，尽管在整体性能上略有妥协。\n\n本研究为工业应用中选择成本效益高、任务适配性强的开源LLM提供了一个实用框架，凸显了小型参数模型在计算资源受限企业中的实际价值。"
  },
  {
    "date": "2026-2-11",
    "title": "Compiler Design 5.0: Enabling Intelligent Edge Computing in the Era of Industry 5.0 at Qualcomm",
    "authors": "Rashmi Ashtagi, Ranjeet Vasant Bidwe, Ruchita Kamble, Soham Joshi, Priten Jaiswal, Varad Jumbad",
    "publish": "2025 2nd International Conference on Integration of Computational Intelligent System (ICICIS)",
    "url": "https://doi.org/10.1109/icicis65613.2025.11371109",
    "source": "IEEE",
    "abstract": "Industry 5.0 marks the dawn of a new era in manufacturing and computing, where human-driven innovation, Artificial Intelligence (AI) integration, and edge intelligence come together. Leading the charge is Qualcomm, reimagining compiler design to address the challenges of ultra-efficient, heterogeneous computing environments. This paper delves into compiler architecture evolution under Industry 5.0 that addresses Qualcomm's approach to peak performance optimization between AI accelerators, DSPs, and multi-core processors. The case study discusses updates on machine learning aided optimization, adaptive compilation in real-time, and domain-specific languages, all fundamental for supporting interactive, contextually aware applications on the edge. The research also explores how Qualcomm uses these compiler breakthroughs to optimize the deployment of AI workloads in future IoT, automotive, and mobile platforms. Through this prism, we illustrate how Compiler Design 5.0 is not merely a technical imperative but a strategic catalyst in achieving the true promise of Industry 5.0. Unlike existing surveys, this paper uniquely frames Qualcomm's compiler innovations within the broader paradigm of Compiler Design 5.0 and Industry 5.0, highlighting the strategic role of compilers in enabling sustainable, human-centric intelligent edge computing.",
    "title_zh": "高通公司：编译器设计5.0——在工业5.0时代推动智能边缘计算",
    "abstract_zh": "工业5.0标志着制造与计算新时代的开启，人类驱动的创新、人工智能（AI）的深度融合以及边缘智能的协同发展成为核心特征。在这一变革浪潮中，高通公司正重新构想编译器设计，以应对超高效异构计算环境带来的挑战。本文深入探讨了在工业5.0背景下编译器架构的演进，重点分析高通如何通过优化AI加速器、数字信号处理器（DSP）与多核处理器之间的峰值性能，实现系统整体效能的提升。案例研究详细介绍了机器学习辅助优化、实时自适应编译以及领域特定语言（DSL）等方面的最新进展，这些技术均为支持边缘端交互式、情境感知型应用提供了关键支撑。研究还探讨了高通如何利用这些编译器技术突破，优化未来物联网、汽车及移动平台中AI工作负载的部署。通过这一视角，本文阐明了编译器设计5.0不仅是一项技术需求，更是实现工业5.0真正愿景的战略驱动力。与现有综述不同，本文首次将高通的编译器创新置于编译器设计5.0与工业5.0的宏观范式框架下进行系统阐述，凸显了编译器在推动可持续、以人为本的智能边缘计算发展中的战略作用。"
  },
  {
    "date": "2026-2-11",
    "title": "Optimization-Oriented Retrieval-Augmented Generation for Large-Scale Document Understanding",
    "authors": "Yuepeng Zhang, Jiayi Zeng, Jiayi Wang, Yang Gao, Wenqing Wu",
    "publish": "2025 International Conference on Graphics and Signal Processing (ICGSP)",
    "url": "https://doi.org/10.1109/icgsp66091.2025.11379732",
    "source": "IEEE",
    "abstract": "Large language models have made significant strides in natural language processing but still struggle with factual accuracy and domain-specific knowledge retrieval. To address these limitations, Retrieval-Augmented Generation frameworks integrate information retrieval mechanisms with generative models to enhance response relevance and precision. In this paper, we propose an optimization-oriented RAG system for large-scale document understanding, which combines FAISSbased retrieval with multi-model generation architecture to improve retrieval accuracy, response consistency, and crossdomain adaptability. Our approach features advanced metadatarich embedding pipelines, adaptive text tiling, and multi-model integration for response optimization. We used two large-scale datasets to evaluate our system: an ArXiv-based scientific corpus and a domain-specific EV dataset. Experimental results show that our implementation is superior to the traditional RAG system in terms of retrieval efficiency, response quality, and domain adaptability. By introducing dynamic model scheduling and weighted answer aggregation, our system provides a scalable, high-performance solution for knowledge-intensive applications, including academic research and technical document analysis.",
    "title_zh": "面向优化的检索增强生成在大规模文档理解中的应用",
    "abstract_zh": "大型语言模型在自然语言处理领域取得了显著进展，但仍面临事实准确性以及特定领域知识检索方面的挑战。为解决这些局限性，检索增强生成（Retrieval-Augmented Generation, RAG）框架将信息检索机制与生成模型相结合，以提升响应的相关性和精确度。本文提出一种面向优化的RAG系统，用于大规模文档理解任务，该系统结合基于FAISS的检索技术与多模型生成架构，有效提升了检索准确率、响应一致性以及跨领域适应能力。我们的方法引入了先进的元数据丰富的嵌入流水线、自适应文本分块策略以及多模型融合机制，以实现响应优化。我们使用两个大规模数据集对系统进行了评估：一个基于ArXiv的科学文献语料库和一个特定领域的电动汽车（EV）数据集。实验结果表明，与传统RAG系统相比，本方案在检索效率、响应质量及领域适应性方面均表现更优。通过引入动态模型调度与加权答案聚合机制，本系统为知识密集型应用（如学术研究与技术文档分析）提供了一种可扩展、高性能的解决方案。"
  },
  {
    "date": "2026-2-11",
    "title": "NLP-Driven Plagiarism Detection: A Smarter Approach",
    "authors": "Aditya Narsale, Suyog Nannaware, Vishwajeet Patil, Rohan Sapkale, Ratna Patil",
    "publish": "2025 2nd International Conference on Integration of Computational Intelligent System (ICICIS)",
    "url": "https://doi.org/10.1109/icicis65613.2025.11371171",
    "source": "IEEE",
    "abstract": "With the growing availability of digital content, the demand for efficient plagiarism detection has become exponentially high. The major challenge here is detecting semantic similarity and paraphrased text since traditional keywordmatching algorithms tend to fail in detecting conceptual rewording. This paper introduces an NLP-based plagiarism detection system that performs automated text extraction, comparison, and similarity analysis for scholarly and professional writings. The system supports uploading PDFs, extracting text data, and evaluating possible plagiarism using TF-IDF vectorization and cosine similarity. For better accuracy, it cross-checks extracted text with web sources via Google's Custom Search API. The method combines text preprocessing, feature extraction, and similarity measurement to provide a more accurate textual overlap evaluation. Based on a Flask-based framework, the system provides a user-friendly interface for effortless document analysis and result visualization. Addressing the shortcomings of conventional plagiarism detection techniques, this work sets the stage for further enhancements based on deep learning methodologies to enhance identification of subtle textual similarities. This work advances the development of automated plagiarism detection with a scalable and effective solution for content integrity validation. The contribution of this work is combining NLP similarity analysis with real-time web verification through the Google Custom Search API and the provision of a scalable Flask-based interface to detect plagiarism. The combination embodies current NLP methods and real-world deployment, thereby making the system both useful and usable by professionals and academics.",
    "title_zh": "基于自然语言处理的抄袭检测：一种更智能的方法",
    "abstract_zh": "随着数字内容的日益丰富，对高效查重技术的需求呈指数级增长。其中主要挑战在于检测语义相似性及改写文本，因为传统的关键词匹配算法往往难以识别概念性重述。本文提出了一种基于自然语言处理（NLP）的查重系统，能够自动完成文本提取、比对及相似性分析，适用于学术与专业写作。该系统支持上传PDF文件，提取文本数据，并利用TF-IDF向量化与余弦相似度评估潜在的抄袭行为。为提升准确性，系统还通过Google自定义搜索API对提取的文本与网络资源进行交叉比对。该方法结合文本预处理、特征提取与相似性度量，实现了更精准的文本重叠评估。系统基于Flask框架构建，提供用户友好的界面，便于文档分析与结果可视化。针对传统查重技术的不足，本研究为后续基于深度学习的方法改进奠定了基础，以进一步提升对细微文本相似性的识别能力。本工作推动了自动化查重技术的发展，提供了一种可扩展且高效的解决方案，用于内容完整性验证。本研究的贡献在于将NLP相似性分析与实时网络验证（通过Google自定义搜索API）相结合，并提供了一个可扩展的Flask界面，以实现查重检测。该系统融合了前沿的NLP技术与实际应用场景，使其在专业人员与学术界中兼具实用性与可用性。"
  },
  {
    "date": "2026-2-11",
    "title": "Density Measures for Language Generation",
    "authors": "Jon Kleinberg, Fan Wei",
    "publish": "2025 IEEE 66th Annual Symposium on Foundations of Computer Science (FOCS)",
    "url": "https://doi.org/10.1109/focs63196.2025.00034",
    "source": "IEEE",
    "abstract": "The recent successes of large language models (LLMs) have led to a surge of theoretical research into the properties of language generation. A recent line of work has proposed an abstract view of the question — called language generation in the limit — in which we view language generation as a game played between an adversary and an algorithm: the adversary generates strings from an unknown language K, known only to come from a countable collection of candidate languages, and after observing a finite set of these strings, the algorithm must generate new strings from the language K that it hasn't seen before. This formalism highlights an important tension: the trade-off between validity (that the algorithm should only produce strings that come from the language) and breadth (that the algorithm should be able to produce \"many\" strings from the language). This validity-breadth trade-off is a central issue in applied work on language generation as well, where it arises in the balance between hallucination, when models generate invalid utterances, and mode collapse, when models only generate from a very restricted set of feasible outputs. Despite its importance, this trade-off has been challenging to study quantitatively.In this work we develop ways of quantifying this trade-off, by formalizing the notion of breadth through measures of density. Roughly speaking, the density of one language L in another language L' is the limiting fraction of strings from L among the strings of L', where we take the limit over longer and longer finite prefixes of L'. Existing algorithms for language generation in the limit produce output sets that can have zero density in the true language K, in this asymptotic sense, and this represents an important failure of breadth that might seem necessary in any solution to the problem. We show here that such a failure is not in fact necessary: we provide an algorithm for language generation in the limit whose outputs have strictly positive density in the true language K. We also study the internal representations built by algorithms for this problem — the sequence of hypothesized candidate languages they iterate through as they perform generation — showing a precise sense in which the strongest form of breadth achievable is one that may need to \"oscillate\" indefinitely between hypothesized representations of high density and low density. Our analysis introduces a novel topology on language families, with notions of convergence and limit points in this topology playing a key role in the analysis.",
    "title_zh": "语言生成的密度度量",
    "abstract_zh": "大型语言模型（LLMs）的近期成功，引发了对语言生成特性的一系列理论研究。最近的一项研究提出了一种抽象视角——称为“极限下的语言生成”（language generation in the limit）——将语言生成视为一个对抗者与算法之间的博弈：对抗者从一个未知语言K中生成字符串，而该语言K仅属于一个可数的候选语言集合；算法在观察到有限数量的这些字符串后，必须生成此前未见过的、来自语言K的新字符串。这一形式化框架凸显了一个关键矛盾：有效性（algorithm should only produce strings that come from the language）与广度（algorithm should be able to generate \"many\" strings from the language）之间的权衡。这种有效性-广度权衡在语言生成的实际应用中同样至关重要，它体现为模型生成无效语句（即“幻觉”hallucination）与仅在极有限的可行输出模式中生成（即“模式坍缩”mode collapse）之间的平衡难题。尽管这一权衡极为重要，但其定量研究一直颇具挑战。\n\n在本研究中，我们通过引入密度（density）的度量来量化这一权衡。粗略地说，语言L在语言L'中的密度，是指在L'的字符串中，属于L的字符串所占的极限比例，其中极限是通过对L'的越来越长的有限前缀取的。现有针对极限语言生成的算法所生成的输出集合，在渐近意义上可能在真实语言K中的密度为零，这代表了广度上的一个严重缺陷，似乎在该问题的任何解决方案中都不可避免。然而，本文表明，这种缺陷实际上并非不可避免：我们提出了一种极限语言生成算法，其生成的输出在真实语言K中具有严格正密度。此外，我们还研究了此类算法内部构建的表示结构——即算法在生成过程中迭代遍历的一系列假设候选语言——并揭示出：所能达到的最强形式的广度，可能需要在高密度与低密度的假设表示之间无限“振荡”。我们的分析引入了一种语言族上的新颖拓扑结构，其中收敛性与极限点的概念在分析中起到了核心作用。"
  },
  {
    "date": "2026-2-11",
    "title": "Flexible NTT Accelerator Design Framework for Scalable Lattice-Based Cryptosystems",
    "authors": "Yiqiang Zhao, Yanhui Song, Xintong Song, Qizhi Zhang, Yao Li, Jiaji He",
    "publish": "2025 Asian Hardware Oriented Security and Trust Symposium (AsianHOST)",
    "url": "https://doi.org/10.1109/asianhost68425.2025.11370386",
    "source": "IEEE",
    "abstract": "The Number Theoretic Transform (NTT) is a widely adopted technique for accelerating polynomial multiplication in lattice-based cryptographic (LBC) systems, and it often constitutes the primary computational bottleneck. Area-time product (ATP) and scalability are two critical metrics for evaluating accelerator designs. Different cryptographic backgrounds have different security parameters, and the diverse application platforms lead to different cost-performance tradeoffs and hardware constraints. We propose a flexible NTT accelerator design framework for LBC to meet the demand for performance and scalability, supporting various polynomial degrees, moduli, radices, and parallelism. Our hardware implementations show excellent ATP efficiency, with our interconnect achieving up to $6.7 \\times$ better LUT-ATP than other in-place designs under the same configuration. In-place computation demands complex memory access patterns, making the design for varying radices and parallelism tough. We propose an efficient, conflict-free memory mapping scheme that offers scalability for different configurations. Compared to other in-place architectures, our approach significantly reduces interconnect complexity. On average, the accelerators generated by our proposed framework are 65.1% more area-time efficient. Up to 34.9% area-time reduction over the state-of-the-art scalable NTT accelerator can be achieved for the same security parameters.",
    "title_zh": "可扩展格密码系统的灵活NTT加速器设计框架",
    "abstract_zh": "数论变换（NTT）是加速基于格的密码系统（LBC）中多项式乘法的广泛采用技术，通常构成主要的计算瓶颈。面积-时间乘积（ATP）和可扩展性是评估加速器设计的两个关键指标。不同的密码学背景具有不同的安全参数，而多样化的应用平台则导致不同的成本-性能权衡和硬件约束。为此，我们提出了一种面向LBC的灵活NTT加速器设计框架，以满足性能与可扩展性的需求，支持多种多项式阶数、模数、基数及并行度。我们的硬件实现展现出优异的ATP效率，所设计的互连结构在相同配置下，LUT-ATP相比其他就地计算设计最高提升达6.7倍。就地计算要求复杂的内存访问模式，使得针对不同基数和并行度的设计极具挑战性。为此，我们提出了一种高效且无冲突的内存映射方案，能够适应不同配置下的可扩展性需求。与现有就地架构相比，我们的方法显著降低了互连复杂度。平均而言，由本框架生成的加速器在面积-时间效率上提高了65.1%。在相同安全参数下，相比当前最先进的可扩展NTT加速器，最高可实现34.9%的面积-时间降低。"
  },
  {
    "date": "2026-2-11",
    "title": "Headsail: One-Year Tape-Out of a 25-mm\n                    <sup>2</sup>\n                    Linux-Capable RISC-V MPSoC",
    "authors": "Matti Käyrä, Thomas Szymkowiak, Mohamed Soliman, Antti Rautakoura, Antti Nurmi, Kari Hepola, Henri Lunnikivi, Toni Jääskeläinen, Abdesattar Kalache, Petteri Toivanen, Roope Keskinen, Andreas Stergiopoulos, Väinö-Waltteri Granat, Arto Oinonen, Joonas Multanen, Pekka Jääskeläinen, Karri Palovuori, Timo D. Hämäläinen, Syed Mohsin Abbas",
    "publish": "IEEE Transactions on Very Large Scale Integration (VLSI) Systems",
    "url": "https://doi.org/10.1109/tvlsi.2026.3653630",
    "source": "IEEE",
    "abstract": "The Internet-of-Things (IoT) devices feature a broad range of power, memory, and performance requirements. Ultralow-power, low-performance controllers are at one end of the spectrum, while high-performance, power-intensive systems-on-chip (SoCs) are at the other. Heterogeneous and specialized multiprocessor SoC (MPSoC) architectures have emerged as the most effective paradigm for delivering high performance and energy efficiency across a wide range of application workloads. This work introduces <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Headsail</i>, an MPSoC application-specific integrated circuit (ASIC) designed by SoC Hub at Tampere University, Finland. <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Headsail</i> features a 512-KiB primary data buffer, 128 KiB of shared on-chip SRAM, seven CPU cores (including four CVA6 64-bit RISC-V processors), a low power-DDR2 (LP-DDR2) memory controller, two unique chip-to-chip (C2C) interfaces, and shared peripherals. <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Headsail</i> has been successfully implemented using a TSMC 22-nm low-power CMOS technology. Testing results show that the samples can support a maximum operating frequency of 1 GHz and achieve a peak performance of 1100 giga operations per second (GOPS), with an implementation area of 25 mm<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> and a power-consumption range of 64 mW–1.5 W.",
    "title_zh": "帆船：一款25平方毫米、具备Linux运行能力的RISC-V多核片上系统（MPSoC）的一年流片成果",
    "abstract_zh": "物联网（IoT）设备具有广泛的功耗、内存和性能需求。在这一需求谱系的一端是超低功耗、低性能的控制器，而在另一端则是高性能、高功耗的片上系统（SoC）。异构且专用的多处理器片上系统（MPSoC）架构已成为在各种应用工作负载下实现高性能与高能效的最有效范式。本文介绍了由芬兰坦佩雷大学SoC中心设计的MPSoC专用集成电路（ASIC）——<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Headsail</i>。<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Headsail</i>配备512 KiB主数据缓冲区、128 KiB共享片上SRAM、七个CPU核心（包括四个64位RISC-V CVA6处理器）、一个低功耗DDR2（LP-DDR2）内存控制器、两个独特的芯片间（C2C）接口以及共享外设。<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Headsail</i>已成功采用台积电22纳米低功耗CMOS工艺实现。测试结果表明，该芯片样品可支持最高1 GHz的工作频率，峰值性能达1100吉操作每秒（GOPS），芯片实现面积为25 mm<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup>，功耗范围为64 mW至1.5 W。"
  }
]