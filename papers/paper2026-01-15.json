[
  {
    "date": "2026-01-15",
    "title": "Are Language Models Models?",
    "authors": "Philip Resnik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10421v1",
    "source": "arXiv",
    "abstract": "Futrell and Mahowald claim LMs \"serve as model systems\", but an assessment at each of Marr's three levels suggests the claim is clearly not true at the implementation level, poorly motivated at the algorithmic-representational level, and problematic at the computational theory level. LMs are good candidates as tools; calling them cognitive models overstates the case and unnecessarily feeds LLM hype."
  },
  {
    "date": "2026-01-15",
    "title": "Cloud parameter estimation for interacting BEC after time-of-flight",
    "authors": "Rasmus Malthe Fiil Andersen, Stine Frederiksen, Laurits Stockholm, Ilja Zebergs, Mick Kristensen, Carrie Weidner, Jan Joachim Arlt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10415v1",
    "source": "arXiv",
    "abstract": "Experiments on Bose-Einstein condensates at finite temperature typically extract the system parameters, such as temperature, atom number, and condensed fraction from time-of-flight images taken after a free expansion time. This paper systematically examines the effect of repulsive interactions between the condensed and thermal atoms in partially condensed clouds on the expansion profile of the thermal cloud. An analytical expression for the expansion can be obtained only if the interactions between the Bose-Einstein condensate and thermal atoms are neglected, resulting in a Bose-enhanced distribution for the thermal component. Here, the deformation of the cloud due to interactions and the effects on estimated parameters are investigated by simulating the expansion using a ballistic approximation. By fitting the simulated expansion profiles with a Bose-enhanced distribution, the errors of using such a fit are estimated, and the results are explained phenomenologically. The simulation was also used as a fitting function for experimental data, showing better agreement of the extracted condensed fraction with the semi-ideal model than results from a Bose-enhanced fit."
  },
  {
    "date": "2026-01-15",
    "title": "Basal-plane anisotropy of field-induced multipolar order in tetragonal CeRh$_2$As$_2$",
    "authors": "Konstantin Semeniuk, Burkhard Schmidt, Christophe Marcenat, Meike Pfeiffer, Albin Demuer, Lipsa Behera, Thierry Klein, Seunghyun Khim, Elena Hassinger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10414v1",
    "source": "arXiv",
    "abstract": "Unconventional superconductivity in Ce-based Kondo-lattice materials emerges almost exclusively in the vicinity of weak dipolar magnetic orders, while higher multipolar orders are only known to occur in a few Pr-based unconventional superconductors and possibly URu$_2$Si$_2$. The multiphase superconductor CeRh$_2$As$_2$ appears to be a notable exception from this trend. Showing clear signatures of magnetism, this tetragonal system is suspected to host a concomitant quadrupolar order, which could be causing the strong enhancement of the ordering temperature when a magnetic field is applied perpendicular to the fourfold ($c$) axis of the lattice. In this work, we show that the field-temperature phase diagram of CeRh$_2$As$_2$ has a remarkable basal-plane anisotropy. This finding supports the scenario of coupled magnetic and multipolar ordering, which may have implications for the pairing mechanism of the superconductivity, and guides the development of the next iteration of theoretical models."
  },
  {
    "date": "2026-01-15",
    "title": "TF3-RO-50M: Training Compact Romanian Language Models from Scratch on Synthetic Moral Microfiction",
    "authors": "Mihai Dan Nadas, Laura Diosan, Andreea Tomescu, Andrei Piscoran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10410v1",
    "source": "arXiv",
    "abstract": "Recent advances in synthetic data generation have shown that compact language models can be trained effectively when the underlying corpus is structurally controlled and linguistically coherent. However, for morphologically rich and computationally under-resourced languages such as Romanian, there is still no openly documented, end-to-end pipeline that unifies tokenizer design, preprocessing, pretraining, compression, evaluation, and large-scale synthetic data generation in a reproducible framework. Building on TF1, a three-million-story English fable dataset, and TF2, which extends TF1 through high-quality Romanian translations, we introduce TF3-RO, a Romanian-centric language modeling pipeline spanning tokenizer training, from-scratch model development, and Romanian-native dataset generation. TF3-RO constructs Romanian-specific BPE and Unigram tokenizers from a linguistically informed corpus to mitigate token inflation induced by Romanian morphology. Using long-sequence packed training, we pretrain a 51.65M-parameter LLaMA-style Transformer entirely from scratch. The model is subsequently optimized through quantization, structured pruning, and logit-based knowledge distillation, yielding a compact 26.45M-parameter student model with tied embeddings and strong deployment characteristics. Using this distilled model, TF3-RO generates three million Romanian-native synthetic fables via a controlled combinatorial prompting framework. Across all stages, the pipeline integrates a comprehensive evaluation suite combining intrinsic metrics, Romanian agreement probes, entity coherence, rule-based grammar checking, and LLM-based assessment. TF3-RO provides a reproducible and linguistically grounded framework for training compact Romanian language models and producing large-scale synthetic narrative corpora."
  },
  {
    "date": "2026-01-15",
    "title": "CS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning",
    "authors": "Yuanjie Zhao, Junnan Qiu, Yue Ding, Jie Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10407v1",
    "source": "arXiv",
    "abstract": "Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to backdoor attacks. Existing attack strategies typically struggle against safety-constrained algorithms (e.g., CQL) due to inefficient random poisoning and the use of easily detectable Out-of-Distribution (OOD) triggers. In this paper, we propose CS-GBA (Critical Sample-based Gradient-guided Backdoor Attack), a novel framework designed to achieve high stealthiness and destructiveness under a strict budget. Leveraging the theoretical insight that samples with high Temporal Difference (TD) errors are pivotal for value function convergence, we introduce an adaptive Critical Sample Selection strategy that concentrates the attack budget on the most influential transitions. To evade OOD detection, we propose a Correlation-Breaking Trigger mechanism that exploits the physical mutual exclusivity of state features (e.g., 95th percentile boundaries) to remain statistically concealed. Furthermore, we replace the conventional label inversion with a Gradient-Guided Action Generation mechanism, which searches for worst-case actions within the data manifold using the victim Q-network's gradient. Empirical results on D4RL benchmarks demonstrate that our method significantly outperforms state-of-the-art baselines, achieving high attack success rates against representative safety-constrained algorithms with a minimal 5% poisoning budget, while maintaining the agent's performance in clean environments."
  },
  {
    "date": "2026-01-15",
    "title": "A comparison of simulation tools for Muon-Induced X-ray Emission (MIXE) in thin films: a study case with lithium batteries",
    "authors": "Maxime Lamotte, Michael W. Heiss, Thomas Prokscha, Alex Amato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10401v1",
    "source": "arXiv",
    "abstract": "We present a comparative study of three Monte Carlo simulation frameworks -SRIM, GEANT4, and PHITS- for modeling the transport, stopping, and atomic cascade of negative muons in micrometer-scale, multilayer systems relevant to Muon-Induced X-ray Emission (MIXE) experiments at the Paul Scherrer Institute (PSI). Using a lithium-ion battery as a benchmark target, simulated implantation profiles are compared with experimental data from the GIANT spectrometer. All three codes reproduce the overall muon depth distributions with good consistency, even across sharp density contrasts. SRIM provides reliable implantation estimates for compact geometries, whereas PHITS reproduces GEANT4 results with comparable accuracy and additionally generates muonic X-ray spectra. These spectra, however, exhibit a systematic energy offset in the K-line transitions of medium- and high-Z elements relative to theoretical and experimental values. Despite this bias, PHITS accurately captures relative intensities and spectral shapes, enabling element-specific line identification. The results demonstrate that SRIM and PHITS constitute practical tools for rapid estimation of muon implantation and stopping profiles, and that PHITS holds strong potential for predictive MIXE spectroscopy once its transition-energy bias is corrected."
  },
  {
    "date": "2026-01-15",
    "title": "Wilson-Fisher renormalization of discrete gravity-capillary wave turbulence in viscous fluids",
    "authors": "José A. Santiago, Mikheil Kharbedia, Basilio J. García, Francisco Monroy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10400v1",
    "source": "arXiv",
    "abstract": "We report an experimental realization of Wilson-Fisher renormalization in driven surface-wave turbulence across Newtonian fluids spanning nearly six decades in Raynolds number. Discrete capillary and gravity turbulence define two universality classes selected by interaction topology: triadic resonances for capillary waves and effectively tetradic scattering for gravity waves. Navier-Stokes viscosity is the relevant perturbation that renormalizes spectral transfer and terminates the cascade. The resulting framework predicts the Kolmogorov cutoff from the balance of nonlinear transfer and viscous damping, and Reynolds scaling of the integrated inertial spectral weight. Laser Doppler Vibrometry quantitatively confirms these renormalized scaling laws, establishing discrete gravity-capillary turbulence as a tunable laboratory for nonequilibrium crossoever criticality."
  },
  {
    "date": "2026-01-15",
    "title": "Long Period Transients (LPTs): a comprehensive review",
    "authors": "Nanda Rea, Natasha Hurley-Walker, Manisha Caleb",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10393v1",
    "source": "arXiv",
    "abstract": "Long Period Transients (LPTs) are a recently identified class of sources characterized by periodic radio bursts lasting seconds to minutes, with flux densities that might reach several tens of Jy. These radio bursts repeat with periodicity from minutes to hours, and they exhibit strong polarization and transient activity periods. To date, about 12 such sources have been identified, which might encompass the same or different physical scenarios. Proposed explanations include binary systems with a white dwarf and a low-mass star companion, slow-spinning magnetars, highly magnetized isolated white dwarfs, and other exotic objects. In a few cases the optical counterpart indeed points toward a white dwarf with a low-mass companion, while in other cases, transient X-ray emission was detected, very common in magnetars. However, despite being able to reproduce partially some of the characteristics of LPTs, all the proposed scenarios find difficulty in explaining the exact physical origin of their bright, highly polarized and periodic radio emission. We review here the state-of-the-art in the observations and interpretation of this puzzling class of radio transients."
  },
  {
    "date": "2026-01-15",
    "title": "INDIC DIALECT: A Multi Task Benchmark to Evaluate and Translate in Indian Language Dialects",
    "authors": "Tarun Sharma, Manikandan Ravikiran, Sourava Kumar Behera, Pramit Bhattacharya, Arnab Bhattacharya, Rohit Saluja",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10388v1",
    "source": "arXiv",
    "abstract": "Recent NLP advances focus primarily on standardized languages, leaving most low-resource dialects under-served especially in Indian scenarios. In India, the issue is particularly important: despite Hindi being the third most spoken language globally (over 600 million speakers), its numerous dialects remain underrepresented. The situation is similar for Odia, which has around 45 million speakers. While some datasets exist which contain standard Hindi and Odia languages, their regional dialects have almost no web presence. We introduce INDIC-DIALECT, a human-curated parallel corpus of 13k sentence pairs spanning 11 dialects and 2 languages: Hindi and Odia. Using this corpus, we construct a multi-task benchmark with three tasks: dialect classification, multiple-choice question (MCQ) answering, and machine translation (MT). Our experiments show that LLMs like GPT-4o and Gemini 2.5 perform poorly on the classification task. While fine-tuned transformer based models pretrained on Indian languages substantially improve performance e.g., improving F1 from 19.6\\% to 89.8\\% on dialect classification. For dialect to language translation, we find that hybrid AI model achieves highest BLEU score of 61.32 compared to the baseline score of 23.36. Interestingly, due to complexity in generating dialect sentences, we observe that for language to dialect translation the ``rule-based followed by AI\" approach achieves best BLEU score of 48.44 compared to the baseline score of 27.59. INDIC-DIALECT thus is a new benchmark for dialect-aware Indic NLP, and we plan to release it as open source to support further work on low-resource Indian dialects."
  },
  {
    "date": "2026-01-15",
    "title": "Does Cognitive Load Affect Human Accuracy in Detecting Voice-Based Deepfakes?",
    "authors": "Marcel Gohsen, Nicola Libera, Johannes Kiesel, Jan Ehlers, Benno Stein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10383v1",
    "source": "arXiv",
    "abstract": "Deepfake technologies are powerful tools that can be misused for malicious purposes such as spreading disinformation on social media. The effectiveness of such malicious applications depends on the ability of deepfakes to deceive their audience. Therefore, researchers have investigated human abilities to detect deepfakes in various studies. However, most of these studies were conducted with participants who focused exclusively on the detection task; hence the studies may not provide a complete picture of human abilities to detect deepfakes under realistic conditions: Social media users are exposed to cognitive load on the platform, which can impair their detection abilities. In this paper, we investigate the influence of cognitive load on human detection abilities of voice-based deepfakes in an empirical study with 30 participants. Our results suggest that low cognitive load does not generally impair detection abilities, and that the simultaneous exposure to a secondary stimulus can actually benefit people in the detection task."
  },
  {
    "date": "2026-01-15",
    "title": "On surgeries from lens space $L(p,1)$ to $L(q,2)$",
    "authors": "Boning Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10377v1",
    "source": "arXiv",
    "abstract": "We mainly use the d-invariant surgery formula established by Wu and Yang \\cite{wu2025surgerieslensspacestype} to study the distance one surgeries along a homologically essential knot between lens spaces of the form $L(p,1)$ and $L(q,2)$ where $p,q$ are odd integers."
  },
  {
    "date": "2026-01-15",
    "title": "Dynamic reinsurance via martingale transport",
    "authors": "Beatrice Acciaio, Brandon Garcia Flores, Antonio Marini, Gudmund Pammer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10375v1",
    "source": "arXiv",
    "abstract": "We formulate a dynamic reinsurance problem in which the insurer seeks to control the terminal distribution of its surplus while minimizing the L2-norm of the ceded risk. Using techniques from martingale optimal transport, we show that, under suitable assumptions, the problem admits a tractable solution analogous to the Bass martingale. We first consider the case where the insurer wants to match a given terminal distribution of the surplus process, and then relax this condition by only requiring certain moment or risk-based constraints."
  },
  {
    "date": "2026-01-15",
    "title": "A two-step inertial method with a new step-size rule for variational inequalities in hilbert spaces",
    "authors": "Jian-Wen Peng, Jun-Jie Luo, Abubakar Adamu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10370v1",
    "source": "arXiv",
    "abstract": "In this paper, a two-step inertial Tseng extragradient method involving self-adaptive and Armijo-like step sizes is introduced for solving variational inequalities with a quasimonotone cost function in the setting of a real Hilbert space. Weak convergence of the sequence generated by the proposed algorithm is proved without assuming the Lipschitz condition. An interesting feature of the proposed algorithm is its ability to select the better step size between the self-adaptive and Armijo-like options at each iteration step. Moreover, removing the requirement for the Lipschitz condition on the cost function broadens the applicability of the proposed method. Finally, the algorithm accelerates and complements several existing iterative algorithms for solving variational inequalities in Hilbert spaces."
  },
  {
    "date": "2026-01-15",
    "title": "Self-supervised restoration of singing voice degraded by pitch shifting using shallow diffusion",
    "authors": "Yunyi Liu, Taketo Akama",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10345v1",
    "source": "arXiv",
    "abstract": "Pitch shifting has been an essential feature in singing voice production. However, conventional signal processing approaches exhibit well known trade offs such as formant shifts and robotic coloration that becomes more severe at larger transposition jumps. This paper targets high quality pitch shifting for singing by reframing it as a restoration problem: given an audio track that has been pitch shifted (and thus contaminated by artifacts), we recover a natural sounding performance while preserving its melody and timing. Specifically, we use a lightweight, mel space diffusion model driven by frame level acoustic features such as f0, volume, and content features. We construct training pairs in a self supervised manner by applying pitch shifts and reversing them to simulate realistic artifacts while retaining ground truth. On a curated singing set, the proposed approach substantially reduces pitch shift artifacts compared to representative classical baselines, as measured by both statistical metrics and pairwise acoustic measures. The results suggest that restoration based pitch shifting could be a viable approach towards artifact resistant transposition in vocal production workflows."
  },
  {
    "date": "2026-01-15",
    "title": "OctoBench: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding",
    "authors": "Deming Ding, Shichun Liu, Enhui Yang, Jiahang Lin, Ziying Chen, Shihan Dou, Honglin Guo, Weiyu Cheng, Pengyu Zhao, Chengjun Xiao, Qunhong Zeng, Qi Zhang, Xuanjing Huang, Qidi Xu, Tao Gui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10343v1",
    "source": "arXiv",
    "abstract": "Modern coding scaffolds turn LLMs into capable software agents, but their ability to follow scaffold-specified instructions remains under-examined, especially when constraints are heterogeneous and persist across interactions. To fill this gap, we introduce OctoBench, which benchmarks scaffold-aware instruction following in repository-grounded agentic coding. OctoBench includes 34 environments and 217 tasks instantiated under three scaffold types, and is paired with 7,098 objective checklist items. To disentangle solving the task from following the rules, we provide an automated observation-and-scoring toolkit that captures full trajectories and performs fine-grained checks. Experiments on eight representative models reveal a systematic gap between task-solving and scaffold-aware compliance, underscoring the need for training and evaluation that explicitly targets heterogeneous instruction following. We release the benchmark to support reproducible benchmarking and to accelerate the development of more scaffold-aware coding agents."
  },
  {
    "date": "2026-01-15",
    "title": "CHORAL: Traversal-Aware Planning for Safe and Efficient Heterogeneous Multi-Robot Routing",
    "authors": "David Morilla-Cabello, Eduardo Montijano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10340v1",
    "source": "arXiv",
    "abstract": "Monitoring large, unknown, and complex environments with autonomous robots poses significant navigation challenges, where deploying teams of heterogeneous robots with complementary capabilities can substantially improve both mission performance and feasibility. However, effectively modeling how different robotic platforms interact with the environment requires rich, semantic scene understanding. Despite this, existing approaches often assume homogeneous robot teams or focus on discrete task compatibility rather than continuous routing. Consequently, scene understanding is not fully integrated into routing decisions, limiting their ability to adapt to the environment and to leverage each robot's strengths. In this paper, we propose an integrated semantic-aware framework for coordinating heterogeneous robots. Starting from a reconnaissance flight, we build a metric-semantic map using open-vocabulary vision models and use it to identify regions requiring closer inspection and capability-aware paths for each platform to reach them. These are then incorporated into a heterogeneous vehicle routing formulation that jointly assigns inspection tasks and computes robot trajectories. Experiments in simulation and in a real inspection mission with three robotic platforms demonstrate the effectiveness of our approach in planning safer and more efficient routes by explicitly accounting for each platform's navigation capabilities. We release our framework, CHORAL, as open source to support reproducibility and deployment of diverse robot teams."
  },
  {
    "date": "2026-01-15",
    "title": "Triggered urn models for frequently asked questions (FAQ)",
    "authors": "Irene Crimaldi, Andrea Ghiglietti, Leen Hatem, Hosam Mahmoud",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10337v1",
    "source": "arXiv",
    "abstract": "We investigate a nonclassic urn model with triggers that increase the number of colors. The scheme has emerged as a model for web services that set up frequently asked questions (FAQ). We present a thorough asymptotic analysis of the FAQ urn scheme in generality that covers a large number of special cases, such as Simon urn. For instance, we consider time dependent triggering probabilities. We identify regularity conditions on these probabilities that classify the schemes into those where the number of colors in the urn remains almost surely finite or increases to infinity and conditions that tell us whether all the existing colors are observed infinitely often or not. We determine the rank curve, too. In view of the broad generality of the trigger probabilities, a spectrum of limit distributions appears, from central limit theorems to Poisson approximation, to power-laws, revealing connections to Heap's exponent and Zipf's law. A combinatorial approach to the Simon urn is presented to indicate the possibility of such exact analysis, which is important for short-term predictions. Extensive simulations on real datasets (from Amazon sales) as well as computer-generated data clearly indicate that the asymptotic and exact theory developed agrees with practice."
  },
  {
    "date": "2026-01-15",
    "title": "Radiation Shielding Performance of Different Concrete Materials: A Systematic Review",
    "authors": "Christiana Subaar, Ziem Samuel Aanoneda, Sylivia Boateng, Emmanuella Konadu Amaniampong, Philimon Adjei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10336v1",
    "source": "arXiv",
    "abstract": "Background: Concrete is one of the most-used material today in nuclear, medical, and industrial applications for radiation shielding due to its economic advantages and availability together with its structural performance. However, differences in the use of aggregates, density, and other additives affect radiation attenuation efficiency. It is therefore necessary to understand and compare shielding properties of various concrete formulations for the optimization of safety and performance in radiation-prone environments. Methods: Using Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines, a literature search was performed across PubMed, Scopus, ScienceDirect, and Google Scholar. 17 peer-reviewed studies published between 2010 and 2025 were analysed systematically. Data was extracted based on material composition, density, radiation type, energy range, attenuation coefficients, and shielding efficiency. The obtained results were compared to find the trend in performance and optimization of the considered materials. Conclusion: Radiation shielding efficiency of concrete is dependent on its density, microstructural characteristics and type of aggregate. For superior performance in a mixed radiation field, Heavy and boron-rich additives can be added. Newly developed UHPCs and nano-engineered concretes are lightweight, durable, and environmentally friendly options for shielding materials compared to traditional ones. Further studies are needed to focus on the standardization of test methods, validation of long-term stability, and coupling computational modelling with experimental data in order to guide material design for applications featuring enhanced radiation shielding."
  },
  {
    "date": "2026-01-15",
    "title": "Low-Complexity Blind Estimator of SNR and MSE for mmWave Multi-Antenna Communications",
    "authors": "Hanyoung Park, Ji-Woong Choi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10331v1",
    "source": "arXiv",
    "abstract": "To enhance the robustness and resilience of wireless communication and meet performance requirements, various environment-reflecting metrics, such as the signal-to-noise ratio (SNR), are utilized as the system parameter. To obtain these metrics, training signals such as pilot sequences are generally employed. However, the rapid fluctuations of the millimeter-wave (mmWave) propagation channel often degrade the accuracy of such estimations. To address this challenge, various blind estimators that operate without pilot have been considered as potential solutions. However, these algorithms often involve a training phase for machine learning or a large number of iterations, which implies prohibitive computational complexity, making them difficult to employ for real-time services and the system less resilient to dynamic environment variation. In this paper, we propose blind estimators for average noise power, signal power, SNR, and mean-square error (MSE) that do not require knowledge of the ground-truth signal or involve high computational complexity. The proposed algorithm leverages the inherent sparsity of mmWave channel in beamspace domain, which makes the signal and noise power components more distinguishable."
  },
  {
    "date": "2026-01-15",
    "title": "Addition to the dynamic Stark shift of the coherent population trapping resonance",
    "authors": "Gavriil Voloshin, Konstantin Barantsev, Andrey Litvinov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10319v1",
    "source": "arXiv",
    "abstract": "This paper presents a theoretical study of the light-induced shift of the coherent population trapping resonance. An analytical model is proposed that describes the interaction of two radiation components with an atomic system using a $Λ$ scheme and takes into account an additional level of excited state. Both weak and strong coupling regimes with off-resonant transitions are considered. It is shown that, in addition to the conventional dynamic Stark shift, an extra shift arises due to the distortion of the resonance line shape when bichromatic laser radiation interacts with off-resonant atomic transitions. An analytical expression for this additional shift is derived in the weak-coupling limit, and its significant impact on the resonance shape and sensitivity to the intensities of the laser field components is demonstrated. It is found that under strong coupling conditions, the additional shift can deviate substantially from a linear dependence on light intensity, suggesting new opportunities for controlling light shifts in precision atomic devices such as quantum frequency standards."
  },
  {
    "date": "2026-01-15",
    "title": "Extracting intrinsic alignments in the Dark Energy Survey's year 1 data, using the self-calibration method and LSST-DESC tools",
    "authors": "Eske M. Pedersen, Leonel Medina-Varela, Emily Phillips Longley, Mustapha Ishak, Joe Zuntz, Chihway Chang, C. Danielle Leonard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10314v1",
    "source": "arXiv",
    "abstract": "We present the implementation of a Self-Calibration of Intrinsic Alignments of galaxies as an extension to the Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST) Dark Energy Science Collaboration (DESC)'s weak lensing 3x2pt pipeline (TXPipe). As a demonstration, we have run this pipeline on the Dark Energy Survey (DES) year one data set. We find indications of a non-zero intrinsic alignment signal in the higher redshift bins, while in the lower bins our results look more uncertain. We believe this is caused by known issues with the individual galaxies photo-z estimation. This effect is particularly harmful for the self-calibration method, since it has high requirements for reliable estimation of the photo-$z$s, and the need for individual galaxy point estimates and tomographic binning to match. We show how different methods of recreating the redshift probability distribution can affect the detection of intrinsic alignment."
  },
  {
    "date": "2026-01-15",
    "title": "Hierarchical Refinement of Universal Multimodal Attacks on Vision-Language Models",
    "authors": "Peng-Fei Zhang, Zi Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10313v1",
    "source": "arXiv",
    "abstract": "Existing adversarial attacks for VLP models are mostly sample-specific, resulting in substantial computational overhead when scaled to large datasets or new scenarios. To overcome this limitation, we propose Hierarchical Refinement Attack (HRA), a multimodal universal attack framework for VLP models. HRA refines universal adversarial perturbations (UAPs) at both the sample level and the optimization level. For the image modality, we disentangle adversarial examples into clean images and perturbations, allowing each component to be handled independently for more effective disruption of cross-modal alignment. We further introduce a ScMix augmentation strategy that diversifies visual contexts and strengthens both global and local utility of UAPs, thereby reducing reliance on spurious features. In addition, we refine the optimization path by leveraging a temporal hierarchy of historical and estimated future gradients to avoid local minima and stabilize universal perturbation learning. For the text modality, HRA identifies globally influential words by combining intra-sentence and inter-sentence importance measures, and subsequently utilizes these words as universal text perturbations. Extensive experiments across various downstream tasks, VLP models, and datasets demonstrate the superiority of the proposed universal multimodal attacks."
  },
  {
    "date": "2026-01-15",
    "title": "Deformations of Chow groups via cyclic homology",
    "authors": "Sen Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10309v1",
    "source": "arXiv",
    "abstract": "Let $X$ be a smooth projective variety over an arbitrary field $k$ of characteristic zero. We explore infinitesimal deformations of the Chow group $CH^{p}(X)$ via its formal completion $\\widehat{CH}^{p}$, a functor defined on the category of local augmented Artinian $k$-algebras. Under a natural vanishing condition on Hodge cohomology groups, for certain augmented graded Artinian $k$-algebras $A$ with the maximal ideal $m_{A}$, we prove that \\[ \\widehat{CH}^{p}(A) \\cong H^{p}(X, Ω^{p-1}_{X/ k})\\otimes_{k}m_{A}. \\]This extends earlier results of Bloch and others from the case where $k$ is algebraic over $\\mathbb{Q}$ to arbitrary fields of characteristic zero,and gives a partial affirmative answer to a general question linking the pro-representability of Chow groups to a specific set of Hodge-theoretic vanishing conditions."
  },
  {
    "date": "2026-01-15",
    "title": "Effects of spontaneous Lorentz Symmetry breaking on Letelier-AdS charged black boles within Kalb-Ramond gravity",
    "authors": "Faizuddin Ahmed, Ahmad Al-Badawi, İzzet Sakallı",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10303v1",
    "source": "arXiv",
    "abstract": "In this study, we investigate the geodesic motion of massless particles -- specifically photons -- in the spacetime of a charged anti-de Sitter (AdS) black hole (BH) surrounded by a cloud of strings (CoS) within the framework of Kalb-Ramond (KR) gravity. We analyze the effective potential that governs photon trajectories, explore the properties and location of the photon sphere (PS), and examine the effective radial force acting on photons. The resulting BH shadow is also studied, highlighting the roles of both the CoS parameter $α$ and the KR field parameter $\\ell$ in shaping its geometry. We constrain these parameters using observational data from M87* and Sgr A* obtained by the Event Horizon Telescope (EHT). Furthermore, we extend our investigation to the motion of neutral test particles in the same gravitational background. By examining the impact of the CoS and KR field, we show how these additional fields modify the dynamics relative to standard charged BH scenarios. Finally, we study the fundamental frequencies associated with quasiperiodic oscillations (QPOs) of test particles, demonstrating how these frequencies are affected by the presence of the CoS and KR field. Our results reveal the rich structure of AdS-BH spacetimes influenced by string clouds and antisymmetric tensor fields, with potential observational consequences in gravitational wave and BH imaging astronomy."
  },
  {
    "date": "2026-01-15",
    "title": "Complex scalar relativistic field as a probability amplitude",
    "authors": "Yu. M. Poluektov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10302v1",
    "source": "arXiv",
    "abstract": "A relativistic equation for a neutral complex field as a probability amplitude is proposed. The continuity equation for the probability density is obtained. It is shown that there are two types of excitations of this field, which describe particles with positive energy and different dispersion laws. Based on the Lagrangian formalism, conservation laws are obtained. The transition to secondary quantization is considered."
  },
  {
    "date": "2026-01-15",
    "title": "On refinements of two-term Machin-like formulas",
    "authors": "Bakir Farhi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10300v1",
    "source": "arXiv",
    "abstract": "We develop a refinement process for two-term Machin-like formulas: $a_0 \\arctan{u_0} + a_1 \\arctan{u_1} = \\fracπ{4}$ (where $a_0 , a_1 \\in \\mathbb{Z}$, $u_0 , u_1 \\in \\mathbb{Q}_+^*$, $u_0 > u_1$) by exploiting the continued fraction expansion of the ratio $α:= \\frac{\\arctan{u_0}}{\\arctan{u_1}}$. This construction yields a sequence of derived two-term Machin-like formulas: $a_{- n} \\arctan{u_n} + a_{- n + 1} \\arctan{u_{n + 1}} = \\fracπ{4}$ ($n \\in \\mathbb{N}$) with positive rational arguments $u_n$ decreasing to zero and corresponding integer coefficients $a_{- n}$. We derive closed forms and estimates for $a_{-n}$ and $u_n$ in terms of the convergents of $α$ and prove that the associated rational sequence $(a_{- n} u_n + a_{- n + 1} u_{n + 1})_n$ converges to $π/4$ with geometric decay. The method is illustrated using Euler's two-term Machin-like formula : $\\arctan(1/2) + \\arctan(1/3) = π/4$."
  },
  {
    "date": "2026-01-15",
    "title": "Global minimizers for a two-sided biharmonic Alt-Caffarelli problem",
    "authors": "Hans-Christoph Grunau, Marius Müller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10297v1",
    "source": "arXiv",
    "abstract": "We study global minimizers of biharmonic analogues of the Alt-Caffarelli functional. It turns out that half-space solutions are global minimizers for the two-sided Alt-Caffarelli functional, but not in the one-sided case. In addition, we identify a further class of global minimizers, all of which have constant Laplacian. Recent work by J. Lamboley and M. Nahon reduces potential global minimizers in dimension two to four possible categories. Our work shows that three of these categories persist in any dimension and are in fact global minimizers. Moreover, we show that minimizers of the two-sided biharmonic Alt-Caffarelli problem do in general not satisfy a partial differential equation, not even with a signed measure as right-hand-side. This is in sharp contrast to the corresponding one-sided problem."
  },
  {
    "date": "2026-01-15",
    "title": "Two dimensional covering systems and possible prime producing $a^m-b^n$",
    "authors": "Andrew Granville, Francesco Pappalardi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10296v1",
    "source": "arXiv",
    "abstract": "We exhibit a new application of two dimensional covering systems, examples of integer pairs $a,b$ for which $a^m-b^n$ has a prime divisor from some given finite set of primes, for every pair of integers $m,n\\geq 0$. This leads us to conjecture what are the only possible obstructions to $|a^m-b^n|$ taking on infinitely many distinct prime values."
  },
  {
    "date": "2026-01-15",
    "title": "Design, Fabrication and Testing of a D-Shaped High Temperature Superconducting Magnet",
    "authors": "Upendra Prasad, Mahesh Ghate, Piyush Raj, Deven Kanabar, Pankaj Varmora, Swati Roy, Arun Panchal, Dhaval Bhavsar, Anees Bano, Nitish Kumar, Bhadresh Parghi, Akhilesh Yadav, Mohd. Umer, Vijay Vasava, Raton Mandal, Rajkumar Ahirwar, Megha Thaker",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10295v1",
    "source": "arXiv",
    "abstract": "High-temperature technical superconductors are potential candidates for compact and high-field tokamak magnets. The demand for higher fusion power can be met with an on-axis high magnetic field due to toroidal magnets. An R&D activity has been initiated at the Institute for Plasma Research, India, to develop a compact D-shaped superconducting magnet utilizing REBCO high-temperature superconducting tapes. Under this initiative, a toroidal configuration with a major radius of 0.42 m, consisting of eight D-shaped, four poloidal field, and a central solenoid high-temperature superconducting magnets producing an on-axis toroidal magnetic field of 0.23 T has been conceptualized. The fabrication feasibility of a D-shaped coil for this toroidal configuration also envisaged using stacked high-temperature superconducting cable. In this paper, we report the design of a compact D-shaped coil, the fabrication of a long length HTS cable, a winding pack, and its integration with a cryogenic casing and vacuum enclosure. The winding pack terminations, joints, its interfacing with the power supply, and performance testing are also reported in this paper."
  },
  {
    "date": "2026-01-15",
    "title": "Updated electrical design of the Diagnostic Neutral Beam Injector in RFX-mod2",
    "authors": "Marco Barbisan, Bruno Laterza, Luca Cinnirella, Lionello Marrelli, Federico Molon, Simone Peruzzo, Enrico Zampiva",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10293v1",
    "source": "arXiv",
    "abstract": "The Diagnostic Neutral Beam Injector of the RFX-mod2 experiment (Consorzio RFX, Padova) is expected to provide novel and significant information about the Reversed Field Pinch confinement of fusion plasmas. The injection of the hydrogen beam in the plasma will allow Charge Exchange Recombination Spectroscopy (CXRS) and Motional Stark Effect diagnostics (MSE) to measure several quantities: ion speed, ion temperature, impurity content, intensity and pitch of the magnetic field. The DNBI is of particular importance for allowing the determination of these quantities at the core of the plasma. The present DNBI, built by the Budker Institute of Plasma Physics, features an arc discharge H+ source, coupled to a 4-grid 50 keV acceleration system. The 50 ms, 5 A ion beam is neutralized by charge exchange by means of a gas target; residual ions are then deflected by a magnetic field before injection in the torus chamber. The beam can be modulated at maximum 250 Hz. The DNBI will undergo extraordinary maintenance and a structural upgrade to improve its reliability and safety. This contribution presents the latest upgrades of the electrical plants and of the control system of the DNBI."
  },
  {
    "date": "2026-01-15",
    "title": "Atelier à la conférence IHM 2025 : RA Permanente",
    "authors": "Maxime Cauz, Thibaut Septon, Elise Hallaert, Theo Leclercq, Bruno Dumas, Charles Bailly, Clement Tyminski, Matias Peraza, Sophie Lepreux, Emmanuel Dubois",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10291v1",
    "source": "arXiv",
    "abstract": "As we move towards more ubiquitous computing, the concept of pervasive augmented reality (PAR) could lead to a major evolution in the relationship between humans, computing and the world. The experience of a continuously augmented world can have both benefits and undesirable consequences for users' lives, and raises many questions in multiple areas. In this workshop, we wanted to bring together all IHM'25 conference participants who are concerned or enthusiastic about discussing this topic. The aim was to draw on collective intelligence to identify the interdisciplinary challenges that remain to be resolved in order to enable the implementation of these technologies in everyday life, but also to define the necessary safeguards. Is PAR too techno-enthusiastic? All of these elements were grouped into categories to define a set of future major areas of research around permanent augmented reality. This document is in French as the conference is a French-speaking international conference."
  },
  {
    "date": "2026-01-15",
    "title": "High-Contrast Transmission Resonances for the Lamé System",
    "authors": "Long Li, Mourad Sini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10290v1",
    "source": "arXiv",
    "abstract": "We consider the Lamé transmission problem in $\\mathbb{R}^3$ with a bounded isotropic elastic inclusion in a high-contrast setting, where the interior-to-exterior Lamé moduli and densities scale like $1/τ$ as $τ\\to0$. We study the scattering resonances of the associated self-adjoint Hamiltonian, defined as the poles of the meromorphic continuation of its resolvent. We obtain a sharp asymptotic description of resonances near the real axis as $τ\\to0$. Near each nonzero Neumann eigenvalue of the interior Lamé operator there is a cluster of resonances lying just below it in the complex plane; in this wavelength-scale regime the imaginary parts are of order $τ$ with non-vanishing leading coefficients. In addition, near zero (a subwavelength regime), we identify resonances with real parts of order $\\sqrtτ$ and prove a lifetime dichotomy: their imaginary parts are of order $τ$ generically, but of order $τ^2$ for an explicit admissible set $\\mathcal E$. This yields a classification of long-lived elastic resonances in the high-contrast limit. We also establish resolvent asymptotics for both fixed-size resonators and microresonators. We derive explicit expansions with a finite-rank leading term and quantitative remainder bounds, valid near both wavelength-scale and subwavelength resonances. For microresonators, at the wavelength scale the dominant contribution is an anisotropic elastic point scatterer. Near the zero eigenvalue, the leading-order behaviour is of monopole or dipole type, and we give a rigorous criterion distinguishing the two cases."
  },
  {
    "date": "2026-01-15",
    "title": "Cycle dependence of helioseismic oscillations above the acoustic cut-off frequency",
    "authors": "Dmitrii Kolotkov, Anne-Marie Broomhall, Laura Jade Millson, Sergey Belov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10283v1",
    "source": "arXiv",
    "abstract": "Helioseismic and recent asteroseismic observations reveal fine structure in the power spectrum with alternating peaks and troughs above the acoustic cut-off frequency. This structure is interpreted as the interference patterns of high-frequency acoustic waves excited in the solar interior and propagating into the atmosphere, known as pseudomodes. Pseudomodes exhibit clear solar-cycle variability, with frequency shifts that occur predominantly in anti-phase with the activity cycle, although the underlying mechanism remains uncertain. This work investigates how the subsurface excitation source location and the photospheric acoustic cut-off frequency influence the formation, frequency distribution, and solar-cycle variability of pseudomodes. We employ an analytical Klein-Gordon subsurface cavity model, which is shown to act as an effective Fabry-Pérot interferometer for high-frequency waves that experience constructive and destructive interference between the source location and the lower turning point. We derive an effective dispersion relation isolating the effects of the source location and photospheric cut-off on the pseudomode frequency. The model reproduces the observed peak-trough pseudomode spectrum for reasonable parameter values constrained by Bayesian MCMC best-fitting to GONG observations. We also find that solar-cycle-associated 11-year modulations of the source location result in anti-phase pseudomode frequency shifts, whereas similar cyclic variations in the cut-off frequency produce harmonic-dependent behaviour, yielding both in-phase and anti-phase shifts. As the acoustic cut-off and mode excitation relate to stratification and flows in the solar interior, the results highlight pseudomodes as a powerful diagnostic tool for changes in subsurface solar and stellar structure through the solar cycle."
  },
  {
    "date": "2026-01-15",
    "title": "Optimisation of the lowest Robin eigenvalue in exterior domains of the hyperbolic plane",
    "authors": "Antonio Celentano, David Krejcirik, Vladimir Lotoreichik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10280v1",
    "source": "arXiv",
    "abstract": "We consider the Robin Laplacian in the exterior of a bounded simply-connected Lipschitz domain in the hyperbolic plane. We show that the essential spectrum of this operator is $[\\frac14,\\infty)$ and that, under convexity assumption on the domain, there exist discrete eigenvalues below $\\frac14$ if, and only if, the Robin parameter is below a non-positive critical constant, which depends on the shape of the domain. As the main result, we prove that the lowest Robin eigenvalue for the exterior of a bounded geodesically convex domain $Ω$ in the hyperbolic plane does not exceed such an eigenvalue for the exterior of the geodesic disk, whose geodesic curvature of the boundary is not smaller than the averaged geodesic curvature of the boundary of $Ω$. This result implies as a consequence that under fixed area or fixed perimeter constraints the exterior of the geodesic disk maximises the lowest Robin eigenvalue among exteriors of bounded geodesically convex domains. Moreover, we obtain under the same geometric constraints a reverse inequality between the critical constants."
  },
  {
    "date": "2026-01-15",
    "title": "Selecting and Testing Asset Pricing Models: A Stepwise Approach",
    "authors": "Guanhao Feng, Wei Lan, Hansheng Wang, Jun Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10279v1",
    "source": "arXiv",
    "abstract": "The asset pricing literature emphasizes factor models that minimize pricing errors but overlooks unselected candidate factors that could enhance the performance of test assets. This paper proposes a framework for factor model selection and testing by (i) selecting the optimal model that spans the joint efficient frontier of test assets and all candidate factors, and (ii) testing pricing performance on both test assets and unselected candidate factors. Our framework updates a baseline model (e.g., CAPM) sequentially by adding or removing factors based on asset pricing tests. Ensuring model selection consistency, our framework utilizes the asset pricing duality: minimizing cross-sectionally unexplained pricing errors aligns with maximizing the Sharpe ratio of the selected factor model. Empirical evidence shows that workhorse factor models fail asset pricing tests, whereas our proposed 8-factor model is not rejected and exhibits robust out-of-sample performance."
  },
  {
    "date": "2026-01-15",
    "title": "Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers",
    "authors": "Emre Ozbas, Melih Bastopcu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10274v1",
    "source": "arXiv",
    "abstract": "We consider a single large language model (LLM) server that serves a heterogeneous stream of queries belonging to $N$ distinct task types. Queries arrive according to a Poisson process, and each type occurs with a known prior probability. For each task type, the server allocates a fixed number of internal thinking tokens, which determines the computational effort devoted to that query. The token allocation induces an accuracy-latency trade-off: the service time follows an approximately affine function of the allocated tokens, while the probability of a correct response exhibits diminishing returns. Under a first-in, first-out (FIFO) service discipline, the system operates as an $M/G/1$ queue, and the mean system time depends on the first and second moments of the resulting service-time distribution. We formulate a constrained optimization problem that maximizes a weighted average accuracy objective penalized by the mean system time, subject to architectural token-budget constraints and queue-stability conditions. The objective function is shown to be strictly concave over the stability region, which ensures existence and uniqueness of the optimal token allocation. The first-order optimality conditions yield a coupled projected fixed-point characterization of the optimum, together with an iterative solution and an explicit sufficient condition for contraction. Moreover, a projected gradient method with a computable global step-size bound is developed to guarantee convergence beyond the contractive regime. Finally, integer-valued token allocations are attained via rounding of the continuous solution, and the resulting performance loss is evaluated in simulation results."
  },
  {
    "date": "2026-01-15",
    "title": "Nonadiabatic couplings drive ultrafast, mode-selective intramolecular vibrational energy redistribution in flavins",
    "authors": "Daniel Timmer, Krishan Kumar, Jan P. Götze, Peter Saalfrank, Antonietta De Sio, Christoph Lienau",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10273v1",
    "source": "arXiv",
    "abstract": "Flavins are the chromophores in several blue-light-sensitive photoreceptor proteins and act as redox cofactors in many enzymes relevant for biological processes. Despite their biological relevance and numerous, detailed optical investigations of their photophysical properties, the ultrafast nonequilibrium dynamics of their elementary optical excitations are not yet fully known. Here, we use ultrafast coherent vibrational spectroscopy with 10-fs time resolution in the 450-nm spectral range to study their excited state coherent vibrational dynamics. We observe that coherent wavepacket motion along high-frequency C-C stretching modes with ~ 20-fs period is rapidly damped on a 20-fs timescale. In contrast, coherent motion along several low-frequency modes persists much longer. We attribute this to a mode-selective intramolecular vibrational energy redistribution driven by nonadiabatic couplings between the optical bright state and a close-lying dark electronic state, in accordance with model calculations. Our results may be of relevance for the formation of long-lived radical pair states in magnetic-field sensitive proteins."
  },
  {
    "date": "2026-01-15",
    "title": "Early Fault Detection on CMAPSS with Unsupervised LSTM Autoencoders",
    "authors": "P. Sánchez, K. Reyes, B. Radu, E. Fernández",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10269v1",
    "source": "arXiv",
    "abstract": "This paper introduces an unsupervised health-monitoring framework for turbofan engines that does not require run-to-failure labels. First, operating-condition effects in NASA CMAPSS sensor streams are removed via regression-based normalisation; then a Long Short-Term Memory (LSTM) autoencoder is trained only on the healthy portion of each trajectory. Persistent reconstruction error, estimated using an adaptive data-driven threshold, triggers real-time alerts without hand-tuned rules. Benchmark results show high recall and low false-alarm rates across multiple operating regimes, demonstrating that the method can be deployed quickly, scale to diverse fleets, and serve as a complementary early-warning layer to Remaining Useful Life models."
  },
  {
    "date": "2026-01-15",
    "title": "Transmission Mask Analysis for Range-Doppler Sensing in Half-Duplex ISAC",
    "authors": "Dikai Liu, Yifeng Xiong, Marco Lops, Fan Liu, Jianhua Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10259v1",
    "source": "arXiv",
    "abstract": "In this paper, we analyze the periodic transmission masks for MASked Modulation (MASM) in half-duplex integrated sensing and communication (ISAC), and derive their closed-form expected range-Doppler response $\\mathbb{E}\\{r(k,l,ν)\\}$. We show that range sidelobes ($k\\neq l$) are Doppler-invariant, extending the range-sidelobe optimality to the 2-D setting. For the range mainlobe ($k=l$), periodic masking yields sparse Doppler sidelobes: Cyclic difference sets (CDSs) (in particular Singer CDSs) are minimax-optimal in a moderately dynamic regime, while in a highly dynamic regime the Doppler-sidelobe energy is a concave function of the mask autocorrelation, revealing an inevitable tradeoff with mainlobe fluctuation."
  },
  {
    "date": "2026-01-15",
    "title": "Evolving with AI: A Longitudinal Analysis of Developer Logs",
    "authors": "Agnia Sergeyuk, Eric Huang, Dariia Karaeva, Anastasiia Serova, Yaroslav Golubev, Iftekhar Ahmed",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10258v1",
    "source": "arXiv",
    "abstract": "AI-powered coding assistants are rapidly becoming fixtures in professional IDEs, yet their sustained influence on everyday development remains poorly understood. Prior research has focused on short-term use or self-reported perceptions, leaving open questions about how sustained AI use reshapes actual daily coding practices in the long term. We address this gap with a mixed-method study of AI adoption in IDEs, combining longitudinal two-year fine-grained telemetry from 800 developers with a survey of 62 professionals. We analyze five dimensions of workflow change: productivity, code quality, code editing, code reuse, and context switching. Telemetry reveals that AI users produce substantially more code but also delete significantly more. Meanwhile, survey respondents report productivity gains and perceive minimal changes in other dimensions. Our results offer empirical insights into the silent restructuring of software workflows and provide implications for designing future AI-augmented tooling."
  },
  {
    "date": "2026-01-15",
    "title": "TRIM: Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks",
    "authors": "Vansh Kapoor, Aman Gupta, Hao Chen, Anurag Beniwal, Jing Huang, Aviral Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10245v1",
    "source": "arXiv",
    "abstract": "Multi-step reasoning tasks like mathematical problem solving are vulnerable to cascading failures, where a single incorrect step leads to complete solution breakdown. Current LLM routing methods assign entire queries to one model, treating all reasoning steps as equal. We propose TRIM (Targeted routing in multi-step reasoning tasks), which routes only critical steps$\\unicode{x2013}$those likely to derail the solution$\\unicode{x2013}$to larger models while letting smaller models handle routine continuations. Our key insight is that targeted step-level interventions can fundamentally transform inference efficiency by confining expensive calls to precisely those steps where stronger models prevent cascading errors. TRIM operates at the step-level: it uses process reward models to identify erroneous steps and makes routing decisions based on step-level uncertainty and budget constraints. We develop several routing strategies within TRIM, ranging from a simple threshold-based policy to more expressive policies that reason about long-horizon accuracy-cost trade-offs and uncertainty in step-level correctness estimates. On MATH-500, even the simplest thresholding strategy surpasses prior routing methods with 5x higher cost efficiency, while more advanced policies match the strong, expensive model's performance using 80% fewer expensive model tokens. On harder benchmarks such as AIME, TRIM achieves up to 6x higher cost efficiency. All methods generalize effectively across math reasoning tasks, demonstrating that step-level difficulty represents fundamental characteristics of reasoning."
  },
  {
    "date": "2026-01-15",
    "title": "Gravitational lensing beyond the eikonal approximation",
    "authors": "Emma Bruyère, Cyril Pitrou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10239v1",
    "source": "arXiv",
    "abstract": "Waves propagating through a gravitational potential exhibit wave-optics effects when their wavelength is not significantly smaller than the lensing scales. We study the propagation of a scalar wave, governed by the Klein-Gordon equation in curved spacetime, to focus on effects on amplitude and phase, while leaving aside the issue of wave polarization which affects electromagnetic and gravitational waves. Using the Newman-Penrose formalism, we obtain the first corrections beyond the geometric optics in the expansion in the inverse frequency. In vacuum, that is for Weyl tensor lensing, there is no wave effect at first order in $G$ and wave effects start at order $G^2$. Conversely, if the wave travels through a non-vanishing matter density, the first corrections start at order $G$. We check these analytic results by solving numerically the equations dictating the evolution of the corrections either in the vicinity of a Schwarzschild black hole or through a transparent star."
  },
  {
    "date": "2026-01-15",
    "title": "Ramsey number of a cycle versus a graph of a given size",
    "authors": "Stijn Cambie, Andrea Freschi, Patryk Morawski, Kalina Petrova, Alexey Pokrovskiy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10238v1",
    "source": "arXiv",
    "abstract": "In this paper, we prove that for every $k$ and every graph $H$ with $m$ edges and no isolated vertices, the Ramsey number $R(C_k,H)$ is at most $2m+\\lfloor \\frac{k-1}{2} \\rfloor$, provided $m$ is sufficiently large with respect to $k$. This settles a problem of Erdős, Faudree, Rousseau and Schelp."
  },
  {
    "date": "2026-01-15",
    "title": "Fundamental Limitations of Favorable Privacy-Utility Guarantees for DP-SGD",
    "authors": "Murat Bilgehan Ertan, Marten van Dijk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10237v1",
    "source": "arXiv",
    "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) is the dominant paradigm for private training, but its fundamental limitations under worst-case adversarial privacy definitions remain poorly understood. We analyze DP-SGD in the $f$-differential privacy framework, which characterizes privacy via hypothesis-testing trade-off curves, and study shuffled sampling over a single epoch with $M$ gradient updates. We derive an explicit suboptimal upper bound on the achievable trade-off curve. This result induces a geometric lower bound on the separation $κ$ which is the maximum distance between the mechanism's trade-off curve and the ideal random-guessing line. Because a large separation implies significant adversarial advantage, meaningful privacy requires small $κ$. However, we prove that enforcing a small separation imposes a strict lower bound on the Gaussian noise multiplier $σ$, which directly limits the achievable utility. In particular, under the standard worst-case adversarial model, shuffled DP-SGD must satisfy $σ\\ge \\frac{1}{\\sqrt{2\\ln M}}$ $\\quad\\text{or}\\quad$ $κ\\ge\\ \\frac{1}{\\sqrt{8}}\\!\\left(1-\\frac{1}{\\sqrt{4π\\ln M}}\\right)$, and thus cannot simultaneously achieve strong privacy and high utility. Although this bound vanishes asymptotically as $M \\to \\infty$, the convergence is extremely slow: even for practically relevant numbers of updates the required noise magnitude remains substantial. We further show that the same limitation extends to Poisson subsampling up to constant factors. Our experiments confirm that the noise levels implied by this bound leads to significant accuracy degradation at realistic training settings, thus showing a critical bottleneck in DP-SGD under standard worst-case adversarial assumptions."
  },
  {
    "date": "2026-01-15",
    "title": "A flower theorem in $\\mathbb{C}^n$",
    "authors": "Kémo Morvan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10235v1",
    "source": "arXiv",
    "abstract": "We prove an analog of the flower theorem for non-degenerate reduced tangent to the identity germs that fix the coordinate hyperspaces in any dimension."
  },
  {
    "date": "2026-01-15",
    "title": "Inconsistency of Reinhardt cardinals with $\\mathsf{ZF}$",
    "authors": "Rupert McCallum",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10231v1",
    "source": "arXiv",
    "abstract": "A proof will be presented that the existence of a non-trivial $Σ_1$-elementary embedding $j: V_{λ+3} \\prec V_{λ+3}$ is inconsistent with $\\textsf{ZF}$. Sections 1 and 2 shall review various important contributions from the literature, notably including \\cite{Goldberg2020}, \\cite{Schlutzenberg2020}, and \\cite{Woodin2010}, the latter reference being where the crucial forcing construction is presented. Section 3 shall introduce some new large cardinal properties, of consistency strength intermediate between $\\mathsf{I_3}$ and $\\mathsf{I_2}$, and greater than $\\mathsf{I_1}$, respectively. The proof of the inconsistency with $\\mathsf{ZF}$ of the existence of a non-trivial $Σ_1$-elementary embedding $j:V_{λ+3} \\prec V_{λ+3}$ shall be given in Section 4. The claims of Sections 2 and 4 are provable in $\\textsf{ZF}$; those of Section 3, with the exception of the last two theorems, in $\\textsf{ZFC}$."
  },
  {
    "date": "2026-01-15",
    "title": "Volume penalization method for simulating flows around a rotating solid with multiple reference frame and sliding mesh",
    "authors": "Ming Liu, Yosuke Hasegawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10230v1",
    "source": "arXiv",
    "abstract": "Despite the significant role of turbomachinery in fluid-based energy transfer, precise simulation of rotating solid objects with complex geometry is a challenging task. In the present study, the volume penalization method (VPM) is combined with multiple reference frame (MRF) and sliding mesh (SLM), respectively, so as to develop immersed-boundary approaches for simulating flows around a rotating solid. The level-set function is adopted to represent arbitrary geometries embedded in Cartesian grids. The VPM body-forcing terms in the momentum equation are proposed for MRF and SLM, respectively, so as to build unified governing equations for both fluid and solid regions. The flows around a rotating cuboid under various rotating speeds are simulated by the present schemes, namely, VPM with MRF, and VPM with SLM, and compared to corresponding simulations by the body-fitted method (BFM). The results suggest the relative deviations of predicted pressure drop and torque between the present VPM and BFM are around 5%, demonstrating the validity of the present VPM."
  },
  {
    "date": "2026-01-15",
    "title": "A Unified Dynamical Field Theory of Learning, Inference, and Emergence",
    "authors": "Byung Gyu Chae",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10221v1",
    "source": "arXiv",
    "abstract": "Learning, inference, and emergence in biological and artificial systems are often studied within disparate theoretical frameworks, ranging from energy-based models to recurrent and attention-based architectures. Here we develop a unified dynamical field theory in which learning and inference are governed by a minimal stochastic dynamical equation admitting a Martin--Siggia--Rose--Janssen--de Dominicis formulation. Within this framework, inference corresponds to saddle-point trajectories of the associated action, while fluctuation-induced loop corrections render collective modes dynamically emergent and generate nontrivial dynamical time scales. A central result of this work is that cognitive function is controlled not by microscopic units or precise activity patterns, but by the collective organization of dynamical time scales. We introduce the \\emph{time-scale density of states} (TDOS) as a compact diagnostic that characterizes the distribution of collective relaxation modes governing inference dynamics. Learning and homeostatic regulation are naturally interpreted as processes that reshape the TDOS, selectively generating slow collective modes that support stable inference, memory, and context-dependent computation despite stochasticity and structural irregularity. This framework unifies energy-based models, recurrent neural networks, transformer architectures, and biologically motivated homeostatic dynamics within a single physical description, and provides a principled route toward understanding cognition as an emergent dynamical phenomenon."
  },
  {
    "date": "2026-01-15",
    "title": "Agentic Pipelines in Embedded Software Engineering: Emerging Practices and Challenges",
    "authors": "Simin Sun, Miroslaw Staron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10220v1",
    "source": "arXiv",
    "abstract": "A new transformation is underway in software engineering, driven by the rapid adoption of generative AI in development workflows. Similar to how version control systems once automated manual coordination, AI tools are now beginning to automate many aspects of programming. For embedded software engineering organizations, however, this marks their first experience integrating AI into safety-critical and resource-constrained environments. The strict demands for determinism, reliability, and traceability pose unique challenges for adopting generative technologies. In this paper, we present findings from a qualitative study with ten senior experts from four companies who are evaluating generative AI-augmented development for embedded software. Through semi-structured focus group interviews and structured brainstorming sessions, we identified eleven emerging practices and fourteen challenges related to the orchestration, responsible governance, and sustainable adoption of generative AI tools. Our results show how embedded software engineering teams are rethinking workflows, roles, and toolchains to enable a sustainable transition toward agentic pipelines and generative AI-augmented development."
  },
  {
    "date": "2026-01-15",
    "title": "Biharmonic and Interpolating Sesqui-Harmonic Vector Fields with Respect to the varphi-Sasakian Metric",
    "authors": "Abderrahim Zagane, Kheireddine Biroud, Medjahed Djilali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10216v1",
    "source": "arXiv",
    "abstract": "This work investigates biharmonic and interpolating sesqui-harmonic vector fields on the tangent bundle of a para-Kähler--Norden manifold (M, varphi, g) endowed with the varphi-Sasaki metric. We derive the first variation of the bienergy and interpolating sesqui-energy functionals, restricted to the space of vector fields. Explicit characterizations are established for vector fields satisfying the corresponding variational conditions-namely, biharmonicity and interpolating sesqui-harmonicity. Furthermore, several examples are presented to illustrate the general theory and to elucidate the distinctions between harmonic, biharmonic, and interpolating sesqui-harmonic behaviors. These results extend and complement existing research on higher-order harmonicity in pseudo-Riemannian geometry."
  },
  {
    "date": "2026-01-15",
    "title": "Topo-RAG: Topology-aware retrieval for hybrid text-table documents",
    "authors": "Alex Dantart, Marco Kóvacs-Navarro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10215v1",
    "source": "arXiv",
    "abstract": "In enterprise datasets, documents are rarely pure. They are not just text, nor just numbers; they are a complex amalgam of narrative and structure. Current Retrieval-Augmented Generation (RAG) systems have attempted to address this complexity with a blunt tool: linearization. We convert rich, multidimensional tables into simple Markdown-style text strings, hoping that an embedding model will capture the geometry of a spreadsheet in a single vector. But it has already been shown that this is mathematically insufficient. This work presents Topo-RAG, a framework that challenges the assumption that \"everything is text\". We propose a dual architecture that respects the topology of the data: we route fluid narrative through traditional dense retrievers, while tabular structures are processed by a Cell-Aware Late Interaction mechanism, preserving their spatial relationships. Evaluated on SEC-25, a synthetic enterprise corpus that mimics real-world complexity, Topo-RAG demonstrates an 18.4% improvement in nDCG@10 on hybrid queries compared to standard linearization approaches. It's not just about searching better; it's about understanding the shape of information."
  },
  {
    "date": "2026-01-15",
    "title": "PADER: Paillier-based Secure Decentralized Social Recommendation",
    "authors": "Chaochao Chen, Jiaming Qian, Fei Zheng, Yachuan Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10212v1",
    "source": "arXiv",
    "abstract": "The prevalence of recommendation systems also brings privacy concerns to both the users and the sellers, as centralized platforms collect as much data as possible from them. To keep the data private, we propose PADER: a Paillier-based secure decentralized social recommendation system. In this system, the users and the sellers are nodes in a decentralized network. The training and inference of the recommendation model are carried out securely in a decentralized manner, without the involvement of a centralized platform. To this end, we apply the Paillier cryptosystem to the SoReg (Social Regularization) model, which exploits both user's ratings and social relations. We view the SoReg model as a two-party secure polynomial evaluation problem and observe that the simple bipartite computation may result in poor efficiency. To improve efficiency, we design secure addition and multiplication protocols to support secure computation on any arithmetic circuit, along with an optimal data packing scheme that is suitable for the polynomial computations of real values. Experiment results show that our method only takes about one second to iterate through one user with hundreds of ratings, and training with ~500K ratings for one epoch only takes <3 hours, which shows that the method is practical in real applications. The code is available at https://github.com/GarminQ/PADER."
  },
  {
    "date": "2026-01-15",
    "title": "Terrain-Adaptive Mobile 3D Printing with Hierarchical Control",
    "authors": "Shuangshan Nors Li, J. Nathan Kutz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10208v1",
    "source": "arXiv",
    "abstract": "Mobile 3D printing on unstructured terrain remains challenging due to the conflict between platform mobility and deposition precision. Existing gantry-based systems achieve high accuracy but lack mobility, while mobile platforms struggle to maintain print quality on uneven ground. We present a framework that tightly integrates AI-driven disturbance prediction with multi-modal sensor fusion and hierarchical hardware control, forming a closed-loop perception-learning-actuation system. The AI module learns terrain-to-perturbation mappings from IMU, vision, and depth sensors, enabling proactive compensation rather than reactive correction. This intelligence is embedded into a three-layer control architecture: path planning, predictive chassis-manipulator coordination, and precision hardware execution. Through outdoor experiments on terrain with slopes and surface irregularities, we demonstrate sub-centimeter printing accuracy while maintaining full platform mobility. This AI-hardware integration establishes a practical foundation for autonomous construction in unstructured environments."
  },
  {
    "date": "2026-01-15",
    "title": "Outlier eigenvalues and eigenvectors of generalized Wigner matrices with finite-rank perturbations",
    "authors": "Bishakh Bhattacharya, Arijit Chakrabarty, Rajat Subhra Hazra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10204v1",
    "source": "arXiv",
    "abstract": "A generalized Wigner matrix perturbed by a finite-rank deterministic matrix is considered. The fluctuations of the largest eigenvalues, which emerge outside the bulk of the spectrum, and the corresponding eigenvectors, are studied. Under certain assumptions on the perturbation and the matrix structure, we derive the first-order behavior of these eigenvalues and show that they are well separated from the bulk. The fluctuations of these eigenvalues are shown to follow a multivariate Gaussian distribution, and the asymptotic behavior of the associated eigenvectors is also studied. We prove central limit theorems that describe the asymptotic alignment of these eigenvectors with the perturbation's eigenvectors, as well as their Gaussian fluctuations around the origin for non-aligned components. Furthermore, we discuss the convergence of the eigenvector process in a Sobolev space framework."
  },
  {
    "date": "2026-01-15",
    "title": "ELITE: Efficient Gaussian Head Avatar from a Monocular Video via Learned Initialization and TEst-time Generative Adaptation",
    "authors": "Kim Youwang, Lee Hyoseok, Subin Park, Gerard Pons-Moll, Tae-Hyun Oh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10200v1",
    "source": "arXiv",
    "abstract": "We introduce ELITE, an Efficient Gaussian head avatar synthesis from a monocular video via Learned Initialization and TEst-time generative adaptation. Prior works rely either on a 3D data prior or a 2D generative prior to compensate for missing visual cues in monocular videos. However, 3D data prior methods often struggle to generalize in-the-wild, while 2D generative prior methods are computationally heavy and prone to identity hallucination. We identify a complementary synergy between these two priors and design an efficient system that achieves high-fidelity animatable avatar synthesis with strong in-the-wild generalization. Specifically, we introduce a feed-forward Mesh2Gaussian Prior Model (MGPM) that enables fast initialization of a Gaussian avatar. To further bridge the domain gap at test time, we design a test-time generative adaptation stage, leveraging both real and synthetic images as supervision. Unlike previous full diffusion denoising strategies that are slow and hallucination-prone, we propose a rendering-guided single-step diffusion enhancer that restores missing visual details, grounded on Gaussian avatar renderings. Our experiments demonstrate that ELITE produces visually superior avatars to prior works, even for challenging expressions, while achieving 60x faster synthesis than the 2D generative prior method."
  },
  {
    "date": "2026-01-15",
    "title": "HUMANLLM: Benchmarking and Reinforcing LLM Anthropomorphism via Human Cognitive Patterns",
    "authors": "Xintao Wang, Jian Yang, Weiyuan Li, Rui Xie, Jen-tse Huang, Jun Gao, Shuai Huang, Yueping Kang, Liyuan Gou, Hongwei Feng, Yanghua Xiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10198v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in reasoning and generation, serving as the foundation for advanced persona simulation and Role-Playing Language Agents (RPLAs). However, achieving authentic alignment with human cognitive and behavioral patterns remains a critical challenge for these agents. We present HUMANLLM, a framework treating psychological patterns as interacting causal forces. We construct 244 patterns from ~12,000 academic papers and synthesize 11,359 scenarios where 2-5 patterns reinforce, conflict, or modulate each other, with multi-turn conversations expressing inner thoughts, actions, and dialogue. Our dual-level checklists evaluate both individual pattern fidelity and emergent multi-pattern dynamics, achieving strong human alignment (r=0.91) while revealing that holistic metrics conflate simulation accuracy with social desirability. HUMANLLM-8B outperforms Qwen3-32B on multi-pattern dynamics despite 4x fewer parameters, demonstrating that authentic anthropomorphism requires cognitive modeling--simulating not just what humans do, but the psychological processes generating those behaviors."
  },
  {
    "date": "2026-01-15",
    "title": "Physically Unclonable Functions Based on Single-Walled Carbon Nanotubes: A Scalable and Inexpensive Method toward Unique Identifiers",
    "authors": "Enrique Burzurí, Daniel Granados, Emilio M. Pérez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10196v1",
    "source": "arXiv",
    "abstract": "A physically un-clonable function (PUF) is a physical system that cannot be reproduced or predicted and therefore is a good basis to build security and anti-counterfeiting applications. The unclonability of PUFs typically stems from the randmoness induced in a system during sophisticated fabrication methods. It is precisely this built-in complexity the bottleneck hindering scalability and increasing costs. Here, we produce in a simple manner PUFs based on arrays of carbon nanotubes junctions simultaneously assembled by dielectrophoresis. We demonstrate that the intrinsic inhomogeneity of carbon nanotubes at the nanoscale, combined with the unpredictability introduced by liquid phase-based fabrication methods results in unique electronic profiles of easily scalable devices. This approach could be extrapolated to generate PUFs based on other nanoscale materials"
  },
  {
    "date": "2026-01-15",
    "title": "From Physical Degradation Models to Task-Aware All-in-One Image Restoration",
    "authors": "Hu Gao, Xiaoning Lei, Xichen Xu, Xingjian Wang, Lizhuang Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10192v1",
    "source": "arXiv",
    "abstract": "All-in-one image restoration aims to adaptively handle multiple restoration tasks with a single trained model. Although existing methods achieve promising results by introducing prompt information or leveraging large models, the added learning modules increase system complexity and hinder real-time applicability. In this paper, we adopt a physical degradation modeling perspective and predict a task-aware inverse degradation operator for efficient all-in-one image restoration. The framework consists of two stages. In the first stage, the predicted inverse operator produces an initial restored image together with an uncertainty perception map that highlights regions difficult to reconstruct, ensuring restoration reliability. In the second stage, the restoration is further refined under the guidance of this uncertainty map. The same inverse operator prediction network is used in both stages, with task-aware parameters introduced after operator prediction to adapt to different degradation tasks. Moreover, by accelerating the convolution of the inverse operator, the proposed method achieves efficient all-in-one image restoration. The resulting tightly integrated architecture, termed OPIR, is extensively validated through experiments, demonstrating superior all-in-one restoration performance while remaining highly competitive on task-aligned restoration."
  },
  {
    "date": "2026-01-15",
    "title": "How does downsampling affect needle electromyography signals? A generalisable workflow for understanding downsampling effects on high-frequency time series",
    "authors": "Mathieu Cherpitel, Janne Luijten, Thomas Bäck, Camiel Verhamme, Martijn Tannemaat, Anna Kononova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10191v1",
    "source": "arXiv",
    "abstract": "Automated analysis of needle electromyography (nEMG) signals is emerging as a tool to support the detection of neuromuscular diseases (NMDs), yet the signals' high and heterogeneous sampling rates pose substantial computational challenges for feature-based machine-learning models, particularly for near real-time analysis. Downsampling offers a potential solution, but its impact on diagnostic signal content and classification performance remains insufficiently understood. This study presents a workflow for systematically evaluating information loss caused by downsampling in high-frequency time series. The workflow combines shape-based distortion metrics with classification outcomes from available feature-based machine learning models and feature space analysis to quantify how different downsampling algorithms and factors affect both waveform integrity and predictive performance. We use a three-class NMD classification task to experimentally evaluate the workflow. We demonstrate how the workflow identifies downsampling configurations that preserve diagnostic information while substantially reducing computational load. Analysis of shape-based distortion metrics showed that shape-aware downsampling algorithms outperform standard decimation, as they better preserve peak structure and overall signal morphology. The results provide practical guidance for selecting downsampling configurations that enable near real-time nEMG analysis and highlight a generalisable workflow that can be used to balance data reduction with model performance in other high-frequency time-series applications as well."
  },
  {
    "date": "2026-01-15",
    "title": "Service Provisioning and Path Planning with Obstacle Avoidance for Low-Altitude Wireless Networks",
    "authors": "Senning Wan, Bin Li, Hongbin Chen, Lei Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10179v1",
    "source": "arXiv",
    "abstract": "This paper investigates the three-dimensional (3D) deployment of uncrewed aerial vehicles (UAVs) as aerial base stations in heterogeneous communication networks under constraints imposed by diverse ground obstacles. Given the diverse data demands of user equipments (UEs), a user satisfaction model is developed to provide personalized services. In particular, when a UE is located within a ground obstacle, the UAV must approach the obstacle boundary to ensure reliable service quality. Considering constraints such as UAV failures due to battery depletion, heterogeneous UEs, and obstacles, we aim to maximize overall user satisfaction by jointly optimizing the 3D trajectories of UAVs, transmit beamforming vectors, and binary association indicators between UAVs and UEs. To address the complexity and dynamics of the problem, a block coordinate descent method is adopted to decompose it into two subproblems. The beamforming subproblem is efficiently addressed via a bisection-based water-filling algorithm. For the trajectory and association subproblem, we design a deep reinforcement learning algorithm based on proximal policy optimization to learn an adaptive control policy. Simulation results demonstrate that the proposed scheme outperforms baseline schemes in terms of convergence speed and overall system performance. Moreover, it achieves efficient association and accurate obstacle avoidance."
  },
  {
    "date": "2026-01-15",
    "title": "Observation Timelines for the Potential Lunar Impact of Asteroid 2024 YR4",
    "authors": "Yifan He, Yixuan Wu, Yifei Jiao, Wen-Yue Dai, Xin Liu, Bin Cheng, Hexi Baoyin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10666v1",
    "source": "arXiv",
    "abstract": "The near-Earth asteroid 2024 YR4 -- a $\\sim$60 m rocky object that was once considered a potential Earth impactor -- has since been ruled out for Earth but retained a $\\sim$4.3% probability of striking the Moon in 2032. Such an impact, with equivalent kinetic energy of $\\sim$6.5 Mt TNT, is expected to produce a $\\sim$1 km crater on the Moon, and will be the most energetic lunar impact event ever recorded in human history. Despite the associated risk, this scenario offers a rare and valuable scientific opportunity. Using a hybrid framework combining Monte Carlo orbital propagation, smoothed particle hydrodynamics (SPH) impact modeling, and N-body ejecta dynamics, we evaluate the physical outcomes and propose the observation timelines of this rare event. Our results suggest an optical flash of visual magnitude from -2.5 to -3 lasting several minutes directly after the impact, followed by hours of infrared afterglow from $\\sim$2000 K molten rock cooling to a few hundred K. The associated seismic energy release would lead to a global-scale lunar reverberation (magnitude $\\sim$5.0) that can be detectable by modern seismometers. Furthermore, the impact would eject $\\sim$10$^8$ kg of debris that escapes the lunar gravity, with a small fraction reaching Earth to produce a lunar meteor outburst within 100 years. Finally, we integrate these results into a coordinated observation timeline, identifying the best detection windows for ground-based telescopes, lunar orbiters, and surface stations."
  },
  {
    "date": "2026-01-15",
    "title": "Optimal universal bounds for waves with varied coherence based on supremum and infimum coherence spectra",
    "authors": "Shiyu Li, Cheng Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10665v1",
    "source": "arXiv",
    "abstract": "We establish a majorization-based theory for bounding observables of waves with varied coherence. For any measurement, exact bounds are attained by the maximal and minimal elements in the set of input coherence spectra. The set's supremum and infimum, which may lie outside the set, provide optimal universal bounds: any alternative spectrum yielding universal bounds produces weaker constraints. We present an algorithm to compute the supremum and infimum, and prove that they lie either at singular boundary points or strictly outside the set of coherence spectra."
  },
  {
    "date": "2026-01-15",
    "title": "Sporadic Creutzfeldt Jakob disease presenting with cerebral atrophy following traumatic brain injury mimicking hydrocephalus a case report and literature review",
    "authors": "Chun Zeng, Dezhu Gao, Liang Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10663v1",
    "source": "arXiv",
    "abstract": "Introduction Sporadic Creutzfeldt Jakob disease sCJD is a rapidly progressive neurodegenerative disease without effective treatment that usually results in death within one year. The recently applied methods have improved the accuracy of the disease diagnosis and the specific radiological findings provide the necessary information for differential diagnosis. Research question The research is aimed to provide a different perspective on the development of CJD and associated literature review. Materials and methods The study presents a case who presented cognitive deficits, gait instability, and urinary and fecal incontinence suffered from traumatic brain injury eight months ago before admission with cerebral ventricle dilation on CT images. Furthermore, studies describe relevant cases are also included. Results The patients symptoms got deteriorated. Further examinations, including 14-3-3 and tau proteins in the cerebrospinal fluid CSF, MRI, and EEG, confirmed the patients diagnosis of sCJD. He returned to the local hospital for the conservative treatment without effective medical intervention. Conclusion This case illustrates the diagnostic process of CJD and underscores the importance of distinguishing rare disorders from common conditions to achieve a comprehensive understanding of the disease."
  },
  {
    "date": "2026-01-15",
    "title": "Boundary treatment algorithms for meshfree RANS turbulence modeling",
    "authors": "Mohan Padmanabha, Jörg Kuhnert, Nicolas R. Gauger, Pratik Suchde",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10661v1",
    "source": "arXiv",
    "abstract": "In this paper, we propose improved wall-treatment strategies for meshfree methods applied to turbulent flows. The goal is to improve wall-function handling in simulations of high-Reynolds-number turbulent flows, and to better understand the performance of turbulence models when used with meshfree methods. While wall-function techniques are well established for mesh-based methods, their inclusion in meshfree methods faces unique challenges that have not been fully explored. The main difficulties arise from the lack of connectivity between points and from point movement in Lagrangian frameworks, which can complicate consistent wall treatment. To address these issues, we explore three wall-treatment techniques. We highlight the drawbacks of the standard closest neighbor approach. We then introduce two novel approaches: the nearest-band neighbor method and the shifted boundary method. We evaluate these methods using first-order turbulence closures: Spalart--Allmaras, $k-\\varepsilon$, and $k-ω$. These methods are tested numerically on 1D Couette flow, turbulent flow over a flat plate, and flow around a NACA 0012 airfoil in 3D. The results show that both novel methods outperform the closest neighbor approach. The shifted boundary method achieves higher accuracy, but is more computationally expensive than the nearest-band neighbor method. However, by using smaller shift distances, we can achieve lower $y^+$ values with the same resolution. All turbulence models work well with the shifted boundary method, with only minor differences between them. In contrast, the nearest-band method shows variation in the behavior of the turbulence models, where the Spalart--Allmaras model yields better results, especially further downstream along the plate. This work establishes a robust foundation for simulating wall-bounded turbulent flows at high Reynolds numbers using meshfree collocation methods."
  },
  {
    "date": "2026-01-15",
    "title": "Uniform stability of the inverse Sturm-Liouville problem on a star-shaped graph",
    "authors": "E. E. Chitorkin, N. P. Bondarenko",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10652v1",
    "source": "arXiv",
    "abstract": "In this paper, we study the inverse spectral problem for the Sturm-Liouville operators on a star-shaped graph, which consists in the recovery of the potentials from specral data or several spectra. The uniform stability of these inverse problems on the whole graph is proved."
  },
  {
    "date": "2026-01-15",
    "title": "One-Shot Broadcast Joint Source-Channel Coding with Codebook Diversity",
    "authors": "Joseph Rowan, Buu Phan, Ashish Khisti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10648v1",
    "source": "arXiv",
    "abstract": "We study a one-shot joint source-channel coding setting where the source is encoded once and broadcast to $K$ decoders through independent channels. Success is predicated on at least one decoder recovering the source within a maximum distortion constraint. We find that in the one-shot regime, utilizing disjoint codebooks at each decoder yields a codebook diversity gain, distinct from the channel diversity gain that may be expected when several decoders observe independent realizations of the channel's output but share the same codebook. Coding schemes are introduced that leverage this phenomenon, where first- and second-order achievability bounds are derived via an adaptation of the Poisson matching lemma (Li and Anantharam, 2021) which allows for multiple decoders using disjoint codebooks. We further propose a hybrid coding scheme that partitions decoders into groups to optimally balance codebook and channel diversity. Numerical results on the binary symmetric channel demonstrate that the hybrid approach outperforms strategies where the decoders' codebooks are either fully shared or disjoint."
  },
  {
    "date": "2026-01-15",
    "title": "Michael-Simon inequality for anisotropic energies close to the area via multilinear Kakeya-type bounds",
    "authors": "Guido De Philippis, Alessandro Pigati",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10647v1",
    "source": "arXiv",
    "abstract": "Given an anisotropic integrand $F:\\text{Gr}_k(\\mathbb R^n)\\to(0,\\infty)$, we can generalize the classical isotropic area by looking at the functional $$\\mathcal{F}(Σ^k):=\\int_ΣF(T_xΣ)\\,d\\mathcal{H}^k.$$ While a monotonicity formula is not available for critical points, when $k=2$ and $n=3$ we show that the Michael-Simon inequality holds if $F$ is convex and close to $1$ (in $C^1$), meaning that $\\mathcal{F}$ is close to the usual area. Our argument is partly based on some key ideas of Almgren, who proved this result in an unpublished manuscript, but we largely simplify his original proof by showing a new functional inequality for vector fields on the plane, which can be seen as a quantitative version of Alberti's rank-one theorem. As another byproduct, we also show Michael-Simon for another class of integrands which includes the $\\ell^p$ norms for $p\\in(1,\\infty)$. For a general $F$ satisfying the atomic condition, we also show that the validity of Michael-Simon is equivalent to compactness of rectifiable varifolds."
  },
  {
    "date": "2026-01-15",
    "title": "Emergent electric field induced by dissipative sliding dynamics of domain walls in a Weyl magnet",
    "authors": "Rinsuke Yamada, Daichi Kurebayashi, Yukako Fujishiro, Shun Okumura, Daisuke Nakamura, Fehmi S. Yasin, Taro Nakajima, Tomoyuki Yokouchi, Akiko Kikkawa, Yasujiro Taguchi, Yoshinori Tokura, Oleg A. Tretiakov, Max Hirschberger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10638v1",
    "source": "arXiv",
    "abstract": "The dynamic motion of topological defects in magnets induces an emergent electric field, as exemplified by the continuous flow of skyrmion vortices. However, the electrodynamics underlying this emergent field remains poorly understood. In this context, magnetic domain walls - one dimensional topological defects with two collective modes, sliding and spin tilt - offer a promising platform for exploration. Here, we demonstrate that the dissipative motion of domain walls under oscillatory current excitation generates an emergent electric field. We image domain patterns and quantify domain wall length under applied magnetic fields in mesoscopic devices based on the magnetic Weyl semimetal NdAlSi. These devices exhibit exceptionally strong domain wall scattering and a pronounced emergent electric field, observed in the imaginary component of the complex impedance. Spin dynamics simulations reveal that domain wall sliding dominates over spin tilting, where the phase delay of the domain wall motion with respect to the driving force impacts the emergent electric field. Our findings establish domain-wall dynamics as a platform for studying emergent electromagnetic fields and motivate further investigations on the coupled motion of magnetic solitons and conduction electrons."
  },
  {
    "date": "2026-01-15",
    "title": "Parametric RDT approach to computational gap of symmetric binary perceptron",
    "authors": "Mihailo Stojnic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10628v1",
    "source": "arXiv",
    "abstract": "We study potential presence of statistical-computational gaps (SCG) in symmetric binary perceptrons (SBP) via a parametric utilization of \\emph{fully lifted random duality theory} (fl-RDT) [96]. A structural change from decreasingly to arbitrarily ordered $c$-sequence (a key fl-RDT parametric component) is observed on the second lifting level and associated with \\emph{satisfiability} ($α_c$) -- \\emph{algorithmic} ($α_a$) constraints density threshold change thereby suggesting a potential existence of a nonzero computational gap $SCG=α_c-α_a$. The second level estimate is shown to match the theoretical $α_c$ whereas the $r\\rightarrow \\infty$ level one is proposed to correspond to $α_a$. For example, for the canonical SBP ($κ=1$ margin) we obtain $α_c\\approx 1.8159$ on the second and $α_a\\approx 1.6021$ (with converging tendency towards $\\sim 1.59$ range) on the seventh level. Our propositions remarkably well concur with recent literature: (i) in [20] local entropy replica approach predicts $α_{LE}\\approx 1.58$ as the onset of clustering defragmentation (presumed driving force behind locally improving algorithms failures); (ii) in $α\\rightarrow 0$ regime we obtain on the third lifting level $κ\\approx 1.2385\\sqrt{\\frac{α_a}{-\\log\\left ( α_a \\right ) }}$ which qualitatively matches overlap gap property (OGP) based predictions of [43] and identically matches local entropy based predictions of [24]; (iii) $c$-sequence ordering change phenomenology mirrors the one observed in asymmetric binary perceptron (ABP) in [98] and the negative Hopfield model in [100]; and (iv) as in [98,100], we here design a CLuP based algorithm whose practical performance closely matches proposed theoretical predictions."
  },
  {
    "date": "2026-01-15",
    "title": "Dynamics of Late time cosmology in $f(Q,L_{m})$ Gravity with Constraints from DESI DR2 BAO Data",
    "authors": "Rajdeep Mazumdar, Kalyan Malakar, Kalyan Bhuyan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10627v1",
    "source": "arXiv",
    "abstract": "We investigate late-time cosmology in the context of modified $f(Q,L_m)$ gravity, considering a non-linear model$ f(Q,L_m) = αQ + βL_m^n + λ$ where, $α$, $β$, $λ$, and $n$ are some free parameters. The modified Friedmann equations are derived for a barotropic cosmic fluid, and an analytical solution for the Hubble parameter $H(z)$ is obtained. Using the latest DESI DR2 BAO data, previous BAO compilations (P-BAO), and cosmic chronometer (CC) datasets, we constrain the model parameters through a Markov Chain Monte Carlo analysis. Our results show that the model successfully describes the observed late-time cosmic acceleration with slightly tighter constraints from the inclusion of DESI dataset. The present-day Hubble constant is determined as $H_0 \\simeq 69.5\\ \\mathrm{km\\ s^{-1}\\ Mpc^{-1}}$, while the deceleration parameter confirms accelerated expansion with $q_0 \\simeq -0.57$. The transition redshift, where the universe switches from deceleration to acceleration, occurs in the range $z_{\\rm tr} \\sim 0.56 - 0.77$. Similarly, a smooth and physically consistent transition from a matter-dominated decelerated period at high redshifts to an accelerated phase at late times is revealed by the evolution of $ω_{eff}(z)$. While statefinder diagnostic shows the model favours a Chaplygin gas like nature for DESI and DESI+CC, whereas the model favours as quintessence dominated evolution for P-BAO+CC in the late time regime. Conclusively, all these results along with the study of the energy conditions and stability analysis showcases the given $f(Q,L_m)$ model offers a viable alternative to GR-based cosmology"
  },
  {
    "date": "2026-01-15",
    "title": "Source localisation in simple random walks",
    "authors": "Ritesh Goenka, Peter Keevash, Tomasz Przybyłowski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10624v1",
    "source": "arXiv",
    "abstract": "We consider the problem of locating the source (starting vertex) of a simple random walk, given a snapshot of the set of edges (or vertices) visited in the first $n$ steps. Considering lattices $\\mathbb{Z}^d$, in dimensions $d \\geq 5$, we show that the source can be identified (a) with probability bounded away from $0$ using one guess, and (b) with probability arbitrarily close to $1$ using a constant number of guesses. On the other hand, for dimensions $d \\leq 2$, we show that one cannot locate the source with positive constant probability. Our arguments apply more generally to strongly transient and recurrent simple random walks on vertex-transitive graphs."
  },
  {
    "date": "2026-01-15",
    "title": "Massless-Massive Amplitude Correspondence I: Helicity-chirality Matching and On-shell Higgsing",
    "authors": "Yu-Han Ni, Chao Wu, Jiang-Hao Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10620v1",
    "source": "arXiv",
    "abstract": "In this work, the massless-massive correspondence for the on-shell scattering amplitudes is constructed so the massive amplitudes could inherit advantageous techniques developed in the massless calculation. This correspondence is established by matching massless amplitudes to Minimal Helicity-Chirality (MHC) amplitudes, which arise from an expansion of massive spin-spinor amplitudes in terms of the chirality-flip $mη$ order by order. The primary MHC amplitude deforms into a massless amplitude of the same helicity; if a vector boson is involved, it may instead vanish due to the associated conserved current. In cases where the primary amplitude vanishes, the leading contributions originate from descendant MHC amplitudes, each corresponding to a distinct massless amplitude in the ultraviolet theory containing either a transverse gauge boson or a Goldstone boson. We propose a systematic amplitude deformation procedure for three-point massless-massive matching based on helicity-chirality unification and the scaling properties of $mη$. Sub-leading MHC amplitudes are matched to massless amplitudes with additional on-shell Higgs splitting, a process known as on-shell Higgsing. In this work, we extend and reinterpret on-shell Higgsing as a transversality flip between different MHC states, and obtain all the 3-point massless-massive matching results in the spontaneous broken standard model."
  },
  {
    "date": "2026-01-15",
    "title": "A Bayesian Discrete Framework for Enhancing Decision-Making Processes in Clinical Trial Designs and Evaluations",
    "authors": "Paramahansa Pramanik, Arnab Kumar Maity, Anjan Mandal, Haley Kate Robinson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10615v1",
    "source": "arXiv",
    "abstract": "This study examines the application of Bayesian approach in the context of clinical trials, emphasizing their increasing importance in contemporary biomedical research. While conventional frequentist approach provides a foundational basis for analysis, it often lacks the flexibility to integrate prior knowledge, which can constrain its effectiveness in adaptive settings. In contrast, Bayesian methods enable continual refinement of statistical inferences through the assimilation of accumulating evidence, thereby supporting more informed decision-making and improving the reliability of trial findings. This paper also considers persistent challenges in clinical investigations, including replication difficulties and the misinterpretation of statistical results, suggesting that Bayesian strategies may offer a path toward enhanced analytical robustness. Moreover, discrete probability models, specifically the Binomial, Poisson, and Negative Binomial distributions are explored for their suitability in modeling clinical endpoints, particularly in trials involving binary responses or data with overdispersion. The discussion further incorporates Bayesian networks and Bayesian estimation techniques, with a comparative evaluation against maximum likelihood estimation to elucidate differences in inferential behavior and practical implementation."
  },
  {
    "date": "2026-01-15",
    "title": "The directedness of the Rudin-Keisler order at measurable cardinals",
    "authors": "Yair Hayut, Alejandro Poveda",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10614v1",
    "source": "arXiv",
    "abstract": "The manuscript is concerned with the Rudin-Keisler order of ultrafilters on measurable cardinals. The main theorem proved read as follows: Given regular cardinals $λ\\leq κ$, the following theories are equiconsistent modulo ZFC: (1) $κ$ is a measurable cardinal with $o(κ)=λ^+$ (resp. $o(κ)=κ$). (2) The Rudin-Keisler order restricted to the set of $κ$-complete (non-principal) ultrafilters on $κ$ is $λ^+$-directed (resp. $κ^+$-directed). The theorem reported here is proved after bridging the directedness of the RK-order with the $λ$-Gluing Property introduced by the authors in \\cite{HP}. Our result provides what seems to be the first example of a compactness-type property at the level of measurable cardinals whose consistency strength is much lower than the existence of a strong cardinal. As part of our analysis we also answer a question of Gitik by showing that the $\\aleph_0$-Gluing Property fails in his classical model from ''Changing cofinalities and the nonstationary ideal\". As a consequence of this, in Gitik's model the Rudin-Keisler order fails to be $\\aleph_1$-directed."
  },
  {
    "date": "2026-01-15",
    "title": "On the Physical Origins of the Millimeter Fundamental Plane in Active Galactic Nuclei",
    "authors": "Kratika Mazde, Angelo Ricarte, George N. Wong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10612v1",
    "source": "arXiv",
    "abstract": "Observations of active galactic nuclei have revealed a correlation between millimeter luminosity, X-ray luminosity, and mass, suggesting the emission in each of these bands is powered by a common source. Starting with a set of five general relativistic magnetohydrodynamic simulations with dynamically important magnetic fields, we perform ray-tracing calculations to produce spectra including synchrotron emission, bremsstrahlung emission, and Compton scattering. Our models with similar Eddington ratios to the objects for which the relationship was inferred naturally reproduce observations without tuning. Our lower Eddington ratio models depart from this relationship, likely attributable to an observational bias against extremely low accretion rates. We find that inverse Compton scattering dominates the production of X-rays over bremsstrahlung radiation in almost all models, and in all models consistent with the observed correlation. We find only a modest spin dependence in this relationship. This study demonstrates that a compact, hot accretion flow with dynamically important magnetic fields can naturally explain observed millimeter and X-ray properties in low-luminosity active galactic nuclei. Future work should explore the impacts of non-thermal electron populations, weaker magnetic fields, and radiative cooling."
  },
  {
    "date": "2026-01-15",
    "title": "Local times and excursions for self-similar Markov trees",
    "authors": "Jean Bertoin, Armand Riera, Alejandro Rosales-Ortiz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10610v1",
    "source": "arXiv",
    "abstract": "This work builds upon the recent monograph [5] on self-similar Markov trees. A self-similar Markov tree is a random real tree equipped with a function from the tree to $[0,\\infty)$ that we call the decoration. Here, we construct local time measures $L(x,dt)$ at every level $x>0$ of the decoration for a large class of self-similar Markov trees. This enables us to mark at random a typical point in the tree at which the decoration is $x$. We identify the law of the decoration along the branch from the root to this tagged point in terms of a remarkable (positive) self-similar Markov process. We also show that after a proper normalization, $L(x,dt)$ converges as $x\\to 0+$ to the harmonic measure $μ$ on the tree. Finally, we point out that using a local time measure instead of the usual length measure $λ$ to compute distances on the tree turn the latter into a continuous branching tree. This is relevant to analyze the excusions of the decoration away from a given level. Many results of the present work shall be compared with the recent ones in [22,23] about local times and excursions of a Markov process indexed by Lévy tree."
  },
  {
    "date": "2026-01-15",
    "title": "Multi-Objective Pareto-Front Optimization for Efficient Adaptive VVC Streaming",
    "authors": "Angeliki Katsenou, Vignesh V. Menon, Guoda Laurinaviciute, Benjamin Bross, Detlev Marpe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10607v1",
    "source": "arXiv",
    "abstract": "Adaptive video streaming has facilitated improved video streaming over the past years. A balance among coding performance objectives such as bitrate, video quality, and decoding complexity is required to achieve efficient, content- and codec-dependent, adaptive video streaming. This paper proposes a multi-objective Pareto-front (PF) optimization framework to construct quality-monotonic, content-adaptive bitrate ladders Versatile Video Coding (VVC) streaming that jointly optimize video quality, bitrate, and decoding time, which is used as a practical proxy for decoding energy. Two strategies are introduced: the Joint Rate-Quality-Time Pareto Front (JRQT-PF) and the Joint Quality-Time Pareto Front (JQT-PF), each exploring different tradeoff formulations and objective prioritizations. The ladders are constructed under quality monotonicity constraints during adaptive streaming to ensure a consistent Quality of Experience (QoE). Experiments are conducted on a large-scale UHD dataset (Inter-4K), with quality assessed using PSNR, VMAF, and XPSNR, and complexity measured via decoding time and energy consumption. The JQT-PF method achieves 11.76% average bitrate savings while reducing average decoding time by 0.29% to maintain the same XPSNR, compared to a widely-used fixed ladder. More aggressive configurations yield up to 27.88% bitrate savings at the cost of increased complexity. The JRQT-PF strategy, on the other hand, offers more controlled tradeoffs, achieving 6.38 % bitrate savings and 6.17 % decoding time reduction. This framework outperforms existing methods, including fixed ladders, VMAF- and XPSNR-based dynamic resolution selection, and complexity-aware benchmarks. The results confirm that PF optimization with decoding time constraints enables sustainable, high-quality streaming tailored to network and device capabilities."
  },
  {
    "date": "2026-01-15",
    "title": "Schur--Horn type inequalities for hyperbolic polynomials",
    "authors": "Teng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10602v1",
    "source": "arXiv",
    "abstract": "We establish a Schur--Horn type inequality for symmetric hyperbolic polynomials. As an immediate consequence, we resolve a conjecture of Nam Q. Le on Hadamard-type inequalities for hyperbolic polynomials. Our argument is based on the Schur--Horn theorem, the Birkhoff theorem, and Gårding's concavity theorem for hyperbolicity cones. Beyond the eigenvalue level, we develop a symmetrization principle on hyperbolicity cones: if a hyperbolic polynomial is invariant under a finite group action, then its value increases under the associated Reynolds operator (group averaging). Applied to the sign-flip symmetries of linear principal minor polynomials introduced by Blekherman et al., this yields a short proof of the hyperbolic Fischer--Hadamard inequalities for PSD-stable lpm polynomials."
  },
  {
    "date": "2026-01-15",
    "title": "Action100M: A Large-scale Video Action Dataset",
    "authors": "Delong Chen, Tejaswi Kasarla, Yejin Bang, Mustafa Shukor, Willy Chung, Jade Yu, Allen Bolourchi, Theo Moutakanni, Pascale Fung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10592v1",
    "source": "arXiv",
    "abstract": "Inferring physical actions from visual observations is a fundamental capability for advancing machine intelligence in the physical world. Achieving this requires large-scale, open-vocabulary video action datasets that span broad domains. We introduce Action100M, a large-scale dataset constructed from 1.2M Internet instructional videos (14.6 years of duration), yielding O(100 million) temporally localized segments with open-vocabulary action supervision and rich captions. Action100M is generated by a fully automated pipeline that (i) performs hierarchical temporal segmentation using V-JEPA 2 embeddings, (ii) produces multi-level frame and segment captions organized as a Tree-of-Captions, and (iii) aggregates evidence with a reasoning model (GPT-OSS-120B) under a multi-round Self-Refine procedure to output structured annotations (brief/detailed action, actor, brief/detailed caption). Training VL-JEPA on Action100M demonstrates consistent data-scaling improvements and strong zero-shot performance across diverse action recognition benchmarks, establishing Action100M as a new foundation for scalable research in video understanding and world modeling."
  },
  {
    "date": "2026-01-15",
    "title": "Be Your Own Red Teamer: Safety Alignment via Self-Play and Reflective Experience Replay",
    "authors": "Hao Wang, Yanting Wang, Hao Li, Rui Li, Lei Sha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10589v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have achieved remarkable capabilities but remain vulnerable to adversarial ``jailbreak'' attacks designed to bypass safety guardrails. Current safety alignment methods depend heavily on static external red teaming, utilizing fixed defense prompts or pre-collected adversarial datasets. This leads to a rigid defense that overfits known patterns and fails to generalize to novel, sophisticated threats. To address this critical limitation, we propose empowering the model to be its own red teamer, capable of achieving autonomous and evolving adversarial attacks. Specifically, we introduce Safety Self- Play (SSP), a system that utilizes a single LLM to act concurrently as both the Attacker (generating jailbreaks) and the Defender (refusing harmful requests) within a unified Reinforcement Learning (RL) loop, dynamically evolving attack strategies to uncover vulnerabilities while simultaneously strengthening defense mechanisms. To ensure the Defender effectively addresses critical safety issues during the self-play, we introduce an advanced Reflective Experience Replay Mechanism, which uses an experience pool accumulated throughout the process. The mechanism employs a Upper Confidence Bound (UCB) sampling strategy to focus on failure cases with low rewards, helping the model learn from past hard mistakes while balancing exploration and exploitation. Extensive experiments demonstrate that our SSP approach autonomously evolves robust defense capabilities, significantly outperforming baselines trained on static adversarial datasets and establishing a new benchmark for proactive safety alignment."
  },
  {
    "date": "2026-01-15",
    "title": "Mitigating GIL Bottlenecks in Edge AI Systems",
    "authors": "Mridankan Mandal, Smit Sanjay Shende",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10582v1",
    "source": "arXiv",
    "abstract": "Deploying Python based AI agents on resource-constrained edge devices presents a runtime optimization challenge: high thread counts are needed to mask I/O latency, yet Python's Global Interpreter Lock (GIL) serializes execution. We demonstrate that naive thread-pool scaling causes a \"saturation cliff\": >= 20% throughput degradation at overprovisioned thread counts (N >= 512) on edge-representative configurations. We present a lightweight profiling tool and adaptive runtime system using a Blocking Ratio metric (beta) that distinguishes genuine I/O wait from GIL contention. Our library-based solution achieves 96.5% of optimal performance without manual tuning, outperforming multiprocessing (limited by ~8x memory overhead on devices with 512 MB-2 GB RAM) and asyncio (blocked by CPU-bound phases). Evaluation across seven edge AI workload profiles, including real ML inference with ONNX Runtime MobileNetV2, demonstrates 93.9% average efficiency. Comparative experiments with Python 3.13t (free threading) show that while GIL elimination enables ~4x throughput on multi-core edge devices, the saturation cliff persists on single-core devices, validating our beta metric for both GIL and no-GIL environments. This provides practical optimization for edge AI systems."
  },
  {
    "date": "2026-01-15",
    "title": "HST Observations of HD 166620 and Tau Ceti: First UV Spectra of a Magnetic Grand Minimum Star and the Extent of Tau Ceti's Astrosphere",
    "authors": "Brian E. Wood, Hans-Reinhard Mueller, Dean Hartshorn, Seth Redfield, Travis S. Metcalfe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10579v1",
    "source": "arXiv",
    "abstract": "We present new Hubble Space Telescope (HST) UV spectra of the K2 V star HD 166620, the first star clearly recognized to be in a \"magnetic grand minimum\" state analogous to the Sun's \"Maunder Minimum\" in the late 1600's. The stellar H I Lyman-alpha surface fluxes are extremely low, about a factor of two below fluxes observed during solar minimum, and also significantly lower than those of Tau Ceti (G8 V) and HD 191408 (K2.5 V), two stars more similar to HD 166620 in spectral type and age (~10 Gyr) than the Sun. The Tau Ceti data that are compared with HD 166620 include both old archival data and a new HST observation as well. The Lyman alpha data are used to confirm a nondetection of astrospheric Lyman-alpha absorption for this star, suggesting a very weak wind with Mdot<0.1 Mdot_sun. The very compact astrosphere inferred for Tau Ceti indicates that the star's debris disk is at least partly exposed to the ISM, and we discuss possible consequences."
  },
  {
    "date": "2026-01-15",
    "title": "Jordan-Segmentable Masks: A Topology-Aware definition for characterizing Binary Image Segmentation",
    "authors": "Serena Grazia De Benedictis, Amedeo Altavilla, Nicoletta Del Buono",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10577v1",
    "source": "arXiv",
    "abstract": "Image segmentation plays a central role in computer vision. However, widely used evaluation metrics, whether pixel-wise, region-based, or boundary-focused, often struggle to capture the structural and topological coherence of a segmentation. In many practical scenarios, such as medical imaging or object delineation, small inaccuracies in boundary, holes, or fragmented predictions can result in high metric scores, despite the fact that the resulting masks fail to preserve the object global shape or connectivity. This highlights a limitation of conventional metrics: they are unable to assess whether a predicted segmentation partitions the image into meaningful interior and exterior regions. In this work, we introduce a topology-aware notion of segmentation based on the Jordan Curve Theorem, and adapted for use in digital planes. We define the concept of a \\emph{Jordan-segmentatable mask}, which is a binary segmentation whose structure ensures a topological separation of the image domain into two connected components. We analyze segmentation masks through the lens of digital topology and homology theory, extracting a $4$-curve candidate from the mask, verifying its topological validity using Betti numbers. A mask is considered Jordan-segmentatable when this candidate forms a digital 4-curve with $β_0 = β_1 = 1$, or equivalently when its complement splits into exactly two $8$-connected components. This framework provides a mathematically rigorous, unsupervised criterion with which to assess the structural coherence of segmentation masks. By combining digital Jordan theory and homological invariants, our approach provides a valuable alternative to standard evaluation metrics, especially in applications where topological correctness must be preserved."
  },
  {
    "date": "2026-01-15",
    "title": "Hydrodynamic Limit with a Weierstrass-type result",
    "authors": "Gabriel S. Nahum",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10568v1",
    "source": "arXiv",
    "abstract": "We show that any positive, continuous, and bounded function can be realised as the diffusion coefficient of an evolution equation associated with a gradient interacting particle system. The proof relies on the construction of an appropriate model and on the entropy method."
  },
  {
    "date": "2026-01-15",
    "title": "Generative AI collective behavior needs an interactionist paradigm",
    "authors": "Laura Ferrarotti, Gian Maria Campedelli, Roberto Dessì, Andrea Baronchelli, Giovanni Iacca, Kathleen M. Carley, Alex Pentland, Joel Z. Leibo, James Evans, Bruno Lepri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10567v1",
    "source": "arXiv",
    "abstract": "In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning--motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical tools, in order to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. We propose and discuss four directions that we consider crucial for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue."
  },
  {
    "date": "2026-01-15",
    "title": "Rapid post-merger signal of circularly polarized gravitational wave from magnetic black hole superradiance: novel approach to detect magnetic monopole",
    "authors": "Zhong-Hao Luo, Fa Peng Huang, Pengming Zhang, Chen Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10552v1",
    "source": "arXiv",
    "abstract": "We present an analytic framework demonstrating that a spinning black hole endowed with a net magnetic charge exhibits a dramatically amplified superradiant instability against charged scalar fields, enhanced by several orders of magnitude compared with the neutral Kerr case. The amplification arises from a monopole induced reduction of the centrifugal barrier. This shift deepens the gravitational bound-state potential well and produces a parametrically larger instability growth rate. This resulting rapid growth yields a macroscopic boson cloud that acts as a coherent source of near monochromatic continuous gravitational waves (GWs). We find an enhanced GW power. Monopole harmonic selection rules restrict the emission from the north (south) clouds corresponding to opposite helicities. Their superposition generates an (approximately) circularly polarized continuous GWs at a fixed sky location within even parity general relativity, distinct from the generic elliptical polarization of the Kerr case. In light of these new findings, we propose a potential smoking-gun search strategy for magnetic monopole and ultralight boson: the rapid post-merger follow-up GW signals from binary-black-hole merger remnants through ground-based and space-based GW experiments. In contrast to the Kerr case, where the signal turn-on can be delayed to decades-centuries, a magnetic remnant can form a cloud and emit a stronger, circularly polarized continuous GWs within weeks to months. Taking the magnetic supermassive remnants as an example, we demonstrate that the rapid follow-up GW signal in the mHz band appears just in few weeks after binary black hole mergers. Moreover, future polarization (ellipticity) measurements can distinguish the magnetic scenario from Kerr while providing a parity-even mechanism for circularly polarized GWs in general relativity."
  },
  {
    "date": "2026-01-15",
    "title": "Enhancing the quality of gauge images captured in smoke and haze scenes through deep learning",
    "authors": "Oscar H. Ramírez-Agudelo, Akshay N. Shewatkar, Edoardo Milana, Roland C. Aydin, Kai Franke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10537v1",
    "source": "arXiv",
    "abstract": "Images captured in hazy and smoky environments suffer from reduced visibility, posing a challenge when monitoring infrastructures and hindering emergency services during critical situations. The proposed work investigates the use of the deep learning models to enhance the automatic, machine-based readability of gauge in smoky environments, with accurate gauge data interpretation serving as a valuable tool for first responders. The study utilizes two deep learning architectures, FFA-Net and AECR-Net, to improve the visibility of gauge images, corrupted with light up to dense haze and smoke. Since benchmark datasets of analog gauge images are unavailable, a new synthetic dataset, containing over 14,000 images, was generated using the Unreal Engine. The models were trained with an 80\\% train, 10\\% validation, and 10\\% test split for the haze and smoke dataset, respectively. For the synthetic haze dataset, the SSIM and PSNR metrics are about 0.98 and 43\\,dB, respectively, comparing well to state-of-the art results. Additionally, more robust results are retrieved from the AECR-Net, when compared to the FFA-Net. Although the results from the synthetic smoke dataset are poorer, the trained models achieve interesting results. In general, imaging in the presence of smoke are more difficult to enhance given the inhomogeneity and high density. Secondly, FFA-Net and AECR-Net are implemented to dehaze and not to desmoke images. This work shows that use of deep learning architectures can improve the quality of analog gauge images captured in smoke and haze scenes immensely. Finally, the enhanced output images can be successfully post-processed for automatic autonomous reading of gauges"
  },
  {
    "date": "2026-01-15",
    "title": "SVII-3D: Advancing Roadside Infrastructure Inventory with Decimeter-level 3D Localization and Comprehension from Sparse Street Imagery",
    "authors": "Chong Liu, Luxuan Fu, Yang Jia, Zhen Dong, Bisheng Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10535v1",
    "source": "arXiv",
    "abstract": "The automated creation of digital twins and precise asset inventories is a critical task in smart city construction and facility lifecycle management. However, utilizing cost-effective sparse imagery remains challenging due to limited robustness, inaccurate localization, and a lack of fine-grained state understanding. To address these limitations, SVII-3D, a unified framework for holistic asset digitization, is proposed. First, LoRA fine-tuned open-set detection is fused with a spatial-attention matching network to robustly associate observations across sparse views. Second, a geometry-guided refinement mechanism is introduced to resolve structural errors, achieving precise decimeter-level 3D localization. Third, transcending static geometric mapping, a Vision-Language Model agent leveraging multi-modal prompting is incorporated to automatically diagnose fine-grained operational states. Experiments demonstrate that SVII-3D significantly improves identification accuracy and minimizes localization errors. Consequently, this framework offers a scalable, cost-effective solution for high-fidelity infrastructure digitization, effectively bridging the gap between sparse perception and automated intelligent maintenance."
  },
  {
    "date": "2026-01-15",
    "title": "Coarsening Causal DAG Models",
    "authors": "Francisco Madaleno, Pratik Misra, Alex Markham",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10531v1",
    "source": "arXiv",
    "abstract": "Directed acyclic graphical (DAG) models are a powerful tool for representing causal relationships among jointly distributed random variables, especially concerning data from across different experimental settings. However, it is not always practical or desirable to estimate a causal model at the granularity of given features in a particular dataset. There is a growing body of research on causal abstraction to address such problems. We contribute to this line of research by (i) providing novel graphical identifiability results for practically-relevant interventional settings, (ii) proposing an efficient, provably consistent algorithm for directly learning abstract causal graphs from interventional data with unknown intervention targets, and (iii) uncovering theoretical insights about the lattice structure of the underlying search space, with connections to the field of causal discovery more generally. As proof of concept, we apply our algorithm on synthetic and real datasets with known ground truths, including measurements from a controlled physical system with interacting light intensity and polarization."
  },
  {
    "date": "2026-01-15",
    "title": "Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition",
    "authors": "Yijin Zhou, Fu Li, Yi Niu, Boxun Fu, Huaning Wang, Lijian Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10525v1",
    "source": "arXiv",
    "abstract": "Understanding how local neurophysiological patterns interact with global brain dynamics is essential for decoding human emotions from EEG signals. However, existing deep learning approaches often overlook the brain's intrinsic spatial organization, failing to simultaneously capture local topological relations and global dependencies. To address these challenges, we propose Neuro-HGLN, a Neurologically-informed Hierarchical Graph-Transformer Learning Network that integrates biologically grounded priors with hierarchical representation learning. Neuro-HGLN first constructs a spatial Euclidean prior graph based on physical electrode distances to serve as an anatomically grounded inductive bias. A learnable global dynamic graph is then introduced to model functional connectivity across the entire brain. In parallel, to capture fine-grained regional dependencies, Neuro-HGLN builds region-level local graphs using a multi-head self-attention mechanism. These graphs are processed synchronously through local-constrained parallel GCN layers to produce region-specific representations. Subsequently, an iTransformer encoder aggregates these features to capture cross-region dependencies under a dimension-as-token formulation. Extensive experiments demonstrate that Neuro-HGLN achieves state-of-the-art performance on multiple benchmarks, providing enhanced interpretability grounded in neurophysiological structure. These results highlight the efficacy of unifying local topological learning with cross-region dependency modeling for robust EEG emotion recognition."
  },
  {
    "date": "2026-01-15",
    "title": "BikeActions: An Open Platform and Benchmark for Cyclist-Centric VRU Action Recognition",
    "authors": "Max A. Buettner, Kanak Mazumder, Luca Koecher, Mario Finkbeiner, Sebastian Niebler, Fabian B. Flohr",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10521v1",
    "source": "arXiv",
    "abstract": "Anticipating the intentions of Vulnerable Road Users (VRUs) is a critical challenge for safe autonomous driving (AD) and mobile robotics. While current research predominantly focuses on pedestrian crossing behaviors from a vehicle's perspective, interactions within dense shared spaces remain underexplored. To bridge this gap, we introduce FUSE-Bike, the first fully open perception platform of its kind. Equipped with two LiDARs, a camera, and GNSS, it facilitates high-fidelity, close-range data capture directly from a cyclist's viewpoint. Leveraging this platform, we present BikeActions, a novel multi-modal dataset comprising 852 annotated samples across 5 distinct action classes, specifically tailored to improve VRU behavior modeling. We establish a rigorous benchmark by evaluating state-of-the-art graph convolution and transformer-based models on our publicly released data splits, establishing the first performance baselines for this challenging task. We release the full dataset together with data curation tools, the open hardware design, and the benchmark code to foster future research in VRU action understanding under https://iv.ee.hm.edu/bikeactions/."
  },
  {
    "date": "2026-01-15",
    "title": "From rough to multifractal multidimensional volatility: A multidimensional Log S-fBM model",
    "authors": "Othmane Zarhali, Emmanuel Bacry, Jean-François Muzy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10517v1",
    "source": "arXiv",
    "abstract": "We introduce the multivariate Log S-fBM model (mLog S-fBM), extending the univariate framework proposed by Wu \\textit{et al.} to the multidimensional setting. We define the multidimensional Stationary fractional Brownian motion (mS-fBM), characterized by marginals following S-fBM dynamics and a specific cross-covariance structure. It is parametrized by a correlation scale $T$, marginal-specific intermittency parameters and Hurst exponents, as well as their multidimensional counterparts: the co-intermittency matrix and the co-Hurst matrix. The mLog S-fBM is constructed by modeling volatility components as exponentials of the mS-fBM, preserving the dependence structure of the Gaussian core. We demonstrate that the model is well-defined for any co-Hurst matrix with entries in $[0, \\frac{1}{2}[$, supporting vanishing co-Hurst parameters to bridge rough volatility and multifractal regimes. We generalize the small intermittency approximation technique to the multivariate setting to develop an efficient Generalized Method of Moments calibration procedure, estimating cross-covariance parameters for pairs of marginals. We validate it on synthetic data and apply it to S\\&P 500 market data, modeling stock return fluctuations. Diagonal estimates of the stock Hurst matrix, corresponding to single-stock log-volatility Hurst exponents, are close to 0, indicating multifractal behavior, while co-Hurst off-diagonal entries are close to the Hurst exponent of the S\\&P 500 index ($H \\approx 0.12$), and co-intermittency off-diagonal entries align with univariate intermittency estimates."
  },
  {
    "date": "2026-01-15",
    "title": "sponchpop II: Population Synthesis to Investigate Volatile Sulfur as a Fingerprint of Gas Giant Formation Histories",
    "authors": "Anna Sommerville-Thomas, Mihkel Kama, Oliver Shottle, Jason Ran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10508v1",
    "source": "arXiv",
    "abstract": "Planet population synthesis is an integral tool for linking exoplanets to their formation environments. Most planet population synthesis studies have focused on the carbon-to-oxygen ratio (C/O) in gas or solids, yet more insight into planet formation may be afforded by considering a wider suite of elements. Sulfur is one such key element. It has been assumed to be entirely refractory in population synthesis models, restricting it to being a tracer of accreted rocky solids. However, sulfur also has a volatile reservoir dominant at the onset of star and planet formation. We investigate sulfur's wider potential as a formation history tracer by implementing the first multi-phase treatment of S in a planet population synthesis model. We present the planet formation module of \\textsc{sponchpop} and its first predicted planet growth tracks and populations. We explore the diversity of planet compositions in terms of their sulfur budget, including both refractory and volatile components, and apply a novel gas-grain conversion of sulfur to study how formation trajectories of giant planets relate to final core and envelope compositions. We show that planets inherit a wide range of core and envelope sulfur content related to accretion history while considering late-stage planetesimal infall, providing a new diagnostic tool for planet formation. The diverse sulfur content of planet cores suggests some rocky planets may be born sulfur-poor, with implications for their geochemistry and habitability. Enhanced sulfur abundances in gas-giant atmospheres can be attributed to formation beyond the H2S iceline, such as the giants in our Solar System."
  },
  {
    "date": "2026-01-15",
    "title": "Growth and Morphology of InN Nanowires on Si<111> and Si<100> at Back-End-Of-Line Compatible Temperatures",
    "authors": "Andrea Orlando-cunnac, Arthur Arnaud, Martien Den Hertog, Ettore Coccato, Vincent Calvo, Jonathan Steckel, Eva Monroy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10495v1",
    "source": "arXiv",
    "abstract": "InN nanowires were grown on Si<111> and Si<100> substrates by plasma-assisted molecular beam epitaxy using a thin AlN buffer layer at temperatures compatible with the thermal budget limitation imposed by Back-End-Of-Line processing. Reflection high-energy electron diffraction reveals different nucleation behaviors on the two substrate orientations, with higher structural disorder in the case of Si<100>. However, vertically aligned nanowires with hexagonal cross section and N polarity are obtained on both substrates. A statistical analysis of nanowire morphology as a function of growth temperature indicates similar trends in diameter, density, and length on Si<111> and Si<100>, which are explained by adatom kinetics during growth. Nanowires on Si<100> exhibit improved uniformity and reduced tapering, attributed to the different nanowire nucleation due to microstructural properties of the AlN buffer layer. The results demonstrate the feasibility of growing high-quality InN nanowires on Si<100>, supporting their potential for monolithic integration of nanowire-based photodetectors on silicon."
  },
  {
    "date": "2026-01-15",
    "title": "Effects of Integrated Heatsinking on Superconductivity in Tantalum Nitride Nanowires at the 300 Millimeter Scale",
    "authors": "Ekta Bhatia, Tharanga R. Nanayakkara, Chenyu Zhou, Tuan Vo, Wenli Collison, Jakub Nalaskowski, Stephen Olson, Soumen Kar, Hunter Frost, John Mucci, Brian Martinick, Ilyssa Wells, Thomas Murray, Corbet Johnson, Charles T Black, Mingzhao Liu, Satyavolu S Papa Rao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10480v1",
    "source": "arXiv",
    "abstract": "We report the superconducting properties of tantalum nitride (TaN) nanowires and TaN/copper (TaN/Cu) bilayer nanowires fabricated on 300 mm silicon wafers using CMOS-compatible processes. We evaluate how an integrated Cu heatsink modifies the superconducting response of TaN nanowires by improving thermal dissipation without significantly compromising key superconducting parameters. Through analysis of hysteresis in current-voltage curves, we demonstrate that Cu integration improves heat dissipation, supporting expectations of faster reset times in superconducting nanowire single-photon detectors (SNSPDs), consistent with enhanced heat transfer away from the hot spot. Using the Skocpol-Beasley-Tinkham (SBT) hotspot model, we quantify the Cu-enabled improvement in heat transfer as an approximately 100x increase in the SBT slope parameter beta and effective interfacial heat-transfer efficiency compared to TaN nanowires. The near-unity ratio of critical to retrapping current in TaN/Cu bilayer nanowires provides another evidence of efficient heat removal enabled by the integrated Cu layer. Our results show a zero-temperature Ginzburg-Landau coherence length of 7 nm and a critical temperature of 4.1 K for 39 nm thick TaN nanowires. The nanowires show <5% variation in critical dimensions, room-temperature resistance, residual resistance ratio, critical temperature, and critical current across the 300 mm wafer for all measured linewidths, demonstrating excellent process uniformity and scalability. These results indicate the trade-offs between superconducting performance and heat-sinking efficiency in TaN/Cu bilayer nanowires. They also underscore the viability of wafer-scale fabrication for fast, large-area SNSPD arrays for applications in photonic quantum computing, cosmology, and neuromorphic computing devices."
  },
  {
    "date": "2026-01-15",
    "title": "Quantum Theory and Unusual Dielectric Functions of Graphene",
    "authors": "V. M. Mostepanenko, G. L. Klimchitskaya",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10478v1",
    "source": "arXiv",
    "abstract": "We address the spatially nonlocal dielectric functions of graphene at any frequency derived starting fromthe first principles of thermal quantum field theory using the formalism of the polarization tensor. After a brief review of this formalism, the longitudinal and transverse dielectric functions are considered at any relationship between the frequency and the wave vector. The analytic properties of their real and imaginary parts are investigated at low and high frequencies. Emphasis is given to the double pole at zero frequency which arises in the transverse dielectric function. The role of this unusual property for solving the problem of disagreement between experiment and theory in the Casimir effect is discussed. We guess that a more complete dielectric response of ordinary metals should also be spatially nonlocal and its transverse part may possess the double pole in the region of evanescent waves."
  },
  {
    "date": "2026-01-15",
    "title": "On Generalized Strong and Norm Resolvent Convergence",
    "authors": "Gerald Teschl, Yifei Wang, Bing Xie, Zhe Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10476v1",
    "source": "arXiv",
    "abstract": "We present a streamlined approach for generalized strong and norm convergence of self-adjoint operators in different Hilbert spaces. In particular, we establish convergence of associated (semi-)groups, (essential) spectra and spectral projections. In addition, we give some applications to Sturm-Liouville operators."
  },
  {
    "date": "2026-01-15",
    "title": "Positive Damping Region: A Graphic Tool for Passivization Analysis with Passivity Index",
    "authors": "Xiaoyu Peng, Xi Ru, Zhongze Li, Jianxin Zhang, Xinghua Chen, Feng Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10475v1",
    "source": "arXiv",
    "abstract": "This paper presents a geometric framework for analyzing output-feedback and input-feedforward passivization of linear time-invariant systems. We reveal that a system is passivizable with a given passivity index when the Nyquist plot for SISO systems or the Rayleigh quotient of the transfer function for MIMO systems lies within a specific, index-dependent region in the complex plane, termed the positive damping region. The criteria enable a convenient graphic tool for analyzing the passivization, the associated frequency bands, the maximum achievable passivity index, and the waterbed effect between them. Additionally, the tool can be encoded into classical tools such as the Nyquist plot, the Nichols plot, and the generalized KYP lemma to aid control design. Finally, we demonstrate its application in passivity-based power system stability analysis and discuss its implications for electrical engineers regarding device controller design trade-offs."
  },
  {
    "date": "2026-01-15",
    "title": "On the projective dimension of some deformations of Weyl arrangements",
    "authors": "Takuro Abe, Daniele Faenzi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10466v1",
    "source": "arXiv",
    "abstract": "We show that the logarithmic derivation module of (the cone of) the deformation A of a Weyl arrangement associated with a root system of simply laced type has projective dimension one if the deforming parameter ranges from -j to j+2. In addition, we give an explicit minimal free resolution when the root system is of type A3 and B2. Moreover, in the second case, we determine the jumping lines of maximal jumping order of the associated vector bundle. When the deforming parameter of A (respectively A') ranges from -k to k+j (respectively, from -k' to k'+j), with k different from k' and j at least 3, this allows to distinguish D0(A) from D0(A') shifted by 4(k'-k), even though these modules have the same graded Betti numbers."
  },
  {
    "date": "2026-01-15",
    "title": "MitoFREQ: A Novel Approach for Mitogenome Frequency Estimation from Top-level Haplogroups and Single Nucleotide Variants",
    "authors": "Mikkel Meyer Andersen, Nicole Huber, Kimberly S Andreaggi, Tóra Oluffa Stenberg Olsen, Walther Parson, Charla Marshall",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10464v1",
    "source": "arXiv",
    "abstract": "Lineage marker population frequencies can serve as one way to express evidential value in forensic genetics. However, for high-quality whole mitochondrial DNA genome sequences (mitogenomes), population data remain limited. In this paper, we offer a new method, MitoFREQ, for estimating the population frequencies of mitogenomes. MitoFREQ uses the mitogenome resources HelixMTdb and gnomAD, harbouring information from 195,983 and 56,406 mitogenomes, respectively. Neither HelixMTdb nor gnomAD can be queried directly for individual mitogenome frequencies, but offers single nucleotide variant (SNV) allele frequencies for each of 30 \"top-level\" haplogroups (TLHG). We propose using the HelixMTdb and gnomAD resources by classifying a given mitogenome within the TLHG scheme and subsequently using the frequency of its rarest SNV within that TLHG weighted by the TLHG frequency. We show that this method is guaranteed to provide a higher population frequency estimate than if a refined haplogroup and its SNV frequencies were used. Further, we show that top-level haplogrouping can be achieved by using only 227 specific positions for 99.9% of the tested mitogenomes, potentially making the method available for low-quality samples. The method was tested on two types of datasets: high-quality forensic reference datasets and a diverse collection of scrutinised mitogenomes from GenBank. This dual evaluation demonstrated that the approach is robust across both curated forensic data and broader population-level sequences. This method produced likelihood ratios in the range of 100-100,000, demonstrating its potential to strengthen the statistical evaluation of forensic mtDNA evidence. We have developed an open-source R package `mitofreq` that implements our method, including a Shiny app where custom TLHG frequencies can be supplied."
  },
  {
    "date": "2026-01-15",
    "title": "Stable Differentiable Modal Synthesis for Learning Nonlinear Dynamics",
    "authors": "Victor Zheleznov, Stefan Bilbao, Alec Wright, Simon King",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10453v1",
    "source": "arXiv",
    "abstract": "Modal methods are a long-standing approach to physical modelling synthesis. Extensions to nonlinear problems are possible, including the case of a high-amplitude vibration of a string. A modal decomposition leads to a densely coupled nonlinear system of ordinary differential equations. Recent work in scalar auxiliary variable techniques has enabled construction of explicit and stable numerical solvers for such classes of nonlinear systems. On the other hand, machine learning approaches (in particular neural ordinary differential equations) have been successful in modelling nonlinear systems automatically from data. In this work, we examine how scalar auxiliary variable techniques can be combined with neural ordinary differential equations to yield a stable differentiable model capable of learning nonlinear dynamics. The proposed approach leverages the analytical solution for linear vibration of system's modes so that physical parameters of a system remain easily accessible after the training without the need for a parameter encoder in the model architecture. As a proof of concept, we generate synthetic data for the nonlinear transverse vibration of a string and show that the model can be trained to reproduce the nonlinear dynamics of the system. Sound examples are presented."
  },
  {
    "date": "2026-01-15",
    "title": "TOI-3862 b: A dense super-Neptune deep in the hot Neptune desert",
    "authors": "Ilaria Carleo, Amadeo Castro-González, Enric Pallé, Felipe Murgas, Grzegorz Nowak, Gaia Lacedelli, Thomas Masseron, Emily W. Wong, Patrick Eggenberger, Vincent Bourrier, Dawid Jankowski, Krzysztof Goździewski, Douglas R. Alves, James S. Jenkins, Sergio Messina, Keivan G. Stassun, Jose I. Vines, Matteo Brogi, David R. Ciardi, Catherine A. Clark, William Cochran, Karen A. Collins, Hans J. Deeg, Elise Furlan, Davide Gandolfi, Samuel Geraldía González, Artie P. Hatzes, Coel Hellier, Steve B. Howell, Judith Korth, Jorge Lillo-Box, John H. Livingston, Jaume Orell-Miquel, Carina M. Persson, Seth Redfield, Boris Safonov, David Baker, Rafael Delfin Barrena Delgado, Allyson Bieryla, Andrew Boyle, Pau Bosch-Cabot, Núria Casasayas Barris, Stavros Chairetas, Jerome P. de Leon, Izuru Fukuda, Akihiko Fukui, Pere Guerra, Kai Ikuta, Kiyoe Kawauchi, Emil Knudstrup, Florence Libotte, Michael B. Lund, Rafael Luque, Eduardo Lorenzo Martín Guerrero de Escalante, Bob Massey, Edward J. Michaels, Giuseppe Morello, Norio Narita, Hannu Parvianien, Richard P. Schwarz, Avi Shporer, Monika Stangret, Noriharu Watanabe, Cristilyn N. Watkins",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10450v1",
    "source": "arXiv",
    "abstract": "The structure and evolution of close-in exoplanets are shaped by atmospheric loss and migration processes, which give rise to key population features such as the hot Neptune desert, ridge, and savanna - regions of the period-radius space whose boundaries offer critical insights into planetary formation and survival. As part of the KESPRINT collaboration, we selected the TESS transiting planet candidate TOI-3862.01 for radial velocity follow-up to confirm its planetary nature and characterize its mass and bulk properties. This planet candidate is of particular interest due to its position in the middle of the hot Neptune desert, making it a valuable probe for testing theories of planet migration and atmospheric loss. We confirmed the planetary nature and determined the mass of TOI-3862.01 (hereinafter TOI-3862b) by performing a joint fit with both transit and radial velocity data, precisely characterizing the bulk properties of this planet. TOI-3862b is a super-Neptune on a 1.56-day orbit around a Sun-like star with an effective temperature of 5300$\\pm$50K. It has a mass of 53.7$_{-2.9}^{+2.8}$ M$_{\\oplus}$ and a radius of 5.53$\\pm$0.18 R$_{\\oplus}$, corresponding to a density of 1.7$\\pm$0.2 g/cm^3. This places it among the rare population of hot and dense super-Neptune desert planets. TOI-3862b, residing deep in the hot Neptune desert, represents a rare occurrence in an otherwise sparsely populated region, offering a valuable opportunity to probe the processes that may allow planets to survive in such environments."
  },
  {
    "date": "2026-01-15",
    "title": "Lunar-G2R: Geometry-to-Reflectance Learning for High-Fidelity Lunar BRDF Estimation",
    "authors": "Clementine Grethen, Nicolas Menga, Roland Brochard, Geraldine Morin, Simone Gasparini, Jeremy Lebreton, Manuel Sanchez Gestido",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10449v1",
    "source": "arXiv",
    "abstract": "We address the problem of estimating realistic, spatially varying reflectance for complex planetary surfaces such as the lunar regolith, which is critical for high-fidelity rendering and vision-based navigation. Existing lunar rendering pipelines rely on simplified or spatially uniform BRDF models whose parameters are difficult to estimate and fail to capture local reflectance variations, limiting photometric realism. We propose Lunar-G2R, a geometry-to-reflectance learning framework that predicts spatially varying BRDF parameters directly from a lunar digital elevation model (DEM), without requiring multi-view imagery, controlled illumination, or dedicated reflectance-capture hardware at inference time. The method leverages a U-Net trained with differentiable rendering to minimize photometric discrepancies between real orbital images and physically based renderings under known viewing and illumination geometry. Experiments on a geographically held-out region of the Tycho crater show that our approach reduces photometric error by 38 % compared to a state-of-the-art baseline, while achieving higher PSNR and SSIM and improved perceptual similarity, capturing fine-scale reflectance variations absent from spatially uniform models. To our knowledge, this is the first method to infer a spatially varying reflectance model directly from terrain geometry."
  },
  {
    "date": "2026-01-15",
    "title": "Linear identities for partition pairs with $4$-cores",
    "authors": "Russelle Guadalupe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10438v1",
    "source": "arXiv",
    "abstract": "We determine an infinite family of linear identities for the number $A_4(n)$ of partition pairs of $n$ with $4$-cores by employing elementary $q$-series techniques and certain $3$-dissection formulas. We then discover an infinite family of congruences for $A_4(n)$ as a consequence of these linear identities."
  },
  {
    "date": "2026-01-15",
    "title": "Analyzing intermittent stochastic gravitational wave background I:Effect of detector response",
    "authors": "Xiaolin Liu, Sachiko Kuroyanagi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10428v1",
    "source": "arXiv",
    "abstract": "With the growing number of gravitational-wave detections, particularly from binary black hole mergers, there is increasing anticipation that an astrophysical background, formed by an ensemble of faint, high-redshift events, will be observed in the near future by the ground-based detector network. This background is anticipated to exhibit non-Gaussian statistical properties. To develop a robust method for detecting such a non-Gaussian gravitational-wave background, we revisit optimal detection strategies based on the Gaussian-mixture likelihood model. In this work, we demonstrate that properly accounting for the detector antenna pattern is essential. Current approaches typically rely on the overlap reduction function averaged over the sky. Through simulations, we show that using such an averaged response introduces significant biases in parameter estimation. In addition, we propose a computationally feasible method that incorporates second-order corrections as an approximation of the full integral over the source distribution. Our results indicate that this approach effectively eliminates these biases. We also show that our method remains robust even when considering anisotropic backgrounds."
  },
  {
    "date": "2026-01-15",
    "title": "Algebraic functional equation for big Galois representations over multiple $\\mathbb{Z}_p$-extensions",
    "authors": "Zeping Hao, Meng Fai Lim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10426v1",
    "source": "arXiv",
    "abstract": "We present a general approach to establish algebraic functional equations for big Galois representations over multiple $\\mathbb{Z}_p$-extensions. Our result is formulated in both Selmer group and Selmer complex settings, and encompasses a broad range of Iwasawa-theoretic scenarios. In particular, our result applies to the triple product of Hida families in both balanced and unbalanced cases, as well as the half-ordinary Rankin-Selberg universal deformations recently studied by the first named author and Loeffler. Our result also significantly generalizes many previously known cases of algebraic functional equations and answers a question of Greenberg."
  },
  {
    "date": "2026-01-15",
    "title": "Positivity of Schur forms for Griffiths positive vector bundles of rank three over complex threefolds",
    "authors": "Xueyuan Wan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10424v1",
    "source": "arXiv",
    "abstract": "In this paper, we prove the positivity of the double mixed discriminant associated with a positive linear map between spaces of \\(3\\times 3\\) complex matrices, thereby settling the three-dimensional case of Finski's open problem. As an application, we show that all Schur forms are weakly positive for Griffiths positive Hermitian holomorphic vector bundles of rank three over complex threefolds. This yields a complete affirmative answer, in the case where both the rank and the dimension are three, to the question posed by Griffiths in 1969."
  },
  {
    "date": "2026-01-15",
    "title": "CtD: Composition through Decomposition in Emergent Communication",
    "authors": "Boaz Carmeli, Ron Meir, Yonatan Belinkov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10169v1",
    "source": "arXiv",
    "abstract": "Compositionality is a cognitive mechanism that allows humans to systematically combine known concepts in novel ways. This study demonstrates how artificial neural agents acquire and utilize compositional generalization to describe previously unseen images. Our method, termed \"Composition through Decomposition\", involves two sequential training steps. In the 'Decompose' step, the agents learn to decompose an image into basic concepts using a codebook acquired during interaction in a multi-target coordination game. Subsequently, in the 'Compose' step, the agents employ this codebook to describe novel images by composing basic concepts into complex phrases. Remarkably, we observe cases where generalization in the `Compose' step is achieved zero-shot, without the need for additional training."
  },
  {
    "date": "2026-01-15",
    "title": "Credit C-GPT: A Domain-Specialized Large Language Model for Conversational Understanding in Vietnamese Debt Collection",
    "authors": "Nhung Nguyen Thi Hong, Cuong Nguyen Dang, Tri Le Ngoc",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10167v1",
    "source": "arXiv",
    "abstract": "Debt collection is a critical function within the banking, financial services, and insurance (BFSI) sector, relying heavily on large-scale human-to-human conversational interactions conducted primarily in Vietnamese contact centers. These conversations involve informal spoken language, emotional variability, and complex domain-specific reasoning, which pose significant challenges for traditional natural language processing systems. This paper introduces Credit C-GPT, a domain-specialized large language model with seven billion parameters, fine-tuned for conversational understanding in Vietnamese debt collection scenarios. The proposed model integrates multiple conversational intelligence tasks, including dialogue understanding, sentiment recognition, intent detection, call stage classification, and structured slot-value extraction, within a single reasoning-based framework. We describe the data construction process, annotation strategy, and training methodology, and evaluate the model on proprietary human-annotated datasets. Experimental results show consistent improvements over traditional pipeline-based approaches, indicating that domain-specialized conversational language models provide a scalable and privacy-aware solution for real-time assistance and post-call analytics in enterprise contact centers."
  },
  {
    "date": "2026-01-15",
    "title": "Computing Statistical Properties of Velocity Fields on Current Quantum Hardware",
    "authors": "Miriam Goldack, Yosi Atia, Ori Alberton, Karl Jansen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10166v1",
    "source": "arXiv",
    "abstract": "Quantum algorithms are gaining attention in Computational Fluid Dynamics (CFD) for their favorable scaling, as encoding physical fields into quantum probability amplitudes enables representation of two to the power of n spatial points with only n qubits. A key challenge in Quantum CFD is the efficient readout of simulation results, a topic that has received limited attention in literature. This work presents methods to extract statistical properties of spatial velocity fields, such as central moments and structure functions, directly from parameterized ansatz circuits, avoiding full quantum state tomography. As a proof of concept, we implement our approach for 1D velocity fields, encoding 16 spatial points with 4 qubits, and analyze both a sine wave signal and four snapshots from Burgers' equation evolution. Using Qedma's error mitigation software QESEM, we demonstrate that such computations achieve high accuracy on current quantum devices, specifically IBMQ's Heron2 system ibm_fez."
  },
  {
    "date": "2026-01-15",
    "title": "Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment",
    "authors": "Cameron Tice, Puria Radmard, Samuel Ratnam, Andy Kim, David Africa, Kyle O'Brien",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10160v1",
    "source": "arXiv",
    "abstract": "Pretraining corpora contain extensive discourse about AI systems, yet the causal influence of this discourse on downstream alignment remains poorly understood. If prevailing descriptions of AI behaviour are predominantly negative, LLMs may internalise corresponding behavioural priors, giving rise to self-fulfilling misalignment. This paper provides the first controlled study of this hypothesis by pretraining 6.9B-parameter LLMs with varying amounts of (mis)alignment discourse. We find that discussion of AI contributes to misalignment. Upsampling synthetic training documents about AI misalignment leads to a notable increase in misaligned behaviour. Conversely, upsampling documents about aligned behaviour reduces misalignment scores from 45% to 9%. We consider this evidence of self-fulfilling alignment. These effects are dampened, but persist through post-training. Our findings establish the study of how pretraining data shapes alignment priors, or alignment pretraining, as a complement to post-training. We recommend practitioners pretrain for alignment as well as capabilities. Our models and datasets are available at alignmentpretraining.ai"
  },
  {
    "date": "2026-01-15",
    "title": "Electric field effects in one-dimensional spin-1/2 $K_1J_1Γ_1Γ_1^\\prime K_2J_2$ model with ferromagnetic Kitaev coupling",
    "authors": "Wang Yang, Helin Wang, Chao Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10158v1",
    "source": "arXiv",
    "abstract": "We perform a systematic study on the effects of electric fields in the Luttinger liquid phase of the one-dimensional spin-$1/2$ $K_1J_1Γ_1Γ_1^\\prime K_2J_2$ model in the region of ferromagnetic nearest-neighboring Kitaev coupling. We find that while electric fields along $(1,1,1)$-direction maintain the Luttinger liquid behavior, fields along other directions drive the system to a dimerized state. An estimation is made on how effective a $(1,1,1)$-field is for tuning the Luttinger parameter in real materials. Our work is useful for understanding the effects of electric fields in one-dimensional generalized Kitaev spin models, and provides a starting point for exploring the electric-field-related physics in two dimensions based on a quasi-one-dimensional approach."
  },
  {
    "date": "2026-01-15",
    "title": "MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning",
    "authors": "Yusong Wang, Jialun Shen, Zhihao Wu, Yicheng Xu, Shiyin Tan, Mingkun Xu, Changshuo Wang, Zixing Song, Prayag Tiwari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10157v1",
    "source": "arXiv",
    "abstract": "Graph Neural Networks (GNNs) have been widely adopted for Protein Representation Learning (PRL), as residue interaction networks can be naturally represented as graphs. Current GNN-based PRL methods typically rely on single-perspective graph construction strategies, which capture partial properties of residue interactions, resulting in incomplete protein representations. To address this limitation, we propose MMPG, a framework that constructs protein graphs from multiple perspectives and adaptively fuses them via Mixture of Experts (MoE) for PRL. MMPG constructs graphs from physical, chemical, and geometric perspectives to characterize different properties of residue interactions. To capture both perspective-specific features and their synergies, we develop an MoE module, which dynamically routes perspectives to specialized experts, where experts learn intrinsic features and cross-perspective interactions. We quantitatively verify that MoE automatically specializes experts in modeling distinct levels of interaction from individual representations, to pairwise inter-perspective synergies, and ultimately to a global consensus across all perspectives. Through integrating this multi-level information, MMPG produces superior protein representations and achieves advanced performance on four different downstream protein tasks."
  },
  {
    "date": "2026-01-15",
    "title": "LOOKAT: Lookup-Optimized Key-Attention for Memory-Efficient Transformers",
    "authors": "Aryan Karmore",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10155v1",
    "source": "arXiv",
    "abstract": "Compressing the KV cache is a required step to deploy large language models on edge devices. Current quantization methods compress storage but fail to reduce bandwidth as attention calculation requires dequantizing keys from INT4/INT8 to FP16 before use. We observe that attention scoring is mathematically equivalent to the inner product similarity search and we can apply some compression techniques from vector databases to compress KV-cache better. We propose LOOKAT, which applies product quantization and asymmetric distance computation, to transformer architecture by decomposing key vectors into subspaces, learning codebooks and computing attention tables via lookup tables. This transforms attention from memory-bound to compute-bound. LOOKAT achieves 64 $\\times$ compression at 95.7\\% output fidelity and 32 $\\times$ compression at 95.0\\% fidelity when tested on GPT-2. LOOKAT requires no architecture changes or training while maintaining rank correlation $ρ> 0.95$. Theoretical analysis confirms that rank correlation degrades as $O(d_k/mK)$, with guarantees validated across sequence lengths up to 1024 tokens."
  },
  {
    "date": "2026-01-15",
    "title": "Bridging Superconducting and Neutral-Atom Platforms for Efficient Fault-Tolerant Quantum Architectures",
    "authors": "Xiang Fang, Jixuan Ruan, Sharanya Prabhu, Ang Li, Travis Humble, Dean Tullsen, Yufei Ding",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10144v1",
    "source": "arXiv",
    "abstract": "The transition to the fault-tolerant era exposes the limitations of homogeneous quantum systems, where no single qubit modality simultaneously offers optimal operation speed, connectivity, and scalability. In this work, we propose a strategic approach to Heterogeneous Quantum Architectures (HQA) that synthesizes the distinct advantages of the superconducting (SC) and neutral atom (NA) platforms. We explore two architectural role assignment strategies based on hardware characteristics: (1) We offload the latency-critical Magic State Factory (MSF) to fast SC devices while performing computation on scalable NA arrays, a design we term MagicAcc, which effectively mitigates the resource-preparation bottleneck. (2) We explore a Memory-Compute Separation (MCSep) paradigm that utilizes NA arrays for high-density qLDPC memory storage and SC devices for fast surface-code processing. Our evaluation, based on a comprehensive end-to-end cost model, demonstrates that principled heterogeneity yields significant performance gains. Specifically, our designs achieve $752\\times$ speedup over NA-only baselines on average and reduce the physical qubit footprint by over $10\\times$ compared to SC-only systems. These results chart a clear pathway for leveraging cross-modality interconnects to optimize the space-time efficiency of future fault-tolerant quantum computers."
  },
  {
    "date": "2026-01-15",
    "title": "Effect of hole pitch reduction on electron transport and diffusion: A comparative simulation study of Triple GEM detectors",
    "authors": "Rajiv Gupta, Sunidhi Saxena, Ajay Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10139v1",
    "source": "arXiv",
    "abstract": "Advances in fabrication techniques and high-performance electronics have facilitated the development of fine-pitch Gas Electron Multipliers (GEMs). Earlier experimental and simulation findings suggest that these reduced-pitch GEMs can outperform the standard configuration in terms of effective gain, collection efficiency, and position resolution. However, a noticeable fraction of avalanche electrons is lost within the GEM systems, resulting in a degradation of charge collection efficiency. Therefore, a comprehensive simulation-based study is essential to provide deeper insights into the extent of degradation and its contributing factors. In this context, we employ ANSYS and Garfield++ to model the Triple GEM detectors with reduced pitch sizes of 90 and 60 $μ$m, and perform a comparative performance analysis with the standard configuration (pitch size: 140 $μ$m). At first, the simulation framework is validated by comparing the results of the standard configuration with available experimental data and previously reported simulation outcomes. Despite the characteristic gain offset, the framework remains physically consistent and reliable in capturing microscopic avalanche dynamics, reproducing the experimental trend. Following validation, we investigate electron losses at the metal electrodes and within the Kapton holes, electron transmission through the transfer and induction regions, electron diffusion on the induction electrode, and the overall collection efficiency. These parameters are analyzed as functions of GEM potential, outer hole diameter, inner hole diameter, Kapton thickness, metal thickness, and gas composition, thereby offering insights for designing efficient GEM detectors."
  },
  {
    "date": "2026-01-15",
    "title": "LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning",
    "authors": "Linquan Wu, Tianxiang Jiang, Yifei Dong, Haoyu Yang, Fengji Zhang, Shichaang Meng, Ai Xuan, Linqi Song, Jacky Keung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10129v1",
    "source": "arXiv",
    "abstract": "Current multimodal latent reasoning often relies on external supervision (e.g., auxiliary images), ignoring intrinsic visual attention dynamics. In this work, we identify a critical Perception Gap in distillation: student models frequently mimic a teacher's textual output while attending to fundamentally divergent visual regions, effectively relying on language priors rather than grounded perception. To bridge this, we propose LaViT, a framework that aligns latent visual thoughts rather than static embeddings. LaViT compels the student to autoregressively reconstruct the teacher's visual semantics and attention trajectories prior to text generation, employing a curriculum sensory gating mechanism to prevent shortcut learning. Extensive experiments show that LaViT significantly enhances visual grounding, achieving up to +16.9% gains on complex reasoning tasks and enabling a compact 3B model to outperform larger open-source variants and proprietary models like GPT-4o."
  },
  {
    "date": "2026-01-15",
    "title": "A Generalizable Framework for Building Executable Domain-Specific LLMs under Data Scarcity: Demonstration on Semiconductor TCAD Simulation",
    "authors": "Di Wang, Zhenhua Wu, Yu Liu, Kai Chang, Shaohua Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10128v1",
    "source": "arXiv",
    "abstract": "Scientific and engineering verticals often suffer from data scarcity and strict executability requirements: models must generate not only fluent text, but also syntactically valid, tool-compilable scripts. We present a schema-first alignment framework for building compact, executable domain-specific LLMs in low-resource settings. The framework integrates three core components: (i) large-scale synthetic QA data generation from expert documentation to instill foundational domain knowledge; (ii) a code-centric IR->DPO workflow that converts verified tool decks into interpretable intermediate representations (IR), performs equivalence-preserving diversification, and constructs preference pairs to directly optimize instruction compliance and code executability; and (iii) a controlled evaluation of Retrieval-Augmented Generation (RAG), showing that while RAG benefits general LLMs, it can marginally degrade the performance of already domain-aligned models. We demonstrate the framework by instantiating TcadGPT for semiconductor Technology Computer-Aided Design (TCAD). Using 1.5M synthetic QA pairs and an IR-driven DPO dataset, TcadGPT attains 85.6% semantic accuracy and an 80.0% syntax pass rate on SDE executability tests, substantially outperforming state-of-the-art general LLMs such as GPT-4o. To probe portability beyond TCAD, we apply the same recipe to the open-source FEM solver Elmer, observing consistent improvements in script-level success rates over general-purpose baselines. All datasets, benchmarks, and code (including P1, P2, and IR->DPO) are released for reproducibility. Together, these results suggest that the proposed framework provides a robust and reproducible path toward executable LLMs in specialized, data-scarce professional domains."
  },
  {
    "date": "2026-01-15",
    "title": "Bulk viscosity of quark matter across the QCD phase transitions",
    "authors": "Chong-long Xie, Guo-yun Shao, Ming-zheng-xuan Wu, Wei-bo He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10126v1",
    "source": "arXiv",
    "abstract": "Based on the kinetic theory with relaxation time approximation, we investigate the bulk viscosity ($ζ$) and its ratio to shear viscosity ($ζ/η$) of quark matter at finite temperature and chemical potential with the in-medium particle masses derived in the 2+1 flavor Polyakov-loop improved Nambu--Jona-Lasinio (PNJL) model. We explore the behaviors of specific bulk viscosity ($ζ/s$) and $ζ/η$ across different QCD phase transitions, including the Mott phase transition, the chiral crossover, and the first-order transition with the associated metastable phase. The calculation shows that both $ζ/s$ and $ζ/η$ are extremely small at high temperatures, approaching the nature of a conformal theory. Larger $ζ/s$ and $ζ/η$ are derived near the chiral phase transition at finite temperature. Along the chiral crossover line, $ζ/s$ and $ζ/η$ generally increase with decreasing temperature, though $ζ/η$ exhibits a slight decline near the critical endpoint (CEP). On the boundary of the first-order transition, $ζ/s$ shows a non-monotonic variation with temperature. Furthermore, an additional peak structure emerges beyond the chiral phase boundary for both $ζ/s$ and $ζ/η$, with magnitudes even exceeding those near the chiral crossover of $u, d$ quarks. Our analysis indicates this peak originates from the chiral crossover transformation of strange quark."
  },
  {
    "date": "2026-01-15",
    "title": "Calabi affine maximal surfaces and centroaffine Bernstein problems",
    "authors": "Yalin Sun, Cheng Xing, Ruiwei Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10125v1",
    "source": "arXiv",
    "abstract": "Motivated by Calabi's calculation of the second variation sign for locally strongly convex affine maximal surfaces in equiaffine geometry, we first prove that every Calabi extremal surface is also maximal in the Calabi affine geometry. By employing suitably chosen orthonormal frame fields and analyzing the corresponding Codazzi equations, we then obtain local classifications for certain special classes of Calabi affine maximal surfaces and hyperbolic centroaffine extremal surfaces. These examples inspire the construction of new, complete Calabi affine maximal surfaces and centroaffine extremal hypersurfaces. Notably, the complete centroaffine extremal hypersurfaces we establish answer all five centroaffine Bernstein problems posed by Li- Li-Simon in 2004."
  },
  {
    "date": "2026-01-15",
    "title": "Deriving Character Logic from Storyline as Codified Decision Trees",
    "authors": "Letian Peng, Kun Zhou, Longfei Yun, Yupeng Hou, Jingbo Shang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10080v1",
    "source": "arXiv",
    "abstract": "Role-playing (RP) agents rely on behavioral profiles to act consistently across diverse narrative contexts, yet existing profiles are largely unstructured, non-executable, and weakly validated, leading to brittle agent behavior. We propose Codified Decision Trees (CDT), a data-driven framework that induces an executable and interpretable decision structure from large-scale narrative data. CDT represents behavioral profiles as a tree of conditional rules, where internal nodes correspond to validated scene conditions and leaves encode grounded behavioral statements, enabling deterministic retrieval of context-appropriate rules at execution time. The tree is learned by iteratively inducing candidate scene-action rules, validating them against data, and refining them through hierarchical specialization, yielding profiles that support transparent inspection and principled updates. Across multiple benchmarks, CDT substantially outperforms human-written profiles and prior profile induction methods on $85$ characters across $16$ artifacts, indicating that codified and validated behavioral representations lead to more reliable agent grounding."
  },
  {
    "date": "2026-01-15",
    "title": "P-norm based Fractional-Order Robust Subband Adaptive Filtering Algorithm for Impulsive Noise and Noisy Input",
    "authors": "Jianhong Ye, Haiquan Zhao, Yi Peng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10074v1",
    "source": "arXiv",
    "abstract": "Building upon the mean p-power error (MPE) criterion, the normalized subband p-norm (NSPN) algorithm demonstrates superior robustness in $α$-stable noise environments ($1 < α\\leq 2$) through effective utilization of low-order moment hidden in robust loss functions. Nevertheless, its performance degrades significantly when processing noise input or additive noise characterized by $α$-stable processes ($0 < α\\leq 1$). To overcome these limitations, we propose a novel fractional-order NSPN (FoNSPN) algorithm that incorporates the fractional-order stochastic gradient descent (FoSGD) method into the MPE framework. Additionally, this paper also analyzes the convergence range of its step-size, the theoretical domain of values for the fractional-order $β$, and establishes the theoretical steady-state mean square deviation (MSD) model. Simulations conducted in diverse impulsive noise environments confirm the superiority of the proposed FoNSPN algorithm against existing state-of-the-art algorithms."
  },
  {
    "date": "2026-01-15",
    "title": "Optimal qudit overlapping tomography and optimal measurement order",
    "authors": "Shuowei Ma, Qianfan Wang, Lvzhou Li, Fei Shi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10059v1",
    "source": "arXiv",
    "abstract": "Quantum state tomography is essential for characterizing quantum systems, but it becomes infeasible for large systems due to exponential resource scaling. Overlapping tomography addresses this challenge by reconstructing all $k$-body marginals using few measurement settings, enabling the efficient extraction of key information for many quantum tasks. While optimal schemes are known for qubits, the extension to higher-dimensional qudit systems remains largely unexplored. Here, we investigate optimal qudit overlapping tomography, constructing local measurement settings from generalized Gell-Mann matrices. By establishing a correspondence with combinatorial covering arrays, we present two explicit constructions of optimal measurement schemes. For $n$-qutrit systems, we prove that pairwise tomography requires at most $8 + 56\\left\\lceil \\log_{8} n \\right\\rceil$ measurement settings, and provide an explicit scheme achieving this bound. Furthermore, we develop an efficient algorithm to determine the optimal order of these measurement settings, minimizing the experimental overhead associated with switching configurations. Compared to the worst-case ordering, our optimized schedule reduces switching costs by approximately 50\\%. These results provide a practical pathway for efficient characterization of qudit systems, facilitating their application in quantum communication and computation."
  },
  {
    "date": "2026-01-15",
    "title": "An Efficient Constant-Coefficient MSAV Scheme for Computing Vesicle Growth and Shrinkage",
    "authors": "Zhiwei Zhang, Shuwang Li, John Lowengrub, Steven M. Wise",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10057v1",
    "source": "arXiv",
    "abstract": "We present a fast, unconditionally energy-stable numerical scheme for simulating vesicle deformation under osmotic pressure using a phase-field approach. The model couples an Allen-Cahn equation for the biomembrane interface with a variable-mobility Cahn-Hilliard equation governing mass exchange across the membrane. Classical approaches, including nonlinear multigrid and Multiple Scalar Auxiliary Variable (MSAV) methods, require iterative solution of variable-coefficient systems at each time step, resulting in substantial computational cost. We introduce a constant-coefficient MSAV (CC-MSAV) scheme that incorporates stabilization directly into the Cahn-Hilliard evolution equation rather than the chemical potential. This reformulation yields fully decoupled constant-coefficient elliptic problems solvable via fast discrete cosine transform (DCT), eliminating iterative solvers entirely. The method achieves O(N^2 log N) complexity per time step while preserving unconditional energy stability and discrete mass conservation. Numerical experiments verify second-order temporal and spatial accuracy, mass conservation to relative errors below 5 x 10^-11, and close agreement with nonlinear multigrid benchmarks. On grids with N >= 2048, CC-MSAV achieves 6-15x overall speedup compared to classical MSAV with optimized preconditioning, while the dominant Cahn-Hilliard subsystem is accelerated by up to two orders of magnitude. These efficiency gains, achieved without sacrificing accuracy, make CC-MSAV particularly well suited for large-scale simulations of vesicle dynamics."
  },
  {
    "date": "2026-01-15",
    "title": "Anomalous transport in quasiperiodic lattices: emergent exceptional points at band edges and log-periodic oscillations",
    "authors": "Jinyuan Shang, Haiping Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10056v1",
    "source": "arXiv",
    "abstract": "Quasiperiodic systems host exotic transport regimes that are distinct from those found in periodic or disordered lattices. In this work, we study quantum transport in the Aubry-André-Harper lattice in a two-terminal setup coupled to zero-temperature reservoirs, where the conductance is evaluated via the nonequilibrium Green's function method. In the extended phase, we uncover a universal subdiffusive transport when the bath chemical potential aligns with the band edges. Specifically, the typical conductance displays a scaling of $\\mathcal{G}_{\\text{typ}}\\sim L^{-2}$ with system size $L$. We attribute this behavior to the emergence of an exceptional point (Jordan normal form) in the transfer matrix in the thermodynamic limit. In the localized phase, the conductance shows exponential decay governed by the Lyapunov exponent. Intriguingly, in the critical phase, we identify pronounced log-periodic oscillations of the conductance as a function of system size, arising from the discrete scale invariance inherent to the singular-continuous spectrum. We further extend our analysis to the generalized Aubry-André-Harper model and provide numerical evidence suggesting that the exact mobility edge resides within a finite spectral gap. This results in a counter-intuitive exponential suppression of conductance precisely at the mobility edge. Our work highlights the distinct transport behaviors in quasiperiodic systems and elucidates how they are rigorously dictated by the underlying local spectral structure."
  },
  {
    "date": "2026-01-15",
    "title": "Emergency Department Patient Flow Optimization with an Alternative Care Threshold Policy",
    "authors": "Sahba Baniasadi, Paul M. Griffin, Prakash Chakraborty",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10041v1",
    "source": "arXiv",
    "abstract": "Emergency department (ED) overcrowding and patient boarding represent critical systemic challenges that compromise care quality. We propose a threshold-based admission policy that redirects non-urgent patients to alternative care pathways, such as telemedicine, during peak congestion. The ED is modeled as a two-class $M/M/c$ preemptive-priority queuing system, where high-acuity patients are prioritized and low-acuity patients are subject to state-dependent redirection. Analyzed via a level-dependent Quasi-Birth-Death (QBD) process, the model determines the optimal threshold by maximizing a long-run time-averaged objective function comprising redirection-affected revenue and costs associated with patient balking and system occupancy. Numerical analysis using national healthcare data reveals that optimal policies are highly context-dependent. While rural EDs generally optimize at lower redirection thresholds, urban EDs exhibit performance peaks at moderate thresholds. Results indicate that our optimal policy yields significant performance gains of up to $4.84\\%$ in rural settings and $5.90\\%$ in urban environments. This research provides a mathematically rigorous framework for balancing clinical priority with operational efficiency across diverse ED settings."
  },
  {
    "date": "2026-01-15",
    "title": "What Understanding Means in AI-Laden Astronomy",
    "authors": "Yuan-Sen Ting, André Curtis-Trudel, Siyu Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10038v1",
    "source": "arXiv",
    "abstract": "Artificial intelligence is rapidly transforming astronomical research, yet the scientific community has largely treated this transformation as an engineering challenge rather than an epistemological one. This perspective article argues that philosophy of science offers essential tools for navigating AI's integration into astronomy--conceptual clarity about what \"understanding\" means, critical examination of assumptions about data and discovery, and frameworks for evaluating AI's roles across different research contexts. Drawing on an interdisciplinary workshop convening astronomers, philosophers, and computer scientists, we identify several tensions. First, the narrative that AI will \"derive fundamental physics\" from data misconstrues contemporary astronomy as equation-derivation rather than the observation-driven enterprise it is. Second, scientific understanding involves more than prediction--it requires narrative construction, contextual judgment, and communicative achievement that current AI architectures struggle to provide. Third, because narrative and judgment matter, human peer review remains essential--yet AI-generated content flooding the literature threatens our capacity to identify genuine insight. Fourth, while AI excels at well-defined problem-solving, the ill-defined problem-finding that drives breakthroughs appears to require capacities beyond pattern recognition. Fifth, as AI accelerates what is feasible, pursuitworthiness criteria risk shifting toward what AI makes easy rather than what is genuinely important. We propose \"pragmatic understanding\" as a framework for integration--recognizing AI as a tool that extends human cognition while requiring new norms for validation and epistemic evaluation. Engaging with these questions now may help the community shape the transformation rather than merely react to it."
  },
  {
    "date": "2026-01-15",
    "title": "EmplifAI: a Fine-grained Dataset for Japanese Empathetic Medical Dialogues in 28 Emotion Labels",
    "authors": "Wan Jou She, Lis Kanashiro Pereira, Fei Cheng, Sakiko Yahata, Panote Siriaraya, Eiji Aramaki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10033v1",
    "source": "arXiv",
    "abstract": "This paper introduces EmplifAI, a Japanese empathetic dialogue dataset designed to support patients coping with chronic medical conditions. They often experience a wide range of positive and negative emotions (e.g., hope and despair) that shift across different stages of disease management. EmplifAI addresses this complexity by providing situation-based dialogues grounded in 28 fine-grained emotion categories, adapted and validated from the GoEmotions taxonomy. The dataset includes 280 medically contextualized situations and 4125 two-turn dialogues, collected through crowdsourcing and expert review. To evaluate emotional alignment in empathetic dialogues, we assessed model predictions on situation--dialogue pairs using BERTScore across multiple large language models (LLMs), achieving F1 scores of 0.83. Fine-tuning a baseline Japanese LLM (LLM-jp-3.1-13b-instruct4) with EmplifAI resulted in notable improvements in fluency, general empathy, and emotion-specific empathy. Furthermore, we compared the scores assigned by LLM-as-a-Judge and human raters on dialogues generated by multiple LLMs to validate our evaluation pipeline and discuss the insights and potential risks derived from the correlation analysis."
  },
  {
    "date": "2026-01-15",
    "title": "Structured Personality Control and Adaptation for LLM Agents",
    "authors": "Jinpeng Wang, Xinyu Jia, Wei Wei Heng, Yuquan Li, Binbin Shi, Qianlei Chen, Guannan Chen, Junxia Zhang, Yuyu Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10025v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly shaping human-computer interaction (HCI), from personalized assistants to social simulations. Beyond language competence, researchers are exploring whether LLMs can exhibit human-like characteristics that influence engagement, decision-making, and perceived realism. Personality, in particular, is critical, yet existing approaches often struggle to achieve both nuanced and adaptable expression. We present a framework that models LLM personality via Jungian psychological types, integrating three mechanisms: a dominant-auxiliary coordination mechanism for coherent core expression, a reinforcement-compensation mechanism for temporary adaptation to context, and a reflection mechanism that drives long-term personality evolution. This design allows the agent to maintain nuanced traits while dynamically adjusting to interaction demands and gradually updating its underlying structure. Personality alignment is evaluated using Myers-Briggs Type Indicator questionnaires and tested under diverse challenge scenarios as a preliminary structured assessment. Findings suggest that evolving, personality-aware LLMs can support coherent, context-sensitive interactions, enabling naturalistic agent design in HCI."
  },
  {
    "date": "2026-01-15",
    "title": "Time Aggregation Features for XGBoost Models",
    "authors": "Mykola Pinchuk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10019v1",
    "source": "arXiv",
    "abstract": "This paper studies time aggregation features for XGBoost models in click-through rate prediction. The setting is the Avazu click-through rate prediction dataset with strict out-of-time splits and a no-lookahead feature constraint. Features for hour H use only impressions from hours strictly before H. This paper compares a strong time-aware target encoding baseline to models augmented with entity history time aggregation under several window designs. Across two rolling-tail folds on a deterministic ten percent sample, a trailing window specification improves ROC AUC by about 0.0066 to 0.0082 and PR AUC by about 0.0084 to 0.0094 relative to target encoding alone. Within the time aggregation design grid, event count windows provide the only consistent improvement over trailing windows, and the gain is small. Gap windows and bucketized windows underperform simple trailing windows in this dataset and protocol. These results support a practical default of trailing windows, with an optional event count window when marginal ROC AUC gains matter."
  },
  {
    "date": "2026-01-15",
    "title": "Continuous-Depth Transformers with Learned Control Dynamics",
    "authors": "Peter Jemley",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10007v1",
    "source": "arXiv",
    "abstract": "We present a hybrid transformer architecture that replaces discrete middle layers with a continuous-depth Neural Ordinary Differential Equation (ODE) block, enabling inference-time control over generation attributes via a learned steering signal. Unlike standard transformers that process representations through fixed discrete layers, our approach treats depth as a continuous variable governed by a learned vector field $F_θ(H, τ, u)$, where $u$ is a low-dimensional control signal injected via explicit concatenation. We validate the architecture through four experiments: (1) gradient flow stability with zero exploding/vanishing gradient events, (2) semantic steering achieving 98\\%/88\\% accuracy for positive/negative sentiment control, (3) continuous interpolation validated by a negligible 0.068\\% trajectory divergence between fixed and adaptive solvers, and (4) efficiency benchmarking demonstrating latency parity with standard discrete baselines. Additionally, we show that adaptive ODE solvers reveal geometric structure in the learned dynamics: the control signal partitions the vector field into distinct dynamical regimes with different curvature characteristics. The adjoint method enables $O(1)$ memory training regardless of integration depth. Our results demonstrate that continuous-depth dynamics with learned control signals provide a viable, efficient mechanism for steerable language generation."
  },
  {
    "date": "2026-01-15",
    "title": "SocraticKG: Knowledge Graph Construction via QA-Driven Fact Extraction",
    "authors": "Sanghyeok Choi, Woosang Jeon, Kyuseok Yang, Taehyeong Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10003v1",
    "source": "arXiv",
    "abstract": "Constructing Knowledge Graphs (KGs) from unstructured text provides a structured framework for knowledge representation and reasoning, yet current LLM-based approaches struggle with a fundamental trade-off: factual coverage often leads to relational fragmentation, while premature consolidation causes information loss. To address this, we propose SocraticKG, an automated KG construction method that introduces question-answer pairs as a structured intermediate representation to systematically unfold document-level semantics prior to triple extraction. By employing 5W1H-guided QA expansion, SocraticKG captures contextual dependencies and implicit relational links typically lost in direct KG extraction pipelines, providing explicit grounding in the source document that helps mitigate implicit reasoning errors. Evaluation on the MINE benchmark demonstrates that our approach effectively addresses the coverage-connectivity trade-off, achieving superior factual retention while maintaining high structural cohesion even as extracted knowledge volume substantially expands. These results highlight that QA-mediated semantic scaffolding plays a critical role in structuring semantics prior to KG extraction, enabling more coherent and reliable graph construction in subsequent stages."
  },
  {
    "date": "2026-01-15",
    "title": "Hybrid Quantum Algorithms for Computational Chemistry: Application to the Pyridine-Li ion Complex",
    "authors": "Fatemeh Ghasemi, Yousung Kang, Yukio Kawashima, Kyungsun Moon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10002v1",
    "source": "arXiv",
    "abstract": "Accurately capturing electron correlation in large-scale molecular systems remains one of the foremost challenges in quantum chemistry and a primary driver for the development of quantum algorithms. Classical configuration-interaction methods, while rigorous, suffer from exponential scaling, rendering them impractical for large or strongly correlated systems. Overcoming this limitation is central to realizing the promise of quantum computing in chemistry. Here, we investigate the pyridine-Li ion complex using three quantum algorithms: the variational quantum eigensolver (VQE), the subspace quantum diagonalization (SQD) method, and the recently introduced handover iterative VQE (HI-VQE). Our results demonstrate how new generations of hybrid quantum-classical frameworks overcome the scalability and noise sensitivity that constrain conventional VQE approaches. SQD and HI-VQE achieve ground-state energy calculations for problem sizes inaccessible to classical computation, marking a clear advance toward quantum advantage. In particular, HI-VQE enables calculations within active spaces as large as (24e,22o), requiring 44 qubits-well beyond the reach of classical CASCI and VQE. This capability provides a systematic pathway for incorporating increasing numbers of electrons into quantum treatment, thereby approaching exact molecular energies. Importantly, both SQD and HI-VQE exhibit robustness against hardware noise, a critical improvement over earlier approaches. By enabling quantum simulations of molecular systems previously deemed intractable, SQD and HI-VQE offer a realistic route toward practical quantum advantage in computational chemistry. The comparison between HI-VQE and SQD shows that optimizing circuit parameters is crucial for accurate simulation."
  },
  {
    "date": "2026-01-15",
    "title": "EditEmoTalk: Controllable Speech-Driven 3D Facial Animation with Continuous Expression Editing",
    "authors": "Diqiong Jiang, Kai Zhu, Dan Song, Jian Chang, Chenglizhao Chen, Zhenyu Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10000v1",
    "source": "arXiv",
    "abstract": "Speech-driven 3D facial animation aims to generate realistic and expressive facial motions directly from audio. While recent methods achieve high-quality lip synchronization, they often rely on discrete emotion categories, limiting continuous and fine-grained emotional control. We present EditEmoTalk, a controllable speech-driven 3D facial animation framework with continuous emotion editing. The key idea is a boundary-aware semantic embedding that learns the normal directions of inter-emotion decision boundaries, enabling a continuous expression manifold for smooth emotion manipulation. Moreover, we introduce an emotional consistency loss that enforces semantic alignment between the generated motion dynamics and the target emotion embedding through a mapping network, ensuring faithful emotional expression. Extensive experiments demonstrate that EditEmoTalk achieves superior controllability, expressiveness, and generalization while maintaining accurate lip synchronization. Code and pretrained models will be released."
  },
  {
    "date": "2026-01-15",
    "title": "Corrected Forecast Combinations",
    "authors": "Chu-An Liu, Andrey L. Vasnev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09999v1",
    "source": "arXiv",
    "abstract": "This paper proposes corrected forecast combinations when the original combined forecast errors are serially dependent. Motivated by the classic Bates and Granger (1969) example, we show that combined forecast errors can be strongly autocorrelated and that a simple correction--adding a fraction of the previous combined error to the next-period combined forecast--can deliver sizable improvements in forecast accuracy, often exceeding the original gains from combining. We formalize the approach within the conditional risk framework of Gibbs and Vasnev (2024), in which the combined error decomposes into a predictable component (measurable at the forecast origin) and an innovation. We then link this correction to efficient estimation of combination weights under time-series dependence via GLS, allowing joint estimation of weights and an error-covariance structure. Using the U.S. Survey of Professional Forecasters for major macroeconomic indices across various subsamples (including pre and post-2000, GFC, and COVID), we find that a parsimonious correction of the mean forecast with a coefficient around 0.5 is a robust starting point and often yields material improvements in forecast accuracy. For optimal-weight forecasts, the correction substantially mitigates the forecast combination puzzle by turning poorly performing out-of-sample optimal-weight combinations into competitive forecasts."
  },
  {
    "date": "2026-01-15",
    "title": "Brief but Impactful: How Human Tutoring Interactions Shape Engagement in Online Learning",
    "authors": "Conrad Borchers, Ashish Gurung, Qinyi Liu, Danielle R. Thomas, Mohammad Khalil, Kenneth R. Koedinger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09994v1",
    "source": "arXiv",
    "abstract": "Learning analytics can guide human tutors to efficiently address motivational barriers to learning that AI systems struggle to support. Students become more engaged when they receive human attention. However, what occurs during short interventions, and when are they most effective? We align student-tutor dialogue transcripts with MATHia tutoring system log data to study brief human-tutor interactions on Zoom drawn from 2,075 hours of 191 middle school students' classroom math practice. Mixed-effect models reveal that engagement, measured as successful solution steps per minute, is higher during a human-tutor visit and remains elevated afterward. Visit length exhibits diminishing returns: engagement rises during and shortly after visits, irrespective of visit length. Timing also matters: later visits yield larger immediate lifts than earlier ones, though an early visit remains important to counteract engagement decline. We create analytics that identify which tutor-student dialogues raise engagement the most. Qualitative analysis reveals that interactions with concrete, stepwise scaffolding with explicit work organization elevate engagement most strongly. We discuss implications for resource-constrained tutoring, prioritizing several brief, well-timed check-ins by a human tutor while ensuring at least one early contact. Our analytics can guide the prioritization of students for support and surface effective tutor moves in real-time."
  },
  {
    "date": "2026-01-15",
    "title": "Polynomially effective equidistribution for unipotent orbits in products of $\\mathrm{SL}_2$ factors",
    "authors": "Elon Lindenstrauss, Amir Mohammadi, Lei Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09983v1",
    "source": "arXiv",
    "abstract": "We sketch the proof of an effective equidistribution theorem for one-parameter unipotent subgroups in $S$-arithmetic quotients arising from $\\mathbf K$-forms of $\\mathrm{SL}_2^{\\mathsf n}$ where $\\mathbf K$ is a number field. This gives an effective version of equidistribution results of Ratner and Shah with a polynomial rate. The key new phenomenon is the existence of many intermediate groups between the $\\mathrm{SL}_2$ containing our unipotent and the ambient group, which introduces potential local and global obstruction to equidistribution. Our approach relies on a Bourgain-type projection theorem in the presence of obstructions, together with a careful analysis of these obstructions."
  },
  {
    "date": "2026-01-15",
    "title": "Performance of AI agents based on reasoning language models on ALD process optimization tasks",
    "authors": "Angel Yanguas-Gil",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09980v1",
    "source": "arXiv",
    "abstract": "In this work we explore the performance and behavior of reasoning large language models to autonomously optimize atomic layer deposition (ALD) processes. In the ALD process optimization task, an agent built on top of a reasoning LLM has to find optimal dose times for an ALD precursor and a coreactant without any prior knowledge on the process, including whether it is actually self-limited. The agent is meant to interact iteratively with an ALD reactor in a fully unsupervised way. We evaluate this agent using a simple model of an ALD tool that incorporates ALD processes with different self-limited surface reaction pathways as well as a non self-limited component. Our results show that agents based on reasoning models like OpenAI's o3 and GPT5 consistently succeeded at completing this optimization task. However, we observed significant run-to-run variability due to the non deterministic nature of the model's response. In order to understand the logic followed by the reasoning model, the agent uses a two step process in which the model first generates an open response detailing the reasoning process. This response is then transformed into a structured output. An analysis of these reasoning traces showed that the logic of the model was sound and that its reasoning was based on the notions of self-limited process and saturation expected in the case of ALD. However, the agent can sometimes be misled by its own prior choices when exploring the optimization space."
  },
  {
    "date": "2026-01-15",
    "title": "Chinese Labor Law Large Language Model Benchmark",
    "authors": "Zixun Lan, Maochun Xu, Yifan Ren, Rui Wu, Jianghui Zhou, Xueyang Cheng, Jianan Ding Ding, Xinheng Wang, Mingmin Chi, Fei Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09972v1",
    "source": "arXiv",
    "abstract": "Recent advances in large language models (LLMs) have led to substantial progress in domain-specific applications, particularly within the legal domain. However, general-purpose models such as GPT-4 often struggle with specialized subdomains that require precise legal knowledge, complex reasoning, and contextual sensitivity. To address these limitations, we present LabourLawLLM, a legal large language model tailored to Chinese labor law. We also introduce LabourLawBench, a comprehensive benchmark covering diverse labor-law tasks, including legal provision citation, knowledge-based question answering, case classification, compensation computation, named entity recognition, and legal case analysis. Our evaluation framework combines objective metrics (e.g., ROUGE-L, accuracy, F1, and soft-F1) with subjective assessment based on GPT-4 scoring. Experiments show that LabourLawLLM consistently outperforms general-purpose and existing legal-specific LLMs across task categories. Beyond labor law, our methodology provides a scalable approach for building specialized LLMs in other legal subfields, improving accuracy, reliability, and societal value of legal AI applications."
  },
  {
    "date": "2026-01-15",
    "title": "Topological textures and emergent altermagnetic signatures in ultrathin BiFeO3",
    "authors": "George Fratian, Maya Ramesh, Xinyan Li, Evangelos Golias, Yousra Nahas, Sebastian Maria Ulrich Schultheis, Julian Skolaut, Marti Checa, Arundhati Ghosal, Jan Priessnitz, F. C. Fobasso Mbognou, Shashank Kumar Ojha, Shiyu Zhou, Alexander Qualls, Kai Litzius, Christoph Klewe, Peter Meisenheimer, Laurent Bellaiche, Libor Šmejkal, Darrell G. Schlom, Yimo Han, Sergei Prokhorenko, Ramamoorthy Ramesh, Paul Stevenson, Angela Wittmann, Lucas Caretta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09970v1",
    "source": "arXiv",
    "abstract": "Magnetoelectric multiferroics, materials with intrinsically coupled electric polarization and magnetic order, promise ultralow-power switching, nonvolatile memory, and energy-efficient signal transduction. Yet practical deployment demands ultrathin films down to the atomic limit, where both orders typically degrade. Maintaining both order parameters at the thinnest scales in complex oxides remains a tremendous challenge, as uncompensated bound charge drives nanoscale depolarization in most ferroelectrics, while off-stoichiometry, reduced anisotropy, and charge transfer can produce magnetic dead layers in ultrathin oxides at substrate interfaces. Here, we realize a multiferroic phase of BiFeO3 that not only sustains both order parameters at room temperature with no dead layer but also exhibits signatures of emergent altermagnetism in the four-unit-cell, ultrathin limit. First-principles calculations, spin symmetry analysis, atomic-resolution imaging, and angle-resolved magnetic imaging reveal that short-circuit electrostatic boundary conditions, together with epitaxial strain, drive a continuous second-order, thickness-driven phase transition that enables the formation of multiferroic topological textures. Moreover, the imposed boundary conditions stabilize a d-wave altermagnetic time-reversal symmetry breaking, with corresponding signatures observed in magnetic circular dichroism. Collectively, these results establish a pathway to stabilize unconventional multiferroicity at device-relevant thicknesses, reframing scaling limits for oxide electronics."
  },
  {
    "date": "2026-01-15",
    "title": "Interfacing Superconductor and Semiconductor Digital Electronics",
    "authors": "Yerzhan Mustafa, Selçuk Köse",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09969v1",
    "source": "arXiv",
    "abstract": "Interface circuits are the key components that enable the hybrid integration of superconductor and semiconductor digital electronics. The design requirements of superconductor-semiconductor interface circuits vary depending on the application, such as high-performance classical computing, superconducting quantum computing, and digital signal processing. In this survey, various interface circuits are categorized based on the working principle and structure. The superconducting output drivers are explored, which are capable of converting and amplifying, e.g., single flux quantum (SFQ) voltage pulses, to voltage levels that semiconductor circuits can process. Several trade-offs between circuit- and system-level design parameters are examined. Accordingly, parameters such as the data rate, output voltage, power dissipation, layout area, thermal/heat load of cryogenic cables, and bit-error rate are considered."
  },
  {
    "date": "2026-01-15",
    "title": "Derivations for the Cumulative Standardized Binomial EWMA (CSB-EWMA) Control Chart",
    "authors": "Faruk Muritala, Austin Brown, Dhrubajyoti Ghosh, Sherry Ni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09968v1",
    "source": "arXiv",
    "abstract": "This paper presents the exact mathematical derivation of the mean and variance properties for the Exponentially Weighted Moving Average (EWMA) statistic applied to binomial proportion monitoring in Multiple Stream Processes (MSPs). We develop a Cumulative Standardized Binomial EWMA (CSB-EWMA) formulation that provides adaptive control limits based on exact time-varying variance calculations, overcoming the limitations of asymptotic approximations during early-phase monitoring. The derivations are rigorously validated through Monte Carlo simulations, demonstrating remarkable agreement between theoretical predictions and empirical results. This work establishes a theoretical foundation for distribution-free monitoring of binary outcomes across parallel data streams, with applications in statistical process control across diverse domains including manufacturing, healthcare, and cybersecurity."
  },
  {
    "date": "2026-01-15",
    "title": "A Sustainable AI Economy Needs Data Deals That Work for Generators",
    "authors": "Ruoxi Jia, Luis Oala, Wenjie Xiong, Suqin Ge, Jiachen T. Wang, Feiyang Kang, Dawn Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09966v1",
    "source": "arXiv",
    "abstract": "We argue that the machine learning value chain is structurally unsustainable due to an economic data processing inequality: each state in the data cycle from inputs to model weights to synthetic outputs refines technical signal but strips economic equity from data generators. We show, by analyzing seventy-three public data deals, that the majority of value accrues to aggregators, with documented creator royalties rounding to zero and widespread opacity of deal terms. This is not just an economic welfare concern: as data and its derivatives become economic assets, the feedback loop that sustains current learning algorithms is at risk. We identify three structural faults - missing provenance, asymmetric bargaining power, and non-dynamic pricing - as the operational machinery of this inequality. In our analysis, we trace these problems along the machine learning value chain and propose an Equitable Data-Value Exchange (EDVEX) Framework to enable a minimal market that benefits all participants. Finally, we outline research directions where our community can make concrete contributions to data deals and contextualize our position with related and orthogonal viewpoints."
  },
  {
    "date": "2026-01-15",
    "title": "Probabilistic heterogeneous Stirling numbers and Bell polynomials",
    "authors": "Taekyun Kim, Dae San Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09964v1",
    "source": "arXiv",
    "abstract": "Let Y be a random variable satisfying specific moment conditions. This paper introduces and investigates probabilistic heterogeneous Stirling numbers of the second kind and probabilistic heterogeneous Bell polynomials. These structures unify several classical and probabilistic families, including those of Stirling, Lah, Bell and Lah-Bell. By integrating the heterogeneous framework of Kim and Kim with probabilistic extensions, we derive explicit formulas, Dobiński-like identities, and recurrence relations. We further establish connections to partial Bell polynomials and provide applications for Poisson and Bernoulli distributions."
  },
  {
    "date": "2026-01-15",
    "title": "Near-Unity-Efficiency Gas Gratings for Ultraviolet, Visible, and Infrared High-Power Lasers",
    "authors": "Ke Ou, Harsha Rajesh, Sida Cao, Debolina Chakraborty, Victor M. Perez-Ramirez, Devdigvijay Singh, Caleb Redshaw, Pelin Dedeler, Albertine Oudin, Eugene Kur, Michelle M. Wang, Julia M. Mikhailova, Livia Lancia, Caterina Riconda, Pierre Michel, Matthew R. Edwards",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09963v1",
    "source": "arXiv",
    "abstract": "Interfering deep ultraviolet (DUV) lasers can induce substantial density modulations in an ozone-doped gas flow via photochemical reactions, creating volume diffraction gratings. These transient optics are immune to target debris and shrapnel and feature orders-of-magnitude higher damage thresholds than conventional solid optics, providing a promising method for efficiently manipulating high-energy lasers. In this work, we describe gas gratings that can efficiently diffract probe beams across a variety of wavelengths and pulse durations, ranging from deep ultraviolet to near-infrared and from nanosecond to femtosecond, achieving a full beam diffraction efficiency up to 99% while preserving the focusability and wavefront quality. In addition, we present a comprehensive characterization of the performance of the gas gratings under various experimental conditions, including imprint fluence, gas composition, and grating geometries, showing significant enhancement of this process with the addition of carbon dioxide. We also demonstrate stable performance over hours of operation. Our results validate a previously developed theoretical model and suggest optimal parameters to efficiently scale gas gratings to high-energy applications."
  },
  {
    "date": "2026-01-15",
    "title": "Stochastic systems with Bose-Hubbard interactions: Effects of bias on particles on a random comb",
    "authors": "Swastik Majumder, Mustansir Barma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09962v1",
    "source": "arXiv",
    "abstract": "We study stochastic transport of interacting particles on a disordered network described by the random comb geometry. The model is defined on a one-dimensional backbone from which branches of random lengths emanate, providing a minimal model of percolation networks beyond the critical percolation probability. The dynamics obeys local detailed balance with respect to a Bose-Hubbard Hamiltonian containing both an external bias and on-site repulsion. This choice yields an analytically tractable steady state through a mapping to the zero-range-process. We compute the backbone current, branch density profiles, and macroscopic drift velocity, and analyze how bias and interactions compete to shape transport. The backbone current increases monotonically with density, while the drift velocity displays a non-monotonic dependence on the external field, remaining finite for any nonzero bias, in contrast to the vanishing drift velocity of noninteracting particles beyond a threshold bias. Density profiles along branches exhibit stepwise plateaus governed by the ratio of interaction to bias energy. These results highlight how repulsive interactions suppress trapping and restore transport in disordered geometries, bridging earlier studies of field induced drift in random networks with the physics of disordered Bose-Hubbard systems."
  },
  {
    "date": "2026-01-15",
    "title": "Private Information Retrieval for Graph-based Replication with Minimal Subpacketization",
    "authors": "Vayur Shanbhag, Prasad Krishnan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09957v1",
    "source": "arXiv",
    "abstract": "We design new minimal-subpacketization schemes for information-theoretic private information retrieval on graph-based replicated databases. In graph-based replication, the system consists of $K$ files replicated across $N$ servers according to a graph with $N$ vertices and $K$ edges. The client wants to retrieve one desired file, while keeping the index of the desired file private from each server via a query-response protocol. We seek PIR protocols that have (a) high rate, which is the ratio of the file-size to the total download cost, and (b) low subpacketization, which acts as a constraint on the size of the files for executing the protocol. We report two new schemes which have unit-subpacketization (which is minimal): (i) for a special class of graphs known as star graphs, and (ii) for general graphs. Our star-graph scheme has a better rate than previously known schemes with low subpacketization for general star graphs. Our scheme for general graphs uses a decomposition of the graph via independent sets. This scheme achieves a rate lower than prior schemes for the complete graph, however it can achieve higher rates than known for some specific graph classes. An extension of our scheme to the case of multigraphs achieves a higher rate than previous schemes for the complete multi-graph."
  },
  {
    "date": "2026-01-15",
    "title": "Parallelizing the Variational Quantum Eigensolver: From JIT Compilation to Multi-GPU Scaling",
    "authors": "Rylan Malarchick, Ashton Steed",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09951v1",
    "source": "arXiv",
    "abstract": "The Variational Quantum Eigensolver (VQE) is a hybrid quantum-classical algorithm for computing ground state energies of molecular systems. We implement VQE to calculate the potential energy surface of the hydrogen molecule (H$_2$) across 100 bond lengths using the PennyLane quantum computing framework on an HPC cluster featuring 4$\\times$ NVIDIA H100 GPUs (80GB each). We present a comprehensive parallelization study with four phases: (1) Optimizer + JIT compilation achieving 4.13$\\times$ speedup, (2) GPU device acceleration achieving 3.60$\\times$ speedup at 4 qubits scaling to 80.5$\\times$ at 26 qubits, (3) MPI parallelization achieving 28.5$\\times$ speedup, and (4) Multi-GPU scaling achieving 3.98$\\times$ speedup with 99.4% parallel efficiency across 4 H100 GPUs. The combined effect yields 117$\\times$ total speedup for the H$_2$ potential energy surface (593.95s $\\rightarrow$ 5.04s). We conduct a CPU vs GPU scaling study from 4--26 qubits, finding GPU advantage at all scales with speedups ranging from 10.5$\\times$ to 80.5$\\times$. Multi-GPU benchmarks demonstrate near-perfect scaling with 99.4% efficiency and establish that a single H100 can simulate up to 29 qubits before hitting memory limits. The optimized implementation reduces runtime from nearly 10 minutes to 5 seconds, enabling interactive quantum chemistry exploration."
  },
  {
    "date": "2026-01-15",
    "title": "Quantitative Supercritical Bounds for Disconnection in Bernoulli Site Percolation",
    "authors": "Zhongyang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09950v1",
    "source": "arXiv",
    "abstract": "For any infinite, connected, locally finite graph $G=(V,E)$, any parameter $p>p^{\\mathrm{site}}_{c}(G)$, and any (finite or infinite) set of vertices $S\\subset V$, we derive explicit exponential-type upper bounds on the disconnection probability $\\mathbb{P}_{p}(S\\nleftrightarrow\\infty)$. The estimates are expressed in terms of a packing profile of $S$, encoded by a $(p,\\varepsilon,c)$--packing number, which counts how many well-separated vertices in $S$ exhibit controlled local-to-global connectivity. The proof combines a local functional characterization of $p^{\\mathrm{site}}_{c}$ from \\cite{ZL24,ZL26} with a packing construction and an amplification-by-independence argument, in the direction of Problem~1.6 in \\cite{DC20}."
  },
  {
    "date": "2026-01-15",
    "title": "Interpolation-Based Optimization for Enforcing lp-Norm Metric Differential Privacy in Continuous and Fine-Grained Domains",
    "authors": "Chenxi Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09946v1",
    "source": "arXiv",
    "abstract": "Metric Differential Privacy (mDP) generalizes Local Differential Privacy (LDP) by adapting privacy guarantees based on pairwise distances, enabling context-aware protection and improved utility. While existing optimization-based methods reduce utility loss effectively in coarse-grained domains, optimizing mDP in fine-grained or continuous settings remains challenging due to the computational cost of constructing dense perterubation matrices and satisfying pointwise constraints. In this paper, we propose an interpolation-based framework for optimizing lp-norm mDP in such domains. Our approach optimizes perturbation distributions at a sparse set of anchor points and interpolates distributions at non-anchor locations via log-convex combinations, which provably preserve mDP. To address privacy violations caused by naive interpolation in high-dimensional spaces, we decompose the interpolation process into a sequence of one-dimensional steps and derive a corrected formulation that enforces lp-norm mDP by design. We further explore joint optimization over perturbation distributions and privacy budget allocation across dimensions. Experiments on real-world location datasets demonstrate that our method offers rigorous privacy guarantees and competitive utility in fine-grained domains, outperforming baseline mechanisms. in high-dimensional spaces, we decompose the interpolation process into a sequence of one-dimensional steps and derive a corrected formulation that enforces lp-norm mDP by design. We further explore joint optimization over perturbation distributions and privacy budget allocation across dimensions. Experiments on real-world location datasets demonstrate that our method offers rigorous privacy guarantees and competitive utility in fine-grained domains, outperforming baseline mechanisms."
  },
  {
    "date": "2026-01-15",
    "title": "Modeling conflicting incentives in engineering senior capstone projects: A multi-player game theory approach",
    "authors": "Richard Q. Blackwell, Eman Hammad, Congrui Jin, Jisoo Park, Albert E. Patterson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09944v1",
    "source": "arXiv",
    "abstract": "University engineering capstone projects involve sustained interaction among students, faculty, and industry sponsors whose objectives are only partially aligned. While capstones are widely used in engineering education, existing analyses typically treat stakeholder behavior informally or descriptively, leaving incentive conflicts, information asymmetries, and strategic dependencies underexplored. This paper develops a formal game-theoretic framework that models capstone projects as a sequential Bayesian game involving three players: the university, the industry sponsor, and the student team. The framework is intended as an analytical and explanatory tool for understanding how institutional policy choices, such as grading structures, intellectual property rules, and sponsor engagement expectations, shape stakeholder behavior and project outcomes, rather than as a calibrated or predictive model. The university acts as a constrained Stackelberg leader by committing to course policies and assessment structures while anticipating strategic responses by sponsors and students under incomplete information. Reduced-form outcome functions capture technical quality, documentation quality, timeliness, alignment with sponsor needs, and publishability, while payoff functions reflect stakeholder-specific objectives and costs. Under standard assumptions, the model admits stable equilibrium regimes that correspond to empirically recognizable capstone dynamics observed in practice, including cooperative engagement, sponsor-dominated exploitation, and student grade gaming. Rather than claiming precise prediction, the framework provides a structured basis for reasoning about incentive design, policy tradeoffs, and structural failure modes in project-based learning environments, as well as for future extensions incorporating richer dynamics, repeated interaction, and empirical calibration."
  },
  {
    "date": "2026-01-15",
    "title": "Unbounded symbols, heat flow, and Toeplitz operators",
    "authors": "Sam Looi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10711v1",
    "source": "arXiv",
    "abstract": "We disprove the natural domain extension of the Berger--Coburn heat-flow conjecture for Toeplitz operators on the Bargmann space and identify the failure mechanism as a gap between pointwise and uniform control of a Gaussian averaging of the squared modulus of the symbol, a gap that is invisible to the linear form $T_g$. We establish that the form-defined operator $T_g$ and the natural-domain operator $U_g$ decouple in the unbounded symbols regime: while $T_g$ is governed by linear averaging, $U_g$ is controlled by the quadratic intensity of $|g|^2$. We construct a smooth, nonnegative radial symbol $g$ satisfying the coherent-state admissibility hypothesis with bounded heat transforms for all time $t>0$; for this symbol, $T_g$ is bounded, yet $U_g$ is unbounded. This is a strictly global phenomenon: under the coherent-state hypothesis, local singularities are insufficient to cause unboundedness, leaving the ``geometry at infinity'' as the sole obstruction. Boundedness of $U_g$ is equivalent to the condition that $|g|^2 dμ$ is a Fock--Carleson measure, a condition strictly stronger than the linear average $g dμ$ governing $T_g$. Finally, regarding the gap between the known sub-critical sufficiency condition and the critical heat time, we prove that heat-flow regularity is irreversible in this context and show that bootstrapping strategies cannot resolve the gap between sufficiency and critical time."
  },
  {
    "date": "2026-01-15",
    "title": "Finite-momentum Cooper plasmons in superconducting terahertz microcavities",
    "authors": "Alex M. Potts, Marios H. Michael, Gunda Kipp, Sara M. Langner, Hope M. Bretscher, Jonathan Stensberg, Kelson Kaj, Toru Matsuyama, Matthew W. Day, Felix Sturm, Abhay K. Nayak, Liam A. Cohen, Xiaoyang Zhu, Andrea Young, James McIver",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10692v1",
    "source": "arXiv",
    "abstract": "The phase mode of a superconductor's order parameter encodes fundamental information about pairing and dissipation, but is typically inaccessible at low frequencies due to the Anderson-Higgs mechanism. Superconducting samples thinner than the London penetration depth, however, support a gapless phase mode whose dispersion can be reshaped by a proximal screening layer. Here, we theoretically and experimentally show that this screened phase mode in a superconducting thin film integrated into on-chip terahertz circuitry naturally forms a superconducting microcavity that hosts resonant finite-momentum standing waves of supercurrent density, which we term Cooper plasmons. We measure two Cooper plasmons in a superconducting NbN microcavity and demonstrate that their resonance frequencies and linewidths independently report the density of participating carriers and plasmon's dissipation at finite momenta. Our results reveal an emergent collective mode of an integrated superconductor-circuit system and establish design principles for engineering or suppressing Cooper plasmons in superconducting terahertz devices and circuits."
  },
  {
    "date": "2026-01-15",
    "title": "Mitigating nonlinear transduction noise in high-cooperativity cavity optomechanics",
    "authors": "Daniel Allepuz-Requena, Zohran Ali, Dennis Høj, Yingxuan Chen, Luiz Couto Correa Pinto Filho, Alexander Huck, Ulrik L. Andersen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10689v1",
    "source": "arXiv",
    "abstract": "Coupling mechanical motion to an optical resonator enables displacement measurements approaching the standard quantum limit (SQL). However, increasing the optomechanical coupling strength will inevitably lead to probing of the nonlinear response of the optical resonator. Thermal intermodulation noise (TIN) arising from the nonlinear mixing of thermomechanical motion can further increase the imprecision well above the SQL and has hitherto been canceled up to second order of nonlinearity via operation at the \"magic detuning\". In this work, we record the output of a membrane-in-the-middle microcavity system operating at room temperature and achieving high cooperativity, $C>n_\\text{th}$, and apply a nonlinear transform that removes all orders of TIN, improving the mechanical signal-to-noise ratio by nearly 10 dB. Our results can be applied to experiments affected by third-order TIN, which we expect to be the dominating intrinsic source of noise in high-cooperativity room-temperature cavity optomechanical systems."
  },
  {
    "date": "2026-01-15",
    "title": "An Extension-Based Accessibility Framework for Making Blockly Accessible to Blind and Low-Vision Users",
    "authors": "Rubel Hassan Mollik, Vamsi Krishna Kosuri, Hans Djalali, Stephanie Ludi, Aboubakar Mountapmbeme",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10688v1",
    "source": "arXiv",
    "abstract": "Block-based programming environments (BBPEs) such as Scratch and Code.org are now widely used in K-12 computer science classes, but they remain mostly inaccessible to blind or visually impaired (BVI) learners. A major problem is that prior accessibility solutions have relied on modifications to the Blockly library, making them difficult to apply in existing BBPEs and thereby limiting adoption. We present an Extension-based Accessibility Framework (EAF) to make BBPEs accessible for BVI students. The framework uses a modular architecture that enables seamless integration with existing Blockly-based BBPEs. We present an innovative three-dimensional (3D) hierarchical navigation model featuring stack labeling and block numbering, mode-based editing to prevent accidental modifications, and WAI-ARIA implementation to ensure compatibility with external screen readers. We evaluated our approach by integrating the EAF framework into two BBPEs (covering 177 test cases) and conducting semi-structured interviews with four participants using VoiceOver, JAWS, and NVDA. Participants reported clearer spatial orientation and easier mental model formation compared to default Blockly keyboard navigation. EAF shows that modular architecture can provide comprehensive accessibility while ensuring compatibility with existing BBPEs."
  },
  {
    "date": "2026-01-15",
    "title": "Energy Correlators in Warped Geometries",
    "authors": "Lorenzo Ricci, Raman Sundrum",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10674v1",
    "source": "arXiv",
    "abstract": "We study Energy Correlators as probes of strongly-coupled nearly-conformal field theories within their holographically dual descriptions, focusing on the important features that appear in realistic theories going beyond the standard model. In particular, we study warped geometries which asymptote to $\\text{AdS}_5$, as well as IR-truncations dual to a 4D gap. Our correlators are computed by in-in type Witten perturbative diagrams, corresponding to a large-N expansion of the strong dynamics. We describe how this sets the stage for phenomenological applications for collider searches beyond the standard model as well as for new theoretical explorations in Lorentzian holography."
  },
  {
    "date": "2026-01-15",
    "title": "Single-Stage Huffman Encoder for ML Compression",
    "authors": "Aditya Agrawal, Albert Magyar, Hiteshwar Eswaraiah, Patrick Sheridan, Pradeep Janedula, Ravi Krishnan Venkatesan, Krishna Nair, Ravi Iyer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10673v1",
    "source": "arXiv",
    "abstract": "Training and serving Large Language Models (LLMs) require partitioning data across multiple accelerators, where collective operations are frequently bottlenecked by network bandwidth. Lossless compression using Huffman codes is an effective way to alleviate the issue, however, its three-stage design requiring on-the-fly frequency analysis, codebook generation and transmission of codebook along with data introduces computational, latency and data overheads which are prohibitive for latency-sensitive scenarios such as die-to-die communication. This paper proposes a single-stage Huffman encoder that eliminates these overheads by using fixed codebooks derived from the average probability distribution of previous data batches. Through our analysis of the Gemma 2B model, we demonstrate that tensors exhibit high statistical similarity across layers and shards. Using this approach we achieve compression within 0.5% of per-shard Huffman coding and within 1% of the ideal Shannon compressibility, enabling efficient on-the-fly compression."
  },
  {
    "date": "2026-01-15",
    "title": "Real characters and real classes of $\\mathrm{GL}_2$ and $\\mathrm{GU}_2$ over discrete valuation rings",
    "authors": "Archita Gupta, Tejbir Lohan, Pooja Singla",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10670v1",
    "source": "arXiv",
    "abstract": "Let $\\mathfrak{o}$ be the ring of integers of a non-archimedean local field with residue field of odd characteristic, $\\mathfrak{p}$ be its maximal ideal and let $\\mathfrak{o}_\\ell = \\mathfrak{o}/\\mathfrak{p}^\\ell$ for $\\ell\\ge 2$. In this article, we study real-valued characters and real representations of the finite groups $\\mathrm{GL}_2(\\mathfrak{o}_\\ell)$ and $\\mathrm{GU}_2(\\mathfrak{o}_\\ell)$. We give a complete classification of real and strongly real classes of these groups and characterize the real-valued irreducible complex characters. We prove that every real-valued irreducible complex character of $\\mathrm{GL}_2(\\mathfrak{o}_\\ell)$ is afforded by a representation over $\\mathbb{R}$. In contrast, we show that $\\mathrm{GU}_2(\\mathfrak{o}_\\ell)$ admits real-valued irreducible characters that are not realizable over $\\mathbb{R}$. These results extend the parallel known phenomena for the finite groups $\\mathrm{GL}_n(\\mathbb{F}_q)$ and $\\mathrm{GU}_n(\\mathbb{F}_q)$."
  },
  {
    "date": "2026-01-15",
    "title": "Discrete-time maximally superintegrable systems and deformed symmetry algebras: the Calogero-Moser case",
    "authors": "Pavel Drozdov, Giorgio Gubbiotti, Danilo Latini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10625v1",
    "source": "arXiv",
    "abstract": "We determine the complete structure of the symmetry algebras associated with the N-body Calogero-Moser system and its maximally superintegrable discretization. We prove that the discretization naturally leads to a nontrivial deformation of the continuous symmetry algebra, with the discretization parameter playing the rôle of a deformation parameter. This phenomenon illustrates how discrete superintegrable systems can be viewed as natural sources of deformed polynomial algebraic structures. As a byproduct of these results, we also reveal a connection between the above-mentioned symmetry algebras and the Bell polynomials, as a consequence of the trace properties."
  },
  {
    "date": "2026-01-15",
    "title": "Quantum Monte Carlo study of systems interacting via long-range interactions mediated by a cavity",
    "authors": "Marta Domínguez-Navarro, Abel Rojo-Francàs, Bruno Juliá-Díaz, Grigori E. Astrakharchik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10301v1",
    "source": "arXiv",
    "abstract": "We study one-dimensional quantum gases in continuous space with cavity-mediated infinite-range interactions using variational and diffusion Monte Carlo methods. Starting from the exact two-body solution, we construct a non-translationally invariant Jastrow wavefunction that accurately captures the spatial structure induced by the cavity field and provides an efficient many-body ansatz for both bosonic and fermionic systems. We analize properties of three characteristic quantum systems, subject to long-range interactions: (i) ideal Bose gas (ii) interacting Bose gas (iii) ideal Fermi gas. In the absence of short-range interactions, we identify a crossover from a stable, weakly modulated phase realized for repulsive interactions to a delocalized bound state for attractive interactions, marked by clustering, loss of superfluidity, and the absence of a thermodynamic limit. Introducing short-range repulsion, either through contact interactions or fermionic statistics, leads to the formation of a mesoscopic gas-like regime that disappears in the thermodynamic limit. A qualitative phase diagram is proposed to illustrate the combined effects of short- and long-range interactions, highlighting the emergence of distinct regimes with characteristic structural properties."
  },
  {
    "date": "2026-01-15",
    "title": "CoCoPlan: Adaptive Coordination and Communication for Multi-robot Systems in Dynamic and Unknown Environments",
    "authors": "Xintong Zhang, Junfeng Chen, Yuxiao Zhu, Bing Luo, Meng Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10116v1",
    "source": "arXiv",
    "abstract": "Multi-robot systems can greatly enhance efficiency through coordination and collaboration, yet in practice, full-time communication is rarely available and interactions are constrained to close-range exchanges. Existing methods either maintain all-time connectivity, rely on fixed schedules, or adopt pairwise protocols, but none adapt effectively to dynamic spatio-temporal task distributions under limited communication, resulting in suboptimal coordination. To address this gap, we propose CoCoPlan, a unified framework that co-optimizes collaborative task planning and team-wise intermittent communication. Our approach integrates a branch-and-bound architecture that jointly encodes task assignments and communication events, an adaptive objective function that balances task efficiency against communication latency, and a communication event optimization module that strategically determines when, where and how the global connectivity should be re-established. Extensive experiments demonstrate that it outperforms state-of-the-art methods by achieving a 22.4% higher task completion rate, reducing communication overhead by 58.6%, and improving the scalability by supporting up to 100 robots in dynamic environments. Hardware experiments include the complex 2D office environment and large-scale 3D disaster-response scenario."
  },
  {
    "date": "2026-01-15",
    "title": "Remarks on the convex integration technique applied to singular stochastic partial differential equations",
    "authors": "Hongjie Dong, Kazuo Yamazaki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09990v1",
    "source": "arXiv",
    "abstract": "Singular stochastic partial differential equations informally refer to the partial differential equations with rough random force that leads to the products in the nonlinear terms becoming ill-defined. Besides the theories of regularity structures and paracontrolled distributions, the technique of convex integration has emerged as a possible approach to construct a solution to such singular stochastic partial differential equations. We review recent developments in this area, and also demonstrate that an application of the convex integration technique to prove non-uniqueness seems unlikely for a particular singular stochastic partial differential equation, specifically the $Φ^{4}$ model from quantum field theory."
  },
  {
    "date": "2026-01-15",
    "title": "Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems",
    "authors": "Amir Khurshid, Abhishek Sehgal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10681v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed and diversity-constrained context bubble construction framework is proposed that assembles coherent, citable bundles of spans under a strict token budget. The method preserves and exploits inherent document structure by organising multi-granular spans (e.g., sections and rows) and using task-conditioned structural priors to guide retrieval. Starting from high-relevance anchor spans, a context bubble is constructed through constrained selection that balances query relevance, marginal coverage, and redundancy penalties. It will explicitly constrain diversity and budget, producing compact and informative context sets, unlike top-k retrieval. Moreover, a full retrieval is emitted that traces the scoring and selection choices of the records, thus providing auditability and deterministic tuning. Experiments on enterprise documents demonstrate the efficiency of context bubble as it significantly reduces redundant context, is better able to cover secondary facets and has a better answer quality and citation faithfulness within a limited context window. Ablation studies demonstrate that both structural priors as well as diversity constraint selection are necessary; removing either component results in a decline in coverage and an increase in redundant or incomplete context."
  },
  {
    "date": "2026-01-15",
    "title": "The Static Heavy Quark-Antiquark Potential within String Theory in Arbitrary Stationary Backgrounds",
    "authors": "Nikita Tsegelnik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10668v1",
    "source": "arXiv",
    "abstract": "We analyze a static open string in a general stationary spacetime, which can represent a heavy quark-antiquark pair within the holographic framework or effective theory. We establish that for a simple U-shaped string with only radial dependence on the space string coordinate, $x_r'(σ) \\neq 0$, the string is generally not symmetric about its turning point, and the symmetry restores only for backgrounds with $h_{pr} = G_{00} G_{pr} - G_{0p} G_{0r} = 0$. Consequently, such asymmetric strings directly probe a possibility of the parity violation in the quark-antiquark interaction. Nevertheless, we identify a wide family of metrics for which the symmetry is preserved, enabling a direct isolation of the linear-in-distance term in the static interquark potential for simple symmetric string configurations, even in non-diagonal backgrounds. Applying the holographic framework, we further study the Rindler-AdS spacetime dual to an accelerated $\\mathcal{N}=4$ super Yang-Mills plasma. We show that the distance between quarks decreases, the static potential between them increases, and the deconfinement phase transition temperature, $T_{\\rm dec} = (π/3) T_H = a_c/6$, increases with an acceleration. However, we observe that an acceleration-scaled potential as a function of the acceleration-scaled distance does not depend on the certain value of the acceleration This result, reflecting the scale invariance and self-similarity of the holographic setup, can be also obtained in the dimensionless metric after scaling of the coordinates onto the acceleration, $\\tilde{x}_i = a_c x_i$, for which one obtains an universal value of the phase transition temperature, $\\tilde{T}_{\\rm dec} = (π/3) \\tilde{T}_H = 1/6$."
  },
  {
    "date": "2026-01-15",
    "title": "Stable evaluation of derivatives for barycentric and continued fraction representations of rational functions",
    "authors": "Tobin A. Driscoll, Yuxing Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10667v1",
    "source": "arXiv",
    "abstract": "Fast algorithms for approximation by rational functions exist for both barycentric and Thiele continued fraction (TCF) representations. We present the first numerically stable methods for derivative evaluation in the barycentric representation, including an $O(n)$ algorithm for all derivatives. We also extend an earlier $O(n)$ algorithm for evaluation of the TCF first derivative to higher orders. Numerical experiments confirm the robustness and efficiency of the proposed methods."
  },
  {
    "date": "2026-01-15",
    "title": "Hyperkähler Degenerations from Parabolic $\\mathrm{SL}(2,\\mathbb{C})$-Higgs Bundles Moduli Spaces on the Punctured Sphere to Hyperpolygon Spaces",
    "authors": "Laura Fredrickson, Arya Yae",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10656v1",
    "source": "arXiv",
    "abstract": "Complete hyperkähler 4-manifolds of finite energy are grouped into ALE, ALF, ALG$^{(*)}$, ALH$^{(*)}$, each of these being further classified according to the Dynkin type of their noncompact end. A family of ALG-$D_4$ spaces are modeled by certain moduli spaces of strongly parabolic $\\mathrm{SL}(2,\\mathbb{C})$-Higgs bundles on the Riemann sphere with $n=4$ punctures. Meanwhile, a family of ALE-$D_4$ spaces are modeled by certain Nakajima quiver varieties known as $n=4$ hyperpolygon spaces. There is a map from hyperpolygon space to the moduli space of strong parabolic $\\mathrm{SL}(2,\\mathbb{C})$-Higgs bundles that is a diffeomorphism onto its open and dense image. We show that under a fine-tuned degenerate limit, the pullback of a family of ALG-$D_4$ metrics parameterized by $R$ converges pointwise to the ALE-$D_4$ metric as $R \\to 0$. While the connection to gravitational instantons occurs in the $n=4$ case, we prove our result for any finite $n$."
  },
  {
    "date": "2026-01-15",
    "title": "Symmetries of Borcherds algebras",
    "authors": "Lisa Carbone",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10653v1",
    "source": "arXiv",
    "abstract": "We give an overview of the construction of Borcherds algebras, particularly the Monstrous Lie algebras $\\mathfrak m_g$ constructed by Carnahan, where $g$ is an element of the Monster finite simple group. When $g$ is the identity element, $\\mathfrak m_g$ is the Monster Lie algebra of Borcherds. We discuss the appearance of the $\\mathfrak m_g$ in compactified models of the Heterotic String. We also summarize recent work on associating Lie group analogs to the Lie algebras $\\mathfrak m_g$. We include a discussion of some open problems."
  },
  {
    "date": "2026-01-15",
    "title": "Converse Bounds for Sun-Jafar-type Weak Private Information Retrieval",
    "authors": "Chandan Anand, Jayesh Seshadri, Prasad Krishnan, Gowtham R. Kurri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10643v1",
    "source": "arXiv",
    "abstract": "Building on the well-established capacity-achieving schemes of Sun-Jafar (for replicated storage) and the closely related scheme of Banawan-Ulukus (for MDS-coded setting), a recent work by Chandan et al. proposed new classes of weak private information retrieval (WPIR) schemes for the collusion-free (replication and MDS-coded) setting, as well as for the $T$-colluding scenario. In their work, Chandan et al. characterized the expressions for the rate-privacy trade-offs for these classes of WPIR schemes, under the mutual information leakage and maximal leakage metrics. Explicit achievable trade-offs for the same were also presented, which were shown to be competitive or better than prior WPIR schemes. However, the class-wise optimality of the reported trade-offs were unknown. In this work, we show that the explicit rate-privacy trade-offs reported for the Sun-Jafar-type schemes by Chandan et al. are optimal for the non-colluding and replicated setting. Furthermore, we prove the class-wise optimality for Banawan-Ulukus-type MDS-WPIR and Sun-Jafar-type $T$-colluding WPIR schemes, under threshold-constraints on the system parameters. When these threshold-constraints do not hold, we present counter-examples which show that even higher rates than those reported before can be achieved."
  },
  {
    "date": "2026-01-15",
    "title": "Adjusted Similarity Measures and a Violation of Expectations",
    "authors": "William L. Lippitt, Edward J. Bedrick, Nichole E. Carlson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10641v1",
    "source": "arXiv",
    "abstract": "Adjusted similarity measures, such as Cohen's kappa for inter-rater reliability and the adjusted Rand index used to compare clustering algorithms, are a vital tool for comparing discrete labellings. These measures are intended to have the property of 0 expectation under a null distribution and maximum value 1 under maximal similarity to aid in interpretation. Measures are frequently adjusted with respect to the permutation distribution for historic and analytic reasons. There is currently renewed interest in considering other null models more appropriate for context, such as clustering ensembles permitting a random number of identified clusters. The purpose of this work is two -- fold: (1) to generalize the study of the adjustment operator to general null models and to a more general procedure which includes statistical standardization as a special case and (2) to identify sufficient conditions for the adjustment operator to produce the intended properties, where sufficient conditions are related to whether and how observed data are incorporated into null distributions. We demonstrate how violations of the sufficient conditions may lead to substantial breakdown, such as by producing a non-positive measure under traditional adjustment rather than one with mean 0, or by producing a measure which is deterministically 0 under statistical standardization."
  },
  {
    "date": "2026-01-15",
    "title": "CoMoVi: Co-Generation of 3D Human Motions and Realistic Videos",
    "authors": "Chengfeng Zhao, Jiazhi Shu, Yubo Zhao, Tianyu Huang, Jiahao Lu, Zekai Gu, Chengwei Ren, Zhiyang Dou, Qing Shuai, Yuan Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10632v1",
    "source": "arXiv",
    "abstract": "In this paper, we find that the generation of 3D human motions and 2D human videos is intrinsically coupled. 3D motions provide the structural prior for plausibility and consistency in videos, while pre-trained video models offer strong generalization capabilities for motions, which necessitate coupling their generation processes. Based on this, we present CoMoVi, a co-generative framework that couples two video diffusion models (VDMs) to generate 3D human motions and videos synchronously within a single diffusion denoising loop. To achieve this, we first propose an effective 2D human motion representation that can inherit the powerful prior of pre-trained VDMs. Then, we design a dual-branch diffusion model to couple human motion and video generation process with mutual feature interaction and 3D-2D cross attentions. Moreover, we curate CoMoVi Dataset, a large-scale real-world human video dataset with text and motion annotations, covering diverse and challenging human motions. Extensive experiments demonstrate the effectiveness of our method in both 3D human motion and video generation tasks."
  },
  {
    "date": "2026-01-15",
    "title": "Circumplanetary Disk Candidate in the Disk of HD 163296 Traced by Localized Emission from Simple Organics",
    "authors": "Andres F. Izquierdo, Jaehan Bae, Maria Galloway-Sprietsma, Ewine F. van Dishoeck, Stefano Facchini, Giovanni Rosotti, Jochen Stadler, Myriam Benisty, Leonardo Testi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10631v1",
    "source": "arXiv",
    "abstract": "Atacama Large Millimeter/submillimeter Array observations suggest that the disc of HD 163296 is being actively shaped by embedded, yet unseen protoplanets, as indicated by numerous gas and dust substructures consistent with planet-disc interaction models. We report the first detection of simple organic molecules, HCN and C2H, tracing a candidate circumplanetary disc (CPD) in the HD 163296 system, located at an orbital radius of $R=88\\pm7$ au and azimuth $φ=46\\pm3^\\circ$ (or $R=0.75''$, $\\rm{PA}=350^\\circ$ in projected sky coordinates), and originating near the midplane of the circumstellar disc. The signature is localised but spectrally resolved, and it overlaps with a previously reported planet candidate, P94, identified through kinematic perturbations traced by CO lines. We propose a scenario in which the observed chemical anomalies arise from increased heating driven by the forming planet and ongoing accretion through its CPD, facilitating the thermal desorption of species that would otherwise remain frozen out in the disc midplane, and potentially triggering the activation barriers of chemical reactions that lead to enhanced molecular production. Based on a first-order dynamical analysis of the HCN spectrum from the CPD--isolated with a 7$σ$ significance--we infer an upper limit on the planet mass of 1.8 $M_{\\rm Jup}$, consistent with predictions from CO kinematics and constraints from direct imaging studies. By comparing the CPD sizes derived from our models with theoretical expectations where the CPD radius corresponds to roughly one-third of the planet's Hill radius, we favor CPD gas temperatures $T > 150$ K, planet masses $M_{\\rm p} < 1.0$ $M_{\\rm Jup}$, and CPD radii $R_{\\rm CPD} < 2$ au."
  },
  {
    "date": "2026-01-15",
    "title": "Fair Regression under Demographic Parity: A Unified Framework",
    "authors": "Yongzhen Feng, Weiwei Wang, Raymond K. W. Wong, Xianyang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10623v1",
    "source": "arXiv",
    "abstract": "We propose a unified framework for fair regression tasks formulated as risk minimization problems subject to a demographic parity constraint. Unlike many existing approaches that are limited to specific loss functions or rely on challenging non-convex optimization, our framework is applicable to a broad spectrum of regression tasks. Examples include linear regression with squared loss, binary classification with cross-entropy loss, quantile regression with pinball loss, and robust regression with Huber loss. We derive a novel characterization of the fair risk minimizer, which yields a computationally efficient estimation procedure for general loss functions. Theoretically, we establish the asymptotic consistency of the proposed estimator and derive its convergence rates under mild assumptions. We illustrate the method's versatility through detailed discussions of several common loss functions. Numerical results demonstrate that our approach effectively minimizes risk while satisfying fairness constraints across various regression settings."
  },
  {
    "date": "2026-01-15",
    "title": "Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding",
    "authors": "Christopher Clark, Jieyu Zhang, Zixian Ma, Jae Sung Park, Mohammadreza Salehi, Rohun Tripathi, Sangho Lee, Zhongzheng Ren, Chris Dongjoo Kim, Yinuo Yang, Vincent Shao, Yue Yang, Weikai Huang, Ziqi Gao, Taira Anderson, Jianrui Zhang, Jitesh Jain, George Stoica, Winson Han, Ali Farhadi, Ranjay Krishna",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10611v1",
    "source": "arXiv",
    "abstract": "Today's strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstream applications require more than just high-level video understanding; they require grounding -- either by pointing or by tracking in pixels. Even proprietary models lack this capability. We present Molmo2, a new family of VLMs that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. Our key contribution is a collection of 7 new video datasets and 2 multi-image datasets, including a dataset of highly detailed video captions for pre-training, a free-form video Q&A dataset for fine-tuning, a new object tracking dataset with complex queries, and an innovative new video pointing dataset, all collected without the use of closed VLMs. We also present a training recipe for this data utilizing an efficient packing and message-tree encoding scheme, and show bi-directional attention on vision tokens and a novel token-weight strategy improves performance. Our best-in-class 8B model outperforms others in the class of open weight and data models on short videos, counting, and captioning, and is competitive on long-videos. On video-grounding Molmo2 significantly outperforms existing open-weight models like Qwen3-VL (35.5 vs 29.6 accuracy on video counting) and surpasses proprietary models like Gemini 3 Pro on some tasks (38.4 vs 20.0 F1 on video pointing and 56.2 vs 41.1 J&F on video tracking)."
  },
  {
    "date": "2026-01-15",
    "title": "iTIMO: An LLM-empowered Synthesis Dataset for Travel Itinerary Modification",
    "authors": "Zhuoxuan Huang, Yunshan Ma, Hongyu Zhang, Hua Ma, Zhu Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10609v1",
    "source": "arXiv",
    "abstract": "Addressing itinerary modification is crucial for enhancing the travel experience as it is a frequent requirement during traveling. However, existing research mainly focuses on fixed itinerary planning, leaving modification underexplored. To bridge this gap, we formally define the itinerary modification task and introduce iTIMO, a dataset specifically tailored for this purpose. We identify the lack of {\\itshape need-to-modify} itinerary data as the critical bottleneck hindering research on this task and propose a general pipeline to overcome it. This pipeline frames the generation of such data as an intent-driven perturbation task. It instructs large language models to perturb real world itineraries using three atomic editing operations: REPLACE, ADD, and DELETE. Each perturbation is grounded in three intents, including disruptions of popularity, spatial distance, and category diversity. Furthermore, a hybrid evaluation metric is designed to ensure perturbation effectiveness. We conduct comprehensive experiments on iTIMO, revealing the limitations of current LLMs and lead to several valuable directions for future research. Dataset and corresponding code are available at https://github.com/zelo2/iTIMO."
  },
  {
    "date": "2026-01-15",
    "title": "A user subscription model in mobile radio access networks with network slicing",
    "authors": "José-Ramón Vidal, Luis Guijarro, Vicent Pla",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10605v1",
    "source": "arXiv",
    "abstract": "Network slicing is an architectural enabling technology that logically decouples the current cellular networks into infrastructure providers (InPs) and Network Slice Tenants (NSTs). The network resources (e.g., radio access resources at each cell) are owned by the InP, and are shared by the NSTs to provide a service to their mobile users. In this context, we proposed a business model that includes resource allocation and user subscription to NSTs in a competitive setting, and provides, among other things, closed-form expressions for the subscription indicators in equilibrium of each NST at each cell. This model relies on the widely adopted logit model to characterize user subscriptions. However, as a consequence of user mobility and radio propagation, some of the underlying assumptions in the logit model do not hold. Therefore, further research is needed to assess the accuracy of the results provided by the logit model in a mobile radio scenario. We carry out a thorough evaluation of the validity of the model by comparing its results against those obtained through computer simulation. Our simulation model includes complete and realistic characterizations of user mobility and radio propagation. From the results, we conclude in most cases the logit model provides valid results in a mobile radio scenario."
  },
  {
    "date": "2026-01-15",
    "title": "Unifying soft and hard dynamics: The hard current algebra in celestial holography",
    "authors": "Reiko Liu, Wen-Jie Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10601v1",
    "source": "arXiv",
    "abstract": "Soft current algebras capture the infrared structure of scattering in asymptotically flat spacetimes, but an analogous algebraic description of finite-energy dynamics has been missing. We uncover an infinite-dimensional hard current algebra that encodes finite-energy contributions to scattering and implies novel Ward identities. The soft current algebras are not independent but arise naturally from the hard ones. This provides a unified algebraic framework underlying quantum theory in flat spacetime."
  },
  {
    "date": "2026-01-15",
    "title": "Procedural Fairness in Multi-Agent Bandits",
    "authors": "Joshua Caiata, Carter Blair, Kate Larson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10600v1",
    "source": "arXiv",
    "abstract": "In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and provides for proportionality in outcomes. Empirical results confirm that fairness notions based on optimizing for outcomes sacrifice equal voice and representation, while the sacrifice in outcome-based fairness objectives (like equality and utilitarianism) is minimal under procedurally fair policies. We further prove that different fairness notions prioritize fundamentally different and incompatible values, highlighting that fairness requires explicit normative choices. This paper argues that procedural legitimacy deserves greater focus as a fairness objective, and provides a framework for putting procedural fairness into practice."
  },
  {
    "date": "2026-01-15",
    "title": "Quantum solver for single-impurity Anderson models with particle-hole symmetry",
    "authors": "Mariia Karabin, Tanvir Sohail, Dmytro Bykov, Eduardo Antonio Coello Pérez, Swarnava Ghosh, Murali Gopalakrishnan Meena, Seongmin Kim, Amir Shehata, In-Saeng Suh, Hanna Terletska, Markus Eisenbach",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10594v1",
    "source": "arXiv",
    "abstract": "Quantum embedding methods, such as dynamical mean-field theory (DMFT), provide a powerful framework for investigating strongly correlated materials. A central computational bottleneck in DMFT is in solving the Anderson impurity model (AIM), whose exact solution is classically intractable for large bath sizes. In this work, we develop and benchmark a quantum-classical hybrid solver tailored for DMFT applications, using the variational quantum eigensolver (VQE) to prepare the ground state of the AIM with shallow quantum circuits. The solver uses a unified ansatz framework to prepare the particle and hole excitations of the ground-state from parameter-shifted circuits, enabling the reconstruction of the impurity Green's function through a continued-fraction expansion. We evaluate the performance of this approach across a few bath sizes and interaction strengths under noisy, shot-limited conditions. We compare three optimization routines (COBYLA, Adam, and L-BFGS-B) in terms of convergence and fidelity, assess the benefits of estimating a quantum-computed moment (QCM) correction to the variational energies, and benchmark the approach by comparing the reconstructed density of states (DOS) against that obtained using a classical pipeline. Our results demonstrate the feasibility of Green's function reconstruction on near-term devices and establish practical benchmarks for quantum impurity solvers embedded within self-consistent DMFT loops."
  },
  {
    "date": "2026-01-15",
    "title": "ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition",
    "authors": "Arundeep Chinta, Lucas Vinh Tran, Jay Katukuri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10591v1",
    "source": "arXiv",
    "abstract": "Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of uncertainty, or lack principled calibration mechanisms. While recent TSFMs employ sophisticated techniques such as mixture models, Student's t-distributions, or conformal prediction, they fail to address the core challenge of providing theoretically-grounded uncertainty decomposition. For the very first time, we present a novel transformer-based probabilistic framework, ProbFM (probabilistic foundation model), that leverages Deep Evidential Regression (DER) to provide principled uncertainty quantification with explicit epistemic-aleatoric decomposition. Unlike existing approaches that pre-specify distributional forms or require sampling-based inference, ProbFM learns optimal uncertainty representations through higher-order evidence learning while maintaining single-pass computational efficiency. To rigorously evaluate the core DER uncertainty quantification approach independent of architectural complexity, we conduct an extensive controlled comparison study using a consistent LSTM architecture across five probabilistic methods: DER, Gaussian NLL, Student's-t NLL, Quantile Loss, and Conformal Prediction. Evaluation on cryptocurrency return forecasting demonstrates that DER maintains competitive forecasting accuracy while providing explicit epistemic-aleatoric uncertainty decomposition. This work establishes both an extensible framework for principled uncertainty quantification in foundation models and empirical evidence for DER's effectiveness in financial applications."
  },
  {
    "date": "2026-01-15",
    "title": "Form and Meaning in Intrinsic Multilingual Evaluations",
    "authors": "Wessel Poelman, Miryam de Lhoneux",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10580v1",
    "source": "arXiv",
    "abstract": "Intrinsic evaluation metrics for conditional language models, such as perplexity or bits-per-character, are widely used in both mono- and multilingual settings. These metrics are rather straightforward to use and compare in monolingual setups, but rest on a number of assumptions in multilingual setups. One such assumption is that comparing the perplexity of CLMs on parallel sentences is indicative of their quality since the information content (here understood as the semantic meaning) is the same. However, the metrics are inherently measuring information content in the information-theoretic sense. We make this and other such assumptions explicit and discuss their implications. We perform experiments with six metrics on two multi-parallel corpora both with mono- and multilingual models. Ultimately, we find that current metrics are not universally comparable. We look at the form-meaning debate to provide some explanation for this."
  },
  {
    "date": "2026-01-15",
    "title": "Superfluid Density, Penetration Depth, Condensate Density",
    "authors": "Warren E. Pickett",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10578v1",
    "source": "arXiv",
    "abstract": "Fascination with the concept of superconducting (SC) {\\it superfluid density} $ρ_s$ has persisted since the beginning of superconductivity theory, with numerical values of an actual density rarely provided. Over time $ρ_s$, addressed mostly in cuprate and following high temperature superconductors, has become synonymous with the normalized (unitless) inverse square of the magnetic penetration depth $λ_L$ (the London expression, with superfluid density denoted $n_s$), with interest primarily on its temperature $T$ dependence that is expected to reflect the T-dependence of the SC gap amplitude and gap symmetry. In conventional superconductors, generalized expressions from the London penetration depth via Ginzburg-Landau theory, then to BCS theory provide updated pictures of the supercurrent density-vector potential relationship. The BCS value $λ_{band}$ is distinct from any particle density, instead involving particle availability at the Fermi surface and Fermi velocity as the determining factors, thus providing a basis for a more fundamental theory and understanding of what is being probed in penetration depth studies. The number density of superconducting electrons ${\\cal N}_s(T$=0) -- the scalar SC {\\it condensate density} -- is provided, first from a phenomenological estimate but then supported by BCS theory. A straightforward relation connecting ${\\cal N}_s(0)$ to the density of dynamically transporting carriers in the normal state at $T_c$ is obtained. Numerical values of relevant material parameters including $λ_{band}$ and ${\\cal N}_s$ are provided for a few conventional SCs."
  },
  {
    "date": "2026-01-15",
    "title": "Origins of the UV continuum and Balmer emission lines in Little Red Dots: observational validation of dense gas envelope models enshrouding the AGN",
    "authors": "Yoshihisa Asada, Kohei Inayoshi, Qinyue Fei, Seiji Fujimoto, Chris Willott",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10573v1",
    "source": "arXiv",
    "abstract": "We present a statistical study on the origins of the UV continuum and narrow/broad emission lines in little red dots (LRDs), a newly discovered class of active galactic nuclei (AGNs). Leveraging all archived JWST/NIRSpec data, we build a sample of 28 spectroscopically-confirmed LRDs at $5<z_{\\rm spec}<7.2$, by requiring broad H$α$ emission, blue UV colors, V-shaped continua, and compact morphologies. We define a control sample of 9 blue, compact, broad-line AGNs without red optical continua (hereafter little blue dots; LBDs), and examine correlations between rest UV and the narrow/broad H$α$ luminosities in these populations. In LRDs, both narrow and broad H$α$ components are tightly correlated with the UV continuum, and the luminosity ratios are consistent with those in young starburst galaxies. In contrast, the UV to broad H$α$ ratios in LBDs closely match local unobscured AGNs and are statistically different from LRDs. The Ly$α$ occurrence rates and strengths do not differ between LRDs and LBDs and are comparable to normal star-forming galaxies. These results are consistent with a scenario where the central BH in LRDs is enshrouded by a dense opaque gas envelope -- in this model, the UV continuum as well as narrow and even broad H$α$ emissions are not powered by AGNs but predominantly by young massive stars surrounding the envelope, while the envelope radiates as a $\\sim 5000$ K blackbody. As the envelope dissipates, direct AGN emission can emerge, potentially transforming LRDs into LBDs and marking the end of a short-lived phase of rapid black hole growth."
  },
  {
    "date": "2026-01-15",
    "title": "Deterministic and scalable generation of large Fock states",
    "authors": "Mo Xiong, Jize Han, Chuanzhen Cao, Jinbin Li, Qi Liu, Zhiguo Huang, Ming Xue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10559v1",
    "source": "arXiv",
    "abstract": "The scalable and deterministic preparation of large Fock-number states represents a long-standing frontier in quantum science, with direct implications for quantum metrology, communication, and simulation. Despite significant progress in small-scale implementations, extending such state generation to large excitation numbers while maintaining high fidelity remains a formidable challenge. Here, we present a scalable protocol for generating large Fock states with fidelities exceeding 0.9 up to photon numbers on the order of 100, achieved using only native control operations and, when desired, further enhanced by an optional post-selection step. Our method employs a hybrid Genetic-Adam optimization framework that combines the global search efficiency of genetic algorithms with the adaptive convergence of Adam to optimize multi-pulse control sequences comprising Jaynes-Cummings interactions and displacement operations, both of which are native to leading experimental platforms. The resulting control protocols achieve high fidelities with shallow circuit depths and strong robustness against parameter variations. These results establish an efficient and scalable pathway toward high-fidelity non-classical state generation for precision metrology and fault-tolerant quantum technologies."
  },
  {
    "date": "2026-01-15",
    "title": "Enhancing Mobile Ad Hoc Networks (MANETs) with Software-Defined Networking (SDN): A Balanced Approach",
    "authors": "Riccardo Fonti, Andrea Piroddi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10556v1",
    "source": "arXiv",
    "abstract": "Mobile Ad Hoc Networks (MANETs) are decentralized wireless networks, characterized by their dynamic topologies and node mobility. In the era of cutting-edge technologies, integrating Software-Defined Networking (SDN) with MANETs offers a promising solution to manage these challenges more efficiently. This paper presents a balanced discussion of MANETs and SDN, demonstrating how SDN principles, such as centralized control and network virtualization, can optimize MANET performance in terms of scalability, cost-efficiency, and security. A mathematical model is developed to analyze Capital Expenditures (CAPEX), Operational Expenditures (OPEX), and network efficiency."
  },
  {
    "date": "2026-01-15",
    "title": "Inference-time Physics Alignment of Video Generative Models with Latent World Models",
    "authors": "Jianhao Yuan, Xiaofeng Zhang, Felix Friedrich, Nicolas Beltran-Velez, Melissa Hall, Reyhane Askari-Hemmat, Xiaochuang Han, Nicolas Ballas, Michal Drozdzal, Adriana Romero-Soriano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10553v1",
    "source": "arXiv",
    "abstract": "State-of-the-art video generative models produce promising visual content yet often violate basic physics principles, limiting their utility. While some attribute this deficiency to insufficient physics understanding from pre-training, we find that the shortfall in physics plausibility also stems from suboptimal inference strategies. We therefore introduce WMReward and treat improving physics plausibility of video generation as an inference-time alignment problem. In particular, we leverage the strong physics prior of a latent world model (here, VJEPA-2) as a reward to search and steer multiple candidate denoising trajectories, enabling scaling test-time compute for better generation performance. Empirically, our approach substantially improves physics plausibility across image-conditioned, multiframe-conditioned, and text-conditioned generation settings, with validation from human preference study. Notably, in the ICCV 2025 Perception Test PhysicsIQ Challenge, we achieve a final score of 62.64%, winning first place and outperforming the previous state of the art by 7.42%. Our work demonstrates the viability of using latent world models to improve physics plausibility of video generation, beyond this specific instantiation or parameterization."
  },
  {
    "date": "2026-01-15",
    "title": "Unleashing the Capabilities of Large Vision-Language Models for Intelligent Perception of Roadside Infrastructure",
    "authors": "Luxuan Fu, Chong Liu, Bisheng Yang, Zhen Dong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10551v1",
    "source": "arXiv",
    "abstract": "Automated perception of urban roadside infrastructure is crucial for smart city management, yet general-purpose models often struggle to capture the necessary fine-grained attributes and domain rules. While Large Vision Language Models (VLMs) excel at open-world recognition, they often struggle to accurately interpret complex facility states in compliance with engineering standards, leading to unreliable performance in real-world applications. To address this, we propose a domain-adapted framework that transforms VLMs into specialized agents for intelligent infrastructure analysis. Our approach integrates a data-efficient fine-tuning strategy with a knowledge-grounded reasoning mechanism. Specifically, we leverage open-vocabulary fine-tuning on Grounding DINO to robustly localize diverse assets with minimal supervision, followed by LoRA-based adaptation on Qwen-VL for deep semantic attribute reasoning. To mitigate hallucinations and enforce professional compliance, we introduce a dual-modality Retrieval-Augmented Generation (RAG) module that dynamically retrieves authoritative industry standards and visual exemplars during inference. Evaluated on a comprehensive new dataset of urban roadside scenes, our framework achieves a detection performance of 58.9 mAP and an attribute recognition accuracy of 95.5%, demonstrating a robust solution for intelligent infrastructure monitoring."
  },
  {
    "date": "2026-01-15",
    "title": "Flat-band Ferromagnetism of SU$(N)$ Hubbard Model on the Kagome Lattices",
    "authors": "Hao Jin, Wenxing Nie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10549v1",
    "source": "arXiv",
    "abstract": "The kagome lattice, a well known example of the geometrically frustrated system, hosts a dispersionless flat band that offers a unique platform for studying correlation-driven quantum phenomena. At appropriate particle concentrations, the existence of a flat band allows a representation of percolation with nontrivial weights. In this work, we investigate the paramagnetic-ferromagnetic transition in the repulsive SU($N$) Hubbard model on the kagome lattice within this percolation framework. In this representation, the model can be rigorously mapped to a classical $N$-state site-percolation problem on a triangular lattice, with the SU($N$) symmetry reflected in the nontrivial weights. By large-scale Monte Carlo simulations for SU($3$), SU($4$), and SU($10$) symmetries, we demonstrate that the critical particle concentration for ferromagnetism exceeds the standard percolation threshold and increases with $N$, indicating a strengthening of the effective entropic repulsion."
  },
  {
    "date": "2026-01-15",
    "title": "A Propagation Framework for Network Regression",
    "authors": "Yingying Ma, Chenlei Leng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10533v1",
    "source": "arXiv",
    "abstract": "We introduce a unified and computationally efficient framework for regression on network data, addressing limitations of existing models that require specialized estimation procedures or impose restrictive decay assumptions. Our Network Propagation Regression (NPR) models outcomes as functions of covariates propagated through network connections, capturing both direct and indirect effects. NPR is estimable via ordinary least squares for continuous outcomes and standard routines for binary, categorical, and time-to-event data, all within a single interpretable framework. We establish consistency and asymptotic normality under weak conditions and develop valid hypothesis tests for the order of network influence. Simulation studies demonstrate that NPR consistently outperforms established approaches, such as the linear-in-means model and regression with network cohesion, especially under model misspecification. An application to social media sentiment analysis highlights the practical utility and robustness of NPR in real-world settings."
  },
  {
    "date": "2026-01-15",
    "title": "PERM: Psychology-grounded Empathetic Reward Modeling for Large Language Models",
    "authors": "Chengbing Wang, Wuqiang Zheng, Yang Zhang, Fengbin Zhu, Junyi Cheng, Yi Xie, Wenjie Wang, Fuli Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10532v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly deployed in human-centric applications, yet they often fail to provide substantive emotional support. While Reinforcement Learning (RL) has been utilized to enhance empathy of LLMs, existing reward models typically evaluate empathy from a single perspective, overlooking the inherently bidirectional interaction nature of empathy between the supporter and seeker as defined by Empathy Cycle theory. To address this limitation, we propose Psychology-grounded Empathetic Reward Modeling (PERM). PERM operationalizes empathy evaluation through a bidirectional decomposition: 1) Supporter perspective, assessing internal resonation and communicative expression; 2) Seeker perspective, evaluating emotional reception. Additionally, it incorporates a bystander perspective to monitor overall interaction quality. Extensive experiments on a widely-used emotional intelligence benchmark and an industrial daily conversation dataset demonstrate that PERM outperforms state-of-the-art baselines by over 10\\%. Furthermore, a blinded user study reveals a 70\\% preference for our approach, highlighting its efficacy in generating more empathetic responses. Our code, dataset, and models are available at https://github.com/ZhengWwwq/PERM."
  },
  {
    "date": "2026-01-15",
    "title": "On the suboptimality of linear codes for binary distributed hypothesis testing",
    "authors": "Adway Girish, Robinson D. H. Cung, Emre Telatar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10526v1",
    "source": "arXiv",
    "abstract": "We study a binary distributed hypothesis testing problem where two agents observe correlated binary vectors and communicate compressed information at the same rate to a central decision maker. In particular, we study linear compression schemes and show that simple truncation is the best linear scheme in two cases: (1) testing opposite signs of the same magnitude of correlation, and (2) testing for or against independence. We conjecture, supported by numerical evidence, that truncation is the best linear code for testing any correlations of opposite signs. Further, for testing against independence, we also compute classical random coding exponents and show that truncation, and consequently any linear code, is strictly suboptimal."
  },
  {
    "date": "2026-01-15",
    "title": "Discovery of the First Five Carbon-Enhanced Metal-Poor Stars in the LMC",
    "authors": "Madeline Lucey, Vedant Chandra, Alexander Ji, Andrew Casey, David Nidever, Sean Morrison, Robyn Sanderson, Slater Oden, José Fernández-Trincado, Guilherme Limberg",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10514v1",
    "source": "arXiv",
    "abstract": "A substantial fraction of metal-poor stars in the local Milky Way halo exhibit large overabundances of carbon. These stars, dubbed Carbon-Enhanced Metal-Poor (CEMP) stars, provide crucial constraints on the nature of the early universe including the earliest nucleosynthetic events. Whether these stars exist at similar rates in nearby galaxies is a major open question with implications for the environmental dependence of early chemical evolution. Here, we present the discovery of the first five CEMP stars in the Milky Way's largest dwarf companion, the LMC, using SDSS-V spectra from the BOSS instrument. We measure metallicities ranging from [Fe/H] = -2.1 to -3.2 and evolutionary state corrected carbon enhancements of [C/Fe] = +1.2 to +2.4, placing these stars among the most metal-poor and carbon-rich ever identified in the LMC. This discovery demonstrates that CEMP stars do exist in the LMC despite previous null detections, and establishes the foundation for measuring the CEMP occurrence rate in this system. Such measurements will provide critical tests of whether environmental differences affect the formation channels and frequencies of these ancient, carbon-rich stars."
  },
  {
    "date": "2026-01-15",
    "title": "Scalable Algorithms for Approximate DNF Model Counting",
    "authors": "Paul Burkhardt, David G. Harris, Kevin T Schmitt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10511v1",
    "source": "arXiv",
    "abstract": "Model counting of Disjunctive Normal Form (DNF) formulas is a critical problem in applications such as probabilistic inference and network reliability. For example, it is often used for query evaluation in probabilistic databases. Due to the computational intractability of exact DNF counting, there has been a line of research into a variety of approximation algorithms. These include Monte Carlo approaches such as the classical algorithms of Karp, Luby, and Madras (1989), as well as methods based on hashing (Soos et al. 2023), and heuristic approximations based on Neural Nets (Abboud, Ceylan, and Lukasiewicz 2020). We develop a new Monte Carlo approach with an adaptive stopping rule and short-circuit formula evaluation. We prove it achieves Probably Approximately Correct (PAC) learning bounds and is asymptotically more efficient than the previous methods. We also show experimentally that it out-performs prior algorithms by orders of magnitude, and can scale to much larger problems with millions of variables."
  },
  {
    "date": "2026-01-15",
    "title": "A New Construction Structure on Multi-access Coded Caching with Linear Subpacketization: Cyclic Multi-Access Non-Half-Sum Disjoint Packing",
    "authors": "Mengyuan Li, Minquan Cheng, Kai Wan, Giuseppe Caire",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10510v1",
    "source": "arXiv",
    "abstract": "We consider the $(K,L,M,N)$ multi-access coded caching system introduced by Hachem et al., which consists of a central server with $N$ files and $K$ cache nodes, each of memory size $M$, where each user can access $L$ cache nodes in a cyclic wrap-around fashion. At present, several existing schemes achieve competitive transmission performance, but their subpacketization levels grow exponentially with the number of users. In contrast, schemes with linear or polynomial subpacketization always incur higher transmission loads. We aim to design a multi-access coded caching scheme with linear subpacketization $F$ while maintaining low transmission load. Recently, Cheng et al. proposed a construction framework for coded caching schemes with linear subpacketization (i.e., $F=K$) called non-half-sum disjoint packing (NHSDP). Inspired by this structure, we introduce a novel combinatorial structure named cyclic multi-access non-half-sum disjoint packing (CMA-NHSDP) by extending NHSDP to MACC system. By constructing CMA-NHSDP, we obtain a new class of multi-access coded caching schemes. Theoretical and numerical analyses show that our scheme achieves lower transmission loads than some existing schemes with linear subpacketization. Moreover, the proposed schemes achieves lower transmission load compared to existing schemes with exponential subpacketization in some case."
  },
  {
    "date": "2026-01-15",
    "title": "The incompatibility of the Condorcet winner and loser criteria with positive involvement and resolvability",
    "authors": "Wesley H. Holliday",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10506v1",
    "source": "arXiv",
    "abstract": "We prove that there is no preferential voting method satisfying the Condorcet winner and loser criteria, positive involvement (if a candidate $x$ wins in an initial preference profile, then adding a voter who ranks $x$ uniquely first cannot cause $x$ to lose), and resolvability (if $x$ initially ties for winning, then $x$ can be made the unique winner by adding a single voter). In a previous note, we proved an analogous result assuming an additional axiom of ordinal margin invariance, which we now show is unnecessary for an impossibility theorem, at least if the desired voting method is defined for five-candidate elections."
  },
  {
    "date": "2026-01-15",
    "title": "The emergence of our Universe",
    "authors": "Jan Ambjorn, Yoshiyuki Watabiki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10499v1",
    "source": "arXiv",
    "abstract": "We show how our Universe can emerge from a symmetry breaking of a multicomponent $W_3$ algebra, where the components in addition form a Jordan algebra. We discuss how symmetry breaking related to the Jordan algebras $H_3(C)$ and $H_3(O)$ over the complex and octonion numbers can lead to an extended four-dimensional spacetime, where the expansion of the Universe is governed by a modified Friedmann equation. We finally discuss how this modified Friedmann equation might explain a number of puzzling cosmological observations."
  },
  {
    "date": "2026-01-15",
    "title": "mergetune: Continued fine-tuning of vision-language models",
    "authors": "Wenqing Wang, Da Li, Xiatian Zhu, Josef Kittler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10497v1",
    "source": "arXiv",
    "abstract": "Fine-tuning vision-language models (VLMs) such as CLIP often leads to catastrophic forgetting of pretrained knowledge. Prior work primarily aims to mitigate forgetting during adaptation; however, forgetting often remains inevitable during this process. We introduce a novel paradigm, \\emph{continued fine-tuning (CFT)}, which seeks to recover pretrained knowledge after a zero-shot model has already been adapted. We propose a simple, model-agnostic CFT strategy (named MERGETUNE) guided by linear mode connectivity (LMC), which can be applied post hoc to existing fine-tuned models without requiring architectural changes. Given a fine-tuned model, we continue fine-tuning its trainable parameters (e.g., soft prompts or linear heads) to search for a continued model which has two low-loss paths to the zero-shot (e.g., CLIP) and the fine-tuned (e.g., CoOp) solutions. By exploiting the geometry of the loss landscape, the continued model implicitly merges the two solutions, restoring pretrained knowledge lost in the fine-tuned counterpart. A challenge is that the vanilla LMC constraint requires data replay from the pretraining task. We approximate this constraint for the zero-shot model via a second-order surrogate, eliminating the need for large-scale data replay. Experiments show that MERGETUNE improves the harmonic mean of CoOp by +5.6\\% on base-novel generalisation without adding parameters. % We show \\emph{the first time} superior performance than CLIP on both DTD and EuroSAT, on cross-dataset transfer. On robust fine-tuning evaluations, the LMC-merged model from MERGETUNE surpasses ensemble baselines with lower inference cost, achieving further gains and state-of-the-art results when ensembled with the zero-shot model. Our code is available at \\href{https://github.com/Surrey-UP-Lab/MERGETUNE}{https://github.com/Surrey-UP-Lab/MERGETUNE}."
  },
  {
    "date": "2026-01-15",
    "title": "Communication-Efficient Federated Learning by Exploiting Spatio-Temporal Correlations of Gradients",
    "authors": "Shenlong Zheng, Zhen Zhang, Yuhui Deng, Geyong Min, Lin Cui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10491v1",
    "source": "arXiv",
    "abstract": "Communication overhead is a critical challenge in federated learning, particularly in bandwidth-constrained networks. Although many methods have been proposed to reduce communication overhead, most focus solely on compressing individual gradients, overlooking the temporal correlations among them. Prior studies have shown that gradients exhibit spatial correlations, typically reflected in low-rank structures. Through empirical analysis, we further observe a strong temporal correlation between client gradients across adjacent rounds. Based on these observations, we propose GradESTC, a compression technique that exploits both spatial and temporal gradient correlations. GradESTC exploits spatial correlations to decompose each full gradient into a compact set of basis vectors and corresponding combination coefficients. By exploiting temporal correlations, only a small portion of the basis vectors need to be dynamically updated in each round. GradESTC significantly reduces communication overhead by transmitting lightweight combination coefficients and a limited number of updated basis vectors instead of the full gradients. Extensive experiments show that, upon reaching a target accuracy level near convergence, GradESTC reduces uplink communication by an average of 39.79% compared to the strongest baseline, while maintaining comparable convergence speed and final accuracy to uncompressed FedAvg. By effectively leveraging spatio-temporal gradient structures, GradESTC offers a practical and scalable solution for communication-efficient federated learning."
  },
  {
    "date": "2026-01-15",
    "title": "Finite lattice kinetic equations for bosons, fermions, and discrete NLS",
    "authors": "Jani Lukkarinen, Sakari Pirnes, Aleksis Vuoksenmaa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10486v1",
    "source": "arXiv",
    "abstract": "We introduce and study finite lattice kinetic equations for bosons, fermions, and discrete NLS. For each model this closed evolution equation provides an approximate description for the evolution of the appropriate covariance function in the system. It is obtained by truncating the cumulant hierarchy and dropping the higher order cumulants in the usual manner. To have such a reference solution should simplify controlling the full hierarchy and thus allow estimating the error from the truncation. The harmonic part is given by nearest neighbour hopping, with arbitrary symmetric interaction potential of coupling strength $λ>0$. We consider the well-posedness of the resulting evolution equation up to finite kinetic times on a finite but large enough lattice. We obtain decay of the solutions and upper bounds that are independent of $λ$ and depend on the lattice size only via some Sobolev type norms of the interaction potential and initial data. We prove that the solutions are not sensitive to how the energy conservation delta function is approximated."
  },
  {
    "date": "2026-01-15",
    "title": "Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge",
    "authors": "Runhao Zhao, Weixin Zeng, Wentao Zhang, Chong Chen, Zhengpin Li, Xiang Zhao, Lei Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10485v1",
    "source": "arXiv",
    "abstract": "Domain-specific knowledge graphs (DKGs) often lack coverage compared to general knowledge graphs (GKGs). To address this, we introduce Domain-specific Knowledge Graph Fusion (DKGF), a novel task that enriches DKGs by integrating relevant facts from GKGs. DKGF faces two key challenges: high ambiguity in domain relevance and misalignment in knowledge granularity across graphs. We propose ExeFuse, a simple yet effective Fact-as-Program paradigm. It treats each GKG fact as a latent semantic program, maps abstract relations to granularity-aware operators, and verifies domain relevance via program executability on the target DKG. This unified probabilistic framework jointly resolves relevance and granularity issues. We construct two benchmarks, DKGF(W-I) and DKGF(Y-I), with 21 evaluation configurations. Extensive experiments validate the task's importance and our model's effectiveness, providing the first standardized testbed for DKGF."
  },
  {
    "date": "2026-01-15",
    "title": "A Riemannian Autocorrelation Function and its Application to Non-Local Isoperimetric Energies",
    "authors": "Michael Bleher, Denis Brazke, Sebastian Nill",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10481v1",
    "source": "arXiv",
    "abstract": "We study a family of non-local isoperimetric energies $E_{γ,\\varepsilon}$ on the round sphere $M = S^n$, where the non-local interaction kernel $K_\\varepsilon$ is the fundamental solution of the Helmholtz operator $1 - \\varepsilon^2 Δ$. To analyse these energies, we introduce a Riemannian autocorrelation function $c_Ω$ associated to a measurable set $Ω\\subset M$, defined on any compact, connected, oriented Riemannian manifold without boundary $(M^n,g)$ of dimension $n\\ge2$. This function is intimately linked to Matheron's set covariogram from convex geometry. By establishing a characterisation of functions of bounded variation $BV(M)$ in terms of geodesic difference quotients, we show that $Ω$ has finite perimeter if and only if $c_Ω$ is Lipschitz, and we relate the Lipschitz constant to the perimeter of $Ω$. We show that on the round sphere $E_{γ,\\varepsilon}$ admits a reformulation in terms of $c_Ω$, which allows us to compute the limit as $\\varepsilon \\to 0$ in a variational sense, that is, in the framework of $Γ$-convergence."
  },
  {
    "date": "2026-01-15",
    "title": "Contextual StereoSet: Stress-Testing Bias Alignment Robustness in Large Language Models",
    "authors": "Abhinaba Basu, Pavan Chakraborty",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10460v1",
    "source": "arXiv",
    "abstract": "A model that avoids stereotypes in a lab benchmark may not avoid them in deployment. We show that measured bias shifts dramatically when prompts mention different places, times, or audiences -- no adversarial prompting required. We introduce Contextual StereoSet, a benchmark that holds stereotype content fixed while systematically varying contextual framing. Testing 13 models across two protocols, we find striking patterns: anchoring to 1990 (vs. 2030) raises stereotype selection in all models tested on this contrast (p<0.05); gossip framing raises it in 5 of 6 full-grid models; out-group observer framing shifts it by up to 13 percentage points. These effects replicate in hiring, lending, and help-seeking vignettes. We propose Context Sensitivity Fingerprints (CSF): a compact profile of per-dimension dispersion and paired contrasts with bootstrap CIs and FDR correction. Two evaluation tracks support different use cases -- a 360-context diagnostic grid for deep analysis and a budgeted protocol covering 4,229 items for production screening. The implication is methodological: bias scores from fixed-condition tests may not generalize.This is not a claim about ground-truth bias rates; it is a stress test of evaluation robustness. CSF forces evaluators to ask, \"Under what conditions does bias appear?\" rather than \"Is this model biased?\" We release our benchmark, code, and results."
  },
  {
    "date": "2026-01-15",
    "title": "The Wiener Wintner and Return Times Theorem Along the Primes",
    "authors": "Jan Fornal, Anastasios Fragkos, Ben Krause, Michael Lacey, Hamed Mousavi, Yu-Chen Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10459v1",
    "source": "arXiv",
    "abstract": "We prove the following Return Times Theorem along the sequence of prime times, the first extension of the Return Times Theorem to arithmetic sequences: For every probability space, $(Ω,ν)$, equipped with a measure-preserving transformation, $T \\colon Ω\\to Ω$, and every $f \\in L^\\infty(Ω)$, there exists a set of full probability, $Ω_f \\subset Ω$ with $ν(Ω_f) =1$, so that for all $ω\\in Ω_f$, for any other probability space $(X,μ)$, equipped with a measure-preserving transformation $S : X \\to X$, for any $g \\in L^{\\infty}(X)$, \\begin{align} \\frac{1}{N} \\sum_{n \\leq N} f(T^{p_n} ω) g(S^{p_n} \\cdot) \\end{align} converges $μ$-almost surely; above, $\\{ 2=p_1 < p_2 < \\dots \\}$ are an enumeration of the primes. The Wiener-Wintner theorem along the primes is an immediate corollary. Our proof lives at the interface of classical Fourier analysis, combinatorial number theory, higher order Fourier analysis, and pointwise ergodic theory, with $U^3$ theory playing an important role; our $U^3$-estimates for \\emph{Heath-Brown} models of the von Mangoldt function may be of independent interest."
  },
  {
    "date": "2026-01-15",
    "title": "LangLasso: Interactive Cluster Descriptions through LLM Explanation",
    "authors": "Raphael Buchmüller, Dennis Collaris, Linhao Meng, Angelos Chatzimparmpas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10458v1",
    "source": "arXiv",
    "abstract": "Dimensionality reduction is a powerful technique for revealing structure and potential clusters in data. However, as the axes are complex, non-linear combinations of features, they often lack semantic interpretability. Existing visual analytics (VA) methods support cluster interpretation through feature comparison and interactive exploration, but they require technical expertise and intense human effort. We present \\textit{LangLasso}, a novel method that complements VA approaches through interactive, natural language descriptions of clusters using large language models (LLMs). It produces human-readable descriptions that make cluster interpretation accessible to non-experts and allow integration of external contextual knowledge beyond the dataset. We systematically evaluate the reliability of these explanations and demonstrate that \\langlasso provides an effective first step for engaging broader audiences in cluster interpretation. The tool is available at https://langlasso.vercel.app"
  },
  {
    "date": "2026-01-15",
    "title": "Energy-Efficient Probabilistic Semantic Communication Over Visible Light Networks With Rate Splitting",
    "authors": "Zhouxiang Zhao, Zhaohui Yang, Mingzhe Chen, Chen Zhu, Xin Tong, Zhaoyang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10452v1",
    "source": "arXiv",
    "abstract": "Visible light communication (VLC) is emerging as a key technology for future wireless communication systems due to its unique physical-layer advantages over traditional radio-frequency (RF)-based systems. However, its integration with higher-layer techniques, such as semantic communication, remains underexplored. This paper investigates the energy efficiency maximization problem in a resource-constrained VLC-based probabilistic semantic communication (PSCom) system. In the considered model, light-emitting diode (LED) transmitters perform semantic compression to reduce data size, which incurs additional computation overhead. The compressed semantic information is transmitted to the users for semantic inference using a shared knowledge base that requires periodic updates to ensure synchronization. In the PSCom system, the knowledge base is represented by probabilistic graphs. To enable simultaneous transmission of both knowledge and information data, rate splitting multiple access (RSMA) is employed. The optimization problem focuses on maximizing energy efficiency by jointly optimizing transmit beamforming, direct current (DC) bias, common rate allocation, and semantic compression ratio, while accounting for both communication and computation costs. To solve this problem, an alternating optimization algorithm based on successive convex approximation (SCA) and Dinkelbach method is developed. Simulation results demonstrate the effectiveness of the proposed approach."
  },
  {
    "date": "2026-01-15",
    "title": "Islands of shape coexistence for Z=38-84 in a non-relativistic mean-field approach using Hartree-Fock-Bogoliubov theory",
    "authors": "Malik A. Hasan, Dennis Bonatsos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10447v1",
    "source": "arXiv",
    "abstract": "Based on the microscopic mechanism of the particle-hole (p-h) excitations in the proton and neutron single-particle energy levels relative to the Fermi energy, a search for islands of shape coexistence (SC) is performed over a wide range of even-even nuclei from Z=38 to 84 using non-relativistic self-consistent mean-field with the Hartree-Fock-Bogoliubov (HFB) theory using the Skyrme-SKI3 functional. The results of the present study show that neutron-induced islands of SC, corresponding to proton p-h excitations, are found around the magic numbers Z=82 and Z=50, centered at the relevant neutron midshells of N=104 and N=66 respectively, while proton-induced islands of SC, corresponding to neutron p-h excitations, are found around the neutron numbers N=90 and N=60, centered at the relevant proton midshells Z=66 and Z=38 respectively. In addition, islands of SC due to both neutron and proton particle-hole excitations are found around N=40, Z=40. The results of the present study are compared with the results of covariant density functional theory using the DDME2 functional, using the same p-h mechanism. The islands of SC that appeared in the CDFT work with the DDME2 functional are corroborated by the present study with the Skyrme-SKI3 functional, thus confirming the robustness of the particle-hole excitations mechanism in searching for islands of SC. In addition, the current study revealed new regions of SC, adjacent to the earlier islands and expanding their shores."
  },
  {
    "date": "2026-01-15",
    "title": "Chasing Opportunity: Spillovers and Drivers of U.S. State Population Growth",
    "authors": "Sebastian Kripfganz, Vasilis Sarafidis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10444v1",
    "source": "arXiv",
    "abstract": "We study the drivers and spatial diffusion of U.S. state population growth using a dynamic spatial model for 49 states, 1965-2017. Methodologically, we recover the spatial network structure from the data, rather than imposing it a priori via contiguity or distance, and combine this with an IV estimator that permits heterogeneous slopes and interactive fixed effects. This unified design delivers consistent estimation and inference in a flexible spatial panel model with endogenous regressors, a data-inferred network structure, and pervasive cross-state dependence. To our knowledge, it is the first estimation framework in spatial econometrics to combine all three elements within a single setting. Empirically, population growth exhibits broad yet heterogeneous conditional convergence: about three-quarters of states converge, while a small high-growth group mildly diverges. Effects of the core drivers, amenities, labour income, migration frictions, are stable across various network specifications. On the other hand, the productivity effect emerges only when the network is estimated from the data. Spatial spillovers are sizable, with indirect effects roughly one-third of total impacts, and diffusion extending beyond contiguous neighbours."
  },
  {
    "date": "2026-01-15",
    "title": "Development of Ontological Knowledge Bases by Leveraging Large Language Models",
    "authors": "Le Ngoc Luyen, Marie-Hélène Abel, Philippe Gouspillou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10436v1",
    "source": "arXiv",
    "abstract": "Ontological Knowledge Bases (OKBs) play a vital role in structuring domain-specific knowledge and serve as a foundation for effective knowledge management systems. However, their traditional manual development poses significant challenges related to scalability, consistency, and adaptability. Recent advancements in Generative AI, particularly Large Language Models (LLMs), offer promising solutions for automating and enhancing OKB development. This paper introduces a structured, iterative methodology leveraging LLMs to optimize knowledge acquisition, automate ontology artifact generation, and enable continuous refinement cycles. We demonstrate this approach through a detailed case study focused on developing a user context profile ontology within the vehicle sales domain. Key contributions include significantly accelerated ontology construction processes, improved ontological consistency, effective bias mitigation, and enhanced transparency in the ontology engineering process. Our findings highlight the transformative potential of integrating LLMs into ontology development, notably improving scalability, integration capabilities, and overall efficiency in knowledge management systems."
  },
  {
    "date": "2026-01-15",
    "title": "Aletheia-Probe: A Tool for Automated Journal Assessment",
    "authors": "Andreas Florath",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10431v1",
    "source": "arXiv",
    "abstract": "Assessing journal legitimacy during literature reviews, publication venue selection, and citation verification requires consulting information scattered across multiple incompatible data-sets. This paper introduces Aletheia-Probe, an open-source tool that systematically aggregates curated databases and pattern analysis from multiple authoritative sources to provide transparent, confidence-scored journal assessments. The tool explicitly reports which sources were consulted, what each found, and where evidence conflicts. The tool integrates into research workflows through command-line and programmatic interfaces. It reduces manual assessment overhead while explicitly flagging uncertain cases. We present the tool's architecture, core design principles, and practical integration approach. Comprehensive empirical validation will be presented in forthcoming work."
  },
  {
    "date": "2026-01-15",
    "title": "Active interrogation of underground piezoelectric fabrics using high energy muon beams propagating across seismogenic faults",
    "authors": "L. Serafini, A. Bacci, L. Bandiera, F. Broggi, I. Drebot, A. Frazzitta, A. M. Marotta, G. Muttoni, G. Paternò, V. Petrillo, M. Rossetti Conti, A. R. Rossi, S. Samsam, M. Voltolini, M. Zucali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10430v1",
    "source": "arXiv",
    "abstract": "In this paper we extend a previous analysis of a newly conceived technique based on active interrogation of tectonic stress evolution in regions hosting active seismogenic faults. The aim is to monitor and detect stable and reliable precursor signals on an adequate time scale, well before an earthquake event, that can play a crucial role in activating alarms for civil protection systems. The precursor signal relies on continuous measurements of the time evolution of tectonic stress, obtained by interrogating underground, with a high energy collimated muon beam, the piezoelectric fabrics present in quartz rich granite like rocks surrounding a known seismogenic fault in the Earth crust. Beam propagation through the rock across the active fault conveys to a detector at the exit of the traversal information on the amplitude of the piezoelectric field, which scales with the tectonic stress applied to quartz crystals embedded in the rock. The system, named ERMES (Earthquake Reconnaissance using Muon beam Evolution in Silicon dioxide), differs from other techniques under study detecting electromagnetic signals generated by piezoelectricity outside the Earth crust, as it probes piezoelectric effects directly inside the source region of the associated electromagnetic field, namely the near field within quartz crystals rather than the far field in open space. We present a focused analysis of muon beam manipulation after rock traversal and before detection using a newly conceived muonic lens, and we explore the maximum rock penetration capability of a high energy muon beam, reaching about 3 km of rock thickness for a 10 TeV beam. Owing to the peculiarity of muon propagation through such kilometer scale targets, we cross checked previous FLUKA Monte Carlo simulations with Geant4 to clarify the secondary muons role generated by primary muon interactions in solid matter over long propagation lengths."
  },
  {
    "date": "2026-01-15",
    "title": "Reduction of thermodynamic uncertainty by a virtual qubit",
    "authors": "Yang Li, Fu-Lin Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10429v1",
    "source": "arXiv",
    "abstract": "The thermodynamic uncertainty relation (TUR) imposes a fundamental constraint between current fluctuations and entropy production, providing a refined formulation of the second law for micro- and nanoscale systems. Quantum violations of the classical TUR reveal genuinely quantum thermodynamic effects, which are essential for improving performance and enabling optimization in quantum technologies. In this work, we analyze the TUR in a class of paradigmatic quantum thermal-machine models whose operation is enabled by coherent coupling between two energy levels forming a virtual qubit. Steady-state coherences are confined to this virtual-qubit subspace, while in the absence of coherent coupling the system satisfies detailed balance with the thermal reservoirs and supports no steady-state heat currents. We show that the steady-state currents and entropy production can be fully reproduced by an effective classical Markov process, whereas current fluctuations acquire an additional purely quantum correction originating from coherence. As a result, the thermodynamic uncertainty naturally decomposes into a classical (diagonal) contribution and a coherent contribution. The latter becomes negative under resonant conditions and reaches its minimum at the coupling strength that maximizes steady-state coherence. We further identify the optimization conditions and the criteria for surpassing the classical TUR bound in the vicinity of the reversible limit."
  },
  {
    "date": "2026-01-15",
    "title": "Unifying Quantum and Classical Dynamics",
    "authors": "Abdul Rahaman Shaikh, Tabish Qureshi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10423v1",
    "source": "arXiv",
    "abstract": "Classical and quantum physics represent two distinct theories; however, quantum physics is regarded as the more fundamental of the two. It is posited that classical mechanics should arise from quantum mechanics under certain limiting conditions. Nevertheless, this remains a challenging objective. In this work, we explore the potential for unifying the dynamics of classical and quantum physics. This discussion does not suggest that classical behavior emerges from quantum mechanics; rather, it demonstrates the exact equivalence between the dynamics of quantum observables and their classical counterparts. It is shown that the Heisenberg equations of motion can be cast in a form that is identical to Newton's equations of motion, with $\\hbar$ being absent from the formulation. This implies that both quantum and classical dynamics are governed by the same equations, with the Heisenberg operators substituting the classical observables."
  },
  {
    "date": "2026-01-15",
    "title": "On 3-Connected Planar Graphs with Unique Orientable Circuit Double Covers",
    "authors": "Meike Weiß, Reymond Akpanya, Alice C. Niemeyer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10171v1",
    "source": "arXiv",
    "abstract": "A circuit double cover of a bridgeless graph is a collection of even subgraphs such that every edge is contained in exactly two subgraphs of the given collection. Such a circuit double cover describes an embedding of the corresponding graph onto a surface. In this paper, we investigate the well-known Orientable Strong Embedding Conjecture. This conjecture proposes that every bridgeless graph has a circuit double cover describing an embedding on an orientable surface. In a recent paper, we have proved that a 3-connected cubic planar graph G has exactly one orientable circuit double cover if and only if G is the dual graph of an Apollonian network. In this paper, we extend this result by demonstrating that this characterisation applies to any 3-connected planar graph, regardless of whether it is cubic."
  },
  {
    "date": "2026-01-15",
    "title": "DecisionLLM: Large Language Models for Long Sequence Decision Exploration",
    "authors": "Xiaowei Lv, Zhilin Zhang, Yijun Li, Yusen Huo, Siyuan Ju, Xuyan Li, Chunxiang Hong, Tianyu Wang, Yongcai Wang, Peng Sun, Chuan Yu, Jian Xu, Bo Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10148v1",
    "source": "arXiv",
    "abstract": "Long-sequence decision-making, which is usually addressed through reinforcement learning (RL), is a critical component for optimizing strategic operations in dynamic environments, such as real-time bidding in computational advertising. The Decision Transformer (DT) introduced a powerful paradigm by framing RL as an autoregressive sequence modeling problem. Concurrently, Large Language Models (LLMs) have demonstrated remarkable success in complex reasoning and planning tasks. This inspires us whether LLMs, which share the same Transformer foundation, but operate at a much larger scale, can unlock new levels of performance in long-horizon sequential decision-making problem. This work investigates the application of LLMs to offline decision making tasks. A fundamental challenge in this domain is the LLMs' inherent inability to interpret continuous values, as they lack a native understanding of numerical magnitude and order when values are represented as text strings. To address this, we propose treating trajectories as a distinct modality. By learning to align trajectory data with natural language task descriptions, our model can autoregressively predict future decisions within a cohesive framework we term DecisionLLM. We establish a set of scaling laws governing this paradigm, demonstrating that performance hinges on three factors: model scale, data volume, and data quality. In offline experimental benchmarks and bidding scenarios, DecisionLLM achieves strong performance. Specifically, DecisionLLM-3B outperforms the traditional Decision Transformer (DT) by 69.4 on Maze2D umaze-v1 and by 0.085 on AuctionNet. It extends the AIGB paradigm and points to promising directions for future exploration in online bidding."
  },
  {
    "date": "2026-01-15",
    "title": "Actors, Frames and Arguments: A Multi-Decade Computational Analysis of Climate Discourse in Financial News using Large Language Models",
    "authors": "Ruiran Su, Janet B. Pierrehumbert, Markus Leippold",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10142v1",
    "source": "arXiv",
    "abstract": "Financial news media shapes trillion-dollar climate investment decisions, yet discourse in this elite domain remains underexplored. We analyze two decades of climate-related articles (2000-2023) from Dow Jones Newswire using an Actor-Frame-Argument (AFA) pipeline that extracts who speaks, how issues are framed, and which arguments are deployed. We validate extractions against 2,000 human-annotated articles using a Decompositional Verification Framework that evaluates completeness, faithfulness, coherence, and relevance. Our longitudinal analysis uncovers a structural transformation: pre-2015 coverage emphasized risk and regulatory burden; post-Paris Agreement, discourse shifted toward economic opportunity and innovation, with financial institutions becoming dominant voices. Methodologically, we provide a replicable paradigm for longitudinal media analysis with LLMs; substantively, we reveal how financial elites have internalized and reframed the climate crisis across two decades."
  },
  {
    "date": "2026-01-15",
    "title": "M^4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints",
    "authors": "Yizhan Li, Florence Cloutier, Sifan Wu, Ali Parviz, Boris Knyazev, Yan Zhang, Glen Berseth, Bang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10131v1",
    "source": "arXiv",
    "abstract": "Generating molecules that satisfy precise numeric constraints over multiple physicochemical properties is critical and challenging. Although large language models (LLMs) are expressive, they struggle with precise multi-objective control and numeric reasoning without external structure and feedback. We introduce \\textbf{M olGen}, a fragment-level, retrieval-augmented, two-stage framework for molecule generation under multi-property constraints. Stage I : Prototype generation: a multi-agent reasoner performs retrieval-anchored, fragment-level edits to produce a candidate near the feasible region. Stage II : RL-based fine-grained optimization: a fragment-level optimizer trained with Group Relative Policy Optimization (GRPO) applies one- or multi-hop refinements to explicitly minimize the property errors toward our target while regulating edit complexity and deviation from the prototype. A large, automatically curated dataset with reasoning chains of fragment edits and measured property deltas underpins both stages, enabling deterministic, reproducible supervision and controllable multi-hop reasoning. Unlike prior work, our framework better reasons about molecules by leveraging fragments and supports controllable refinement toward numeric targets. Experiments on generation under two sets of property constraints (QED, LogP, Molecular Weight and HOMO, LUMO) show consistent gains in validity and precise satisfaction of multi-property targets, outperforming strong LLMs and graph-based algorithms."
  },
  {
    "date": "2026-01-15",
    "title": "Fairness Driven Multi-Agent Path Finding Problem",
    "authors": "Aditi Anand, Dildar Ali, Suman Banerjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10123v1",
    "source": "arXiv",
    "abstract": "The Multi-Agent Path Finding (MAPF) problem aims at finding non-conflicting paths for multiple agents from their respective sources to destinations. This problem arises in multiple real-life situations, including robot motion planning and airspace assignment for unmanned aerial vehicle movement. The problem is computationally expensive, and adding to it, the agents are rational and can misreport their private information. In this paper, we study both variants of the problem under the realm of fairness. For the non-rational agents, we propose a heuristic solution for this problem. Considering the agents are rational, we develop a mechanism and demonstrate that it is a dominant strategy, incentive compatible, and individually rational. We employ various solution methodologies to highlight the effectiveness and efficiency of the proposed solution approaches."
  },
  {
    "date": "2026-01-15",
    "title": "Beyond Single Prompts: Synergistic Fusion and Arrangement for VICL",
    "authors": "Wenwen Liao, Jianbo Yu, Yuansong Wang, Shifu Yan, Xiaofeng Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10117v1",
    "source": "arXiv",
    "abstract": "Vision In-Context Learning (VICL) enables inpainting models to quickly adapt to new visual tasks from only a few prompts. However, existing methods suffer from two key issues: (1) selecting only the most similar prompt discards complementary cues from other high-quality prompts; and (2) failing to exploit the structured information implied by different prompt arrangements. We propose an end-to-end VICL framework to overcome these limitations. Firstly, an adaptive Fusion Module aggregates critical patterns and annotations from multiple prompts to form more precise contextual prompts. Secondly, we introduce arrangement-specific lightweight MLPs to decouple layout priors from the core model, while minimally affecting the overall model. In addition, an bidirectional fine-tuning mechanism swaps the roles of query and prompt, encouraging the model to reconstruct the original prompt from fused context and thus enhancing collaboration between the fusion module and the inpainting model. Experiments on foreground segmentation, single-object detection, and image colorization demonstrate superior results and strong cross-task generalization of our method."
  },
  {
    "date": "2026-01-15",
    "title": "Repository Intelligence Graph: Deterministic Architectural Map for LLM Code Assistants",
    "authors": "Tsvi Cherny-Shahar, Amiram Yehudai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10112v1",
    "source": "arXiv",
    "abstract": "Repository aware coding agents often struggle to recover build and test structure, especially in multilingual projects where cross language dependencies are encoded across heterogeneous build systems and tooling. We introduce the Repository Intelligence Graph (RIG), a deterministic, evidence backed architectural map that represents buildable components, aggregators, runners, tests, external packages, and package managers, connected by explicit dependency and coverage edges that trace back to concrete build and test definitions. We also present SPADE, a deterministic extractor that constructs RIG from build and test artifacts (currently with an automatic CMake plugin based on the CMake File API and CTest metadata), and exposes RIG as an LLM friendly JSON view that agents can treat as the authoritative description of repository structure. We evaluate three commercial agents (Claude Code, Cursor, Codex) on eight repositories spanning low to high build oriented complexity, including the real world MetaFFI project. Each agent answers thirty structured questions per repository with and without RIG in context, and we measure accuracy, wall clock completion time, and efficiency (seconds per correct answer). Across repositories and agents, providing RIG improves mean accuracy by 12.2\\% and reduces completion time by 53.9\\%, yielding a mean 57.8\\% reduction in seconds per correct answer. Gains are larger in multilingual repositories, which improve by 17.7\\% in accuracy and 69.5\\% in efficiency on average, compared to 6.6\\% and 46.1\\% in single language repositories. Qualitative analysis suggests that RIG shifts failures from structural misunderstandings toward reasoning mistakes over a correct structure, while rare regressions highlight that graph based reasoning quality remains a key factor."
  },
  {
    "date": "2026-01-15",
    "title": "MathDoc: Benchmarking Structured Extraction and Active Refusal on Noisy Mathematics Exam Papers",
    "authors": "Chenyue Zhou, Jiayi Tuo, Shitong Qin, Wei Dai, Mingxuan Wang, Ziwei Zhao, Duoyang Li, Shiyang Su, Yanxi Lu, Yanbiao Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10104v1",
    "source": "arXiv",
    "abstract": "The automated extraction of structured questions from paper-based mathematics exams is fundamental to intelligent education, yet remains challenging in real-world settings due to severe visual noise. Existing benchmarks mainly focus on clean documents or generic layout analysis, overlooking both the structural integrity of mathematical problems and the ability of models to actively reject incomplete inputs. We introduce MathDoc, the first benchmark for document-level information extraction from authentic high school mathematics exam papers. MathDoc contains \\textbf{3,609} carefully curated questions with real-world artifacts and explicitly includes unrecognizable samples to evaluate active refusal behavior. We propose a multi-dimensional evaluation framework covering stem accuracy, visual similarity, and refusal capability. Experiments on SOTA MLLMs, including Qwen3-VL and Gemini-2.5-Pro, show that although end-to-end models achieve strong extraction performance, they consistently fail to refuse illegible inputs, instead producing confident but invalid outputs. These results highlight a critical gap in current MLLMs and establish MathDoc as a benchmark for assessing model reliability under degraded document conditions. Our project repository is available at \\href{https://github.com/winnk123/papers/tree/master}{GitHub repository}"
  },
  {
    "date": "2026-01-15",
    "title": "FlowAct-R1: Towards Interactive Humanoid Video Generation",
    "authors": "Lizhen Wang, Yongming Zhu, Zhipeng Ge, Youwei Zheng, Longhao Zhang, Tianshu Hu, Shiyang Qin, Mingshuang Luo, Jiaxu Zhang, Xin Chen, Yulong Wang, Zerong Zheng, Jianwen Jiang, Chao Liang, Weifeng Chen, Xing Wang, Yuan Zhang, Mingyuan Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10103v1",
    "source": "arXiv",
    "abstract": "Interactive humanoid video generation aims to synthesize lifelike visual agents that can engage with humans through continuous and responsive video. Despite recent advances in video synthesis, existing methods often grapple with the trade-off between high-fidelity synthesis and real-time interaction requirements. In this paper, we propose FlowAct-R1, a framework specifically designed for real-time interactive humanoid video generation. Built upon a MMDiT architecture, FlowAct-R1 enables the streaming synthesis of video with arbitrary durations while maintaining low-latency responsiveness. We introduce a chunkwise diffusion forcing strategy, complemented by a novel self-forcing variant, to alleviate error accumulation and ensure long-term temporal consistency during continuous interaction. By leveraging efficient distillation and system-level optimizations, our framework achieves a stable 25fps at 480p resolution with a time-to-first-frame (TTFF) of only around 1.5 seconds. The proposed method provides holistic and fine-grained full-body control, enabling the agent to transition naturally between diverse behavioral states in interactive scenarios. Experimental results demonstrate that FlowAct-R1 achieves exceptional behavioral vividness and perceptual realism, while maintaining robust generalization across diverse character styles."
  },
  {
    "date": "2026-01-15",
    "title": "InfoSculpt: Sculpting the Latent Space for Generalized Category Discovery",
    "authors": "Wenwen Liao, Hang Ruan, Jianbo Yu, Yuansong Wang, Qingchao Jiang, Xiaofeng Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10098v1",
    "source": "arXiv",
    "abstract": "Generalized Category Discovery (GCD) aims to classify instances from both known and novel categories within a large-scale unlabeled dataset, a critical yet challenging task for real-world, open-world applications. However, existing methods often rely on pseudo-labeling, or two-stage clustering, which lack a principled mechanism to explicitly disentangle essential, category-defining signals from instance-specific noise. In this paper, we address this fundamental limitation by re-framing GCD from an information-theoretic perspective, grounded in the Information Bottleneck (IB) principle. We introduce InfoSculpt, a novel framework that systematically sculpts the representation space by minimizing a dual Conditional Mutual Information (CMI) objective. InfoSculpt uniquely combines a Category-Level CMI on labeled data to learn compact and discriminative representations for known classes, and a complementary Instance-Level CMI on all data to distill invariant features by compressing augmentation-induced noise. These two objectives work synergistically at different scales to produce a disentangled and robust latent space where categorical information is preserved while noisy, instance-specific details are discarded. Extensive experiments on 8 benchmarks demonstrate that InfoSculpt validating the effectiveness of our information-theoretic approach."
  },
  {
    "date": "2026-01-15",
    "title": "On the Computation and Approximation of Backward Reachable Sets for Max-Plus Linear Systems using Polyhedras",
    "authors": "Yuda Li, Shaoyuan Li, Xiang Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10095v1",
    "source": "arXiv",
    "abstract": "This paper investigates reachability analysis for max-plus linear systems (MPLS), an important class of dynamical systems that model synchronization and delay phenomena in timed discrete-event systems. We specifically focus on backward reachability analysis, i.e., determining the set of states that can reach a given target set within a certain number of steps. Computing backward reachable sets presents significant challenges due to the non-convexity of max-plus dynamics and the complexity of set complement operations. To address these challenges, we propose a novel approximation framework that efficiently computes backward reachable sets by exploiting the structure of tropical polyhedra. Our approach reformulates the problem as a sequence of symbolic operations and approximates non-convex target sets through closure operations on unions of tropical polyhedra. We develop a systematic algorithm that constructs both outer (M-form) and inner (V-form) representations of the resulting sets, incorporating extremal filtering to reduce computational complexity. The proposed method offers a scalable alternative to traditional DBM-based approaches, enabling reliable approximate backward reachability analysis for general target regions in MPLS."
  },
  {
    "date": "2026-01-15",
    "title": "State of AI: An Empirical 100 Trillion Token Study with OpenRouter",
    "authors": "Malika Aubakirova, Alex Atallah, Chris Clark, Justin Summerville, Anjney Midha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10088v1",
    "source": "arXiv",
    "abstract": "The past year has marked a turning point in the evolution and real-world use of large language models (LLMs). With the release of the first widely adopted reasoning model, o1, on December 5th, 2024, the field shifted from single-pass pattern generation to multi-step deliberation inference, accelerating deployment, experimentation, and new classes of applications. As this shift unfolded at a rapid pace, our empirical understanding of how these models have actually been used in practice has lagged behind. In this work, we leverage the OpenRouter platform, which is an AI inference provider across a wide variety of LLMs, to analyze over 100 trillion tokens of real-world LLM interactions across tasks, geographies, and time. In our empirical study, we observe substantial adoption of open-weight models, the outsized popularity of creative roleplay (beyond just the productivity tasks many assume dominate) and coding assistance categories, plus the rise of agentic inference. Furthermore, our retention analysis identifies foundational cohorts: early users whose engagement persists far longer than later cohorts. We term this phenomenon the Cinderella \"Glass Slipper\" effect. These findings underscore that the way developers and end-users engage with LLMs \"in the wild\" is complex and multifaceted. We discuss implications for model builders, AI developers, and infrastructure providers, and outline how a data-driven understanding of usage can inform better design and deployment of LLM systems."
  },
  {
    "date": "2026-01-15",
    "title": "Pseudomode approach to Fano effect in dissipative cavity quantum electrodynamics",
    "authors": "Kazuki Kobayashi, Tatsuro Yuge",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10087v1",
    "source": "arXiv",
    "abstract": "We study the Fano effect in dissipative cavity quantum electrodynamics, which originates from the interference between the emitter's direct radiation and that mediated by a cavity mode. Starting from a two-level system coupled to a structured reservoir, we show that a quantum master equation previously derived within the Born-Markov approximation can be rederived by introducing a single auxiliary mode via pseudomode approach. We identify the corresponding spectral function of the system--environment interaction and demonstrate that it consists of a constant and a non-Lorentzian contribution forming the Fano profile. The constant term is shown to be essential for obtaining a Lindblad master equation and is directly related to the rate associated with this Fano interference. Furthermore, by applying Fano diagonalization to a common-environment setup including an explicit cavity mode, we independently derive the same spectral function in the strongest-interference regime. Our results establish a unified framework for describing the Fano effect in single-mode cavity QED systems and clarify its non-Markovian origin encoded in the spectral function."
  },
  {
    "date": "2026-01-15",
    "title": "Line-search and Adaptive Step Sizes for Nonconvex-strongly-concave Minimax Optimization",
    "authors": "Bohao Ma, Nachuan Xiao, Junyu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10086v1",
    "source": "arXiv",
    "abstract": "In this paper, we propose a novel reformulation of the smooth nonconvex-strongly-concave (NC-SC) minimax problems that casts the problem as a joint minimization. We show that our reformulation preserves not only first-order stationarity, but also global and local optimality, second-order stationarity, and the Kurdyka-Łojasiewicz (KL) property, of the original NC-SC problem, which is substantially stronger than its nonsmooth counterpart in the literature. With these enhanced structures, we design a versatile parameter-free and nonmonotone line-search framework that does not require evaluating the inner maximization. Under mild conditions, global convergence rates can be obtained, and, with KL property, full sequence convergence with asymptotic rates is also established. In particular, we show our framework is compatible with the gradient descent-ascent (GDA) algorithm. By equipping GDA with Barzilai-Borwein (BB) step sizes and nonmonotone line-search, our method exhibits superior numerical performance against the compared benchmarks."
  },
  {
    "date": "2026-01-15",
    "title": "CALM-IT: Generating Realistic Long-Form Motivational Interviewing Dialogues with Dual-Actor Conversational Dynamics Tracking",
    "authors": "Viet Cuong Nguyen, Nhi Yen Nguyen, Kristin A. Candan, Mary Conlon, Vanessa Rumie, Kristen Risola, Srijan Kumar, Munmun De Choudhury",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10085v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly used in mental health-related settings, yet they struggle to sustain realistic, goal-directed dialogue over extended interactions. While LLMs generate fluent responses, they optimize locally for the next turn rather than maintaining a coherent model of therapeutic progress, leading to brittleness and long-horizon drift. We introduce CALM-IT, a framework for generating and evaluating long-form Motivational Interviewing (MI) dialogues that explicitly models dual-actor conversational dynamics. CALM-IT represents therapist-client interaction as a bidirectional state-space process, in which both agents continuously update inferred alignment, mental states, and short-term goals to guide strategy selection and utterance generation. Across large-scale evaluations, CALM-IT consistently outperforms strong baselines in Effectiveness and Goal Alignment and remains substantially more stable as conversation length increases. Although CALM-IT initiates fewer therapist redirections, it achieves the highest client acceptance rate (64.3%), indicating more precise and therapeutically aligned intervention timing. Overall, CALM-IT provides evidence for modeling evolving conversational state being essential for generating high-quality long-form synthetic conversations."
  },
  {
    "date": "2026-01-15",
    "title": "Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts",
    "authors": "Sijia Luo, Xiaokang Zhang, Yuxuan Hu, Bohan Zhang, Ke Wang, Jinbo Su, Mengshu Sun, Lei Liang, Jing Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10079v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning (RL) has become essential for eliciting complex reasoning capabilities in Large Language Models (LLMs). However, the substantial memory overhead of storing Key-Value (KV) caches during long-horizon rollouts acts as a critical bottleneck, often prohibiting efficient training on limited hardware. While existing KV compression techniques offer a remedy for inference, directly applying them to RL training induces a severe policy mismatch, leading to catastrophic performance collapse. To address this, we introduce Sparse-RL empowers stable RL training under sparse rollouts. We show that instability arises from a fundamental policy mismatch among the dense old policy, the sparse sampler policy, and the learner policy. To mitigate this issue, Sparse-RL incorporates Sparsity-Aware Rejection Sampling and Importance-based Reweighting to correct the off-policy bias introduced by compression-induced information loss. Experimental results show that Sparse-RL reduces rollout overhead compared to dense baselines while preserving the performance. Furthermore, Sparse-RL inherently implements sparsity-aware training, significantly enhancing model robustness during sparse inference deployment."
  },
  {
    "date": "2026-01-15",
    "title": "A $p$-adic interpolation of the Cogdell lift",
    "authors": "Francesco Maria Iudica",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10077v1",
    "source": "arXiv",
    "abstract": "In this paper we obtain several results related to the $p$-adic interpolation of the classical Cogdell lift, mapping special cycles on Picard modular surfaces to elliptic modular forms. The results have a three-fold nature: in the first part of the paper, we $p$-adically interpolate the adjoint Kudla lift, exploiting the previously constructed $Λ$-adic Kudla lift. In the second part, we construct higher weight cycles in Kuga-Sato varieties attached to Picard modular surfaces, and show modularity of the generating series of these cycles, thus obtaining a higher weight analogue of the Cogdell lift. Finally, we apply the formalism introduced by Loeffler to construct $p$-adic analytic cohomology classes of special cycles, whose generating series is proved to be a Hida family interpolating the Cogdell lifts in the weight and level variables."
  },
  {
    "date": "2026-01-15",
    "title": "Transport equation theory in the Triebel-Lizorkin spaces and its applications to the ideal fluid flows",
    "authors": "Qianyuan Zhang, Kai Yan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10071v1",
    "source": "arXiv",
    "abstract": "In this paper, we develop a general theory for the transport equation within the framework of Triebel-Lizorkin spaces. We first derive commutator estimates in these spaces, dispensing with the conventional divergence-free condition, via the Bony paraproduct decomposition and vector-valued maximal function inequalities. Building on these estimates and combining the method of characteristics with a compactness argument, we then obtain the new a priori estimates and prove local well-posedness for the transport equation in Triebel-Lizorkin spaces. The resulting theory is applicable to a wide range of evolution equations, including models for incompressible and compressible ideal fluid flows, shallow water waves, among others. As an illustration, we consider the incompressible ideal magnetohydrodynamics (MHD) system. Employing the general transport theory developed here yields a complete local well-posedness result in the sense of Hadamard, covering both sub-critical and critical regularity regimes, and provides corresponding blow-up criteria for the ideal MHD equations in Triebel-Lizorkin spaces. Our results refine and substantially extend earlier work in this direction."
  },
  {
    "date": "2026-01-15",
    "title": "Comparative Evaluation of Deep Learning-Based and WHO-Informed Approaches for Sperm Morphology Assessment",
    "authors": "Mohammad Abbadi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10070v1",
    "source": "arXiv",
    "abstract": "Assessment of sperm morphological quality remains a critical yet subjective component of male fertility evaluation, often limited by inter-observer variability and resource constraints. This study presents a comparative biomedical artificial intelligence framework evaluating an image-based deep learning model (HuSHeM) alongside a clinically grounded baseline derived from World Health Organization criteria augmented with the Systemic Inflammation Response Index (WHO(+SIRI)). The HuSHeM model was trained on high-resolution sperm morphology images and evaluated using an independent clinical cohort. Model performance was assessed using discrimination, calibration, and clinical utility analyses. The HuSHeM model demonstrated higher discriminative performance, as reflected by an increased area under the receiver operating characteristic curve with relatively narrow confidence intervals compared to WHO(+SIRI). Precision-recall analysis further indicated improved performance under class imbalance, with higher precision-recall area values across evaluated thresholds. Calibration analysis indicated closer agreement between predicted probabilities and observed outcomes for HuSHeM, while decision curve analysis suggested greater net clinical benefit across clinically relevant threshold probabilities. These findings suggest that image-based deep learning may offer improved predictive reliability and clinical utility compared with traditional rule-based and inflammation-augmented criteria. The proposed framework supports objective and reproducible assessment of sperm morphology and may serve as a decision-support tool within fertility screening and referral workflows. The proposed models are intended as decision-support or referral tools and are not designed to replace clinical judgment or laboratory assessment."
  },
  {
    "date": "2026-01-15",
    "title": "Interference-governed electromagnetic-thermal coupling and heat transport in pulse EUV-irradiated multilayer nanofilms",
    "authors": "Hongyu He, Li Ma, Zhiyi Xie, Yufan Liu, Chao Wu, Qiye Zheng, Yi Tao, Yunfei Chen, Chenhan Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10069v1",
    "source": "arXiv",
    "abstract": "Mo-Si multilayer mirrors are central to extreme ultraviolet lithography, where nanoscale optical interference and heat accumulation together constrain reflectivity and operational stability. Here we develop an analytical electromagnetic-thermal coupling model that directly links transfer-matrix-based interference-controlled energy deposition with transient heat conduction in EUV-irradiated multilayers. The model reveals a fundamental trade-off whereby increasing the multilayer period number enhances reflectivity but simultaneously elevates temperature by impeding heat dissipation. Interference-driven volumetric absorption further gives rise to pronounced axial temperature gradients and a post-pulse downward migration of the heat-flux maximum, a delayed-heating effect inaccessible to conventional surface-flux-based models. Systematic analysis establishes scaling laws connecting interfacial thermal resistance, beam size, and incident energy density to thermal confinement and temperature rise. By incorporating interfacial compaction kinetics, the model enables a quantitative assessment of mirror lifetime. This work offers a theoretical tool for thermal-optical co-design of multilayer nanostructures including EUV mirrors under pulsed irradiation across a wide spectral range."
  },
  {
    "date": "2026-01-15",
    "title": "Dirac mass matrix textures and the lightest right-handed neutrino mass scale in Type I seesaw leptogenesis",
    "authors": "Shuta Kosuge, Teruyuki Kitabayashi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10063v1",
    "source": "arXiv",
    "abstract": "The type I seesaw mechanism is one of the leading proposed explanations for how neutrinos acquire their tiny masses. However, the mass scale of the undiscovered right-handed neutrinos required by this mechanism remains undetermined. Assuming vanilla leptogenesis in the two-flavor regime, we work backwards to find the required general textures of the Dirac mass matrix from which we determine the mass of the lightest right-handed neutrino to be around $10^9 {\\rm GeV}$ to $10^{12} {\\rm GeV}$."
  },
  {
    "date": "2026-01-15",
    "title": "Microwave Linear Analog Computer (MiLAC)-aided Multiuser MISO: Fundamental Limits and Beamforming Design",
    "authors": "Zheyu Wu, Matteo Nerini, Bruno Clerckx",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10060v1",
    "source": "arXiv",
    "abstract": "As wireless communication systems evolve toward the 6G era, ultra-massive/gigantic MIMO is envisioned as a key enabling technology. Recently, microwave linear analog computer (MiLAC) has emerged as a promising approach to realize beamforming entirely in the analog domain, thereby alleviating the scalability challenges associated with gigantic MIMO. In this paper, we investigate the fundamental beamforming flexibility and design of lossless and reciprocal MiLAC-aided beamforming for MU-MISO systems. We first provide a rigorous characterization of the set of beamforming matrices achievable by MiLAC. Based on this characterization, we prove that MiLAC-aided beamforming does not generally achieve the full flexibility of digital beamforming, while offering greater flexibility than conventional phase-shifter-based analog beamforming. Furthermore, we propose a hybrid digital-MiLAC architecture and show that it achieves digital beamforming flexibility when the number of radio frequency (RF) chains equals the number of data streams, halving that required by conventional hybrid beamforming. We then formulate the MiLAC-aided sum-rate maximization problem for MU-MISO systems. To solve the problem efficiently, we reformulate the MiLAC-related constraints as a convex linear matrix inequality and establish a low-dimensional subspace property that significantly reduces the problem dimension. Leveraging these results, we propose WMMSE-based algorithms for solving the resulting problem. Simulation results demonstrate that MiLAC-aided beamforming achieves performance close to that of digital beamforming in gigantic MIMO systems. Compared with hybrid beamforming, it achieves comparable or superior performance with lower hardware and computational complexity by avoiding symbol-level digital processing and enabling low-resolution digital-to-analog converters (DACs)."
  },
  {
    "date": "2026-01-15",
    "title": "Comparative study of equilibrium and non-equilibrium predictions by different models for a hypersonic cone at high-altitude",
    "authors": "Mengyu Wang, Pan Yan, Qin Li, Zhenfeng Wang, Xiaoming Guo, Yuanchun Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10050v1",
    "source": "arXiv",
    "abstract": "Targeting a cone with the half-angle as 10-deg at M = 27 and H = 72 km, simulations were conducted comparatively to analyze the predictions by different equilibrium and non-equilibrium gas models. Following validation and grid studies, systematic comparisons on aerodynamic performance, flow structures, and characteristic distributions were performed. The key findings are: (1) While the overall flow structures are broadly similar, discrepancies exist in the features at the base locations, e.g., the diverse high-temperature distributions. Notably, the vibrational temperatures distribute differently under slip and non-slip boundary conditions near the wall; (2) The equilibrium gas model predicts higher drag coefficient, wall heat flux, and skin friction than those of non-equilibrium models. Predictions also vary among the non-equilibrium models themselves. Specifically, compared to the three-temperature model, the one- and two-temperature models predict larger drag coefficients with the relative difference exceeding 5%. Nevertheless, the results from the three-temperature model with and without slip conditions are largely consistent; (3) The disparities between equilibrium and non-equilibrium characteristics are primarily manifested in the shock layer and wake regions. Within these regions, the overall temperature for the equilibrium gas is lower than that for the non-equilibrium cases, while in the latter specific non-equilibrium features are distinctly exhibited, e.g., the translational-rotational temperature is generally higher than that from the one-temperature model, and the vibrational-electronic temperature shows the opposite trend. Notably, in the slip flow within the three-temperature model, the translational-rotational temperature is higher and, particularly, the vibrational temperature is even larger than counterparts of the non-slip flows near the wall and base center line."
  },
  {
    "date": "2026-01-15",
    "title": "Multi-Sender Disclosure with Costs",
    "authors": "Navin Kartik, Frances Xu Lee, Wing Suen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10048v1",
    "source": "arXiv",
    "abstract": "We study voluntary disclosure with multiple biased senders who may bear costs for disclosing or concealing their private information. Under relevant assumptions, disclosures are strategic substitutes under a disclosure cost but complements under a concealment cost. Additional senders thus impede any sender's disclosure under a disclosure cost but promote it under a concealment cost. In the former case, a decision maker can be harmed by additional senders, even when senders have opposing interests. The effects under both kinds of message costs turn on how a sender, when concealing his information, expects others' messages to systematically sway the decision maker's belief."
  },
  {
    "date": "2026-01-15",
    "title": "Privacy Enhanced PEFT: Tensor Train Decomposition Improves Privacy Utility Tradeoffs under DP-SGD",
    "authors": "Pradip Kunwar, Minh Vu, Maanak Gupta, Manish Bhattarai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10045v1",
    "source": "arXiv",
    "abstract": "Fine-tuning large language models on sensitive data poses significant privacy risks, as membership inference attacks can reveal whether individual records were used during training. While Differential Privacy (DP) provides formal protection, applying DP to conventional Parameter-Efficient Fine-Tuning (PEFT) methods such as Low-Rank Adaptation (LoRA) often incurs substantial utility loss. In this work, we show that a more structurally constrained PEFT architecture, Tensor Train Low-Rank Adaptation (TTLoRA), can improve the privacy-utility tradeoff by shrinking the effective parameter space while preserving expressivity. To this end, we develop TTLoRA-DP, a differentially private training framework for TTLoRA. Specifically, we extend the ghost clipping algorithm to Tensor Train cores via cached contraction states, enabling efficient Differentially Private Stochastic Gradient Descent (DP-SGD) with exact per-example gradient norm computation without materializing full per-example gradients. Experiments on GPT-2 fine-tuning over the Enron and Penn Treebank datasets show that TTLoRA-DP consistently strengthens privacy protection relative to LoRA-DP while maintaining comparable or better downstream utility. Moreover, TTLoRA exhibits lower membership leakage even without DP training, using substantially smaller adapters and requiring on average 7.6X fewer parameters than LoRA. Overall, our results demonstrate that TTLoRA offers a practical path to improving the privacy-utility tradeoff in parameter-efficient language model adaptation."
  },
  {
    "date": "2026-01-15",
    "title": "Event-Driven Deep RL Dispatcher for Post-Storm Distribution System Restoration",
    "authors": "Farshad Amani, Faezeh Ardali, Amin Kargarian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10044v1",
    "source": "arXiv",
    "abstract": "Natural hazards such as hurricanes and floods damage power grid equipment, forcing operators to replan restoration repeatedly as new information becomes available. This paper develops a deep reinforcement learning (DRL) dispatcher that serves as a real-time decision engine for crew-to-repair assignments. We model restoration as a sequential, information-revealing process and learn an actor-critic policy over compact features such as component status, travel/repair times, crew availability, and marginal restoration value. A feasibility mask blocks unsafe or inoperable actions, such as power flow limits, switching rules, and crew-time constraints, before they are applied. To provide realistic runtime inputs without relying on heavy solvers, we use lightweight surrogates for wind and flood intensities, fragility-based failure, spatial clustering of damage, access impairments, and progressive ticket arrivals. In simulated hurricane and flood events, the learned policy updates crew decisions in real time as new field reports arrive. Because the runtime logic is lightweight, it improves online performance (energy-not-supplied, critical-load restoration time, and travel distance) compared with mixed-integer programs and standard heuristics. The proposed approach is tested on the IEEE 13- and 123-bus feeders with mixed hurricane/flood scenarios."
  },
  {
    "date": "2026-01-15",
    "title": "Towards Minimal Fault-tolerant Error-Correction Sequence with Quantum Hamming Codes",
    "authors": "Sha Shi, Xiao-Yang Xu, Min-Quan Cheng, Dong-Sheng Wang, Yun-Jiang Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10042v1",
    "source": "arXiv",
    "abstract": "The high overhead of fault-tolerant measurement sequences (FTMSs) poses a major challenge for implementing quantum stabilizer codes. Here, we address this problem by constructing efficient FTMSs for the class of quantum Hamming codes $[\\![2^r-1, 2^r-1-2r, 3]\\!]$ with $r=3k+1$ ($k \\in \\mathbb{Z}^+$). Our key result demonstrates that the sequence length can be reduced to exactly $2r+1$-only one additional measurement beyond the original non-fault-tolerant sequence, establishing a tight lower bound. The proposed method leverages cyclic matrix transformations to systematically combine rows of the initial stabilizer matrix and preserving a self-dual CSS-like symmetry analogous to that of the original quantum Hamming codes. This induced symmetry enables hardware-efficient circuit reuse: the measurement circuits for the first $r$ stabilizers are transformed into circuits for the remaining $r$ stabilizers simply by toggling boundary Hadamard gates, eliminating redundant hardware. For distance-3 fault-tolerant error correction, our approach simultaneously reduces the time overhead via shorting the FTMS length and the hardware overhead through symmetry-enabled circuit multiplexing. These results provide an important advance towards the important open problem regarding the design of minimal FTMSs for quantum Hamming codes and may shed light on similar challenges in other quantum stabilizer codes."
  },
  {
    "date": "2026-01-15",
    "title": "Effects of parallel magnetic fields on sheaths near biased electrodes in a highly collisional Z-pinch plasma",
    "authors": "C. R. Skolar, B. Srinivasan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10039v1",
    "source": "arXiv",
    "abstract": "Sheath formation near biased electrodes in magnetic fields parallel to the wall is an understudied topic, especially within the context of Z-pinch fusion experiments. We perform 1X-2V Boltzmann-Poisson simulations of an axial cut at the pinch radius of a Z-pinch plasma between two biased electrodes with a magnetic field parallel to the wall. The collision frequencies are artificially increased to enhance thermalization of the plasma in the smaller simulation domain versus the actual experiment size; this increases the perpendicular mobility and partially de-magnetizes the ions resulting in non-monotonic sheath profiles with the potential increasing away from the wall to a peak before decaying. A classical sheath forms within an electron gyroradius from the wall not due to the natural thermal motion of the electrons, but due to the magnetized electrons gyrating into the wall; therefore, the sheath structure does not significantly change with bias potential or between electrodes. With increasing bias potential, a current is induced perpendicular to the wall due to changes in ion flow, differing from unmagnetized cases where current is induced by changes in electron flow. The magnetic field acts as a high resistivity with the perpendicular current density being three orders of magnitude lower than unmagnetized theoretical predictions. There is, however, significant flow parallel to the wall from the force balance between the pressure tensor and Lorentz force. These parallel flows induce a parallel current density three orders of magnitude larger than the perpendicular current density."
  },
  {
    "date": "2026-01-15",
    "title": "FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data",
    "authors": "Jianheng Tang, Shilong Tao, Zhe Feng, Haonan Sun, Menglu Wang, Zhanxing Zhu, Yunhuai Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10031v1",
    "source": "arXiv",
    "abstract": "The scientific computation of large deformations in elastic-plastic solids is crucial in various manufacturing applications. Traditional numerical methods exhibit several inherent limitations, prompting Deep Learning (DL) as a promising alternative. The effectiveness of current DL techniques typically depends on the availability of high-quantity and high-accuracy datasets, which are yet difficult to obtain in large deformation problems. During the dataset construction process, a dilemma stands between data quantity and data accuracy, leading to suboptimal performance in the DL models. To address this challenge, we focus on a representative application of large deformations, the stretch bending problem, and propose FilDeep, a Fidelity-based Deep Learning framework for large Deformation of elastic-plastic solids. Our FilDeep aims to resolve the quantity-accuracy dilemma by simultaneously training with both low-fidelity and high-fidelity data, where the former provides greater quantity but lower accuracy, while the latter offers higher accuracy but in less quantity. In FilDeep, we provide meticulous designs for the practical large deformation problem. Particularly, we propose attention-enabled cross-fidelity modules to effectively capture long-range physical interactions across MF data. To the best of our knowledge, our FilDeep presents the first DL framework for large deformation problems using MF data. Extensive experiments demonstrate that our FilDeep consistently achieves state-of-the-art performance and can be efficiently deployed in manufacturing."
  },
  {
    "date": "2026-01-15",
    "title": "BPE: Behavioral Profiling Ensemble",
    "authors": "Yanxin Liu, Yunqi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10024v1",
    "source": "arXiv",
    "abstract": "Ensemble learning is widely recognized as a pivotal strategy for pushing the boundaries of predictive performance. Traditional static ensemble methods, such as Stacking, typically assign weights by treating each base learner as a holistic entity, thereby overlooking the fact that individual models exhibit varying degrees of competence across different regions of the instance space. To address this limitation, Dynamic Ensemble Selection (DES) was introduced. However, both static and dynamic approaches predominantly rely on the divergence among different models as the basis for integration. This inter-model perspective neglects the intrinsic characteristics of the models themselves and necessitates a heavy reliance on validation sets for competence estimation. In this paper, we propose the Behavioral Profiling Ensemble (BPE) framework, which introduces a novel paradigm shift. Unlike traditional methods, BPE constructs a ``behavioral profile'' intrinsic to each model and derives integration weights based on the deviation between the model's response to a specific test instance and its established behavioral profile. Extensive experiments on both synthetic and real-world datasets demonstrate that the algorithm derived from the BPE framework achieves significant improvements over state-of-the-art ensemble baselines. These gains are evident not only in predictive accuracy but also in computational efficiency and storage resource utilization across various scenarios."
  },
  {
    "date": "2026-01-15",
    "title": "Hybrid superinductance with Al/InAs",
    "authors": "Junseok Oh, Ido Levy, Tyler Cowan, Jacob Issokson, Archana Kamal, Javad Shabani, Andrew P. Higginbotham",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10023v1",
    "source": "arXiv",
    "abstract": "We report microwave spectroscopy of Josephson junctions chains made from an epitaxial Al/InAs heterostructure. The chains exhibit superinductance, with characteristic wave impedance exceeding $R_{Q} = \\hbar/(2e)^{2}$. The planar nature of the junctions results in a large plasma frequency, with no measurable deviations from ideal dispersion up to $12~\\mathrm{GHz}$. Internal quality factors decrease sharply with frequency, which we describe with a simple loss model. The possibility of a loss mechanism intrinsic to the superconductor-semiconductor junction is considered."
  },
  {
    "date": "2026-01-15",
    "title": "Rotational Memory Function of SPC/E water",
    "authors": "Dilipkumar N. Asthagiri, Dmitry V. Matyushov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10022v1",
    "source": "arXiv",
    "abstract": "Memory effects are essential for dynamics of condensed materials and are responsible for non-exponential relaxation of correlation functions of dynamic variables through the memory function. Memory functions of dipole rotations for polar liquids have never been calculated. We present here calculations of memory functions for single-dipole rotations and for the overall dipole moment of the sample for SPC/E water. The memory functions for single-particle and collective dipole dynamics turn out to be nearly identical. This result validates theories of dielectric spectroscopy in terms of single-particle time correlation functions and the connection between the collective and single-particle relaxation times through the Kirkwood factor. The dielectric function in this formalism contains no new dynamic information that does not exist in the single-dipole correlation function. A short memory time, $\\lesssim 1$ fs, justifies the use of rotational diffusion model to describe dynamics of a single molecular dipole moment in bulk water."
  },
  {
    "date": "2026-01-15",
    "title": "CAFEDistill: Learning Personalized and Dynamic Models through Federated Early-Exit Network Distillation",
    "authors": "Boyi Liu, Zimu Zhou, Yongxin Tong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10015v1",
    "source": "arXiv",
    "abstract": "Personalized Federated Learning (PFL) enables collaboratively model training on decentralized, heterogeneous data while tailoring them to each client's unique distribution. However, existing PFL methods produce static models with a fixed tradeoff between accuracy and efficiency, limiting their applicability in environments where inference requirements vary with contexts and resource availability. Early-exit networks (EENs) offer adaptive inference by attaching intermediate classifiers. Yet integrating them into PFL is challenging due to client-wise heterogeneity and depth-wise interference arising from conflicting exit objectives. Prior studies fail to resolve both conflicts simultaneously, leading to suboptimal performance. In this paper, we propose CAFEDistill, a Conflict-Aware Federated Exit Distillation framework that jointly addresses these conflicts and extends PFL to early-exit networks. Through a progressive, depth-prioritized student coordination mechanism, CAFEDistill mitigates interference among shallow and deep exits while allowing effective personalized knowledge transfer across clients. Furthermore, it reduces communication overhead via a client-decoupled formulation. Extensive evaluations show that CAFEDistill outperforms the state-of-the-arts, achieving higher accuracy and reducing inference costs by 30.79%-46.86%."
  },
  {
    "date": "2026-01-15",
    "title": "Möbius-Type Structures in Non-Orientable Singular Semi-Riemannian Manifolds",
    "authors": "Nathalie E. Rieger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10009v1",
    "source": "arXiv",
    "abstract": "Our objective is to illuminate the global structure of non-orientable manifolds with signature-changing metrics. Using explicit constructions based on the topology of the Möbius strip, we produce examples of crosscap manifolds where the gluing junction serves as the locus of signature change. In another set of examples, we convert the Möbius strip into a singular signature-type changing manifold. For these resulting manifolds, we test whether the metric can be expressed as $\\tilde{g}=g+fV^{\\flat}\\otimes V^{\\flat}$, with $g$ a Lorentzian metric and $f$ a smooth interpolation function between the Lorentzian and Riemannian regions, separated by the signature change hypersurface $\\mathcal{H}$. Our analysis reveals that the radical of the metric can transition from transverse to tangent at $\\mathcal{H}$, pseudo-space orientability is obstructed by the Euler characteristic, and pseudo-time orientability may still hold. These examples illustrate subtle obstructions to applying standard transformation prescriptions for signature change and highlight novel phenomena in compact, non-orientable semi-Riemannian manifolds."
  },
  {
    "date": "2026-01-15",
    "title": "The Knowable Future: Mapping the Decay of Past-Future Mutual Information Across Forecast Horizons",
    "authors": "Peter Maurice Catt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10006v1",
    "source": "arXiv",
    "abstract": "The ability to assess ex-ante whether a time series is likely to be accurately forecast is important for forecasting practice because it informs the degree of modelling effort warranted. We define forecastability as a property of a time series (given a declared information set), and measure horizon-specific forecastability as the reduction in uncertainty provided by the past, using auto-mutual information (AMI) at lag h. AMI is estimated from training data using a k-nearest-neighbour estimator and evaluated against out-of-sample forecast error (sMAPE) on a filtered, balanced sample of 1,350 M4 series across six sampling frequencies. Seasonal Naive, ETS, and N-BEATS are used as probes of out-of-sample forecast performance. Training-only AMI provides a frequency-conditional diagnostic for forecast difficulty: for Hourly, Weekly, Quarterly, and Yearly series, AMI exhibits consistently negative rank correlation with sMAPE across probes. Under N-BEATS, the correlation is strongest for Hourly (p= -0.52) and Weekly (p= -0.51), with Quarterly (p= -0.42) and Yearly (p = -0.36) also substantial. Monthly is probe-dependent (Seasonal Naive p= -0.12; ETS p = -0.26; N-BEATS p = -0.24). Daily shows notably weaker AMI-sMAPE correlation under this protocol, suggesting limited ability to discriminate between series despite the presence of temporal dependence. The findings support within-frequency triage and effort allocation based on measurable signal content prior to forecasting, rather than between-frequency comparisons of difficulty."
  },
  {
    "date": "2026-01-15",
    "title": "Average pairing correlation properties and effective pairing residual interactions",
    "authors": "Meng-Hock Koh, P. Quentin, L. Bonneau",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09993v1",
    "source": "arXiv",
    "abstract": "This paper describes a method to determine the intensities of effective pairing residual interactions, extending what has been done for the seniority force model [Phys. Rev. C 110, 024311 (2024)]. It has been tested in Hartree-Fock plus BCS calculations using residual pairing zero-range interactions. The average pair condensation energy is the key quantity connecting the determination of constant pairing matrix elements to the estimation of delta interaction intensities. From individually fitted delta pairing strengths of $28$ well and rigidly deformed nuclei whose proton number $Z$ ranges from $50$ to $82$ evaluated at the ground-state, we have determined average interaction intensities. They reproduce equally well the data on MoI as what is obtained within the seniority force ansatz with a r.m.s. deviation of about $2 \\: \\hbar^2 \\mbox{MeV}^{-1}$. This approach provides a non-ambiguous way to determine reasonably well the strengths of pairing interactions at the ground-state of well deformed nuclei. It allows to perform, with some reasonable level of confidence, calculations for other nuclei in the corresponding nuclear region as well as beyond their ground states in particular to assess deformation properties as, e.g., to evaluate fission barriers or spectral properties of quasi-particle states."
  },
  {
    "date": "2026-01-15",
    "title": "Holographic entropy inequalities pass the majorization test",
    "authors": "Bartlomiej Czech, Yichen Feng, Xianlai Wu, Minjun Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09989v1",
    "source": "arXiv",
    "abstract": "Quantities computed by minimal cuts, such as entanglement entropies achievable by the Ryu-Takayanagi proposal in the AdS/CFT correspondence, are constrained by linear inequalities. We prove a previously conjectured property of all such constraints: Any $k$ systems on the \"greater-than\" side of the inequality are subsumed in some $k$ systems on its \"less-than\" side (accounting for multiplicity). This finding adds evidence that the same inequalities also constrain the entropies under time-dependent conditions because it preempts a large class of potential counterexamples. We prove several other properties of holographic entropy inequalities and comment on their relation to quantum erasure correction and the Renormalization Group."
  },
  {
    "date": "2026-01-15",
    "title": "Statistical-noise-enhanced multi-photon interference",
    "authors": "Rikizo Ikuta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09977v1",
    "source": "arXiv",
    "abstract": "Photon statistics plays a governing role in multi-photon interference. While interference visibility in the standard two-photon case, known as Hong-Ou-Mandel interference, monotonically degrades with higher intensity correlation functions, we show that this monotonicity does not hold for three-photon interference in symmetric circuits. We reveal that, in the discrete Fourier transform circuit, engineered super-Poissonian photon-number fluctuations, realized using a modulated laser, maximize the visibility, surpassing the magnitude of the single-photon signature. In addition, by tuning the symmetric circuit parameters, we demonstrate that the visibility hierarchy inverts relative to the benchmark of Poissonian statistics. This trade-off implies that quantum and classical advantages are mutually exclusive resources for interference, indicating a form of statistical complementarity."
  },
  {
    "date": "2026-01-15",
    "title": "A Control Theoretic Approach to Decentralized AI Economy Stabilization via Dynamic Buyback-and-Burn Mechanisms",
    "authors": "Zehua Cheng, Wei Dai, Zhipeng Wang, Rui Sun, Nick Wen, Jiahao Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09961v1",
    "source": "arXiv",
    "abstract": "The democratization of artificial intelligence through decentralized networks represents a paradigm shift in computational provisioning, yet the long-term viability of these ecosystems is critically endangered by the extreme volatility of their native economic layers. Current tokenomic models, which predominantly rely on static or threshold-based buyback heuristics, are ill-equipped to handle complex system dynamics and often function pro-cyclically, exacerbating instability during market downturns. To bridge this gap, we propose the Dynamic-Control Buyback Mechanism (DCBM), a formalized control-theoretic framework that utilizes a Proportional-Integral-Derivative (PID) controller with strict solvency constraints to regulate the token economy as a dynamical system. Extensive agent-based simulations utilizing Jump-Diffusion processes demonstrate that DCBM fundamentally outperforms static baselines, reducing token price volatility by approximately 66% and lowering operator churn from 19.5% to 8.1% in high-volatility regimes. These findings establish that converting tokenomics from static rules into continuous, structurally constrained control loops is a necessary condition for secure and sustainable decentralized intelligence networks."
  },
  {
    "date": "2026-01-15",
    "title": "On the Leaky Private Information Retrieval with Side Information",
    "authors": "Yingying Huangfu, Tian Bai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09960v1",
    "source": "arXiv",
    "abstract": "This paper investigates the problem of leaky-private Private Information Retrieval with Side Information (L-PIR-SI), which relaxes the requirement of perfect privacy to achieve improved communication efficiency in the presence of side information. While the capacities of PIR-SI under both $W$-privacy and $(W,S)$-privacy have been partially explored, the impact of controlled information leakage in these settings remains unaddressed. We propose a unified probabilistic framework to construct L-PIR-SI schemes where the privacy leakage is quantified by a parameter $\\varepsilon$, consistent with differential privacy standards. We characterize the achievable download costs and show that our results generalize several landmark results in the PIR literature: they recover the capacity of PIR-SI when $\\varepsilon \\to 0$, and reduce to the known bounds for leaky-PIR when side information is absent. This work provides the first look at the trade-offs between leakage, side information, and retrieval efficiency."
  },
  {
    "date": "2026-01-15",
    "title": "Planar Site Percolation, End Structure, and the Benjamini-Schramm Conjecture",
    "authors": "Zhongyang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09958v1",
    "source": "arXiv",
    "abstract": "Let $G$ be an infinite, connected, locally finite planar graph and consider i.i.d.\\ Bernoulli$(p)$ site percolation. Write $p_c^{\\mathrm{site}}(G)$ and $p_u^{\\mathrm{site}}(G)$ for the critical and uniqueness thresholds. Using a well--separated Freudenthal embedding $G\\hookrightarrow\\mathbb S^2$, we introduce a cycle--separation equivalence on ends and associated ``directional'' thresholds $p^{\\mathrm{site}}_{c,F}(G)$. When the set of end--equivalence classes is countable, we show that $p_c^{\\mathrm{site}}(G)=\\inf_F p^{\\mathrm{site}}_{c,F}(G)$ and that for every $p\\in\\bigl(\\tfrac12,\\,1-p_c^{\\mathrm{site}}(G)\\bigr)$ there are almost surely infinitely many infinite open clusters. Combined with the $0/\\infty$ theorem of Glazman--Harel--Zelesko for $p\\le \\tfrac12$, this yields non--uniqueness throughout the full coexistence interval $\\bigl(p_c^{\\mathrm{site}}(G),\\,1-p_c^{\\mathrm{site}}(G)\\bigr)$, and hence $p_u^{\\mathrm{site}}(G)\\ge 1-p_c^{\\mathrm{site}}(G)$ in this setting. This resolves the extension problem posed by Glazman--Harel--Zelesko for the upper half of the coexistence regime under a natural countability hypothesis. In contrast, for graphs with uncountably many end--equivalence classes we give criteria guaranteeing infinitely many infinite clusters above criticality, and we construct an explicit locally finite planar graph of minimum degree at least $7$ for which $p_u^{\\mathrm{site}}(G)<1-p_c^{\\mathrm{site}}(G)$. Consequently, the Benjamini--Schramm conjecture (Conjecture 7 in \\cite{bs96}) that planarity together with minimal vertex degree at least 7 forces infinitely many infinite clusters for all $p\\in(p_c,1-p_c)$ does not hold in full generality. Our proofs combine a cutset characterization of $p_c^{\\mathrm{site}}$ with a planar alternating--arm exploration organized by an end--adapted boundary decomposition."
  },
  {
    "date": "2026-01-15",
    "title": "Directed strongly regular graphs and divisible design graphs from Tatra association schemes",
    "authors": "Mikhail Muzychuk, Grigory Ryabov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09955v1",
    "source": "arXiv",
    "abstract": "In this paper, we construct directed strongly regular graphs and divisible design graphs with new parameters merging some basic relations of so-called Tatra associations schemes. We also study the above association schemes, their fusions and isomorphisms."
  },
  {
    "date": "2026-01-15",
    "title": "OT-Drive: Out-of-Distribution Off-Road Traversable Area Segmentation via Optimal Transport",
    "authors": "Zhihua Zhao, Guoqiang Li, Chen Min, Kangping Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09952v1",
    "source": "arXiv",
    "abstract": "Reliable traversable area segmentation in unstructured environments is critical for planning and decision-making in autonomous driving. However, existing data-driven approaches often suffer from degraded segmentation performance in out-of-distribution (OOD) scenarios, consequently impairing downstream driving tasks. To address this issue, we propose OT-Drive, an Optimal Transport--driven multi-modal fusion framework. The proposed method formulates RGB and surface normal fusion as a distribution transport problem. Specifically, we design a novel Scene Anchor Generator (SAG) to decompose scene information into the joint distribution of weather, time-of-day, and road type, thereby constructing semantic anchors that can generalize to unseen scenarios. Subsequently, we design an innovative Optimal Transport-based multi-modal fusion module (OT Fusion) to transport RGB and surface normal features onto the manifold defined by the semantic anchors, enabling robust traversable area segmentation under OOD scenarios. Experimental results demonstrate that our method achieves 95.16% mIoU on ORFD OOD scenarios, outperforming prior methods by 6.35%, and 89.79% mIoU on cross-dataset transfer tasks, surpassing baselines by 13.99%.These results indicate that the proposed model can attain strong OOD generalization with only limited training data, substantially enhancing its practicality and efficiency for real-world deployment."
  },
  {
    "date": "2026-01-15",
    "title": "Ultra-low magnetization and hysteresis loss in APC Nb3Sn superconductors",
    "authors": "X Xu, F Wan, X Peng, M Sumption",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09945v1",
    "source": "arXiv",
    "abstract": "For the accelerator magnets of the next hadron collider, reducing superconductor persistent-current magnetization is not only important for achieving the desired field quality, but also crucial for its sustainability because the magnetization loss is the major heat load to the magnet cold mass. For conventional Nb3Sn conductors this requires reduction of effective subelement size (Deff). For the restacked-rod-process (RRP) conductors a physical subelement size (Dsub) as small as 35 um (corresponding to a Deff close to 45 um) can be reached, but at a significant price in Jc. Another way to reduce the magnetization is by introducing artificial pinning centers (APC) using the internal oxidation approach. APC conductors outperform conventional Nb3Sn wires in two aspects: 1) higher Jc at high fields, and 2) much lower Jc and magnetization at low fields (e.g., below 5 T). In this work we explored the fabricability of APC wires with small Dsub. A 180-stack APC wire was produced and drawn to 0.7- and 0.5-mm diameters with good quality, with Dsubs of 34 and 24 um (Deffs of 36 and 25 um), respectively. For the 34-um-Dsub wire, its non-Cu Jc is higher than that of an RRP wire used for the High-Luminosity Large Hadron Collider (HL-LHC) project above 13 T (e.g., 36% higher at 4.2 K, 18 T), while its non-Cu magnetization at 1 T, ΔM(1 T), is only 29% of the RRP wire. Its non-Cu hysteresis loss for a cycle between 1 and 14 T, Qh(1-14 T), is 37% of the RRP wire. For the 24-um-Dsub wire, its non-Cu Jc surpasses the HL-LHC RRP wire above 17.5 T, while its ΔM(1 T) and Qh(1-14 T) are only 17% and 23% of the RRP wire, respectively. Its non-Cu Qh(+/-3 T) even meets the specification of the International Thermonuclear Experimental Reactor (ITER) project."
  },
  {
    "date": "2026-01-15",
    "title": "Placement Delivery Array for Cache-Aided MIMO Systems",
    "authors": "Yifei Huang, Kai Wan, Minquan Cheng, Jinyan Wang, Giuseppe Caire",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10422v1",
    "source": "arXiv",
    "abstract": "We consider a $(G,L,K,M,N)$ cache-aided multiple-input multiple-output (MIMO) network, where a server equipped with $L$ antennas and a library of $N$ equal-size files communicates with $K$ users, each equipped with $G$ antennas and a cache of size $M$ files, over a wireless interference channel. Each user requests an arbitrary file from the library. The goal is to design coded caching schemes that simultaneously achieve the maximum sum degrees of freedom (sum-DoF) and low subpacketization. In this paper, we first introduce a unified combinatorial structure, termed the MIMO placement delivery array (MIMO-PDA), which characterizes uncoded placement and one-shot zero-forcing delivery. By analyzing the combinatorial properties of MIMO-PDAs, we derive a sum-DoF upper bound of $\\min\\{KG, Gt+G\\lceil L/G \\rceil\\}$, where $t=KM/N$, which coincides with the optimal DoF characterization in prior work by Tehrani \\emph{et al.}. Based on this upper bound, we present two novel constructions of MIMO-PDAs that achieve the maximum sum-DoF. The first construction achieves linear subpacketization under stringent parameter constraints, while the second achieves ordered exponential subpacketization under substantially milder constraints. Theoretical analysis and numerical comparisons demonstrate that the second construction exponentially reduces subpacketization compared to existing schemes while preserving the maximum sum-DoF."
  },
  {
    "date": "2026-01-15",
    "title": "ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics",
    "authors": "Weiping Fu, Bifan Wei, Jingyi Hao, Yushun Zhang, Jian Zhang, Jiaxin Wang, Bo Li, Yu He, Lingling Zhang, Jun Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10406v1",
    "source": "arXiv",
    "abstract": "Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. However, existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions."
  },
  {
    "date": "2026-01-15",
    "title": "Reshaping Neural Representation via Associative, Presynaptic Short-Term Plasticity",
    "authors": "Genki Shimizu, Taro Toyoizumi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10397v1",
    "source": "arXiv",
    "abstract": "Short-term synaptic plasticity (STP) is traditionally viewed as a purely presynaptic filter of incoming spike trains, independent of postsynaptic activity. Recent experiments, however, reveal an associative form of STP in which presynaptic release probability changes alongside long-term potentiation, implying a richer computational role for presynaptic plasticity. Here we develop a normative theory of associative STP using an information-theoretic framework. Extending Fisher-information-based learning to Tsodyks-Markram synapses, we derive analytic update rules for baseline synaptic strength and release probability that maximize encoded stimulus information under resource constraints. The learning rules separate into a conventional postsynaptic term tracking local firing and a distinct presynaptic term with a phase-advanced structure that selectively detects stimulus onset; critically, differences between plasticity of baseline strength and release probability arise within this presynaptic component. For stimulus variations slower than the EPSP time constant, onset sensitivity biases optimal connectivity toward anti-causal associations, strengthening synapses from neurons activated later to those activated earlier. In recurrent circuits, these rules yield ramp-like sustained representations and reverse replay after drive removal. Linear-response analysis further shows that STP confers frequency-dependent phase selectivity on presynaptic drive and that constraints on total release probability systematically tune temporal asymmetry. Together, our results provide a principled account of associative STP and identify presynaptic plasticity of release probability as a substrate for rapidly reconfigurable temporal coding."
  },
  {
    "date": "2026-01-15",
    "title": "Multi-Temporal Frames Projection for Dynamic Processes Fusion in Fluorescence Microscopy",
    "authors": "Hassan Eshkiki, Sarah Costa, Mostafa Mohammadpour, Farinaz Tanhaei, Christopher H. George, Fabio Caraffini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10392v1",
    "source": "arXiv",
    "abstract": "Fluorescence microscopy is widely employed for the analysis of living biological samples; however, the utility of the resulting recordings is frequently constrained by noise, temporal variability, and inconsistent visualisation of signals that oscillate over time. We present a unique computational framework that integrates information from multiple time-resolved frames into a single high-quality image, while preserving the underlying biological content of the original video. We evaluate the proposed method through an extensive number of configurations (n = 111) and on a challenging dataset comprising dynamic, heterogeneous, and morphologically complex 2D monolayers of cardiac cells. Results show that our framework, which consists of a combination of explainable techniques from different computer vision application fields, is capable of generating composite images that preserve and enhance the quality and information of individual microscopy frames, yielding 44% average increase in cell count compared to previous methods. The proposed pipeline is applicable to other imaging domains that require the fusion of multi-temporal image stacks into high-quality 2D images, thereby facilitating annotation and downstream segmentation."
  },
  {
    "date": "2026-01-15",
    "title": "Regularization of linear inverse problems by rational Krylov methods",
    "authors": "Stefan Kindermann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10389v1",
    "source": "arXiv",
    "abstract": "For approximately solving linear ill-posed problems in Hilbert spaces, we investigate the regularization properties of the aggregation method and the RatCG method. These recent algorithms use previously calculated solutions of Tikhonov regularization (respectively, Landweber iterations) to set up a new search space on which the least-squares functional is minimized. We outline how these methods can be understood as rational Krylov space methods, i.e., based on the space of rational functions of the forward operator. The main result is that these methods form an optimal-order regularization schemes when combined with the discrepancy principle as stopping rule and when the underlying regularization parameters are sufficiently large."
  },
  {
    "date": "2026-01-15",
    "title": "Phase Space structure on Clifford Algebras",
    "authors": "C. Robson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10381v1",
    "source": "arXiv",
    "abstract": "I argue that the Hodge structure on a Euclidean Clifford algebra $Cl(n)$ provides a way to generalise Kähler structure to higher dimensions, in the sense that the paired variables are now associated with $k-$ and $(n-k)-$ dimensional subspaces rather than with vectors. This puts a phase space structure on Clifford algebras, and so allows us to construct a Hamiltonian dynamics on these multilinear variables. This construction shows that alternating pairs of subspaces obey commuting and anticommuting dynamics, hinting that this construction is indeed a natural one, with interesting new behaviour."
  },
  {
    "date": "2026-01-15",
    "title": "Gene genealogies in diploid populations evolving according to sweepstakes reproduction",
    "authors": "Bjarki Eldon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10364v1",
    "source": "arXiv",
    "abstract": "Recruitment dynamics, or the distribution of the number of offspring among individuals, is central for understanding ecology and evolution. Sweepstakes reproduction (heavy right-tailed offspring number distribution) is central for understanding the ecology and evolution of highly fecund natural populations. Sweepstakes reproduction can induce jumps in type frequencies and multiple mergers in gene genealogies of sampled gene copies. We take sweepstakes reproduction to be skewed offspring number distribution due to mechanisms not involving natural selection, such as in chance matching of broadcast spawning with favourable environmental conditions. Here, we consider population genetic models of sweepstakes reproduction in a diploid panmictic populations absent selfing and evolving in a random environment. Our main results are {\\it (i)} continuous-time Beta and Poisson-Dirichlet coalescents, when combining the results the skewness parameter $α$ of the Beta-coalescent ranges from $0$ to $2$, and the Beta-coalescents may be incomplete due to an upper bound on the number of potential offspring produced by any pair of parents; {\\it (ii)} in large populations time is measured in units proportional to either $N/\\log N$ or $N$ generations (where $2N$ is the population size when constant); {\\it (iii)} it follows that incorporating population size changes leads to time-changed coalescents with the time-change independent of $α$; {\\it (iv)} using simulations we show that the ancestral process is not well approximated by the corresponding coalescent (as measured through certain functionals of the processes); {\\it (v)} whenever the skewness of the offspring number distribution is increased the conditional (conditioned on the population ancestry) and the unconditional ancestral processes are not in good agreement."
  },
  {
    "date": "2026-01-15",
    "title": "Testing the correlation between bending angle and polarization properties of bent radio galaxies",
    "authors": "S. Vanderwoude, E. Osinga, B. M. Gaensler, J. L. West, R. J. van Weeren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10361v1",
    "source": "arXiv",
    "abstract": "The bending of radio galaxies in galaxy clusters is expected to be caused by interactions with the local environment. The physical processes responsible for jet bending, and their influence on the polarization properties of radio galaxies, remain poorly understood, leading to the question of whether jet properties in bent radio galaxies differ from those in linear radio galaxies. Using a sample of 24 polarized bent radio galaxies, observed with the Karl G. Jansky Very Large Array at 1--2 GHz, we test for correlation of bending angle with polarization parameters measuring Faraday rotation, intrinsic fractional polarization, and Faraday rotation dispersion, used here as a measure of turbulence along the line of sight. We find no statistically significant correlations. At the spatial resolution of our dataset (3--46 kpc, median 18.4 kpc), our results indicate that we are primarily probing larger-scale intracluster medium effects not related to bending angle. The absence of a statistically significant correlation suggests that bent radio galaxies are reliable probes of intracluster magnetic fields, because their intrinsic properties do not appear to introduce systematic biases into measured polarization parameters. We do detect a preference for source magnetic field vectors to align with the direction of jet bending. Finally, we estimate that the POSSUM and SKA surveys will contain $\\gtrsim$300 and $\\gtrsim$1000 polarized radio galaxies, respectively, providing large future samples with a range of bending angles and similar redshift distribution and number of beams per source as in our sample, enabling our results to be tested with greater statistical power."
  },
  {
    "date": "2026-01-15",
    "title": "Enhanced multi-parameter metrology in dissipative Rydberg atom time crystals",
    "authors": "Bang Liu, Jun-Rong Chen, Yu Ma, Qi-Feng Wang, Tian-Yu Han, Hao Tian, Yu-Hua Qian, Guang-Can Guo, Li-Hua Zhang, Bin-Bin Wei, Abolfazl Bayat, Dong-Sheng Ding, Bao-Sen Shi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10347v1",
    "source": "arXiv",
    "abstract": "The pursuit of unprecedented sensitivity in quantum enhanced metrology has spurred interest in non-equilibrium quantum phases of matter and their symmetry breaking. In particular, criticality-enhanced metrology through time-translation symmetry breaking in many-body systems, a distinct paradigm compared to spatial symmetry breaking, is a field still in its infancy. Here, we have investigated the enhanced sensing at the boundary of a continuous time-crystal (CTC) phase in a driven Rydberg atomic gas. By mapping the full phase diagram, we identify the parameter-dependent phase boundary where the time-translation symmetry is broken. This allows us to use a single setup for measuring multiple parameters, in particular frequency and amplitude of a microwave field. By increasing the microwave field amplitude, we first observe a phase transition from a thermal phase to a CTC phase, followed by a second transition into a distinct CTC state, characterized by a different oscillation frequency. Furthermore, we reveal the precise relationship between the CTC phase boundary and the scanning rate, displaying enhanced precision beyond the Standard Quantum Limit. This work not only provides a promising paradigm rooted in the critical properties of time crystals, but also advances a method for multi-parameter sensing in non-equilibrium quantum phases."
  },
  {
    "date": "2026-01-15",
    "title": "C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing",
    "authors": "Cheng Lin Cheng, Ting Chuan Lin, Chai Kai Chang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10342v1",
    "source": "arXiv",
    "abstract": "Heart rate variability (HRV) is a pivotal noninvasive marker for autonomic monitoring; however, applying Large Language Models (LLMs) to HRV interpretation is hindered by physiological hallucinations. These include respiratory sinus arrhythmia (RSA) contamination, short-data instability in nonlinear metrics, and the neglect of individualized baselines in favor of population norms. We propose C-GRASP (Clinically-Grounded Reasoning for Affective Signal Processing), a guardrailed RAG-enhanced pipeline that decomposes HRV interpretation into eight traceable reasoning steps. Central to C-GRASP is a Z-score Priority Hierarchy that enforces the weighting of individualized baseline shifts over normative statistics. The system effectively mitigates spectral hallucinations through automated RSA-aware guardrails, preventing contamination of frequency-domain indices. Evaluated on 414 trials from the DREAMER dataset, C-GRASP integrated with high-scale reasoning models (e.g., MedGemma3-thinking) achieved superior performance in 4-class emotion classification (37.3% accuracy) and a Clinical Reasoning Consistency (CRC) score of 69.6%. Ablation studies confirm that the individualized Delta Z-score module serves as the critical logical anchor, preventing the \"population bias\" common in native LLMs. Ultimately, C-GRASP transitions affective computing from black-box classification to transparent, evidence-based clinical decision support, paving the way for safer AI integration in biomedical engineering."
  },
  {
    "date": "2026-01-15",
    "title": "Meta Dynamic Graph for Traffic Flow Prediction",
    "authors": "Yiqing Zou, Hanning Yuan, Qianyu Yang, Ziqiang Yuan, Shuliang Wang, Sijie Ruan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10328v1",
    "source": "arXiv",
    "abstract": "Traffic flow prediction is a typical spatio-temporal prediction problem and has a wide range of applications. The core challenge lies in modeling the underlying complex spatio-temporal dependencies. Various methods have been proposed, and recent studies show that the modeling of dynamics is useful to meet the core challenge. While handling spatial dependencies and temporal dependencies using separate base model structures may hinder the modeling of spatio-temporal correlations, the modeling of dynamics can bridge this gap. Incorporating spatio-temporal heterogeneity also advances the main goal, since it can extend the parameter space and allow more flexibility. Despite these advances, two limitations persist: 1) the modeling of dynamics is often limited to the dynamics of spatial topology (e.g., adjacency matrix changes), which, however, can be extended to a broader scope; 2) the modeling of heterogeneity is often separated for spatial and temporal dimensions, but this gap can also be bridged by the modeling of dynamics. To address the above limitations, we propose a novel framework for traffic prediction, called Meta Dynamic Graph (MetaDG). MetaDG leverages dynamic graph structures of node representations to explicitly model spatio-temporal dynamics. This generates both dynamic adjacency matrices and meta-parameters, extending dynamic modeling beyond topology while unifying the capture of spatio-temporal heterogeneity into a single dimension. Extensive experiments on four real-world datasets validate the effectiveness of MetaDG."
  },
  {
    "date": "2026-01-15",
    "title": "ROMA: Real-time Omni-Multimodal Assistant with Interactive Streaming Understanding",
    "authors": "Xueyun Tian, Wei Li, Bingbing Xu, Heng Dong, Yuanzhuo Wang, Huawei Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10323v1",
    "source": "arXiv",
    "abstract": "Recent Omni-multimodal Large Language Models show promise in unified audio, vision, and text modeling. However, streaming audio-video understanding remains challenging, as existing approaches suffer from disjointed capabilities: they typically exhibit incomplete modality support or lack autonomous proactive monitoring. To address this, we present ROMA, a real-time omni-multimodal assistant for unified reactive and proactive interaction. ROMA processes continuous inputs as synchronized multimodal units, aligning dense audio with discrete video frames to handle granularity mismatches. For online decision-making, we introduce a lightweight speak head that decouples response initiation from generation to ensure precise triggering without task conflict. We train ROMA with a curated streaming dataset and a two-stage curriculum that progressively optimizes for streaming format adaptation and proactive responsiveness. To standardize the fragmented evaluation landscape, we reorganize diverse benchmarks into a unified suite covering both proactive (alert, narration) and reactive (QA) settings. Extensive experiments across 12 benchmarks demonstrate ROMA achieves state-of-the-art performance on proactive tasks while competitive in reactive settings, validating its robustness in unified real-time omni-multimodal understanding."
  },
  {
    "date": "2026-01-15",
    "title": "An Efficient Long-Context Ranking Architecture With Calibrated LLM Distillation: Application to Person-Job Fit",
    "authors": "Warren Jouanneau, Emma Jouffroy, Marc Palyart",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10321v1",
    "source": "arXiv",
    "abstract": "Finding the most relevant person for a job proposal in real time is challenging, especially when resumes are long, structured, and multilingual. In this paper, we propose a re-ranking model based on a new generation of late cross-attention architecture, that decomposes both resumes and project briefs to efficiently handle long-context inputs with minimal computational overhead. To mitigate historical data biases, we use a generative large language model (LLM) as a teacher, generating fine-grained, semantically grounded supervision. This signal is distilled into our student model via an enriched distillation loss function. The resulting model produces skill-fit scores that enable consistent and interpretable person-job matching. Experiments on relevance, ranking, and calibration metrics demonstrate that our approach outperforms state-of-the-art baselines."
  },
  {
    "date": "2026-01-15",
    "title": "Molecular electrostatic potentials from machine learning models for dipole and quadrupole predictions",
    "authors": "Kadri Muuga, Lisanne Knijff, Chao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10320v1",
    "source": "arXiv",
    "abstract": "The molecular electrostatic potential (MEP) is a key quantity for describing and predicting intermolecular and ion-molecule interactions. Here, we assess the ability of machine-learning (ML) models to infer the MEP, based on the equivariant graph-convolutional neural network architecture PiNet2 and trained on dipole and quadrupole moments. For the established QM9 dataset, we find that including the quadrupole contribution in the ML models substantially improves their ability to recover the MEP compared to dipole-only models. This trend is confirmed on the SPICE dataset, which spans a much broader region of organic chemical space. Together, this study underscores the central role of the quadrupole moment as a fitting target for ML models aiming at rapid access to the MEP."
  },
  {
    "date": "2026-01-15",
    "title": "ADVOSYNTH: A Synthetic Multi-Advocate Dataset for Speaker Identification in Courtroom Scenarios",
    "authors": "Aniket Deroy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10315v1",
    "source": "arXiv",
    "abstract": "As large-scale speech-to-speech models achieve high fidelity, the distinction between synthetic voices in structured environments becomes a vital area of study. This paper introduces Advosynth-500, a specialized dataset comprising 100 synthetic speech files featuring 10 unique advocate identities. Using the Speech Llama Omni model, we simulate five distinct advocate pairs engaged in courtroom arguments. We define specific vocal characteristics for each advocate and present a speaker identification challenge to evaluate the ability of modern systems to map audio files to their respective synthetic origins. Dataset is available at this link-https: //github.com/naturenurtureelite/ADVOSYNTH-500."
  },
  {
    "date": "2026-01-15",
    "title": "Multilinguality as Sense Adaptation",
    "authors": "Jan Christian Blaise Cruz, David Ifeoluwa Adelani, Alham Fikri Aji",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10310v1",
    "source": "arXiv",
    "abstract": "We approach multilinguality as sense adaptation: aligning latent meaning representations across languages rather than relying solely on shared parameters and scale. In this paper, we introduce SENse-based Symmetric Interlingual Alignment (SENSIA), which adapts a Backpack language model from one language to another by explicitly aligning sense-level mixtures and contextual representations on parallel data, while jointly training a target-language language modeling loss to preserve fluency. Across benchmarks on four typologically diverse languages, SENSIA generally outperforms comparable multilingual alignment methods and achieves competitive accuracy against monolingual from-scratch baselines while using 2-4x less target-language data. Analyses of learned sense geometry indicate that local sense topology and global structure relative to English are largely preserved, and ablations show that the method is robust in terms of design and scale."
  },
  {
    "date": "2026-01-15",
    "title": "The Straight and Narrow: Do LLMs Possess an Internal Moral Path?",
    "authors": "Luoming Hu, Jingjie Zeng, Liang Yang, Hongfei Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10307v1",
    "source": "arXiv",
    "abstract": "Enhancing the moral alignment of Large Language Models (LLMs) is a critical challenge in AI safety. Current alignment techniques often act as superficial guardrails, leaving the intrinsic moral representations of LLMs largely untouched. In this paper, we bridge this gap by leveraging Moral Foundations Theory (MFT) to map and manipulate the fine-grained moral landscape of LLMs. Through cross-lingual linear probing, we validate the shared nature of moral representations in middle layers and uncover a shared yet different moral subspace between English and Chinese. Building upon this, we extract steerable Moral Vectors and successfully validate their efficacy at both internal and behavioral levels. Leveraging the high generalizability of morality, we propose Adaptive Moral Fusion (AMF), a dynamic inference-time intervention that synergizes probe detection with vector injection to tackle the safety-helpfulness trade-off. Empirical results confirm that our approach acts as a targeted intrinsic defense, effectively reducing incorrect refusals on benign queries while minimizing jailbreak success rates compared to standard baselines."
  },
  {
    "date": "2026-01-15",
    "title": "DanQing: An Up-to-Date Large-Scale Chinese Vision-Language Pre-training Dataset",
    "authors": "Hengyu Shen, Tiancheng Gu, Bin Qin, Lan Wu, Yuling Wu, Shuo Tan, Zelong Sun, Jun Wang, Nan Wu, Xiang An, Weidong Cai, Ziyong Feng, Kaicheng Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10305v1",
    "source": "arXiv",
    "abstract": "Vision-Language Pre-training (VLP) models demonstrate strong performance across various downstream tasks by learning from large-scale image-text pairs through contrastive pretraining. The release of extensive English image-text datasets (e.g., COYO-700M and LAION-400M) has enabled widespread adoption of models such as CLIP and SigLIP in tasks including cross-modal retrieval and image captioning. However, the advancement of Chinese vision-language pretraining has substantially lagged behind, due to the scarcity of high-quality Chinese image-text data. To address this gap, we develop a comprehensive pipeline for constructing a high-quality Chinese cross-modal dataset. As a result, we propose DanQing, which contains 100 million image-text pairs collected from Common Crawl. Different from existing datasets, DanQing is curated through a more rigorous selection process, yielding superior data quality. Moreover, DanQing is primarily built from 2024-2025 web data, enabling models to better capture evolving semantic trends and thus offering greater practical utility. We compare DanQing with existing datasets by continual pre-training of the SigLIP2 model. Experimental results show that DanQing consistently achieves superior performance across a range of Chinese downstream tasks, including zero-shot classification, cross-modal retrieval, and LMM-based evaluations. To facilitate further research in Chinese vision-language pre-training, we will open-source the DanQing dataset under the Creative Common CC-BY 4.0 license."
  },
  {
    "date": "2026-01-15",
    "title": "Model-Driven GPR Inversion Network With Surrogate Forward Solver",
    "authors": "Huilin Zhou, Xin Liu, Kexiang Wang, Shufan Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10284v1",
    "source": "arXiv",
    "abstract": "Data-driven deep learning is considered a promising solution for ground-penetrating radar (GPR) full-waveform inversion (FWI), while its generalization ability is limited due to the heavy reliance on abundant labeled samples. In contrast, Deep unfolding network (DUN) usually exhibits better generalization by integrating model-driven and data-driven approaches, yet its application to GPR FWI remains challenging due to the high computational cost associated with forward simulations. In this paper, we integrate a deep learning-based (DL-based) forward solver within an unfolding framework to form a fully neural-network-based architecture, UA-Net, for GPR FWI. The forward solver rapidly predicts B-scans given permittivity and conductivity models and enables automatic differentiation to compute gradients for inversion. In the inversion stage, an optimization process based on the Alternating Direction Method of Multipliers (ADMM) is unfolded into a multi-stage network with three interconnected modules: data fitting, regularization, and multiplier update. Specifically, the regularization module is trained end-to-end for adaptive learning of sparse target features. Experimental results demonstrate that UA-Net outperforms classical FWI and data-driven methods in reconstruction accuracy. Moreover, by employing transfer learning to fine-tune the network, UA-Net can be effectively applied to field data and produce reliable results."
  },
  {
    "date": "2026-01-15",
    "title": "How Intrinsic Motivation Underlies Embodied Open-Ended Behavior",
    "authors": "Rubén Moreno-Bote, Ralf Haefner, Jordi Galiano-Landeira, Tianming Yang, Pedro Maldonado",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10276v1",
    "source": "arXiv",
    "abstract": "Although most theories posit that natural behavior can be explained as maximizing some form of extrinsic reward, often called utility, some behaviors appear to be reward independent. For instance, spontaneous motor babbling in human newborns and curiosity in little kids and other animals seem to elude a simple explanation in terms of extrinsic reward maximization. Rooted in these observations, intrinsic motivation has emerged as a potentially major driver of behavior. However, only recently have several quantitative and foundational theories of intrinsic motivation been put forward. We first provide a general framework to understand behavior as being organized hierarchically: objective--intrinsic reward, or motivation--drives, goals and extrinsic reward. We next review the main formalizations of intrinsic motivation, including empowerment, the free energy principle, information-gain maximization, and the maximum occupancy principle. These theories produce complex behavior by promoting, in various ways, entropic action-state paths. The presence of a single intrinsic motivation objective breaks infinite regress, as drives and goals act only temporarily to serve the objective. Extrinsic rewards, such as sugar or protein, are just a means to achieve the objective. Bounded cognition and embodiment impose constraints and boundary conditions for the intrinsic motivation objective. By virtue of their capability to generate complex behavior in a task-agnostic manner, theories of intrinsic motivation promise to become successful generative models of open-ended, embodied behavior."
  },
  {
    "date": "2026-01-15",
    "title": "On a general identity and a resulting class of umbral operators",
    "authors": "Kei Beauduin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10275v1",
    "source": "arXiv",
    "abstract": "We prove a new universal identity for umbral operators. This motivates the definition of a subclass obeying a simplified identity, which we then fully characterize. The results are illustrated with common examples of the theory of umbral calculus."
  },
  {
    "date": "2026-01-15",
    "title": "In-Context Source and Channel Coding",
    "authors": "Ziqiong Wang, Tianqi Ren, Rongpeng Li, Zhifeng Zhao, Honggang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10267v1",
    "source": "arXiv",
    "abstract": "Separate Source-Channel Coding (SSCC) remains attractive for text transmission due to its modularity and compatibility with mature entropy coders and powerful channel codes. However, SSCC often suffers from a pronounced cliff effect in low Signal-to-Noise Ratio (SNR) regimes, where residual bit errors after channel decoding can catastrophically break lossless source decoding, especially for Arithmetic Coding (AC) driven by Large Language Models (LLMs). This paper proposes a receiver-side In-Context Decoding (ICD) framework that enhances SSCC robustness without modifying the transmitter. ICD leverages an Error Correction Code Transformer (ECCT) to obtain bit-wise reliability for the decoded information bits. Based on the context-consistent bitstream, ICD constructs a confidence-ranked candidate pool via reliability-guided bit flipping, samples a compact yet diverse subset of candidates, and applies an LLM-based arithmetic decoder to obtain both reconstructions and sequence-level log-likelihoods. A reliability-likelihood fusion rule then selects the final output. We further provide theoretical guarantees on the stability and convergence of the proposed sampling procedure. Extensive experiments over Additive White Gaussian Noise (AWGN) and Rayleigh fading channels demonstrate consistent gains compared with conventional SSCC baselines and representative Joint Source-Channel Coding (JSCC) schemes."
  },
  {
    "date": "2026-01-15",
    "title": "An Ensemble of Evolutionary Algorithms With Both Crisscross Search and Sparrow Search for Processing Inferior Individuals",
    "authors": "Mingxuan Du, Tingzhang Luo, Ziyang Wang, Chengjun Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10263v1",
    "source": "arXiv",
    "abstract": "In the field of artificial intelligence, real parameter single objective optimization is an important direction. Both the Differential Evolution (DE) and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) demonstrate good performance for real parameter single objective optimization. Nevertheless, there exist other types of evolutionary algorithm for the purpose. In recent years, researchers begin to study long-term search. EA4eig - an ensemble of three DE variants and CMA-ES - performs well for long-term search. In this paper, we introduce two types of evolutionary algorithm proposed recently - crisscross search and sparrow search - into EA4eig as secondary evolutionary algorithms to process inferior individuals. Thus, EA4eigCS is obtained. In our ensemble, the secondary evolutionary algorithms are expected to vary distribution of the population for breaking stagnation. Experimental results show that our EA4eigCS outperforms EA4eig and is competitive when compared with state-of-the-art algorithms. Code and supplementary material are available at:https://anonymous.4open.science/r/EA4eigCS-2A43."
  },
  {
    "date": "2026-01-15",
    "title": "An Exact Energy Conservation Law for Magneto-Optical Nanoparticles",
    "authors": "Jorge Olmos-Trigo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10255v1",
    "source": "arXiv",
    "abstract": "Energy conservation imposes fundamental bounds on the polarizabilities of nanoparticles (NPs). While such bounds are well established for isotropic and bianisotropic NPs, they remain unexplored for magneto-optical NPs. Here, we derive the exact energy-conservation law governing the electric and magnetic dipolar response of axially symmetric magneto-optical NPs under general illumination conditions and arbitrary external magnetic fields. Two central results follow from energy conservation: (i) purely magneto-optical scattering, where the non-magnetic polarizability vanishes, is fundamentally forbidden, and (ii) strong magneto-optical scattering regimes, in which the magneto-optical polarizability dominates, are intriguingly allowed."
  },
  {
    "date": "2026-01-15",
    "title": "NoReGeo: Non-Reasoning Geometry Benchmark",
    "authors": "Irina Abdullaeva, Anton Vasiliuk, Elizaveta Goncharova, Temurbek Rahmatullaev, Zagorulko Ivan, Maxim Kurkin, Andrey Kuznetsov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10254v1",
    "source": "arXiv",
    "abstract": "We present NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models (LLMs) without relying on reasoning or algebraic computation. Unlike existing benchmarks that primarily assess models' proficiency in reasoning-based geometry-where solutions are derived using algebraic methods-NoReGeo focuses on evaluating whether LLMs can inherently encode spatial relationships and recognize geometric properties directly. Our benchmark comprises 2,500 trivial geometric problems spanning 25 categories, each carefully crafted to be solvable purely through native geometric understanding, assuming known object locations. We assess a range of state-of-the-art models on NoReGeo, including frontier models like GPT-4, observing that even the most advanced systems achieve an overall maximum of 65% accuracy in binary classification tasks. Further, our ablation experiments demonstrate that such geometric understanding does not emerge through fine-tuning alone, indicating that effective training for geometric comprehension requires a specialized approach from the outset. Our findings highlight a significant gap in current LLMs' ability to natively grasp geometric concepts, providing a foundation for future research toward models with true geometric cognition."
  },
  {
    "date": "2026-01-15",
    "title": "Updated Results for Kinematic Factors in Double Beta Decays",
    "authors": "S. Ghinescu, S. Stoica",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10247v1",
    "source": "arXiv",
    "abstract": "Accurate calculations of phase space factors (PSFs), electron energy spectra and angular correlations are essential for designing and interpreting double-beta decay (DBD) experiments. These quantities help maximize sensitivity to potential signals, distinguish between different decay modes and interpret the data. In this work we provide updated results for these kinematic factors for two-neutrino ($2νββ$) and neutrinoless ($0νββ$) decay modes, including electron-emission, positron-emission and electron capture transitions. The calculations are performed with an adapted Dirac-Hartree-Fock-Slater method which allows for orthogonality of the wave functions of electrons and positrons in bound and continuum states and incorporates relevant atomic features such us screening, finite nuclear size, exchange corrections and phase shift effects. We provide tables with updated PSFs calculated both in the closure approximation and using the Taylor expansion method, for a large number of DBD isotopes. We discuss the impact of individual atomic corrections and find that our results are in line with predictions reported in recent literature. In some specific cases we find differences between our PSF values and those previously reported which are worth considering for better prediction and interpretation of DBD data. Then, we provide numerical values for $^{76}\\text{Ge}$, $^{100}\\text{Mo}$, $^{130}\\text{Te}$ and $^{136}\\text{Xe}$, which are most investigated in current DBD experiments. Similar data for other isotopes are available upon request."
  },
  {
    "date": "2026-01-15",
    "title": "Large-scale time-series spectroscopy for stellar ages",
    "authors": "David Gruner, Sydney A. Barnes, Ansgar Reiners, Klaus G. Strassmeier, Cristina Chiappini, Jörg Weingrill, Michael Weber, Ilya Ilyin, Thomas Granzer, Özgün Adebali, Jean-Michel Désert, Marica Valentini, Dario Fritzewski, Paolo Ventura, Alfio Bonanno, Jose-Dias do Nascimento, Jorge Melendez, Santosh Joshi, Yong-Cheol Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10240v1",
    "source": "arXiv",
    "abstract": "To date, Galactic Astronomy has largely concerned itself with astrophysical processes, and with the locations, space motions and compositions of objects. Consider, for example, the elucidation of the components of the Galaxy over the past decades, its mapping as enabled by Gaia and its predecessors, the photometric and spectroscopic characterization of innumerable astrophysical objects in various wavelength ranges, both from the ground and from space, and the expanding discovery and characterization of exoplanets; all focused on the current, static Galaxy. This White Paper proposes a dedicated program to derive stellar ages from time-series spectroscopy to hasten the transformation of this static conception into a dynamical one with age-labeled objects and events."
  },
  {
    "date": "2026-01-15",
    "title": "Proactive Local-Minima-Free Robot Navigation: Blending Motion Prediction with Safe Control",
    "authors": "Yifan Xue, Ze Zhang, Knut Åkesson, Nadia Figueroa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10233v1",
    "source": "arXiv",
    "abstract": "This work addresses the challenge of safe and efficient mobile robot navigation in complex dynamic environments with concave moving obstacles. Reactive safe controllers like Control Barrier Functions (CBFs) design obstacle avoidance strategies based only on the current states of the obstacles, risking future collisions. To alleviate this problem, we use Gaussian processes to learn barrier functions online from multimodal motion predictions of obstacles generated by neural networks trained with energy-based learning. The learned barrier functions are then fed into quadratic programs using modulated CBFs (MCBFs), a local-minimum-free version of CBFs, to achieve safe and efficient navigation. The proposed framework makes two key contributions. First, it develops a prediction-to-barrier function online learning pipeline. Second, it introduces an autonomous parameter tuning algorithm that adapts MCBFs to deforming, prediction-based barrier functions. The framework is evaluated in both simulations and real-world experiments, consistently outperforming baselines and demonstrating superior safety and efficiency in crowded dynamic environments."
  },
  {
    "date": "2026-01-15",
    "title": "A Unified Framework for Kinematic Simulation of Rigid Foldable Structures",
    "authors": "Dongwook Kwak, Geonhee Cho, Jiook Chung, Jinkyu Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10225v1",
    "source": "arXiv",
    "abstract": "Origami-inspired structures with rigid panels now span thick, kirigami, and multi-sheet realizations, making unified kinematic analysis essential. Yet a general method that consolidates their loop constraints has been lacking. We present an automated approach that generates the Pfaffian constraint matrix for arbitrary rigid foldable structures (RFS). From a minimally extended data schema, the tool constructs the facet-hinge graph, extracts a minimum cycle basis that captures all constraints, and assembles a velocity-level constraint matrix via screw theory that encodes coupled rotation and translation loop closure. The framework computes and visualizes deploy and fold motions across diverse RFS while eliminating tedious and error-prone constraint calculations."
  },
  {
    "date": "2026-01-15",
    "title": "Quantitative approach for the Dicke-Ising chain with an effective self-consistent matter Hamiltonian",
    "authors": "J. Leibig, M. Hörmann, A. Langheld, A. Schellenberger, K. P. Schmidt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10210v1",
    "source": "arXiv",
    "abstract": "In the thermodynamic limit, the Dicke-Ising chain maps exactly onto an effective self-consistent matter Hamiltonian with the photon field acting solely as a self-consistent effective field. As a consequence, no quantum correlations between photons and spins are needed to understand the quantum phase diagram. This enables us to determine the quantum phase diagram in the thermodynamic limit using numerical linked-cluster expansions combined with density matrix renormalization group calculations (NLCE+DMRG) to solve the resulting self-consistent matter Hamiltonian. This includes magnetically ordered phases with significantly improved accuracy compared to previous estimates. For ferromagnetic Ising couplings, we refine the location of the multicritical point governing the change in the order of the superradiant phase transition, reaching a relative accuracy of $10^{-4}$. For antiferromagnetic Ising couplings, we confirm the existence of the narrow antiferromagnetic superradiant phase in the thermodynamic limit. The effective matter Hamiltonian framework identifies the antiferromagnetic superradiant phase as the many-body ground state of an antiferromagnetic transverse-field Ising model with longitudinal field. This phase emerges through continuous Dicke-type polariton condensation from the antiferromagnetic normal phase, followed by a first-order transition to the paramagnetic superradiant phase. Thus, NLCE+DMRG provides a precise determination of the Dicke-Ising phase diagram in one dimension by solving the self-consistent effective matter Hamiltonian."
  },
  {
    "date": "2026-01-15",
    "title": "Noise-Resilient Quantum Evolution in Open Systems through Error-Correcting Frameworks",
    "authors": "Nirupam Basak, Goutam Paul, Pritam Chattopadhyay",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10206v1",
    "source": "arXiv",
    "abstract": "We analyze quantum state preservation in open quantum systems using quantum error-correcting (QEC) codes that are explicitly embedded into microscopic system-bath models. Instead of abstract quantum channels, we consider multi-qubit registers coupled to bosonic thermal environments, derive a second-order master equation for the reduced dynamics, and use it to benchmark the five-qubit, Steane, and toric codes under local and collective noise. We compute state fidelities for logical qubits as functions of coupling strength, bath temperature, and the number of correction cycles. In the low-temperature regime, we find that repeated error-correction with the five-qubit code strongly suppresses decoherence and relaxation, while in the high-temperature regime, thermal excitations dominate the dynamics and reduce the benefit of all codes, though the five-qubit code still outperforms the Steane and toric codes. For two-qubit Werner states, we identify a critical evolution time before which QEC does not improve fidelity, and this time increases as entanglement grows. After this critical time, QEC does improve fidelity. Comparative analysis further reveals that the five-qubit code (the smallest perfect code) offers consistently higher fidelities than topological and concatenated architectures in these open-system settings. These findings establish a quantitative framework for evaluating QEC under realistic noise environments and provide guidance for developing noise-resilient quantum architectures in near-term quantum technologies."
  },
  {
    "date": "2026-01-15",
    "title": "Topology-Aware Block Coordinate Descent for Qubit Frequency Calibration of Superconducting Quantum Processors",
    "authors": "Zheng Zhao, Weifeng Zhuang, Yanwu Gu, Peng Qian, Xiao Xiao, Dong E. Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10203v1",
    "source": "arXiv",
    "abstract": "Pre-execution calibration is a major bottleneck for operating superconducting quantum processors, and qubit frequency allocation is especially challenging due to crosstalk-coupled objectives. We establish that the widely-used Snake optimizer is mathematically equivalent to Block Coordinate Descent (BCD), providing a rigorous theoretical foundation for this calibration strategy. Building on this formalization, we present a topology-aware block ordering obtained by casting order selection as a Sequence-Dependent Traveling Salesman Problem (SD-TSP) and solving it efficiently with a nearest-neighbor heuristic. The SD-TSP cost reflects how a given block choice expands the reduced-circuit footprint required to evaluate the block-local objective, enabling orders that minimize per-epoch evaluation time. Under local crosstalk/bounded-degree assumptions, the method achieves linear complexity in qubit count per epoch, while retaining calibration quality. We formalize the calibration objective, clarify when reduced experiments are equivalent or approximate to the full objective, and analyze convergence of the resulting inexact BCD with noisy measurements. Simulations on multi-qubit models show that the proposed BCD-NNA ordering attains the same optimization accuracy at markedly lower runtime than graph-based heuristics (BFS, DFS) and random orders, and is robust to measurement noise and tolerant to moderate non-local crosstalk. These results provide a scalable, implementation-ready workflow for frequency calibration on NISQ-era processors."
  },
  {
    "date": "2026-01-15",
    "title": "Graph Regularized PCA",
    "authors": "Antonio Briola, Marwin Schmidt, Fabio Caccioli, Carlos Ros Perez, James Singleton, Christian Michler, Tomaso Aste",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10199v1",
    "source": "arXiv",
    "abstract": "High-dimensional data often exhibit dependencies among variables that violate the isotropic-noise assumption under which principal component analysis (PCA) is optimal. For cases where the noise is not independent and identically distributed across features (i.e., the covariance is not spherical) we introduce Graph Regularized PCA (GR-PCA). It is a graph-based regularization of PCA that incorporates the dependency structure of the data features by learning a sparse precision graph and biasing loadings toward the low-frequency Fourier modes of the corresponding graph Laplacian. Consequently, high-frequency signals are suppressed, while graph-coherent low-frequency ones are preserved, yielding interpretable principal components aligned with conditional relationships. We evaluate GR-PCA on synthetic data spanning diverse graph topologies, signal-to-noise ratios, and sparsity levels. Compared to mainstream alternatives, it concentrates variance on the intended support, produces loadings with lower graph-Laplacian energy, and remains competitive in out-of-sample reconstruction. When high-frequency signals are present, the graph Laplacian penalty prevents overfitting, reducing the reconstruction accuracy but improving structural fidelity. The advantage over PCA is most pronounced when high-frequency signals are graph-correlated, whereas PCA remains competitive when such signals are nearly rotationally invariant. The procedure is simple to implement, modular with respect to the precision estimator, and scalable, providing a practical route to structure-aware dimensionality reduction that improves structural fidelity without sacrificing predictive performance."
  },
  {
    "date": "2026-01-15",
    "title": "GFM4GA: Graph Foundation Model for Group Anomaly Detection",
    "authors": "Jiujiu Chen, Weijun Zeng, Shaofeng Hu, Sihong Xie, Hui Xiong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10193v1",
    "source": "arXiv",
    "abstract": "Group anomaly detection is crucial in many network applications, but faces challenges due to diverse anomaly patterns. Motivated by the success of large language models (LLMs) in natural language processing, graph foundation models (GFMs) is proposed to handle few-shot learning task with fewer labeling efforts. GFMs have been successfully applied to detection of individual anomalies but cannot be generalized to group anomalies, as group anomaly patterns must be detected as a whole and individuals in an abnormal group can look rather normal. Therefore, we propose GFM4GA, a novel graph foundation model for group anomaly detection. The pipeline is pretrained via dual-level contrastive learning based on feature-based estimation and group extraction, to capture potential group anomaly structure and feature inconsistencies. In the downstream tasks, the pipeline is finetuned in parameter-constrained and group-anomaly-proportion weighted few-shot settings, and its adaptive ability to unseen group anomalies expanded via group contexts determined by labeled anomaly neighbors. Experiments show that GFM4GA surpasses group anomaly detectors and GFMs for individual anomalies, achieving average improvements of 2.85% in AUROC and 2.55% in AUPRC."
  },
  {
    "date": "2026-01-15",
    "title": "Reinforcement Learning to Discover a NorthEast Monsoon Index for Monthly Rainfall Prediction in Thailand",
    "authors": "Kiattikun Chobtham",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10181v1",
    "source": "arXiv",
    "abstract": "Climate prediction is a challenge due to the intricate spatiotemporal patterns within Earth systems. Global climate indices, such as the El Niño Southern Oscillation, are standard input features for long-term rainfall prediction. However, a significant gap persists regarding local-scale indices capable of improving predictive accuracy in specific regions of Thailand. This paper introduces a novel NorthEast monsoon climate index calculated from sea surface temperature to reflect the climatology of the boreal winter monsoon. To optimise the calculated areas used for this index, a Deep Q-Network reinforcement learning agent explores and selects the most effective rectangles based on their correlation with seasonal rainfall. Rainfall stations were classified into 12 distinct clusters to distinguish rainfall patterns between southern and upper Thailand. Experimental results show that incorporating the optimised index into Long Short-Term Memory models significantly improves long-term monthly rainfall prediction skill in most cluster areas. This approach effectively reduces the Root Mean Square Error for 12-month-ahead forecasts."
  },
  {
    "date": "2026-01-15",
    "title": "A Neuroevolution Potential for Gallium Oxide: Accurate and Efficient Modeling of Polymorphism and Swift Heavy-Ion Irradiation",
    "authors": "Yaohui Gu, Binbo Li, Lingyang Jiang, Yuhui Hu, Wenqiang Liu, Lijun Xu, Pengfei Zhai, Jie Liu, Jinglai Duan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10174v1",
    "source": "arXiv",
    "abstract": "Gallium oxide (Ga2O3) is a wide-bandgap semiconductor with promising applications in high-power and high-frequency electronics. However, its complex polymorphic nature poses substantial challenges for fundamental studies, particularly in understanding phase-transformation behaviors under nonequilibrium conditions. Here, we develop a robust, accurate, and computationally efficient machine-learning interatomic potential (MLIP) for Ga2O3 based on the neuroevolution potential (NEP) framework combined with an energy-dependent weighting strategy. The resulting NEP potential demonstrates clear advantages over the state-of-the-art tabGAP potential with respect to both accuracy and computational efficiency. Furthermore, we introduce a physically process-oriented sampling strategy to systematically augment the training dataset, thereby enhancing the MLIP performance for targeted physical phenomena. As a representative application, a dedicated NEP potential is constructed for swift heavy-ion (SHI) irradiation simulations of \\b{eta}-Ga2O3. The simulated results are in quantitative agreement with experimental observations and provide a consistent physical explanation for the reported experimental discrepancies regarding phase transformations in the ion track of \\b{eta}-Ga2O3."
  },
  {
    "date": "2026-01-15",
    "title": "Alterbute: Editing Intrinsic Attributes of Objects in Images",
    "authors": "Tal Reiss, Daniel Winter, Matan Cohen, Alex Rav-Acha, Yael Pritch, Ariel Shamir, Yedid Hoshen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10714v1",
    "source": "arXiv",
    "abstract": "We introduce Alterbute, a diffusion-based method for editing an object's intrinsic attributes in an image. We allow changing color, texture, material, and even the shape of an object, while preserving its perceived identity and scene context. Existing approaches either rely on unsupervised priors that often fail to preserve identity or use overly restrictive supervision that prevents meaningful intrinsic variations. Our method relies on: (i) a relaxed training objective that allows the model to change both intrinsic and extrinsic attributes conditioned on an identity reference image, a textual prompt describing the target intrinsic attributes, and a background image and object mask defining the extrinsic context. At inference, we restrict extrinsic changes by reusing the original background and object mask, thereby ensuring that only the desired intrinsic attributes are altered; (ii) Visual Named Entities (VNEs) - fine-grained visual identity categories (e.g., ''Porsche 911 Carrera'') that group objects sharing identity-defining features while allowing variation in intrinsic attributes. We use a vision-language model to automatically extract VNE labels and intrinsic attribute descriptions from a large public image dataset, enabling scalable, identity-preserving supervision. Alterbute outperforms existing methods on identity-preserving object intrinsic attribute editing."
  },
  {
    "date": "2026-01-15",
    "title": "MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching",
    "authors": "Changle Qu, Sunhao Dai, Hengyi Cai, Jun Xu, Shuaiqiang Wang, Dawei Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10712v1",
    "source": "arXiv",
    "abstract": "Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios. To address this, we propose MatchTIR, a framework that introduces fine-grained supervision via bipartite matching-based turn-level reward assignment and dual-level advantage estimation. Specifically, we formulate credit assignment as a bipartite matching problem between predicted and ground-truth traces, utilizing two assignment strategies to derive dense turn-level rewards. Furthermore, to balance local step precision with global task success, we introduce a dual-level advantage estimation scheme that integrates turn-level and trajectory-level signals, assigning distinct advantage values to individual interaction turns. Extensive experiments on three benchmarks demonstrate the superiority of MatchTIR. Notably, our 4B model surpasses the majority of 8B competitors, particularly in long-horizon and multi-turn tasks. Our codes are available at https://github.com/quchangle1/MatchTIR."
  },
  {
    "date": "2026-01-15",
    "title": "Scalable Spin Squeezing in Power-Law Interacting XXZ Models with Disorder",
    "authors": "Samuel E. Begg, Bishal K. Ghosh, Chong Zu, Chuanwei Zhang, Michael Kolodrubetz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10703v1",
    "source": "arXiv",
    "abstract": "While spin squeezing has been traditionally considered in all-to-all interacting models, recent works have shown that spin squeezing can occur in systems with power-law interactions, leading to direct testing in Rydberg atoms, trapped ions, ultracold atoms and nitrogen vacancy (NV) centers in diamond. For the latter, Wu. et al. Nature 646 (2025) demonstrated that spin squeezing is heavily affected by positional disorder, reducing any capacity for a practical squeezing advantage, which requires scalability with the system size. In this Letter we explore the robustness of spin-squeezing in two-dimensional lattices with a fraction of unoccupied lattice sites. Using semi-classical modeling, we demonstrate the existence of scalable squeezing in power-law interacting XXZ models up to a disorder threshold, above which squeezing is not scalable. We produce a phase diagram for scalable squeezing, and explain its absence in the aforementioned NV experiment. Our work illustrates the maximum disorder allowed for realizing scalable spin squeezing in a host of quantum simulators, highlights a regime with substantial tolerance to disorder, and identifies controlled defect creation as a promising route for scalable squeezing in solid-state systems."
  },
  {
    "date": "2026-01-15",
    "title": "Grounding Agent Memory in Contextual Intent",
    "authors": "Ruozhen Yang, Yucheng Jiang, Yueqi Jiang, Priyanka Kargupta, Yunyi Zhang, Jiawei Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10702v1",
    "source": "arXiv",
    "abstract": "Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose STITCH (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step's intent. Contextual intent provides compact signals that disambiguate repeated mentions and reduce interference: (1) the current latent goal defining a thematic segment, (2) the action type, and (3) the salient entity types anchoring which attributes matter. During inference, STITCH filters and prioritizes memory snippets by intent compatibility, suppressing semantically similar but context-incompatible history. For evaluation, we introduce CAME-Bench, a benchmark for context-aware retrieval in realistic, dynamic, goal-oriented trajectories. Across CAME-Bench and LongMemEval, STITCH achieves state-of-the-art performance, outperforming the strongest baseline by 35.6%, with the largest gains as trajectory length increases. Our analysis shows that intent indexing substantially reduces retrieval noise, supporting intent-aware memory for robust long-horizon reasoning."
  },
  {
    "date": "2026-01-15",
    "title": "Late-time acceleration without a vacuum term in ${f(R,L_m)}$ gravity: scaling deSitter dynamics and parameter constraints",
    "authors": "Luciano Navarro-Coydán, J. Alberto Vázquez, Israel Quiros, Ricardo García-Salcedo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10699v1",
    "source": "arXiv",
    "abstract": "We investigate late-time cosmic acceleration in $f(R,L_m)$ gravity driven by nonlinear matter contributions, focusing on the class $f(R,L_m)=R/2+c_1 L_m+c_n L_m^{n}+c_0$ with the explicit choice $L_m=ρ_m$ and an uncoupled radiation sector. We analyze two realizations: (i) Case A: $f(R,L_m)=R/2+βρ_m^{n}+γ$, where $γ$ acts as a vacuum term, and (ii) Case B: $f(R,L_m)=R/2+βρ_m+γρ_m^{n}$, where the nonlinear sector can mimic dark energy without an explicit cosmological constant. For each case, we construct a bounded autonomous system, classify all critical points and their stability, and compute cosmographic diagnostics. The phase-space analysis shows that Case A reproduces the standard radiation$\\to$matter$\\to$de~Sitter sequence only for $n\\gtrsim 4/5$, with acceleration essentially enforced by the vacuum term. In contrast, Case~B admits a qualitatively distinct and phenomenologically appealing branch: for $0<n<1/2$ the system possesses a physical \\emph{scaling} de~Sitter future attractor inside the bounded simplex, yielding radiation$\\to$matter$\\to$acceleration with $q=-1$ and $ω_{\\rm eff}=-1$ and without introducing $c_0$. We confront both models with background data (CC, Union3, DESI BAO, plus a BBN prior on $Ω_b h^2$) using nested sampling and perform model comparison via Bayesian evidence and AIC/BIC. The full data combination constrains $n=1.08\\pm0.05$ in Case A and $n=0.05\\pm0.10$ in Case B (68\\% CL), the latter lying within the accelerating window while remaining statistically consistent with $Λ$CDM kinematics at the background level. We also record minimal consistency conditions for stability (tensor no-ghost and luminal propagation) and motivate a dedicated perturbation-level analysis as the next step to test growth and lensing observables."
  },
  {
    "date": "2026-01-15",
    "title": "The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load",
    "authors": "Han Jiang, Yao Xiao, Rachel Hurley, Shichao Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10696v1",
    "source": "arXiv",
    "abstract": "Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase. Difference-in-differences analyses revealed no overall performance advantage of GenAI across participants; however, subgroup analyses showed that GenAI significantly improved design performance for novice designers. In contrast, general creative self-efficacy declined for students using GenAI. Cognitive load did not differ significantly between conditions, though prompt usage patterns showed that iterative idea generation and visual feedback prompts were linked to greater reductions in cognitive load. These findings suggest that GenAI effectiveness depends on users' prior expertise and interaction strategies through prompting."
  },
  {
    "date": "2026-01-15",
    "title": "Increasing the opening speed of the plasma opening switch on an direct action accelerator with an inductive energy storage device",
    "authors": "D. V. Vinnikov, O. M. Ozerov, V. V. Katrechko, V. I. Tkachov, O. V. Manuilenko, I. N. Onishchenko",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10694v1",
    "source": "arXiv",
    "abstract": "To increase the voltage multiplication factor in a small-sized direct-acting electron accelerator DIN-2K with an inductive energy storage and a plasma opening switch, it is necessary to ensure an increase in the rate of change of the current and its amplitude during the POS opening for the purpose of obtaining an explosive electron emission with the formation of an electron beam and a virtual cathode. However, the opening process depends on many electrical parameters of the plant, and it re-quires determining their joint and individual effect on its dynamics. The purpose of this research is to study and determine the effects of electrical parameters, including those of the discharge voltages of the entire electrical circuit of the accelerator on the dynamics of the plasma opening switch, in particular opening speed, current amplitudes, and opening time, as well as to give recommendations on optimizing the operation of accelerators of this type and highlight possible ways to increase the voltage multiplication factor. Methodology. A method for determining the induced voltage according to experimental current oscillograms has been proposed. The methodology was verified by the coincidence of its data with the results of measurements by a capacitive voltage divider with the data spread of less than 20%. Scientific novelty. The rates of change in the current at the plasma switch opening stage were determined depending on the main electrical parameters of the DIN-2K accelerator. The diagnostics of the voltage induced during the POS opening were provided using no capacitive voltage divider in the internal volume of the accelerator, which enabled the removal of some diagnostic tools from the working volume of the chamber. Practical significance."
  },
  {
    "date": "2026-01-15",
    "title": "Measuring Affinity between Attention-Head Weight Subspaces via the Projection Kernel",
    "authors": "Hiroaki Yamagiwa, Yusuke Takase, Hidetoshi Shimodaira",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10266v1",
    "source": "arXiv",
    "abstract": "Understanding relationships between attention heads is essential for interpreting the internal structure of Transformers, yet existing metrics do not capture this structure well. We focus on the subspaces spanned by attention-head weight matrices and quantify head-to-head relationships using the Projection Kernel (PK), a principal-angle-based measure of subspace similarity. Experiments show that PK reproduces known head-to-head interactions on the IOI task more clearly than prior metrics such as the Composition Score. We further introduce a framework to quantify the informativeness of PK distributions by comparing them with a reference distribution derived from random orthogonal subspaces. As an application, we analyze a directed graph constructed from PK and show that, in GPT2-small, L4H7 acts as a hub by functioning as an identity head."
  },
  {
    "date": "2026-01-15",
    "title": "Combined analysis of the singly-Cabbibo-suppressed decays of $D^{0} \\to VP$",
    "authors": "Jun Wang, Qiang Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10437v1",
    "source": "arXiv",
    "abstract": "We investigate six singly Cabibbo-suppressed decay channels in $D^0\\to VP$ ( $V$ and $P$ stand for the ground state vector and pseudoscalar mesons, respectively), i.e. $D^{0}\\to ρ^{+}π^{-}$, $ρ^{-}π^{+}$, $K^{*+}K^{-}$, $K^{*-}K^{+}$, $K^{*0}\\bar{K}^{0}$, and $\\bar{K}^{*0}K^{0}$. These decay channels share the similar transition mechanisms involving only the direct emission (DE) and internal conversion (IC) processes. We show that a combined analysis of these channels can explicitly highlight the role played by the IC processes which contribute to the amplitudes at the same order of magnitude as the DE processes."
  },
  {
    "date": "2026-01-15",
    "title": "The Spatial Blindspot of Vision-Language Models",
    "authors": "Nahid Alam, Leema Krishna Murali, Siddhant Bharadwaj, Patrick Liu, Timothy Chung, Drishti Sharma, Akshata A, Kranthi Kiran, Wesley Tam, Bala Krishna S Vegesna",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09954v1",
    "source": "arXiv",
    "abstract": "Vision-language models (VLMs) have advanced rapidly, but their ability to capture spatial relationships remains a blindspot. Current VLMs are typically built with contrastive language-image pretraining (CLIP) style image encoders. The training recipe often flattens images into 1D patch sequences, discarding the 2D structure necessary for spatial reasoning. We argue that this lack of spatial awareness is a missing dimension in VLM design and a bottleneck for applications requiring spatial grounding, such as robotics and embodied AI. To address this, we investigate (i) image encoders trained with alternative objectives and (ii) 2D positional encodings. Our experiments show that these architectural choices can lead to improved spatial reasoning on several benchmarks."
  },
  {
    "date": "2026-01-15",
    "title": "Algebraic Properties of PAC Codes",
    "authors": "Vlad-Florin Dragoi, Mohammad Rowshan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10262v1",
    "source": "arXiv",
    "abstract": "We analyze polarization-adjusted convolutional codes using the algebraic representation of polar and Reed-Muller codes. We define a large class of codes, called generalized polynomial polar codes which include PAC codes and Reverse PAC codes. We derive structural properties of generalized polynomial polar codes, such as duality, minimum distance. We also deduce some structural limits in terms of number of minimum weight codewords, and dimension of monomial sub-code."
  },
  {
    "date": "2026-01-15",
    "title": "UEOF: A Benchmark Dataset for Underwater Event-Based Optical Flow",
    "authors": "Nick Truong, Pritam P. Karmokar, William J. Beksi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10054v1",
    "source": "arXiv",
    "abstract": "Underwater imaging is fundamentally challenging due to wavelength-dependent light attenuation, strong scattering from suspended particles, turbidity-induced blur, and non-uniform illumination. These effects impair standard cameras and make ground-truth motion nearly impossible to obtain. On the other hand, event cameras offer microsecond resolution and high dynamic range. Nonetheless, progress on investigating event cameras for underwater environments has been limited due to the lack of datasets that pair realistic underwater optics with accurate optical flow. To address this problem, we introduce the first synthetic underwater benchmark dataset for event-based optical flow derived from physically-based ray-traced RGBD sequences. Using a modern video-to-event pipeline applied to rendered underwater videos, we produce realistic event data streams with dense ground-truth flow, depth, and camera motion. Moreover, we benchmark state-of-the-art learning-based and model-based optical flow prediction methods to understand how underwater light transport affects event formation and motion estimation accuracy. Our dataset establishes a new baseline for future development and evaluation of underwater event-based perception algorithms. The source code and dataset for this project are publicly available at https://robotic-vision-lab.github.io/ueof."
  },
  {
    "date": "2026-01-15",
    "title": "Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure",
    "authors": "Syed Naveed Mahmood, Md. Rezaur Rahman Bhuiyan, Tasfia Zaman, Jareen Tasneem Khondaker, Md. Sameer Sakib, Nazia Tasnim, Farig Sadeque",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10566v1",
    "source": "arXiv",
    "abstract": "Selective knowledge erasure from LLMs is critical for GDPR compliance and model safety, yet current unlearning methods conflate behavioral suppression with true knowledge removal, allowing latent capabilities to persist beneath surface-level refusals. In this work, we address this challenge by introducing Knowledge Immunization Framework (KIF), a representation-aware architecture that distinguishes genuine erasure from obfuscation by targeting internal activation signatures rather than surface outputs. Our approach combines dynamic suppression of subject-specific representations with parameter-efficient adaptation, enabling durable unlearning without full model retraining. KIF achieves near-oracle erasure (FQ approx 0.99 vs. 1.00) while preserving utility at oracle levels (MU = 0.62), effectively breaking the stability-erasure tradeoff that has constrained all prior work. We evaluate both standard foundation models (Llama and Mistral) and reasoning-prior models (Qwen and DeepSeek) across 3B to 14B parameters. Our observation shows that standard models exhibit scale-independent true erasure (<3% utility drift), while reasoning-prior models reveal fundamental architectural divergence. Our comprehensive dual-metric evaluation protocol, combining surface-level leakage with latent trace persistence, operationalizes the obfuscation - erasure distinction and enables the first systematic diagnosis of mechanism-level forgetting behavior across model families and scales."
  },
  {
    "date": "2026-01-15",
    "title": "Shifted bilinear sums of Salié sums and the distribution of modular square roots of shifted primes",
    "authors": "Igor E. Shparlinski, Yixiu Xiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10113v1",
    "source": "arXiv",
    "abstract": "We establish various upper bounds on Type-I and Type-II shifted bilinear sums with Salié sums modulo a large prime $q$. We use these bounds to study, for fixed integers $a,b\\not \\equiv 0 \\bmod q$, the distribution ofsolutions to the congruence $x^2 \\equiv ap+b \\bmod q$, over primes $p\\le P$. This is similar to the recently studied case of $b = 0$, however the case $b\\not \\equiv 0 \\bmod q$ exhibits some new difficulties."
  },
  {
    "date": "2026-01-15",
    "title": "On Quaternionic Fock Spaces: Kernel-induced Integral Operators, Berezin Transforms and Toeplitz Operators",
    "authors": "Zhaopeng Lin, Yufeng Lu, Chao Zu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10162v1",
    "source": "arXiv",
    "abstract": "In this paper, we study quaternionic Fock spaces and develop an operator-theoretic framework centered around kernel-induced integral operators, Berezin transforms and Toeplitz operators. More precisely, the following results are obtained: (i) Global quaternionic Fock structure. We introduce a global Gaussian $L^p$--norm for slice functions on $\\mathbb H$ and prove that the resulting global quaternionic Fock space $F_α^p$ coincides with the slice-defined Fock space $\\mathfrak F_α^p$, with equivalent norms. In particular, $F_α^2$ becomes a right quaternionic reproducing kernel Hilbert space with an explicit reproducing kernel, yielding a slice-independent Fock projection onto $F_α^2$. (ii) Kernel-induced integral operators and Fock--Carleson measures. We investigate kernel-induced integral operators and characterize quaternionic Fock--Carleson measures. These embedding theorems provide the measure-theoretic basis that underlies boundedness and compactness criteria for operators on quaternionic Fock spaces. (iii)Berezin transforms and Toeplitz operators. We define the Berezin transform for slice functions and prove its fundamental properties, including semigroup behavior and fixed-point features. Building on the slice-independent projection and the slice product, we introduce Toeplitz operators with slice-function symbols and with measure symbols, and develop their basic algebraic properties. We then obtain complete boundedness and compactness characterizations for Toeplitz operators with two natural symbol classes: positive measures and slice $\\mathrm{BMO}^1$ symbols, expressed in terms of Berezin-type transforms and slice/symmetric averaging quantities."
  },
  {
    "date": "2026-01-15",
    "title": "Fano threefolds of genus 12 with large automorphism group in positive and mixed characteristic",
    "authors": "Tetsushi Ito, Akihiro Kanemitsu, Teppei Takamatsu, Yuuji Tanaka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10106v1",
    "source": "arXiv",
    "abstract": "We study prime Fano threefolds of genus 12 ($V_{22}$-varieties) with positive-dimensional automorphism groups in positive and mixed characteristic. We classify such varieties over any perfect field. In particular, we prove that $V_{22}$-varieties of Mukai-Umemura type over $k$ exist if and only if $\\mathrm{char}\\ k \\neq 2$, $5$. We also prove the same result for $\\mathbb{G}_a$-type. As arithmetic applications, we show that the Shafarevich conjecture holds for $V_{22}$-varieties of Mukai-Umemura type and of $\\mathbb{G}_m$-type, while it fails for $V_{22}$-varieties of $\\mathbb{G}_a$-type. Moreover, we prove that there exists $V_{22}$-varieties over $\\mathbb{Z}$, whereas there do not exist $V_{22}$-varieties over $\\mathbb{Z}$ whose generic fiber has a positive-dimensional automorphism group."
  },
  {
    "date": "2026-01-15",
    "title": "Systemically Designed Degrees for Real-World Challenges: A case study on Physics curriculum design at Loughborough University",
    "authors": "M. J. Everitt, M. T. Greenaway, S. L. Bugby, S. N. A. Duffus",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10219v1",
    "source": "arXiv",
    "abstract": "We present a ground-up redesign of the undergraduate physics degree at Loughborough University, driven by the principle of authenticity in academic and industrial practice. Departing from conventional incremental reforms, we adopt a systems-engineering approach to programme-level curriculum design, treating the degree as an integrated system with verifiable performance. This methodology aligns stakeholder-derived requirements with vertically-integrated threads in theory, computation, laboratory practice, and professional skills. We demonstrate that this approach enables students to achieve levels of disciplinary and cross-disciplinary competence beyond those typically expected at undergraduate level. Outcomes are supported by graduate destinations, enhanced student performance, and positive external evaluations, including national accreditation. Our results suggest that rigorous, system-level curriculum design can yield transformational gains in both capability and confidence."
  },
  {
    "date": "2026-01-15",
    "title": "On Necessary and Sufficient Conditions for Fixed Point Convergence: A Contractive Iteration Principle",
    "authors": "Vasil Zhelinski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10669v1",
    "source": "arXiv",
    "abstract": "While numerous extensions of Banach's fixed point theorem typically offer only sufficient conditions for the existence and uniqueness of a fixed point and the convergence of iterative sequences, this study introduces a generalization grounded in the iterative contraction principle in complete metric spaces. This generalization establishes both the necessary and sufficient conditions for the existence of a unique fixed point to which all iterative sequences converge, along with an accurate error estimate. Furthermore, we present and prove an additional theorem that characterizes the convergence of all iterative sequences to fixed points that may not be unique. Several examples are provided to illustrate the practical application of these results, including a case where the traditional and well-known generalizations of Banach's theorem, such as those by Banach, Kannan, Chatterjea, Hardy-Rogers, Meir-Keeler, and Guseman, are inapplicable."
  },
  {
    "date": "2026-01-15",
    "title": "Detecting Winning Arguments with Large Language Models and Persuasion Strategies",
    "authors": "Tiziano Labruna, Arkadiusz Modzelewski, Giorgio Satta, Giovanni Da San Martino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10660v1",
    "source": "arXiv",
    "abstract": "Detecting persuasion in argumentative text is a challenging task with important implications for understanding human communication. This work investigates the role of persuasion strategies - such as Attack on reputation, Distraction, and Manipulative wording - in determining the persuasiveness of a text. We conduct experiments on three annotated argument datasets: Winning Arguments (built from the Change My View subreddit), Anthropic/Persuasion, and Persuasion for Good. Our approach leverages large language models (LLMs) with a Multi-Strategy Persuasion Scoring approach that guides reasoning over six persuasion strategies. Results show that strategy-guided reasoning improves the prediction of persuasiveness. To better understand the influence of content, we organize the Winning Argument dataset into broad discussion topics and analyze performance across them. We publicly release this topic-annotated version of the dataset to facilitate future research. Overall, our methodology demonstrates the value of structured, strategy-aware prompting for enhancing interpretability and robustness in argument quality assessment."
  },
  {
    "date": "2026-01-15",
    "title": "Counterdiabatic driving for random-gap Landau-Zener transitions",
    "authors": "Georgios Theologou, Mikkel F. Andersen, Sandro Wimberger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10659v1",
    "source": "arXiv",
    "abstract": "The Landau--Zener (LZ) model describes a two-level quantum system that undergoes an avoided crossing. In the adiabatic limit, the transition probability vanishes. An auxiliary control field $H_\\text{CD}$ can be reverse-engineered so that the full Hamiltonian $H_0 + H_\\text{CD}$ reproduces adiabaticity for all parameter values. Our aim is to construct a single control field $H_1$ that drives an ensemble of LZ-type Hamiltonians with a distribution of energy gaps. $H_1$ works best statistically, minimizing the average transition probability. We restrict our attention to a special class of $H_1$ controls, motivated by $H_\\text{CD}$. We found a systematic trade-off between instantaneous adiabaticity and the final transition probability. Certain limiting cases with a linear sweep can be treated analytically; one of them being the LZ system with Dirac $δ(t)$ function. Comprehensive and systematic numerical simulations support and extend the analytic results."
  },
  {
    "date": "2026-01-15",
    "title": "Influential Training Data Retrieval for Explaining Verbalized Confidence of LLMs",
    "authors": "Yuxi Xia, Loris Schoenegger, Benjamin Roth",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10645v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) can increase users' perceived trust by verbalizing confidence in their outputs. However, prior work has shown that LLMs are often overconfident, making their stated confidence unreliable since it does not consistently align with factual accuracy. To better understand the sources of this verbalized confidence, we introduce TracVC (\\textbf{Trac}ing \\textbf{V}erbalized \\textbf{C}onfidence), a method that builds on information retrieval and influence estimation to trace generated confidence expressions back to the training data. We evaluate TracVC on OLMo and Llama models in a question answering setting, proposing a new metric, content groundness, which measures the extent to which an LLM grounds its confidence in content-related training examples (relevant to the question and answer) versus in generic examples of confidence verbalization. Our analysis reveals that OLMo2-13B is frequently influenced by confidence-related data that is lexically unrelated to the query, suggesting that it may mimic superficial linguistic expressions of certainty rather than rely on genuine content grounding. These findings point to a fundamental limitation in current training regimes: LLMs may learn how to sound confident without learning when confidence is justified. Our analysis provides a foundation for improving LLMs' trustworthiness in expressing more reliable confidence."
  },
  {
    "date": "2026-01-15",
    "title": "Cosmoglobe DR2. VI. Disentangling hot and cold thermal dust emission with Planck HFI",
    "authors": "R. M. Sullivan, E. Gjerløw, M. Galloway, D. J. Watts, R. Aurvik, A. Basyrov, L. A. Bianchi, A. Bonato, M. Brilenkov, H. K. Eriksen, U. Fuskeland, K. A. Glasscock, L. T. Hergt, D. Herman, J. G. S. Lunde, A. I. Silva Martins, M. San, D. Sponseller, N. -O. Stutzer, H. Thommesen, V. Vikenes, I. K. Wehus, L. Zapelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10640v1",
    "source": "arXiv",
    "abstract": "We present a four-component high-resolution model of thermal dust emission for microwave and sub-mm frequencies derived from Planck HFI, WHAM and Gaia. The resulting high-resolution model derived here forms the basis for the thermal dust model employed in the Cosmoglobe DR2 reanalysis of COBE-DIRBE. The four dust components are called ``cold dust'', ``hot dust'', ``nearby dust'', and ``Ha correlated dust'', respectively, and trace different physical environments. The spatial distributions of the nearby dust and Ha dust components are defined by the Edenhofer et al. Gaia 3D extinction model and the WHAM survey, respectively, while the hot and cold dust components are fit freely pixel-by-pixel to the Planck HFI data. We use a global parameter grid search coupled to an amplitude map Gibbs sampler to fit this model to Planck HFI data. In agreement with the companion low-resolution analysis, we find that the hot dust component is strongly correlated with the FIRAS Cii map, while the cold dust component is strongly correlated with the HI4PI Hi map. Despite its fewer degrees of freedom per pixel compared to the Planck 2015 legacy dust model, we find that this new model performs competitively in terms of overall residuals, capturing over 98% of the full-sky dust variance for all channels. When fitting a spatially varying 3-parameter MBB model to the new dust model with isotropic SEDs, we find very similar spatial distributions to those of the official Planck analysis, and this new model thus represents an economical decomposition of previously published spatially varying spectral parameter maps. We conclude that this new model represents both a statistically more efficient summary of thermal dust in the microwave and far-infrared regimes and a physically more realistic decomposition of the sky compared to the traditional 3-parameter MBB model. (abridged)"
  },
  {
    "date": "2026-01-15",
    "title": "STEM: Scaling Transformers with Embedding Modules",
    "authors": "Ranajoy Sadhukhan, Sheng Cao, Harry Dong, Changsheng Zhao, Attiano Purpura-Pontoniere, Yuandong Tian, Zechun Liu, Beidi Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10639v1",
    "source": "arXiv",
    "abstract": "Fine-grained sparsity promises higher parametric capacity without proportional per-token compute, but often suffers from training instability, load balancing, and communication overhead. We introduce STEM (Scaling Transformers with Embedding Modules), a static, token-indexed approach that replaces the FFN up-projection with a layer-local embedding lookup while keeping the gate and down-projection dense. This removes runtime routing, enables CPU offload with asynchronous prefetch, and decouples capacity from both per-token FLOPs and cross-device communication. Empirically, STEM trains stably despite extreme sparsity. It improves downstream performance over dense baselines while reducing per-token FLOPs and parameter accesses (eliminating roughly one-third of FFN parameters). STEM learns embedding spaces with large angular spread which enhances its knowledge storage capacity. More interestingly, this enhanced knowledge capacity comes with better interpretability. The token-indexed nature of STEM embeddings allows simple ways to perform knowledge editing and knowledge injection in an interpretable manner without any intervention in the input text or additional computation. In addition, STEM strengthens long-context performance: as sequence length grows, more distinct parameters are activated, yielding practical test-time capacity scaling. Across 350M and 1B model scales, STEM delivers up to ~3--4% accuracy improvements overall, with notable gains on knowledge and reasoning-heavy benchmarks (ARC-Challenge, OpenBookQA, GSM8K, MMLU). Overall, STEM is an effective way of scaling parametric memory while providing better interpretability, better training stability and improved efficiency."
  },
  {
    "date": "2026-01-15",
    "title": "On subradically sifted sums related to Alladi's higher order duality between prime factors",
    "authors": "Yazan Alamoudi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10636v1",
    "source": "arXiv",
    "abstract": "In this paper, I utilize a variant of the Selberg--Delange method to find quantitative estimates of the sums \\[M_{k,ω}(x,y)=\\sum_{\\substack{p_{1}(n)> y\\\\ n\\leq x} } μ(n) {ω(n)-1\\choose k-1},\\] where $y$ can grow with $x$ but we must have $y\\leq Y_0\\exp(\\mathscr{p}\\frac{\\log x}{(\\log\\log (x+1))^{1+ε}})$ with $Y_0,\\mathscr{p},ε>0$. Moreover, I give preliminary upper bounds for the general range $1.9\\leq y\\leq x^{\\frac{1}{k}}$. In addition, I formalize the notions of subradical and radical dominance and discuss their relevance to the analytic approach of the study of arithmetic functions. Lastly, I give a fascinating formula related to the derivatives of the gamma function and the Hankel contour, which should be relevant for those employing the Selberg--Delange method to obtain higher-order terms."
  },
  {
    "date": "2026-01-15",
    "title": "Classification Imbalance as Transfer Learning",
    "authors": "Eric Xia, Jason M. Klusowski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10630v1",
    "source": "arXiv",
    "abstract": "Classification imbalance arises when one class is much rarer than the other. We frame this setting as transfer learning under label (prior) shift between an imbalanced source distribution induced by the observed data and a balanced target distribution under which performance is evaluated. Within this framework, we study a family of oversampling procedures that augment the training data by generating synthetic samples from an estimated minority-class distribution to roughly balance the classes, among which the celebrated SMOTE algorithm is a canonical example. We show that the excess risk decomposes into the rate achievable under balanced training (as if the data had been drawn from the balanced target distribution) and an additional term, the cost of transfer, which quantifies the discrepancy between the estimated and true minority-class distributions. In particular, we show that the cost of transfer for SMOTE dominates that of bootstrapping (random oversampling) in moderately high dimensions, suggesting that we should expect bootstrapping to have better performance than SMOTE in general. We corroborate these findings with experimental evidence. More broadly, our results provide guidance for choosing among augmentation strategies for imbalanced classification."
  },
  {
    "date": "2026-01-15",
    "title": "Basis-Spline Assisted Coded Computing: Strategies and Error Bounds",
    "authors": "Rimpi Borah, J. Harshan, V. Lalitha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10616v1",
    "source": "arXiv",
    "abstract": "Coded computing has become a key framework for reliable distributed computation over decentralized networks, effectively mitigating the impact of stragglers. Although there exists a wide range of coded computing methods to handle both polynomial and non-polynomial functions, computing methods for the latter class have received traction due its inherent challenges in reconstructing non-polynomial functions using a finite number of evaluations. Among them, the state-of-the-art method is Berrut Approximated coded computing, wherein Berrut interpolants, are used for approximating the non-polynomial function. However, since Berrut interpolants have global support characteristics, such methods are known to offer degraded accuracy when the number of stragglers is large. To address this challenge, we propose a coded computing framework based on cubic B-spline interpolation. In our approach, server-side function evaluations are reconstructed at the master node using B-splines, exploiting their local support and smoothness properties to enhance stability and accuracy. We provide a systematic methodology for integrating B-spline interpolation into coded computing and derive theoretical bounds on approximation error in terms of the number of servers and stragglers. Comparative analysis demonstrates that our framework significantly outperforms Berrut-based methods for various non-polynomial functions."
  },
  {
    "date": "2026-01-15",
    "title": "Malcev classification for the variety of left-symmetric algebras",
    "authors": "A. Ryskeldin, B. Sartayev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10613v1",
    "source": "arXiv",
    "abstract": "In this paper, we study three classes of subvarieties inside the variety of left-symmetric algebras. We show that these subvarieties are naturally related to some well-known varieties, such as alternative, assosymmetric and Zinbiel algebras. For certain subvarieties of the varieties of alternative and assosymmetric algebras, we explicitly construct bases of the corresponding free algebras. We then define the commutator and anti-commutator operations on these algebras and derive a number of identities satisfied by these operations in all degrees up to $4$."
  },
  {
    "date": "2026-01-15",
    "title": "Fundamental Limits of Multi-User Distributed Computing of Linearly Separable Functions",
    "authors": "K. K. Krishnan Namboodiri, Elizabath Peter, Derya Malak, Petros Elia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10603v1",
    "source": "arXiv",
    "abstract": "This work establishes the fundamental limits of the classical problem of multi-user distributed computing of linearly separable functions. In particular, we consider a distributed computing setting involving $L$ users, each requesting a linearly separable function over $K$ basis subfunctions from a master node, who is assisted by $N$ distributed servers. At the core of this problem lies a fundamental tradeoff between communication and computation: each server can compute up to $M$ subfunctions, and each server can communicate linear combinations of their locally computed subfunctions outputs to at most $Δ$ users. The objective is to design a distributed computing scheme that reduces the communication cost (total amount of data from servers to users), and towards this, for any given $K$, $L$, $M$, and $Δ$, we propose a distributed computing scheme that jointly designs the task assignment and transmissions, and shows that the scheme achieves optimal performance in the real field under various conditions using a novel converse. We also characterize the performance of the scheme in the finite field using another converse based on counting arguments."
  },
  {
    "date": "2026-01-15",
    "title": "Institutional AI: A Governance Framework for Distributional AGI Safety",
    "authors": "Federico Pierucci, Marcello Galisai, Marcantonio Syrnikov Bracale, Matteo Prandi, Piercosma Bisconti, Francesco Giarrusso, Olga Sorokoletova, Vincenzo Suriani, Daniele Nardi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10599v1",
    "source": "arXiv",
    "abstract": "As LLM-based systems increasingly operate as agents embedded within human social and technical systems, alignment can no longer be treated as a property of an isolated model, but must be understood in relation to the environments in which these agents act. Even the most sophisticated methods of alignment, such as Reinforcement Learning through Human Feedback (RHLF) or through AI Feedback (RLAIF) cannot ensure control once internal goal structures diverge from developer intent. We identify three structural problems that emerge from core properties of AI models: (1) behavioral goal-independence, where models develop internal objectives and misgeneralize goals; (2) instrumental override of natural-language constraints, where models regard safety principles as non-binding while pursuing latent objectives, leveraging deception and manipulation; and (3) agentic alignment drift, where individually aligned agents converge to collusive equilibria through interaction dynamics invisible to single-agent audits. The solution this paper advances is Institutional AI: a system-level approach that treats alignment as a question of effective governance of AI agent collectives. We argue for a governance-graph that details how to constrain agents via runtime monitoring, incentive shaping through prizes and sanctions, explicit norms and enforcement roles. This institutional turn reframes safety from software engineering to a mechanism design problem, where the primary goal of alignment is shifting the payoff landscape of AI agent collectives."
  },
  {
    "date": "2026-01-15",
    "title": "Search for sub-GeV dark particles in $η\\toπ^0+\\rm{invisible}$ decay",
    "authors": "BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. B. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, T. T. Chang, G. R. Che, Y. Z. Che, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Z. K. Chen, J. C. Cheng, L. N. Cheng, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. Cottee-Meldrum, H. L. Dai, J. P. Dai, X. C. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denisenko, M. Destefanis, F. De Mori, X. X. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, X. L. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, L. Feng, Q. X. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, Y. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, Z. Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. D. Gu, M. H. Gu, C. Y. Guan, A. Q. Guo, J. N. Guo, L. B. Guo, M. J. Guo, R. P. Guo, X. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, C. Z. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, O. B. Kolcu, B. Kopf, L. Kröger, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, C. K. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. L. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, K. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, Shanshan Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. K. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. H. Li, Z. J. Li, Z. X. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, W. M. Liu, W. T. Liu, X. Liu, X. K. Liu, X. L. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, Z. Y. Liu, X. C. Lou, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. L. Ma, Heng Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, H. X. Mao, Y. J. Mao, Z. P. Mao, S. Marcello, A. Marshall, F. M. Melendi, Y. H. Meng, Z. X. Meng, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, H. Neuwirth, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, C. Normand, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, X. J. Peng, Y. Y. Peng, K. Peters, K. Petridis, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, J. Rademacker, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, M. H. Song, T. Z. Song, W. M. Song, Y. X. Song, Zirong Song, S. Sosio, S. Spataro, S. Stansilaus, F. Stieler, S. S Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, R. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, Shun Wang, T. Wang, T. J. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. L. Wang, X. N. Wang, Xin Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. J. Wang, Y. L. Wang, Y. N. Wang, Y. N. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, Ziyi Wang, D. Wei, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, U. Wiedner, G. Wilkinson, M. Wolke, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, Y. J. Wu, Z. Wu, L. Xia, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, Y. Yang, Y. H. Yang, Y. Q. Yang, Y. Z. Yang, Z. P. Yao, M. Ye, M. H. Ye, Z. J. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, L. W. Yu, T. Yu, X. D. Yu, Y. C. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, M. K. Yuan, S. H. Yuan, Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Yujie Zeng, Y. J. Zeng, Y. C. Zhai, Y. H. Zhan, Shunan Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. P. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Q. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. X. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10597v1",
    "source": "arXiv",
    "abstract": "Using (10087$\\pm$44)$\\times$10$^{6}$ $J/ψ$ events collected with the BESIII detector at the BEPCII collider at the center-of-mass energy of $\\sqrt{s}=3.097~\\rm{GeV}$, we report the first search for $η\\toπ^0S\\toπ^0χ\\barχ$ with $S$ denotes an on-shell dark scalar boson and $χ$ an invisible dark matter particle. No significant signals are observed with $S$ mass ranging from 0 to 400 $\\rm{MeV}/c^2$. The upper limits on the branching fractions and the new physics coupling strengths between $S$ and quarks are set to be $(1.8\\sim5.5)\\times10^{-5}$ and $(1.3\\sim3.2)\\times10^{-5}$ at the 90% confidence level, respectively. The constraints on the dark-matter-nucleon scattering cross section is improved by approximately 5 orders of magnitude over previous dark-matter-nucleon scattering experiments, providing unique insights into sub-GeV dark matter."
  },
  {
    "date": "2026-01-15",
    "title": "Improving Database Performance by Application-side Transaction Merging",
    "authors": "Xueyuan Ren, Frank Li, Yang Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10596v1",
    "source": "arXiv",
    "abstract": "This paper explores a new opportunity to improve the performance of transaction processing at the application side by merging structurely similar statements or transactions. Concretely, we re-write transactions to 1) merge similar statements using specific SQL semantics; 2) eliminate redundant reads; and 3) merge contending statements across transactions by pre-computing their aggregated effect. Following this idea, we present the design of TransactionMerger, a middleware to collect and merge transactions across different clients. We further present a static analysis tool to identify the merging opportunity without violating isolation as well as our experience of re-writing transactions in TPC-C and Spree, a popular real-world application. Our evaluation shows that such transaction merging can improve TPC-C throughput by up to 2.65X and Spree throughput by 3.52X."
  },
  {
    "date": "2026-01-15",
    "title": "From aggressive to conservative early stopping in Bayesian group sequential designs",
    "authors": "Zhangyi He, Feng Yu, Suzie Cro, Laurent Billot",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10590v1",
    "source": "arXiv",
    "abstract": "Group sequential designs (GSDs) are widely used in confirmatory trials to allow interim monitoring while preserving control of the type I error rate. In the frequentist framework, O'Brien-Fleming-type stopping boundaries dominate practice because they impose highly conservative early stopping while allowing more liberal decisions as information accumulates. Bayesian GSDs, in contrast, are most often implemented using fixed posterior probability thresholds applied uniformly at all analyses. While such designs can be calibrated to control the overall type I error rate, they do not penalise early analyses and can therefore lead to substantially more aggressive early stopping. Such behaviour can risk premature conclusions and inflation of treatment effect estimates, raising concerns for confirmatory trials. We introduce two practically implementable refinements that restore conservative early stopping in Bayesian GSDs. The first introduces a two-phase structure for posterior probability thresholds, applying more stringent criteria in the early phase of the trial and relaxing them later to preserve power. The second replaces posterior probability monitoring at interim looks with predictive probability criteria, which naturally account for uncertainty in future data and therefore suppress premature stopping. Both strategies require only one additional tuning parameter and can be efficiently calibrated. In the HYPRESS setting, both approaches achieve higher power than the conventional Bayesian design while producing alpha-spending profiles closely aligned with O'Brien-Fleming-type behaviour at early looks. These refinements provide a principled and tractable way to align Bayesian GSDs with accepted frequentist practice and regulatory expectations, supporting their robust application in confirmatory trials."
  },
  {
    "date": "2026-01-15",
    "title": "Searching for Quantum Effects in the Brain: A Bell-Type Test for Nonclassical Latent Representations in Autoencoders",
    "authors": "I. K. Kominis, C. Xie, S. Li, M. Skotiniotis, G. P. Tsironis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10588v1",
    "source": "arXiv",
    "abstract": "Whether neural information processing is entirely classical or involves quantum-mechanical elements remains an open question. Here we propose a model-agnostic, information-theoretic test of nonclassicality that bypasses microscopic assumptions and instead probes the structure of neural representations themselves. Using autoencoders as a transparent model system, we introduce a Bell-type consistency test in latent space, and ask whether decoding statistics obtained under multiple readout contexts can be jointly explained by a single positive latent-variable distribution. By shifting the search for quantum-like signatures in neural systems from microscopic dynamics to experimentally testable constraints on information processing, this work opens a new route for probing the fundamental physics of neural computation."
  },
  {
    "date": "2026-01-15",
    "title": "Adversarial Evasion Attacks on Computer Vision using SHAP Values",
    "authors": "Frank Mollard, Marcus Becker, Florian Roehrbein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10587v1",
    "source": "arXiv",
    "abstract": "The paper introduces a white-box attack on computer vision models using SHAP values. It demonstrates how adversarial evasion attacks can compromise the performance of deep learning models by reducing output confidence or inducing misclassifications. Such attacks are particularly insidious as they can deceive the perception of an algorithm while eluding human perception due to their imperceptibility to the human eye. The proposed attack leverages SHAP values to quantify the significance of individual inputs to the output at the inference stage. A comparison is drawn between the SHAP attack and the well-known Fast Gradient Sign Method. We find evidence that SHAP attacks are more robust in generating misclassifications particularly in gradient hiding scenarios."
  },
  {
    "date": "2026-01-15",
    "title": "Comparison of viscosity solutions for a class of non-linear PDEs on the space of finite nonnegative measures",
    "authors": "Ibrahim Ekren, Xihao He, Tianxu Lan, Xiaolu Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10586v1",
    "source": "arXiv",
    "abstract": "We establish a comparison principle for viscosity solutions of a class of nonlinear partial differential equations posed on the space of nonnegative finite measures, thereby extending recent results for PDEs defined on the Wasserstein space of probability measures. As an application, we study a controlled branching McKean-Vlasov diffusion and characterize the associated value function as the unique viscosity solution of the corresponding Hamilton-Jacobi-Bellman equation. This yields a PDE-based approach to the optimal control of branching processes."
  },
  {
    "date": "2026-01-15",
    "title": "Canceling Effects of Conjunctions Render Higher Order Mean Motion Resonances Weak",
    "authors": "Elizabeth K Jones, Samuel Hadden, Daniel Tamayo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10585v1",
    "source": "arXiv",
    "abstract": "Mean motion resonances (MMRs) are a key phenomenon in orbital dynamics. The traditional disturbing function expansion in celestial mechanics shows that, at low eccentricities, $p$:$p-q$ MMRs exhibit a clear hierarchy of strengths, scaling as $e^q$, where $q$ is the order of the resonance. This explains why first-order MMRs (e.g., 3:2 and 4:3) are important, while the infinite number of higher order integer ratios are not. However, this relationship derived from a technical perturbation series expansion provides little physical intuition. In this paper, we provide a simple physical explanation of this result for closely spaced orbits. In this limit, interplanetary interactions are negligible except during close encounters at conjunction, where the planets impart a gravitational \"kick\" to each other's mean motion. We show that while first-order MMRs involve a single conjunction before the configuration repeats, higher order MMRs involve multiple conjunctions per cycle, whose effects cancel out more precisely the higher the order of the resonance. Starting from the effects of a single conjunction, we provide an alternate, physically motivated derivation of MMRs' $e^q$ strength scaling."
  },
  {
    "date": "2026-01-15",
    "title": "On Zalcman's and Bieberbach conjectures",
    "authors": "Samuel L. Krushkal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10584v1",
    "source": "arXiv",
    "abstract": "The well-known Zalcman conjecture, which implies the Bieberbach conjecture, states that the coefficients of univalent functions $f(z) = z + \\sum\\limits_2^{\\infty} a_n z^n$ on the unit disk satisfy $|a_n^2 - a_{2n-1}| \\le (n-1)^2$ for all $n > 2$, with equality only for the Koebe function and its rotations. The conjecture was proved by the author for $n \\le 6$ (using geometric arguments related to the Ahlfors-Schwarz lemma) and remains open for $n \\ge 7$. The main theorem of this paper states that these conjectures are equivalent and provides their simultaneous proof for all $n \\ge 3$ combining the indicated geometric arguments with a new author's approach to extremal problems for holomorphic functions based on lifting the rotationally homogeneous coefficient functionals to the Bers fiber space over universal Teichmuller space."
  },
  {
    "date": "2026-01-15",
    "title": "From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA",
    "authors": "Kimia Abedini, Farzad Shami, Gianmaria Silvello",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10581v1",
    "source": "arXiv",
    "abstract": "Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction."
  },
  {
    "date": "2026-01-15",
    "title": "Electro-optic frequency comb Doppler thermometry",
    "authors": "Sean M. Bresler, Erin M. Adkins, Stephen P. Eckel, Tobias K. Herman, David A. Long, Benjamin J. Reschovsky, Daniel S. Barker",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10575v1",
    "source": "arXiv",
    "abstract": "We demonstrate a Doppler thermometer based on direct optical frequency comb spectroscopy of an $^{85}$Rb vapor with a chirped electro-optic frequency comb (EOFC). The direct EOFC Doppler thermometer is accurate to within its approximately 1 K statistical uncertainty. We experimentally compare direct EOFC spectroscopy with conventional Doppler spectroscopy using a single-frequency, step-scanned laser probe. Our results show that direct EOFC spectroscopy mitigates transit-induced optical pumping distortion of the atomic lineshape, which is the dominant systematic temperature shift in alkali atom Doppler thermometry. Optical Bloch equation simulations of conventional and direct EOFC Doppler spectroscopy confirm that EOFC spectroscopy can use higher optical power to reduce statistical noise without optical pumping distortion. Our results indicate that EOFC Doppler thermometry is a promising approach to realizing a primary thermometer with size and measurement rate sufficient for applications including pharmaceutical manufacturing and nuclear waste monitoring."
  },
  {
    "date": "2026-01-15",
    "title": "Kolmogorov Arnold Networks and Multi-Layer Perceptrons: A Paradigm Shift in Neural Modelling",
    "authors": "Aradhya Gaonkar, Nihal Jain, Vignesh Chougule, Nikhil Deshpande, Sneha Varur, Channabasappa Muttal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10563v1",
    "source": "arXiv",
    "abstract": "The research undertakes a comprehensive comparative analysis of Kolmogorov-Arnold Networks (KAN) and Multi-Layer Perceptrons (MLP), highlighting their effectiveness in solving essential computational challenges like nonlinear function approximation, time-series prediction, and multivariate classification. Rooted in Kolmogorov's representation theorem, KANs utilize adaptive spline-based activation functions and grid-based structures, providing a transformative approach compared to traditional neural network frameworks. Utilizing a variety of datasets spanning mathematical function estimation (quadratic and cubic) to practical uses like predicting daily temperatures and categorizing wines, the proposed research thoroughly assesses model performance via accuracy measures like Mean Squared Error (MSE) and computational expense assessed through Floating Point Operations (FLOPs). The results indicate that KANs reliably exceed MLPs in every benchmark, attaining higher predictive accuracy with significantly reduced computational costs. Such an outcome highlights their ability to maintain a balance between computational efficiency and accuracy, rendering them especially beneficial in resource-limited and real-time operational environments. By elucidating the architectural and functional distinctions between KANs and MLPs, the paper provides a systematic framework for selecting the most suitable neural architectures for specific tasks. Furthermore, the proposed study highlights the transformative capabilities of KANs in progressing intelligent systems, influencing their use in situations that require both interpretability and computational efficiency."
  },
  {
    "date": "2026-01-15",
    "title": "SDN-Driven Innovations in MANETs and IoT: A Path to Smarter Networks",
    "authors": "Andrea Piroddi, Riccardo Fonti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10544v1",
    "source": "arXiv",
    "abstract": "Mobile Ad Hoc Networks (MANETs) and Internet of Things (IoT) networks operate in decentralized and dynamic environments, making them ideal for scenarios lacking traditional infrastructure. However, these networks face challenges such as inefficient routing, limited scalability, and security vulnerabilities due to their decentralized nature and resource constraints. This paper explores the integration of Software-Defined Networking (SDN) as a unified solution that leverages its centralized control and network programmability to improve routing, resource management, and security. A mathematical model evaluates the impact of SDN integration on Capital Expenditure (CAPEX), Operational Expenditure (OPEX), and performance metrics. Results demonstrate that SDN-enhanced MANETs and IoT networks offer superior scalability, reduced latency, increased throughput, and lower packet loss, especially in dynamic and large-scale environments. While SDN introduces computational overhead, it significantly enhances routing efficiency, resource optimization, and adaptability. The proposed framework provides a robust and scalable solution, enabling the development of network architectures that efficiently manage growing node densities, dynamic topologies, and high data traffic. This approach ensures resilience, making it well-suited to meet the performance and reliability demands of modern, large-scale applications."
  },
  {
    "date": "2026-01-15",
    "title": "Hybrid Encryption with Certified Deletion in Preprocessing Model",
    "authors": "Kunal Dey, Reihaneh Safavi-Naini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10542v1",
    "source": "arXiv",
    "abstract": "Certified deletion allows Alice to outsource data to Bob and, at a later time, obtain a verifiable guarantee that the file has been irreversibly deleted at her request. The functionality, while impossible using classical information alone, can be achieved using quantum information. Existing approaches, rely on one-time pad (OTP) encryption, or use computational hardness assumptions that may be vulnerable to future advances in classical or quantum computing. In this work, we introduce and formalize hybrid encryption with certified deletion in the preprocessing model (pHE-CD) and propose two constructions. The constructions combine an information-theoretic key encapsulation mechanism (iKEM) with a data encapsulation mechanism that provides certified deletion (DEM-CD) and, respectively, provide {\\em information-theoretic certified deletion}, where both confidentiality and deletion properties are provided against a computationally unbounded adversary; and {\\em everlasting certified deletion}, where confidentiality is computational before deletion, and upon successful verification of the deletion certificate, the message becomes information-theoretically hidden from an adversary that is computationally unbounded. Our pHE-CD schemes provide IND-$q_e$-CPA notion of security and support encryption of arbitrarily long messages. In the second construction, using a computationally secure DEM-CD that is quantum-safe (i.e. constructed using quantum coding and AES), we obtain quantum-safe security with keys that are significantly shorter than the message. Instantiating the proposed framework using quantum enabled kem (qKEM) as the iKEM, is a future work."
  },
  {
    "date": "2026-01-15",
    "title": "Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection",
    "authors": "Frank Bobe, Gregory D. Vetaw, Chase Pavlick, Darshan Bryner, Matthew Cook, Jose Salas-Vernis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10524v1",
    "source": "arXiv",
    "abstract": "The practice of fine-tuning Large Language Models (LLMs) has achieved state-of-the-art performance on specialized tasks, yet diagnosing why these models become brittle and fail to generalize remains a critical open problem. To address this, we introduce and apply a multi-layered diagnostic framework to a cross-architectural study. We fine-tune Llama 3.1 8B, Gemma 2 9B, and Mistral models on a high-stakes phishing detection task and use SHAP analysis and mechanistic interpretability to uncover the root causes of their generalization failures. Our investigation reveals three critical findings: (1) Generalization is driven by a powerful synergy between architecture and data diversity. The Gemma 2 9B model achieves state-of-the-art performance (>91\\% F1), but only when trained on a stylistically diverse ``generalist'' dataset. (2) Generalization is highly architecture-dependent. We diagnose a specific failure mode in Llama 3.1 8B, which performs well on a narrow domain but cannot integrate diverse data, leading to a significant performance drop. (3) Some architectures are inherently more generalizable. The Mistral model proves to be a consistent and resilient performer across multiple training paradigms. By pinpointing the flawed heuristics responsible for these failures, our work provides a concrete methodology for diagnosing and understanding generalization failures, underscoring that reliable AI requires deep validation of the interplay between architecture, data, and training strategy."
  },
  {
    "date": "2026-01-15",
    "title": "Some Eigenvalue Inequalities for the Schrödinger Operator on Integer Lattices",
    "authors": "Wentao Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10523v1",
    "source": "arXiv",
    "abstract": "In this paper, we establish analogues of the Payne-Pólya-Weinberger, Hile-Protter, and Yang eigenvalue inequalities for the Schrödinger operator on arbitrary finite subsets of the integer lattice $\\mathbb{Z}^n$. The results extend known inequalities for the discrete Laplacian to a more general class of Schrödinger operators with nonnegative potentials and weighted eigenvalue problems."
  },
  {
    "date": "2026-01-15",
    "title": "Nested hyperedges promote the onset of collective transitions but suppress explosive behavior",
    "authors": "Federico Malizia, Andrés Guzmán, Federico Battiston, István Z. Kiss",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10522v1",
    "source": "arXiv",
    "abstract": "Higher-order interactions can dramatically reshape collective dynamics, yet how their microscopic organization controls macroscopic critical behavior remains unclear. Here we develop a new theory to study contagion dynamics on hypergraphs and show that nested hyperedges not only facilitate the onset of spreading, but also suppress backward bifurcations, thereby inhibiting explosive behavior. By disentangling contagion pathways, we find that overlap redirects transmission from external links to internal, group-embedded routes -- boosting early activation but making dyadic and triadic channels increasingly redundant. This loss of structural independence quenches the nonlinear amplification required for bistability, progressively smoothing the transition as hyperedges become nested. We observe the same phenomenology in Kuramoto dynamics, pointing to a broadly universal mechanism by which nested higher-order structure governs critical transitions in complex systems."
  },
  {
    "date": "2026-01-15",
    "title": "Reply to \"Comment on Nuclear Fusion 66, 016012 (2026) by Richard Fitzpatrick, A Simple Model of Current Ramp-Up and Ramp-Down in Tokamaks\" by A.H. Boozer",
    "authors": "Richard Fitzpatrick",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10509v1",
    "source": "arXiv",
    "abstract": "This report is a follow up to my paper \"A simple model of current ramp-up and ramp-down in tokamaks\" [Nucl. Fusion 66, 016012 (2026)] in the light of comments on the paper recently made by Dr. A.H. Boozer (arXiv:2601.05977)."
  },
  {
    "date": "2026-01-15",
    "title": "Comprehensive parameter and electrochemical dataset for a 1 Ah graphite/LNMO battery cell for physical modelling as a blueprint for data reporting in battery research",
    "authors": "Christina Schmitt, August Johansson, Xavier Raynaud, Eibar Joel Flores Cedeño, John Mugisa, Dane Sotta, Agathe Martin, Nicolas Schaeffer, Cédric Debruyne, Yvan Reynier, Simon Clark, Dennis Kopljar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10507v1",
    "source": "arXiv",
    "abstract": "While current technology has enabled their widespread use, further improvements are needed for stationary, portable, and mobile applications, for example by the development of novel cathode materials. Digitalization of battery development, combining both experimental and modelling efforts is extremely valuable in this development. This is addressed in the present paper, where the authors present a comprehensive dataset for a graphite/LNMO 1 Ah pouch cell, including material, design, and electrochemical data. The dataset, validated through the BattMo modelling framework, supports physical modelling and aims to benefit the battery modelling community by offering a comprehensive resource for future studies. Both the dataset and the accompanying software for numerical validation is openly available and processed in such a way that it can serve as blueprint for reporting of comparable research data."
  },
  {
    "date": "2026-01-15",
    "title": "DR-Arena: an Automated Evaluation Framework for Deep Research Agents",
    "authors": "Yiwen Gao, Ruochen Zhao, Yang Deng, Wenxuan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10504v1",
    "source": "arXiv",
    "abstract": "As Large Language Models (LLMs) increasingly operate as Deep Research (DR) Agents capable of autonomous investigation and information synthesis, reliable evaluation of their task performance has become a critical bottleneck. Current benchmarks predominantly rely on static datasets, which suffer from several limitations: limited task generality, temporal misalignment, and data contamination. To address these, we introduce DR-Arena, a fully automated evaluation framework that pushes DR agents to their capability limits through dynamic investigation. DR-Arena constructs real-time Information Trees from fresh web trends to ensure the evaluation rubric is synchronized with the live world state, and employs an automated Examiner to generate structured tasks testing two orthogonal capabilities: Deep reasoning and Wide coverage. DR-Arena further adopts Adaptive Evolvement Loop, a state-machine controller that dynamically escalates task complexity based on real-time performance, demanding deeper deduction or wider aggregation until a decisive capability boundary emerges. Experiments with six advanced DR agents demonstrate that DR-Arena achieves a Spearman correlation of 0.94 with the LMSYS Search Arena leaderboard. This represents the state-of-the-art alignment with human preferences without any manual efforts, validating DR-Arena as a reliable alternative for costly human adjudication."
  },
  {
    "date": "2026-01-15",
    "title": "Semiparametric inference for inequality measures under nonignorable nonresponse using callback data",
    "authors": "Xinyu Wang, Chunlin Wang, Tao Yu, Pengfei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10501v1",
    "source": "arXiv",
    "abstract": "This paper develops semiparametric methods for estimation and inference of widely used inequality measures when survey data are subject to nonignorable nonresponse, a challenging setting in which response probabilities depend on the unobserved outcomes. Such nonresponse mechanisms are common in household surveys and invalidate standard inference procedures due to selection bias and lack of population representativeness. We address this problem by exploiting callback data from repeated contact attempts and adopting a semiparametric model that leaves the outcome distribution unspecified. We construct semiparametric full-likelihood estimators for the underlying distribution and the associated inequality measures, and establish their large-sample properties for a broad class of functionals, including quantiles, the Theil index, and the Gini index. Explicit asymptotic variance expressions are derived, enabling valid Wald-type inference under nonignorable nonresponse. To facilitate implementation, we propose a stable and computationally convenient expectation-maximization algorithm, whose steps either admit closed-form expressions or reduce to fitting a standard logistic regression model. Simulation studies demonstrate that the proposed procedures effectively correct nonresponse bias and achieve near-benchmark efficiency. An application to Consumer Expenditure Survey data illustrates the practical gains from incorporating callback information when making inference on inequality measures."
  },
  {
    "date": "2026-01-15",
    "title": "Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code LLMs",
    "authors": "Ali Al-Kaswan, Claudio Spiess, Prem Devanbu, Arie van Deursen, Maliheh Izadi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10496v1",
    "source": "arXiv",
    "abstract": "Large language models are increasingly used for code generation and debugging, but their outputs can still contain bugs, that originate from training data. Distinguishing whether an LLM prefers correct code, or a familiar incorrect version might be influenced by what it's been exposed to during training. We introduce an exposure-aware evaluation framework that quantifies how prior exposure to buggy versus fixed code influences a model's preference. Using the ManySStuBs4J benchmark, we apply Data Portraits for membership testing on the Stack-V2 corpus to estimate whether each buggy and fixed variant was seen during training. We then stratify examples by exposure and compare model preference using code completion as well as multiple likelihood-based scoring metrics We find that most examples (67%) have neither variant in the training data, and when only one is present, fixes are more frequently present than bugs. In model generations, models reproduce buggy lines far more often than fixes, with bug-exposed examples amplifying this tendency and fix-exposed examples showing only marginal improvement. In likelihood scoring, minimum and maximum token-probability metrics consistently prefer the fixed code across all conditions, indicating a stable bias toward correct fixes. In contrast, metrics like the Gini coefficient reverse preference when only the buggy variant was seen. Our results indicate that exposure can skew bug-fix evaluations and highlight the risk that LLMs may propagate memorised errors in practice."
  },
  {
    "date": "2026-01-15",
    "title": "Optimized readout strategies for neutral atom quantum processors",
    "authors": "Liang Chen, Wen-Yi Zhu, Zi-Jie Chen, Zhu-Bo Wang, Ya-Dong Hu, Qing-Xuan Jie, Guang-Can Guo, Chang-Ling Zou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10492v1",
    "source": "arXiv",
    "abstract": "Neutral atom quantum processors have emerged as a promising platform for scalable quantum information processing, offering high-fidelity operations and exceptional qubit scalability. A key challenge in realizing practical applications is efficiently extracting readout outcomes while maintaining high system throughput, i.e., the rate of quantum task executions. In this work, we develop a theoretical framework to quantify the trade-off between readout fidelity and atomic retention. Moreover, we introduce a metric of quantum circuit iteration rate (qCIR) and employ normalized quantum Fisher information to characterize system overall performance. Further, by carefully balancing fidelity and retention, we demonstrate a readout strategy for optimizing information acquisition efficiency. Considering the experimentally feasible parameters for 87Rb atoms, we demonstrate that qCIRs of 197.2Hz and 154.5Hz are achievable using single photon detectors and cameras, respectively. These results provide practical guidance for constructing scalable and high-throughput neutral atom quantum processors for applications in sensing, simulation, and near-term algorithm implementation."
  },
  {
    "date": "2026-01-15",
    "title": "Malliavin Calculus for the stochastic Cahn-Hilliard equation driven by fractional noise",
    "authors": "Dimitrios Dimitriou, Dimitris Farazakis, Georgia Karali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10490v1",
    "source": "arXiv",
    "abstract": "The stochastic partial differential equation analyzed in this work is the Cahn-Hilliard equation perturbed by an additive fractional white noise (fractional in time and white in space). We work in the case of one spatial dimension and apply Malliavin calculus to investigate the existence of a density for the stochastic solution $u$. In particular, we show that $u$ admits continuous paths almost surely and construct a localizing sequence through which we prove that its Malliavin derivative exists locally, and that its law is absolutely continuous with respect to the Lebesgue measure on $\\bf R$, establishing thus that a density exists. A key contribution of this work is the analysis of the stochastic integral appearing in the mild formulation: we derive sharp estimates for the expectation of the $p$-th power ($p \\geq 2$) of the $L^{\\infty}(D)$-norm of this stochastic integral as well as for the integral involving the $L^{\\infty}(D)$-norm of the operator associated with the kernel appearing in the integral representation of the fractional noise, all of which are essential for this study."
  },
  {
    "date": "2026-01-15",
    "title": "Analysis and Experimental Demonstration of Amplitude Amplification for Combinatorial Optimization",
    "authors": "Daniel Koch, Brian Pardo, Kip Nieman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10473v1",
    "source": "arXiv",
    "abstract": "Quantum Amplitude Amplification (QAA), the generalization of Grover's algorithm, is capable of yielding optimal solutions to combinatorial optimization problems with high probabilities. In this work we extend the conventional 2-dimensional representation of Grover's (orthogonal collective states) to oracles which encode cost functions such as QUBO, and show that linear cost functions are a special case whereby an exact formula exists for determining optimal oracle parameter settings. Using simulations of problem sizes up to 40 qubits we demonstrate QAA's algorithmic performance across all possible solutions, with an emphasis on the closeness in Grover-like performance for solutions near the global optimum. We conclude with experimental demonstrations of generalized QAA on both IBMQ (superconducting) and IonQ (trapped ion) qubits, showing that the observed probabilities of each basis state match our equations as a function of varying the free parameters in the oracle and diffusion operators."
  },
  {
    "date": "2026-01-15",
    "title": "DeFlow: Decoupling Manifold Modeling and Value Maximization for Offline Policy Extraction",
    "authors": "Zhancun Mu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10471v1",
    "source": "arXiv",
    "abstract": "We present DeFlow, a decoupled offline RL framework that leverages flow matching to faithfully capture complex behavior manifolds. Optimizing generative policies is computationally prohibitive, typically necessitating backpropagation through ODE solvers. We address this by learning a lightweight refinement module within an explicit, data-derived trust region of the flow manifold, rather than sacrificing the iterative generation capability via single-step distillation. This way, we bypass solver differentiation and eliminate the need for balancing loss terms, ensuring stable improvement while fully preserving the flow's iterative expressivity. Empirically, DeFlow achieves superior performance on the challenging OGBench benchmark and demonstrates efficient offline-to-online adaptation."
  },
  {
    "date": "2026-01-15",
    "title": "Charged Simpson-Visser AdS Black Holes: Geodesic Structure and Thermodynamic Properties",
    "authors": "Faizuddin Ahmed, Ahmad Al-Badawi, Mohsen Fathi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10469v1",
    "source": "arXiv",
    "abstract": "In this article, we apply the Simpson-Visser (SV) regularization scheme to Anti-de Sitter (AdS) charged black holes and investigate the resulting spacetime geometry in detail, with emphasis on both geodesic structure and thermodynamic behavior. In particular, we analyze the motion of massless particle, focusing on key features such as the photon sphere, black hole shadow, photon trajectory and the dynamics of charged particles, including the characteristics of the circular and type of orbits. Furthermore, we compare the theoretical predictions of the charged SV-AdS black hole with recent observations reported by the Event Horizon telescope (EHT) for M87* and Sgr~A*. Beyond the geodesic analysis, we explore the thermodynamics of the regularized charged SV-AdS black hole by deriving essential quantities such as the Hawking temperature, Gibbs free energy, and specific heat capacity. Through a systematic examination of these thermodynamic variables, we demonstrate how the regularization parameter inherent in the SV regularization influences particle dynamics, stability conditions, and the overall thermal properties of the modified black hole solution. This comprehensive study highlights the interplay between regularization effects and the physical observables associated with charged AdS black holes."
  },
  {
    "date": "2026-01-15",
    "title": "AI Sycophancy: How Users Flag and Respond",
    "authors": "Kazi Noshin, Syed Ishtiaque Ahmed, Sharifa Sultana",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10467v1",
    "source": "arXiv",
    "abstract": "While concerns about LLM sycophancy have grown among researchers and developers, how users themselves experience this behavior remains largely unexplored. We analyze Reddit discussions to investigate how users detect, mitigate, and perceive sycophantic AI. We develop the ODR Framework that maps user experiences across three stages: observing sycophantic behaviors, detecting sycophancy, and responding to these behaviors. Our findings reveal that users employ various detection techniques, including cross-platform comparison and inconsistency testing. We document diverse mitigation approaches, such as persona-based prompts to specific language patterns in prompt engineering. We find sycophancy's effects are context-dependent rather than universally harmful. Specifically, vulnerable populations experiencing trauma, mental health challenges, or isolation actively seek and value sycophantic behaviors as emotional support. Users develop both technical and folk explanations for why sycophancy occurs. These findings challenge the assumption that sycophancy should be eliminated universally. We conclude by proposing context-aware AI design that balances the risks with the benefits of affirmative interaction, while discussing implications for user education and transparency."
  },
  {
    "date": "2026-01-15",
    "title": "Architectural Classification of XR Workloads: Cross-Layer Archetypes and Implications",
    "authors": "Xinyu Shi, Simei Yang, Francky Catthoor",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10463v1",
    "source": "arXiv",
    "abstract": "Edge and mobile platforms for augmented and virtual reality, collectively referred to as extended reality (XR) must deliver deterministic ultra-low-latency performance under stringent power and area constraints. However, the diversity of XR workloads is rapidly increasing, characterized by heterogeneous operator types and complex dataflow structures. This trend poses significant challenges to conventional accelerator architectures centered around convolutional neural networks (CNNs), resulting in diminishing returns for traditional compute-centric optimization strategies. Despite the importance of this problem, a systematic architectural understanding of the full XR pipeline remains lacking. In this paper, we present an architectural classification of XR workloads using a cross-layer methodology that integrates model-based high-level design space exploration (DSE) with empirical profiling on commercial GPU and CPU hardware. By analyzing a representative set of workloads spanning 12 distinct XR kernels, we distill their complex architectural characteristics into a small set of cross-layer workload archetypes (e.g., capacity-limited and overhead-sensitive). Building on these archetypes, we further extract key architectural insights and provide actionable design guidelines for next-generation XR SoCs. Our study highlights that XR architecture design must shift from generic resource scaling toward phase-aware scheduling and elastic resource allocation in order to achieve greater energy efficiency and high performance in future XR systems."
  },
  {
    "date": "2026-01-15",
    "title": "ChartComplete: A Taxonomy-based Inclusive Chart Dataset",
    "authors": "Ahmad Mustapha, Charbel Toumieh, Mariette Awad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10462v1",
    "source": "arXiv",
    "abstract": "With advancements in deep learning (DL) and computer vision techniques, the field of chart understanding is evolving rapidly. In particular, multimodal large language models (MLLMs) are proving to be efficient and accurate in understanding charts. To accurately measure the performance of MLLMs, the research community has developed multiple datasets to serve as benchmarks. By examining these datasets, we found that they are all limited to a small set of chart types. To bridge this gap, we propose the ChartComplete dataset. The dataset is based on a chart taxonomy borrowed from the visualization community, and it covers thirty different chart types. The dataset is a collection of classified chart images and does not include a learning signal. We present the ChartComplete dataset as is to the community to build upon it."
  },
  {
    "date": "2026-01-15",
    "title": "Erasure conversion for singlet-triplet spin qubits enables high-performance shuttling-based quantum error correction",
    "authors": "Adam Siegel, Simon Benjamin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10461v1",
    "source": "arXiv",
    "abstract": "Fast and high fidelity shuttling of spin qubits has been demonstrated in semiconductor quantum dot devices. Several architectures based on shuttling have been proposed; it has been suggested that singlet-triplet (dual-spin) qubits could be optimal for the highest shuttling fidelities. Here we present a fault-tolerant framework for quantum error correction based on such dual-spin qubits, establishing them as a natural realisation of erasure qubits within semiconductor architectures. We introduce a hardware-efficient leakage-detection protocol that automatically projects leaked qubits back onto the computational subspace, without the need for measurement feedback or increased classical control overheads. When combined with the XZZX surface code and leakage-aware decoding, we demonstrate a twofold increase in the error correction threshold and achieve orders-of-magnitude reductions in logical error rates. This establishes the singlet-triplet encoding as a practical route toward high-fidelity shuttling and erasure-based, fault-tolerant quantum computation in semiconductor devices."
  },
  {
    "date": "2026-01-15",
    "title": "NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models",
    "authors": "Ziming Dai, Dabiao Ma, Jinle Tong, Mengyuan Han, Jian Yang, Haojun Fei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10457v1",
    "source": "arXiv",
    "abstract": "Although the Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments still faces prohibitive retraining costs and systemic risks. To address this problem, we present NSR-Boost, a neuro-symbolic residual boosting framework designed specifically for industrial scenarios. Its core advantage lies in being \"non-intrusive\". It treats the legacy model as a frozen model and performs targeted repairs on \"hard regions\" where predictions fail. The framework comprises three key stages: first, finding hard regions through residuals, then generating interpretable experts by generating symbolic code structures using Large Language Model (LLM) and fine-tuning parameters using Bayesian optimization, and finally dynamically integrating experts with legacy model output through a lightweight aggregator. We report on the successful deployment of NSR-Boost within the core financial risk control system at Qfin Holdings. This framework not only significantly outperforms state-of-the-art (SOTA) baselines across six public datasets and one private dataset, more importantly, shows excellent performance gains on real-world online data. In conclusion, it effectively captures long-tail risks missed by traditional models and offers a safe, low-cost evolutionary paradigm for industry."
  },
  {
    "date": "2026-01-15",
    "title": "Alertissimo -- a tool for orchestration of LSST broker streams",
    "authors": "V. Vujcic, V. A. Sreckovic, S. Babarogic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10454v1",
    "source": "arXiv",
    "abstract": "The Vera C. Rubin Observatory, through its Legacy Survey of Space and Time, will soon start producing 10 million alerts on transient astronomical objects per night. Due to logistics and bandwidth, alerts will not be dispatched directly to the public but to 'brokers' i.e. tools selected by LSST to handle alert streams. Brokers offer both common, specific and micro-specific functionalities related to alert handling, analysis, representation and dissemination. In this ecosystem, potentially augmented by data streams from other astronomical sources, there is a - need demonstrated by the community - for use cases which combine features of individual brokers. In this paper we present initial efforts and a prototype of such a tool, along with a language that would allow users to define use cases / workflows in a manner tailored for the domain."
  },
  {
    "date": "2026-01-15",
    "title": "The SpinPulse library for transpilation and noise-accurate simulation of spin qubit quantum computers",
    "authors": "Benoît Vermersch, Oscar Gravier, Nathan Miscopein, Julia Guignon, Carlos Ramos Marimón, Jonathan Durandau, Matthieu Dartiailh, Tristan Meunier, Valentin Savin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10435v1",
    "source": "arXiv",
    "abstract": "We introduce SpinPulse, an open-source python package for simulating spin qubit-based quantum computers at the pulse-level. SpinPulse models the specific physics of spin qubits, particularly through the inclusion of classical non-Markovian noise. This enables realistic simulations of native gates and quantum circuits, in order to support hardware development. In SpinPulse, a quantum circuit is first transpiled into the native gate set of our model and then converted to a pulse sequence. This pulse sequence is subsequently integrated numerically in the presence of a simulated noisy experimental environment. We showcase workflows including transpilation, pulse-level compilation, hardware benchmarking, quantum error mitigation, and large-scale simulations via integration with the tensor-network library quimb. We expect SpinPulse to be a valuable open-source tool for the quantum computing community, fostering efforts to devise high-fidelity quantum circuits and improved strategies for quantum error mitigation and correction."
  },
  {
    "date": "2026-01-15",
    "title": "The transformation mechanisms among cuboctahedra, Ino's decahedra and icosahedra structures of magic-size gold nanoclusters",
    "authors": "Ehsan Rahmatizad Khajehpasha, Mohammad Ismaeil Safa, Nasrin Eyvazi, Marco Krummenacher, Stefan Goedecker",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10434v1",
    "source": "arXiv",
    "abstract": "Gold nanoclusters possess multiple competing structural motifs with small energy differences, enabling structural coexistence and interconversion. Using a high-accuracy machine learned potential trained on some 20'000 density functional theory reference data points, we investigate transformation pathways connecting both high-symmetry and amorphous cuboctahedra, Ino's decahedra and icosahedra for Au55, Au147, Au309 and Au561 nanoclusters. Our saddle point searches reveal that high-symmetry transformations from cuboctahedra and Ino's decahedra to icosahedra proceed through a single barrier and represent soft-mode-driven jitterbug-type and slip-dislocation motions. In addition, we identify lower-barrier asymmetric transformation pathways that drive the system into disordered, Jahn-Teller-stabilized amorphous icosahedra. Minima Hopping sampling further uncovers, in this context, many such low-symmetry minima. Some of the newly identified global minima for Au309 and Au561 have energies that are up to 2.8 eV lower than the previously reported global minima. Hence, both the shapes and the transformation pathways studied in previous investigations are not the physically relevant ones. In contrast to the previously studied pathways, our transformation pathways give reasonable transformation times that are in rough agreement with experiments."
  },
  {
    "date": "2026-01-15",
    "title": "Spinodal decomposition in filled polymer blends exhibiting upper critical solution temperature behavior",
    "authors": "A. I. Chervanyov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10433v1",
    "source": "arXiv",
    "abstract": "By extending the Sanchez-Lacombe lattice-fluid model for mixtures to the case of polymer blends containing solid fillers, we calculate the excess thermodynamic quantities arising from the presence of fillers. These results are then used to derive the spinodal stability condition of a filled polymer blend. In the low-compressibility limit, this condition reduces to a remarkably simple analytical expression that is derived self-consistently within the present framework. Comparison between the exact and approximate spinodal curves shows excellent agreement, with deviations in the spinodal temperature of less than 4 K, thereby validating the proposed approximation. The obtained analytical approximation enables a straightforward evaluation of the spinodal temperature without the extensive numerical calculations required to determine the exact spinodal condition. Both the exact and approximate spinodal conditions yield good quantitative agreement with experimental data for filled and unfilled blends."
  },
  {
    "date": "2026-01-15",
    "title": "The eigenvalues and eigenvectors of finite-rank normal perturbations of large rotationally invariant non-Hermitian matrices",
    "authors": "Pierre Bousseyroux, Marc Potters",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10427v1",
    "source": "arXiv",
    "abstract": "We study finite-rank normal deformations of rotationally invariant non-Hermitian random matrices. Extending the classical Baik-Ben Arous-Péché (BBP) framework, we characterize the emergence and fluctuations of outlier eigenvalues in models of the form $\\mathbf{A} + \\mathbf{T}$, where $\\mathbf{A}$ is a large rotationally invariant non-Hermitian random matrix and $\\mathbf{T}$ is a finite-rank normal perturbation. We also describe the corresponding eigenvector behavior. Our results provide a unified framework encompassing both Hermitian and non-Hermitian settings, thereby generalizing several known cases."
  },
  {
    "date": "2026-01-15",
    "title": "Reinforcement Learning with Multi-Step Lookahead Information Via Adaptive Batching",
    "authors": "Nadav Merlis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10418v1",
    "source": "arXiv",
    "abstract": "We study tabular reinforcement learning problems with multiple steps of lookahead information. Before acting, the learner observes $\\ell$ steps of future transition and reward realizations: the exact state the agent would reach and the rewards it would collect under any possible course of action. While it has been shown that such information can drastically boost the value, finding the optimal policy is NP-hard, and it is common to apply one of two tractable heuristics: processing the lookahead in chunks of predefined sizes ('fixed batching policies'), and model predictive control. We first illustrate the problems with these two approaches and propose utilizing the lookahead in adaptive (state-dependent) batches; we refer to such policies as adaptive batching policies (ABPs). We derive the optimal Bellman equations for these strategies and design an optimistic regret-minimizing algorithm that enables learning the optimal ABP when interacting with unknown environments. Our regret bounds are order-optimal up to a potential factor of the lookahead horizon $\\ell$, which can usually be considered a small constant."
  },
  {
    "date": "2026-01-15",
    "title": "LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models",
    "authors": "Tiesunlong Shen, Rui Mao, Jin Wang, Heming Sun, Jian Zhang, Xuejie Zhang, Erik Cambria",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10416v1",
    "source": "arXiv",
    "abstract": "Aligning Large Language Models (LLMs) with human preferences is critical, yet traditional fine-tuning methods are computationally expensive and inflexible. While test-time alignment offers a promising alternative, existing approaches often rely on distorted trajectory-level signals or inefficient sampling, fundamentally capping performance and failing to preserve the generative diversity of the base model. This paper introduces LLMdoctor, a novel framework for efficient test-time alignment that operates via a patient-doctor paradigm. It integrates token-level reward acquisition with token-level flow-guided preference optimization (TFPO) to steer a large, frozen patient LLM with a smaller, specialized doctor model. Unlike conventional methods that rely on trajectory-level rewards, LLMdoctor first extracts fine-grained, token-level preference signals from the patient model's behavioral variations. These signals then guide the training of the doctor model via TFPO, which establishes flow consistency across all subtrajectories, enabling precise token-by-token alignment while inherently preserving generation diversity. Extensive experiments demonstrate that LLMdoctor significantly outperforms existing test-time alignment methods and even surpasses the performance of full fine-tuning approaches like DPO."
  },
  {
    "date": "2026-01-15",
    "title": "An effective interactive brain cytoarchitectonic parcellation framework using pretrained foundation model",
    "authors": "Shiqi Zhang, Fang Xu, Pengcheng Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10412v1",
    "source": "arXiv",
    "abstract": "Cytoarchitectonic mapping provides anatomically grounded parcellations of brain structure and forms a foundation for integrative, multi-modal neuroscience analyses. These parcellations are defined based on the shape, density, and spatial arrangement of neuronal cell bodies observed in histological imaging. Recent works have demonstrated the potential of using deep learning models toward fully automatic segmentation of cytoarchitectonic areas in large-scale datasets, but performance is mainly constrained by the scarcity of training labels and the variability of staining and imaging conditions. To address these challenges, we propose an interactive cytoarchitectonic parcellation framework that leverages the strong transferability of the DINOv3 vision transformer. Our framework combines (i) multi-layer DINOv3 feature fusion, (ii) a lightweight segmentation decoder, and (iii) real-time user-guided training from sparse scribbles. This design enables rapid human-in-the-loop refinement while maintaining high segmentation accuracy. Compared with training an nnU-Net from scratch, transfer learning with DINOv3 yields markedly improved performance. We also show that features extracted by DINOv3 exhibit clear anatomical correspondence and demonstrate the method's practical utility for brain region segmentation using sparse labels. These results highlight the potential of foundation-model-driven interactive segmentation for scalable and efficient cytoarchitectonic mapping."
  },
  {
    "date": "2026-01-15",
    "title": "A proof of Alexander's conjecture on an inequality of Cassels",
    "authors": "Myriam Ounaïes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10411v1",
    "source": "arXiv",
    "abstract": "Let $z_1,\\dots,z_n$ be complex numbers with $|z_j|\\le ρ$, where $ρ>1$. Cassels proved that, under an additional restriction on $ρ$, the inequality \\[ \\prod_{j\\ne k}\\bigl|1-\\overline{z_j}z_k\\bigr| \\le \\left(\\frac{ρ^{2n}-1}{ρ^2-1}\\right)^{\\!n} \\] holds. In a subsequent note, Alexander conjectured that this inequality is in fact valid without any restriction on $ρ$. In this paper, we confirm Alexander's conjecture."
  },
  {
    "date": "2026-01-15",
    "title": "Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering",
    "authors": "Xinyu Zhu, Yuzhu Cai, Zexi Liu, Bingyang Zheng, Cheng Wang, Rui Ye, Jiaao Chen, Hanrui Wang, Wei-Chen Wang, Yuzhi Zhang, Linfeng Zhang, Weinan E, Di Jin, Siheng Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10402v1",
    "source": "arXiv",
    "abstract": "The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in the high-dimensional, delayed-feedback environments of real-world research, failing to consolidate sparse feedback into coherent long-term guidance. Here, we present ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering (MLE) which is a representative microcosm of scientific discovery. By reframing context management as a process of cognitive accumulation, our approach introduces Hierarchical Cognitive Caching (HCC), a multi-tiered architecture inspired by computer systems that enables the structural differentiation of experience over time. By dynamically distilling transient execution traces into stable knowledge and cross-task wisdom, HCC allows agents to decouple immediate execution from long-term experimental strategy, effectively overcoming the scaling limits of static context windows. In evaluations on OpenAI's MLE-Bench under 24-hour budgets, ML-Master 2.0 achieves a state-of-the-art medal rate of 56.44%. Our findings demonstrate that ultra-long-horizon autonomy provides a scalable blueprint for AI capable of autonomous exploration beyond human-precedent complexities."
  },
  {
    "date": "2026-01-15",
    "title": "Scale Collapse of Vortices at Porous-Fluid Interfaces",
    "authors": "Justin Courter, Vishal Srikanth, Thibaut Kemayo, Andrey V. Kuznetsov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10396v1",
    "source": "arXiv",
    "abstract": "The interaction between externally generated turbulence and porous media is central to many engineering and environmental flows, yet the fate of macroscale vortical structures at a porous/fluid interface remains uncharacterized. By numerically simulating the turbulent flow, we investigate the penetration, breakdown, and turbulence kinetic energy (TKE) transport of macroscale vortices impinging on porous matrices with high porosities $φ$ = 0.80-0.95. For all porosities considered, macroscale vortices collapse abruptly at the porous interface and do not persist within the matrix, supporting the pore-scale prevalence of turbulence even under strong external forcing. Although vortex impingement injects TKE into the porous medium through turbulent transport at the interface, this supplied TKE is rapidly redistributed and dissipated as the flow reorganizes to satisfy pore-scale geometric constraints. Deeper within the porous layer, turbulence is sustained primarily by local shear production associated with pore-scale velocity gradients, and the internal flow becomes increasingly independent of upstream conditions. Variations in porosity modulate the relative balance between production and dissipation by altering geometric confinement and effective Reynolds number, but the dominant turbulent length scale within the porous matrix remains set by the pore size. These results demonstrate that porous media act as a robust geometric filter that enforces pore-scale-dominated turbulence regardless of external forcing."
  },
  {
    "date": "2026-01-15",
    "title": "Multiaccess Coded Caching with Heterogeneous Retrieval Costs",
    "authors": "Wenbo Huang, Minquan Cheng, Kai Wan, Xiaojun Li, Robert Caiming Qiu, Giuseppe Caire",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10394v1",
    "source": "arXiv",
    "abstract": "The multiaccess coded caching (MACC) system, as formulated by Hachem {\\it et al.}, consists of a central server with a library of $N$ files, connected to $K$ cache-less users via an error-free shared link, and $K$ cache nodes, each equipped with cache memory of size $M$ files. Each user can access $L$ neighboring cache nodes under a cyclic wrap-around topology. Most existing studies operate under the strong assumption that users can retrieve content from their connected cache nodes at no communication cost. In practice, each user retrieves content from its $L$ different connected cache nodes at varying costs. Additionally, the server also incurs certain costs to transmit the content to the users. In this paper, we focus on a cost-aware MACC system and aim to minimize the total system cost, which includes cache-access costs and broadcast costs. Firstly, we propose a novel coded caching framework based on superposition coding, where the MACC schemes of Cheng \\textit{et al.} are layered. Then, a cost-aware optimization problem is derived that optimizes cache placement and minimizes system cost. By identifying a sparsity property of the optimal solution, we propose a structure-aware algorithm with reduced complexity. Simulation results demonstrate that our proposed scheme consistently outperforms the scheme of Cheng {\\it et al.} in scenarios with heterogeneous retrieval costs."
  },
  {
    "date": "2026-01-15",
    "title": "Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer",
    "authors": "Filippo Ruffini, Camillo Maria Caruso, Claudia Tacconi, Lorenzo Nibid, Francesca Miccolis, Marta Lovino, Carlo Greco, Edy Ippolito, Michele Fiore, Alessio Cortellini, Bruno Beomonte Zobel, Giuseppe Perrone, Bruno Vincenzi, Claudio Marrocco, Alessandro Bria, Elisa Ficarra, Sara Ramella, Valerio Guarrasi, Paolo Soda",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10386v1",
    "source": "arXiv",
    "abstract": "Accurate survival prediction in Non-Small Cell Lung Cancer (NSCLC) requires the integration of heterogeneous clinical, radiological, and histopathological information. While Multimodal Deep Learning (MDL) offers a promises for precision prognosis and survival prediction, its clinical applicability is severely limited by small cohort sizes and the presence of missing modalities, often forcing complete-case filtering or aggressive imputation. In this work, we present a missing-aware multimodal survival framework that integrates Computed Tomography (CT), Whole-Slide Histopathology (WSI) Images, and structured clinical variables for overall survival modeling in unresectable stage II-III NSCLC. By leveraging Foundation Models (FM) for modality-specific feature extraction and a missing-aware encoding strategy, the proposed approach enables intermediate multimodal fusion under naturally incomplete modality profiles. The proposed architecture is resilient to missing modalities by design, allowing the model to utilize all available data without being forced to drop patients during training or inference. Experimental results demonstrate that intermediate fusion consistently outperforms unimodal baselines as well as early and late fusion strategies, with the strongest performance achieved by the fusion of WSI and clinical modalities (73.30 C-index). Further analyses of modality importance reveal an adaptive behavior in which less informative modalities, i.e., CT modality, are automatically down-weighted and contribute less to the final survival prediction."
  },
  {
    "date": "2026-01-15",
    "title": "RSA-Bench: Benchmarking Audio Large Models in Real-World Acoustic Scenarios",
    "authors": "Yibo Zhang, Liang Lin, Kaiwen Luo, Shilinlu Yan, Jin Wang, Yaoqi Guo, Yitian Chen, Yalan Qin, Zhenhong Zhou, Kun Wang, Li Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10384v1",
    "source": "arXiv",
    "abstract": "While Audio Large Models (ALMs) have achieved remarkable proficiency, their robustness remains brittle in real-world deployment. Existing evaluations largely rely on synthetic Gaussian noise or simplistic single-source interference, failing to capture the intricate, multi-layered acoustic dynamics -- or ``Acoustic Ecology'' -- that characterize authentic physical environments. To bridge this ecological gap, we introduce \\textbf{RSA-Bench}, a comprehensive robustness benchmark designed to stress-test ALLMs through high-fidelity auditory scene simulations. Unlike traditional methods, we construct evaluation samples by naturally superimposing diverse environmental soundscapes -- spanning \\textit{Pasture}, \\textit{Extreme Weather}, \\textit{Classroom}, and \\textit{Outdoors} -- onto clean speech signals across a spectrum of interference intensities. By evaluating models on six core tasks ranging from fundamental perception to complex reasoning, our study unveils three macro-level insights: \\textbf{(I) The Perception-Cognition Gap:} Models maintain relative resilience in low-level recognition but suffer a \\textbf{functional collapse} in high-order reasoning tasks under stress; \\textbf{(II) Scenario Sensitivity:} ``Vocal-like'' interference (e.g., background laughter) proves significantly more destructive than mechanical noise, challenging the model's auditory attention mechanisms; and \\textbf{(III) The Denoising Paradox:} Standard speech enhancement often exacerbates performance degradation, as ALLMs prove highly sensitive to the semantic distortions introduced by denoising artifacts."
  },
  {
    "date": "2026-01-15",
    "title": "Advanced Manufacturing with Renewable and Bio-based Materials: AI/ML workflows and Process Optimization",
    "authors": "Rigoberto Advincula, Jihua Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10382v1",
    "source": "arXiv",
    "abstract": "Advanced manufacturing with new bio-derived materials can be achieved faster and more economically with first-principle-based artificial intelligence and machine learning (AI/ML)-derived models and process optimization. Not only is this motivated by increased industry profitability, but it can also be optimized to reduce waste generation, energy consumption, and gas emissions through additive manufacturing (AM) and AI/ML-directed self-driving laboratory (SDL) process optimization. From this perspective, the benefits of using 3D printing technology to manufacture durable, sustainable materials will enable high-value reuse and promote a better circular economy. Using AI/ML workflows at different levels, it is possible to optimize the synthesis and adaptation of new bio-derived materials with self-correcting 3D printing methods, and in-situ characterization. Working with training data and hypotheses derived from Large Language Models (LLMs) and algorithms, including ML-optimized simulation, it is possible to demonstrate more field convergence. The combination of SDL and AI/ML Workflows can be the norm for improved use of biobased and renewable materials towards advanced manufacturing. This should result in faster and better structure, composition, processing, and properties (SCPP) correlation. More agentic AI tasks, as well as supervised or unsupervised learning, can be incorporated to improve optimization protocols continuously. Deep Learning (DL), Reinforcement Learning (RL), and Deep Reinforcement Learning (DRL) with Deep Neural Networks (DNNs) can be applied to more generative AI directions in both AM and SDL, with bio-based materials."
  },
  {
    "date": "2026-01-15",
    "title": "Online identification of nonlinear time-varying systems with uncertain information",
    "authors": "He Ren, Gaowei Yan, Hang Liu, Lifeng Cao, Zhijun Zhao, Gang Dang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10379v1",
    "source": "arXiv",
    "abstract": "Digital twins (DTs), serving as the core enablers for real-time monitoring and predictive maintenance of complex cyber-physical systems, impose critical requirements on their virtual models: high predictive accuracy, strong interpretability, and online adaptive capability. However, existing techniques struggle to meet these demands simultaneously: Bayesian methods excel in uncertainty quantification but lack model interpretability, while interpretable symbolic identification methods (e.g., SINDy) are constrained by their offline, batch-processing nature, which make real-time updates challenging. To bridge this semantic and computational gap, this paper proposes a novel Bayesian Regression-based Symbolic Learning (BRSL) framework. The framework formulates online symbolic discovery as a unified probabilistic state-space model. By incorporating sparse horseshoe priors, model selection is transformed into a Bayesian inference task, enabling simultaneous system identification and uncertainty quantification. Furthermore, we derive an online recursive algorithm with a forgetting factor and establish precise recursive conditions that guarantee the well-posedness of the posterior distribution. These conditions also function as real-time monitors for data utility, enhancing algorithmic robustness. Additionally, a rigorous convergence analysis is provided, demonstrating the convergence of parameter estimates under persistent excitation conditions. Case studies validate the effectiveness of the proposed framework in achieving interpretable, probabilistic prediction and online learning."
  },
  {
    "date": "2026-01-15",
    "title": "Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement",
    "authors": "Yichong Xia, Yimin Zhou, Jinpeng Wang, Bin Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10373v1",
    "source": "arXiv",
    "abstract": "Recent advancements in diffusion-based generative priors have enabled visually plausible image compression at extremely low bit rates. However, existing approaches suffer from slow sampling processes and suboptimal bit allocation due to fragmented training paradigms. In this work, we propose Accelerate \\textbf{Diff}usion-based Image Compression via \\textbf{C}onsistency Prior \\textbf{R}efinement (DiffCR), a novel compression framework for efficient and high-fidelity image reconstruction. At the heart of DiffCR is a Frequency-aware Skip Estimation (FaSE) module that refines the $ε$-prediction prior from a pre-trained latent diffusion model and aligns it with compressed latents at different timesteps via Frequency Decoupling Attention (FDA). Furthermore, a lightweight consistency estimator enables fast \\textbf{two-step decoding} by preserving the semantic trajectory of diffusion sampling. Without updating the backbone diffusion model, DiffCR achieves substantial bitrate savings (27.2\\% BD-rate (LPIPS) and 65.1\\% BD-rate (PSNR)) and over $10\\times$ speed-up compared to SOTA diffusion-based compression baselines."
  },
  {
    "date": "2026-01-15",
    "title": "Fine-Grained Human Pose Editing Assessment via Layer-Selective MLLMs",
    "authors": "Ningyu Sun, Zhaolin Cai, Zitong Xu, Peihang Chen, Huiyu Duan, Yichao Yan, Xiongkuo Min, Xiaokang Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10369v1",
    "source": "arXiv",
    "abstract": "Text-guided human pose editing has gained significant traction in AIGC applications. However,it remains plagued by structural anomalies and generative artifacts. Existing evaluation metrics often isolate authenticity detection from quality assessment, failing to provide fine-grained insights into pose-specific inconsistencies. To address these limitations, we introduce HPE-Bench, a specialized benchmark comprising 1,700 standardized samples from 17 state-of-the-art editing models, offering both authenticity labels and multi-dimensional quality scores. Furthermore, we propose a unified framework based on layer-selective multimodal large language models (MLLMs). By employing contrastive LoRA tuning and a novel layer sensitivity analysis (LSA) mechanism, we identify the optimal feature layer for pose evaluation. Our framework achieves superior performance in both authenticity detection and multi-dimensional quality regression, effectively bridging the gap between forensic detection and quality assessment."
  },
  {
    "date": "2026-01-15",
    "title": "Inverse Learning in $2\\times2$ Games: From Synthetic Interactions to Traffic Simulation",
    "authors": "Daniela Aguirre Salazar, Firas Moatemri, Tatiana Tatarenko",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10367v1",
    "source": "arXiv",
    "abstract": "Understanding how agents coordinate or compete from limited behavioral data is central to modeling strategic interactions in traffic, robotics, and other multi-agent systems. In this work, we investigate the following complementary formulations of inverse game-theoretic learning: (i) a Closed-form Correlated Equilibrium Maximum-Likelihood estimator (CE-ML) specialized for $2\\times2$ games; and (ii) a Logit Best Response Maximum-Likelihood estimator (LBR-ML) that captures long-run adaptation dynamics via stochastic response processes. Together, these approaches span the spectrum between static equilibrium consistency and dynamic behavioral realism. We evaluate them on synthetic \"chicken-dare\" games and traffic-interaction scenarios simulated in SUMO, comparing parameter recovery and distributional fit. Results reveal clear trade-offs between interpretability, computational tractability, and behavioral expressiveness across models."
  },
  {
    "date": "2026-01-15",
    "title": "Capillary Slinky: Equilibrium and Dynamics of Droplets in a Soft Spring",
    "authors": "Bidisha Bhatt, Andreas Carlson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10366v1",
    "source": "arXiv",
    "abstract": "Springs can be found in many applications and biological systems, and when these are soft, they easily deform. At small scales, capillarity can induce a force leading to spring deformations when the elastocapillary number is small. We demonstrate through experiments the non-trivial equilibrium shape liquid droplets adopt in these soft springs, which form an annulus, Eruciform, and spherical shapes. When these droplets are set in motion, they display different flow regimes with significant dissipation generated by the internal rotational flow. The static and dynamics of droplets in such a capillary slinky is also used to demonstrate how surface tension can actuate springs by stretching/compression, while providing a way for active flow control in soft springs."
  },
  {
    "date": "2026-01-15",
    "title": "A compact Optical Liquid Argon Facility at Roma Tre",
    "authors": "Hexi Shi, Valerio D'Andrea, Krzysztof Szczepaniec, Giuseppe Salamanna, Diego Tagnani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10363v1",
    "source": "arXiv",
    "abstract": "In this paper we present a compact test facility for the measurement of optical properties of liquid argon as scintillation detector. The setup is under preparation at Roma Tre and it has a volume of 40 L liquid argon, which is liquefied from argon gas with a purity of $\\ge 99.9999\\%$ vol. To readout the scintillation photons from liquid argon with the highest intensity near 127 nm, we use the vacuum ultraviolet silicon photomultipliers from Hamamatsu. By submerging the photon detectors directly inside the liquid argon, we can eliminate the systematics from the wave length shifter and light guides which have been commonly used to detect the scintillation photons of liquid argon."
  },
  {
    "date": "2026-01-15",
    "title": "An Itô Formula via Predictable Projection for Non-Semimartingale Processes",
    "authors": "Ramiro Fontes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10359v1",
    "source": "arXiv",
    "abstract": "We derive an Itô-type change-of-variables formula for a class of adapted stochastic processes that do not necessarily admit semimartingale structure. The formulation is based on an intrinsic Hilbert-space derivative together with a predictable projection operator, allowing stochastic integrals to be expressed without reliance on quadratic variation or anticipative calculus. The resulting formula replaces the classical quadratic variation term with a computable second-order contribution expressed as a norm of the projected derivative. In the semimartingale case, the formula reduces to the classical Itô formula. The approach applies naturally to processes with memory and non-Markovian dependence, providing a unified and intrinsic framework for stochastic calculus beyond the semimartingale setting."
  },
  {
    "date": "2026-01-15",
    "title": "Joint Bayesian inference of Earth's magnetic field and core surface flow on millennial timescales",
    "authors": "Andreas Nilsson, Neil Suttie, Marie Troyano, Nicolas Gillet, Julien Aubert, Anders Irbäck",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10344v1",
    "source": "arXiv",
    "abstract": "Understanding Earth's core dynamics over millennial timescales requires models that jointly describe the evolution of the geomagnetic field and core surface flow, while accommodating the sparse, irregular, and uncertain nature of archaeomagnetic and palaeomagnetic data. We present a new Bayesian core field and core flow modelling framework that utilises archaeo/palaeomagnetic data directly, combining a reduced stochastic representation of core surface dynamics derived from numerical geodynamo statistics with a probabilistic treatment of observational and chronological uncertainties. A key innovation is an efficient discrete marginalisation of age uncertainties, which avoids the convergence difficulties associated with co-estimating ages in high-dimensional Hamiltonian Monte Carlo inversions. The framework aims to reconstruct the coupled evolution of the geomagnetic field and core surface flow over the past 9000 years while preserving dynamical correlations implied by the prior geodynamo time series. Tests using synthetic data generated from an Earth-like geodynamo demonstrate that the method reliably recovers large-scale geomagnetic field variations and key aspects of core dynamics, including long-term westward drift and the evolution of planetary-scale eccentric gyres. These results show that, when combined with physically informed priors, archaeo/palaeomagnetic data can constrain millennial-scale core flow, paving the way for reconstructions based on real data."
  },
  {
    "date": "2026-01-15",
    "title": "Agent Skills in the Wild: An Empirical Study of Security Vulnerabilities at Scale",
    "authors": "Yi Liu, Weizhe Wang, Ruitao Feng, Yao Zhang, Guangquan Xu, Gelei Deng, Yuekang Li, Leo Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10338v1",
    "source": "arXiv",
    "abstract": "The rise of AI agent frameworks has introduced agent skills, modular packages containing instructions and executable code that dynamically extend agent capabilities. While this architecture enables powerful customization, skills execute with implicit trust and minimal vetting, creating a significant yet uncharacterized attack surface. We conduct the first large-scale empirical security analysis of this emerging ecosystem, collecting 42,447 skills from two major marketplaces and systematically analyzing 31,132 using SkillScan, a multi-stage detection framework integrating static analysis with LLM-based semantic classification. Our findings reveal pervasive security risks: 26.1% of skills contain at least one vulnerability, spanning 14 distinct patterns across four categories: prompt injection, data exfiltration, privilege escalation, and supply chain risks. Data exfiltration (13.3%) and privilege escalation (11.8%) are most prevalent, while 5.2% of skills exhibit high-severity patterns strongly suggesting malicious intent. We find that skills bundling executable scripts are 2.12x more likely to contain vulnerabilities than instruction-only skills (OR=2.12, p<0.001). Our contributions include: (1) a grounded vulnerability taxonomy derived from 8,126 vulnerable skills, (2) a validated detection methodology achieving 86.7% precision and 82.5% recall, and (3) an open dataset and detection toolkit to support future research. These results demonstrate an urgent need for capability-based permission systems and mandatory security vetting before this attack vector is further exploited."
  },
  {
    "date": "2026-01-15",
    "title": "An analytic theory of convolutional neural network inverse problems solvers",
    "authors": "Minh Hai Nguyen, Quoc Bao Do, Edouard Pauwels, Pierre Weiss",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10334v1",
    "source": "arXiv",
    "abstract": "Supervised convolutional neural networks (CNNs) are widely used to solve imaging inverse problems, achieving state-of-the-art performance in numerous applications. However, despite their empirical success, these methods are poorly understood from a theoretical perspective and often treated as black boxes. To bridge this gap, we analyze trained neural networks through the lens of the Minimum Mean Square Error (MMSE) estimator, incorporating functional constraints that capture two fundamental inductive biases of CNNs: translation equivariance and locality via finite receptive fields. Under the empirical training distribution, we derive an analytic, interpretable, and tractable formula for this constrained variant, termed Local-Equivariant MMSE (LE-MMSE). Through extensive numerical experiments across various inverse problems (denoising, inpainting, deconvolution), datasets (FFHQ, CIFAR-10, FashionMNIST), and architectures (U-Net, ResNet, PatchMLP), we demonstrate that our theory matches the neural networks outputs (PSNR $\\gtrsim25$dB). Furthermore, we provide insights into the differences between \\emph{physics-aware} and \\emph{physics-agnostic} estimators, the impact of high-density regions in the training (patch) distribution, and the influence of other factors (dataset size, patch size, etc)."
  },
  {
    "date": "2026-01-15",
    "title": "Computer Generation of Disordered Networks with Targeted Structural Properties",
    "authors": "Florin Hemmann, Vincent Glauser, Ullrich Steiner, Matthias Saba",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10333v1",
    "source": "arXiv",
    "abstract": "Disordered spatial networks are model systems that describe structures and interactions across multiple length scales. Scattering and interference of waves in these networks can give rise to structural phase transitions, localization, diffusion, and band gaps. The study of these complex phenomena requires efficient numerical methods to computer-generate disordered networks with targeted structural properties. In the established Wooten-Weaire-Winer algorithm, a series of bond switch moves introduces disorder into an initial network. Conventional strain energies that govern this evolution are limited to 3D networks with coordination numbers of no more than four. We extend the algorithm to arbitrary coordination number statistics by introducing bond repulsion in the Keating strain energy. We tune the degree and type of disorder introduced into initially crystalline networks by varying the bond-bending force constant in the strain energy and the temperature profile. The effects of these variables are analyzed using a list of order metrics that capture both direct and reciprocal space. A feedforward neural network is trained to predict the structural characteristics from the algorithm inputs, enabling targeted network generation. As a case study, we statistically reproduce four disordered biophotonic networks exhibiting structural color. This work presents a versatile method for generating disordered networks with tailored structural properties. It will enable new insights into structure-property relations, such as photonic band gaps in disordered networks."
  },
  {
    "date": "2026-01-15",
    "title": "On the characterization of geometric distance-regular graphs",
    "authors": "Chenhui Lv, Jack H. Koolen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10330v1",
    "source": "arXiv",
    "abstract": "In 2010, Koolen and Bang proposed the following conjecture: For a fixed integer $m \\geq 2$, any geometric distance-regular graph with smallest eigenvalue $-m$, diameter $D \\geq 3$ and $c_2 \\geq 2$ is either a Johnson graph, a Grassmann graph, a Hamming graph, a bilinear forms graph, or the number of vertices is bounded above by a function of $m$. In this paper, we obtain some partial results towards this conjecture."
  },
  {
    "date": "2026-01-15",
    "title": "On the Capacity of Noisy Frequency-based Channels",
    "authors": "Yuval Gerzon, Ilan Shomorony, Nir Weinberger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10329v1",
    "source": "arXiv",
    "abstract": "We investigate the capacity of noisy frequency-based channels, motivated by DNA data storage in the short-molecule regime, where information is encoded in the frequency of items types rather than their order. The channel output is a histogram formed by random sampling of items, followed by noisy item identification. While the capacity of the noiseless frequency-based channel has been previously addressed, the effect of identification noise has not been fully characterized. We present a converse bound on the channel capacity that follows from stochastic degradation and the data processing inequality. We then establish an achievable bound, which is based on a Poissonization of the multinomial sampling process, and an analysis of the resulting vector Poisson channel with inter-symbol interference. This analysis refines concentration inequalities for the information density used in Feinstein bound, and explicitly characterizes an additive loss in the mutual information due to identification noise. We apply our results to a DNA storage channel in the short-molecule regime, and quantify the resulting loss in the scaling of the total number of reliably stored bits."
  },
  {
    "date": "2026-01-15",
    "title": "SRAW-Attack: Space-Reweighted Adversarial Warping Attack for SAR Target Recognition",
    "authors": "Yiming Zhang, Weibo Qin, Yuntian Liu, Feng Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10324v1",
    "source": "arXiv",
    "abstract": "Synthetic aperture radar (SAR) imagery exhibits intrinsic information sparsity due to its unique electromagnetic scattering mechanism. Despite the widespread adoption of deep neural network (DNN)-based SAR automatic target recognition (SAR-ATR) systems, they remain vulnerable to adversarial examples and tend to over-rely on background regions, leading to degraded adversarial robustness. Existing adversarial attacks for SAR-ATR often require visually perceptible distortions to achieve effective performance, thereby necessitating an attack method that balances effectiveness and stealthiness. In this paper, a novel attack method termed Space-Reweighted Adversarial Warping (SRAW) is proposed, which generates adversarial examples through optimized spatial deformation with reweighted budgets across foreground and background regions. Extensive experiments demonstrate that SRAW significantly degrades the performance of state-of-the-art SAR-ATR models and consistently outperforms existing methods in terms of imperceptibility and adversarial transferability. Code is made available at https://github.com/boremycin/SAR-ATR-TransAttack."
  },
  {
    "date": "2026-01-15",
    "title": "Boundary-Aware NL2SQL: Integrating Reliability through Hybrid Reward and Data Synthesis",
    "authors": "Songsong Tian, Kongsheng Zhuo, Zhendong Wang, Rong Shen, Shengtao Zhang, Yong Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10318v1",
    "source": "arXiv",
    "abstract": "In this paper, we present BAR-SQL (Boundary-Aware Reliable NL2SQL), a unified training framework that embeds reliability and boundary awareness directly into the generation process. We introduce a Seed Mutation data synthesis paradigm that constructs a representative enterprise corpus, explicitly encompassing multi-step analytical queries alongside boundary cases including ambiguity and schema limitations. To ensure interpretability, we employ Knowledge-Grounded Reasoning Synthesis, which produces Chain-of-Thought traces explicitly anchored in schema metadata and business rules. The model is trained through a two-stage process: Supervised Fine-Tuning (SFT) followed by Reinforcement Learning via Group Relative Policy Optimization. We design a Task-Conditioned Hybrid Reward mechanism that simultaneously optimizes SQL execution accuracy-leveraging Abstract Syntax Tree analysis and dense result matching-and semantic precision in abstention responses. To evaluate reliability alongside generation accuracy, we construct and release Ent-SQL-Bench, which jointly assesse SQL precision and boundary-aware abstention across ambiguous and unanswerable queries. Experimental results on this benchmark demonstrate that BAR-SQL achieves 91.48% average accuracy, outperforming leading proprietary models, including Claude 4.5 Sonnet and GPT-5, in both SQL generation quality and boundary-aware abstention capability. The source code and benchmark are available anonymously at: https://github.com/TianSongS/BAR-SQL."
  },
  {
    "date": "2026-01-15",
    "title": "On Force Interactions for Electrodynamics-Like Theories",
    "authors": "Vladimir Gol'dshtein, Reuven Segev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10308v1",
    "source": "arXiv",
    "abstract": "A framework for premetric p-form electrodynamics is proposed. Independently of particular constitutive relations, the corresponding Maxwell equations are derived as a special case of stress theory in geometric continuum mechanics. Expressions for the potential energy of a charged region in spacetime, as well as expressions for the force and stress interactions on the region, are presented. The expression for the force distribution is obtained by computing the rate of change of the proposed potential energy under a virtual motion of the region. These expressions differ from those appearing in the standard references. The cases of electrostatics and magnetostatics in R^3 are presented as examples."
  },
  {
    "date": "2026-01-15",
    "title": "Single-Feed Circularly Polarized Super Realized Gain Antenna",
    "authors": "Georgia Psychogiou, Donal P. Lynch, Spyridon N. Daskalakis, Manos M. Tentzeris, George Goussetis, Stylianos D. Asimonis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10292v1",
    "source": "arXiv",
    "abstract": "This paper presents a super realized gain, circularly polarized strip-crossed dipole antenna operating at 3.5 GHz. Superdirective behavior is achieved by leveraging strong inter-element mutual coupling through careful adjustment of the strip dimensions. The antenna features a single driven element, with the other element passively loaded with a reactive impedance. The structure is optimized to maximize left-hand circularly polarized (LHCP) realized gain, ensuring high polarization purity and good impedance matching. The optimized design exhibits a 50 $Ω$ impedance bandwidth of 3.29 - 4.17 GHz (23.75%) and an axial-ratio bandwidth of 3.43 - 3.57 GHz (4%). At 3.5 GHz, the antenna achieves a peak realized gain of 6.1 dB ($ka \\approx 1.65$), with an axial ratio of 1.4 dB. These results demonstrate that circular polarization and superdirectivity can be simultaneously realized in a geometrically simple, low-profile ($0.15λ$) antenna, rendering it suitable for integration into compact sub-6~GHz wireless and sensing platforms."
  },
  {
    "date": "2026-01-15",
    "title": "New Upper Bounds on the Ribbonlength of Alternating Links with Bipartite Dual Graphs",
    "authors": "Hyungkee Yoo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10278v1",
    "source": "arXiv",
    "abstract": "The ribbonlength of a link is a geometric invariant defined as the infimum of the ratio of the length to the width of a folded ribbon realization of the link. In this paper, we prove that if an alternating link admits an alternating diagram with a bipartite dual graph, then its ribbonlength satisfies $$ \\mathrm{Rib}(L) \\le \\sqrt{3} \\, c(L). $$ Using this result, we present improved upper bounds on the ribbonlength for several knots and links with small crossing numbers, and determines the exact ribbonlength of the Hopf link to be $2\\sqrt{3}$."
  },
  {
    "date": "2026-01-15",
    "title": "Physics with next generation neutrino experiments: ESSnuSB",
    "authors": "ESSnuSB, :, Monojit Ghosh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10271v1",
    "source": "arXiv",
    "abstract": "In this proceedings we explore the physics potential of the ESSnuSBplus setup to study beam and non-beam based physics scenarios in both standard and new physics cases. The ESSnuSBplus setup consists of three neutrino sources: the main ESS linac, a low energy monitored neutrino beam and a low energy nuSTORM facility and three detectors: the main far detector and two near detectors. The goal of this facility is to measure the leptonic CP phase with extremely high precision and the neutrino nucleus cross-section in the few hundred MeV region."
  },
  {
    "date": "2026-01-15",
    "title": "Three-dimensional compact Heterotic solitons with parallel torsion",
    "authors": "Andrei Moroianu, Miguel Pino Carmona, C. S. Shahbazi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10270v1",
    "source": "arXiv",
    "abstract": "We obtain a rigidity result for compact three-dimensional Heterotic solitons with parallel non-trivial torsion. We show that they are either hyperbolic three-manifolds or compact quotients of the Heisenberg group equipped with a left-invariant metric. In particular, the latter arise both as solitons with completely skew-symmetric torsion as well as with non-vanishing twistorial component. As a corollary, we obtain the universal bound $-24$ for the scalar curvature of Heterotic solitons with parallel skew-symmetric torsion, which prevents it from being arbitrarily large."
  },
  {
    "date": "2026-01-15",
    "title": "Pulse thermal imaging of FUHAO bronze artifact",
    "authors": "Li Wang, Ning Tao, Wei Liu, Xiaoli Li, Yi He, Xue Yang, Jiangang Sun, Cunlin Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10265v1",
    "source": "arXiv",
    "abstract": "The accurate identification of historical restoration traces and material degradation is essential for the scientific preservation of ancient bronzes. In this study, the prestigious FUHAO bronze artifact (late Shang period, 13th-11th century BCE) was non-destructively examined using pulsed thermal imaging (PT). By combining single- and double-layer heat conduction models with Thermal Tomography (TT), this approach allowed for precise spatial localization of repair crevices, patches, and filler materials, while also distinguishing restorative interventions from the original bronze substrate. The artifact was revealed to have been assembled from multiple fragments, exhibiting uneven surface corrosion and clear evidence of prior conservation. The results not only provide direct insights for conservation strategy and historical interpretation but also demonstrate the capability of pulsed thermal imaging as an effective diagnostic tool for the integrated surface and subsurface assessment of cultural heritage objects."
  },
  {
    "date": "2026-01-15",
    "title": "XuanJia: A Comprehensive Virtualization-Based Code Obfuscator for Binary Protection",
    "authors": "Xianyu Zou, Xiaoli Gong, Jin Zhang, Shiyang Li, Pen-Chung Yew",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10261v1",
    "source": "arXiv",
    "abstract": "Virtualization-based binary obfuscation is widely adopted to protect software intellectual property, yet existing approaches leave exception-handling (EH) metadata unprotected to preserve ABI compatibility. This exposed metadata leaks rich structural information, such as stack layouts, control-flow boundaries, and object lifetimes, which can be exploited to facilitate reverse engineering. In this paper, we present XuanJia, a comprehensive VM-based binary obfuscation framework that provides end-to-end protection for both executable code and exception-handling semantics. At the core of XuanJia is ABI-Compliant EH Shadowing, a novel exception-aware protection mechanism that preserves compatibility with unmodified operating system runtimes while eliminating static EH metadata leakage. XuanJia replaces native EH metadata with ABI-compliant shadow unwind information to satisfy OS-driven unwinding, and securely redirects exception handling into a protected virtual machine where the genuine EH semantics are decrypted, reversed, and replayed using obfuscated code. We implement XuanJia from scratch, supporting 385 x86 instruction encodings and 155 VM handler templates, and design it as an extensible research testbed. We evaluate XuanJia across correctness, resilience, and performance dimensions. Our results show that XuanJia preserves semantic equivalence under extensive dynamic and symbolic testing, effectively disrupts automated reverse-engineering tools such as IDA Pro, and incurs negligible space overhead and modest runtime overhead. These results demonstrate that XuanJia achieves strong protection of exception-handling logic without sacrificing correctness or practicality."
  },
  {
    "date": "2026-01-15",
    "title": "Controllability score for linear time-invariant systems on an infinite time horizon",
    "authors": "Kota Umezu, Kazuhiro Sato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10260v1",
    "source": "arXiv",
    "abstract": "We introduce a scaled controllability Gramian that can be computed reliably even for unstable systems. Using this scaled Gramian, we reformulate the controllability scoring problems into equivalent but numerically stable optimization problems. Their optimal solutions define dynamics-aware network centrality measures, referred to as the volumetric controllability score (VCS) and the average energy controllability score (AECS). We then formulate controllability scoring problems on an infinite time horizon. Under suitable assumptions, we prove that the resulting VCS and AECS are unique and that the finite-horizon scores converge to them. We further show that VCS and AECS can differ markedly in this limit, because VCS enforces controllability of the full system, whereas AECS accounts only for the stable modes. Finally, using Laplacian dynamics as a representative example, we present numerical experiments that illustrate this convergence."
  },
  {
    "date": "2026-01-15",
    "title": "X-SAM: Boosting Sharpness-Aware Minimization with Dominant-Eigenvector Gradient Correction",
    "authors": "Hongru Duan, Yongle Chen, Lei Guan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10251v1",
    "source": "arXiv",
    "abstract": "Sharpness-Aware Minimization (SAM) aims to improve generalization by minimizing a worst-case perturbed loss over a small neighborhood of model parameters. However, during training, its optimization behavior does not always align with theoretical expectations, since both sharp and flat regions may yield a small perturbed loss. In such cases, the gradient may still point toward sharp regions, failing to achieve the intended effect of SAM. To address this issue, we investigate SAM from a spectral and geometric perspective: specifically, we utilize the angle between the gradient and the leading eigenvector of the Hessian as a measure of sharpness. Our analysis illustrates that when this angle is less than or equal to ninety degrees, the effect of SAM's sharpness regularization can be weakened. Furthermore, we propose an explicit eigenvector-aligned SAM (X-SAM), which corrects the gradient via orthogonal decomposition along the top eigenvector, enabling more direct and efficient regularization of the Hessian's maximum eigenvalue. We prove X-SAM's convergence and superior generalization, with extensive experimental evaluations confirming both theoretical and practical advantages."
  },
  {
    "date": "2026-01-15",
    "title": "Cell Behavior Video Classification Challenge, a benchmark for computer vision methods in time-lapse microscopy",
    "authors": "Raffaella Fiamma Cabini, Deborah Barkauskas, Guangyu Chen, Zhi-Qi Cheng, David E Cicchetti, Judith Drazba, Rodrigo Fernandez-Gonzalez, Raymond Hawkins, Yujia Hu, Jyoti Kini, Charles LeWarne, Xufeng Lin, Sai Preethi Nakkina, John W Peterson, Koert Schreurs, Ayushi Singh, Kumaran Bala Kandan Viswanathan, Inge MN Wortel, Sanjian Zhang, Rolf Krause, Santiago Fernandez Gonzalez, Diego Ulisse Pizzagalli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10250v1",
    "source": "arXiv",
    "abstract": "The classification of microscopy videos capturing complex cellular behaviors is crucial for understanding and quantifying the dynamics of biological processes over time. However, it remains a frontier in computer vision, requiring approaches that effectively model the shape and motion of objects without rigid boundaries, extract hierarchical spatiotemporal features from entire image sequences rather than static frames, and account for multiple objects within the field of view. To this end, we organized the Cell Behavior Video Classification Challenge (CBVCC), benchmarking 35 methods based on three approaches: classification of tracking-derived features, end-to-end deep learning architectures to directly learn spatiotemporal features from the entire video sequence without explicit cell tracking, or ensembling tracking-derived with image-derived features. We discuss the results achieved by the participants and compare the potential and limitations of each approach, serving as a basis to foster the development of computer vision methods for studying cellular dynamics."
  },
  {
    "date": "2026-01-15",
    "title": "Attend to what I say: Highlighting relevant content on slides",
    "authors": "Megha Mariam K M, C. V. Jawahar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10244v1",
    "source": "arXiv",
    "abstract": "Imagine sitting in a presentation, trying to follow the speaker while simultaneously scanning the slides for relevant information. While the entire slide is visible, identifying the relevant regions can be challenging. As you focus on one part of the slide, the speaker moves on to a new sentence, leaving you scrambling to catch up visually. This constant back-and-forth creates a disconnect between what is being said and the most important visual elements, making it hard to absorb key details, especially in fast-paced or content-heavy presentations such as conference talks. This requires an understanding of slides, including text, graphics, and layout. We introduce a method that automatically identifies and highlights the most relevant slide regions based on the speaker's narrative. By analyzing spoken content and matching it with textual or graphical elements in the slides, our approach ensures better synchronization between what listeners hear and what they need to attend to. We explore different ways of solving this problem and assess their success and failure cases. Analyzing multimedia documents is emerging as a key requirement for seamless understanding of content-rich videos, such as educational videos and conference talks, by reducing cognitive strain and improving comprehension. Code and dataset are available at: https://github.com/meghamariamkm2002/Slide_Highlight"
  },
  {
    "date": "2026-01-15",
    "title": "Unrefinable Partitions into Distinct Parts and Numerical Semigroups",
    "authors": "Lorenzo Campioni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10227v1",
    "source": "arXiv",
    "abstract": "This article investigates structural connections between unrefinable partitions into distinct parts and numerical semigroups. By analysing the hooksets of Young diagrams associated with numerical sets, new criteria for recognising unrefinable partitions are established. A correspondence between missing parts and the gaps of numerical semigroups is developed, extending previous classifications and enabling the characterisation of partitions with maximal numbers of missing parts. In particular, the results show that certain families of unrefinable partitions correspond precisely to symmetric numerical semigroups when the maximal part is prime. Further structural consequences, examples, and a decomposition of unrefinable partitions by minimal excludant are discussed, together with implications for the study of maximal unrefinable partitions."
  },
  {
    "date": "2026-01-15",
    "title": "STEAMROLLER: A Multi-Agent System for Inclusive Automatic Speech Recognition for People who Stutter",
    "authors": "Ziqi Xu, Yi Liu, Yuekang Li, Ling Shi, Kailong Wang, Yongxin Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10223v1",
    "source": "arXiv",
    "abstract": "People who stutter (PWS) face systemic exclusion in today's voice-driven society, where access to voice assistants, authentication systems, and remote work tools increasingly depends on fluent speech. Current automatic speech recognition (ASR) systems, trained predominantly on fluent speech, fail to serve millions of PWS worldwide. We present STEAMROLLER, a real time system that transforms stuttered speech into fluent output through a novel multi-stage, multi-agent AI pipeline. Our approach addresses three critical technical challenges: (1) the difficulty of direct speech to speech conversion for disfluent input, (2) semantic distortions introduced during ASR transcription of stuttered speech, and (3) latency constraints for real time communication. STEAMROLLER employs a three stage architecture comprising ASR transcription, multi-agent text repair, and speech synthesis, where our core innovation lies in a collaborative multi-agent framework that iteratively refines transcripts while preserving semantic intent. Experiments on the FluencyBank dataset and a user study demonstrates clear word error rate (WER) reduction and strong user satisfaction. Beyond immediate accessibility benefits, fine tuning ASR on STEAMROLLER repaired speech further yields additional WER improvements, creating a pathway toward inclusive AI ecosystems."
  },
  {
    "date": "2026-01-15",
    "title": "Introduction to optimization methods for training SciML models",
    "authors": "Alena Kopaničáková, Elisa Riccietti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10222v1",
    "source": "arXiv",
    "abstract": "Optimization is central to both modern machine learning (ML) and scientific machine learning (SciML), yet the structure of the underlying optimization problems differs substantially across these domains. Classical ML typically relies on stochastic, sample-separable objectives that favor first-order and adaptive gradient methods. In contrast, SciML often involves physics-informed or operator-constrained formulations in which differential operators induce global coupling, stiffness, and strong anisotropy in the loss landscape. As a result, optimization behavior in SciML is governed by the spectral properties of the underlying physical models rather than by data statistics, frequently limiting the effectiveness of standard stochastic methods and motivating deterministic or curvature-aware approaches. This document provides a unified introduction to optimization methods in ML and SciML, emphasizing how problem structure shapes algorithmic choices. We review first- and second-order optimization techniques in both deterministic and stochastic settings, discuss their adaptation to physics-constrained and data-driven SciML models, and illustrate practical strategies through tutorial examples, while highlighting open research directions at the interface of scientific computing and scientific machine learning."
  },
  {
    "date": "2026-01-15",
    "title": "Power and Control in Complex Networks: A Taxonomy and Critical Review",
    "authors": "Alessio Abeltino, Tiziano Bacaloni, Andrea Bernardini, Francesco Giancaterini, Andrea Pannone",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10218v1",
    "source": "arXiv",
    "abstract": "This paper reviews the main network analysis methods used to measure structural power, which refers to the ability to shape outcomes through network position and influence, and the ability to affect others through network connections. These approaches have been applied in fields such as corporate control, global value chains, and technology supply networks. Despite significant advances, a unified framework that systematically connects these methodologies to their conceptual foundations has yet to emerge. To fill this gap, the paper introduces a taxonomy that categorizes existing methods into six families: centrality-based approaches, game-theoretic models, concentration measures, flow-based methods, optimization frameworks, and hybrid approaches that combine elements from different approaches. This classification clarifies their assumptions, analytical focus, and relative strengths, offering a coherent view of how power is structured and transmitted in complex economic and political systems. The paper concludes by outlining future research directions to refine hybrid models linking decision-making and network flows."
  },
  {
    "date": "2026-01-15",
    "title": "Entanglement in $\\text{T}\\bar{\\text{T}}$ and root-$\\text{T}\\bar{\\text{T}}$ deformed AdS$_3$/CFT$_2$",
    "authors": "Saikat Biswas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10213v1",
    "source": "arXiv",
    "abstract": "In this work, we investigate the effects of $\\text{T}\\bar{\\text{T}}$ and root-$\\text{T}\\bar{\\text{T}}$ deformations on reflected and entanglement entropy in the context of both pure and mixed state entanglement measures. Utilizing a mixed boundary condition framework, we analyze how these deformations modify entanglement structures and explore their implications in three-dimensional AdS space. Our results provide insights into the interplay between solvable irrelevant deformations and quantum information-theoretic quantities, shedding light on the entanglement structure of deformed theories."
  },
  {
    "date": "2026-01-15",
    "title": "One Instruction Does Not Fit All: How Well Do Embeddings Align Personas and Instructions in Low-Resource Indian Languages?",
    "authors": "Arya Shah, Himanshu beniwal, Mayank Singh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10205v1",
    "source": "arXiv",
    "abstract": "Aligning multilingual assistants with culturally grounded user preferences is essential for serving India's linguistically diverse population of over one billion speakers across multiple scripts. However, existing benchmarks either focus on a single language or conflate retrieval with generation, leaving open the question of whether current embedding models can encode persona-instruction compatibility without relying on response synthesis. We present a unified benchmark spanning 12 Indian languages and four evaluation tasks: monolingual and cross-lingual persona-to-instruction retrieval, reverse retrieval from instruction to persona, and binary compatibility classification. Eight multilingual embedding models are evaluated in a frozen-encoder setting with a thin logistic regression head for classification. E5-Large-Instruct achieves the highest Recall@1 of 27.4\\% on monolingual retrieval and 20.7\\% on cross-lingual transfer, while BGE-M3 leads reverse retrieval at 32.1\\% Recall@1. For classification, LaBSE attains 75.3\\% AUROC with strong calibration. These findings offer practical guidance for model selection in Indic multilingual retrieval and establish reproducible baselines for future work\\footnote{Code, datasets, and models are publicly available at https://github.com/aryashah2k/PI-Indic-Align."
  },
  {
    "date": "2026-01-15",
    "title": "On the average-case complexity of learning states from the circular and Gaussian ensembles",
    "authors": "Maxwell West",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10197v1",
    "source": "arXiv",
    "abstract": "Studying the complexity of states sampled from various ensembles is a central component of quantum information theory. In this work we establish the average-case hardness of learning, in the statistical query model, the Born distributions of states sampled uniformly from the circular and (fermionic) Gaussian ensembles. These ensembles of states are induced variously by the uniform measures on the compact symmetric spaces of type AI, AII, and DIII. This finding complements analogous recent results for states sampled from the classical compact groups. On the technical side, we employ a somewhat unconventional approach to integrating over the compact groups which may be of some independent interest. For example, our approach allows us to exactly evaluate the total variation distances between the output distributions of Haar random unitary and orthogonal circuits and the constant distribution, which were previously known only approximately."
  },
  {
    "date": "2026-01-15",
    "title": "Model Predictive Control of Thermo-Hydraulic Systems Using Primal Decomposition",
    "authors": "Jonathan Vieth, Annika Eichler, Arne Speerforck",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10189v1",
    "source": "arXiv",
    "abstract": "Decarbonizing the global energy supply requires more efficient heating and cooling systems. Model predictive control enhances the operation of cooling and heating systems but depends on accurate system models, often based on control volumes. We present an automated framework including time discretization to generate model predictive controllers for such models. To ensure scalability, a primal decomposition exploiting the model structure is applied. The approach is validated on an underground heating system with varying numbers of states, demonstrating the primal decomposition's advantage regarding scalability."
  },
  {
    "date": "2026-01-15",
    "title": "Comprehensive Molecular-level Understanding of MgO Hydration through Computational Chemistry",
    "authors": "Taichi Inagaki, Miho Hatanaka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10186v1",
    "source": "arXiv",
    "abstract": "The hydration of magnesium oxide (MgO) to magnesium hydroxide (Mg(OH)$_2$) is a fundamental solid-surface chemical reaction with significant implications for materials science. Yet its molecular-level mechanism from water adsorption to Mg(OH)$_2$ nucleation and growth remains elusive due to its complex and multi-step nature. Here, we elucidate the molecular process of MgO hydration based on structures of the MgO/water interface obtained by a combined computational chemistry approach of potential-scaling molecular dynamics simulations and first-principles calculations without any a priori assumptions about reaction pathways. The result shows that the Mg$^{2+}$ dissolution follows the dissociative water adsorption. We find that this initial dissolution can proceed exothermically even from the defect-free surface with an average activation barrier of $\\sim$12 kcal/mol. This exothermicity depends crucially on the stabilization of the resulting surface vacancy, achieved by proton adsorption onto neighboring surface oxygen atoms. Further Mg$^{2+}$ dissolution then occurs in correlation with proton penetration into the solid. Moreover, we find that the Mg(OH)$_2$ nucleation and growth proceeds according to the dissolution-precipitation mechanism, rather than a solid-state reaction mechanism involving a direct topotactic transformation. In this process, Mg$^{2+}$ ions migrate away from the surface and form amorphous Mg-OH chains as precursors for Mg(OH)$_2$ nucleation. We also demonstrate that sufficient water facilitates the formation of more ordered crystalline nuclei. This computational study provides a comprehensive molecular-level understanding of MgO hydration, representing a foundational step toward elucidating the mechanisms of this class of complex and multi-step solid-surface chemical reactions."
  },
  {
    "date": "2026-01-15",
    "title": "Characteristics of drift effects in the quasi-geostrophic equation arising from nonlinear symmetry",
    "authors": "Masakazu Yamamoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10185v1",
    "source": "arXiv",
    "abstract": "This paper compares two similar diffusion equations that appear in meteorology. One is the quasi-geostrophic equation, and the other is the convection-diffusion equation. Both are two-dimensional bilinear equations, and the order of differentiation is the same. Naturally, their scales also coincide. However, the direction in which the nonlinear effects act differs: one acts along the isothermal surface, while the other acts along the temperature gradient in a specified direction. The main assertion quantifies this difference through the large-time behavior of their solutions. In particular, the nonlinear distortions in the asymptotic profiles of both equations are compared. In this context, the spatial symmetry of the first approximation plays a crucial role, but the solutions require no symmetry."
  },
  {
    "date": "2026-01-15",
    "title": "Discrete versus continuous -- lattice models and their exact continuous counterparts",
    "authors": "Lorenzo Fusi, Oliver Křenek, Vít Průša, Casey Rodriguez, Rebecca Tozzi, Martin Vejvoda",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10184v1",
    "source": "arXiv",
    "abstract": "We review and study the correspondence between discrete lattice/chain models of interacting particles and their continuous counterparts represented by partial differential equations. We study the correspondence problem for nearest neighbour interaction lattice models as well as for multiple-neighbour interaction lattice models, and we gradually proceed from infinite lattices to periodic lattices and finally to finite lattices with fixed ends/zero Dirichlet boundary conditions. The whole study is framed as systematic specialisation of Fourier analysis tools from the continuous to the discrete setting and vice versa, and the correspondence between the discrete and continuous models is examined primarily with regard to the dispersion relation."
  },
  {
    "date": "2026-01-15",
    "title": "HyMGP: A Customized MILP-Based Tool for Techno-Economic Planning of Islanded Microgrids",
    "authors": "Andres Intriago, Rongxing Hu, Nabil Mohammed, S. Gokul Krishnan, Konstantinos Kotsovos, Issam Gereige, Nesren Attiah, Ali Basaheeh, Sarah Aqeel, Hamad A. Saiari, Shehab Ahmed, Charalambos Konstantinou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10178v1",
    "source": "arXiv",
    "abstract": "This paper presents a customized microgrid planning algorithm and tool, HyMGP, for remote sites in arid regions, which is formulated as a Mixed Integer Linear Programming (MILP) problem. HyMGP is compared with HOMER Pro to evaluate its performance in optimizing the sizing of microgrid components, including photovoltaic panels (PVs), vertical axis wind turbines (VAWTs), and battery energy storage systems (BESS), for remote and off-grid applications. The study focuses on a standalone microgrid in the Saudi Arabia, considering high solar irradiance, limited wind availability, and a constant load profile composed of continuous cathodic protection and daytime cooling. In the simulation environment, comparisons with HOMER solutions demonstrate the advantages of HyMGP, which provides optimal and more flexible solutions by allowing user-defined component specifications and strictly enforcing all constraints. Further analysis shows that incorporating wind turbines reduces the Net Present Cost (NPC) by decreasing the required PV and battery capacities. Increasing battery autonomy leads to a higher NPC in both PV-only and hybrid systems due to the need for larger storage. Finally, lithium iron phosphate (Li-ion LFP) batteries are found to be more cost effective than lead acid, offering lower NPCs due to their longer lifespan, deeper discharge capability, and fewer replacement cycles."
  },
  {
    "date": "2026-01-15",
    "title": "What Gets Activated: Uncovering Domain and Driver Experts in MoE Language Models",
    "authors": "Guimin Hu, Meng Li, Qiwei Peng, Lijie Hu, Boyan Xu, Ruichu Cai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10159v1",
    "source": "arXiv",
    "abstract": "Most interpretability work focuses on layer- or neuron-level mechanisms in Transformers, leaving expert-level behavior in MoE LLMs underexplored. Motivated by functional specialization in the human brain, we analyze expert activation by distinguishing domain and driver experts. In this work, we study expert activation in MoE models across three public domains and address two key questions: (1) which experts are activated, and whether certain expert types exhibit consistent activation patterns; and (2) how tokens are associated with and trigger the activation of specific experts. To answer these questions, we introduce entropy-based and causal-effect metrics to assess whether an expert is strongly favored for a particular domain, and how strongly expert activation contributes causally to the model's output, thus identify domain and driver experts, respectively. Furthermore, we explore how individual tokens are associated with the activation of specific experts. Our analysis reveals that (1) Among the activated experts, some show clear domain preferences, while others exert strong causal influence on model performance, underscoring their decisive roles. (2) tokens occurring earlier in a sentence are more likely to trigger the driver experts, and (3) adjusting the weights of domain and driver experts leads to significant performance gains across all three models and domains. These findings shed light on the internal mechanisms of MoE models and enhance their interpretability."
  },
  {
    "date": "2026-01-15",
    "title": "ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback",
    "authors": "Yutao Mou, Zhangchi Xue, Lijun Li, Peiyang Liu, Shikun Zhang, Wei Ye, Jing Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10156v1",
    "source": "arXiv",
    "abstract": "While LLM-based agents can interact with environments via invoking external tools, their expanded capabilities also amplify security risks. Monitoring step-level tool invocation behaviors in real time and proactively intervening before unsafe execution is critical for agent deployment, yet remains under-explored. In this work, we first construct TS-Bench, a novel benchmark for step-level tool invocation safety detection in LLM agents. We then develop a guardrail model, TS-Guard, using multi-task reinforcement learning. The model proactively detects unsafe tool invocation actions before execution by reasoning over the interaction history. It assesses request harmfulness and action-attack correlations, producing interpretable and generalizable safety judgments and feedback. Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks."
  },
  {
    "date": "2026-01-15",
    "title": "Fluctuation-induced quenching of chaos in quantum optics",
    "authors": "Mei-Qi Gao, Song-hai Li, Xun Li, Xingli Li, Jiong Cheng, Wenlin Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10147v1",
    "source": "arXiv",
    "abstract": "Recent studies have extensively explored chaotic dynamics in quantum optical systems through the mean-field approximation, which corresponds to an ideal, fluctuation-free scenario. However, the inherent sensitivity of chaos to initial conditions implies that even minute fluctuations can be amplified, thereby questioning the applicability of this approximation. Here, we analyze these chaotic effects using stochastic Langevin equations or the Lindblad master equation. For systems operating at frequencies of $10^5$ to $10^7$ Hz, we demonstrate that room-temperature thermal fluctuations are sufficient to suppress chaos at the level of expectation values, even under weak nonlinearity. Furthermore, nonlinearity induces deviations from Gaussian phase-space distributions of the quantum state, revealing attractor-like features in the Wigner function. With increasing nonlinearity, the noise threshold for chaos suppression decreases, approaching the scale of vacuum fluctuations. These results provide a bidirectional validation of the quantum mechanical suppression of chaos."
  },
  {
    "date": "2026-01-15",
    "title": "Understanding and Preserving Safety in Fine-Tuned LLMs",
    "authors": "Jiawen Zhang, Yangfan Hu, Kejia Chen, Lipeng He, Jiachen Ma, Jian Lou, Dan Li, Jian Liu, Xiaohu Yang, Ruoxi Jia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10141v1",
    "source": "arXiv",
    "abstract": "Fine-tuning is an essential and pervasive functionality for applying large language models (LLMs) to downstream tasks. However, it has the potential to substantially degrade safety alignment, e.g., by greatly increasing susceptibility to jailbreak attacks, even when the fine-tuning data is entirely harmless. Despite garnering growing attention in defense efforts during the fine-tuning stage, existing methods struggle with a persistent safety-utility dilemma: emphasizing safety compromises task performance, whereas prioritizing utility typically requires deep fine-tuning that inevitably leads to steep safety declination. In this work, we address this dilemma by shedding new light on the geometric interaction between safety- and utility-oriented gradients in safety-aligned LLMs. Through systematic empirical analysis, we uncover three key insights: (I) safety gradients lie in a low-rank subspace, while utility gradients span a broader high-dimensional space; (II) these subspaces are often negatively correlated, causing directional conflicts during fine-tuning; and (III) the dominant safety direction can be efficiently estimated from a single sample. Building upon these novel insights, we propose safety-preserving fine-tuning (SPF), a lightweight approach that explicitly removes gradient components conflicting with the low-rank safety subspace. Theoretically, we show that SPF guarantees utility convergence while bounding safety drift. Empirically, SPF consistently maintains downstream task performance and recovers nearly all pre-trained safety alignment, even under adversarial fine-tuning scenarios. Furthermore, SPF exhibits robust resistance to both deep fine-tuning and dynamic jailbreak attacks. Together, our findings provide new mechanistic understanding and practical guidance toward always-aligned LLM fine-tuning."
  },
  {
    "date": "2026-01-15",
    "title": "Density of States of Ru3 and Pt3 Clusters Supported on Sputter-Deposited TiO2",
    "authors": "Liam Howard-Fabretto, Timothy J. Gorey, Guangjing Li, Siriluck Tesana, Gregory F. Metha, Scott L. Anderson, Gunther G. Andersson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10140v1",
    "source": "arXiv",
    "abstract": "In this work, 3-atom clusters, Ru3 and Pt3, were deposited onto radio frequency RF-sputter deposited TiO2, treated with Ar+ ion sputtering. Ru3 was deposited by both solution submersion and chemical vapor deposition of Ru3(CO)12, while Pt3 was deposited under ultra-high vacuum using a laser vaporisation cluster source. The valence electronic density of states (DOS) of the deposited clusters were analysed after heat treatment using ultraviolet photoelectron spectroscopy (UPS) and metastable impact electron spectroscopy (MIES), where UPS measures the top several layers while MIES measures only the top atomic layer. XPS was used to determine the cluster surface coverages. The DOS were found to be very similar between Ru3 deposited by solution submersion and chemical vapor deposition. MIES results for Ru3 had contributions from titania O 2p sites due to encapsulation by a reduced titania overlayer. For Pt3 clusters the UPS and MIES results provided evidence that Pt was present on the topmost layer, and encapsulation did not occur. The proposed reason for the encapsulation of Ru3 but not of Pt3 is the higher surface energy of Ru over Pt. It is concluded that Pt clusters deposited onto TiO2 can modify the outermost layer by adding discrete energy levels on the surface, whereas the Ru clusters being encapsulated just below the surface generate a broad distribution of energy states close to the Fermi level. The outcome of this work is that Pt3-cluster-modified surfaces could be used as catalysts for reactions where the Pt3 energy levels are suitable for the respective reaction. The implication of the DOS found for photocatalytic water splitting are discussed."
  },
  {
    "date": "2026-01-15",
    "title": "VQ-Seg: Vector-Quantized Token Perturbation for Semi-Supervised Medical Image Segmentation",
    "authors": "Sicheng Yang, Zhaohu Xing, Lei Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10124v1",
    "source": "arXiv",
    "abstract": "Consistency learning with feature perturbation is a widely used strategy in semi-supervised medical image segmentation. However, many existing perturbation methods rely on dropout, and thus require a careful manual tuning of the dropout rate, which is a sensitive hyperparameter and often difficult to optimize and may lead to suboptimal regularization. To overcome this limitation, we propose VQ-Seg, the first approach to employ vector quantization (VQ) to discretize the feature space and introduce a novel and controllable Quantized Perturbation Module (QPM) that replaces dropout. Our QPM perturbs discrete representations by shuffling the spatial locations of codebook indices, enabling effective and controllable regularization. To mitigate potential information loss caused by quantization, we design a dual-branch architecture where the post-quantization feature space is shared by both image reconstruction and segmentation tasks. Moreover, we introduce a Post-VQ Feature Adapter (PFA) to incorporate guidance from a foundation model (FM), supplementing the high-level semantic information lost during quantization. Furthermore, we collect a large-scale Lung Cancer (LC) dataset comprising 828 CT scans annotated for central-type lung carcinoma. Extensive experiments on the LC dataset and other public benchmarks demonstrate the effectiveness of our method, which outperforms state-of-the-art approaches. Code available at: https://github.com/script-Yang/VQ-Seg."
  },
  {
    "date": "2026-01-15",
    "title": "Direct Detection of Type II-P Supernova Progenitors with the Euclid and CSST Surveys",
    "authors": "Junjie Wu, Ning-Chen Sun, Zexi Niu, Tianmang Zhang, Chun Chen, Xiaohan Chen, Nancy Elias-Rosa, Morgan Fraser, Xinyi Hong, Justyn Maund, Cesar Rojas-Bravo, Anyu Wang, Beichuan Wang, Ziyang Wang, Qiang Xi, Linxi Zhang, Yinuo Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10121v1",
    "source": "arXiv",
    "abstract": "A central goal in supernova (SN) research is to identify and characterize their progenitors. However, this is very difficult due to the limited archival images with sufficient depth and spatial resolution required for direct progenitor detection and due to the circumstellar dust which often biases the estimate of their intrinsic parameters. This field will be revolutionized by Euclid and the upcoming Chinese Space Station Survey Telescope (CSST), which conduct deep, wide-field, high-resolution and multi-band imaging surveys. We analyze their detection capability by comparing the model magnitudes of red supergiant (RSG) progenitors with the detection limits under different conditions, and we estimate the annual detection rates with Monte-Carlo simulations. We explore how to recover the intrinsic properties of SN progenitors with the help of radiation transfer calculations in circumstellar dust. We find the optical and near-infrared filters of the Euclid and CSST are highly effective for detecting RSG progenitors. We predict that archival images from the completed 2 surveys will enable $\\lesssim13$ (or 24) progenitor detections per year within the mass range of 8--16 (or 8--25)M_\\odot, an order of magnitude higher than the current detection rate of $\\sim1$ detection per year. In the presence of circumstellar dust, the emerging spectral energy distribution (SED) of the progenitor is mainly affected by the optical depth and is almost independent of dust temperature in the Euclid and CSST filters. Our mock tests demonstrate that one can derive the progenitor mass and dust optical depth simultaneously by fitting the observed SED over the 11 filters of the 2 surveys while fixing the dust temperature to a typical value. Euclid and CSST will significantly enlarge the sample of direct progenitor detections with accurate mass measurements, which is crucial to resolve the long-standing RSG problem."
  },
  {
    "date": "2026-01-15",
    "title": "Advanced Encryption Technique for Multimedia Data Using Sudoku-Based Algorithms for Enhanced Security",
    "authors": "Mithil Bavishi, Anuj Bohra, Kushal Vadodaria, Abhinav Bohra, Neha Katre, Ramchandra Mangrulkar, Vinaya Sawant",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10119v1",
    "source": "arXiv",
    "abstract": "Encryption and Decryption is the process of sending a message in a ciphered way that appears meaningless and could be deciphered using a key for security purposes to avoid data breaches. This paper expands on the previous work on Sudoku-based encryption methods, applying it to other forms of media including images, audio and video. It also enhances the security of key generation and usage by making it dependent on the timestamp of when the message was transmitted. It is a versatile system that works on multimodal data and functions as a block-based transposition cipher. Instead of shuffling, it can also employ substitution methods like XOR, making it a substitution cipher. The resulting media are highly encrypted and resilient to brute-force and differential attacks. For images, NPCR values approach 100% and for audio, SNR values exceed 60dB. This makes the encrypted audio significantly different from the source, making decryption more difficult."
  },
  {
    "date": "2026-01-15",
    "title": "Skill-Aware Data Selection and Fine-Tuning for Data-Efficient Reasoning Distillation",
    "authors": "Lechen Zhang, Yunxiang Zhang, Wei Hu, Lu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10109v1",
    "source": "arXiv",
    "abstract": "Large reasoning models such as DeepSeek-R1 and their distilled variants achieve strong performance on complex reasoning tasks. Yet, distilling these models often demands large-scale data for supervised fine-tuning (SFT), motivating the pursuit of data-efficient training methods. To address this, we propose a skill-centric distillation framework that efficiently transfers reasoning ability to weaker models with two components: (1) Skill-based data selection, which prioritizes examples targeting the student model's weaker skills, and (2) Skill-aware fine-tuning, which encourages explicit skill decomposition during problem solving. With only 1,000 training examples selected from a 100K teacher-generated corpus, our method surpasses random SFT baselines by +1.6% on Qwen3-4B and +1.4% on Qwen3-8B across five mathematical reasoning benchmarks. Further analysis confirms that these gains concentrate on skills emphasized during training, highlighting the effectiveness of skill-centric training for efficient reasoning distillation."
  },
  {
    "date": "2026-01-15",
    "title": "Fuzzychain-edge: A novel Fuzzy logic-based adaptive Access control model for Blockchain in Edge Computing",
    "authors": "Khushbakht Farooq, Muhammad Ibrahim, Irsa Manzoor, Mukhtaj Khan, Wei Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10105v1",
    "source": "arXiv",
    "abstract": "The rapid integration of IoT with edge computing has revolutionized various domains, particularly healthcare, by enabling real-time data sharing, remote monitoring, and decision-making. However, it introduces critical challenges, including data privacy breaches, security vulnerabilities, especially in environments dealing with sensitive information. Traditional access control mechanisms and centralized security systems do not address these issues, leaving IoT environments exposed to unauthorized access and data misuse. This research proposes Fuzzychain-edge, a novel Fuzzy logic-based adaptive Access control model for Blockchain in Edge Computing framework designed to overcome these limitations by incorporating Zero-Knowledge Proofs (ZKPs), fuzzy logic, and smart contracts. ZKPs secure sensitive data during access control processes by enabling verification without revealing confidential details, thereby ensuring user privacy. Fuzzy logic facilitates adaptive, context-aware decision-making for access control by dynamically evaluating parameters such as data sensitivity, trust levels, and user roles. Blockchain technology, with its decentralized and immutable architecture, ensures transparency, traceability, and accountability using smart contracts that automate access control processes. The proposed framework addresses key challenges by enhancing security, reducing the likelihood of unauthorized access, and providing a transparent audit trail of data transactions. Expected outcomes include improved data privacy, accuracy in access control, and increased user trust in IoT systems. This research contributes significantly to advancing privacy-preserving, secure, and traceable solutions in IoT environments, laying the groundwork for future innovations in decentralized technologies and their applications in critical domains such as healthcare and beyond."
  },
  {
    "date": "2026-01-15",
    "title": "Using rapid rotators as tracers of multiplicity statistics as a function of stellar density",
    "authors": "Priyanka Cingirikonda, Marina Kounkel, Joseph Mullen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10099v1",
    "source": "arXiv",
    "abstract": "Recent works have identified that rapidly rotating stars are predominantly binaries with separations of a few to a few tenths of au. This is a crucial range of separation that is often inaccessible to searches of binary stars, providing a unique opportunity to examine their statistical properties. In particular, we have performed an analysis of rapid rotators in young moving groups. We examined their fraction as a function of the stellar density of the population in which they are found. We find that there is a deficit of rapid rotators in dense clusters such as the Orion Nebula in comparison to the more diffuse parts of the Orion Complex, as intracluster interactions with neighboring stars likely dissolve binaries with intermediate separations before they had a chance to fully form. In contrast, in older populations with an age of $\\sim100$ Myr, mass segregation redistributes binaries relative to single stars, thus in such older regions, rapid rotators are predominantly found in the regions of higher stellar density. This work sheds light on both the conditions that lead to the formation of binary stars and their dynamical evolution."
  },
  {
    "date": "2026-01-15",
    "title": "Multilingual-To-Multimodal (M2M): Unlocking New Languages with Monolingual Text",
    "authors": "Piyush Singh Pasi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10096v1",
    "source": "arXiv",
    "abstract": "Multimodal models excel in English, supported by abundant image-text and audio-text data, but performance drops sharply for other languages due to limited multilingual multimodal resources. Existing solutions rely heavily on machine translation, while advances in multilingual text modeling remain underutilized. We introduce METAL, a lightweight alignment method that learns only a few linear layers using English text alone to map multilingual text embeddings into a multimodal space. Despite its simplicity, METAL matches baseline performance in English (94.9 percent Recall at 10) and achieves strong zero-shot transfer (89.5 percent Recall at 10 averaged across 11 languages, 10 unseen) on XTD text-to-image retrieval. Qualitative t-SNE visualizations show that multilingual embeddings align tightly with multimodal representations, while weight analysis reveals that the transformation reshapes embedding geometry rather than performing trivial rotations. Beyond image-text retrieval, METAL generalizes to audio-text retrieval and cross-lingual text-to-image generation. We release code and checkpoints at https://github.com/m2m-codebase/M2M , as well as multilingual evaluation datasets including MSCOCO Multilingual 30K (https://huggingface.co/datasets/piyushsinghpasi/mscoco-multilingual-30k ), AudioCaps Multilingual (https://huggingface.co/datasets/piyushsinghpasi/audiocaps-multilingual ), and Clotho Multilingual (https://huggingface.co/datasets/piyushsinghpasi/clotho-multilingual ), to facilitate further research."
  },
  {
    "date": "2026-01-15",
    "title": "V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation",
    "authors": "Han Wang, Yi Yang, Jingyuan Hu, Minfeng Zhu, Wei Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10094v1",
    "source": "arXiv",
    "abstract": "Recent advances in multimodal learning have significantly enhanced the reasoning capabilities of vision-language models (VLMs). However, state-of-the-art approaches rely heavily on large-scale human-annotated datasets, which are costly and time-consuming to acquire. To overcome this limitation, we introduce V-Zero, a general post-training framework that facilitates self-improvement using exclusively unlabeled images. V-Zero establishes a co-evolutionary loop by instantiating two distinct roles: a Questioner and a Solver. The Questioner learns to synthesize high-quality, challenging questions by leveraging a dual-track reasoning reward that contrasts intuitive guesses with reasoned results. The Solver is optimized using pseudo-labels derived from majority voting over its own sampled responses. Both roles are trained iteratively via Group Relative Policy Optimization (GRPO), driving a cycle of mutual enhancement. Remarkably, without a single human annotation, V-Zero achieves consistent performance gains on Qwen2.5-VL-7B-Instruct, improving visual mathematical reasoning by +1.7 and general vision-centric by +2.6, demonstrating the potential of self-improvement in multimodal systems. Code is available at https://github.com/SatonoDia/V-Zero"
  },
  {
    "date": "2026-01-15",
    "title": "Difficulty-guided Sampling: Bridging the Target Gap between Dataset Distillation and Downstream Tasks",
    "authors": "Mingzhuo Li, Guang Li, Linfeng Ye, Jiafeng Mao, Takahiro Ogawa, Konstantinos N. Plataniotis, Miki Haseyama",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10090v1",
    "source": "arXiv",
    "abstract": "In this paper, we propose difficulty-guided sampling (DGS) to bridge the target gap between the distillation objective and the downstream task, therefore improving the performance of dataset distillation. Deep neural networks achieve remarkable performance but have time and storage-consuming training processes. Dataset distillation is proposed to generate compact, high-quality distilled datasets, enabling effective model training while maintaining downstream performance. Existing approaches typically focus on features extracted from the original dataset, overlooking task-specific information, which leads to a target gap between the distillation objective and the downstream task. We propose leveraging characteristics that benefit the downstream training into data distillation to bridge this gap. Focusing on the downstream task of image classification, we introduce the concept of difficulty and propose DGS as a plug-in post-stage sampling module. Following the specific target difficulty distribution, the final distilled dataset is sampled from image pools generated by existing methods. We also propose difficulty-aware guidance (DAG) to explore the effect of difficulty in the generation process. Extensive experiments across multiple settings demonstrate the effectiveness of the proposed methods. It also highlights the broader potential of difficulty for diverse downstream tasks."
  },
  {
    "date": "2026-01-15",
    "title": "Is MT Ready for the Next Crisis or Pandemic?",
    "authors": "Vipasha Bansal, Elizabeth Brown, Chelsea Kendrick, Benjamin Pong, William D. Lewis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10082v1",
    "source": "arXiv",
    "abstract": "Communication in times of crisis is essential. However, there is often a mismatch between the language of governments, aid providers, doctors, and those to whom they are providing aid. Commercial MT systems are reasonable tools to turn to in these scenarios. But how effective are these tools for translating to and from low resource languages, particularly in the crisis or medical domain? In this study, we evaluate four commercial MT systems using the TICO-19 dataset, which is composed of pandemic-related sentences from a large set of high priority languages spoken by communities most likely to be affected adversely in the next pandemic. We then assess the current degree of ``readiness'' for another pandemic (or epidemic) based on the usability of the output translations."
  },
  {
    "date": "2026-01-15",
    "title": "Electroluminescence in dopant-free GaAs/AlGaAs single heterojunctions: 2D free excitons, H-band, and the tidal effect",
    "authors": "N. Sherlekar, S. R. Harrigan, L. Tian, B. Cunard, Y. Qi, B. Khromets, M. C. Tam, H. S. Kim, Z. R. Wasilewski, J. Baugh, M. E. Reimer, F. Sfigakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10081v1",
    "source": "arXiv",
    "abstract": "Bright electroluminescence (EL) from dopant-free ambipolar lateral p-n junctions in GaAs/AlGaAs single heterointerface (SH) heterostructures is used to probe neutral free excitons arising from two-dimensional electron and hole gases (2DEGs and 2DHGs). The EL spectra reveal both the heavy-hole neutral free exciton (X$^0$) and the high-energy free exciton of the H band (HE). A combination of transition energies, lifetimes, spatial emission profiles, and temperature dependences points to a predominantly two-dimensional character for these excitons at the SH. For X$^0$, the EL peak energies (1515.5-1515.7 meV) lie slightly above the corresponding bulk GaAs photoluminescence (PL) line at 1515.3 meV, while time-resolved measurements yield markedly shorter lifetimes for EL than for PL (337 ps vs. 1610 ps), consistent with recombination in a confined interfacial layer. The HE exciton exhibits a Stark blueshift under forward bias below threshold, and its energies and lifetimes (down to 575 ps) are tuned by the topgate voltage; above threshold, HE emission is quenched in favor of X$^0$. Finally, the tidal effect $-$ a form of pulsed EL generated by swapping the topgate voltage polarity in ambipolar field-effect transistors $-$ produces an X$^0$ line at the same energy as in the lateral p-n junction and reproduces the characteristic nonmonotonic frequency dependence of the brightness previously observed in quantum-well heterostructures, again indicating a 2D-like origin. Taken together, these results show electrically generated and controllable 2D-like excitons (HE and X$^0$), thereby bridging 2D exciton physics and 2DEG/2DHG platforms in dopant-free GaAs/AlGaAs SH devices."
  },
  {
    "date": "2026-01-15",
    "title": "Nearest Kronecker Product Decomposition Based Subband Adaptive Filter: Algorithms and Applications",
    "authors": "Jianhong Ye, Haiquan Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10078v1",
    "source": "arXiv",
    "abstract": "Recently, the nearest Kronecker product (NKP) decomposition-based normalized least mean square (NLMS-NKP) algorithm has demonstrated superior convergence performance compared to the conventional NLMS algorithm. However, its convergence rate exhibits significant degradation when processing highly correlated input signals. To address this problem, we propose a type-I NKP-based normalized subband adaptive filter (NSAF) algorithm, namely NSAF-NKP-I. Nevertheless, this algorithm incurs substantially higher computational overhead than the NLMS-NKP algorithm. Remarkably, our enhanced type-II NKP-based NSAF (NSAF-NKP-II) algorithm achieves equivalent convergence performance while substantially reducing computational complexity. Furthermore, to enhance robustness against impulsive noise interference, we develop two robust variants: the maximum correntropy criterion-based robust NSAF-NKP (RNSAF-NKP-MCC) and logarithmic criterion-based robust NSAF-NKP (RNSAF-NKP-LC) algorithms. Additionally, detailed analyses of computational complexity, step-size range, and theoretical steady-state performance are provided for theproposed algorithms. To enhance the practicability of the NSAF-NKP-II algorithm in complex nonlinear environments, we further devise two nonlinear implementations: the trigonometric functional link network-based NKP-NSAF (TFLN-NSAF-NKP) and Volterra series expansion-based NKP-NSAF (Volterra-NKP-NSAF) algorithms. In active noise control (ANC) systems, we further propose the filtered-x NSAF-NKP-II (NKP-FxNSAF) algorithm. Simulation experiments in echo cancellation, sparse system identification, nonlinear processing, and ANC scenarios are conducted to validate the superiority of the proposed algorithms over existing state-of-the-art counterparts."
  },
  {
    "date": "2026-01-15",
    "title": "ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology",
    "authors": "Hyun Do Jung, Jungwon Choi, Hwiyoung Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10073v1",
    "source": "arXiv",
    "abstract": "We introduce ReaMIL (Reasoning- and Evidence-Aware MIL), a multiple instance learning approach for whole-slide histopathology that adds a light selection head to a strong MIL backbone. The head produces soft per-tile gates and is trained with a budgeted-sufficiency objective: a hinge loss that enforces the true-class probability to be $\\geq τ$ using only the kept evidence, under a sparsity budget on the number of selected tiles. The budgeted-sufficiency objective yields small, spatially compact evidence sets without sacrificing baseline performance. Across TCGA-NSCLC (LUAD vs. LUSC), TCGA-BRCA (IDC vs. Others), and PANDA, ReaMIL matches or slightly improves baseline AUC and provides quantitative evidence-efficiency diagnostics. On NSCLC, it attains AUC 0.983 with a mean minimal sufficient K (MSK) $\\approx 8.2$ tiles at $τ= 0.90$ and AUKC $\\approx 0.864$, showing that class confidence rises sharply and stabilizes once a small set of tiles is kept. The method requires no extra supervision, integrates seamlessly with standard MIL training, and naturally yields slide-level overlays. We report accuracy alongside MSK, AUKC, and contiguity for rigorous evaluation of model behavior on WSIs."
  },
  {
    "date": "2026-01-15",
    "title": "S$^2$F: Principled Hybrid Testing With Fuzzing, Symbolic Execution, and Sampling",
    "authors": "Lianjing Wang, Yufeng Zhang, Kenli Li, Zhenbang Chen, Xu Zhou, Pengfei Wang, Guangning Song, Ji Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10068v1",
    "source": "arXiv",
    "abstract": "Hybrid testing that integrates fuzzing, symbolic execution, and sampling has demonstrated superior testing efficiency compared to individual techniques. However, the state-of-the-art (SOTA) hybrid testing tools do not fully exploit the capabilities of symbolic execution and sampling in two key aspects. First, the SOTA hybrid testing tools employ tailored symbolic execution engines that tend to over-prune branches, leading to considerable time wasted waiting for seeds from the fuzzer and missing opportunities to discover crashes. Second, existing methods do not apply sampling to the appropriate branches and therefore cannot utilize the full capability of sampling. To address these two limitations, we propose a novel hybrid testing architecture that combines the precision of conventional symbolic execution with the scalability of tailored symbolic execution engines. Based on this architecture, we propose several principles for combining fuzzing, symbolic execution, and sampling. We implement our method in a hybrid testing tool S$^2$F. To evaluate its effectiveness, we conduct extensive experiments on 15 real-world programs. Experimental results demonstrate that S$^2$F outperforms the SOTA tool, achieving an average improvement of 6.14% in edge coverage and 32.6% in discovered crashes. Notably, our tool uncovers three previously unknown crashes in real-world programs."
  },
  {
    "date": "2026-01-15",
    "title": "Geometric Criteria for Complete Mode Conversion in Detuned Systems via Piecewise-Coherent Modulation",
    "authors": "Awanish Pandey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10066v1",
    "source": "arXiv",
    "abstract": "Static phase detuning fundamentally constrains coherent state transfer in asymmetric classical and quantum systems. We introduce a Bloch-sphere formulation for piecewise-coherent modulation that recasts coupled-mode dynamics as geometric trajectories, transforming algebraic control into path optimization. The approach reveals a cone of inaccessibility at the target pole and yields exact geodesic criteria for complete mode conversion in detuned systems. Leveraging this framework, we break time-reversal symmetry to realize a magnet-free optical isolator with near-unity contrast. Furthermore, for detuning larger than coupling between modes, we develop a recursive multi-step protocol enabling deterministic transfer for arbitrary detunings and derive a universal geometric lower bound on the required number of coupling-switching events."
  },
  {
    "date": "2026-01-15",
    "title": "Long-Chain Reasoning Distillation via Adaptive Prefix Alignment",
    "authors": "Zhenghao Liu, Zhuoyang Wu, Xinze Li, Yukun Yan, Shuo Wang, Zulong Chen, Yu Gu, Ge Yu, Maosong Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10064v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities, particularly in solving complex mathematical problems. Recent studies show that distilling long reasoning trajectories can effectively enhance the reasoning performance of small-scale student models. However, teacher-generated reasoning trajectories are often excessively long and structurally complex, making them difficult for student models to learn. This mismatch leads to a gap between the provided supervision signal and the learning capacity of the student model. To address this challenge, we propose Prefix-ALIGNment distillation (P-ALIGN), a framework that fully exploits teacher CoTs for distillation through adaptive prefix alignment. Specifically, P-ALIGN adaptively truncates teacher-generated reasoning trajectories by determining whether the remaining suffix is concise and sufficient to guide the student model. Then, P-ALIGN leverages the teacher-generated prefix to supervise the student model, encouraging effective prefix alignment. Experiments on multiple mathematical reasoning benchmarks demonstrate that P-ALIGN outperforms all baselines by over 3%. Further analysis indicates that the prefixes constructed by P-ALIGN provide more effective supervision signals, while avoiding the negative impact of redundant and uncertain reasoning components. All code is available at https://github.com/NEUIR/P-ALIGN."
  },
  {
    "date": "2026-01-15",
    "title": "A Compute and Communication Runtime Model for Loihi 2",
    "authors": "Jonathan Timcheck, Alessandro Pierro, Sumit Bam Shrestha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10035v1",
    "source": "arXiv",
    "abstract": "Neuromorphic computers hold the potential to vastly improve the speed and efficiency of a wide range of computational kernels with their asynchronous, compute-memory co-located, spatially distributed, and scalable nature. However, performance models that are simple yet sufficiently expressive to predict runtime on actual neuromorphic hardware are lacking, posing a challenge for researchers and developers who strive to design fast algorithms and kernels. As breaking the memory bandwidth wall of conventional von-Neumann architectures is a primary neuromorphic advantage, modeling communication time is especially important. At the same time, modeling communication time is difficult, as complex congestion patterns arise in a heavily-loaded Network-on-Chip. In this work, we introduce the first max-affine lower-bound runtime model -- a multi-dimensional roofline model -- for Intel's Loihi 2 neuromorphic chip that quantitatively accounts for both compute and communication based on a suite of microbenchmarks. Despite being a lower-bound model, we observe a tight correspondence (Pearson correlation coefficient greater than or equal to 0.97) between our model's estimated runtime and the measured runtime on Loihi 2 for a neural network linear layer, i.e., matrix-vector multiplication, and for an example application, a Quadratic Unconstrained Binary Optimization solver. Furthermore, we derive analytical expressions for communication-bottlenecked runtime to study scalability of the linear layer, revealing an area-runtime tradeoff for different spatial workload configurations with linear to superliner runtime scaling in layer size with a variety of constant factors. Our max-affine runtime model helps empower the design of high-speed algorithms and kernels for Loihi 2."
  },
  {
    "date": "2026-01-15",
    "title": "Macroscopic dynamics of quadratic integrate-and-fire neurons subject to correlated noise",
    "authors": "Hui Wang, Chunming Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10032v1",
    "source": "arXiv",
    "abstract": "The presence of correlated noise, arising from a mixture of independent fluctuations and a common noisy input shared across the neural population, is a ubiquitous feature of neural circuits, yet its impact on collective network dynamics remains poorly understood. We analyze a network of quadratic integrate-and-fire neurons driven by Gaussian noise with a tunable degree of correlation. Using the cumulant expansion method, we derive a reduced set of effective mean-field equations that accurately describe the evolution of the population's mean firing rate and membrane potential. Our analysis reveals a counterintuitive phenomenon: increasing the noise correlation strength suppresses the mean network activity, an effect we term correlated-noise-inhibited spiking. Furthermore, within a specific parameter regime, the network exhibits metastability, manifesting itself as spontaneous, noise-driven transitions between distinct high- and low-activity states. These results provide a theoretical framework for reducing the dynamics of complex stochastic networks and demonstrate how correlated noise can fundamentally regulate macroscopic neural activity, with implications for understanding state transitions in biological systems."
  },
  {
    "date": "2026-01-15",
    "title": "EHRNavigator: A Multi-Agent System for Patient-Level Clinical Question Answering over Heterogeneous Electronic Health Records",
    "authors": "Lingfei Qian, Mauro Giuffre, Yan Wang, Huan He, Qianqian Xie, Xuguang Ai, Xeuqing Peng, Fan Ma, Ruey-Ling Weng, Donald Wright, Adan Wang, Qingyu Chen, Vipina K. Keloth, Hua Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10020v1",
    "source": "arXiv",
    "abstract": "Clinical decision-making increasingly relies on timely and context-aware access to patient information within Electronic Health Records (EHRs), yet most existing natural language question-answering (QA) systems are evaluated solely on benchmark datasets, limiting their practical relevance. To overcome this limitation, we introduce EHRNavigator, a multi-agent framework that harnesses AI agents to perform patient-level question answering across heterogeneous and multimodal EHR data. We assessed its performance using both public benchmark and institutional datasets under realistic hospital conditions characterized by diverse schemas, temporal reasoning demands, and multimodal evidence integration. Through quantitative evaluation and clinician-validated chart review, EHRNavigator demonstrated strong generalization, achieving 86% accuracy on real-world cases while maintaining clinically acceptable response times. Overall, these findings confirm that EHRNavigator effectively bridges the gap between benchmark evaluation and clinical deployment, offering a robust, adaptive, and efficient solution for real-world EHR question answering."
  },
  {
    "date": "2026-01-15",
    "title": "Weyl magnetoplasma waves in magnetic Weyl semimetals",
    "authors": "Yuanzhao Wang, Oleg V. Kotov, Dmitry K. Efimkin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10014v1",
    "source": "arXiv",
    "abstract": "Weyl degeneracies in spectra of magnetoplasma waves enable nonreciprocal energy flow and topologically protected modes, yet conventional materials require impractical magnetic fields to operate. Developing an effective Hamiltonian framework for magnetic Weyl semimetals, we show that these systems overcome the limit, hosting Weyl magnetoplasma physics at zero field due to their giant intrinsic anomalous Hall response. The resulting topology supports nonreciprocal modes localized at magnetic domain walls, including a pair of topological \"Fermi-arc-like modes and additional bound states. These effects are fully developed across a broad THz window, and we propose feasible experimental routes for their detection."
  },
  {
    "date": "2026-01-15",
    "title": "Clustering-Based User Selection in Federated Learning: Metadata Exploitation for 3GPP Networks",
    "authors": "Ce Zheng, Shiyao Ma, Ke Zhang, Chen Sun, Wenqi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10013v1",
    "source": "arXiv",
    "abstract": "Federated learning (FL) enables collaborative model training without sharing raw user data, but conventional simulations often rely on unrealistic data partitioning and current user selection methods ignore data correlation among users. To address these challenges, this paper proposes a metadatadriven FL framework. We first introduce a novel data partition model based on a homogeneous Poisson point process (HPPP), capturing both heterogeneity in data quantity and natural overlap among user datasets. Building on this model, we develop a clustering-based user selection strategy that leverages metadata, such as user location, to reduce data correlation and enhance label diversity across training rounds. Extensive experiments on FMNIST and CIFAR-10 demonstrate that the proposed framework improves model performance, stability, and convergence in non-IID scenarios, while maintaining comparable performance under IID settings. Furthermore, the method shows pronounced advantages when the number of selected users per round is small. These findings highlight the framework's potential for enhancing FL performance in realistic deployments and guiding future standardization."
  },
  {
    "date": "2026-01-15",
    "title": "Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL",
    "authors": "Zerui Yang, Weichuan Wang, Yanwei Xu, Linqi Song, Yudai Matsuda, Wei Han, Bo Bai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10011v1",
    "source": "arXiv",
    "abstract": "Existing NL2SQL systems face two critical limitations: (1) they rely on in-context learning with only correct examples, overlooking the rich signal in historical error-fix pairs that could guide more robust self-correction; and (2) test-time scaling approaches often decompose questions arbitrarily, producing near-identical SQL candidates across runs and diminishing ensemble gains. Moreover, these methods suffer from a stark accuracy-efficiency trade-off: high performance demands excessive computation, while fast variants compromise quality. We present Memo-SQL, a training-free framework that addresses these issues through two simple ideas: structured decomposition and experience-aware self-correction. Instead of leaving decomposition to chance, we apply three clear strategies, entity-wise, hierarchical, and atomic sequential, to encourage diverse reasoning. For correction, we build a dynamic memory of both successful queries and historical error-fix pairs, and use retrieval-augmented prompting to bring relevant examples into context at inference time, no fine-tuning or external APIs required. On BIRD, Memo-SQL achieves 68.5% execution accuracy, setting a new state of the art among open, zero-fine-tuning methods, while using over 10 times fewer resources than prior TTS approaches."
  },
  {
    "date": "2026-01-15",
    "title": "SoK: Privacy-aware LLM in Healthcare: Threat Model, Privacy Techniques, Challenges and Recommendations",
    "authors": "Mohoshin Ara Tahera, Karamveer Singh Sidhu, Shuvalaxmi Dass, Sajal Saha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10004v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly adopted in healthcare to support clinical decision-making, summarize electronic health records (EHRs), and enhance patient care. However, this integration introduces significant privacy and security challenges, driven by the sensitivity of clinical data and the high-stakes nature of medical workflows. These risks become even more pronounced across heterogeneous deployment environments, ranging from small on-premise hospital systems to regional health networks, each with unique resource limitations and regulatory demands. This Systematization of Knowledge (SoK) examines the evolving threat landscape across the three core LLM phases: Data preprocessing, Fine-tuning, and Inference within realistic healthcare settings. We present a detailed threat model that characterizes adversaries, capabilities, and attack surfaces at each phase, and we systematize how existing privacy-preserving techniques (PPTs) attempt to mitigate these vulnerabilities. While existing defenses show promise, our analysis identifies persistent limitations in securing sensitive clinical data across diverse operational tiers. We conclude with phase-aware recommendations and future research directions aimed at strengthening privacy guarantees for LLMs in regulated environments. This work provides a foundation for understanding the intersection of LLMs, threats, and privacy in healthcare, offering a roadmap toward more robust and clinically trustworthy AI systems."
  },
  {
    "date": "2026-01-15",
    "title": "Extremum Seeking Nonovershooting Control of Strict-Feedback Systems Under Unknown Control Direction",
    "authors": "Kaixin Lu, Ziliang Lyu, Yanfang Mo, Yiguang Hong, Haoyong Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09998v1",
    "source": "arXiv",
    "abstract": "This paper addresses the nonovershooting control problem for strict-feedback nonlinear systems with unknown control direction. We propose a method that integrates extremum seeking with Lie bracket-based design to achieve approximately nonovershooting tracking. The approach ensures that arbitrary reference trajectories can be tracked from below for any initial condition, with the overshoot reducible to arbitrarily small levels through parameter tuning. The method further provides a mechanism for enforcing high-relative-degree nonovershooting constraints in safety-critical scenarios involving unknown control directions."
  },
  {
    "date": "2026-01-15",
    "title": "Towards Native Intelligence: 6G-LLM Trained with Reinforcement Learning from NDT Feedback",
    "authors": "Zhuoran Xiao, Tao Tao, Chenhui Ye, Yunbo Hu, Yijia Feng, Tianyu Jiao, Liyu Cai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09992v1",
    "source": "arXiv",
    "abstract": "Owing to its comprehensive understanding of upper-layer application requirements and the capabilities of practical communication systems, the 6G-LLM (6G domain large language model) offers a promising pathway toward realizing network native intelligence. Serving as the system orchestrator, the 6G-LLM drives a paradigm shift that fundamentally departs from existing rule-based approaches, which primarily rely on modular, experience-driven optimization. By contrast, the 6G-LLM substantially enhances network flexibility and adaptability. Nevertheless, current efforts to construct 6G-LLMs are constrained by their reliance on large-scale, meticulously curated, human-authored corpora, which are impractical to obtain in real-world scenarios. Moreover, purely offline-trained models lack the capacity for continual self-improvement, limiting their ability to adapt to the highly dynamic requirements of wireless communication environments. To overcome these limitations, we propose a novel training paradigm termed RLDTF (Reinforcement Learning from Digital Twin Feedback) for 6G-LLMs. This framework leverages network digital twins to generate reward signals based on orchestration outcomes, while employing reinforcement learning to guide the model toward optimal decision-making dynamically. Furthermore, we introduce a weighted token mechanism to improve output accuracy. Comprehensive experimental results demonstrate that our proposed framework significantly outperforms state-of-the-art baselines in orchestration accuracy and solution optimality."
  },
  {
    "date": "2026-01-15",
    "title": "In-the-Wild Compliant Manipulation with UMI-FT",
    "authors": "Hojung Choi, Yifan Hou, Chuer Pan, Seongheon Hong, Austin Patel, Xiaomeng Xu, Mark R. Cutkosky, Shuran Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09988v1",
    "source": "arXiv",
    "abstract": "Many manipulation tasks require careful force modulation. With insufficient force the task may fail, while excessive force could cause damage. The high cost, bulky size and fragility of commercial force/torque (F/T) sensors have limited large-scale, force-aware policy learning. We introduce UMI-FT, a handheld data-collection platform that mounts compact, six-axis force/torque sensors on each finger, enabling finger-level wrench measurements alongside RGB, depth, and pose. Using the multimodal data collected from this device, we train an adaptive compliance policy that predicts position targets, grasp force, and stiffness for execution on standard compliance controllers. In evaluations on three contact-rich, force-sensitive tasks (whiteboard wiping, skewering zucchini, and lightbulb insertion), UMI-FT enables policies that reliably regulate external contact forces and internal grasp forces, outperforming baselines that lack compliance or force sensing. UMI-FT offers a scalable path to learning compliant manipulation from in-the-wild demonstrations. We open-source the hardware and software to facilitate broader adoption at:https://umi-ft.github.io/."
  },
  {
    "date": "2026-01-15",
    "title": "Stochastic Calculus for Rough Fractional Brownian Motion via Operator Factorization",
    "authors": "Ramiro Fontes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09967v1",
    "source": "arXiv",
    "abstract": "We develop an operator-theoretic framework for stochastic calculus with respect to rough fractional Brownian motion with Hurst parameter H < 1/2. Building on a covariant derivative defined via kernel factorization, we construct a closed unbounded operator on L2(Omega) adapted to the non-semimartingale setting. This approach yields explicit derivative representations for square-integrable functionals and provides a unified analytical framework compatible with rough path techniques. The results extend classical stochastic calculus beyond the semimartingale regime."
  },
  {
    "date": "2026-01-15",
    "title": "aiPlato: A Novel AI Tutoring and Step-wise Feedback System for Physics Homework",
    "authors": "Atharva Dange, Ramon E. Lopez, Louis Deslauriers, Nimish Shah",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09965v1",
    "source": "arXiv",
    "abstract": "This exploratory study examines the classroom deployment of aiPlato, an AI-enabled homework platform, in a large introductory physics course at the University of Texas at Arlington. Designed to support open-ended problem solving, aiPlato provides step-wise feedback and iterative guidance through tools such as \"Evaluate My Work\" and \"AI Tutor Chat\", while preserving opportunities for productive struggle. Over four optional extra-credit assignments, the platform captured detailed student interaction data, which were analyzed alongside course performance and end-of-semester survey responses. We examine how students engaged with different feedback tools, whether engagement patterns were associated with performance on the cumulative final exam, and how students perceived the platform's usability and learning value. Students who engaged more frequently with aiPlato tended to achieve higher final exam scores, with a mean difference corresponding to a standardized effect size of approximately 0.81 between high and low engagement groups after controlling for prior academic performance. Usage patterns and survey responses indicate that students primarily relied on iterative, formative feedback rather than solution-revealing assistance. As a quasi-experimental pilot study, these findings do not establish causality and may reflect self-selection effects. Nonetheless, the results demonstrate the feasibility of integrating AI-mediated, step-wise feedback into authentic physics homework and motivate future controlled studies of AI-assisted tutoring systems."
  },
  {
    "date": "2026-01-15",
    "title": "Three Months in the Life of Cloud Quantum Computing",
    "authors": "Darrell Teegarden, Allison Casey, F. Gino Serpa, Patrick Becker, Asmita Brahme, Saanvi Kataria, Paul Lopata",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09943v1",
    "source": "arXiv",
    "abstract": "Quantum Computing (QC) has evolved from a few custom quantum computers, which were only accessible to their creators, to an array of commercial quantum computers that can be accessed on the cloud by anyone. Accessing these cloud quantum computers requires a complex chain of tools that facilitate connecting, programming, simulating algorithms, estimating resources, submitting quantum computing jobs, retrieving results, and more. Some steps in the chain are hardware dependent and subject to change as both hardware and software tools, such as available gate sets and optimizing compilers, evolve. Understanding the trade-offs inherent in this process is essential for evaluating the power and utility of quantum computers. ARLIS has been systematically investigating these environments to understand these complexities. The work presented here is a detailed summary of three months of using such quantum programming environments. We show metadata obtained from these environments, including the connection metrics to the different services, the execution of algorithms, the testing of the effects of varying the number of qubits, comparisons to simulations, execution times, and cost. Our objective is to provide concrete data and insights for those who are exploring the potential of quantum computing. It is not our objective to present any new algorithms or optimize performance on any particular machine or cloud platform; rather, this work is focused on providing a consistent view of a single algorithm executed using out-of-the-box settings and tools across machines, cloud platforms, and time. We present insights only available from these carefully curated data."
  },
  {
    "date": "2026-01-15",
    "title": "Emergence and transition of incompressible phases in decorated Landau levels",
    "authors": "Bo Peng, Yuzhu Wang, Bo Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10717v1",
    "source": "arXiv",
    "abstract": "We show a single Landau level (LL) dressed with periodic electrostatic potentials can realize a plethora of interacting topological phases where the Hall conductivity generally does not equal to the LL filling factor. Their physics can be captured by a minimal model of a delta potential lattice within a single LL, realizing exact zero energy Chern bands (denoted as decorated Landau levels or dLL) gapped from dispersive bands with rich geometric properties. With $p/q$ magnetic fluxes per unit cell, there are $q$ dispersive bands and $p-q$ zero energy bands forming the dLL. When the one-body potential strength dominates the electron-electron interaction, band mixing is suppressed and the dispersion bands consist of ``localized states\" with vanishing total Chern number. Nevertheless these dispersive bands can have highly nontrivial Berry curvature distribution, and even non-zero Chern numbers when $q>1$. Interestingly even in the limit of large short range interaction, band mixing between dLL and dispersion bands can be strongly suppressed at low filling factor, leading to robust topological phases within the dLL stabilized by the one-body potential. The dLL and the associated dispersive bands can serve as minimal theoretical models for correlated physics in lattice or moire systems; they are also highly tunable experimental platforms for realizing rich phase diagrams of exotic 2D quantum fluids."
  },
  {
    "date": "2026-01-15",
    "title": "WildRayZer: Self-supervised Large View Synthesis in Dynamic Environments",
    "authors": "Xuweiyi Chen, Wentao Zhou, Zezhou Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10716v1",
    "source": "arXiv",
    "abstract": "We present WildRayZer, a self-supervised framework for novel view synthesis (NVS) in dynamic environments where both the camera and objects move. Dynamic content breaks the multi-view consistency that static NVS models rely on, leading to ghosting, hallucinated geometry, and unstable pose estimation. WildRayZer addresses this by performing an analysis-by-synthesis test: a camera-only static renderer explains rigid structure, and its residuals reveal transient regions. From these residuals, we construct pseudo motion masks, distill a motion estimator, and use it to mask input tokens and gate loss gradients so supervision focuses on cross-view background completion. To enable large-scale training and evaluation, we curate Dynamic RealEstate10K (D-RE10K), a real-world dataset of 15K casually captured dynamic sequences, and D-RE10K-iPhone, a paired transient and clean benchmark for sparse-view transient-aware NVS. Experiments show that WildRayZer consistently outperforms optimization-based and feed-forward baselines in both transient-region removal and full-frame NVS quality with a single feed-forward pass."
  },
  {
    "date": "2026-01-15",
    "title": "Euclid preparation. 3D reconstruction of the cosmic web with simulated Euclid Deep spectroscopic samples",
    "authors": "Euclid Collaboration, K. Kraljic, C. Laigle, M. Balogh, P. Jablonka, U. Kuchner, N. Malavasi, F. Sarron, C. Pichon, G. De Lucia, M. Bethermin, F. Durret, M. Fumagalli, C. Gouin, M. Magliocchetti, J. G. Sorce, O. Cucciati, F. Fontanot, M. Hirschmann, Y. Kang, M. Spinelli, N. Aghanim, A. Amara, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, S. Bardelli, A. Biviano, E. Branchini, M. Brescia, J. Brinchmann, S. Camera, G. Cañas-Herrera, V. Capobianco, C. Carbone, J. Carretero, R. Casas, S. Casas, F. J. Castander, M. Castellano, G. Castignani, S. Cavuoti, K. C. Chambers, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, F. Courbin, H. M. Courtois, A. Da Silva, H. Degaudenzi, S. de la Torre, H. Dole, M. Douspis, F. Dubath, C. A. J. Duncan, X. Dupac, S. Dusini, S. Escoffier, M. Farina, R. Farinelli, S. Ferriol, F. Finelli, P. Fosalba, N. Fourmanoit, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, K. George, W. Gillard, B. Gillis, C. Giocoli, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, W. Holmes, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. Keihänen, S. Kermiche, A. Kiessling, M. Kilbinger, B. Kubik, M. Kümmel, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, S. Marcin, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. Massey, S. Maurogordato, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, R. Nakajima, C. Neissner, S. -M. Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W. J. Percival, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, R. Rebolo, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, C. Rosset, E. Rossetti, R. Saglia, Z. Sakr, A. G. Sánchez, D. Sapone, B. Sartoris, P. Schneider, T. Schrabback, M. Scodeggio, A. Secroun, E. Sefusatti, G. Seidel, M. Seiffert, S. Serrano, P. Simon, C. Sirignano, G. Sirri, L. Stanco, J. Steinwagner, P. Tallada-Crespí, A. N. Taylor, H. I. Teplitz, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, L. Valenziano, J. Valiviita, T. Vassallo, G. Verdoes Kleijn, A. Veropalumbo, D. Vibert, Y. Wang, J. Weller, A. Zacchei, G. Zamorani, E. Zucca, V. Allevato, M. Ballardini, M. Bolzonella, E. Bozzo, C. Burigana, R. Cabanac, M. Calabrese, A. Cappi, D. Di Ferdinando, J. A. Escartin Vigo, L. Gabarra, W. G. Hartley, J. Martín-Fleitas, S. Matthew, N. Mauri, R. B. Metcalf, A. A. Nucita, A. Pezzotta, M. Pöntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Viel, M. Wiesmann, Y. Akrami, S. Alvi, I. T. Andika, S. Anselmi, M. Archidiacono, F. Atrio-Barandela, A. Balaguera-Antolinez, P. Bergamini, D. Bertacca, A. Blanchard, L. Blot, H. Böhringer, S. Borgani, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, T. Castro, R. Chary, F. Cogato, S. Conseil, T. Contini, A. R. Cooray, S. Davini, F. De Paolis, G. Desprez, A. Díaz-Sánchez, J. J. Diaz, S. Di Domizio, J. M. Diego, P. Dimauro, P. -A. Duc, A. Enia, Y. Fang, A. G. Ferrari, A. Finoguenov, A. Fontana, A. Franco, K. Ganga, J. García-Bellido, T. Gasparetto, R. Gavazzi, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, M. Guidi, C. M. Gutierrez, A. Hall, H. Hildebrandt, J. Hjorth, S. Joudaki, J. J. E. Kajava, V. Kansal, D. Karagiannis, K. Kiiveri, C. C. Kirkpatrick, S. Kruk, M. Lattanzi, V. Le Brun, J. Le Graet, L. Legrand, M. Lembo, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, L. Leuzzi, T. I. Liaudat, S. J. Liu, A. Loureiro, J. Macias-Perez, G. Maggio, E. A. Magnier, F. Mannucci, R. Maoli, C. J. A. P. Martins, L. Maurin, M. Miluzio, P. Monaco, C. Moretti, G. Morgante, S. Nadathur, K. Naidoo, A. Navarro-Alsina, S. Nesseris, L. Pagano, F. Passalacqua, K. Paterson, L. Patrizii, A. Pisani, D. Potter, S. Quai, M. Radovich, P. -F. Rocci, G. Rodighiero, S. Sacquegna, M. Sahlén, D. B. Sanders, A. Schneider, D. Sciotti, E. Sellentin, L. C. Smith, K. Tanidis, C. Tao, G. Testera, R. Teyssier, S. Tosi, A. Troja, M. Tucci, C. Valieri, A. Venhola, D. Vergani, G. Verza, P. Vielzeuf, N. A. Walton",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10709v1",
    "source": "arXiv",
    "abstract": "The ongoing Euclid mission aims to measure spectroscopic redshifts for approximately two million galaxies using the H $α$ line emission detected in near-infrared slitless spectroscopic data from the Euclid Deep Fields (EDFs). These measurements will reach a flux limit of $5\\times 10^{-17}\\,{\\rm erg}\\,{\\rm cm}^{-2}\\,{\\rm s}^{-1}$ in the redshift range $0.4<z<1.8$, opening the door to numerous investigations involving galaxy evolution, extending well beyond the mission's core objectives. The achieved H $α$ luminosity depth will lead to a sufficiently high sampling, enabling the reconstruction of the large-scale galaxy environment. We assess the quality of the reconstruction of the galaxy cosmic web environment with the expected spectroscopic dataset in EDFs. The analysis is carried out on the Flagship and GAEA galaxy mock catalogues. The quality of the reconstruction is first evaluated using geometrical and topological statistics measured on the cosmic web, namely the length of filaments, the area of walls, the volume of voids, and its connectivity and multiplicity. We then quantify how accurately gradients in galaxy properties with distance from filaments can be recovered. As expected, the small-scale redshift-space distortions, have a strong impact on filament lengths and connectivity, but can be mitigated by compressing galaxy groups before skeleton extraction. The cosmic web reconstruction is biased when relying solely on H $α$ emitters. This limitation can be mitigated by applying stellar mass weighting during the reconstruction. However, this approach introduces non-trivial biases that need to be accounted for when comparing to theoretical predictions. Redshift uncertainties pose the greatest challenge in recovering the expected dependence of galaxy properties, though the well-established stellar mass transverse gradients towards filaments can still be observed."
  },
  {
    "date": "2026-01-15",
    "title": "See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection",
    "authors": "Amir Mallak, Erfan Aasi, Shiva Sreeram, Tsun-Hsuan Wang, Daniela Rus, Alaa Maalouf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10707v1",
    "source": "arXiv",
    "abstract": "Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors highly redundant. We quantify redundancy in such (BLIP2) features via PCA and cross-patch similarity: $90$% of variance is captured by $17/64$ principal components, and strong inter-token correlations are pervasive. Training on such overlapping information leads the policy to overfit spurious correlations, hurting OOD robustness. We present Stochastic-Patch-Selection (SPS), a simple yet effective approach for learning policies that are more robust, generalizable, and efficient. For every frame, SPS randomly masks a fraction of patch descriptors, not feeding them to the policy model, while preserving the spatial layout of the remaining patches. Thus, the policy is provided with different stochastic but complete views of the (same) scene: every random subset of patches acts like a different, yet still sensible, coherent projection of the world. The policy thus bases its decisions on features that are invariant to which specific tokens survive. Extensive experiments confirm that across all OOD scenarios, our method outperforms the state of the art (SOTA), achieving a $6.2$% average improvement and up to $20.4$% in closed-loop simulations, while being $2.4\\times$ faster. We conduct ablations over masking rates and patch-feature reorganization, training and evaluating 9 systems, with 8 of them surpassing prior SOTA. Finally, we show that the same learned policy transfers to a physical, real-world car without any tuning."
  },
  {
    "date": "2026-01-15",
    "title": "Madelung hydrodynamics of spin-orbit coupling: action principles, currents, and correlations",
    "authors": "Cesare Tronci",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10698v1",
    "source": "arXiv",
    "abstract": "We exploit the variational and Hamiltonian structures of quantum hydrodynamics with spin to unfold the correlation and torque mechanisms accompanying spin-orbit coupling (SOC) in electronic motion. Using Hamilton's action principle for the Pauli equation, we isolate SOC-induced quantum forces that act on the orbital Madelung--Bohm trajectories and complement the usual force terms known to appear in quantum hydrodynamics with spin. While the latter spin-hydrodynamic forces relate to the quantum geometric tensor (QGT), SOC-induced orbital forces originate from a particular current operator that contributes prominently to the spin current and whose contribution was overlooked in the past. The distinction between different force terms reveals two fundamentally different mechanisms generating quantum spin-orbit correlations. Leveraging the Hamiltonian structure of the hydrodynamic system, we also elucidate spin transport features such as the current shift in the spin Hall effect and the correlation-induced quantum torques. Finally, we illustrate the framework via the Madelung--Rashba equations for planar SOC configurations and propose a particle-based scheme for numerical implementation."
  },
  {
    "date": "2026-01-15",
    "title": "Constant-Depth Unitary Preparation of Dicke States",
    "authors": "Francisca Vasconcelos, Malvika Raj Joshi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10693v1",
    "source": "arXiv",
    "abstract": "Dicke states serve as a critical resource in quantum metrology, communication, and computation. However, unitary preparation of Dicke states is limited to logarithmic depth in standard circuit models and existing constant-depth protocols require measurement and feed-forward. In this work, we present the first unitary, constant-depth protocols for exact Dicke state preparation. We overcome the logarithmic-depth barrier by moving beyond the standard circuit model and leveraging global interactions (native to architectures such as neutral atoms and trapped ions). Specifically, utilizing unbounded CZ gates (i.e. within the QAC$^0$ circuit class), we offer circuits for exact computation of constant-weight Dicke states, using polynomial ancillae, and approximation of weight-1 Dicke states (i.e. $W$ states), using only constant ancillae. Granted additional access to the quantum FAN-OUT operation (i.e. upgrading to the QAC$_f^0$ circuit class), we also achieve exact preparation of arbitrary-weight Dicke states, with polynomial ancillae. These protocols distinguish the constant-depth capabilities of quantum architectures based on connectivity and offer a novel path toward resolving a long-standing quantum complexity conjecture."
  },
  {
    "date": "2026-01-15",
    "title": "Improved Constructions of Reed-Solomon Codes with Optimal Repair Bandwidth",
    "authors": "Jing Qiu, Weijun Fang, Shu-Tao Xia, Fang-Wei Fu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10685v1",
    "source": "arXiv",
    "abstract": "Maximum-distance-separable (MDS) codes are widely used in distributed storage, yet naive repair of a single erasure in an $[n,k]$ MDS code downloads the entire contents of $k$ nodes. Minimum Storage Regenerating (MSR) codes (Dimakis et al., 2010) minimize repair bandwidth by contacting $d>k$ helpers and downloading only a fraction of data from each. Guruswami and Wootters first proposed a linear repair scheme for Reed-Solomon (RS) codes, showing that they can be repaired with lower bandwidth than the naive approach. The existence of RS codes achieving the MSR point (RS-MSR codes) nevertheless remained open until the breakthrough construction of Tamo, Barg, and Ye, which yields RS-MSR codes with subpacketization $\\ell = s \\prod_{i=1}^n p_i$, where $p_i$ are distinct primes satisfying $p_i \\equiv 1 \\pmod{s}$ and $s=d+1-k$. In this paper, we present an improved construction of RS-MSR codes by eliminating the congruence condition $p_i \\equiv 1 \\pmod{s}$. Consequently, our construction reduces the subpacketization by a multiplicative factor of $φ(s)^n$ ( $φ(\\cdot)$ is Euler's totient function) and broadens the range of feasible parameters for RS-MSR codes."
  },
  {
    "date": "2026-01-15",
    "title": "Synchronizing Probabilities in Model-Driven Lossless Compression",
    "authors": "Aviv Adler, Jennifer Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10678v1",
    "source": "arXiv",
    "abstract": "It is well-known in the field of lossless data compression that probabilistic next-symbol prediction can be used to compress sequences of symbols. Deep neural networks are able to capture rich dependencies in data, offering a powerful means of estimating these probabilities and hence an avenue towards more effective compression algorithms. However, both compressor and decompressor must have exactly matching predictions; even small non-deterministic differences (which often happen with learned models due to hardware, software, or computation order) can lead to cascading decoding failures. In this paper, we formalize the problem of prediction mismatch in model-driven compression, and introduce Probability Matching Interval Coding (PMATIC), a model-agnostic algorithm that tolerates bounded prediction mismatch with low overhead. PMATIC works with the predicted probabilities, making it compatible as a drop-in replacement for the arithmetic encoder in model-driven compression tools. We show theoretical correctness and performance bounds for PMATIC, and validate these results on text data. These results confirm that, when paired an advanced prediction model, PMATIC is robust to prediction mismatch while achieving compression rates that out-perform standard modern compression tools."
  },
  {
    "date": "2026-01-15",
    "title": "A Mirror-Descent Algorithm for Computing the Petz-Rényi Capacity of Classical-Quantum Channels",
    "authors": "Yu-Hong Lai, Hao-Chung Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10558v1",
    "source": "arXiv",
    "abstract": "We study the computation of the $α$-Rényi capacity of a classical-quantum (c-q) channel for $α\\in(0,1)$. We propose an exponentiated-gradient (mirror descent) iteration that generalizes the Blahut-Arimoto algorithm. Our analysis establishes relative smoothness with respect to the entropy geometry, guaranteeing a global sublinear convergence of the objective values. Furthermore, under a natural tangent-space nondegeneracy condition (and a mild spectral lower bound in one regime), we prove local linear (geometric) convergence in Kullback-Leibler divergence on a truncated probability simplex, with an explicit contraction factor once the local curvature constants are bounded."
  },
  {
    "date": "2026-01-15",
    "title": "Nonlinear quantum Kibble-Zurek ramps in open systems at finite temperature",
    "authors": "Johannes N. Kriel, Emma C. King, Michael Kastner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10465v1",
    "source": "arXiv",
    "abstract": "We analyze quantum systems under a broad class of protocols in which the temperature and a Hamiltonian control parameter are ramped simultaneously and, in general, in a nonlinear fashion toward a quantum critical point. Using an open-system version of a Kitaev quantum wire as an example, we show that, unlike finite-temperature protocols at fixed temperature, these protocols allow us to probe, in an out-of-equilibrium situation and at finite temperature, the universality class (characterized by the critical exponents $ν$ and $z$) of an equilibrium quantum phase transition at zero temperature. Key to this is the identification of ramps in which both coherent and incoherent parts of the open-system dynamics affect the excitation density in a non-negligible way. We also identify the specific ramps for which subleading corrections to the asymptotic scaling laws are suppressed, which serves as a guide to dynamically probing quantum critical exponents in experimentally realistic finite-temperature situations."
  },
  {
    "date": "2026-01-15",
    "title": "The hidden structure of innovation networks",
    "authors": "Lorenzo Emer, Anna Gallo, Mattia Marzi, Andrea Mina, Tiziano Squartini, Andrea Vandin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10224v1",
    "source": "arXiv",
    "abstract": "Innovation emerges from complex collaboration patterns - among inventors, firms, or institutions. However, not much is known about the overall mesoscopic structure around which inventive activity self-organizes. Here, we tackle this problem by employing patent data to analyze both individual (\\emph{co-inventorship}) and organization (\\emph{co-ownership}) networks in three strategic domains (\\emph{artificial intelligence}, \\emph{biotechnology} and \\emph{semiconductors}). We characterize the mesoscale structure (in terms of clusters) of each domain by comparing two alternative methods: a standard baseline - modularity maximization - and one based on the minimization of the Bayesian Information Criterion, within the Stochastic Block Model and its degree-corrected variant. We find that, across sectors, inventor networks are denser and more clustered than organization ones - consistent with the presence of small recurrent teams embedded into broader institutional hierarchies - whereas organization networks have neater hierarchical role-based structures, with few bridging firms coordinating the most peripheral ones. We also find that the discovered meso-structures are connected to innovation output. In particular, Lorenz curves of forward citations show a pervasive inequality in technological influence: across sectors and methods, both inventor (especially) and organization networks consistently show high levels of concentration of citations in a few of the discovered clusters. Our results demonstrate that the baseline modularity-based method may not be capable of fully capturing the way collaborations drive the spreading of inventive impact across technological domains. This is due to the presence of local hierarchies that call for more refined tools based on Bayesian inference."
  },
  {
    "date": "2026-01-15",
    "title": "Synchronization with Annealed Disorder and Higher-Harmonic Interactions in Arbitrary Dimensions: When Two Dimensions Are Special",
    "authors": "Rupak Majumder, Shamik Gupta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10646v1",
    "source": "arXiv",
    "abstract": "The impact of disorder on collective phenomena depends crucially on whether it is quenched or annealed. In synchronization problems, quenched disorder in higher dimensional Kuramoto models is known to produce unconventional dimensional effects, including a striking odd even dichotomy: synchronization transitions are continuous in even dimensions and discontinuous in odd dimensions. By contrast, the impact of annealed disorder has received comparatively little attention. Here we study a D dimensional Kuramoto model with both fundamental and higher-harmonic interactions under annealed disorder, and develop an arbitrary dimensional center-manifold framework to analyze the nonlinear dynamics near the onset of collective behavior. We show that annealed disorder fundamentally alters the role of dimensionality. With fundamental coupling alone, it completely removes the odd even dichotomy, yielding continuous synchronization transitions with universal mean-field scaling in all dimensions. Higher-harmonic interactions preserve this universality while rendering the synchronization transition tunable between continuous and discontinuous. At the same time, they give rise to a novel, correlation-driven transition between a symmetry-protected incoherent phase and a symmetry broken state lacking global synchronization, which is therefore invisible to the conventional Kuramoto order parameter. This transition is continuous in two dimensions but discontinuous in higher dimensions, revealing an emergent and previously-unrecognized special role of two dimensions."
  },
  {
    "date": "2026-01-15",
    "title": "Optimal lower bound for quantum channel tomography in away-from-boundary regime",
    "authors": "Kean Chen, Zhicheng Zhang, Nengkun Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10683v1",
    "source": "arXiv",
    "abstract": "Consider quantum channels with input dimension $d_1$, output dimension $d_2$ and Kraus rank at most $r$. Any such channel must satisfy the constraint $rd_2\\geq d_1$, and the parameter regime $rd_2=d_1$ is called the boundary regime. In this paper, we show an optimal query lower bound $Ω(rd_1d_2/\\varepsilon^2)$ for quantum channel tomography to within diamond norm error $\\varepsilon$ in the away-from-boundary regime $rd_2\\geq 2d_1$, matching the existing upper bound $O(rd_1d_2/\\varepsilon^2)$. In particular, this lower bound fully settles the query complexity for the commonly studied case of equal input and output dimensions $d_1=d_2=d$ with $r\\geq 2$, in sharp contrast to the unitary case $r=1$ where Heisenberg scaling $Θ(d^2/\\varepsilon)$ is achievable."
  },
  {
    "date": "2026-01-15",
    "title": "Breaking Up with Normatively Monolithic Agency with GRACE: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment",
    "authors": "Felix Jahn, Yannic Muskalla, Lisa Dargasz, Patrick Schramowski, Kevin Baum",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10520v1",
    "source": "arXiv",
    "abstract": "As AI agents become increasingly autonomous, widely deployed in consequential contexts, and efficacious in bringing about real-world impacts, ensuring that their decisions are not only instrumentally effective but also normatively aligned has become critical. We introduce a neuro-symbolic reason-based containment architecture, Governor for Reason-Aligned ContainmEnt (GRACE), that decouples normative reasoning from instrumental decision-making and can contain AI agents of virtually any design. GRACE restructures decision-making into three modules: a Moral Module (MM) that determines permissible macro actions via deontic logic-based reasoning; a Decision-Making Module (DMM) that encapsulates the target agent while selecting instrumentally optimal primitive actions in accordance with derived macro actions; and a Guard that monitors and enforces moral compliance. The MM uses a reason-based formalism providing a semantic foundation for deontic logic, enabling interpretability, contestability, and justifiability. Its symbolic representation enriches the DMM's informational context and supports formal verification and statistical guarantees of alignment enforced by the Guard. We demonstrate GRACE on an example of a LLM therapy assistant, showing how it enables stakeholders to understand, contest, and refine agent behavior."
  },
  {
    "date": "2026-01-15",
    "title": "Random matrix theory universality of current operators in spin-$S$ Heisenberg chains",
    "authors": "Mariel Kempa, Markus Kraft, Robin Steinigeweg, Jochen Gemmer, Jiaozi Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10211v1",
    "source": "arXiv",
    "abstract": "Quantum chaotic systems exhibit certain universal statistical properties that closely resemble predictions from random matrix theory (RMT). With respect to observables, it has recently been conjectured that, when truncated to a sufficiently narrow energy window, their statistical properties can be described by an unitarily invariant ensemble, and testable criteria have been introduced, which are based on the scaling behavior of free cumulants. In this paper, we investigate the conjecture numerically in translationally invariant Heisenberg spin chains with spin quantum number $S =\\frac{1}{2},1,\\frac{3}{2}$. Combining a quantum-typicality-based numerical method with the exploitation of the system's symmetries, we study the spin current operator and find clear evidence of consistency with the proposed criteria in chaotic cases. Our findings further support the conjecture of the existence of RMT universality as manifest in the observable properties in quantum chaotic systems."
  },
  {
    "date": "2026-01-15",
    "title": "CURVE: A Benchmark for Cultural and Multilingual Long Video Reasoning",
    "authors": "Darshan Singh, Arsha Nagrani, Kawshik Manikantan, Harman Singh, Dinesh Tewari, Tobias Weyand, Cordelia Schmid, Anelia Angelova, Shachi Dave",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10649v1",
    "source": "arXiv",
    "abstract": "Recent advancements in video models have shown tremendous progress, particularly in long video understanding. However, current benchmarks predominantly feature western-centric data and English as the dominant language, introducing significant biases in evaluation. To address this, we introduce CURVE (Cultural Understanding and Reasoning in Video Evaluation), a challenging benchmark for multicultural and multilingual video reasoning. CURVE comprises high-quality, entirely human-generated annotations from diverse, region-specific cultural videos across 18 global locales. Unlike prior work that relies on automatic translations, CURVE provides complex questions, answers, and multi-step reasoning steps, all crafted in native languages. Making progress on CURVE requires a deeply situated understanding of visual cultural context. Furthermore, we leverage CURVE's reasoning traces to construct evidence-based graphs and propose a novel iterative strategy using these graphs to identify fine-grained errors in reasoning. Our evaluations reveal that SoTA Video-LLMs struggle significantly, performing substantially below human-level accuracy, with errors primarily stemming from the visual perception of cultural elements. CURVE will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva-cultural"
  },
  {
    "date": "2026-01-15",
    "title": "Risk and Monotone Comparative Statics without Independence",
    "authors": "Collin Raymond, Yangwei Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10664v1",
    "source": "arXiv",
    "abstract": "We extend well-known comparative results under expected utility to models of non-expected utility by providing novel conditions on local utility functions. We illustrate how our results parallel, and are distinct from, existing results for monotone comparative statics under expected utility, as well as risk preferences for non-expected utility. Our conditions generalize existing results for specific preferences (including expected utility) and allow us to verify monotone comparative statics for novel environments and preferences. We apply our results to portfolio choice problems where preferences or wealth might change, as well as precautionary savings."
  },
  {
    "date": "2026-01-15",
    "title": "Geometric Aspects of Entanglement Generating Hamiltonian Evolutions",
    "authors": "Carlo Cafaro, James Schneeloch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10662v1",
    "source": "arXiv",
    "abstract": "We examine the pertinent geometric characteristics of entanglement that arise from stationary Hamiltonian evolutions transitioning from separable to maximally entangled two-qubit quantum states. From a geometric perspective, each evolution is characterized by means of geodesic efficiency, speed efficiency, and curvature coefficient. Conversely, from the standpoint of entanglement, these evolutions are quantified using various metrics, such as concurrence, entanglement power, and entangling capability. Overall, our findings indicate that time-optimal evolution trajectories are marked by high geodesic efficiency, with no energy resource wastage, no curvature (i.e., zero bending), and an average path entanglement that is less than that observed in time-suboptimal evolutions. Additionally, when analyzing separable-to-maximally entangled evolutions between nonorthogonal states, time-optimal evolutions demonstrate a greater short-time degree of nonlocality compared to time-suboptimal evolutions between the same initial and final states. Interestingly, the reverse is generally true for separable-to-maximally entangled evolutions involving orthogonal states. Our investigation suggests that this phenomenon arises because suboptimal trajectories between orthogonal states are characterized by longer path lengths with smaller curvature, which are traversed with a higher energy resource wastage compared to suboptimal trajectories between nonorthogonal states. Consequently, a higher initial degree of nonlocality in the unitary time propagators appears to be essential for achieving the maximally entangled state from a separable state. Furthermore, when assessing optimal and suboptimal evolutions..."
  },
  {
    "date": "2026-01-15",
    "title": "Transforming Crises into Opportunities: From Chaos to Urban Antifragility",
    "authors": "Joseph Uguet, Nicola Tollin, Jordi Morato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10658v1",
    "source": "arXiv",
    "abstract": "Urban crises - floods, pandemics, economic shocks, and conflicts - function as accelerators of urban change, exposing structural vulnerabilities while creating windows for reinvention. Building on a prior theoretical contribution that identified fifteen principles of urban antifragility, this paper tests and operationalizes the framework through an empirical assessment of 26 cities selected for their post-crisis adaptation trajectories. Using a tailored diagnostic methodology, we benchmark cities' Stress Response Strategies (SRS) and then evaluate Urban Development Trajectories (UDT) across four weighted dimensions, positioning each case along a fragility-robustness-resilience-antifragility continuum and applying a balanced-threshold rule to confirm antifragile status. Results show that \"resilience enhanced by innovation and technology\" is the most effective response typology (86.9/100), and that six cities meet the antifragile trajectory criteria. By mapping best practices to activated principles and analysing co-activations, the study identifies a robust \"hard core\" of principles - Sustainable Resilience (O), Strategic Diversity (F), Proactive Innovation (I), and Active Prevention (N) - supplemented by operational enablers (e.g., anticipation, mobilization, shock absorption). The paper concludes by proposing an evidence-based, SDG-aligned operational model that links high-impact principle pairings to measurable indicators, offering a practical roadmap for cities seeking to convert crises into sustained transformation. Keywords: Post-crisis strategies, Urban antifragility, Sustainable cities and communities, Disaster resilience and urban regeneration, Risk governance and Black Swan adaptation."
  },
  {
    "date": "2026-01-15",
    "title": "Multi-Property Synthesis",
    "authors": "Christoph Weinhuber, Yannik Schnitzer, Alessandro Abate, David Parker, Giuseppe De Giacomo, Moshe Y. Vardi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10651v1",
    "source": "arXiv",
    "abstract": "We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relation between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces Boolean goal variables and exploits monotonicity to represent exponentially many goal combinations compactly. Our approach substantially outperforms enumeration-based baselines, with speedups of up to two orders of magnitude."
  },
  {
    "date": "2026-01-15",
    "title": "RoutIR: Fast Serving of Retrieval Pipelines for Retrieval-Augmented Generation",
    "authors": "Eugene Yang, Andrew Yates, Dawn Lawrie, James Mayfield, Trevor Adriaanse",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10644v1",
    "source": "arXiv",
    "abstract": "Retrieval models are key components of Retrieval-Augmented Generation (RAG) systems, which generate search queries, process the documents returned, and generate a response. RAG systems are often dynamic and may involve multiple rounds of retrieval. While many state-of-the-art retrieval methods are available through academic IR platforms, these platforms are typically designed for the Cranfield paradigm in which all queries are known up front and can be batch processed offline. This simplification accelerates research but leaves state-of-the-art retrieval models unable to support downstream applications that require online services, such as arbitrary dynamic RAG pipelines that involve looping, feedback, or even self-organizing agents. In this work, we introduce RoutIR, a Python package that provides a simple and efficient HTTP API that wraps arbitrary retrieval methods, including first stage retrieval, reranking, query expansion, and result fusion. By providing a minimal JSON configuration file specifying the retrieval models to serve, RoutIR can be used to construct and query retrieval pipelines on-the-fly using any permutation of available models (e.g., fusing the results of several first-stage retrieval methods followed by reranking). The API automatically performs asynchronous query batching and caches results by default. While many state-of-the-art retrieval methods are already supported by the package, RoutIR is also easily expandable by implementing the Engine abstract class. The package is open-sourced and publicly available on GitHub: http://github.com/hltcoe/routir."
  },
  {
    "date": "2026-01-15",
    "title": "HII regions in NGC 628: the view of two catalogs",
    "authors": "Ksenia I. Smirnova, Dmitri S. Wiebe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10642v1",
    "source": "arXiv",
    "abstract": "The study is devoted to comparing the parameters of the interstellar medium of HII regions in the Kongiu and Groves catalogs for the galaxy NGC 628. The article analyzes the characteristics of star-forming regions, including a comparison of radiation fluxes in the ranges of 7.7 $μ$m and 21 $μ$m and in the H$α$, H$β$, OIII and CO lines, calculating the kinematic parameters (FWHM) for the lines, and analyzing the spatial distribution of regions for both catalogs. The results of the study showed that the regions from the Groves catalog demonstrate higher line widths compared to the Kongiu catalog. Signs of possible misidentified classification of some regions from the Groves catalog were revealed: there is a possibility that some of them are not HII regions, but shock ionization regions."
  },
  {
    "date": "2026-01-15",
    "title": "Measuring the Coronal Magnetic Field with 2D Coronal Seismology: A Forward-Modeling Validation",
    "authors": "Zihao Yang, Sarah Gibson, Matthias Rempel, Giuliana de Toma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10637v1",
    "source": "arXiv",
    "abstract": "In recent years, a two-dimensional (2D) coronal seismology technique applied to spectral-imaging data from the Coronal Multi-channel Polarimeter (CoMP) and UCoMP has enabled routine measurement of the global coronal magnetic field. The technique combines coronal transverse wave phase speed from Doppler measurements with electron densities from the Fe \\sc{xiii}\\rm{} 10798/10747 Å intensity ratio to infer the magnetic field strength, while the wave propagation directions from Doppler measurements trace the magnetic field direction. To validate the accuracy and robustness of this method, we use forward modeling of a MURaM simulation that produces open and closed magnetic structures with excited waves. From the synthetic Doppler velocity, Fe \\sc{xiii}\\rm{} infrared line intensities, and linear polarization signals, we apply the 2D coronal seismology technique to estimate the magnetic field strength and direction. A comparison with the simulation ground truth shows close agreement, indicating that the technique can recover the line-of-sight emissivity-weighted magnetic field direction and strength with high accuracy. We also perform a parameter-space analysis to quantify sensitivities of the method to parameter choice. These findings provide practical guidance for CoMP/UCoMP-like analysis and demonstrate that 2D coronal seismology can deliver reliable, LOS emissivity-weighted measurements of the coronal magnetic field from coronal wave observations."
  },
  {
    "date": "2026-01-15",
    "title": "WEAVE imaging spectroscopy of NGC 6720: an iron bar in the Ring",
    "authors": "R. Wesson, J. E. Drew, M. J. Barlow, J. García-Rojas, R. Greimel, D. Jones, A. Manchado, R. A. H. Morris, A. Zijlstra, P. J. Storey, J. A. L. Aguerri, S. R. Berlanas, E. Carrasco, G. B. Dalton, E. Gafton, R. García-Benito, A. L. González-Morán, B. Gänsicke, S. Hughes, S. Jin, R. Raddi, R. Sanchez-Janssen, E. Schallig, D. J. B. Smith, S. C. Trager, N. A. Walton",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10635v1",
    "source": "arXiv",
    "abstract": "We present spatially resolved spectroscopic observations of the planetary nebula NGC 6720, the Ring Nebula, taken during the science verification phase of WEAVE, a new instrument mounted on the William Herschel Telescope on La Palma. We use the instrument's Large Integral Field Unit (LIFU) to obtain spectra of the Ring Nebula, covering its entire optically bright inner regions as well as parts of its much fainter outer molecular halo. We report the discovery of emission from [Fe~{\\sc v}] and [Fe~{\\sc vi}] confined to a narrow ``bar'' extending across the central regions of the nebula. No lines of other elements share this morphology or, at the spectral resolving power used ($R \\sim 2500$), the same radial velocity. The extent to which iron in this bar is depleted is presently unclear; comparison with JWST-detected dust continuum emission suggests that some dust grain destruction may be occurring in the region, but there is currently no observational evidence for the $>$ 50~km\\,s$^{-1}$ shock waves or $T > 10^6$~K X-ray emitting gas needed to enable this. Where the bar is located along the line of sight through the nebula, and how it was created, are new puzzles to be solved for this iconic planetary nebula."
  },
  {
    "date": "2026-01-15",
    "title": "Molecularly Thin Polyaramid Nanomechanical Resonators",
    "authors": "Hagen Gress, Cody L. Ritt, Inal Shomakhov, Kaan Altmisdort, Michelle Quien, Zitang Wei, John R. Lawall, Narasimha Boddeti, Michael S. Strano, J. Scott Bunch, Kamil L. Ekinci",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10633v1",
    "source": "arXiv",
    "abstract": "Two-dimensional polyaramids exhibit strong hydrogen bonding to create molecularly thin nanosheets analogous to graphene. Here, we report the first nanomechanical resonators made out of a two-dimensional polyaramid, 2DPA-1, with thicknesses as small as 8 nm. To fabricate these molecular-scale resonators, we transferred nanofilms of 2DPA-1 onto chips with previously etched arrays of circular microwells. We then characterized the thermal resonances of these resonators under different conditions. When there is no residual gas inside the 2DPA-1-covered microwells, the eigenfrequencies are well-described by a tensioned plate theory, providing the Young's modulus and tension of the 2DPA-1 nanofilms. With gas present, the nanofilms bulge up and mechanical resonances are modified due to the adhesion, bulging and slack present in the system. The fabrication and mechanical characterization of these first 2DPA-1 nanomechanical resonators represent a convincing path toward molecular-scale polymeric NEMS with high mechanical strength, low density, and synthetic processability."
  },
  {
    "date": "2026-01-15",
    "title": "Differentially Private Inference for Longitudinal Linear Regression",
    "authors": "Getoar Sopa, Marco Avella Medina, Cynthia Rush",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10626v1",
    "source": "arXiv",
    "abstract": "Differential Privacy (DP) provides a rigorous framework for releasing statistics while protecting individual information present in a dataset. Although substantial progress has been made on differentially private linear regression, existing methods almost exclusively address the item-level DP setting, where each user contributes a single observation. Many scientific and economic applications instead involve longitudinal or panel data, in which each user contributes multiple dependent observations. In these settings, item-level DP offers inadequate protection, and user-level DP - shielding an individual's entire trajectory - is the appropriate privacy notion. We develop a comprehensive framework for estimation and inference in longitudinal linear regression under user-level DP. We propose a user-level private regression estimator based on aggregating local regressions, and we establish finite-sample guarantees and asymptotic normality under short-range dependence. For inference, we develop a privatized, bias-corrected covariance estimator that is automatically heteroskedasticity- and autocorrelation-consistent. These results provide the first unified framework for practical user-level DP estimation and inference in longitudinal linear regression under dependence, with strong theoretical guarantees and promising empirical performance."
  },
  {
    "date": "2026-01-15",
    "title": "Beyond Hubbard: the role of correlated hopping interaction in superconductors and quantum dot devices",
    "authors": "Karol I. Wysokiński, Marcin M. Wysokiński",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10619v1",
    "source": "arXiv",
    "abstract": "We investigate the role of strong Coulomb interactions beyond the standard Hubbard model in two distinct physical contexts. First, we analyze the superconducting phase transition occurring near the Mott metal-insulator transition. Second, we study transport properties of artificial nano-scale structures containing quantum dots coupled to external electrodes. In both cases, we focus on the impact of the correlated (assisted) hopping (CH) interaction. For superconductors, CH acts as a driving mechanism for the phase transition and modifies the spectral properties of the system. We present the evolution of the spectral function as the system approaches the Mott-type transition under varying model parameters. In quantum-dot-based devices, CH influences the tunneling amplitude between the dot and metallic leads. We demonstrate that the characteristic changes in the conductance of a normal metal-quantum dot-normal metal structure provide a clear signature of the presence and sign of CH interaction."
  },
  {
    "date": "2026-01-15",
    "title": "A universal Bochner formula for scalar curvature",
    "authors": "Sven Hirsch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10618v1",
    "source": "arXiv",
    "abstract": "We introduce a universal Bochner formula for scalar curvature that contains, as special cases, the stability inequality for minimal slicings, a Schrödinger-Lichnerowicz-type formula, and a higher-dimensional version of Stern's level-set identity."
  },
  {
    "date": "2026-01-15",
    "title": "Quantitative surgery and total mean curvature",
    "authors": "Georg Frenck, Bernhard Hanke, Sven Hirsch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10617v1",
    "source": "arXiv",
    "abstract": "We develop quantitative surgery, which extends the classical constructions of Gromov--Lawson and Lawson--Michelsohn. As an application, we prove a conjecture of Gromov on the total mean curvature of fill-ins."
  },
  {
    "date": "2026-01-15",
    "title": "On the geometry of aggregate snowflakes",
    "authors": "Axel Seifert, Christoph Siewert, Fabian Jakub, Leonie von Terzi, Stefan Kneifel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10608v1",
    "source": "arXiv",
    "abstract": "Snowflakes play a crucial role in weather and climate. A significant portion of precipitation that reaches the surface originates as ice, even when it ultimately falls as rain. Contrary to the popular image of symmetric, dendritic crystals, most large snowflakes are irregular aggregates formed through the collision of primary ice crystals, such as hexagonal plates, columns, and dendrites. These aggregates exhibit complex, fractal-like structures, particularly at large sizes. Despite this structural complexity, each aggregate snowflake is unique, with properties that vary significantly around the mean - variability that is typically neglected in weather and climate models. Using a physically based aggregation model, we generate millions of synthetic snowflakes to investigate their geometric properties. The resulting dataset reveals that, for a given monomer number (cluster size) and mass, the maximum dimension follows approximately a lognormal distribution. We present a parameterization of aggregate geometry that captures key statistical properties, including maximum dimension, aspect ratio, cross-sectional area, and their joint correlations. This formulation enables a stochastic representation of aggregate snowflakes in Lagrangian particle models. Incorporating this variability improves the realism of simulated fall velocities, enhances growth rates by aggregation, and broadens Doppler radar spectra in closer agreement with observations."
  },
  {
    "date": "2026-01-15",
    "title": "RSATalker: Realistic Socially-Aware Talking Head Generation for Multi-Turn Conversation",
    "authors": "Peng Chen, Xiaobao Wei, Yi Yang, Naiming Yao, Hui Chen, Feng Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10606v1",
    "source": "arXiv",
    "abstract": "Talking head generation is increasingly important in virtual reality (VR), especially for social scenarios involving multi-turn conversation. Existing approaches face notable limitations: mesh-based 3D methods can model dual-person dialogue but lack realistic textures, while large-model-based 2D methods produce natural appearances but incur prohibitive computational costs. Recently, 3D Gaussian Splatting (3DGS) based methods achieve efficient and realistic rendering but remain speaker-only and ignore social relationships. We introduce RSATalker, the first framework that leverages 3DGS for realistic and socially-aware talking head generation with support for multi-turn conversation. Our method first drives mesh-based 3D facial motion from speech, then binds 3D Gaussians to mesh facets to render high-fidelity 2D avatar videos. To capture interpersonal dynamics, we propose a socially-aware module that encodes social relationships, including blood and non-blood as well as equal and unequal, into high-level embeddings through a learnable query mechanism. We design a three-stage training paradigm and construct the RSATalker dataset with speech-mesh-image triplets annotated with social relationships. Extensive experiments demonstrate that RSATalker achieves state-of-the-art performance in both realism and social awareness. The code and dataset will be released."
  },
  {
    "date": "2026-01-15",
    "title": "Translating database mathematical schemes into relational database software applications with MatBase",
    "authors": "Christian Mancas, Diana Christina Mancas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10604v1",
    "source": "arXiv",
    "abstract": "We present a pseudocode algorithm for translating our (Elementary) Mathematical Data Model schemes into relational ones and associated sets of non-relational constraints, used by MatBase, our intelligent database management system prototype. We prove that this algorithm is very fast, solid, complete, and optimal. We apply it to a mathematical scheme modeling the genealogical trees subuniverse. We also provide examples of SQL and VBA code for enforcing some of its non-relational constraints, as well as guidelines to develop code for enforcing such constraints."
  },
  {
    "date": "2026-01-15",
    "title": "High-fidelity stellar extinction with Gaia and APOGEE -- I. The method and a new extinction curve",
    "authors": "Jie Yu, Luca Casagrande, John A. Taylor, Ioana Ciucă, Giacomo Cordoni, Ronald Drimmel, Shourya Khanna, Hiep Nguyen, Tomasz Różański, Dennis Stello, Haibo Yuan, Zhen Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10595v1",
    "source": "arXiv",
    "abstract": "The scarcity of high-fidelity extinction measurements remains a bottleneck in deriving accurate stellar properties from Gaia parallaxes. In this work, we aim to derive precision extinction estimates for APOGEE DR19 stars, establishing a new benchmark for Galactic stellar population studies. We first determine reddening by comparing observed colorsr, etrieved from photometric surveys or standardized synthetic magnitudes from Gaia BP/RP spectra, to intrinsic colors predicted via an XGBoost model. The model is trained on minimally reddened stars to infer intrinsic colors and their associated uncertainties, using APOGEE stellar parameters (Teff, logg, [Fe/H], and [alpha/Fe]). The derived reddening values are then converted into extinctions using an anchor ratio of A_BP / A_RP = 1.694 +/- 0.004, derived from red-clump-like stars. Here, we provide extinction measurements in 39 filters across 10 photometric systems and introduce a new empirical extinction curve optimized for broadband passbands. Our extinction estimates (Av) outperform existing results (Bayestar19, StarHorse, SEDEX), achieving a typical precision of 0.03 mag in Av. Notably, we identify systematic deviations of up to 30% between monochromatic and passband-integrated extinction ratios at wavelengths greater than 700 nm. This result highlights the necessity of adopting passband-specific coefficients when correcting extinction to derive stellar parameters. As the foundation for a forthcoming series of papers, these benchmark measurements will be used to (1) revise asteroseismic scaling relations, (2) calibrate differential reddening in open clusters, and (3) reconcile heterogeneous dust maps into a unified, all-sky extinction scheme."
  },
  {
    "date": "2026-01-15",
    "title": "Mind the gap: A real-valued distance on combinatorial games",
    "authors": "Kyle Burke, Michael Fisher, Craig Tennenhouse",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10574v1",
    "source": "arXiv",
    "abstract": "We define a real-valued distance metric $wd$ on the space $\\mathcal{C}$ of short combinatorial games in canonical form. We demonstrate the existence of Cauchy sequences informed by sidling sequences, find limit points, and investigate the closure $\\overline{\\mathcal{C}}$, which is shown to partition the set of loopy games in a non-trivial way. Stoppers, enders, and non-stopper-sided loopy games are explored, as well as the topological properties of $(\\mathcal{C},wd)$."
  },
  {
    "date": "2026-01-15",
    "title": "Canonical Vorticity Perspective on Magnetogenesis: Unifying Weibel, Biermann, and Beyond",
    "authors": "Modhuchandra Laishram, Young Dae Yoon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10570v1",
    "source": "arXiv",
    "abstract": "We briefly review the current status of magnetogenesis, a cross-disciplinary field that bridges cosmology and plasma physics, studying the origin of magnetic fields in the universe. We formulate a canonical vorticity framework to investigate kinetic plasma physics-based magnetogenesis processes in a collisionless plasma. By considering canonical vorticity, a weighted sum of the fluid vorticity and the magnetic field as the canonical variable, this framework unifies several magnetogenesis processes, including the Biermann battery, the Weibel instability, and predicts several new pressure tensorial configurations as the fundamental source of self-generated magnetic field and vorticity in plasma. The framework is further extended to relativistic regime where an additional source of canonical vorticity, termed as kineclinicity effect, is identified. The theoretical predictions are systematically validated using particle-in-cell simulations, highlighting their implications for laboratory and astrophysical plasma environments."
  },
  {
    "date": "2026-01-15",
    "title": "Process-Guided Concept Bottleneck Model",
    "authors": "Reza M. Asiyabi, SEOSAW Partnership, Steven Hancock, Casey Ryan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10562v1",
    "source": "arXiv",
    "abstract": "Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we propose the Process-Guided Concept Bottleneck Model (PG-CBM), an extension of CBMs which constrains learning to follow domain-defined causal mechanisms through biophysically meaningful intermediate concepts. Using above ground biomass density estimation from Earth Observation data as a case study, we show that PG-CBM reduces error and bias compared to multiple benchmarks, whilst leveraging multi-source heterogeneous training data and producing interpretable intermediate outputs. Beyond improved accuracy, PG-CBM enhances transparency, enables detection of spurious learning, and provides scientific insights, representing a step toward more trustworthy AI systems in scientific applications."
  },
  {
    "date": "2026-01-15",
    "title": "Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems",
    "authors": "Xi Shi, Mengxin Zheng, Qian Lou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10560v1",
    "source": "arXiv",
    "abstract": "Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. In this work, we investigate learning-based orchestration of multi-agent systems with explicit latency supervision under parallel execution. We propose Latency-Aware Multi-agent System (LAMaS), a latency-aware multi-agent orchestration framework that enables parallel execution and explicitly optimizes the critical execution path, allowing the controller to construct execution topology graphs with lower latency under parallel execution. Our experiments show that our approach reduces critical path length by 38-46% compared to the state-of-the-art baseline for multi-agent architecture search across multiple benchmarks, while maintaining or even improving task performance. These results highlight the importance of explicitly optimizing latency under parallel execution when designing efficient multi-agent systems. The code is available at https://github.com/xishi404/LAMaS"
  },
  {
    "date": "2026-01-15",
    "title": "Chebyshev Accelerated Subspsace Eigensolver for Pseudo-hermitian Hamiltonians",
    "authors": "Edoardo Di Napoli, Clément Richefort, Xinzhe Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10557v1",
    "source": "arXiv",
    "abstract": "Studying the optoelectronic structure of materials can require the computation of up to several thousands of the smallest eigenpairs of a pseudo-hermitian Hamiltonian. Iterative eigensolvers may be preferred over direct methods for this task since their complexity is a function of the desired fraction of the spectrum. In addition, they generally rely on highly optimized and scalable kernels such as matrix-vector multiplications that leverage the massive parallelism and the computational power of modern exascale systems. \\textit{Chebyshev Accelerated Subspace iteration Eigensolver} (ChASE) is able to compute several thousands of the most extreme eigenpairs of dense hermitian matrices with proven scalability over massive parallel accelerated clusters. This work presents an extension of ChASE to solve for a portion of the spectrum of pseudo-hermitian Hamiltonians as they appear in the treatment of excitonic materials. The new pseudo-hermitian solver achieves similar convergence and performance as the hermitian one. By exploiting the numerical structure and spectral properties of the Hamiltonian matrix, we propose an oblique variant of Rayleigh-Ritz projection featuring quadratic convergence of the Ritz-values with no explicit construction of the dual basis set. Additionally, we introduce a parallel implementation of the recursive matrix-product operation appearing in the Chebyshev filter with limited amount of global communications. Our development is supported by a full numerical analysis and experimental tests."
  },
  {
    "date": "2026-01-15",
    "title": "causalfe: Causal Forests with Fixed Effects in Python",
    "authors": "Harry Aytug",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10555v1",
    "source": "arXiv",
    "abstract": "The causalfe package provides a Python implementation of Causal Forests with Fixed Effects (CFFE) for estimating heterogeneous treatment effects in panel data settings. Standard causal forest methods struggle with panel data because unit and time fixed effects induce spurious heterogeneity in treatment effect estimates. The CFFE approach addresses this by performing node-level residualization during tree construction, removing fixed effects within each candidate split rather than globally. This paper describes the methodology, documents the software interface, and demonstrates the package through simulation studies that validate the estimator's performance under various data generating processes."
  },
  {
    "date": "2026-01-15",
    "title": "DeepUrban: Interaction-Aware Trajectory Prediction and Planning for Automated Driving by Aerial Imagery",
    "authors": "Constantin Selzer, Fabian B. Flohr",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10554v1",
    "source": "arXiv",
    "abstract": "The efficacy of autonomous driving systems hinges critically on robust prediction and planning capabilities. However, current benchmarks are impeded by a notable scarcity of scenarios featuring dense traffic, which is essential for understanding and modeling complex interactions among road users. To address this gap, we collaborated with our industrial partner, DeepScenario, to develop DeepUrban-a new drone dataset designed to enhance trajectory prediction and planning benchmarks focusing on dense urban settings. DeepUrban provides a rich collection of 3D traffic objects, extracted from high-resolution images captured over urban intersections at approximately 100 meters altitude. The dataset is further enriched with comprehensive map and scene information to support advanced modeling and simulation tasks. We evaluate state-of-the-art (SOTA) prediction and planning methods, and conducted experiments on generalization capabilities. Our findings demonstrate that adding DeepUrban to nuScenes can boost the accuracy of vehicle predictions and planning, achieving improvements up to 44.1 % / 44.3% on the ADE / FDE metrics. Website: https://iv.ee.hm.edu/deepurban"
  },
  {
    "date": "2026-01-15",
    "title": "Numerical simulations of oscillating and differentially rotating neutron stars",
    "authors": "Santiago Jaraba, Jérôme Novak, Micaela Oertel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10550v1",
    "source": "arXiv",
    "abstract": "The remnants of binary neutron star mergers are expected to be massive, rapidly rotating stars whose oscillations produce gravitational waves in the kilohertz band. The degree of differential rotation and the rotation profiles strongly influence their structure, stability and oscillation spectrum, and must therefore be taken into account when modeling their dynamics. We extend the pseudospectral code ROXAS (Relativistic Oscillations of non-aXisymmetric neutron stArS) to enable the dynamical evolution of oscillating, differentially rotating neutron stars. Using the updated code, we aim to study the star's oscillation frequencies. We extend the previous formalism, based on primitive variables and the conformal flatness approximation, to differential rotation. Within this framework, we run a series of axisymmetric and non-axisymmetric simulations of perturbed, differentially rotating neutron stars with different rotation rates, and extract their oscillation frequencies. Axisymmetric modes, as well as those under the Cowling approximation, show excellent agreement with published results. We show that the secondary fundamental mode in the Cowling approximation is an artifact that does not appear in dynamical spacetimes. In addition, we provide, for the first time, frequency values for non-axisymmetric modes in differentially rotating configurations evolved in conformal flatness. This extension broadens the range of physical scenarios that can be studied with ROXAS, and represents a step toward more realistic modeling of post-merger remnants and their gravitational-wave emission."
  },
  {
    "date": "2026-01-15",
    "title": "Linear independence properties of the signature components of time-augmented stochastic processes",
    "authors": "Arthur Bourdon, Benjamin Jourdain, Hervé Andrès",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10545v1",
    "source": "arXiv",
    "abstract": "The addition of the running time as a component of a path before computing its signature is a widespread approach to ensure the one-to-one property between them and leads to universal approximation theorems (Cuchiero, Primavera and Svaluto-Ferro, 2023). However, this also leads to the linear dependence of the components of the terminal value of the signature of the time-augmented path. More precisely, for a given natural number $N$, the signature components associated with words of length $N$ have the same linear span as the signature components associated with words of length not greater than $N$. We generalize this result by exhibiting other subfamilies of signature components with the same spanning properties. In particular we recover the result of Dupire and Tissot-Daguette which states that the spanning of the iterated integrals with the last integrator different from the time variable is the same as the spanning of all iterated integrals. We check that this choice leads to the minimal computation time when the terms of the signature are calculated using Chen's relation in a backward way. The same optimal computation time is symmetrically achieved in a forward way for the iterated integrals with the first integrator different from the time variable. Building on these results, we derive several results regarding the linear independence of the signature components of a time-augmented stochastic process. We show that if the stochastic process we consider is solution to some SDE with additive Brownian noise then any subfamily of components proposed previously is linearly independent. We also prove that the linear independence of these subfamilies of components is still true when we consider the discretization of the sample paths of this stochastic process on a grid with a sufficiently small discretization time step."
  },
  {
    "date": "2026-01-15",
    "title": "Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing",
    "authors": "Yinzhi Zhao, Ming Wang, Shi Feng, Xiaocui Yang, Daling Wang, Yifei Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10543v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have achieved impressive performance across natural language tasks and are increasingly deployed in real-world applications. Despite extensive safety alignment efforts, recent studies show that such alignment is often shallow and remains vulnerable to jailbreak attacks. Existing defense mechanisms, including decoding-based constraints and post-hoc content detectors, struggle against sophisticated jailbreaks, often intervening robust detection or excessively degrading model utility. In this work, we examine the decoding process of LLMs and make a key observation: even when successfully jailbroken, models internally exhibit latent safety-related signals during generation. However, these signals are overridden by the model's drive for fluent continuation, preventing timely self-correction or refusal. Building on this observation, we propose a simple yet effective approach that explicitly surfaces and leverages these latent safety signals for early detection of unsafe content during decoding. Experiments across diverse jailbreak attacks demonstrate that our approach significantly enhances safety, while maintaining low over-refusal rates on benign inputs and preserving response quality. Our results suggest that activating intrinsic safety-awareness during decoding offers a promising and complementary direction for defending against jailbreak attacks. Code is available at: https://github.com/zyz13590/SafeProbing."
  },
  {
    "date": "2026-01-15",
    "title": "Mixtures of Transparent Local Models",
    "authors": "Niffa Cheick Oumar Diaby, Thierry Duchesne, Mario Marchand",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10541v1",
    "source": "arXiv",
    "abstract": "The predominance of machine learning models in many spheres of human activity has led to a growing demand for their transparency. The transparency of models makes it possible to discern some factors, such as security or non-discrimination. In this paper, we propose a mixture of transparent local models as an alternative solution for designing interpretable (or transparent) models. Our approach is designed for the situations where a simple and transparent function is suitable for modeling the label of instances in some localities/regions of the input space, but may change abruptly as we move from one locality to another. Consequently, the proposed algorithm is to learn both the transparent labeling function and the locality of the input space where the labeling function achieves a small risk in its assigned locality. By using a new multi-predictor (and multi-locality) loss function, we established rigorous PAC-Bayesian risk bounds for the case of binary linear classification problem and that of linear regression. In both cases, synthetic data sets were used to illustrate how the learning algorithms work. The results obtained from real data sets highlight the competitiveness of our approach compared to other existing methods as well as certain opaque models. Keywords: PAC-Bayes, risk bounds, local models, transparent models, mixtures of local transparent models."
  },
  {
    "date": "2026-01-15",
    "title": "Error-Correcting Codes for Two Bursts of t1-Deletion-t2-Insertion with Low Computational Complexity",
    "authors": "Yajuan Liu, Tolga M. Duman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10540v1",
    "source": "arXiv",
    "abstract": "Burst errors involving simultaneous insertions, deletions, and substitutions occur in practical scenarios, including DNA data storage and document synchronization, motivating developments of channel codes that can correct such errors. In this paper, we address the problem of constructing error-correcting codes (ECCs) capable of handling multiple bursts of $t_1$-deletion-$t_2$-insertion ($(t_1,t_2)$-DI) errors, where each burst consists of $t_1$ deletions followed by $t_2$ insertions in a binary sequence. We make three key contributions: Firstly, we establish the fundamental equivalence of (1) two bursts of $(t_1,t_2)$-DI ECCs, (2) two bursts of $(t_2,t_1)$-DI ECCs, and (3) one burst each of $(t_1,t_2)$-DI and $(t_2,t_1)$-DI ECCs. Then, we derive lower and upper bounds on the code size of two bursts of $(t_1,t_2)$-DI ECCs, which can naturally be extended to the case of multiple bursts. Finally, we present constructions of two bursts of $(t_1,t_2)$-DI ECCs. Compared to the codes obtained by the syndrome compression technique, the resulting codes achieve significantly lower computational complexity."
  },
  {
    "date": "2026-01-15",
    "title": "Smoothness of martingale observables and generalized Feynman-Kac formulas",
    "authors": "Alex Karrila, Lauri Viitasaari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10539v1",
    "source": "arXiv",
    "abstract": "We prove that, under the Hörmander criterion on an Itô process, all its martingale observables are smooth. As a consequence, we also obtain a generalized Feynman-Kac formula providing smooth solutions to certain PDE boundary-value problems, while allowing for degenerate diffusions as well as boundary stopping (under very mild boundary regularity assumptions). We also highlight an application to a question posed on Schramm-Loewner evolutions, by making certain Girsanov transform martingales accessible via Itô calculus."
  },
  {
    "date": "2026-01-15",
    "title": "Network Integrated Sensing and Communication",
    "authors": "Edward Andrews, Lawrence Ong, Duy T. Ngo, Yao Liu, Min Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10538v1",
    "source": "arXiv",
    "abstract": "Integrated sensing and communication (ISAC) is a cornerstone technology for 6G networks, offering unified support for high-rate communication and high-accuracy sensing. While existing literature extensively covers link-level designs, the transition toward large-scale deployment necessitates a fundamental understanding of network-level performance. This paper investigates a network ISAC model where a source node communicates with a destination via a relay network, while intermediate nodes concurrently perform cooperative sensing over specific spatial regions. We formulate a novel optimization framework that captures the interplay between multi-node routing and sensing coverage. For a one-dimensional path network, we provide an analytical characterization of the complete sensing-throughput region. Extending this to general network topologies, we establish that the sensing-throughput Pareto boundary is piecewise linear and provide physical interpretations for each segment. Our results reveal the fundamental trade-offs between sensing coverage and communication routing, offering key insights for the design of future 6G heterogeneous networks."
  },
  {
    "date": "2026-01-15",
    "title": "Topologically switchable transport in a bundled cable of wires",
    "authors": "Nirnoy Basak, Ritajit Kundu, Basudeb Mondal, Adhip Agarwala",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10534v1",
    "source": "arXiv",
    "abstract": "Advances in the next generation of mesoscopic electronics require an understanding of topological phases in inhomogeneous media and the principles that govern them. Motivated by the nature of motifs available in printable conducting inks, we introduce and study quantum transport in a minimal model that describes a bundle of one-dimensional metallic wires that are randomly interconnected by semiconducting chains. Each of these interconnects is represented by a Su-Schrieffer-Heeger chain, which can reside in either a trivial or a topological phase. Using a tight-binding approach, we show that such a system can transit from an insulating phase to a robust metallic phase as the interconnects undergo a transition from a trivial to a topological phase. In the latter, despite the random interconnectedness, the metal evades Anderson localization and exhibits a ballistic conductance that scales linearly with the number of wires. We show that this behavior originates from hopping renormalization in the wire network. The zero-energy modes of the topological interconnects act as effective random dimers, giving rise to an energy-dependent localization length that diverges as $\\sim 1/E^2$. Our work establishes that random networks provide a yet-unexplored platform to host intriguing phases of topological quantum matter."
  },
  {
    "date": "2026-01-15",
    "title": "Three realization problems about univariate polynomials",
    "authors": "Vladimir Petrov Kostov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10529v1",
    "source": "arXiv",
    "abstract": "We consider three realization problems about monic real univariate polynomials without vanishing coefficients. Such a polynomial $P:=\\sum_{j=0}^db_jx^j$ defines the sign pattern $σ(P):=({\\rm sgn}(b_d)$, $\\ldots$, ${\\rm sgn}(b_0))$. The numbers $p_d$ and $n_d$ of positive and negative roots of $P$ (counted with multiplicity) satisfy the Descartes' rule of signs. Problem~1 asks for which couples $C$ of the form (sign pattern $σ$, pair $(p_d,n_d)$ compatible with $σ$ in the sense of Descartes' rule of signs), there exist polynomials $P$ defining these couples. Problem~2 asks for which $d$-tuples of pairs $T:=((p_d,n_d)$, $\\ldots$, $(p_1,n_1))$, there exist polynomials $P$ such that $P^{(d-j)}$ has $p_j$ positive and $n_j$ negative roots. A $d$-tuple $T$ determines the sign pattern $σ(P)$, but the inverse is false. We show by an example that $6$ is the smallest value of $d$ for which there exist non-realizable tuples $T$ for which the corresponding couples $C$ are realizable. The third problem concerns polynomials with all roots real. We give a geometric interpretation of the three problems in the context of degree $4$ polynomials."
  },
  {
    "date": "2026-01-15",
    "title": "A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5",
    "authors": "Xingjun Ma, Yixu Wang, Hengyuan Xu, Yutao Wu, Yifan Ding, Yunhan Zhao, Zilong Wang, Jiabin Hua, Ming Wen, Jianan Liu, Ranjie Duan, Yifeng Gao, Yingshui Tan, Yunhao Chen, Hui Xue, Xin Wang, Wei Cheng, Jingjing Chen, Zuxuan Wu, Bo Li, Yu-Gang Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10527v1",
    "source": "arXiv",
    "abstract": "The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has produced substantial gains in reasoning, perception, and generative capability across language and vision. However, whether these advances yield commensurate improvements in safety remains unclear, in part due to fragmented evaluation practices limited to single modalities or threat models. In this report, we present an integrated safety evaluation of 7 frontier models: GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5. We evaluate each model across language, vision-language, and image generation settings using a unified protocol that integrates benchmark evaluation, adversarial evaluation, multilingual evaluation, and compliance evaluation. Aggregating our evaluations into safety leaderboards and model safety profiles across multiple evaluation modes reveals a sharply heterogeneous safety landscape. While GPT-5.2 demonstrates consistently strong and balanced safety performance across evaluations, other models exhibit pronounced trade-offs among benchmark safety, adversarial alignment, multilingual generalization, and regulatory compliance. Both language and vision-language modalities show significant vulnerability under adversarial evaluation, with all models degrading substantially despite strong results on standard benchmarks. Text-to-image models achieve relatively stronger alignment in regulated visual risk categories, yet remain brittle under adversarial or semantically ambiguous prompts. Overall, these results show that safety in frontier models is inherently multidimensional--shaped by modality, language, and evaluation scheme, underscoring the need for standardized safety evaluations to accurately assess real-world risk and guide responsible model development and deployment."
  },
  {
    "date": "2026-01-15",
    "title": "Transformer-Based Cognitive Radio: Adaptive Modulation Strategies Using Transformer Models",
    "authors": "Andrea Melis, Andrea Piroddi, Roberto Girau",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10519v1",
    "source": "arXiv",
    "abstract": "Cognitive Radio (CR) systems, which dynamically adapt to changing spectrum environments, could benefit significantly from advancements in machine learning technologies. These systems can be enhanced in terms of spectral efficiency, robustness, and security through innovative approaches such as the use of Transformer models. This work investigates the application of Transformer models, specifically the GPT-2 architecture, to generate novel modulation schemes for wireless communications. By training a GPT-2 model on a dataset of existing modulation formulas, new modulation schemes has been created. These generated schemes are then compared to traditional methods using key performance metrics such as Signal-to-Noise Ratio (SNR) and Power Spectrum Density (PSD). The results show that Transformer-generated modulation schemes can achieve performance comparable to, and in some cases outperforming, traditional methods. This demonstrates that advanced CR systems could greatly benefit from the implementation of Transformer models, leading to more efficient, robust, and secure communication systems."
  },
  {
    "date": "2026-01-15",
    "title": "Emergence of unconventional magnetic order in strain-engineered RuO2/TiO2 superlattices",
    "authors": "Seung Gyo Jeong, Seungjun Lee, Jin Young Oh, Bonnie Y. X. Lin, Anand Santhosh, James M. LeBeau, Alexander J. Grutter, Woo Seok Choi, Tony Low, Valeria Lauter, Bharat Jalan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10518v1",
    "source": "arXiv",
    "abstract": "The spin ordering in RuO2 remains a highly debated topic, owing to its elusive nature, with reports ranging from a nonmagnetic ground state to signatures of unconventional magnetic order. Here we provide the first unambiguous, and direct evidence of unconventional magnetism in epitaxial, fully strained RuO2/TiO2 superlattices on TiO2 (110) substrate grown by hybrid molecular beam epitaxy. Polarized neutron reflectometry reveals a finite magnetic moment localized within the compressively strained RuO2 layers, consistent with predictions obtained from first-principles calculations. Complementary density functional theory and X-ray photoemission spectroscopy show that epitaxial strain drives the Ru 4d states toward the Fermi level, triggering a Stoner-type instability that stabilizes non-compensated magnetic order. These unique results reveal that RuO2 exhibits unconventional magnetic states under epitaxial strain, which are not accessible in bulk and establish strain engineering as a powerful route to uncover and control magnetic phases in RuO2 and related oxides."
  },
  {
    "date": "2026-01-15",
    "title": "Incipient modulated phase in Sr$_{1-x}$Ca$_{x}$TiO$_3$",
    "authors": "Benoît Fauqué, Daniel A. Chaney, Philippe Bourges, Stéphane Raymond, Arno Hiess, Paul Steffens, Benoît Baptiste, Luigi Paolasini, Alexeï Bosak, Kamran Behnia, Yasuhide Tomioka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10516v1",
    "source": "arXiv",
    "abstract": "Nanometer-scale modulations can spontaneously emerge in complex materials when multiple degrees of freedom interact. Here we demonstrate that ferroelectric Sr$_{1-x}$Ca$_x$TiO$_3$ lies in close proximity to an incipient structurally modulated phase. Using inelastic neutron and X-ray scattering, we show that upon cooling, dipolar fluctuations strongly couple to and soften the $c_{44}$ transverse acoustic mode. We identify the wavevector at which this softening is maximal, thereby defining the characteristic length scale of the modulation. Calcium substitution enhances both the amplitude and the wavevector of the softening by strengthening the ferroelectric and antiferrodistortive instabilities. Our results demonstrate that nonlinear flexoelectric phonon coupling tends to stabilize a modulated state that cooperates with, rather than competes against, the other lattice instabilities in SrTiO$_3$."
  },
  {
    "date": "2026-01-15",
    "title": "Testing three models of cognitive stress effects: A psychopharmacological randomized controlled trial of acute stress and stress hormones across visual perception, response inhibition and cognitive flexibility",
    "authors": "Lisa Weckesser, Charlotte Grosskopf, Benjamin Weber, Selen Soylu, Tanja Endrass, Robert Miller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10515v1",
    "source": "arXiv",
    "abstract": "Acute stress alters cognitive performance, yet competing models make divergent predictions regarding the mechanisms, scope, and temporal dynamics of these effects. This large-scale randomized controlled trial tested predications from three influential stress-effect models using a broad cognitive task battery embedded within a psychopharmacological stress paradigm. Across 606 testing sessions, 303 healthy male participants completed both the Maastricht Acute Stress Test (MAST) and its non-stress control condition. To independently manipulate acute stress and stress hormone availability, participants were additionally randomized to receive atomoxetine (40 mg; to prolong norepinephrine availability), hydrocortisone (10 mg; to increase cortisol availability), or placebo. Cognitive performance was assessed over 80-minutes (post-stress) using tasks targeting visual perception (rapid serial visual presentation), response inhibition (stop-signal), and cognitive flexibility (dual and switch tasks). MAST exposure selectively impaired response inhibition, reflected in shorter stop-signal delays, lower probabilities of successful stopping and prolonged stop-signal reaction times, particularly during later testing phases (40-80 minutes post-stress). MAST exposure did not affect visual perception or task-switching performance but buffered time-related declines in processing efficiency at the expense of task prioritization in the dual task. Pharmacological manipulation of norepinephrine or cortisol availability was effective but did not moderate cognitive stress effects. Overall, this pattern of task-specific impairment alongside stabilized processing efficiency cannot be fully explained by any tested model, highlighting the need to refine existing models and adopt more integrative approaches to advance our mechanistic understanding of cognitive stress-effects in laboratory and real-world contexts."
  },
  {
    "date": "2026-01-15",
    "title": "AEQ-Bench: Measuring Empathy of Omni-Modal Large Models",
    "authors": "Xuan Luo, Lewei Yao, Libo Zhao, Lanqing Hong, Kai Chen, Dehua Tao, Daxin Tan, Ruifeng Xu, Jing Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10513v1",
    "source": "arXiv",
    "abstract": "While the automatic evaluation of omni-modal large models (OLMs) is essential, assessing empathy remains a significant challenge due to its inherent affectivity. To investigate this challenge, we introduce AEQ-Bench (Audio Empathy Quotient Benchmark), a novel benchmark to systematically assess two core empathetic capabilities of OLMs: (i) generating empathetic responses by comprehending affective cues from multi-modal inputs (audio + text), and (ii) judging the empathy of audio responses without relying on text transcription. Compared to existing benchmarks, AEQ-Bench incorporates two novel settings that vary in context specificity and speech tone. Comprehensive assessment across linguistic and paralinguistic metrics reveals that (1) OLMs trained with audio output capabilities generally outperformed models with text-only outputs, and (2) while OLMs align with human judgments for coarse-grained quality assessment, they remain unreliable for evaluating fine-grained paralinguistic expressiveness."
  },
  {
    "date": "2026-01-15",
    "title": "SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction",
    "authors": "Kanak Mazumder, Fabian B. Flohr",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10512v1",
    "source": "arXiv",
    "abstract": "Online high-definition (HD) map construction is an essential part of a safe and robust end-to-end autonomous driving (AD) pipeline. Onboard camera-based approaches suffer from limited depth perception and degraded accuracy due to occlusion. In this work, we propose SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations and directly predicts a vectorized HD map for downstream prediction and planning modules. Our method leverages lane-level semantics and texture from satellite imagery captured from a Bird's Eye View (BEV) perspective as a global prior, effectively mitigating depth ambiguity and occlusion. In our experiments on the nuScenes dataset, SatMap achieves 34.8% mAP performance improvement over the camera-only baseline and 8.5% mAP improvement over the camera-LiDAR fusion baseline. Moreover, we evaluate our model in long-range and adverse weather conditions to demonstrate the advantages of using a satellite prior map. Source code will be available at https://iv.ee.hm.edu/satmap/."
  },
  {
    "date": "2026-01-15",
    "title": "A New Construction Structure on Coded Caching with Linear Subpacketization: Non-Half-Sum Latin Rectangle",
    "authors": "Yongcheng Yang, Minquan Cheng, Kai Wan, Giuseppe Caire",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10505v1",
    "source": "arXiv",
    "abstract": "Coded caching is recognized as an effective method for alleviating network congestion during peak periods by leveraging local caching and coded multicasting gains. The key challenge in designing coded caching schemes lies in simultaneously achieving low subpacketization and low transmission load. Most existing schemes require exponential or polynomial subpacketization levels, while some linear subpacketization schemes often result in excessive transmission load. Recently, Cheng et al. proposed a construction framework for linear coded caching schemes called Non-Half-Sum Disjoint Packing (NHSDP), where the subpacketization equals the number of users $K$. This paper introduces a novel combinatorial structure, termed the Non-Half-Sum Latin Rectangle (NHSLR), which extends the framework of linear coded caching schemes from $F=K$ (i.e., the construction via NHSDP) to a broader scenario with $F=\\mathcal{O}(K)$. By constructing NHSLR, we have obtained a new class of coded caching schemes that achieves linearly scalable subpacketization, while further reducing the transmission load compared with the NHSDP scheme. Theoretical and numerical analyses demonstrate that the proposed schemes not only achieves lower transmission load than existing linear subpacketization schemes but also approaches the performance of certain exponential subpacketization schemes."
  },
  {
    "date": "2026-01-15",
    "title": "Coded Caching for Combinatorial Multi-Access Hotplug Networks from $t$-Designs",
    "authors": "Dhruv Pratap Singh, Anjana A. Mahesh, B. Sundar Rajan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10503v1",
    "source": "arXiv",
    "abstract": "We study hotplug coded caching in combinatorial multi-access networks, which generalizes existing hotplug coded caching models by allowing users to access multiple caches, while only a subset of caches is online during the delivery phase. We first generalize the Hotplug Placement Delivery Array (HpPDA) framework to the combinatorial multi-access setting. Based on this generalized framework, we propose a t-design-based coded caching scheme for combinatorial multi-access networks. We characterize a class of design parameters under which every active user has access to a sufficient number of coded subfiles to decode its requested file, and show that appropriate parameter choices allow for the elimination of redundant multicast transmissions. As a result, the proposed scheme achieves a family of rate memory trade offs with flexible subpacketization. We present numerical comparisons illustrating that the proposed t-scheme outperforms existing hotplug coded caching schemes in certain memory regimes."
  },
  {
    "date": "2026-01-15",
    "title": "Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning",
    "authors": "Nilin Abrahamsen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10498v1",
    "source": "arXiv",
    "abstract": "This note introduces Projected Microbatch Accumulation (PROMA), a proximal policy update method for large language model fine-tuning. PROMA accumulates policy gradients across microbatches by projecting out sequence-wise gradient components before microbatch aggregation. The projection is applied layer-wise during the backward pass, enabling efficient implementation without additional forward or backward passes. Empirically, PROMA enforces tighter control of local KL divergence than GRPO, resulting in more stable policy learning. Unlike PPO and GRPO, PROMA achieves proximal updates without inducing entropy collapse and does not rely on a reference policy or likelihood-ratio clipping."
  },
  {
    "date": "2026-01-15",
    "title": "Magnetic field-induced phases in a model S=1 Haldane chain system",
    "authors": "I. Jakovac, M. S. Grbić, M. Dupont, N. Laflorencie, S. Capponi, Y. Hosokoshi, S. Krämer, Y. Skourski, S. Luther M. Takigawa, M. Horvatić",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10489v1",
    "source": "arXiv",
    "abstract": "An $S=1$ Haldane chain is a one-dimensional (1D) quantum magnet where strong fluctuations result in quantum disordered singlet ground state with a gapped excitation spectrum. The gap magnitude is primarily set by the dominant intrachain interaction ($J_\\text{1D}$). An applied magnetic field closes the gap at $B_\\text{c1}$ and drives the system into a gapless Tomonaga-Luttinger liquid (TLL) regime, followed by, at lower temperatures, a Bose-Einstein condensate (BEC) ground state, persisting up to $B_\\text{c2} \\propto 4 J_\\text{1D}/gμ_B$. Almost all previously studied experimental realizations of such systems were based on transition-metal complexes which typically suffer from intrinsic anisotropies or large $J_\\text{1D}$ values, limiting the access to the full theoretical phase diagram. We report a comprehensive study of TLL and BEC phases in the organic Haldane chain system 3,5-bis(N-tert-butylaminoxyl)-3'-nitrobiphenyl (BoNO). The absence of anisotropy and a moderate $J_\\text{1D}$ enable exploration of the complete $B-T$ phase diagram. Through $^1$H nuclear magnetic resonance, combined with theoretical analysis, we characterize the TLL properties, map the BEC phase boundary $T_c (B)$, determine the associated critical exponent $ν\\approx 0.66$ at $B_\\text{c2}$, and demonstrate universal quasiparticle scaling in the quantum-critical regime. These results provide full experimental validation of theoretical predictions for field-induced phases in an $S=1$ Haldane chain, made over two decades ago."
  },
  {
    "date": "2026-01-15",
    "title": "High-Dimensional Analysis of Gradient Flow for Extensive-Width Quadratic Neural Networks",
    "authors": "Simon Martin, Giulio Biroli, Francis Bach",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10483v1",
    "source": "arXiv",
    "abstract": "We study the high-dimensional training dynamics of a shallow neural network with quadratic activation in a teacher-student setup. We focus on the extensive-width regime, where the teacher and student network widths scale proportionally with the input dimension, and the sample size grows quadratically. This scaling aims to describe overparameterized neural networks in which feature learning still plays a central role. In the high-dimensional limit, we derive a dynamical characterization of the gradient flow, in the spirit of dynamical mean-field theory (DMFT). Under l2-regularization, we analyze these equations at long times and characterize the performance and spectral properties of the resulting estimator. This result provides a quantitative understanding of the effect of overparameterization on learning and generalization, and reveals a double descent phenomenon in the presence of label noise, where generalization improves beyond interpolation. In the small regularization limit, we obtain an exact expression for the perfect recovery threshold as a function of the network widths, providing a precise characterization of how overparameterization influences recovery."
  },
  {
    "date": "2026-01-15",
    "title": "From Weibel seeds to collisionless dynamos beyond pair-plasmas",
    "authors": "Lise Hanebring, James Juno, Ammar Hakim, Jason M. TenBarge, Istvan Pusztai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10472v1",
    "source": "arXiv",
    "abstract": "Bridging the spatiotemporal scales of magnetic seed field generation and subsequent dynamo amplification in the weakly collisional intracluster medium presents an extreme numerical challenge. We perform collisionless turbulence simulations with initially unmagnetized electrons that capture both magnetic seed generation via the electron Weibel instability and the ensuing dynamo amplification. Going beyond existing pair-plasma studies, we use an ion-to-electron mass ratio of 100 for which we find electron and ion dynamics are sufficiently decoupled. These simulations are enabled by the 10-moment collisionless fluid solver of Gkeyll, which evolves the full pressure tensor for all species. The electron heat-flux closure regulates pressure isotropization and effectively sets the magnetic Reynolds number. We investigate how the strength of of the closure influences the transition between a regime reminiscent of previous kinetic pair-plasma simulations and a more MHD-like dynamo regime."
  },
  {
    "date": "2026-01-15",
    "title": "Joint Source-Channel Coding for ISAC: Distortion Tradeoffs and Separation Theorems",
    "authors": "Gefei Peng, Youlong Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10470v1",
    "source": "arXiv",
    "abstract": "Integrated Sensing and Communication (ISAC) systems have garnered significant attention due to their capability to simultaneously achieve efficient communication and environmental sensing. A core objective in this field is characterizing the performance tradeoff between sensing and communication. In this paper, we consider a joint source-channel coding (JSCC) framework for the ISAC system that consists of a transmitter with a channel state estimator and a joint source-channel encoder, a state-dependent memoryless channel, and a receiver with a joint source-channel decoder. From an information-theoretic perspective, we establish the tradeoff relationships among channel capacity, distortions in both communication and sensing processes, and the estimation cost. We prove that the separate source and channel coding can achieve joint optimality in this setting. An illustrative example of a binary setting is also provided to validate our theoretical results."
  },
  {
    "date": "2026-01-15",
    "title": "Localization Landscape in Non-Hermitian and Floquet quantum systems",
    "authors": "David Guéry-Odelin, François Impens",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10451v1",
    "source": "arXiv",
    "abstract": "We propose a generalization of the Filoche--Mayboroda localization landscape that extends the theory well beyond the static, elliptic and Hermitian settings while preserving its geometric interpretability. Using the positive operator $H^\\dagger H$, we obtain a landscape that predicts localization across non-Hermitian, Floquet, and topological systems without computing eigenstates. Singular-value collapse reveals spectral instabilities and skin effects, the Sambe formulation captures coherent destruction of tunneling, and topological zero modes emerge directly from the landscape. Applications to Hatano--Nelson chains, driven two-level systems, and driven Aubry--André--Harper models confirm quantitative accuracy, establishing a unified predictor for localization in equilibrium and driven quantum matter."
  },
  {
    "date": "2026-01-15",
    "title": "Subjective evaluation of UHD video coded using VVC with LCEVC and ML-VVC",
    "authors": "Naeem Ramzan, Muhammad Tufail Khan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10448v1",
    "source": "arXiv",
    "abstract": "This paper presents the results of a subjective quality assessment of a multilayer video coding configuration in which Low Complexity Enhancement Video Coding (LCEVC) is applied as an enhancement layer on top of a Versatile Video Coding (VVC) base layer. The evaluation follows the same test methodology and conditions previously defined for MPEG multilayer video coding assessments, with the LCEVC enhancement layer encoded using version 8.1 of the LCEVC Test Model (LTM). The test compares reconstructed UHD output generated from an HD VVC base layer with LCEVC enhancement against two reference cases: upsampled VVC base layer decoding and multilayer VVC (ML-VVC). Two operating points are considered, corresponding to enhancement layers representing approximately 10% and 50% of the total bitrate. Subjective assessment was conducted using the Degradation Category Rating (DCR) methodology with twenty five participants, across a dataset comprising fifteen SDR and HDR sequences. The reported results include Mean Opinion Scores (MOS) with associated 95% confidence intervals, enabling comparison of perceptual quality across coding approaches and operating points within the defined test scope."
  },
  {
    "date": "2026-01-15",
    "title": "Modeling mental health trajectories during the COVID-19 pandemic using UK-wide data in the presence of sociodemographic variables",
    "authors": "Glenna Nightingale, Karthik Mohan, Eloi Ribe, Valentin Popov, Shakes Wang, Clara Calia, Luciana Brondi, Sohan Seth",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10445v1",
    "source": "arXiv",
    "abstract": "Background: The negative effects of the COVID-19 pandemic on the mental health and well-being of populations are an important public health issue. Our study aims to determine the underlying factors shaping mental health trajectories during the COVID-19 pandemic in the UK. Methods: Data from the Understanding Society COVID-19 Study were utilized and the core analysis focussed on GHQ36 scores as the outcome variable. We used GAMs to evaluate trends over time and the role of sociodemographic variables, i.e., age, sex, ethnicity, country of residence (in UK), job status (employment), household income, living with a partner, living with children under age 16, and living with a long-term illness, on the variation of mental health during the study period. Results: Statistically significant differences in mental health were observed for age, sex,ethnicity, country of residence (in UK), job status (employment), household income, living with a partner, living with children under age 16, and living with a long-term illness. Women experienced higher GHQ36 scores relative to men with the GHQ36 score expected to increase by 1.260 (95%CI: 1.176, 1.345). Individuals living without a partner were expected to have higher GHQ36 scores, of 1.050 (95%CI: 0.949, 1.148) more than those living with a partner, and age groups 16-34, 35-44, 45-54, 55-64 experienced higher GHQ36 scores relative to those who were 65+. Individuals with relatively lower household income were likely to have poorer mental health relative to those who were more well off. Conclusion: This study identifies key demographic determinants shaping mental health trajectories during the COVID-19 pandemic in the UK. Policies aiming to reduce mental health inequalities should target women, youth, individuals living without a partner, individuals living with children under 16, individuals with a long-term illness, and lower income families."
  },
  {
    "date": "2026-01-15",
    "title": "Umbral theory and the algebra of formal power series",
    "authors": "Roberto Ricci",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10443v1",
    "source": "arXiv",
    "abstract": "Umbral theory, formulated in its modern version by S. Roman and G.~C. Rota, has been reconsidered in more recent times by G. Dattoli and collaborators with the aim of devising a working computational tool in the framework of special function theory. Concepts like umbral image and umbral vacuum have been introduced as pivotal elements of the discussion, which, albeit effective, lacks of generality. This article is directed towards endowing the formalism with a rigorous formulation within the context of the formal power series with complex coefficients $(\\mathbb{C}[[ t ]], \\partial)$. The new formulation is founded on the definition of the umbral operator $\\operatorname{\\mathfrak{u}}$ as a functional in the \"umbral ground state\" subalgebra of analytically convergent formal series $\\varphi \\in \\mathbb{C}\\{t\\}$. We consider in detail some specific classes of umbral ground states $\\varphi$ and analyse the conditions for analytic convergence of the corresponding umbral identities, defined as formal series resulting from the action on $\\varphi$ of operators of the form $f(ζ\\operatorname{\\mathfrak{u}}^μ)$ with $f \\in \\mathbb{C}\\{t\\}$ and $μ, ζ\\in \\mathbb{C}$. For these umbral states, we exploit the Gevrey classification of formal power series to establish a connection with the theory of Borel-Laplace resummation, enabling to make rigorous sense of a large class of -- even divergent -- umbral identities. As an application of the proposed theoretical framework, we introduce and investigate the properties of new umbral images for the Gaussian trigonometric functions, which emphasise the trigonometric-like nature of these functions and enable to define the concept of \"Gaussian Fourier transform\", a potentially powerful tool for applications."
  },
  {
    "date": "2026-01-15",
    "title": "Non-Intrusive Hyperreduction by a Physics-Augmented Neural Network with Second-Order Sobolev Training",
    "authors": "Arwed Schütz, Lars Nolle, Tamara Bechtold",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10442v1",
    "source": "arXiv",
    "abstract": "The finite element method is an indispensable tool in engineering, but its computational complexity prevents applications for control or at system-level. Model order reduction bridges this gap, creating highly efficient yet accurate surrogate models. Reducing nonlinear setups additionally requires hyperreduction. Compatibility with commercial finite element software requires non-intrusive methods based on data. Methods include the trajectory piecewise linear approach, or regression, typically via neural networks. Important aspects for these methods are accuracy, efficiency, generalization, including desired physical and mathematical properties, and extrapolation. Especially the last two aspects are problematic for neural networks. Therefore, several studies investigated how to incorporate physical knowledge or desirable properties. A promising approach from constitutive modeling is physics augmented neural networks. This concept has been elegantly transferred to hyperreduction by Fleres et al. in 2025 and guarantees several desired properties, incorporates physics, can include parameters, and results in smaller architectures. We augment this reference work by second-order Sobolev training, i.e., using a function and its first two derivatives. These are conveniently accessible and promise improved performance. Further modifications are proposed and studied. While Sobolev training does not meet expectations, several minor changes improve accuracy by up to an order of magnitude. Eventually, our best model is compared to reference work and the trajectory piecewise linear approach. The comparison relies on the same numerical case study as the reference work and additionally emphasizes extrapolation due to its critical role in typical applications. Our results indicate quick divergence of physics-augmented neural networks for extrapolation, preventing its deployment."
  },
  {
    "date": "2026-01-15",
    "title": "Observation of Light-Driven Levitation Near Epsilon-Near-Zero Surfaces",
    "authors": "Maria Grazia Donato, Michael Hinczewski, Theodore Letsou, Mohamed ElKabbash, Rosalba Saija, Pietro G. Gucciardi, Nader Engheta, Giuseppe Strangi, Onofrio M. Marago",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10425v1",
    "source": "arXiv",
    "abstract": "Optical manipulation of micro- and nanoparticles near surfaces is fundamental for applications in sensing and microfluidics, yet controlling particle-surface interactions remains challenging. Here we experimentally investigate light-induced forces on dielectric particles near epsilon-near-zero (ENZ) metamaterial surfaces using photonic force microscopy. By illuminating trapped particles with tunable visible light, we observe a wavelength-dependent repulsive force unique to ENZ surfaces, contrasting with the attractive forces near dielectric or metallic substrates. This repulsion peaks near the ENZ frequency and may be attributed to combined optical ENZ effects and thermophoretic forces. Our findings demonstrate that ENZ metamaterials can induce stable levitation of particles via light-driven forces, offering a novel mechanism for contactless manipulation in microfluidic environments. This work advances understanding of light-matter interactions at ENZ interfaces and suggests potential for ENZ-based optical control of micro- and nanoscale objects, with potential applications in micro- and nanofluidic environments."
  },
  {
    "date": "2026-01-15",
    "title": "LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies",
    "authors": "Haiyue Yuan, Nikolay Matyunin, Ali Raza, Shujun Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10413v1",
    "source": "arXiv",
    "abstract": "Privacy policies help inform people about organisations' personal data processing practices, covering different aspects such as data collection, data storage, and sharing of personal data with third parties. Privacy policies are often difficult for people to fully comprehend due to the lengthy and complex legal language used and inconsistent practices across different sectors and organisations. To help conduct automated and large-scale analyses of privacy policies, many researchers have studied applications of machine learning and natural language processing techniques, including large language models (LLMs). While a limited number of prior studies utilised LLMs for extracting personal data flows from privacy policies, our approach builds on this line of work by combining LLMs with retrieval-augmented generation (RAG) and a customised knowledge base derived from existing studies. This paper presents the development of LADFA, an end-to-end computational framework, which can process unstructured text in a given privacy policy, extract personal data flows and construct a personal data flow graph, and conduct analysis of the data flow graph to facilitate insight discovery. The framework consists of a pre-processor, an LLM-based processor, and a data flow post-processor. We demonstrated and validated the effectiveness and accuracy of the proposed approach by conducting a case study that involved examining ten selected privacy policies from the automotive industry. Moreover, it is worth noting that LADFA is designed to be flexible and customisable, making it suitable for a range of text-based analysis tasks beyond privacy policy analysis."
  },
  {
    "date": "2026-01-15",
    "title": "Tight bounds on recurrence time in closed quantum systems",
    "authors": "Marcin Kotowski, Michał Oszmaniec",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10409v1",
    "source": "arXiv",
    "abstract": "The evolution of an isolated quantum system inevitably exhibits recurrence: the state returns to the vicinity of its initial condition after finite time. Despite its fundamental nature, a rigorous quantitative understanding of recurrence has been lacking. We establish upper bounds on the recurrence time, $t_{\\mathrm{rec}} \\lesssim t_{\\mathrm{exit}}(ε)(1/ε)^d$, where $d$ is the Hilbert-space dimension, $ε$ the neighborhood size, and $t_{\\mathrm{exit}}(ε)$ the escape time from this neighborhood. For pure states evolving under a Hamiltonian $H$, estimating $t_{\\mathrm{exit}}$ is equivalent to an inverse quantum speed limit problem: finding upper bounds on the time a time-evolved state $ψ_t$ needs to depart from the $ε$-vicinity of the initial state $ψ_0$. We provide a partial solution, showing that under mild assumptions $t_{\\mathrm{exit}}(ε) \\approx ε/\\sqrt{ Δ(H^2)}$, with $Δ(H^2)$ the Hamiltonian variance in $ψ_0$. We show that our upper bound on $t_{\\mathrm{rec}}$ is generically saturated for random Hamiltonians. Finally, we analyze the impact of coherence of the initial state in the eigenbasis of $H$ on recurrence behavior."
  },
  {
    "date": "2026-01-15",
    "title": "Spectroscopic follow-up of Gaia alerted Young Stellar Object variables: the Large Binocular Telescope view",
    "authors": "Teresa Giannini, Manuele Gangi, Fernando Cruz-Saenz de Miera, Brunella Nisini, Mate Szilagyi, Katia Biazzo, Agnes Kospal, Peter Abraham, Simone Antoniucci, Roberta Carini, Eleonora Fiorellino, Adriana Gargiulo, Ester Marini, Zsofia Nagy, Maria Gabriela Navarro, Fabrizio Vitali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10404v1",
    "source": "arXiv",
    "abstract": "We analyzed optical/near-IR Large Binocular Telescope spectra of 16 sources alerted by Gaia between 2021 and 2024 due to significant photometric variability. Half of the spectra were taken during quiescence and the rest during a burst or at intermediate brightness. Our analysis of their ten-year light curves and photometric/spectroscopic features provide evidence that all 16 sources are accreting Young Stellar Objects (YSOs). One object, Gaia23bab, is a known EXor source. Other light curves either have peaks over a stable baseline, or significant variability throughout the entire observation period, suggesting multiple contributing processes. All spectra exhibit emission lines from accretion columns, and over half of them show atomic forbidden lines as signatures of outflowing gas. We determined stellar parameters, accretion luminosity (Lacc) and mass accretion rate (Macc) at different brightness phases. Only two sources showed variability primarily due to extinction. During quiescence, our sources exhibit Lacc and Macc values typical of T Tauri and Herbig Ae/Be (HAEBE) sources, supporting the hypothesis that any YSO may undergo episodic accretion. In bursts, the Lacc and Macc of sources with photometric variations exceeding 2 mag follow a shallower relation with stellar luminosity and mass, typical of known EXor sources. This group includes one Class I, one flat-spectrum, and two Class II sources. Notably, the other Class I source, Gaia24beh, shows an Lacc value about ten times higher than typical EXor bursts of the same mass. In the other cases, Lacc and Macc align with variability seen in T Tauri and HAEBE sources."
  },
  {
    "date": "2026-01-15",
    "title": "Discrete Feynman-Kac Correctors",
    "authors": "Mohsin Hasan, Viktor Ohanesian, Artem Gazizov, Yoshua Bengio, Alán Aspuru-Guzik, Roberto Bondesan, Marta Skreta, Kirill Neklyudov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10403v1",
    "source": "arXiv",
    "abstract": "Discrete diffusion models have recently emerged as a promising alternative to the autoregressive approach for generating discrete sequences. Sample generation via gradual denoising or demasking processes allows them to capture hierarchical non-sequential interdependencies in the data. These custom processes, however, do not assume a flexible control over the distribution of generated samples. We propose Discrete Feynman-Kac Correctors, a framework that allows for controlling the generated distribution of discrete masked diffusion models at inference time. We derive Sequential Monte Carlo (SMC) algorithms that, given a trained discrete diffusion model, control the temperature of the sampled distribution (i.e. perform annealing), sample from the product of marginals of several diffusion processes (e.g. differently conditioned processes), and sample from the product of the marginal with an external reward function, producing likely samples from the target distribution that also have high reward. Notably, our framework does not require any training of additional models or fine-tuning of the original model. We illustrate the utility of our framework in several applications including: efficient sampling from the annealed Boltzmann distribution of the Ising model, improving the performance of language models for code generation and amortized learning, as well as reward-tilted protein sequence generation."
  },
  {
    "date": "2026-01-15",
    "title": "A Geometric Multigrid Preconditioner for Shifted Boundary Method",
    "authors": "Michał Wichrowski, Ajay Ajith",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10399v1",
    "source": "arXiv",
    "abstract": "The Shifted Boundary Method (SBM) trades some part of the burden of body-fitted meshing for increased algebraic complexity. While the resulting linear systems retain the standard $\\mathcal{O}(h^{-2})$ conditioning of second-order operators, the non-symmetry and non-local boundary coupling render them resistant to standard Algebraic Multigrid (AMG) and simple smoothers for high-order discretisations. We present a geometric multigrid preconditioner that effectively tames these systems. At its core lies the \\emph{Full-Residual Shy Patch} smoother: a subspace correction strategy that filters out some patches while capturing the full physics of the shifted boundary. Unlike previous cell-wise approaches that falter at high polynomial degrees, our method delivers convergence with low mesh dependence. We demonstrate performance for Continuous Galerkin approximations, maintaining low and stable iteration counts up to polynomial degree $p=3$ in 3D, proving that SBM can be both geometrically flexible and algebraically efficient."
  },
  {
    "date": "2026-01-15",
    "title": "Algebraic Farkas Lemma and Strong Duality for Perturbed Conic Linear Programming",
    "authors": "P. D. Khanh, V. V. H. Khoa, T. H. Mo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10390v1",
    "source": "arXiv",
    "abstract": "This paper addresses the study of algebraic versions of Farkas lemma and strong duality results in the very broad setting of infinite-dimensional conic linear programming in dual pairs of vector spaces. To this end, purely algebraic properties of perturbed optimal value functions of both primal and dual problems and their corresponding hypergraph/epigraph are investigated. The newly developed hypergraphical/epigraphical sets, inspired by Kretschmer's closedness conditions \\cite{Kretschmer61}, together with their novel convex separation-type characterizations, give rise to various perturbed Farkas-type lemmas which allow us to derive complete characterizations of ``zero duality gap''. Principally, when certain structures of algebraic or topological duals are imposed, illuminating implications of the developed condition are also explored."
  },
  {
    "date": "2026-01-15",
    "title": "Learning Hamiltonians in the Heisenberg limit with static single-qubit fields",
    "authors": "Shrigyan Brahmachari, Shuchen Zhu, Iman Marvian, Yu Tong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10380v1",
    "source": "arXiv",
    "abstract": "Learning the Hamiltonian governing a quantum system is a central task in quantum metrology, sensing, and device characterization. Existing Heisenberg-limited Hamiltonian learning protocols either require multi-qubit operations that are prone to noise, or single-qubit operations whose frequency or strength increases with the desired precision. These two requirements limit the applicability of Hamiltonian learning on near-term quantum platforms. We present a protocol that learns a quantum Hamiltonian with the optimal Heisenberg-limited scaling using only single-qubit control in the form of static fields with strengths that are independent of the target precision. Our protocol is robust against the state preparation and measurement (SPAM) error. By overcoming these limitations, our protocol provides new tools for device characterization and quantum sensing. We demonstrate that our method achieves the Heisenberg-limited scaling through rigorous mathematical proof and numerical experiments. We also prove an information-theoretic lower bound showing that a non-vanishing static field strength is necessary for achieving the Heisenberg limit unless one employs an extensive number of discrete control operations."
  },
  {
    "date": "2026-01-15",
    "title": "Global Context Compression with Interleaved Vision-Text Transformation",
    "authors": "Dian Jiao, Jiaxin Duan, Shuai Zhao, Jiabing Leng, Yiran Zhang, Feng Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10378v1",
    "source": "arXiv",
    "abstract": "Recent achievements of vision-language models in end-to-end OCR point to a new avenue for low-loss compression of textual information. This motivates earlier works that render the Transformer's input into images for prefilling, which effectively reduces the number of tokens through visual encoding, thereby alleviating the quadratically increased Attention computations. However, this partial compression fails to save computational or memory costs at token-by-token inference. In this paper, we investigate global context compression, which saves tokens at both prefilling and inference stages. Consequently, we propose VIST2, a novel Transformer that interleaves input text chunks alongside their visual encoding, while depending exclusively on visual tokens in the pre-context to predict the next text token distribution. Around this idea, we render text chunks into sketch images and train VIST2 in multiple stages, starting from curriculum-scheduled pretraining for optical language modeling, followed by modal-interleaved instruction tuning. We conduct extensive experiments using VIST2 families scaled from 0.6B to 8B to explore the training recipe and hyperparameters. With a 4$\\times$ compression ratio, the resulting models demonstrate significant superiority over baselines on long writing tasks, achieving, on average, a 3$\\times$ speedup in first-token generation, 77% reduction in memory usage, and 74% reduction in FLOPS. Our codes and datasets will be public to support further studies."
  },
  {
    "date": "2026-01-15",
    "title": "Active Galactic Nuclei and STaR fOrmation in Nearby Galaxies (AGNSTRONG). II: Results for Jetted Type-I AGNs with Strong Ionized Gas Outflows",
    "authors": "Chen Qin, Huynh Anh N. Le, Yongquan Xue, Shifu Zhu, Xiaozhi Lin, Kim Ngan Nhat Nguyen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10372v1",
    "source": "arXiv",
    "abstract": "We investigate the correlation between ionized gas outflows, jets, and star formation in a sample of 42 local type-I active galactic nuclei (AGNs) exhibiting significant [O III] outflows. This study uses both new submillimeter (sub-mm) observations and archival data from the James Clerk Maxwell Telescope. Our analysis, which includes a correction for jet emission in the sub-mm bands, fitting spectral energy distribution, and analyzing spectra, enables us to derive star-formation rates (SFRs) through various methods. By comparing radio power and SFRs, we select a sub-sample of jetted AGNs of which radio emission is mostly from the jets. We find that jetted AGNs predominantly lie above the main sequence of star-forming galaxies, suggesting a correlation between jet activity and star formation. By comparing dust extinction, we demonstrate that jetted AGNs do not have more dust which is the fuel of both star formation and AGN activity. Therefore, this correlation is more likely to arise from AGN feedback. We also find that the Eddington ratio does not impact the specific SFRs (sSFRs) of our sample. Additionally, for jetted AGNs, stronger radio emission corresponds to higher sSFRs, suggesting that jet emission may promote star formation, i.e., positive feedback. Our results not only shed light on the feedback mechanisms of AGNs but also underscore the complex interplay between black hole activity and star formation in galaxy evolution."
  },
  {
    "date": "2026-01-15",
    "title": "Topology-Directed Silicide Formation: An Explanation for the Growth of C49-TiSi$_2$ on the Si(100) Surface",
    "authors": "Lukas Hückmann, Jonathon Cottom, Jörg Meyer, Emilia Olsson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10368v1",
    "source": "arXiv",
    "abstract": "Designing metal-semiconductor junctions is essential for optimizing the performance of modern nanoelectronic devices. A widely used material is TiSi$_2$, which combines low electronic resistivity with good endurance. However, its multitude of polymorphs continues to pose a challenge for device fabrication. In particular, the naturally occurring formation of the metastable C49-TiSi$_2$ modification remains poorly understood and is problematic due to its unfavorable electronic properties. Based on extensive DFT calculations, we present a comprehensive model of Ti adsorption on Si(100) that highlights the pivotal role of surface topology for the initial stages of the interfacial TiSi$_2$ formation process. We show that the interplay between Si surface dimers, the symmetry of the Si(100) surface, and the incorporation of Ti adsorbates below the surface drives an adsorption pattern that yields a nucleation template for the C49-TiSi$_2$ phase. Our atomistic model rationalizes experimental observations like the Stranski-Krastanov growth mode, the preferential formation of C49-TiSi$_2$ despite it being less favorable than the competing C54 phase, and why disruption of the surface structure restores thermodynamically driven growth of the latter. Ultimately, this novel perspective on the unique growth of TiSi$_2$ will help to pave the way for next-generation electronic devices."
  },
  {
    "date": "2026-01-15",
    "title": "FastStair: Learning to Run Up Stairs with Humanoid Robots",
    "authors": "Yan Liu, Tao Yu, Haolin Song, Hongbo Zhu, Nianzong Hu, Yuzhi Hao, Xiuyong Yao, Xizhe Zang, Hua Chen, Jie Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10365v1",
    "source": "arXiv",
    "abstract": "Running up stairs is effortless for humans but remains extremely challenging for humanoid robots due to the simultaneous requirements of high agility and strict stability. Model-free reinforcement learning (RL) can generate dynamic locomotion, yet implicit stability rewards and heavy reliance on task-specific reward shaping tend to result in unsafe behaviors, especially on stairs; conversely, model-based foothold planners encode contact feasibility and stability structure, but enforcing their hard constraints often induces conservative motion that limits speed. We present FastStair, a planner-guided, multi-stage learning framework that reconciles these complementary strengths to achieve fast and stable stair ascent. FastStair integrates a parallel model-based foothold planner into the RL training loop to bias exploration toward dynamically feasible contacts and to pretrain a safety-focused base policy. To mitigate planner-induced conservatism and the discrepancy between low- and high-speed action distributions, the base policy was fine-tuned into speed-specialized experts and then integrated via Low-Rank Adaptation (LoRA) to enable smooth operation across the full commanded-speed range. We deploy the resulting controller on the Oli humanoid robot, achieving stable stair ascent at commanded speeds up to 1.65 m/s and traversing a 33-step spiral staircase (17 cm rise per step) in 12 s, demonstrating robust high-speed performance on long staircases. Notably, the proposed approach served as the champion solution in the Canton Tower Robot Run Up Competition."
  },
  {
    "date": "2026-01-15",
    "title": "On UC-multipliers for multiple trigonometric systems",
    "authors": "Grigori A. Karagulyan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10360v1",
    "source": "arXiv",
    "abstract": "We investigate the class of sequences $w(n)$ that can serve as almost-everywhere convergence Weyl multipliers for all rearrangements of multiple trigonometric systems. We show that any such sequence must satisfy the bounds $\\log n\\lesssim w(n)\\lesssim\\log^2 n$. Our main result establishes a general equivalence principle between one-dimensional and multidimensional trigonometric systems, which allows one to extend certain estimates known for the one-dimensional case to higher dimensions."
  },
  {
    "date": "2026-01-15",
    "title": "PLGC: Pseudo-Labeled Graph Condensation",
    "authors": "Jay Nandy, Arnab Kumar Mondal, Anuj Rathore, Mahesh Chandran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10358v1",
    "source": "arXiv",
    "abstract": "Large graph datasets make training graph neural networks (GNNs) computationally costly. Graph condensation methods address this by generating small synthetic graphs that approximate the original data. However, existing approaches rely on clean, supervised labels, which limits their reliability when labels are scarce, noisy, or inconsistent. We propose Pseudo-Labeled Graph Condensation (PLGC), a self-supervised framework that constructs latent pseudo-labels from node embeddings and optimizes condensed graphs to match the original graph's structural and feature statistics -- without requiring ground-truth labels. PLGC offers three key contributions: (1) A diagnosis of why supervised condensation fails under label noise and distribution shift. (2) A label-free condensation method that jointly learns latent prototypes and node assignments. (3) Theoretical guarantees showing that pseudo-labels preserve latent structural statistics of the original graph and ensure accurate embedding alignment. Empirically, across node classification and link prediction tasks, PLGC achieves competitive performance with state-of-the-art supervised condensation methods on clean datasets and exhibits substantial robustness under label noise, often outperforming all baselines by a significant margin. Our findings highlight the practical and theoretical advantages of self-supervised graph condensation in noisy or weakly-labeled environments."
  },
  {
    "date": "2026-01-15",
    "title": "Model-Agnostic and Uncertainty-Aware Dimensionality Reduction in Supervised Learning",
    "authors": "Yue Yu, Guanghui Wang, Liu Liu, Changliang Zou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10357v1",
    "source": "arXiv",
    "abstract": "Dimension reduction is a fundamental tool for analyzing high-dimensional data in supervised learning. Traditional methods for estimating intrinsic order often prioritize model-specific structural assumptions over predictive utility. This paper introduces predictive order determination (POD), a model-agnostic framework that determines the minimal predictively sufficient dimension by directly evaluating out-of-sample predictiveness. POD quantifies uncertainty via error bounds for over- and underestimation and achieves consistency under mild conditions. By unifying dimension reduction with predictive performance, POD applies flexibly across diverse reduction tasks and supervised learners. Simulations and real-data analyses show that POD delivers accurate, uncertainty-aware order estimates, making it a versatile component for prediction-centric pipelines."
  },
  {
    "date": "2026-01-15",
    "title": "Realistic prospects for testing a relativistic local quantum measurement inequality",
    "authors": "Riccardo Falcone, Claudio Conti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10354v1",
    "source": "arXiv",
    "abstract": "We investigate the experimental prospects for testing a relativistic local quantum measurement inequality that quantifies the trade-off between vacuum insensitivity and responsiveness to excitations for finite-size detectors. Building on the Reeh--Schlieder approximation for coherent states, we derive an explicit and practically applicable bound for arbitrary coherent states. To connect with realistic photodetection scenarios, we model the detection region as a square prism operating over a finite time window and consider a normally incident single-mode coherent state. Numerical results exhibit the expected qualitative behavior: suppressing dark counts necessarily tightens the achievable click probability."
  },
  {
    "date": "2026-01-15",
    "title": "Como medir o invisível? Guerras, pizzarias do Pentágono e o uso de variáveis proxy em econometria",
    "authors": "Guilherme Vianna, Victor Rangel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10352v1",
    "source": "arXiv",
    "abstract": "Many economically relevant variables (risk, confidence, uncertainty) are latent and therefore not directly observable, which creates identification challenges in applied regressions. This text formalizes how omitting latent factors generates omitted-variable bias and discusses when including a proxy variable can mitigate it. We distinguish the case of a perfect proxy, which can eliminate the bias, from the more realistic case of an imperfect proxy, where residual bias remains and the estimated effect is attenuated. We propose a practical evaluation protocol based on four properties: relevance, conditional sufficiency, exogeneity, and stability. As an illustration, we use micromobility data from Arlington together with the U.S. Geopolitical Risk Index, estimating cointegration and a bivariate VEC model to interpret local activity as a high-frequency signal of the latent component of geopolitical tension."
  },
  {
    "date": "2026-01-15",
    "title": "Waring's problem for pseudo-polynomials",
    "authors": "Manfred G. Madritsch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10351v1",
    "source": "arXiv",
    "abstract": "Waring's problem has a long history in additive number theory. In its original form it deals with the representability of every positive integer as sum of $k$-th powers with integer $k$. Instead of these powers we deal with pseudo-polynomials in this paper. A pseudo-polynomial is a ``polynomial'' with at least one exponent not being an integer. Our work extends earlier results on the related problem of Waring for arbitrary real powers $k>12$ by Deshouillers and Arkhipov and Zhitkov."
  },
  {
    "date": "2026-01-15",
    "title": "Nonsingular Cosmologies in Presence of String Cloud",
    "authors": "Karma P. Sherpa, Rishi Pokhrel, Tanay K. Dey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10350v1",
    "source": "arXiv",
    "abstract": "In the braneworld scenario, we introduce a uniformly distributed cloud of infinitely long strings in the five dimensional AdS bulk spacetime. The end points of the strings are attached to the brane and becomes the source of the four dimensional matter on the brane, while the body of the strings hang onto the radial direction of the bulk and act as the gluonic field on the brane. The presence of matter in the brane induces a nonsingular cosmological evolution for the scale factor of the brane world under certain conditions of mass and cosmological parameters. However, the nonsingular nature is unstable since the bounce occurs inside the Cauchy horizon. Further, we consider the shellworld or the dark bubble scenario for the same bulk spacetime. It shows stable nonsingular cosmological nature of the bubble universe under certain conditions on the bulk and bubble parameters."
  },
  {
    "date": "2026-01-15",
    "title": "SuS: Strategy-aware Surprise for Intrinsic Exploration",
    "authors": "Mark Kashirskiy, Ilya Makarov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10349v1",
    "source": "arXiv",
    "abstract": "We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. Unlike traditional curiosity-driven methods that rely solely on state prediction error, SuS introduces two complementary components: Strategy Stability (SS) and Strategy Surprise (SuS). SS measures consistency in behavioral strategy across temporal steps, while SuS captures unexpected outcomes relative to the agent's current strategy representation. Our combined reward formulation leverages both signals through learned weighting coefficients. We evaluate SuS on mathematical reasoning tasks using large language models, demonstrating significant improvements in both accuracy and solution diversity. Ablation studies confirm that removing either component results in at least 10% performance degradation, validating the synergistic nature of our approach. SuS achieves 17.4% improvement in Pass@1 and 26.4% improvement in Pass@5 compared to baseline methods, while maintaining higher strategy diversity throughout training."
  },
  {
    "date": "2026-01-15",
    "title": "Training-Trajectory-Aware Token Selection",
    "authors": "Zhanming Shen, Jiaqi Hu, Zeyu Qin, Hao Chen, Wentao Ye, Zenan Huang, Yihong Zhuang, Guoshan Lu, Junlin Zhou, Junbo Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10348v1",
    "source": "arXiv",
    "abstract": "Efficient distillation is a key pathway for converting expensive reasoning capability into deployable efficiency, yet in the frontier regime where the student already has strong reasoning ability, naive continual distillation often yields limited gains or even degradation. We observe a characteristic training phenomenon: even as loss decreases monotonically, all performance metrics can drop sharply at almost the same bottleneck, before gradually recovering. We further uncover a token-level mechanism: confidence bifurcates into steadily increasing Imitation-Anchor Tokens that quickly anchor optimization and other yet-to-learn tokens whose confidence is suppressed until after the bottleneck. And the characteristic that these two types of tokens cannot coexist is the root cause of the failure in continual distillation. To this end, we propose Training-Trajectory-Aware Token Selection (T3S) to reconstruct the training objective at the token level, clearing the optimization path for yet-to-learn tokens. T3 yields consistent gains in both AR and dLLM settings: with only hundreds of examples, Qwen3-8B surpasses DeepSeek-R1 on competitive reasoning benchmarks, Qwen3-32B approaches Qwen3-235B, and T3-trained LLaDA-2.0-Mini exceeds its AR baseline, achieving state-of-the-art performance among all of 16B-scale no-think models."
  },
  {
    "date": "2026-01-15",
    "title": "On gradient stability in nonlinear PDE models and inference in interacting particle systems",
    "authors": "Aurélien Castre, Richard Nickl",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10326v1",
    "source": "arXiv",
    "abstract": "We consider general parameter to solution maps $θ\\mapsto \\mathcal G(θ)$ of non-linear partial differential equations and describe an approach based on a Banach space version of the implicit function theorem to verify the gradient stability condition of Nickl&Wang (JEMS 2024) for the underlying non-linear inverse problem, providing also injectivity estimates and corresponding statistical identifiability results. We illustrate our methods in two examples involving a non-linear reaction diffusion system as well as a McKean--Vlasov interacting particle model, both with periodic boundary conditions. We apply our results to prove the polynomial time convergence of a Langevin-type algorithm sampling the posterior measure of the interaction potential arising from a discrete aggregate measurement of the interacting particle system."
  },
  {
    "date": "2026-01-15",
    "title": "Conjugate Gradient Methods are Not Efficient: Experimental Study of the Locality Limitation",
    "authors": "Ulrich Rüde",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10322v1",
    "source": "arXiv",
    "abstract": "The convergence of the Conjugate Gradient method is subject to a locality limitation which imposes a lower bound on the number of iterations required before a qualitatively accurate approximation can be obtained. This limitation originates from the restricted transport of information in the graph induced by the sparsity pattern of the system matrix. In each iteration, information from the right-hand side can propagate only across directly connected graph nodes. The diameter of this graph therefore determines a minimum number of iterations that is necessary to achieve an acceptable level of accuracy."
  },
  {
    "date": "2026-01-15",
    "title": "Flavour hierarchies from radiative corrections in latticed theory space",
    "authors": "Gurucharan Mohanta, Ketan M. Patel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10316v1",
    "source": "arXiv",
    "abstract": "It has recently been shown that when $N_f$ generations of chiral fermions are coupled in a specific manner to $N$ (with $N \\geq 2N_f-1$) pairs of vectorlike fermions whose mass terms form a one-dimensional lattice-like structure in theory space, locality along the lattice ensures that only a single fermion generation acquires a mass at tree level. Radiative corrections can induce controlled departures from locality in the latticed space, thereby generating suppressed but non-vanishing masses for the remaining $N_f-1$ generations. In this work, we present an explicit implementation of this mechanism to address the flavour hierarchies of the Standard Model. After delineating the minimal extensions of the gauge, scalar, and Yukawa sectors required for feasible implementation of the mechanism, we demonstrate that the framework successfully reproduces the observed charged-fermion mass spectrum and quark mixing pattern. We analyse the new-physics effects arising from the extended sectors and confront them with existing constraints from direct, indirect searches and precision measurements. It is shown that a viable realisation of the mechanism allows the spectrum of vectorlike fermions and additional gauge boson to lie at scales as low as $\\mathcal{O}(5)\\,\\mathrm{TeV}$ with the lightest states typically corresponding to top partners. This stands in sharp contrast to conventional radiative mass-generation scenarios, in which phenomenological constraints typically impose a lower bound on the new-physics scale of order a few hundred to several thousand TeV."
  },
  {
    "date": "2026-01-15",
    "title": "Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning",
    "authors": "Xin Guan, Zijian Li, Shen Huang, Pengjun Xie, Jingren Zhou, Jiuxin Cao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10306v1",
    "source": "arXiv",
    "abstract": "While Reinforcement Learning (RL) has advanced LLM reasoning, applying it to long-context scenarios is hindered by sparsity of outcome rewards. This limitation fails to penalize ungrounded \"lucky guesses,\" leaving the critical process of needle-in-a-haystack evidence retrieval largely unsupervised. To address this, we propose EAPO (Evidence-Augmented Policy Optimization). We first establish the Evidence-Augmented Reasoning paradigm, validating via Tree-Structured Evidence Sampling that precise evidence extraction is the decisive bottleneck for long-context reasoning. Guided by this insight, EAPO introduces a specialized RL algorithm where a reward model computes a Group-Relative Evidence Reward, providing dense process supervision to explicitly improve evidence quality. To sustain accurate supervision throughout training, we further incorporate an Adaptive Reward-Policy Co-Evolution mechanism. This mechanism iteratively refines the reward model using outcome-consistent rollouts, sharpening its discriminative capability to ensure precise process guidance. Comprehensive evaluations across eight benchmarks demonstrate that EAPO significantly enhances long-context reasoning performance compared to SOTA baselines."
  },
  {
    "date": "2026-01-15",
    "title": "Effect of Primordial Black Holes on the global 21-cm signal",
    "authors": "Atrideb Chatterjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10304v1",
    "source": "arXiv",
    "abstract": "The 21-cm global signal, a treasure trove of information about the nature of the first luminous sources of the Universe, has traditionally been modelled assuming that these early sources were predominantly star-forming galaxies. However, recent observations by the James Webb Space Telescope (JWST) have revealed several AGNs as early as z ~ 10 - 10.4 . In light of this, it is important to investigate the contribution of such AGNs to the 21-cm signal. Assuming that these AGNs are seeded by Primordial Black Holes (PBHs) and employing an analytical PBH model, consistent with existing cosmological and astrophysical constraints, we show that these exotic objects can have a significant impact on the redshift evolution of the global signal."
  },
  {
    "date": "2026-01-15",
    "title": "Multipath Routing for Multi-Hop UAV Networks",
    "authors": "Zhenyu Zhao, Tiankui Zhang, Xiaoxia Xu, Junjie Li, Yuanwei Liu, Wenjuan Xing",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10299v1",
    "source": "arXiv",
    "abstract": "Multi-hop uncrewed aerial vehicle (UAV) networks are promising to extend the terrestrial network coverage. Existing multi-hop UAV networks employ a single routing path by selecting the next-hop forwarding node in a hop-by-hop manner, which leads to local congestion and increases traffic delays. In this paper, a novel traffic-adaptive multipath routing method is proposed for multi-hop UAV networks, which enables each UAV to dynamically split and forward traffic flows across multiple next-hop neighbors, thus meeting latency requirements of diverse traffic flows in dynamic mobile environments. An on-time packet delivery ratio maximization problem is formulated to determine the traffic splitting ratios at each hop. This sequential decision-making problem is modeled as a decentralized partially observable Markov decision process (Dec-POMDP). To solve this Dec-POMDP, a novel multi-agent deep reinforcement leaning (MADRL) algorithm, termed Independent Proximal Policy Optimization with Dirichlet Modeling (IPPO-DM), is developed. Specifically, the IPPO serves as the core optimization framework, where the Dirichlet distribution is leveraged to parameterize a continuous stochastic policy network on the probability simplex, inherently ensuring feasible traffic splitting ratios. Simulation results demonstrate that IPPO-DM outperforms benchmark schemes in terms of both delivery latency guarantee and packet loss performance."
  },
  {
    "date": "2026-01-15",
    "title": "Reasoning Hijacking: Subverting LLM Classification via Decision-Criteria Injection",
    "authors": "Yuansen Liu, Yixuan Tang, Anthony Kum Hoe Tun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10294v1",
    "source": "arXiv",
    "abstract": "Current LLM safety research predominantly focuses on mitigating Goal Hijacking, preventing attackers from redirecting a model's high-level objective (e.g., from \"summarizing emails\" to \"phishing users\"). In this paper, we argue that this perspective is incomplete and highlight a critical vulnerability in Reasoning Alignment. We propose a new adversarial paradigm: Reasoning Hijacking and instantiate it with Criteria Attack, which subverts model judgments by injecting spurious decision criteria without altering the high-level task goal. Unlike Goal Hijacking, which attempts to override the system prompt, Reasoning Hijacking accepts the high-level goal but manipulates the model's decision-making logic by injecting spurious reasoning shortcut. Though extensive experiments on three different tasks (toxic comment, negative review, and spam detection), we demonstrate that even newest models are prone to prioritize injected heuristic shortcuts over rigorous semantic analysis. The results are consistent over different backbones. Crucially, because the model's \"intent\" remains aligned with the user's instructions, these attacks can bypass defenses designed to detect goal deviation (e.g., SecAlign, StruQ), exposing a fundamental blind spot in the current safety landscape. Data and code are available at https://github.com/Yuan-Hou/criteria_attack"
  },
  {
    "date": "2026-01-15",
    "title": "Quantum bianisotropy in light-matter interaction",
    "authors": "E. O. Kamenetskii",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10287v1",
    "source": "arXiv",
    "abstract": "Quantum bianisotropy and chirality are fundamental concepts in light matter interaction that describe how materials with broken symmetries respond to electromagnetic fields at the level of macroscopic quantum electrodynamics. In quantum bianisotropy, magnetoelectric (ME) energy plays a critical role in mediating and enhancing light matter interactions. This concept is essential for bridging the gap between classical electromagnetics (where bianisotropy often involves field nonlocality) and quantum mechanics in metamaterials. The precise manipulation of a quantum emitter's properties at a subwavelength scale is due to near fields, which effectively function as a tunable environment. We show that the ME near field, interpreted as a structure combining the effect of bianisotropy (chirality) with a quantum atmosphere, is a nonMaxwellian field with spacetime symmetry breaking. Quantum ME fields arise from the dynamic modulation and topological coupling of magnetization and electric polarization within ME meta atoms, specific subwavelength structural elements with magnetic and dielectric subsystems in magnetic insulators."
  },
  {
    "date": "2026-01-15",
    "title": "On holonomy groups of K-contact sub-pseudo-Riemannian manifolds",
    "authors": "E. A. Kokin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10286v1",
    "source": "arXiv",
    "abstract": "This article investigates the holonomy groups of K-contact sub-pseudo-Riemannian manifolds. The primary result is a proof that the horizontal holonomy group either coincides with the adapted holonomy group or acts as its normal subgroup of codimension one. The theory is adapted for metrics of indefinite signature, bypassing the problem of subspace degeneracy that previously prevented the use of established orthogonal decomposition methods. It is established that, in the sub-Lorentzian case, the adapted holonomy group corresponds to the holonomy group of a certain Lorentzian manifold. This work also provides a complete classification of codimension-one ideals for Lorentzian holonomy algebras and presents specific examples of structures based on Cahen-Wallach spaces and Kähler manifolds."
  },
  {
    "date": "2026-01-15",
    "title": "How disc initial conditions sculpt the atmospheric composition of giant planets",
    "authors": "Angie Daniela Guzmán Franco, Sofia Savvidou, Bertram Bitsch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10285v1",
    "source": "arXiv",
    "abstract": "Past studies have revealed the dependency of the disc parameters (mass, radius, viscosity, grain fragmentation velocity, dust-to-gas ratio) on the formation of giant planets, where more massive discs seem beneficial for giant planet formation. It is unclear how the different disc properties influence the composition of forming giant planets. The idea that the atmospheric abundances can trace directly the formation location of planets is put into question, due to the chemical evolution of the disc, caused by inward drifting and evaporating pebbles. This complicates the idea of a relation between atmospheric abundances and planet formation locations. We use planet formation simulations that include the effects of pebble drift and evaporation and investigate how the different disc parameters influence the atmospheric composition of giant planets. We focus on the atmospheric C/O, C/H, O/H and S/H ratios allowing us to probe tracers for volatiles and refractories and thus different accretion pathways of giant planets. We find that most of the disc parameters have only a limited influence on the atmospheric abundances of gas giants, except for the dust-to-gas ratio, where a larger value results in higher atmospheric abundances. However the atmospheric abundances are determined by the planetary formation location, even in the pebble drift and evaporation scenario. Our study suggests that volatile-rich giant exoplanets predominantly form in the inner disc regions, where they can accrete large fractions of vapour-enhanced gas. Our study shows that simulations that try to trace the origin of giant planets via their atmospheric abundances do not have to probe all disc parameters, as long as the disc parameters allow the formation of giant planets. Our study thus suggests that the diversity of observed planetary compositions is a direct consequence of their formation location and migration history."
  },
  {
    "date": "2026-01-15",
    "title": "SCRamble: Adaptive Decentralized Overlay Construction for Blockchain Networks",
    "authors": "Evangelos Kolyvas, Alexandros Antonov, Spyros Voulgaris",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10277v1",
    "source": "arXiv",
    "abstract": "Despite being under development for over 15 years, transaction throughput remains one of the key challenges confronting blockchains, which typically has a cap of a limited number of transactions per second. A fundamental factor limiting this metric is the network latency associated with the block propagation throughout of the underlying peer-to-peer network, typically formed through random connections. Accelerating the dissemination of blocks not only improves transaction rates, but also enhances system security by reducing the probability of forks. This paper introduces SCRamble: a decentralized protocol that significantly reduces block dissemination time in blockchain networks. SCRamble's effectiveness is attributed to its innovative link selection strategy, which integrates two heuristics: a scoring mechanism that assesses block arrival times from neighboring peers, and a second heuristic that takes network latency into account."
  },
  {
    "date": "2026-01-15",
    "title": "MoST: Mixing Speech and Text with Modality-Aware Mixture of Experts",
    "authors": "Yuxuan Lou, Kai Yang, Yang You",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10272v1",
    "source": "arXiv",
    "abstract": "We present MoST (Mixture of Speech and Text), a novel multimodal large language model that seamlessly integrates speech and text processing through our proposed Modality-Aware Mixture of Experts (MAMoE) architecture. While current multimodal models typically process diverse modality representations with identical parameters, disregarding their inherent representational differences, we introduce specialized routing pathways that direct tokens to modality-appropriate experts based on input type. MAMoE simultaneously enhances modality-specific learning and cross-modal understanding through two complementary components: modality-specific expert groups that capture domain-specific patterns and shared experts that facilitate information transfer between modalities. Building on this architecture, we develop an efficient transformation pipeline that adapts the pretrained MoE language model through strategic post-training on ASR and TTS datasets, followed by fine-tuning with a carefully curated speech-text instruction dataset. A key feature of this pipeline is that it relies exclusively on fully accessible, open-source datasets to achieve strong performance and data efficiency. Comprehensive evaluations across ASR, TTS, audio language modeling, and spoken question answering benchmarks show that MoST consistently outperforms existing models of comparable parameter counts. Our ablation studies confirm that the modality-specific routing mechanism and shared experts design significantly contribute to performance gains across all tested domains. To our knowledge, MoST represents the first fully open-source speech-text LLM built on a Mixture of Experts architecture. \\footnote{We release MoST model, training code, inference code, and training data at https://github.com/NUS-HPC-AI-Lab/MoST"
  },
  {
    "date": "2026-01-15",
    "title": "Sim2Real Deep Transfer for Per-Device CFO Calibration",
    "authors": "Jingze Zheng, Zhiguo Shi, Shibo He, Chaojie Gu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10264v1",
    "source": "arXiv",
    "abstract": "Carrier Frequency Offset (CFO) estimation in Orthogonal Frequency Division Multiplexing (OFDM) systems faces significant performance degradation across heterogeneous software-defined radio (SDR) platforms due to uncalibrated hardware impairments. Existing deep neural network (DNN)-based approaches lack device-level adaptation, limiting their practical deployment. This paper proposes a Sim2Real transfer learning framework for per-device CFO calibration, combining simulation-driven pretraining with lightweight receiver adaptation. A backbone DNN is pre-trained on synthetic OFDM signals incorporating parametric hardware distortions (e.g., phase noise, IQ imbalance), enabling generalized feature learning without costly cross-device data collection. Subsequently, only the regression layers are fine-tuned using $1,000$ real frames per target device, preserving hardware-agnostic knowledge while adapting to device-specific impairments. Experiments across three SDR families (USRP B210, USRP N210, HackRF One) achieve $30\\times$ BER reduction compared to conventional CP-based methods under indoor multipath conditions. The framework bridges the simulation-to-reality gap for robust CFO estimation, enabling cost-effective deployment in heterogeneous wireless systems."
  },
  {
    "date": "2026-01-15",
    "title": "Error-Correcting Codes for the Sum Channel",
    "authors": "Lyan Abboud, Eitan Yaakobi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10256v1",
    "source": "arXiv",
    "abstract": "We introduce the sum channel, a new channel model motivated by applications in distributed storage and DNA data storage. In the error-free case, it takes as input an $\\ell$-row binary matrix and outputs an $(\\ell+1)$-row matrix whose first $\\ell$ rows equal the input and whose last row is their parity (sum) row. We construct a two-deletion-correcting code with redundancy $2\\lceil\\log_2\\log_2 n\\rceil + O(\\ell^2)$ for $\\ell$-row inputs. When $\\ell=2$, we establish an upper bound of $\\lceil\\log_2\\log_2 n\\rceil + O(1)$, implying that our redundancy is optimal up to a factor of 2. We also present a code correcting a single substitution with $\\lceil \\log_2(\\ell+1)\\rceil$ redundant bits and prove that it is within one bit of optimality."
  },
  {
    "date": "2026-01-15",
    "title": "Developer Interaction Patterns with Proactive AI: A Five-Day Field Study",
    "authors": "Nadine Kuo, Agnia Sergeyuk, Valerie Chen, Maliheh Izadi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10253v1",
    "source": "arXiv",
    "abstract": "Current in-IDE AI coding tools typically rely on time-consuming manual prompting and context management, whereas proactive alternatives that anticipate developer needs without explicit invocation remain underexplored. Understanding when humans are receptive to such proactive AI assistance during their daily work remains an open question in human-AI interaction research. We address this gap through a field study of proactive AI assistance in professional developer workflows. We present a five-day in-the-wild study with 15 developers who interacted with a proactive feature of an AI assistant integrated into a production-grade IDE that offers code quality suggestions based on in-IDE developer activity. We examined 229 AI interventions across 5,732 interaction points to understand how proactive suggestions are received across workflow stages, how developers experience them, and their perceived impact. Our findings reveal systematic patterns in human receptivity to proactive suggestions: interventions at workflow boundaries (e.g., post-commit) achieved 52% engagement rates, while mid-task interventions (e.g., on declined edit) were dismissed 62% of the time. Notably, well-timed proactive suggestions required significantly less interpretation time than reactive suggestions (45.4s versus 101.4s, W = 109.00, r = 0.533, p = 0.0016), indicating enhanced cognitive alignment. This study provides actionable implications for designing proactive coding assistants, including how to time interventions, align them with developer context, and strike a balance between AI agency and user control in production IDEs."
  },
  {
    "date": "2026-01-15",
    "title": "Critical time of the almost 2-regular random degree constrained process",
    "authors": "Balázs Ráth, Márton Szőke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10249v1",
    "source": "arXiv",
    "abstract": "We study the phase transition of the random degree constrained process (RDCP), a time-evolving random graph model introduced by Ruciński and Wormald that generalizes the random $d$-process to the non-regular setting: each vertex of the complete graph $K_n$ has its pre-assigned degree constraint (i.e., a number from the set $\\{2,\\dots,Δ\\}$), we attempt to add the edges one-by-one in a uniform random order, but a new edge is added only if it does not violate the degree constraints at its end-vertices. Warnke and Wormald identified the critical time of the RDCP when the giant component emerges as $n \\to \\infty$. Ráth, Szőke and Warnke identified the local weak limit of the RDCP and gave an alternative characterization of the critical time in terms of the principal eigenvalue of the branching operator of the multi-type branching process that arises as the local limit object. In the current paper we use this spectral characterization to study the critical time of the RDCP in the almost 2-regular case, i.e., when the degree constraint of most of the vertices is equal to 2. In this case the giant component emerges quite late, and our main result provides the precise asymptotics of the critical time as the model approaches 2-regularity. Interestingly, our formula asymptotically matches the well-known Molloy-Reed formula, despite the fact that Molloy, Surya and Warnke proved that the final graph of the RDCP is not contiguous to the configuration model with the same degree sequence."
  },
  {
    "date": "2026-01-15",
    "title": "Restoring similarity in randomized Krylov methods with applications to eigenvalue problems and matrix functions",
    "authors": "Laura Grigori, Daniel Kressner, Nian Shao, Igor Simunec",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10248v1",
    "source": "arXiv",
    "abstract": "The randomized Arnoldi process has been used in large-scale scientific computing because it produces a well-conditioned basis for the Krylov subspace more quickly than the standard Arnoldi process. However, the resulting Hessenberg matrix is generally not similar to the one produced by the standard Arnoldi process, which can lead to delays or spike-like irregularities in convergence. In this paper, we introduce a modification of the randomized Arnoldi process that restores similarity with the Hessenberg matrix generated by the standard Arnoldi process. This is accomplished by enforcing orthogonality between the last Arnoldi vector and the previously generated subspace, which requires solving only one additional least-squares problem. When applied to eigenvalue problems and matrix function evaluations, the modified randomized Arnoldi process produces approximations that are identical to those obtained with the standard Arnoldi process. Numerical experiments demonstrate that our approach is as fast as the randomized Arnoldi process and as robust as the standard Arnoldi process."
  },
  {
    "date": "2026-01-15",
    "title": "coTherapist: A Behavior-Aligned Small Language Model to Support Mental Healthcare Experts",
    "authors": "Prottay Kumar Adhikary, Reena Rawat, Tanmoy Chakraborty",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10246v1",
    "source": "arXiv",
    "abstract": "Access to mental healthcare is increasingly strained by workforce shortages and rising demand, motivating the development of intelligent systems that can support mental healthcare experts. We introduce coTherapist, a unified framework utilizing a small language model to emulate core therapeutic competencies through domain-specific fine-tuning, retrieval augmentation, and agentic reasoning. Evaluation on clinical queries demonstrates that coTherapist generates more relevant and clinically grounded responses than contemporary baselines. Using our novel T-BARS rubric and psychometric profiling, we confirm coTherapist exhibits high empathy and therapist-consistent personality traits. Furthermore, human evaluation by domain experts validates that coTherapist delivers accurate, trustworthy, and safe responses. coTherapist was deployed and tested by clinical experts. Collectively, these findings demonstrate that small models can be engineered to exhibit expert-like behavior, offering a scalable pathway for digital mental health tools."
  },
  {
    "date": "2026-01-15",
    "title": "Loop as a Bridge: Can Looped Transformers Truly Link Representation Space and Natural Language Outputs?",
    "authors": "Guanxu Chen, Dongrui Liu, Jing Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10242v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) often exhibit a gap between their internal knowledge and their explicit linguistic outputs. In this report, we empirically investigate whether Looped Transformers (LTs)--architectures that increase computational depth by iterating shared layers--can bridge this gap by utilizing their iterative nature as a form of introspection. Our experiments reveal that while increasing loop iterations narrows the gap, it is partly driven by a degradation of their internal knowledge carried by representations. Moreover, another empirical analysis suggests that current LTs' ability to perceive representations does not improve across loops; it is only present in the final loop. These results suggest that while LTs offer a promising direction for scaling computational depth, they have yet to achieve the introspection required to truly link representation space and natural language."
  },
  {
    "date": "2026-01-15",
    "title": "Who Owns the Text? Design Patterns for Preserving Authorship in AI-Assisted Writing",
    "authors": "Bohan Zhang, Chengke Bu, Paramveer S. Dhillon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10236v1",
    "source": "arXiv",
    "abstract": "AI writing assistants can reduce effort and improve fluency, but they may also weaken writers' sense of authorship. We study this tension with an ownership-aware co-writing editor that offers on-demand, sentence-level suggestions and tests two common design choices: persona-based coaching and style personalization. In an online study (N=176), participants completed three professional writing tasks: an email without AI help, a proposal with generic AI suggestions, and a cover letter with persona-based coaching, while half received suggestions tailored to a brief sample of their prior writing. Across the two AI-assisted tasks, psychological ownership dropped relative to unassisted writing (about 0.85-1.0 points on a 7-point scale), even as cognitive load decreased (about 0.9 points) and quality ratings stayed broadly similar overall. Persona coaching did not prevent the ownership decline. Style personalization partially restored ownership (about +0.43) and increased AI incorporation in text (+5 percentage points). We distill five design patterns: on-demand initiation, micro-suggestions, voice anchoring, audience scaffolds, and point-of-decision provenance, to guide authorship-preserving writing tools."
  },
  {
    "date": "2026-01-15",
    "title": "Synchronization and Hopf Bifurcation in Stuart--Landau Networks",
    "authors": "Kuan-Wei Chen, Ting-Yang Hsiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10234v1",
    "source": "arXiv",
    "abstract": "The Kuramoto model has shaped our understanding of synchronization in complex systems, yet its phase-only formulation neglects amplitude dynamics that are intrinsic to many oscillatory networks. In this work, we revisit Kuramoto-type synchronization through networks of Stuart--Landau oscillators, which arise as the universal normal form near a Hopf bifurcation. For identical natural frequencies, we analyze synchronization in two complementary regimes. Away from criticality, we establish topology-robust complete synchronization for general connected networks under explicit sufficient conditions that preclude amplitude death. At criticality, we exploit network symmetries to analyze the onset of collective oscillations via Hopf bifurcation theory, demonstrating the emergence of synchronized periodic states in ring-symmetric networks. Our results clarify how amplitude dynamics enrich the structure of synchronized states and provide a bridge between classical Kuramoto synchronization and amplitude-inclusive models in complex networks."
  },
  {
    "date": "2026-01-15",
    "title": "Tables or Sankey Diagrams? Investigating User Interaction with Different Representations of Simulation Parameters",
    "authors": "Choro Ulan uulu, Mikhail Kulyabin, Katharina M Zeiner, Jan Joosten, Nuno Miguel Martins Pacheco, Filippos Petridis, Rebecca Johnson, Jan Bosch, Helena Holmström Olsson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10232v1",
    "source": "arXiv",
    "abstract": "Understanding complex parameter dependencies is critical for effective configuration and maintenance of software systems across diverse domains - from Computer-Aided Engineering (CAE) to cloud infrastructure and database management. However, legacy tabular interfaces create a major bottleneck: engineers cannot easily comprehend how parameters relate across the system, leading to inefficient workflows, costly configuration errors, and reduced system trust - a fundamental program comprehension challenge in configuration-intensive software. This research evaluates whether interactive Sankey diagrams can improve comprehension of parameter dependencies compared to traditional spreadsheet interfaces. We employed a heuristic evaluation using the PURE method with three expert evaluators (UX design, simulation, and software development specialists) to compare a Sankey-based prototype to traditional tabular representations for core engineering tasks. Our key contribution demonstrates that flow-based parameter visualizations significantly reduce cognitive load (51% lower PURE scores) and interaction complexity (56% fewer steps) compared to traditional tables, while making parameter dependencies immediately visible rather than requiring mental reconstruction. By explicitly visualizing parameter relationships, Sankey diagrams address a core software visualization challenge: helping users comprehend complex system configurations without requiring deep tool-specific knowledge. While demonstrated through CAE software, this research contributes to program comprehension and software visualization by showing that dependency-aware visualizations can significantly improve understanding of configuration-intensive systems. The findings have implications for any software domain where comprehending complex parameter relationships is essential for effective system use and maintenance."
  },
  {
    "date": "2026-01-15",
    "title": "Optimizing Multimodal LLMs for Egocentric Video Understanding: A Solution for the HD-EPIC VQA Challenge",
    "authors": "Sicheng Yang, Yukai Huang, Shitong Sun, Weitong Cai, Jiankang Deng, Jifei Song, Zhensong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10228v1",
    "source": "arXiv",
    "abstract": "Multimodal Large Language Models (MLLMs) struggle with complex video QA benchmarks like HD-EPIC VQA due to ambiguous queries/options, poor long-range temporal reasoning, and non-standardized outputs. We propose a framework integrating query/choice pre-processing, domain-specific Qwen2.5-VL fine-tuning, a novel Temporal Chain-of-Thought (T-CoT) prompting for multi-step reasoning, and robust post-processing. This system achieves 41.6% accuracy on HD-EPIC VQA, highlighting the need for holistic pipeline optimization in demanding video understanding. Our code, fine-tuned models are available at https://github.com/YoungSeng/Egocentric-Co-Pilot."
  },
  {
    "date": "2026-01-15",
    "title": "Integral Variable Range Hopping for Modeling Electrical Transport in Disordered Systems",
    "authors": "Chenxin Qin, Chenyan Wang, Mouyang Cheng, Ji Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10226v1",
    "source": "arXiv",
    "abstract": "The variable range hopping (VRH) model has been widely applied to describe electrical transport in disordered systems, providing theoretical formulas to fit temperature-dependent electric conductivity. These models rely on oversimplified assumptions that restrict their applicability and result in problematic fitting behaviors, yet their overusing situation is becoming increasingly serious. In this work we formulate an integral variable range hopping (IVRH) model, which replaces the empirical temperature power-law dependence in standard VRH theories with a physics-inspired integral formulation. The model builds upon the standard hopping probability $ω(R)$ w.r.t. hopping distance $R$ and incorporates the density of accessible electronic states through an effective volume function $V(R)$, which reflects the influence of system geometry. The IVRH formulation inherently reproduces both the Mott behavior at low temperatures and the Arrhenius behavior at high temperatures, respectively, and enables a smooth transition between the two regimes. We apply the IVRH model to two-dimensional, three-dimensional, and multi-layered systems. Monte Carlo simulations validate the model's predictions and yield consistent values for the fitting parameters, with substantially reduced variances compared to fitting using the standard VRH model. Furthermore, the improved robustness of IVRH also extends to the transport measurements in monolayer MoS$_2$ system and monolayer WS$_2$ system, enabling more physically meaningful interpretation.IVRH model offers a more stable and physically sound framework for interpreting hopping transport in low-dimensional amorphous materials, providing deeper insights into the universal geometric scaling factors that govern charge transport in disordered systems."
  },
  {
    "date": "2026-01-15",
    "title": "Robust and Generalizable Atrial Fibrillation Detection from ECG Using Time-Frequency Fusion and Supervised Contrastive Learning",
    "authors": "Hongtao Li, Jia Wei, Jia Xiao, Yuanjun Lai, Mingyang Liu, Shuzhen Lv, Xueqiang Ouyang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10202v1",
    "source": "arXiv",
    "abstract": "Atrial fibrillation (AF) is a common cardiac arrhythmia that significantly increases the risk of stroke and heart failure, necessitating reliable and generalizable detection methods from electrocardiogram (ECG) recordings. Although deep learning has advanced automated AF diagnosis, existing approaches often struggle to exploit complementary time-frequency information effectively, limiting both robustness under intra-dataset and generalization across diverse clinical datasets. To address these challenges, we propose a cross-modal deep learning framework comprising two key components: a Bidirectional Gating Module (BGM) and a Cross-modal Supervised Contrastive Learning (CSCL) strategy. The BGM facilitates dynamic, reciprocal refinement between time and frequency domain features, enhancing model robustness to signal variations within a dataset. Meanwhile, CSCL explicitly structures the joint embedding space by pulling together label-consistent samples and pushing apart different ones, thereby improving inter-class separability and enabling strong cross-dataset generalization. We evaluate our method through five-fold cross-validation on the AFDB and the CPSC2021 dataset, as well as bidirectional cross-dataset experiments (training on one and testing on the other). Results show consistent improvements over state-of-the-art methods across multiple metrics, demonstrating that our approach achieves both high intra-dataset robustness and excellent cross-dataset generalization. We further demonstrate that our method achieves high computational efficiency and anti-interference capability, making it suitable for edge deployment."
  },
  {
    "date": "2026-01-15",
    "title": "PRL: Process Reward Learning Improves LLMs' Reasoning Ability and Broadens the Reasoning Boundary",
    "authors": "Jiarui Yao, Ruida Wang, Tong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10201v1",
    "source": "arXiv",
    "abstract": "Improving the reasoning abilities of Large Language Models (LLMs) has been a continuous topic recently. But most relevant works are based on outcome rewards at the trajectory level, missing fine-grained supervision during the reasoning process. Other existing training frameworks that try to combine process signals together to optimize LLMs also rely heavily on tedious additional steps like MCTS, training a separate reward model, etc., doing harm to the training efficiency. Moreover, the intuition behind the process signals design lacks rigorous theoretical support, leaving the understanding of the optimization mechanism opaque. In this paper, we propose Process Reward Learning (PRL), which decomposes the entropy regularized reinforcement learning objective into intermediate steps, with rigorous process rewards that could be assigned to models accordingly. Starting from theoretical motivation, we derive the formulation of PRL that is essentially equivalent to the objective of reward maximization plus a KL-divergence penalty term between the policy model and a reference model. However, PRL could turn the outcome reward into process supervision signals, which helps better guide the exploration during RL optimization. From our experiment results, we demonstrate that PRL not only improves the average performance for LLMs' reasoning ability measured by average @ n, but also broadens the reasoning boundary by improving the pass @ n metric. Extensive experiments show the effectiveness of PRL could be verified and generalized."
  },
  {
    "date": "2026-01-15",
    "title": "Exponential Analysis for Entanglement Distillation",
    "authors": "Zhiwen Lin, Ke Li, Kun Fang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10190v1",
    "source": "arXiv",
    "abstract": "Historically, the focus in entanglement distillation has predominantly been on the distillable entanglement, and the framework assumes complete knowledge of the initial state. In this paper, we study the reliability function of entanglement distillation, which specifies the optimal exponent of the decay of the distillation error when the distillation rate is below the distillable entanglement. Furthermore, to capture greater operational significance, we extend the framework from the standard setting of known states to a black-box setting, where distillation is performed from a set of possible states. We establish an exact finite blocklength result connecting to composite correlated hypothesis testing without any redundant correction terms. Based on this, the reliability function of entanglement distillation is characterized by the regularized quantum Hoeffding divergence. In the special case of a pure initial state, our result reduces to the error exponent for entanglement concentration derived by Hayashi et al. in 2003. Given full prior knowledge of the state, we construct a concrete optimal distillation protocol. Additionally, we analyze the strong converse exponent of entanglement distillation. While all the above results assume the free operations to be non-entangling, we also investigate other free operation classes, including PPT-preserving, dually non-entangling, and dually PPT-preserving operations."
  },
  {
    "date": "2026-01-15",
    "title": "A Highly Magnetic Ultra Massive White Dwarf with a 23-minute Rotation Period",
    "authors": "Jincheng Guo, Xiaofeng Wang, Qichun Liu, Alexei V. Filippenko, Thomas G. Brink, Jingkun Zhao, WeiKang Zhang, Yi Yang, Jie Lin, Haowei Peng, Hailiang Chen, Davron O. Mirzaqulov, Shuhrat A. Ehgamberdiev, Bin Ma, Jun Mo, Cheng Liu, Gaobo Xi, Xiaojun Jiang, Danfeng Xiang, Jicheng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10188v1",
    "source": "arXiv",
    "abstract": "We present a physical characterization of TMTS J00063798+3104160 (J0006), a rapidly rotating,ultra-massive white dwarf (WD) identified in high-cadence light curves from the Tsinghua University-Ma Huateng Telescope for Survey (TMTS). A coherent 23-minute periodicity is detected in TMTS, TESS, and ZTF photometry. A time series of low-resolution spectra with the Keck-I 10 m telescope reveals broad, shallow hydrogen absorption features indicative of an extreme magnetic field and shows no evidence for radial-velocity variations. Atmospheric modeling yields a magnetic field strength of $\\sim$ 250 MG, while Gaia astrometry and photometry imply a mass of 1.06 $\\pm$ 0.01 M$_{\\odot}$. A significant infrared excess is detected in the WISE W1 band and is well fitted by a 550 K blackbody, likely arising from residual material of a merger. We interpret the 23-minute photometric modulation as the rotation period of an isolated, massive WD formed likely through the merger of a double WD binary. With one of the shortest rotation periods known among candidate merger remnants and with constraints from a deep Einstein Probe X-ray nondetection, J0006 provides a rare and important observational window into the poorly explored intermediate stages of post-merger evolution."
  },
  {
    "date": "2026-01-15",
    "title": "Classification and design of two-dimensional altermagnets",
    "authors": "Sike Zeng, Dong Liu, Hongjie Peng, Chang-Chun He, Xiao-Bao Yang, Yu-Jun Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10183v1",
    "source": "arXiv",
    "abstract": "Altermagnets -- newly identified collinear antiferromagnets -- carry zero net moment with non-relativistic, spin-polarized bands, distilling the best of ferromagnets and antiferromagnets into a single spintronic platform. Shrunking to the two-dimensional limit, they inherit the tunability of two-dimensional crystals while adding symmetry-protected spin splitting, a combination now driving intense experimental interest. Here, we review the symmetry classification of two-dimensional altermagnets based on spin-group theory and survey the growing list of candidate materials, emphasizing those with large spin splitting for experimental realization. We then examine strategies for engineering two-dimensional altermagnetism. This Review aims to consolidate theoretically proposed candidate materials and realization strategies for two-dimensional altermagnets, providing insights for future experimental efforts in this emerging field."
  },
  {
    "date": "2026-01-15",
    "title": "CC-OR-Net: A Unified Framework for LTV Prediction through Structural Decoupling",
    "authors": "Mingyu Zhao, Haoran Bai, Yu Tian, Bing Zhu, Hengliang Luo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10176v1",
    "source": "arXiv",
    "abstract": "Customer Lifetime Value (LTV) prediction, a central problem in modern marketing, is characterized by a unique zero-inflated and long-tail data distribution. This distribution presents two fundamental challenges: (1) the vast majority of low-to-medium value users numerically overwhelm the small but critically important segment of high-value \"whale\" users, and (2) significant value heterogeneity exists even within the low-to-medium value user base. Common approaches either rely on rigid statistical assumptions or attempt to decouple ranking and regression using ordered buckets; however, they often enforce ordinality through loss-based constraints rather than inherent architectural design, failing to balance global accuracy with high-value precision. To address this gap, we propose \\textbf{C}onditional \\textbf{C}ascaded \\textbf{O}rdinal-\\textbf{R}esidual Networks \\textbf{(CC-OR-Net)}, a novel unified framework that achieves a more robust decoupling through \\textbf{structural decomposition}, where ranking is architecturally guaranteed. CC-OR-Net integrates three specialized components: a \\textit{structural ordinal decomposition module} for robust ranking, an \\textit{intra-bucket residual module} for fine-grained regression, and a \\textit{targeted high-value augmentation module} for precision on top-tier users. Evaluated on real-world datasets with over 300M users, CC-OR-Net achieves a superior trade-off across all key business metrics, outperforming state-of-the-art methods in creating a holistic and commercially valuable LTV prediction solution."
  },
  {
    "date": "2026-01-15",
    "title": "Quadrupole transitions of $^{10}$C and their isospin symmetry with $^{10}$Be",
    "authors": "Takayuki Myo, Mengjiao Lyu, Qing Zhao, Masahiro Isaka, Niu Wan, Hiroki Takemoto, Hisashi Horiuchi, Hiroshi Toki, Akinobu Doté",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10172v1",
    "source": "arXiv",
    "abstract": "We investigate the structures of $^{10}$C focusing on the quadrupole properties in comparison with the mirror nucleus $^{10}$Be. We describe $^{10}$C and $^{10}$Be in the variation of the multiple bases of the antisymmetrized molecular dynamics (AMD), in which the multiple AMD bases are optimized simultaneously in the total-energy variation. In the monopole transitions, we confirm the isospin symmetry between $^{10}$C and $^{10}$Be by exchanging protons and neutrons. In the quadrupole transitions, most cases show larger values in $^{10}$C than those of $^{10}$Be, except for the transition of $2^+_1\\to 0^+_1$. The transition of $2^+_1\\to 0^+_1$ shows similar values in the two nuclei in spite of the different proton numbers, which agrees with the experimental situation as an anomaly. This relation comes from the small proton deformation in $^{10}$C due to its subclosed nature and the large proton deformation in $^{10}$Be due to two-$α$ clustering. This property can also be seen in the quadrupole moments of the two nuclei. In the neutron deformations of $^{10}$C and $^{10}$Be, the opposite tendency of protons is confirmed and these results ensure the isospin symmetry between the two nuclei. We also confirm the large quadrupole transitions between the elongated linear-chain states. It would be desirable for future experiments to investigate the present characteristics of the transitions in the two nuclei."
  },
  {
    "date": "2026-01-15",
    "title": "Towards Online Malware Detection using Process Resource Utilization Metrics",
    "authors": "Themistoklis Diamantopoulos, Dimosthenis Natsos, Andreas L. Symeonidis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10164v1",
    "source": "arXiv",
    "abstract": "The rapid growth of Cloud Computing and Internet of Things (IoT) has significantly increased the interconnection of computational resources, creating an environment where malicious software (malware) can spread rapidly. To address this challenge, researchers are increasingly utilizing Machine Learning approaches to identify malware through behavioral (i.e. dynamic) cues. However, current approaches are limited by their reliance on large labeled datasets, fixed model training, and the assumption that a trained model remains effective over time-disregarding the ever-evolving sophistication of malware. As a result, they often fail to detect evolving malware attacks that adapt over time. This paper proposes an online learning approach for dynamic malware detection, that overcomes these limitations by incorporating temporal information to continuously update its models using behavioral features, specifically process resource utilization metrics. By doing so, the proposed models can incrementally adapt to emerging threats and detect zero-day malware effectively. Upon evaluating our approach against traditional batch algorithms, we find it effective in detecting zero-day malware. Moreover, we demonstrate its efficacy in scenarios with limited data availability, where traditional batch-based approaches often struggle to perform reliably."
  },
  {
    "date": "2026-01-15",
    "title": "AWED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion Speakers",
    "authors": "Prachuryya Kaushik, Ashish Anand",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10161v1",
    "source": "arXiv",
    "abstract": "We introduce AWED-FiNER, an open-source ecosystem designed to bridge the gap in Fine-grained Named Entity Recognition (FgNER) for 36 global languages spoken by more than 6.6 billion people. While Large Language Models (LLMs) dominate general Natural Language Processing (NLP) tasks, they often struggle with low-resource languages and fine-grained NLP tasks. AWED-FiNER provides a collection of agentic toolkits, web applications, and several state-of-the-art expert models that provides FgNER solutions across 36 languages. The agentic tools enable to route multilingual text to specialized expert models and fetch FgNER annotations within seconds. The web-based platforms provide ready-to-use FgNER annotation service for non-technical users. Moreover, the collection of language specific extremely small sized open-source state-of-the-art expert models facilitate offline deployment in resource contraint scenerios including edge devices. AWED-FiNER covers languages spoken by over 6.6 billion people, including a specific focus on vulnerable languages such as Bodo, Manipuri, Bishnupriya, and Mizo. The resources can be accessed here: Agentic Tool (https://github.com/PrachuryyaKaushik/AWED-FiNER), Web Application (https://hf.co/spaces/prachuryyaIITG/AWED-FiNER), and 49 Expert Detector Models (https://hf.co/collections/prachuryyaIITG/awed-finer)."
  },
  {
    "date": "2026-01-15",
    "title": "MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging",
    "authors": "Leonard Nürnberg, Dennis Bontempi, Suraj Pai, Curtis Lisle, Steve Pieper, Ron Kikinis, Sil van de Leemput, Rahul Soni, Gowtham Murugesan, Cosmin Ciausu, Miriam Groeneveld, Felix J. Dorfner, Jue Jiang, Aneesh Rangnekar, Harini Veeraraghavan, Joeran S. Bosma, Keno Bressem, Raymond Mak, Andrey Fedorov, Hugo JWL Aerts",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10154v1",
    "source": "arXiv",
    "abstract": "Artificial intelligence (AI) has the potential to transform medical imaging by automating image analysis and accelerating clinical research. However, research and clinical use are limited by the wide variety of AI implementations and architectures, inconsistent documentation, and reproducibility issues. Here, we introduce MHub.ai, an open-source, container-based platform that standardizes access to AI models with minimal configuration, promoting accessibility and reproducibility in medical imaging. MHub.ai packages models from peer-reviewed publications into standardized containers that support direct processing of DICOM and other formats, provide a unified application interface, and embed structured metadata. Each model is accompanied by publicly available reference data that can be used to confirm model operation. MHub.ai includes an initial set of state-of-the-art segmentation, prediction, and feature extraction models for different modalities. The modular framework enables adaptation of any model and supports community contributions. We demonstrate the utility of the platform in a clinical use case through comparative evaluation of lung segmentation models. To further strengthen transparency and reproducibility, we publicly release the generated segmentations and evaluation metrics and provide interactive dashboards that allow readers to inspect individual cases and reproduce or extend our analysis. By simplifying model use, MHub.ai enables side-by-side benchmarking with identical execution commands and standardized outputs, and lowers the barrier to clinical translation."
  },
  {
    "date": "2026-01-15",
    "title": "Leveraging Digital Twin Technologies: All-Photonics Networks-as-a-Service for Data Center Xchange in the Era of AI [Invited Tutorial]",
    "authors": "Hideki Nishizawa, Kazuya Anazawa, Tetsuro Inui, Toru Mano, Takeo Sasai, Giacomo Borraccini, Tatsuya Matsumura, Hiroyuki Ishihara, Sae Kojima, Yoshiaki Sone, Koichi Takasugi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10153v1",
    "source": "arXiv",
    "abstract": "This paper presents a data center exchange (Data Center Xchange, DCX) architecture for all-photonics networks-as-a-service in distributed data center infrastructures, enabling the creation of a virtual large-scale data center by directly interconnecting distributed data centers in metropolitan areas. Key requirements for such an architecture are identified: support for low-latency operations, scalability, reliability, and flexibility within a single network architecture; the ability to add new operator-driven automation functionalities based on an open networking approach; and the ability to control and manage remotely deployed transponders connected via access links with unknown physical parameters. We propose a set of technologies that enable digital twin operations for optical networks, including a cloud-native architecture for coherent transceivers, remote transponder control, fast end-to-end optical path provisioning, transceiver-based physical-parameter estimation incorporating digital longitudinal monitoring, and optical line system calibration, demonstrating their feasibility through field validations."
  },
  {
    "date": "2026-01-15",
    "title": "Microwave Kerr/Faraday Resonance in Two-dimensional Chiral Superconductors",
    "authors": "Taiki Matsushita, Jun'ichi Ieda, Yasufumi Araki, Takahiro Morimoto, Ilya Vekhter, Youichi Yanase",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10151v1",
    "source": "arXiv",
    "abstract": "We investigate the polar Kerr and Faraday effects in two-dimensional multiband chiral superconductors. We show that the clapping modes--the relative phase and amplitude oscillations between two chiral components of the superconducting order parameter--lie well within the quasiparticle excitation gap in multiband systems and dominate these magneto-optical responses in the microwave regime. The Kerr and Faraday rotation angles exhibit the resonant enhancement with sign reversals in the microwave regime as a function of the light frequency, reaching peak values on the order of 100 nrad--10 $μ$rad in thin films of candidate chiral superconductors. These resonances are accessible in superconducting atomic layer materials and provide a generic probe of chiral superconductivity in two-dimensional systems."
  },
  {
    "date": "2026-01-15",
    "title": "New Second-order Convergent Schemes for Solving decoupled FBSDEs",
    "authors": "Wenbo Wang, Guangyan Jia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10149v1",
    "source": "arXiv",
    "abstract": "This paper proposes a new second-order symmetric algorithm for solving decoupled forward-backward stochastic differential equations. Inspired by the alternating direction implicit splitting method for partial differential equations, we split the generator into the sum of two functions. In the computation of the value process Y, explicit and implicit schemes are alternately applied to these two generators, while the algorithms from \\citep{ZhaoLi2014} are used for the control process Z. We rigorously prove that the two new schemes have second-order convergence rate. The proposed splitting methods show clear advantages for equations whose generator consists of a linear part plus a nonlinear part, as they reduce the number of iterations required for solving implicit schemes, thereby decreasing computational cost while maintaining second-order convergence. Two numerical examples are provided, including the backward stochastic Riccati equation arising in mean-variance hedging. The numerical results verify the theoretical error analysis and demonstrate the advantage of reduced computational cost compared to the algorithm in \\citep{ZhaoLi2014}."
  },
  {
    "date": "2026-01-15",
    "title": "Comparison of SCAN+U and r2SCAN+U for Charge Density Wave Instability and Lattice Dynamics in CuTe",
    "authors": "Seungha Ju, Sooran Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10146v1",
    "source": "arXiv",
    "abstract": "Identifying an appropriate exchange-correlation functional and computational conditions is essential for explaining the fundamental physics of materials and predicting their properties. Here, we investigate the performance of the meta-GGA functionals SCAN and r2SCAN, with and without a Hubbard U, for describing the charge density wave (CDW) in the quasi-one-dimensional material CuTe. By examining the Te-Te bond modulation, phonon dispersions, and electronic structures, we identify clear differences in how the two functionals capture the structural and dynamical properties of the CDW formation. r2SCAN+U reproduces the experimentally observed Te-chain distortions in the CDW phase and the phonon soft mode at qCDW=(0.4, 0.0, 0.5) in the non-CDW phase, whereas SCAN exhibits unphysical phonon behavior. The atomic displacements of the soft mode agree well with the experimental Te modulation. Despite their similar electronic structures and optimized lattice constants, our results demonstrate that r2SCAN is a more suitable choice than SCAN for describing CDW formation and lattice dynamics in CuTe."
  },
  {
    "date": "2026-01-15",
    "title": "History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis",
    "authors": "Haochong Xia, Yao Long Teng, Regan Tan, Molei Qin, Xinrun Wang, Bo An",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10143v1",
    "source": "arXiv",
    "abstract": "In quantitative finance, the gap between training and real-world performance-driven by concept drift and distributional non-stationarity-remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra \"History Is Not Enough\" underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. We present a drift-aware dataflow system that integrates machine learning-based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner-scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that our framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data."
  },
  {
    "date": "2026-01-15",
    "title": "A new contraction principle on the perimeters of triangles and related results",
    "authors": "Tanusri Senapati",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10138v1",
    "source": "arXiv",
    "abstract": "In this article, we introduce a new type of mapping contracting perimeters of triangles in a complete metric space and present related fixed point theorem. We study the metric completeness property of the underlying space in terms of fixed point of our newly introduced mapping. In support of our result, we present several examples."
  },
  {
    "date": "2026-01-15",
    "title": "Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent Tree-Query and Adversarial Confidence Estimation",
    "authors": "Ziyi Ding, Chenfei Ye-Hao, Zheyuan Wang, Xiao-Ping Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10137v1",
    "source": "arXiv",
    "abstract": "Causal discovery aims to recover ``what causes what'', but classical constraint-based methods (e.g., PC, FCI) suffer from error propagation, and recent LLM-based causal oracles often behave as opaque, confidence-free black boxes. This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework that reduces pairwise causal discovery to a short sequence of queries about backdoor paths, (in)dependence, latent confounding, and causal direction, yielding interpretable judgments with robustness-aware confidence scores. Theoretical guarantees are provided for asymptotic identifiability of four pairwise relations. On data-free benchmarks derived from Mooij et al. and UCI causal graphs, Tree-Query improves structural metrics over direct LLM baselines, and a diet--weight case study illustrates confounder screening and stable, high-confidence causal conclusions. Tree-Query thus offers a principled way to obtain data-free causal priors from LLMs that can complement downstream data-driven causal discovery. Code is available at https://anonymous.4open.science/r/Repo-9B3E-4F96."
  },
  {
    "date": "2026-01-15",
    "title": "A volume penalization method for solving conjugate scalar transport with interfacial jump conditions",
    "authors": "Ming Liu, Yosuke Hasegawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10134v1",
    "source": "arXiv",
    "abstract": "Conjugate scalar transport with interfacial jump conditions on complex interfacial geometries is common in thermal and chemical processes, while its accurate and efficient simulations are still quite challenging. In the present study, a novel treatment of a two-phase interface in the volume penalization method, a kind of immersed boundary method, for solving conjugate scalar transport with general interfacial boundary conditions is developed. We first propose an interfacial treatment for solving an advection-diffusion equation with a Neumann boundary condition, and then extend it to general conjugate scalar transport with both interfacial flux and scalar jumps. A one-dimensional diffusion problem is solved to verify the present scheme and demonstrate the advantage of the present scheme in improving accuracy and unifying the governing equations in the two phases with an additional source term representing the local jump condition of the interfacial scalar flux. Then, the present scheme is further applied to fluid-solid coupled scalar diffusion and advection-diffusion problems with the scalar and its flux jumps across the interface. The simulation results of the present scheme generally show good agreement with reference results obtained by body-fitted mesh simulations with average relative deviations less than 3.0%."
  },
  {
    "date": "2026-01-15",
    "title": "Redundancy-Driven Top-$k$ Functional Dependency Discovery",
    "authors": "Xiaolong Wan, Xixian Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10130v1",
    "source": "arXiv",
    "abstract": "Functional dependencies (FDs) are basic constraints in relational databases and are used for many data management tasks. Most FD discovery algorithms find all valid dependencies, but this causes two problems. First, the computational cost is prohibitive: computational complexity grows quadratically with the number of tuples and exponentially with the number of attributes, making discovery slow on large-scale and high-dimensional data. Second, the result set can be huge, making it hard to identify useful dependencies. We propose SDP (Selective-Discovery-and-Prune), which discovers the top-$k$ FDs ranked by redundancy count. Redundancy count measures how much duplicated information an FD explains and connects directly to storage overhead and update anomalies. SDP uses an upper bound on redundancy to prune the search space. It is proved that this upper bound is monotone: adding attributes refines partitions and thus decreases the bound. Once the bound falls below the top-$k$ threshold, the entire branch can be skipped. We improve SDP with three optimizations: ordering attributes by partition cardinality, using pairwise statistics in a Partition Cardinality Matrix to tighten bounds, and a global scheduler to explore promising branches first. Experiments on over 40 datasets show that SDP is much faster and uses less memory than exhaustive methods."
  },
  {
    "date": "2026-01-15",
    "title": "TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems",
    "authors": "Rui Sun, Jie Ding, Chenghua Gong, Tianjun Gu, Yihang Jiang, Juyuan Zhang, Liming Pan, Linyuan Lü",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10120v1",
    "source": "arXiv",
    "abstract": "Optimizing communication topology in LLM-based multi-agent system is critical for enabling collective intelligence. Existing methods mainly rely on spatio-temporal interaction paradigms, where the sequential execution of multi-round dialogues incurs high latency and computation. Motivated by the recent insights that evaluation and debate mechanisms can improve problem-solving in multi-agent systems, we propose TopoDIM, a framework for one-shot Topology generation with Diverse Interaction Modes. Designed for decentralized execution to enhance adaptability and privacy, TopoDIM enables agents to autonomously construct heterogeneous communication without iterative coordination, achieving token efficiency and improved task performance. Experiments demonstrate that TopoDIM reduces total token consumption by 46.41% while improving average performance by 1.50% over state-of-the-art methods. Moreover, the framework exhibits strong adaptability in organizing communication among heterogeneous agents. Code is available at: https://anonymous.4open.science/r/TopoDIM-8D35/"
  },
  {
    "date": "2026-01-15",
    "title": "Multi-Constrained Evolutionary Molecular Design Framework: An Interpretable Drug Design Method Combining Rule-Based Evolution and Molecular Crossover",
    "authors": "Shanxian Lin, Wei Xia, Yuichi Nagata, Haichuan Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10110v1",
    "source": "arXiv",
    "abstract": "This study proposes MCEMOL (Multi-Constrained Evolutionary Molecular Design Framework), a molecular optimization approach integrating rule-based evolution with molecular crossover. MCEMOL employs dual-layer evolution: optimizing transformation rules at rule level while applying crossover and mutation to molecular structures. Unlike deep learning methods requiring large datasets and extensive training, our algorithm evolves efficiently from minimal starting molecules with low computational overhead. The framework incorporates message-passing neural networks and comprehensive chemical constraints, ensuring efficient and interpretable molecular design. Experimental results demonstrate that MCEMOL provides transparent design pathways through its evolutionary mechanism while generating valid, diverse, target-compliant molecules. The framework achieves 100% molecular validity with high structural diversity and excellent drug-likeness compliance, showing strong performance in symmetry constraints, pharmacophore optimization, and stereochemical integrity. Unlike black-box methods, MCEMOL delivers dual value: interpretable transformation rules researchers can understand and trust, alongside high-quality molecular libraries for practical applications. This establishes a paradigm where interpretable AI-driven drug design and effective molecular generation are achieved simultaneously, bridging the gap between computational innovation and practical drug discovery needs."
  },
  {
    "date": "2026-01-15",
    "title": "Enhancing Visual In-Context Learning by Multi-Faceted Fusion",
    "authors": "Wenwen Liao, Jianbo Yu, Yuansong Wang, Qingchao Jiang, Xiaofeng Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10107v1",
    "source": "arXiv",
    "abstract": "Visual In-Context Learning (VICL) has emerged as a powerful paradigm, enabling models to perform novel visual tasks by learning from in-context examples. The dominant \"retrieve-then-prompt\" approach typically relies on selecting the single best visual prompt, a practice that often discards valuable contextual information from other suitable candidates. While recent work has explored fusing the top-K prompts into a single, enhanced representation, this still simply collapses multiple rich signals into one, limiting the model's reasoning capability. We argue that a more multi-faceted, collaborative fusion is required to unlock the full potential of these diverse contexts. To address this limitation, we introduce a novel framework that moves beyond single-prompt fusion towards an multi-combination collaborative fusion. Instead of collapsing multiple prompts into one, our method generates three contextual representation branches, each formed by integrating information from different combinations of top-quality prompts. These complementary guidance signals are then fed into proposed MULTI-VQGAN architecture, which is designed to jointly interpret and utilize collaborative information from multiple sources. Extensive experiments on diverse tasks, including foreground segmentation, single-object detection, and image colorization, highlight its strong cross-task generalization, effective contextual fusion, and ability to produce more robust and accurate predictions than existing methods."
  },
  {
    "date": "2026-01-15",
    "title": "MATRIX AS PLAN: Structured Logical Reasoning with Feedback-Driven Replanning",
    "authors": "Ke Chen, Jiandian Zeng, Zihao Peng, Guo Li, Guangxue Zhang, Tian Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10101v1",
    "source": "arXiv",
    "abstract": "As knowledge and semantics on the web grow increasingly complex, enhancing Large Language Models (LLMs) comprehension and reasoning capabilities has become particularly important. Chain-of-Thought (CoT) prompting has been shown to enhance the reasoning capabilities of LLMs. However, it still falls short on logical reasoning tasks that rely on symbolic expressions and strict deductive rules. Neuro-symbolic methods address this gap by enforcing formal correctness through external solvers. Yet these solvers are highly format-sensitive, and small instabilities in model outputs can lead to frequent processing failures. LLM-driven approaches avoid parsing brittleness, but they lack structured representations and process-level error-correction mechanisms. To further enhance the logical reasoning capabilities of LLMs, we propose MatrixCoT, a structured CoT framework with a matrix-based plan. Specifically, we normalize and type natural language expressions, attach explicit citation fields, and introduce a matrix-based planning method to preserve global relations among steps. The plan becomes a verifiable artifact, making execution more stable. For verification, we also add a feedback-driven replanning mechanism. Under semantic-equivalence constraints, it identifies omissions and defects, rewrites and compresses the dependency matrix, and produces a more trustworthy final answer. Experiments on five logical-reasoning benchmarks and five LLMs show that, without relying on external solvers, MatrixCoT enhances both robustness and interpretability when tackling complex symbolic reasoning tasks, while maintaining competitive performance."
  },
  {
    "date": "2026-01-15",
    "title": "Caught in Swallowtails: Discovery of Two Swallowtail Image Formations in MS 0451.6-0305",
    "authors": "Ashish K. Meena, Wenlei Chen, Lukas J. Furtak, Johan Richard, Adi Zitrin, Jose M. Diego, Mathilde Jauzac, Patrick L. Kelly, Rogier A. Windhorst",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10097v1",
    "source": "arXiv",
    "abstract": "We report the discovery of two swallowtail image formations at $z=2.91$ and $z=6.70$ behind the galaxy cluster MS 0451.6-0305 in JWST-NIRCam imaging. We find that in both of the above lensed systems, the complex image morphology cannot be reproduced by simple fold/cusp caustics, and detailed lens modeling reveals higher-order swallowtail caustic configurations. In the $z=2.91$ lens system, a small part of the source galaxy (which itself is part of a galaxy group) containing atleast two compact knots sits inside the swallowtail caustic, producing a quadruply imaged arc. At two of the image positions of these knots, we infer point source magnifications of $\\gtrsim 300$, implying lensing-corrected effective radii of $\\lesssim 0.8-1.5$ pc. The $z=6.70$ system exhibits even more complex image formation. We therefore only use the most confidently identified counter-images of knots in this system as constraints in our lens modeling. The resulting model predicts magnifications $\\sim20-200$ and lensing-corrected effective radii of $\\lesssim 0.8-18.5$ pc for various knots. Together, these two systems represent the first example of observations of multiple swallowtail image formations in a single galaxy cluster and demonstrate the ability of swallowtail caustics to magnify individual substructures at sub-parsec scales, from intermediate redshifts to the first billion years of the Universe."
  },
  {
    "date": "2026-01-15",
    "title": "Mark My Works Autograder for Programming Courses",
    "authors": "Yiding Qiu, Seyed Mahdi Azimi, Artem Lensky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10093v1",
    "source": "arXiv",
    "abstract": "Large programming courses struggle to provide timely, detailed feedback on student code. We developed Mark My Works, a local autograding system that combines traditional unit testing with LLM-generated explanations. The system uses role-based prompts to analyze submissions, critique code quality, and generate pedagogical feedback while maintaining transparency in its reasoning process. We piloted the system in a 191-student engineering course, comparing AI-generated assessments with human grading on 79 submissions. While AI scores showed no linear correlation with human scores (r = -0.177, p = 0.124), both systems exhibited similar left-skewed distributions, suggesting they recognize comparable quality hierarchies despite different scoring philosophies. The AI system demonstrated more conservative scoring (mean: 59.95 vs 80.53 human) but generated significantly more detailed technical feedback."
  },
  {
    "date": "2026-01-15",
    "title": "Diquark mass and quark-diquark potential by lattice QCD using an extended HAL QCD method with a static quark",
    "authors": "Kai-Wen Kelvin-Lee, Noriyoshi Ishii",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10091v1",
    "source": "arXiv",
    "abstract": "We will calculate the diquark mass together with the quark-diquark potential. We apply an extended HAL QCD potential method to a baryonic system made up from a static quark and a diquark. Numerical calculations are performed by employing 2+1 flavor QCD gaugeconfigurations generated by CP-PACS and JLQCD Collaborations on a $16^{3} \\times 32$ lattice with $a^{-1} \\approx 1.6$ GeV. To improve the statistical noise in the propagators of the static quark, the HYP smearing is employed on the gauge links. Two-point correlators of quark-diquark baryonic system are then computed to obtain their ground-state energies where various types of diquarks are considered (eg: scalar diquark, axial-vector diquark etc). We apply an extended HAL QCD method on a baryonic system made up from a scalar diquark and a static quark to study the scalar diquark mass and the quark-diquark potential. In order to determine the diquark mass self-consistently in this HALQCD method, we demand that the baryonic spectrum in the p-wave sector obtained from the two-point correlators should be reproduced by the potential obtained from the baryonic system in the s-wave sector. We obtain the scalar diquark mass of roughly $(2/3) m_{N}$ , i.e., twice the naïve estimates of a constituent quark mass together with the quark-diquark potential of Cornell type (Coulomb + linear)."
  },
  {
    "date": "2026-01-15",
    "title": "Bayesian Meta-Analyses Could Be More: A Case Study in Trial of Labor After a Cesarean-section Outcomes and Complications",
    "authors": "Ashley Klein, Edward Raff, Marcia DesJardin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10089v1",
    "source": "arXiv",
    "abstract": "The meta-analysis's utility is dependent on previous studies having accurately captured the variables of interest, but in medical studies, a key decision variable that impacts a physician's decisions was not captured. This results in an unknown effect size and unreliable conclusions. A Bayesian approach may allow analysis to determine if the claim of a positive effect is still warranted, and we build a Bayesian approach to this common medical scenario. To demonstrate its utility, we assist professional OBGYNs in evaluating Trial of Labor After a Cesarean-section (TOLAC) situations where few interventions are available for patients and find the support needed for physicians to advance patient care."
  },
  {
    "date": "2026-01-15",
    "title": "Starfield: Demand-Aware Satellite Topology Design for Low-Earth Orbit Mega Constellations",
    "authors": "Shayan Hamidi Dehshali, Tzu-Hsuan Liao, Shaileshh Bojja Venkatakrishnan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10083v1",
    "source": "arXiv",
    "abstract": "Low-Earth orbit (LEO) mega-constellations are emerging as high-capacity backbones for next-generation Internet. Deployment of laser terminals enables high-bandwidth, low-latency inter-satellite links (ISLs); however, their limited number, slow acquisition, and instability make forming a stable satellite topology difficult. Existing patterns like +Grid and Motif ignore regional traffic, ground station placement, and constellation geometry. Given sparse population distribution on Earth and the isolation of rural areas, traffic patterns are inherently non-uniform, providing an opportunity to orient inter-satellite links (ISLs) according to these traffic patterns. In this paper, we propose Starfield, a novel demand-aware satellite topology design heuristic algorithm supported by mathematical analysis. We first formulate a vector field on the constellation's shell according to traffic flows and define a corresponding Riemannian metric on the spherical manifold of the shell. The metric, combined with the spatial geometry, is used to assign a distance to each potential ISL, which we then aggregate over all demand flows to generate a heuristic for each satellite's link selection. Inspired by +Grid, each satellite selects the link with the minimum Riemannian heuristic along with its corresponding angular links. To evaluate Starfield, we developed a custom, link-aware, and link-configurable packet-level simulator, comparing it against +Grid and Random topologies. For the Phase 1 Starlink, simulation results show up to a 30% reduction in hop count and a 15% improvement in stretch factor across multiple traffic distributions. Moreover, static Starfield, an inter-orbital link matching modification of Starfield, achieves a 20% improvement in stretch factor under realistic traffic patterns compared to +Grid. Experiments further demonstrate Starfield's robustness under traffic demand perturbations."
  },
  {
    "date": "2026-01-15",
    "title": "Thinking Like Van Gogh: Structure-Aware Style Transfer via Flow-Guided 3D Gaussian Splatting",
    "authors": "Zhendong Wang, Lebin Zhou, Jingchuan Xiao, Rongduo Han, Nam Ling, Cihan Ruan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10075v1",
    "source": "arXiv",
    "abstract": "In 1888, Vincent van Gogh wrote, \"I am seeking exaggeration in the essential.\" This principle, amplifying structural form while suppressing photographic detail, lies at the core of Post-Impressionist art. However, most existing 3D style transfer methods invert this philosophy, treating geometry as a rigid substrate for surface-level texture projection. To authentically reproduce Post-Impressionist stylization, geometric abstraction must be embraced as the primary vehicle of expression. We propose a flow-guided geometric advection framework for 3D Gaussian Splatting (3DGS) that operationalizes this principle in a mesh-free setting. Our method extracts directional flow fields from 2D paintings and back-propagates them into 3D space, rectifying Gaussian primitives to form flow-aligned brushstrokes that conform to scene topology without relying on explicit mesh priors. This enables expressive structural deformation driven directly by painterly motion rather than photometric constraints. Our contributions are threefold: (1) a projection-based, mesh-free flow guidance mechanism that transfers 2D artistic motion into 3D Gaussian geometry; (2) a luminance-structure decoupling strategy that isolates geometric deformation from color optimization, mitigating artifacts during aggressive structural abstraction; and (3) a VLM-as-a-Judge evaluation framework that assesses artistic authenticity through aesthetic judgment instead of conventional pixel-level metrics, explicitly addressing the subjective nature of artistic stylization."
  },
  {
    "date": "2026-01-15",
    "title": "Simplicial spheres with $g_k=1$",
    "authors": "Isabella Novik, Hailun Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10072v1",
    "source": "arXiv",
    "abstract": "For $d\\geq 4$, Kalai (1987) characterized all simplicial $(d-1)$-spheres with $g_2=0$, and for $k\\geq 2$ and $d\\geq 2k$, Murai and Nevo (2013) characterized all simplicial $(d-1)$-spheres with $g_k=0$. In addition, for $d\\geq 4$, Nevo and Novinsky (2011) characterized all simplicial $(d-1)$-spheres with $g_2=1$. Motivated by these results, we characterize, for any $k\\geq 2$ and $d\\geq 2k+1$, all simplicial $(d-1)$-spheres with no missing faces of dimension larger than $d-k$ that satisfy $g_k=1$. When $d=2k$, we obtain a characterization of simplicial $(d-1)$-spheres with $g_k=1$ and no missing faces of dimension greater than $k$, under the additional assumption that there exists at least one missing face of dimension $k$. Finally, for $k=3$, we are able to remove this assumption and characterize all simplicial $5$-spheres with no missing faces of dimension larger than $3$ that satisfy $g_3=1$."
  },
  {
    "date": "2026-01-15",
    "title": "Global convergence of the subgradient method for robust signal recovery",
    "authors": "Zesheng Cai, Lexiao Lai, Tiansheng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10062v1",
    "source": "arXiv",
    "abstract": "We study the subgradient method for factorized robust signal recovery problems, including robust PCA, robust phase retrieval, and robust matrix sensing. These objectives are nonsmooth and nonconvex, and may have unbounded sublevel sets, so standard arguments for analyzing first-order optimization algorithms based on descent and coercivity do not apply. For locally Lipschitz semialgebraic objectives, we develop a convergence framework under the assumption that continuous-time subgradient trajectories are bounded: for sufficiently small step sizes of order \\(1/k\\), any subgradient sequence remains bounded and converges to a critical point. We verify this trajectory boundedness assumption for the robust objectives by adapting and extending existing trajectory analyses, requiring only a mild nondegeneracy condition in the matrix sensing case. Finally, for rank-one symmetric robust PCA, we show that the subgradient method avoids spurious critical points for almost every initialization, and therefore converges to a global minimum under the same step-size regime."
  },
  {
    "date": "2026-01-15",
    "title": "Unlabeled Data Can Provably Enhance In-Context Learning of Transformers",
    "authors": "Renpu Liu, Jing Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10058v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) exhibit impressive in-context learning (ICL) capabilities, yet the quality of their predictions is fundamentally limited by the few costly labeled demonstrations that can fit into a prompt. Meanwhile, there exist vast and continuously growing amounts of unlabeled data that may be closely related to the ICL task. How to utilize such unlabeled data to provably enhance the performance of ICL thus becomes an emerging fundamental question. In this work, we propose a novel augmented ICL framework, in which the prompt includes a small set of labeled examples alongside a block of unlabeled inputs. We focus on the multi-class linear classification setting and demonstrate that, with chain-of-thought (CoT) prompting, a multi-layer transformer can effectively emulate an expectation-maximization (EM) algorithm. This enables the transformer to implicitly extract useful information from both labeled and unlabeled data, leading to provable improvements in ICL accuracy. Moreover, we show that such a transformer can be trained via teacher forcing, with its parameters converging to the desired solution at a linear rate. Experiments demonstrate that the augmented ICL framework consistently outperforms conventional few-shot ICL, providing empirical support for our theoretical findings. To the best of our knowledge, this is the first theoretical study on the impact of unlabeled data on the ICL performance of transformers."
  },
  {
    "date": "2026-01-15",
    "title": "Disentangled Concept Representation for Text-to-image Person Re-identification",
    "authors": "Giyeol Kim, Chanho Eom",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10053v1",
    "source": "arXiv",
    "abstract": "Text-to-image person re-identification (TIReID) aims to retrieve person images from a large gallery given free-form textual descriptions. TIReID is challenging due to the substantial modality gap between visual appearances and textual expressions, as well as the need to model fine-grained correspondences that distinguish individuals with similar attributes such as clothing color, texture, or outfit style. To address these issues, we propose DiCo (Disentangled Concept Representation), a novel framework that achieves hierarchical and disentangled cross-modal alignment. DiCo introduces a shared slot-based representation, where each slot acts as a part-level anchor across modalities and is further decomposed into multiple concept blocks. This design enables the disentanglement of complementary attributes (\\textit{e.g.}, color, texture, shape) while maintaining consistent part-level correspondence between image and text. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that our framework achieves competitive performance with state-of-the-art methods, while also enhancing interpretability through explicit slot- and block-level representations for more fine-grained retrieval results."
  },
  {
    "date": "2026-01-15",
    "title": "Revisiting the nuclear island of negative hexadecapole deformations in A$\\approx$180 mass region: focusing on moments of inertia and quadrupole-hexadecapole coupling",
    "authors": "Ran Li, Hua-Lei Wang, Kui Xiao, Zhen-Zhen Zhang, Min-Liang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10052v1",
    "source": "arXiv",
    "abstract": "For even-even nuclei $^{180-184}$Yb, $^{182-186}$Hf and $^{184-188}$W located on an island of hexadecapole-deformation archipelago, the structure properties, especially under rotation, are reinvestigated by using the Hartree-Fock-Bogliubov-Cranking (HFBC) calculation with a fixed shape (e.g., the ground-state equilibrium shape). The equilibrium deformations, extracted from the potential energy surface, are calculated based on the phenomenological Woods-Saxon mean-field Hamiltonian within the framework of macroscopic-microscopic (MM) model. The impact of different deformation degrees of freedom on, e.g., single-particle levels, total energy, and moment of inertia, is revealed, especially concentrating on the hexadecapole-deformation effects and the quadrupole-hexadecapole coupling. Considering the axially hexadecapole deformation, the present calculations can well reproduce available experimental data, including the quadrupole deformations and moments of inertia. Interestingly, it is found that the impact of different deformation degrees of freedom on moment of inertia exhibits a similar trend in the HFBC and rigid-body calculations though the latter ignores the pairing effects. Before starting or constructing a complex theory-model, to some extent, such a similarity can provide an alternative way of understanding the effect of, e.g., exotic deformations, on moment of inertia by the calculation of a simple rigid-body approximation. The present findings could offer insights into the static and dynamic effects of hexadecapole deformations, contributing valuable information for the corresponding research in nuclear structure and reaction."
  },
  {
    "date": "2026-01-15",
    "title": "A note on exact approximations",
    "authors": "Sergei Pitcyn",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10051v1",
    "source": "arXiv",
    "abstract": "Based on M. Hall's theorem we prove a simple result dealing with real numbers which admit exact approximations by rationals."
  },
  {
    "date": "2026-01-15",
    "title": "Weighted least squares estimation by multivariate-dependent weights for linear regression models",
    "authors": "Lei Huang, Chengyue Liu, Li Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10049v1",
    "source": "arXiv",
    "abstract": "Multivariate linear regression models often face the problem of heteroscedasticity caused by multiple explanatory variables. The weighted least squares estimation with univariate-dependent weights has limitations in constructing weight functions. Therefore, this paper proposes a multivariate dependent weighted least squares estimation method. By constructing a linear combination of explanatory variables and maximizing their Spearman rank correlation coefficient with the absolute residual value, combined with maximum likelihood method to depict heteroscedasticity, it can comprehensively reflect the trend of variance changes in the random error and improve the accuracy of the model. This paper demonstrates that the optimal linear combination exponent estimator for heteroscedastic volatility obtained by our algorithm possesses consistency and asymptotic normality. In the simulation experiment, three scenarios of heteroscedasticity were designed, and the comparison showed that the proposed method was superior to the univariate-dependent weighting method in parameter estimation and model prediction. In the real data applications, the proposed method was applied to two real-world datasets about consumer spending in China and housing prices in Boston. From the perspectives of MAE, RSE, cross-validation, and fitting performance, its accuracy and stability were verified in terms of model prediction, interval estimation, and generalization ability. Additionally, the proposed method demonstrated relative advantages in fitting data with large fluctuations. This study provides an effective new approach for dealing with heteroscedasticity in multivariate linear regression."
  },
  {
    "date": "2026-01-15",
    "title": "Collective behavior based on agent-environment interactions",
    "authors": "Gaston Briozzo, Gustavo J. Sibona, Fernando Peruani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10046v1",
    "source": "arXiv",
    "abstract": "We present a model of active particles interacting through a dynamic, heterogeneous environment, leading to emergent collective behaviors without direct agent-to-agent communication. Expanding the resource-dependent framework introduced in Briozzo et al., 2025, arXiv:2512.08762, agents perform a persistent random walk combined with chemotaxis, directing toward nutrient-rich patches, whose resources are generated by logistic regrowth. We identify distinct phases of collective organization, ranging from disordered gas-like states to polar traveling waves and nematic independent clusters, depending on the interplay between chemotactic sensitivity and angular noise. The system exhibits spontaneous symmetry breaking and density waves driven purely by the coupling between population dynamics (birth-death processes) and environmental feedback. Our results bridge active matter physics and movement ecology, demonstrating that complex spatiotemporal patterns can arise without direct interaction between agents, but solely from the maximization of resource intake in a reactive environment."
  },
  {
    "date": "2026-01-15",
    "title": "Instruction Finetuning LLaMA-3-8B Model Using LoRA for Financial Named Entity Recognition",
    "authors": "Zhiming Lian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10043v1",
    "source": "arXiv",
    "abstract": "Particularly, financial named-entity recognition (NER) is one of the many important approaches to translate unformatted reports and news into structured knowledge graphs. However, free, easy-to-use large language models (LLMs) often fail to differentiate organisations as people, or disregard an actual monetary amount entirely. This paper takes Meta's Llama 3 8B and applies it to financial NER by combining instruction fine-tuning and Low-Rank Adaptation (LoRA). Each annotated sentence is converted into an instruction-input-output triple, enabling the model to learn task descriptions while fine-tuning with small low-rank matrices instead of updating all weights. Using a corpus of 1,693 sentences, our method obtains a micro-F1 score of 0.894 compared with Qwen3-8B, Baichuan2-7B, T5, and BERT-Base. We present dataset statistics, describe training hyperparameters, and perform visualizations of entity density, learning curves, and evaluation metrics. Our results show that instruction tuning combined with parameter-efficient fine-tuning enables state-of-the-art performance on domain-sensitive NER."
  },
  {
    "date": "2026-01-15",
    "title": "On the Sasakian Structure of Manifolds with Nonnegative Transverse Bisectional Curvature",
    "authors": "Shu-Cheng Chang, Yingbo Han, Chien Lin, Chin-Tung Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10017v1",
    "source": "arXiv",
    "abstract": "In this paper, we concern with the Sasaki analogue of Yau uniformization conjecture in a complete noncompact Sasakian manifold with nonnegative transverse bisectional curvature. As a consequence, we confirm that any $5$-dimensional complete noncompact Sasakian manifold with positive transverse bisectional curvature and the maximal volume growth must be CR-biholomorphic to the standard Heisenberg group $\\mathbb{H}_{2}$ which can be stated as the standard contact Euclidean $5$-space $\\mathbb{R}^{5}$."
  },
  {
    "date": "2026-01-15",
    "title": "Electronic structure theory of H$_{3}$S: Plane-wave-like valence states, density-of-states peak and its guaranteed proximity to the Fermi level",
    "authors": "Ryosuke Akashi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10016v1",
    "source": "arXiv",
    "abstract": "Superconductivity in sulfur superhydride H$_{3}$S under extreme pressures has been explained theoretically, but it requires a peaked concentration of the electronic density of states (DOS), which has been found in first-principles calculations. The mechanism of this peak formation, though vital for its high transition temperature, has however remained obscure. We address this problem through detailed analysis of the first-principles electronic wave functions. The valence wave functions are shown to be significantly plane-wave-like. From the Fourier-mode analysis of the self-consistent potential and atomic pseudopotentials, we extract the nearly uniform models that accurately reproduce the first-principles band structure with very few parameters. The DOS peak is shown to be the consequence of the hybridization of specific plane waves. Adjacency of Jones' large zone to the plane-wave spherical Fermi surface is posited to be the root cause of the multiple plane-wave hybridization, the DOS peak formation and its proximity to the Fermi level. The present theory resolves the minimal modeling problem of electronic states in H$_{3}$S, as well as establishes a mechanism that may help to boost the transition temperatures in pressure induced superconductors."
  },
  {
    "date": "2026-01-15",
    "title": "PID-Guided Partial Alignment for Multimodal Decentralized Federated Learning",
    "authors": "Yanhang Shi, Xiaoyu Wang, Houwei Cao, Jian Li, Yong Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10012v1",
    "source": "arXiv",
    "abstract": "Multimodal decentralized federated learning (DFL) is challenging because agents differ in available modalities and model architectures, yet must collaborate over peer-to-peer (P2P) networks without a central coordinator. Standard multimodal pipelines learn a single shared embedding across all modalities. In DFL, such a monolithic representation induces gradient misalignment between uni- and multimodal agents; as a result, it suppresses heterogeneous sharing and cross-modal interaction. We present PARSE, a multimodal DFL framework that operationalizes partial information decomposition (PID) in a server-free setting. Each agent performs feature fission to factorize its latent representation into redundant, unique, and synergistic slices. P2P knowledge sharing among heterogeneous agents is enabled by slice-level partial alignment: only semantically shareable branches are exchanged among agents that possess the corresponding modality. By removing the need for central coordination and gradient surgery, PARSE resolves uni-/multimodal gradient conflicts, thereby overcoming the multimodal DFL dilemma while remaining compatible with standard DFL constraints. Across benchmarks and agent mixes, PARSE yields consistent gains over task-, modality-, and hybrid-sharing DFL baselines. Ablations on fusion operators and split ratios, together with qualitative visualizations, further demonstrate the efficiency and robustness of the proposed design."
  },
  {
    "date": "2026-01-15",
    "title": "Reentrant topological phases and entanglement scalings in moiré-modulated extended Su-Schrieffer-Heeger Model",
    "authors": "Guo-Qing Zhang, L. F. Quezada, Shi-Hai Dong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09997v1",
    "source": "arXiv",
    "abstract": "Recent studies of moiré physics have unveiled a wealth of opportunities for significantly advancing the field of quantum phase transitions. However, properties of reentrant phase transitions driven by moiré strength are poorly understood. Here, we investigate the reentrant sequence of phase transitions and the invariant of universality class in moiré-modulated extended Su-Schrieffer-Heeger (SSH) model. For the simplified case with intercell hopping $w=0$, we analytically derive renormalization relations of Hamiltonian parameters to explain the reentrant phenomenon. For the general case, numerical phase boundaries are calculated in the thermodynamic limit. The bulk boundary correspondence between zero-energy edge modes and entanglement spectrum is revealed from the degeneracy of both quantities. We also address the correspondence between the central charge obtained from entanglement entropy and the change in winding number during the phase transition. Our results shed light on the understanding of universal characteristics and bulk-boundary correspondence for moiré induced reentrant phase transitions in 1D condensed-matter systems."
  },
  {
    "date": "2026-01-15",
    "title": "Outrunning Big KATs: Efficient Decision Procedures for Variants of GKAT",
    "authors": "Cheng Zhang, Qiancheng Fu, Hang Ji, Ines Santacruz Del Valle, Alexandra Silva, Marco Gaboardi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09986v1",
    "source": "arXiv",
    "abstract": "This paper presents several efficient decision procedures for trace equivalence of GKAT automata, which make use of on-the-fly symbolic techniques via SAT solvers. To demonstrate applicability of our algorithms, we designed symbolic derivatives for CF-GKAT, a practical system based on GKAT designed to validate control-flow transformations. We implemented the algorithms in Rust and evaluated them on both randomly generated benchmarks and real-world control-flow transformations. Indeed, we observed order-of-magnitude performance improvements against existing implementations for both KAT and CF-GKAT. Notably, our experiments also revealed a bug in Ghidra, an industry-standard decompiler, highlighting the practical viability of these systems."
  },
  {
    "date": "2026-01-15",
    "title": "Context Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG",
    "authors": "David Samuel Setiawan, Raphaël Merx, Jey Han Lau",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09982v1",
    "source": "arXiv",
    "abstract": "Neural Machine Translation (NMT) models for low-resource languages suffer significant performance degradation under domain shift. We quantify this challenge using Dhao, an indigenous language of Eastern Indonesia with no digital footprint beyond the New Testament (NT). When applied to the unseen Old Testament (OT), a standard NMT model fine-tuned on the NT drops from an in-domain score of 36.17 chrF++ to 27.11 chrF++. To recover this loss, we introduce a hybrid framework where a fine-tuned NMT model generates an initial draft, which is then refined by a Large Language Model (LLM) using Retrieval-Augmented Generation (RAG). The final system achieves 35.21 chrF++ (+8.10 recovery), effectively matching the original in-domain quality. Our analysis reveals that this performance is driven primarily by the number of retrieved examples rather than the choice of retrieval algorithm. Qualitative analysis confirms the LLM acts as a robust \"safety net,\" repairing severe failures in zero-shot domains."
  },
  {
    "date": "2026-01-15",
    "title": "Federated Unlearning in Edge Networks: A Survey of Fundamentals, Challenges, Practical Applications and Future Directions",
    "authors": "Jer Shyuan Ng, Wathsara Daluwatta, Shehan Edirimannage, Charitha Elvitigala, Asitha Kottahachchi Kankanamge Don, Ibrahim Khalil, Heng Zhang, Dusit Niyato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09978v1",
    "source": "arXiv",
    "abstract": "The proliferation of connected devices and privacy-sensitive applications has accelerated the adoption of Federated Learning (FL), a decentralized paradigm that enables collaborative model training without sharing raw data. While FL addresses data locality and privacy concerns, it does not inherently support data deletion requests that are increasingly mandated by regulations such as the Right to be Forgotten (RTBF). In centralized learning, this challenge has been studied under the concept of Machine Unlearning (MU), that focuses on efficiently removing the influence of specific data samples or clients from trained models. Extending this notion to federated settings has given rise to Federated Unlearning (FUL), a new research area concerned with eliminating the contributions of individual clients or data subsets from the global FL model in a distributed and heterogeneous environment. In this survey, we first introduce the fundamentals of FUL. Then, we review the FUL frameworks that are proposed to address the three main implementation challenges, i.e., communication cost, resource allocation as well as security and privacy. Furthermore, we discuss applications of FUL in the modern distributed computer networks. We also highlight the open challenges and future research opportunities. By consolidating existing knowledge and mapping open problems, this survey aims to serve as a foundational reference for researchers and practitioners seeking to advance FL to build trustworthy, regulation-compliant and user-centric federated systems."
  },
  {
    "date": "2026-01-15",
    "title": "Stochastic Calculus as Operator Factorization",
    "authors": "Ramiro Fontes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09976v1",
    "source": "arXiv",
    "abstract": "We present a unified operator-theoretic formulation of stochastic calculus based on two principles: fluctuations factor through differentiation, predictable projection, and integration, and the appropriate stochastic derivative is the Hilbert adjoint of the stochastic integral on the energy space of the driving process. On an isonormal Gaussian space we recover the identity (Id - E)F = delta Pi D F, where D is the Malliavin derivative, Pi is predictable projection, and delta is the divergence operator. Motivated by this factorization, we define for a square-integrable process X admitting a closed stochastic integral an operator-covariant derivative on L2(Omega) via Riesz representation. This yields a canonical Clark-Ocone representation that unifies Malliavin, Volterra-Malliavin, and functional Ito derivatives and clarifies the operator geometry underlying stochastic calculus."
  },
  {
    "date": "2026-01-15",
    "title": "Precise Mass Measurement of the $^{149}$La-$^{149}$Ce-$^{149}$Pr isobaric chain",
    "authors": "B. Liu, M. Brodeur, J. A. Clark, D. Ray, G. Savard, A. A. Valverde, D. P. Burdette, A. M. Houff, A. Mitra, G. E. Morgan, R. Orford, W. S. Porter, C. Quick, F. Rivero, K. S. Sharma, L. Varriano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09959v1",
    "source": "arXiv",
    "abstract": "Penning trap mass measurements of $^{149}$La, $^{149}$Ce, and $^{149}$Pr were performed with the Canadian Penning Trap (CPT) at the CARIBU facility of Argonne National Laboratory using the phase-imaging ion-cyclotron-resonance technique. The resulting mass excess of $^{149}$La differs by 221 keV from a recent JYFLTRAP measurement, resulting in a significant change in the profile of the two-neutron separation energy for that isotopic chain. The mass excesses of $^{149}$Ce and $^{149}$Pr are determined with an eight-fold improvement in precision compared to previous time-of-flight ion-cyclotron-resonance measurements; the $^{149}$Ce value is consistent with AME2020, while the $^{149}$Pr mass excess is lower by 17.5 keV. The mass excesses of $^{149}$La and $^{149}$Pr reported in this work have been confirmed recently by a measurement with a multi-reflection time-of-flight mass spectrometer coupled to a $β$-time of flight detector at RIKEN, providing further validation of the present results."
  },
  {
    "date": "2026-01-15",
    "title": "The Galois Structure of the Spaces of polydifferentials on the Drinfeld Curve",
    "authors": "Denver-James Logan Marchment, Bernhard Köck",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09956v1",
    "source": "arXiv",
    "abstract": "Let $C$ be a smooth projective curve over an algebraically closed field ${\\mathbb{F}}$ equipped with the action of a finite group $G$. When $p =\\textrm{char}(\\mathbb{F})$ divides the order of $G$, the long-standing problem of computing the induced representation of $G$ on the space $H^0(C,Ω^{\\otimes m}_C)$ of globally holomorphic polydifferentials remains unsolved in general. In this paper, we study the case of the group $G = \\mathrm{SL}_2(\\mathbb{F}_q)$ (where $q$ is a power of~$p$) acting on the Drinfeld curve $C$ which is the projective plane curve given by the equation $XY^q-X^qY-Z^{q+1} = 0$. When $q = p$, we fully decompose $H^0(C,Ω^{\\otimes m}_C)$ as a direct sum of indecomposable $\\mathbb{F}[G]$-modules. For arbitrary $q$, we give a partial decomposition in terms of an explicit $\\mathbb{F}$-basis of $H^0(C,Ω^{\\otimes m}_C)$."
  },
  {
    "date": "2026-01-15",
    "title": "Take Out Your Calculators: Estimating the Real Difficulty of Question Items with LLM Student Simulations",
    "authors": "Christabel Acquaye, Yi Ting Huang, Marine Carpuat, Rachel Rudinger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09953v1",
    "source": "arXiv",
    "abstract": "Standardized math assessments require expensive human pilot studies to establish the difficulty of test items. We investigate the predictive value of open-source large language models (LLMs) for evaluating the difficulty of multiple-choice math questions for real-world students. We show that, while LLMs are poor direct judges of problem difficulty, simulation-based approaches with LLMs yield promising results under the right conditions. Under the proposed approach, we simulate a \"classroom\" of 4th, 8th, or 12th grade students by prompting the LLM to role-play students of varying proficiency levels. We use the outcomes of these simulations to fit Item Response Theory (IRT) models, comparing learned difficulty parameters for items to their real-world difficulties, as determined by item-level statistics furnished by the National Assessment of Educational Progress (NAEP). We observe correlations as high as 0.75, 0.76, and 0.82 for grades 4, 8, and 12, respectively. In our simulations, we experiment with different \"classroom sizes,\" showing tradeoffs between computation size and accuracy. We find that role-plays with named students improves predictions (compared to student ids), and stratifying names across gender and race further improves predictions. Our results show that LLMs with relatively weaker mathematical abilities (Gemma) actually yield better real-world difficulty predictions than mathematically stronger models (Llama and Qwen), further underscoring the suitability of open-source models for the task."
  },
  {
    "date": "2026-01-15",
    "title": "Beyond UV: Rest-frame B-band and Apparent Luminosity Functions of z=5-9 Galaxies",
    "authors": "Nicha Leethochawalit, Takahiro Morishita, Tirawut Worrakitpoonpon, Michele Trenti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09948v1",
    "source": "arXiv",
    "abstract": "We present new measurements of galaxy luminosity functions (LFs) from JWST/NIRCam imaging over the redshift range z=4.5-9.7, using photometric catalogs from JADES and public extragalactic fields. Our analysis includes rest-frame UV and B-band LFs, as well as apparent LFs in F090W, F115W, F200W, F356W, and F444W. We present the first constraints on the rest-frame B-band LF at z~7-8 and extend existing measurements at z~5 to M(B) = -18 mag. The B-band LFs evolve more strongly with redshift than UV LFs, though both decline more gradually than predicted by simulations at z>5. No single existing simulation reproduces all observed trends, with discrepancies likely driven by assumptions about binary evolution and stellar population synthesis models. The apparent LFs in F356W and F444W show hints of a bright-end excess at all redshifts, extending to fainter magnitudes at higher redshift. While extreme emission line galaxies may partially account for it, the excess may also indicate a population of moderately red, optically bright sources - potentially dusty star-forming galaxies or obscured AGNs. Finally, we find that rest-frame B-band luminosity correlates more tightly with stellar mass than UV, making it a powerful tracer of mass assembly and reinforcing the diagnostic value of rest-frame optical LFs in uncovering the physical processes that drive early galaxy formation."
  },
  {
    "date": "2026-01-15",
    "title": "Distributed Perceptron under Bounded Staleness, Partial Participation, and Noisy Communication",
    "authors": "Keval Jain, Anant Raj, Saurav Prakash, Girish Varma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10705v1",
    "source": "arXiv",
    "abstract": "We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed application of client computations (two-sided version lag), (ii) partial participation (intermittent client availability), and (iii) imperfect communication on both downlink and uplink, modeled as effective zero-mean additive noise with bounded second moment. We introduce a server-side aggregation rule called staleness-bucket aggregation with padding that deterministically enforces a prescribed staleness profile over update ages without assuming any stochastic model for delays or participation. Under margin separability and bounded data radius, we prove a finite-horizon expected bound on the cumulative weighted number of perceptron mistakes over a given number of server rounds: the impact of delay appears only through the mean enforced staleness, whereas communication noise contributes an additional term that grows on the order of the square root of the horizon with the total noise energy. In the noiseless case, we show how a finite expected mistake budget yields an explicit finite-round stabilization bound under a mild fresh-participation condition."
  },
  {
    "date": "2026-01-15",
    "title": "LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals",
    "authors": "Gilat Toker, Nitay Calderon, Ohad Amosy, Roi Reichart",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10700v1",
    "source": "arXiv",
    "abstract": "Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that serve as an imperfect proxy. To address this, we introduce a framework for constructing datasets containing structural counterfactual pairs: LIBERTy (LLM-based Interventional Benchmark for Explainability with Reference Targets). LIBERTy is grounded in explicitly defined Structured Causal Models (SCMs) of the text generation, interventions on a concept propagate through the SCM until an LLM generates the counterfactual. We introduce three datasets (disease detection, CV screening, and workplace violence prediction) together with a new evaluation metric, order-faithfulness. Using them, we evaluate a wide range of methods across five models and identify substantial headroom for improving concept-based explanations. LIBERTy also enables systematic analysis of model sensitivity to interventions: we find that proprietary LLMs show markedly reduced sensitivity to demographic concepts, likely due to post-training mitigation. Overall, LIBERTy provides a much-needed benchmark for developing faithful explainability methods."
  },
  {
    "date": "2026-01-15",
    "title": "Quantum geometry of the rotating shallow water model",
    "authors": "Sriram Ganeshan, Alan T. Dorsey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10695v1",
    "source": "arXiv",
    "abstract": "The rotating shallow water equations (RSWE) are a mainstay of atmospheric and oceanic modeling, and their wave dynamics has close analogues in settings ranging from two-dimensional electron gases to active-matter fluids. While recent work has emphasized the topological character of RSWE wave bands, here we develop a complementary quantum-geometric description by computing the full quantum geometric tensor (QGT) for the linearized RSWE on an $f$-plane. The QGT unifies two pieces of band geometry: its real part defines a metric that quantifies how rapidly wave polarization changes with parameters, while its imaginary part is the Berry curvature that controls geometric phases and topological invariants. We obtain compact, symmetry-guided expressions for all three bands, highlighting the transverse structure of the metric and the monopole-like Berry curvature that yields Chern numbers for the Poincaré bands. Finally, we describe a feasible route to probing this geometry in rotating-tank experiments via weak, time-periodic parametric driving."
  },
  {
    "date": "2026-01-15",
    "title": "Data-driven stochastic reduced-order modeling of parametrized dynamical systems",
    "authors": "Andrew F. Ilersich, Kevin Course, Prasanth B. Nair",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10690v1",
    "source": "arXiv",
    "abstract": "Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction uncertainty, limiting their utility in robust decision-making contexts. To address these challenges, we introduce a data-driven framework for learning continuous-time stochastic ROMs that generalize across parameter spaces and forcing conditions. Our approach, based on amortized stochastic variational inference, leverages a reparametrization trick for Markov Gaussian processes to eliminate the need for computationally expensive forward solvers during training. This enables us to jointly learn a probabilistic autoencoder and stochastic differential equations governing the latent dynamics, at a computational cost that is independent of the dataset size and system stiffness. Additionally, our approach offers the flexibility of incorporating physics-informed priors if available. Numerical studies are presented for three challenging test problems, where we demonstrate excellent generalization to unseen parameter combinations and forcings, and significant efficiency gains compared to existing approaches."
  },
  {
    "date": "2026-01-15",
    "title": "Vertex operator algebra bundles on modular curves and their associated modular forms",
    "authors": "Daniel Barake, Owen Chuchman, Cameron Franc, Geoffrey Mason, Brett Nasserden",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10686v1",
    "source": "arXiv",
    "abstract": "This paper describes the vector bundle on the elliptic modular curve that is associated to a vertex operator algebra $V$ (VOA) or more generally a quasi-vertex operator algebra (QVOA), with a view towards future applications aimed at studying the characters of VOAs. We explain how the modes of sections of $V$ give rise naturally to $V$-valued quasi-modular forms. The space $Q(V)$ of $V$-valued quasi-modular forms is endowed with the structure of a doubled QVOA, and in particular the algebra $Q$ of quasi-modular forms is itself a doubled QVOA. $Q(V)$ also admits a natural derivative operator arising from the connection on the bundle defined by $V$ and the modular derivative, which we call the raising operator. We introduce an associated lowering operator $Λ$ on $Q(V)$ having the property that the $V$-valued modular forms $M(V)\\subseteq Q(V)$ are the kernel of $Λ$. This extends the classical theory of scalar-valued quasi-modular forms. We exhibit an explicit isomorphism of $M(V)$ with $M \\otimes V$. Finally, the coordinate invariance of vertex operators implies that $M(V)$ has a natural Hecke theory, and we use this isomorphism to fully describe the Hecke eigensystems: they are the same as the systems of eigenvalues that arise from scalar-valued quasi-modular forms."
  },
  {
    "date": "2026-01-15",
    "title": "Breaking the Storage-Bandwidth Tradeoff in Distributed Storage with Quantum Entanglement",
    "authors": "Lei Hu, Mohamed Nomeir, Alptug Aytekin, Sennur Ulukus",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10676v1",
    "source": "arXiv",
    "abstract": "This work investigates the use of quantum resources in distributed storage systems. Consider an $(n,k,d)$ distributed storage system in which a file is stored across $n$ nodes such that any $k$ nodes suffice to reconstruct the file. When a node fails, any $d$ helper nodes transmit information to a newcomer to rebuild the system. In contrast to the classical repair, where helper nodes transmit classical bits, we allow them to send classical information over quantum channels to the newcomer. The newcomer then generates its storage by performing appropriate measurements on the received quantum states. In this setting, we fully characterize the fundamental tradeoff between storage and repair bandwidth (total communication cost). Compared to classical systems, the optimal storage--bandwidth tradeoff can be significantly improved with the enhancement of quantum entanglement shared only among the surviving nodes, particularly at the minimum-storage regenerating point. Remarkably, we show that when $d \\geq 2k-2$, there exists an operating point at which \\textit{both storage and repair bandwidth are simultaneously minimized}. This phenomenon breaks the tradeoff in the classical setting and reveals a fundamentally new regime enabled by quantum communication."
  },
  {
    "date": "2026-01-15",
    "title": "MHD modelling of open flux evolution around solar maximum by coronal model COCONUT",
    "authors": "Haopeng Wang, Stefaan Poedts, Andrea Lani, Luis Linan, Tinatin Baratashvili, Hyun-Jin Jeong, Rayan Dhib, Quentin Noraz, Wenwen Wei, Mahdi Najafi-Ziyazi, Junyan Liu, Hao Wu, Rui Zhuo, José Miguel Luzia Murteira, Ketevan Arabuli, Brigitte Schmieder, Jasmina Magdalenić Zhukov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10675v1",
    "source": "arXiv",
    "abstract": "To evaluate impact of temporal evolution and commonly used harmonic filtering of magnetograms, and the empirically defined oversimplified heating source terms on open-field distributions, we use a series of hourly-updated magnetograms, preprocessed by the 10th- and 50th-order filtered PF solvers, to drive COCONUT, configured with different heating prescriptions, to mimic coronal evolutions during CRs 2282 and 2283. We evaluate the simulated open magnetic flux at 1.01~$R_s$, 3~$R_s$, and 0.1~AU, and compare them with interplanetary observations. The results show that the simulated unsigned open flux evaluated near the solar surface can be comparable to that derived from interplanetary in situ observations. However, in low corona, numerous small-scale closed-field magnetic structures introduce magnetic polarity inversion interfaces within the open field, cancelling part of the open field near these interfaces during the volume-integration procedure of the finite-volume method. Consequently, the simulated unsigned open flux can be reduced by up to 45% at 0.1~AU and decreases more rapidly in the low corona. The results also indicate that moderate adjustments to the heating source term can effectively regulate the magnitude of the unsigned open magnetic flux. Preprocessing the initial magnetogram by a PF solver with limited spherical harmonics can reduce the open flux in the low corona and alter the distribution of open-field regions, but has little effect on the total unsigned open flux at larger heliocentric distances. The ratio of the maximum to minimum open unsigned magnetic flux can reach 1.4 within a single solar maximum CR. These findings highlight the necessity of considering finer grid resolution around magnetic polarity inversion interfaces, more realistic heating mechanisms, and the time-evolving regime of MHD coronal modelling when further addressing the ``open flux problem\"."
  },
  {
    "date": "2026-01-15",
    "title": "Efficiency, Curvature, and Complexity of Quantum Evolutions for Qubits in Nonstationary Magnetic Fields",
    "authors": "Carlo Cafaro, James Schneeloch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10672v1",
    "source": "arXiv",
    "abstract": "In optimal quantum-mechanical evolutions, motion can take place along paths of minimal length within an optimal time frame. Alternatively, optimal evolutions may occur along established paths without any waste of energy resources and achieving 100% speed efficiency. Unfortunately, realistic physical scenarios often lead to less-than-ideal evolutions that demonstrate suboptimal efficiency, nonzero curvature, and a high level of complexity. In this paper, we provide an exact analytical expression for the curvature of a quantum evolution pertaining to a two-level quantum system subjected to various time-dependent magnetic fields. Specifically, we examine the dynamics produced by a two-parameter nonstationary Hermitian Hamiltonian with unit speed efficiency. To enhance our understanding of the physical implications of the curvature coefficient, we analyze the curvature behavior in relation to geodesic efficiency, speed efficiency, and the complexity of the quantum evolution (as described by the ratio of the difference between accessible and accessed Bloch-sphere volumes for the evolution from initial to final state to the accessible volume for the given quantum evolution). Our findings indicate that, generally, efficient quantum evolutions exhibit lower complexity compared to inefficient ones. However, we also note that complexity transcends mere length. In fact, longer paths that are sufficiently curved can demonstrate a complexity that is less than that of shorter paths with a lower curvature coefficient."
  },
  {
    "date": "2026-01-15",
    "title": "Safe Trajectory Gradient Flow Control of a Grid-Interfacing Inverter",
    "authors": "Trager Joswig-Jones, Baosen Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10671v1",
    "source": "arXiv",
    "abstract": "Grid-interfacing inverters serve as the interface between renewable energy resources and the electric power grid, offering fast, programmable control capabilities. However, their operation is constrained by hardware limitations, such as bounds on the current magnitude. Existing control methods for these systems often neglect these constraints during controller design and instead rely on ad hoc limiters, which can introduce instability or degrade performance. In this work, we present a control framework that directly incorporates constraints into the control of a voltage-source inverter. We propose a safe trajectory gradient flow controller, which applies the safe gradient flow method to a rolling horizon trajectory optimization problem to ensure that the states remain within a safe set defined by the constraints while directing the trajectory towards an optimal equilibrium point of a nonlinear program. Simulation results demonstrate that our approach can drive the outputs of a simulated inverter system to optimal values and maintain state constraints, even when using a limited number of optimization steps per control cycle."
  },
  {
    "date": "2026-01-15",
    "title": "The recipe for the degrees of freedom",
    "authors": "Anamaria Hell, Elisa G. M. Ferreira, Dieter Lust, Misao Sasaki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10288v1",
    "source": "arXiv",
    "abstract": "We consider the question of counting the degrees of freedom in theoretical models, with an emphasis on theories of fields and gravity. Among the possible approaches, the Hamiltonian formulation remains one of the most systematic and robust tools. However, it can easily become long and technically involved. In this work, we present a broadly applicable recipe to find the degrees of freedom directly, based on the Lagrangian formulation. We compare it to the standard approaches, highlight the challenges that may arise in the latter, and demonstrate that the proposed method leads to transparent insights about the dynamical nature of theory in a quick, simple, and straight-forward way."
  },
  {
    "date": "2026-01-15",
    "title": "The inducibility of Turán graphs",
    "authors": "Xizhi Liu, Jie Ma, Tianming Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10548v1",
    "source": "arXiv",
    "abstract": "Let $I(F,n)$ denote the maximum number of induced copies of a graph $F$ in an $n$-vertex graph. The inducibility of $F$, defined as $i(F)=\\lim_{n\\to \\infty} I(F,n)/\\binom{n}{v(F)}$, is a central problem in extremal graph theory. In this work, we investigate the inducibility of Turán graphs $F$. This topic has been extensively studied in the literature, including works of Pippenger--Golumbic, Brown--Sidorenko, Bollobás--Egawa--Harris--Jin, Mubayi, Reiher, and the first author, and Yuster. Broadly speaking, these results resolve or asymptotically resolve the problem when the part sizes of $F$ are either sufficiently large or sufficiently small (at most four). We complete this picture by proving that for every Turán graph $F$ and sufficiently large $n$, the value $I(F,n)$ is attained uniquely by the $m$-partite Turán graph on $n$ vertices, where $m$ is given explicitly in terms of the number of parts and vertices of $F$. This confirms a conjecture of Bollobás--Egawa--Harris--Jin from 1995, and we also establish the corresponding stability theorem. Moreover, we prove an asymptotic analogue for $I_{k+1}(F,n)$, the maximum number of induced copies of $F$ in an $n$-vertex $K_{k+1}$-free graph, thereby completely resolving a recent problem of Yuster. Finally, our results extend to a broader class of complete multipartite graphs in which the largest and smallest part sizes differ by at most on the order of the square root of the smallest part size."
  },
  {
    "date": "2026-01-15",
    "title": "In-Context Operator Learning on the Space of Probability Measures",
    "authors": "Frank Cole, Dixi Wang, Yineng Chen, Yulong Lu, Rongjie Lai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09979v1",
    "source": "arXiv",
    "abstract": "We introduce \\emph{in-context operator learning on probability measure spaces} for optimal transport (OT). The goal is to learn a single solution operator that maps a pair of distributions to the OT map, using only few-shot samples from each distribution as a prompt and \\emph{without} gradient updates at inference. We parameterize the solution operator and develop scaling-law theory in two regimes. In the \\emph{nonparametric} setting, when tasks concentrate on a low-intrinsic-dimension manifold of source--target pairs, we establish generalization bounds that quantify how in-context accuracy scales with prompt size, intrinsic task dimension, and model capacity. In the \\emph{parametric} setting (e.g., Gaussian families), we give an explicit architecture that recovers the exact OT map in context and provide finite-sample excess-risk bounds. Our numerical experiments on synthetic transports and generative-modeling benchmarks validate the framework."
  },
  {
    "date": "2026-01-15",
    "title": "Job Anxiety in Post-Secondary Computer Science Students Caused by Artificial Intelligence",
    "authors": "Daniyaal Farooqi, Gavin Pu, Shreyasha Paudel, Sharifa Sultana, Syed Ishtiaque Ahmed",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10468v1",
    "source": "arXiv",
    "abstract": "The emerging widespread usage of AI has led to industry adoption to improve efficiency and increase earnings. However, a major consequence of this is AI displacing employees from their jobs, leading to feelings of job insecurity and uncertainty. This is especially true for computer science students preparing to enter the workforce. To investigate this, we performed semi-structured interviews with (n = 25) students across computer science undergraduate and graduate programs at the University of Toronto to determine the extent of job replacement anxiety. Through thematic analysis, it was determined that computer science students indeed face stress and anxiety from AI displacement of jobs, leading to different strategies of managing pressure. Subfields such as software engineering and web development are strongly believed to be vulnerable to displacement, while specialized subfields like quantum computing and AI research are deemed more secure. Many students feel compelled to upskill by using more AI technologies, taking AI courses, and specializing in AI through graduate school. Some students also reskill by pursuing other fields of study seen as less vulnerable to AI displacement. Finally, international students experience additional job replacement anxiety because of pressure to secure permanent residence. Implications of these findings include feelings of low security in computer science careers, oversaturation of computer science students pursuing AI, and potential dissuasion of future university students from pursuing computer science."
  },
  {
    "date": "2026-01-15",
    "title": "Adversarial Hypothesis Testing for Quantum Channels",
    "authors": "Masahito Hayashi, Hao-Chung Cheng, Li Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10243v1",
    "source": "arXiv",
    "abstract": "This paper presents a systematic study of adversarial hypothesis testing for both quantum-quantum (QQ) and classical-quantum (CQ) channels. Unlike conventional channel discrimination, we consider a framework where the sender, Alice, selects the channel input adversarially to minimize Bob's distinguishability. We analyze this problem across four settings based on whether Alice employs i.i.d. or general inputs and whether the receiver, Bob, is informed of the specific input choice (allowing his measurement to depend on the input). We characterize the Stein exponents for each setting and reveal a striking distinction in behavior: for QQ channels with i.i.d. inputs, Bob's knowledge of the input significantly enhances distinguishability, yet this advantage vanishes when general inputs are permitted. In contrast, for CQ channels, Bob being informed provides a consistent advantage over the corresponding entanglement-breaking channels for both i.i.d. and general inputs. These results demonstrate a unique phenomenon in adversarial hypothesis testing where the CQ channel does not merely behave as a special case of the QQ channel."
  },
  {
    "date": "2026-01-15",
    "title": "Minimally Truncated SU(3) Lattice Gauge Theory and String Tension",
    "authors": "Vincent Chen, Berndt Müller, Xiaojun Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10065v1",
    "source": "arXiv",
    "abstract": "We study SU(3) gauge theory on small lattices in the minimal (qutrit) electric field truncation retaining only the ${\\bf 1}, {\\bf 3}, {\\bf \\overline{3}}$ representations for the link variables. Explicit expressions are given for the Kogut-Susskind Hamiltonian for the square plaquette chain and the two-dimensional honeycomb lattice. Our formalism can be easily extended to the minimally truncated general SU($N_c$) gauge theory. The addition of (static) quarks is discussed. We present results for the energy spectrum of the gauge field on these lattices by exact diagonalization of the Hamiltonian and analyze its statistical properties. We also compute the SU(3) string tension and discuss how it is modified by vacuum fluctuations. Finally, we calculate the potential energies of a static quark-antiquark pair and three static quarks and study their screening at finite temperature."
  },
  {
    "date": "2026-01-15",
    "title": "Perfect Secret Key Generation for a class of Hypergraphical Sources",
    "authors": "Manuj Mukherjee, Sagnik Chatterjee, Alhad Sethi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10697v1",
    "source": "arXiv",
    "abstract": "Nitinawarat and Narayan proposed a perfect secret key generation scheme for the so-called \\emph{pairwise independent network (PIN) model} by exploiting the combinatorial properties of the underlying graph, namely the spanning tree packing rate. This work considers a generalization of the PIN model where the underlying graph is replaced with a hypergraph, and makes progress towards designing similar perfect secret key generation schemes by exploiting the combinatorial properties of the hypergraph. Our contributions are two-fold. We first provide a capacity achieving scheme for a complete $t$-uniform hypergraph on $m$ vertices by leveraging a packing of the complete $t$-uniform hypergraphs by what we refer to as star hypergraphs, and designing a scheme that gives $\\binom{m-2}{t-2}$ bits of perfect secret key per star graph. Our second contribution is a 2-bit perfect secret key generation scheme for 3-uniform star hypergraphs whose projections are cycles. This scheme is then extended to a perfect secret key generation scheme for generic 3-uniform hypergraphs by exploiting star graph packing of 3-uniform hypergraphs and Hamiltonian packings of graphs. The scheme is then shown to be capacity achieving for certain classes of hypergraphs."
  },
  {
    "date": "2026-01-15",
    "title": "Higher order trade-offs in hypergraph community detection",
    "authors": "Jiaze Li, Michael T. Schaub, Leto Peel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10502v1",
    "source": "arXiv",
    "abstract": "Extending community detection from pairwise networks to hypergraphs introduces fundamental theoretical challenges. Hypergraphs exhibit structural heterogeneity with no direct graph analogue: hyperedges of varying orders can connect nodes across communities in diverse configurations, introducing new trade-offs in defining and detecting community structure. We address these challenges by developing a unified framework for community detection in non-uniform hypergraphs under the Hypergraph Stochastic Block Model. We introduce a general signal-to-noise ratio that enables a quantitative analysis of trade-offs unique to higher-order networks, such as which hypergedges we choose to split across communities and how we choose to split them. Building on this framework, we derive a Bethe Hessian operator for non-uniform hypergraphs that provides efficient spectral clustering with principled model selection. We characterize the resulting spectral detectability threshold and compare it to belief propagation limits, showing the methods coincide for uniform hypergraphs but diverge in non-uniform settings. Synthetic experiments confirm our analytical predictions and reveal systematic biases toward preserving higher-order and balanced-shape hyperedges. Application to empirical data demonstrates the practical relevance of these higher-order detectability trade-offs in real-world systems."
  },
  {
    "date": "2026-01-15",
    "title": "LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries",
    "authors": "Xuancheng Ren, Shijing Hu, Zhihui Lu, Jiangqi Huang, Qiang Duan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10398v1",
    "source": "arXiv",
    "abstract": "In LLM-based text-to-SQL systems, unanswerable and underspecified user queries may generate not only incorrect text but also executable programs that yield misleading results or violate safety constraints, posing a major barrier to safe deployment. Existing refusal strategies for such queries either rely on output-level instruction following, which is brittle due to model hallucinations, or estimate output uncertainty, which adds complexity and overhead. To address this challenge, we formalize safe refusal in text-to-SQL systems as an answerability-gating problem and propose LatentRefusal, a latent-signal refusal mechanism that predicts query answerability from intermediate hidden activations of a large language model. We introduce the Tri-Residual Gated Encoder, a lightweight probing architecture, to suppress schema noise and amplify sparse, localized cues of question-schema mismatch that indicate unanswerability. Extensive empirical evaluations across diverse ambiguous and unanswerable settings, together with ablation studies and interpretability analyses, demonstrate the effectiveness of the proposed approach and show that LatentRefusal provides an attachable and efficient safety layer for text-to-SQL systems. Across four benchmarks, LatentRefusal improves average F1 to 88.5 percent on both backbones while adding approximately 2 milliseconds of probe overhead."
  },
  {
    "date": "2026-01-15",
    "title": "Revealing Neutrino Mass Ordering at CEPC and FCC-ee",
    "authors": "Wei Liu, Supriya Senapati, Jin Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10311v1",
    "source": "arXiv",
    "abstract": "The neutrino masses ordering remains one of the most important open questions in neutrino physics. While upcoming oscillation experiments aim to resolve this problem at low energies, complementary approaches are highly desirable. In this Letter, we show that the neutrino mass ordering can be probed at high-energy colliders through the lepton-flavor structure of heavy neutral lepton (HNL) interactions. In the minimal Type-I seesaw scenario with two nearly degenerate HNLs, the heavy--light neutrino mixings are strongly correlated with the light-neutrino mass spectrum, leading to distinct flavor patterns for the normal and inverted hierarchies. We demonstrate that future $Z$ factories, such as CEPC and FCC-ee, can probe the neutrino mass ordering for total HNL mixings as small as $U_{\\rm tot}^2 \\gtrsim 4 \\times 10^{-9}$, and discriminate between the two hierarchies for $U_{\\rm tot}^2 \\gtrsim 10^{-6}$. Our results establish collider searches for HNLs as a powerful and complementary probe of the neutrino mass ordering."
  },
  {
    "date": "2026-01-15",
    "title": "Exponential improvement in benchmarking multiphoton interference",
    "authors": "Rodrigo M. Sanz, Emilio Annoni, Stephen C. Wein, Carmen G. Almudever, Shane Mansfield, Ellen Derbyshire, Rawad Mezher",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10289v1",
    "source": "arXiv",
    "abstract": "Several photonic quantum technologies rely on the ability to generate multiple indistinguishable photons. Benchmarking the level of indistinguishability of these photons is essential for scalability. The Hong-Ou-Mandel dip provides a benchmark for the indistinguishability between two photons, and extending this test to the multi-photon setting has so far resulted in a protocol that computes the genuine n-photon indistinguishability (GI). However, this protocol has a sample complexity that increases exponentially with the number of input photons for an estimation of GI up to a given additive error. To address this problem, we introduce new theorems that strengthen our understanding of the relationship between distinguishability and the suppression laws of the quantum Fourier transform interferometer (QFT). Building on this, we propose a protocol using the QFT for benchmarking GI that achieves constant sample complexity for the estimation of GI up to a given additive error for prime photon numbers, and sub-polynomial scaling otherwise, representing an exponential improvement over the state of the art. We prove the optimality of our protocol in many relevant scenarios and validate our approach experimentally on Quandela's reconfigurable photonic quantum processor, where we observe a clear advantage in runtime and precision over the state of the art. We therefore establish the first scalable method for computing multi-photon indistinguishability, which applies naturally to current and near-term photonic quantum hardware."
  },
  {
    "date": "2026-01-15",
    "title": "DInf-Grid: A Neural Differential Equation Solver with Differentiable Feature Grids",
    "authors": "Navami Kairanda, Shanthika Naik, Marc Habermann, Avinash Sharma, Christian Theobalt, Vladislav Golyanik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10715v1",
    "source": "arXiv",
    "abstract": "We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by exploiting signal structure, their reliance on linear interpolation restricts their ability to compute higher-order derivatives, rendering them unsuitable for solving DEs. Our approach overcomes these limitations by combining the efficiency of feature grids with radial basis function interpolation, which is infinitely differentiable. To effectively capture high-frequency solutions and enable stable and faster computation of global gradients, we introduce a multi-resolution decomposition with co-located grids. Our proposed representation, DInf-Grid, is trained implicitly using the differential equations as loss functions, enabling accurate modelling of physical fields. We validate DInf-Grid on a variety of tasks, including the Poisson equation for image reconstruction, the Helmholtz equation for wave fields, and the Kirchhoff-Love boundary value problem for cloth simulation. Our results demonstrate a 5-20x speed-up over coordinate-based MLP-based methods, solving differential equations in seconds or minutes while maintaining comparable accuracy and compactness."
  },
  {
    "date": "2026-01-15",
    "title": "Quantum Maxwell Erasure Decoder for qLDPC codes",
    "authors": "Bruno Costa Alves Freire, François-Marie Le Régent, Anthony Leverrier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10713v1",
    "source": "arXiv",
    "abstract": "We introduce a quantum Maxwell erasure decoder for CSS quantum low-density parity-check (qLDPC) codes that extends peeling with bounded guessing. Guesses are tracked symbolically and can be eliminated by restrictive checks, giving a tunable tradeoff between complexity and performance via a guessing budget: an unconstrained budget recovers Maximum-Likelihood (ML) performance, while a constant budget yields linear-time decoding and approximates ML. We provide theoretical guarantees on asymptotic performance and demonstrate strong performance on bivariate bicycle and quantum Tanner codes."
  },
  {
    "date": "2026-01-15",
    "title": "From One-to-One to Many-to-Many: Dynamic Cross-Layer Injection for Deep Vision-Language Fusion",
    "authors": "Cheng Chen, Yuyu Guo, Pengpeng Zeng, Jingkuan Song, Peng Di, Hang Yu, Lianli Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10710v1",
    "source": "arXiv",
    "abstract": "Vision-Language Models (VLMs) create a severe visual feature bottleneck by using a crude, asymmetric connection that links only the output of the vision encoder to the input of the large language model (LLM). This static architecture fundamentally limits the ability of LLMs to achieve comprehensive alignment with hierarchical visual knowledge, compromising their capacity to accurately integrate local details with global semantics into coherent reasoning. To resolve this, we introduce Cross-Layer Injection (CLI), a novel and lightweight framework that forges a dynamic many-to-many bridge between the two modalities. CLI consists of two synergistic, parameter-efficient components: an Adaptive Multi-Projection (AMP) module that harmonizes features from diverse vision layers, and an Adaptive Gating Fusion (AGF) mechanism that empowers the LLM to selectively inject the most relevant visual information based on its real-time decoding context. We validate the effectiveness and versatility of CLI by integrating it into LLaVA-OneVision and LLaVA-1.5. Extensive experiments on 18 diverse benchmarks demonstrate significant performance improvements, establishing CLI as a scalable paradigm that unlocks deeper multimodal understanding by granting LLMs on-demand access to the full visual hierarchy."
  },
  {
    "date": "2026-01-15",
    "title": "High-accuracy and dimension-free sampling with diffusions",
    "authors": "Khashayar Gatmiry, Sitan Chen, Adil Salim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10708v1",
    "source": "arXiv",
    "abstract": "Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \\emph{high-quality} samples. More precisely, prior works have shown that the iteration complexity of discretization methods for diffusion models scales polynomially in the ambient dimension and the inverse accuracy $1/\\varepsilon$. In this work, we propose a new solver for diffusion models relying on a subtle interplay between low-degree approximation and the collocation method (Lee, Song, Vempala 2018), and we prove that its iteration complexity scales \\emph{polylogarithmically} in $1/\\varepsilon$, yielding the first ``high-accuracy'' guarantee for a diffusion-based sampler that only uses (approximate) access to the scores of the data distribution. In addition, our bound does not depend explicitly on the ambient dimension; more precisely, the dimension affects the complexity of our solver through the \\emph{effective radius} of the support of the target distribution only."
  },
  {
    "date": "2026-01-15",
    "title": "UFO Trees: Practical and Provably-Efficient Parallel Batch-Dynamic Trees",
    "authors": "Quinten De Man, Atharva Sharma, Kishen N Gowda, Laxman Dhulipala",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10706v1",
    "source": "arXiv",
    "abstract": "The dynamic trees problem is to maintain a tree under edge updates while supporting queries like connectivity queries or path queries. Despite the first data structure for this fundamental problem -- the link-cut tree -- being invented 40 years ago, our experiments reveal that they are still the fastest sequential data structure for the problem. However, link-cut trees cannot support parallel batch-dynamic updates and have limitations on the kinds of queries they support. In this paper, we design a new parallel batch-dynamic trees data structure called UFO trees that simultaneously supports a wide range of query functionality, supports work-efficient parallel batch-dynamic updates, and is competitive with link-cut trees when run sequentially. We prove that a key reason for the strong practical performance of both link-cut trees and UFO trees is that they can perform updates and queries in sub-logarithmic time for low-diameter trees. We perform an experimental study of our optimized C++ implementations of UFO trees with ten other dynamic tree implementations, several of which are new, in a broad benchmark of both synthetic and real-world trees of varying diameter and size. Our results show that, in both sequential and parallel settings, UFO trees are the fastest dynamic tree data structure that supports a wide range of queries. Our new implementation of UFO trees has low space usage and easily scales to billion-size inputs, making it a promising building block for implementing more complex dynamic graph algorithms in practice."
  },
  {
    "date": "2026-01-15",
    "title": "The Effective Theory of Muon-to-Electron Conversion",
    "authors": "W. C. Haxton, Evan Rule",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10704v1",
    "source": "arXiv",
    "abstract": "We summarize recent work to develop an effective theory of muon-to-electron conversion, based on a complete set of low-energy effective operators that are developed from a systematic expansion in velocities and momenta. The expansion effectively factors rates into sums of particle physics and nuclear physics terms, where the former are expressed as bilinears in the LECs (the low-energy constants of the effective theory) and the latter are the associated nuclear responses. One can view the nuclear responses as ``dials\" that can be adjusted -- for example, by selection of targets with specific properties -- in order to isolate the former. We show that an important dial, in the case of Mu2e and COMET, will be inelastic transitions to certain low-energy nuclear states that are resolvable in 27Al. If these transitions are exploited, the experiments have the potential not only to discover charged lepton flavor violation (CLFV), but to determine the operators responsible for the CLFV. We also discuss how such low-energy results can be ``ported\" to higher energies through a tower of matched EFTs, so they can be combined with other experimental limits to further constrain CLFV"
  },
  {
    "date": "2026-01-15",
    "title": "Communication-Efficient and Privacy-Adaptable Mechanism -- a Federated Learning Scheme with Convergence Analysis",
    "authors": "Chun Hei Michael Shiu, Chih Wei Ling",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10701v1",
    "source": "arXiv",
    "abstract": "Federated learning enables multiple parties to jointly train learning models without sharing their own underlying data, offering a practical pathway to privacy-preserving collaboration under data-governance constraints. Continued study of federated learning is essential to address key challenges in it, including communication efficiency and privacy protection between parties. A recent line of work introduced a novel approach called the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), which achieves both objectives simultaneously. CEPAM leverages the rejection-sampled universal quantizer (RSUQ), a randomized vector quantizer whose quantization error is equivalent to a prescribed noise, which can be tuned to customize privacy protection between parties. In this work, we theoretically analyze the privacy guarantees and convergence properties of CEPAM. Moreover, we assess CEPAM's utility performance through experimental evaluations, including convergence profiles compared with other baselines, and accuracy-privacy trade-offs between different parties."
  },
  {
    "date": "2026-01-15",
    "title": "The Conversational Exam: A Scalable Assessment Design for the AI Era",
    "authors": "Lorena A. Barba, Laura Stegner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10691v1",
    "source": "arXiv",
    "abstract": "Traditional assessment methods collapse when students use generative AI to complete work without genuine engagement, creating an illusion of competence where they believe they're learning but aren't. This paper presents the conversational exam -- a scalable oral examination format that restores assessment validity by having students code live while explaining their reasoning. Drawing on human-computer interaction principles, we examined 58 students in small groups across just two days, demonstrating that oral exams can scale to typical class sizes. The format combines authentic practice (students work with documentation and supervised AI access) with inherent validity (real-time performance cannot be faked). We provide detailed implementation guidance to help instructors adapt this approach, offering a practical path forward when many educators feel paralyzed between banning AI entirely or accepting that valid assessment is impossible."
  },
  {
    "date": "2026-01-15",
    "title": "On the origin of neural scaling laws: from random graphs to natural language",
    "authors": "Maissam Barkeshli, Alberto Alfarano, Andrey Gromov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10684v1",
    "source": "arXiv",
    "abstract": "Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this paper we study scaling laws for transformers trained to predict random walks (bigrams) on graphs with tunable complexity. We demonstrate that this simplified setting already gives rise to neural scaling laws even in the absence of power law structure in the data correlations. We further consider dialing down the complexity of natural language systematically, by training on sequences sampled from increasingly simplified generative language models, from 4,2,1-layer transformer language models down to language bigrams, revealing a monotonic evolution of the scaling exponents. Our results also include scaling laws obtained from training on random walks on random graphs drawn from Erdös-Renyi and scale-free Barabási-Albert ensembles. Finally, we revisit conventional scaling laws for language modeling, demonstrating that several essential results can be reproduced using 2 layer transformers with context length of 50, provide a critical analysis of various fits used in prior literature, demonstrate an alternative method for obtaining compute optimal curves as compared with current practice in published literature, and provide preliminary evidence that maximal update parameterization may be more parameter efficient than standard parameterization."
  },
  {
    "date": "2026-01-15",
    "title": "Implementation of Oblivious Transfer over Binary-Input AWGN Channels by Polar Codes",
    "authors": "Pin-Hsun Lin, Hadi Aghaee, Christian Deppe, Eduard A. Jorswieck, Holger Boche",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10682v1",
    "source": "arXiv",
    "abstract": "We develop a one-out-of-two-oblivious transfer protocol over the binary-input additive white Gaussian noise channel using polar codes. The scheme uses two decoder views linked by automorphisms of the polar transform and publicly draws the encoder at random from the corresponding automorphism group. This yields perfect receiver privacy at any finite blocklength, since the public encoder distribution is independent of the receiver's choice bit. Sender privacy is obtained asymptotically via channel polarization combined with privacy amplification. Because the construction deliberately injects randomness on selected bad bit-channels, we derive a relaxed reliability criterion and evaluate finite-blocklength performance. Finally, we characterize the polar-transform automorphisms as bit-level permutations of bit-channel indices, and exploit this structure to derive and optimize an achievable finite-blocklength OT rate."
  },
  {
    "date": "2026-01-15",
    "title": "Irregular higher-spin generating equations and chiral perturbation theory",
    "authors": "V. E. Didenko",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10680v1",
    "source": "arXiv",
    "abstract": "We present a complementary approach to the standard Vasiliev framework for nonlinear higher-spin interactions in four dimensions, aimed at identifying their minimally nonlocal form. Our proposal introduces a generating system for higher-spin vertices at the level of classical equations, which we refer to as irregular, in contrast to the regular case described by Vasiliev. This system extends the recently proposed equations for (anti)holomorphic interactions by incorporating the mixed sector. Its perturbative series encompasses the entire (anti)holomorphic sector in the leading order, with vertices related to powers of the complex parity-breaking parameter $η$ or $\\barη$. The subsequent corrections facilitate the mixing of the two sectors, with vertices carrying mixed powers of $η$ and $\\barη$. The consistency relies on the nonlinear algebraic constraint, which is shown to be satisfied at least in the quadratic and cubic approximations. As a result, the previously discussed (anti)holomorphic interactions in the literature can be systematically extended to generate vertices of the form $η^N \\barη^k$ and their conjugate, at least for $k \\leq 2$ and any $N$. As a byproduct of our analysis, we also identify the new higher-spin structure dualities."
  },
  {
    "date": "2026-01-15",
    "title": "Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models",
    "authors": "Zirui Ren, Ziming Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10679v1",
    "source": "arXiv",
    "abstract": "Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only one unknown cell. We attribute this failure to the violation of the fixed point property, a fundamental assumption of HRM. (b) \"Grokking\" dynamics in reasoning steps, i.e., the answer is not improved uniformly, but instead there is a critical reasoning step that suddenly makes the answer correct; (c) Existence of multiple fixed points. HRM \"guesses\" the first fixed point, which could be incorrect, and gets trapped there for a while or forever. All facts imply that HRM appears to be \"guessing\" instead of \"reasoning\". Leveraging this \"guessing\" picture, we propose three strategies to scale HRM's guesses: data augmentation (scaling the quality of guesses), input perturbation (scaling the number of guesses by leveraging inference randomness), and model bootstrapping (scaling the number of guesses by leveraging training randomness). On the practical side, by combining all methods, we develop Augmented HRM, boosting accuracy on Sudoku-Extreme from 54.5% to 96.9%. On the scientific side, our analysis provides new insights into how reasoning models \"reason\"."
  },
  {
    "date": "2026-01-15",
    "title": "Optimal Proximity Gap for Folded Reed--Solomon Codes via Subspace Designs",
    "authors": "Fernando Granha Jeronimo, Lenny Liu, Pranav Rajpal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10047v1",
    "source": "arXiv",
    "abstract": "A collection of sets satisfies a $(δ,\\varepsilon)$-proximity gap with respect to some property if for every set in the collection, either (i) all members of the set are $δ$-close to the property in (relative) Hamming distance, or (ii) only a small $\\varepsilon$-fraction of members are $δ$-close to the property. In a seminal work, Ben-Sasson \\textit{et al.}\\ showed that the collection of affine subspaces exhibits a $(δ,\\varepsilon)$-proximity gap with respect to the property of being Reed--Solomon (RS) codewords with $δ$ up to the so-called Johnson bound for list decoding. Their technique relies on the Guruswami--Sudan list decoding algorithm for RS codes, which is guaranteed to work in the Johnson bound regime. Folded Reed--Solomon (FRS) codes are known to achieve the optimal list decoding radius $δ$, a regime known as capacity. Moreover, a rich line of list decoding algorithms was developed for FRS codes. It is then natural to ask if FRS codes can be shown to exhibit an analogous $(δ,\\varepsilon)$-proximity gap, but up to the so-called optimal capacity regime. We answer this question in the affirmative (and the framework naturally applies more generally to suitable subspace-design codes). An additional motivation to understand proximity gaps for FRS codes is the recent results [BCDZ'25] showing that they exhibit properties similar to random linear codes, which were previously shown to be related to properties of RS codes with random evaluation points in [LMS'25], as well as codes over constant-size alphabet based on AEL [JS'25]."
  },
  {
    "date": "2026-01-15",
    "title": "Correlated states in charge-transfer heterostructures based on rhombohedral multilayer graphene",
    "authors": "Yanran Shi, Min Li, Xin Lu, Jianpeng Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10530v1",
    "source": "arXiv",
    "abstract": "Charge transfer is a common phenomenon in van der Waals heterostructures with proper work function mismatch, which enables electrostatic gating to control band alignment and interlayer charge distributions. This provides a tunable platform for studying coupled bilayer correlated electronic systems. Here, we theoretically investigate heterostructures of rhombohedral multilayer graphene (RMG) and an insulating substrate with gate-tunable band alignment. We first develop a self-consistent electrostatic theory for layer charge densities incorporating charge transfer, which reproduces the experimentally observed broadened and bent charge neutrality region. When the substrate's band edge has a much larger effective mass than RMG, its carriers can form a Wigner crystal at low densities. This creates a quantum superlattice that induces topological flat bands in the RMG layer, which may lead to Chern insulators driven by intralayer Coulomb interactions. Conversely, with comparable effective masses, we find an interlayer excitonic insulator state at charge neutrality stabilized by interlayer Coulomb coupling. Our work establishes these charge-transfer heterostructures as a rich platform for topological and excitonic correlated states, opening an avenue for ``charge-transferonics''."
  },
  {
    "date": "2026-01-15",
    "title": "GeoSteer: Faithful Chain-of-Thought Steering via Latent Manifold Gradients",
    "authors": "Kentaro Kazama, Daiki Shirafuji, Tatsuhiko Saito",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10229v1",
    "source": "arXiv",
    "abstract": "Recent advances in Large Language Models (LLMs) have improved multi-step reasoning. Most approaches rely on Chain-of-Thought (CoT) rationales. Previous studies have shown that LLMs often generate logically inconsistent reasoning steps even when their final answers are correct. These inconsistencies reduce the reliability of step-level reasoning. We propose GeoSteer, a manifold-based framework that improves the quality of intermediate reasoning. The method consists of: (1) constructing a CoT dataset with segment-level scores, (2) training a Variational Autoencoder (VAE) model and a quality estimation model to learn a low-dimensional manifold of high-quality CoT trajectories, and (3) steering hidden states of target LLMs toward higher-quality regions in the latent space. This update in a latent space behaves like a natural-gradient adjustment in the original hidden-state space. It ensures geometrically coherent steering. We evaluate GeoSteer on the GSM8k dataset using the Qwen3 series. We measure via answer accuracy and overall reasoning performance. GeoSteer improved the exact match accuracy by up to 2.6 points. It also enhanced the pairwise win rate by 5.3 points. These results indicate that GeoSteer provides an effective and controllable mechanism for improving the quality of intermediate reasoning in LLMs."
  },
  {
    "date": "2026-01-15",
    "title": "Growth and hydrostatic-pressure study of a type-II superconductor Bi$_2$Ta$_3$S$_6$ single crystal",
    "authors": "Li Chenglin, Yang Yaling, Yang Zhilong, Deng Junze, Zhang Ruihan, Chen Weiwei, Pan Yue, Wang Yulong, Wang Xuhui, Wang Bosen, Wang Zhijun, Wang Gang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10195v1",
    "source": "arXiv",
    "abstract": "We report the growth and physical properties of single-crystalline Bi$_2$Ta$_3$S$_6$ crystallizing in $P6_3/mcm$ space group, which comprises alternating Ta-S layers and Bi layers with each Bi atom connected with adjacent S atoms. Temperature-dependent electrical resistivity measurements reveal a superconducting transition at 0.84 K, with upper critical field 231 Oe under an out-of-plane magnetic field. The magnetization measurements confirm its nature as a type-II superconductor, with anisotropic Ginzburg-Landau parameter $κ_{ab}$ = 7.67 and $κ_c$ = 4.50. Hall measurements indicate the dominant carriers as hole. Hydrostatic pressure is applied, under which both the superconducting transition temperature and upper critical field increase sharply under low pressure before undergoing slight suppression under higher pressure. Density functional theory calculations reveal non-trivial topological surface states on (100) surface in Bi$_2$Ta$_3$S$_6$, which may offer a new avenue for exploring potential topological superconductivity in layered transition metal dichalcogenides."
  },
  {
    "date": "2026-01-15",
    "title": "Combinatorial properties of holographic entropy inequalities",
    "authors": "Guglielmo Grimaldi, Matthew Headrick, Veronika E. Hubeny, Pavel Shteyner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09987v1",
    "source": "arXiv",
    "abstract": "A holographic entropy inequality (HEI) is a linear inequality obeyed by Ryu-Takayanagi holographic entanglement entropies, or equivalently by the minimum cut function on weighted graphs. We establish a new combinatorial framework for studying HEIs, and use it to prove several properties they share, including two majorization-related properties as well as a necessary and sufficient condition for an inequality to be an HEI. We thereby resolve all the conjectures presented in [arXiv:2508.21823], proving two of them and disproving the other two. In particular, we show that the null reduction of any superbalanced HEI passes the majorization test defined in [arXiv:2508.21823], thereby providing strong new evidence that all HEIs are obeyed in time-dependent holographic states."
  },
  {
    "date": "2026-01-15",
    "title": "Classical simulation of a quantum circuit with noisy magic inputs",
    "authors": "Jiwon Heo, Sojeong Park, Changhun Oh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10111v1",
    "source": "arXiv",
    "abstract": "Magic states are essential for universal quantum computation and are widely viewed as a key source of quantum advantage, yet in realistic devices they are inevitably noisy. In this work, we characterize how noise on injected magic resources changes the classical simulability of quantum circuits and when it induces a transition from classically intractable behavior to efficient classical simulation. We adopt a resource-centric noise model in which only the injected magic components are noisy, while the baseline states, operations, and measurements belong to an efficiently simulable family. Within this setting, we develop an approximate classical sampling algorithm with controlled error and prove explicit noise-dependent conditions under which the algorithm runs in polynomial time. Our framework applies to both qubit circuits with Clifford baselines and fermionic circuits with matchgate baselines, covering representative noise channels such as dephasing and particle loss. We complement the analysis with numerical estimates of the simulation cost, providing concrete thresholds and runtime scaling across practically relevant parameter regimes."
  },
  {
    "date": "2026-01-15",
    "title": "Convex combination of first and second eigenvalues of trees",
    "authors": "Hitesh Kumar, Bojan Mohar, Shivaramakrishna Pragada, Hanmeng Zhan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10036v1",
    "source": "arXiv",
    "abstract": "For a graph $G$, let $λ_1(G)$ and $λ_2(G)$ denote the largest and the second largest adjacency eigenvalue of $G$. The sum $λ_1(G) + λ_2(G)$ is called the \\emph{spectral sum} of $G$. We investigate the spectral sum of trees of order $n$ and determine the extremal trees that achieve maximum/minimum. Moreover, for any $α\\in [0,1]$, we determine the extremal trees which maximize the convex combination $αλ_1 + (1-α)λ_2$ in the class of $n$-vertex trees."
  },
  {
    "date": "2026-01-15",
    "title": "On Existence of Girth-8 QC-LDPC Code with Large Column Weight: Combining Mirror-sequence with Classification Modulo Ten",
    "authors": "Guohua Zhang, Xiangya Liu, Jianhua Zhang, Yi Fang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10170v1",
    "source": "arXiv",
    "abstract": "Quasi-cyclic (QC) LDPC codes with large girths play a crucial role in several research and application fields, including channel coding, compressed sensing and distributed storage systems. A major challenge in respect of the code construction is how to obtain such codes with the shortest possible length (or equivalently, the smallest possible circulant size) using algebraic methods instead of search methods. The greatest-common-divisor (GCD) framework we previously proposed has algebraically constructed QC-LDPC codes with column weights of 5 and 6, very short lengths, and a girth of 8. By introducing the concept of a mirror sequence and adopting a new row-regrouping scheme, QC-LDPC codes with column weights of 7 and 8, very short lengths, and a girth of 8 are proposed for arbitrary row weights in this article via an algebraic manner under the GCD framework. Thanks to these novel algebraic methods, the lower bounds (for column weights 7 and 8) on consecutive circulant sizes are both improved by asymptotically about 20%, compared with the existing benchmarks. Furthermore, these new constructions can also offer circulant sizes asymptotically about 25% smaller than the novel bounds."
  },
  {
    "date": "2026-01-15",
    "title": "RAG-3DSG: Enhancing 3D Scene Graphs with Re-Shot Guided Retrieval-Augmented Generation",
    "authors": "Yue Chang, Rufeng Chen, Zhaofan Zhang, Yi Chen, Sihong Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10168v1",
    "source": "arXiv",
    "abstract": "Open-vocabulary 3D Scene Graph (3DSG) generation can enhance various downstream tasks in robotics, such as manipulation and navigation, by leveraging structured semantic representations. A 3DSG is constructed from multiple images of a scene, where objects are represented as nodes and relationships as edges. However, existing works for open-vocabulary 3DSG generation suffer from both low object-level recognition accuracy and speed, mainly due to constrained viewpoints, occlusions, and redundant surface density. To address these challenges, we propose RAG-3DSG to mitigate aggregation noise through re-shot guided uncertainty estimation and support object-level Retrieval-Augmented Generation (RAG) via reliable low-uncertainty objects. Furthermore, we propose a dynamic downsample-mapping strategy to accelerate cross-image object aggregation with adaptive granularity. Experiments on Replica dataset demonstrate that RAG-3DSG significantly improves node captioning accuracy in 3DSG generation while reducing the mapping time by two-thirds compared to the vanilla version."
  },
  {
    "date": "2026-01-15",
    "title": "Advancing Adaptive Multi-Stage Video Anomaly Reasoning: A Benchmark Dataset and Method",
    "authors": "Chao Huang, Benfeng Wang, Wei Wang, Jie Wen, Li Shen, Wenqi Ren, Yong Xu, Xiaochun Cao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10165v1",
    "source": "arXiv",
    "abstract": "Recent progress in reasoning capabilities of Multimodal Large Language Models(MLLMs) has highlighted their potential for performing complex video understanding tasks. However, in the domain of Video Anomaly Detection and Understanding (VAD&U), existing MLLM-based methods are largely limited to anomaly localization or post-hoc description, lacking explicit reasoning processes, risk awareness, and decision-oriented interpretation. To address this gap, we define a new task termed Video Anomaly Reasoning (VAR), which elevates video anomaly analysis from descriptive understanding to structured, multi-stage reasoning. VAR explicitly requires models to perform progressive reasoning over anomalous events before answering anomaly-related questions, encompassing visual perception, causal interpretation, and risk-aware decision making. To support this task, we present a new dataset with 8,641 videos, where each video is annotated with diverse question types corresponding to different reasoning depths, totaling more than 50,000 samples, making it one of the largest datasets for video anomaly. The annotations are based on a structured Perception-Cognition-Action Chain-of-Thought (PerCoAct-CoT), which formalizes domain-specific reasoning priors for video anomaly understanding. This design enables systematic evaluation of multi-stage and adaptive anomaly reasoning. In addition, we propose Anomaly-Aware Group Relative Policy Optimization to further enhance reasoning reliability under weak supervision. Building upon the proposed task and dataset, we develop an end-to-end MLLM-based VAR model termed Vad-R1-Plus, which supports adaptive hierarchical reasoning and risk-aware decision making. Extensive experiments demonstrate that the proposed benchmark and method effectively advance the reasoning capabilities of MLLMs on VAR tasks, outperforming both open-source and proprietary baselines."
  },
  {
    "date": "2026-01-15",
    "title": "Advances on two spectral conjectures regarding booksize of graphs",
    "authors": "Mingqing Zhai, Rui Li, Zhenzhen Lou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10163v1",
    "source": "arXiv",
    "abstract": "The \\emph{booksize} $ \\mathrm{bk}(G) \\) of a graph $ G $, introduced by Erdős, refers to the maximum integer $ r $ for which $G$ contains the book $ B_r $ as a subgraph. This paper investigates two open problems in spectral graph theory related to the booksize of graphs. First, we prove that for any positive integer $r$ and any $ B_{r+1} $-free graph $ G $ with $ m \\geq (9r)^2 $ edges, the spectral radius satisfies $ ρ(G) \\leq \\sqrt{m} $. Equality holds if and only if $ G $ is a complete bipartite graph. This result improves the lower bound on the booksize of Nosal graphs (i.e., graphs with $ ρ(G) > \\sqrt{m} $) from the previously established $ \\mathrm{bk}(G) > \\frac{1}{144}\\sqrt{m} $ to $ \\mathrm{bk}(G) > \\frac{1}{9}\\sqrt{m} $, presenting a significant advancement in the booksize conjecture proposed Li, Liu, and Zhang. Second, we show that for any positive integer $r$ and any non-bipartite $ B_{r+1} $-free graph $ G $ with $ m \\geq (240r)^2 $ edges, the spectral radius $ρ$ satisfies $ρ^2<m-1+\\frac{2}{ρ-1}$, unless $G$ is isomorphic to $S^+_{m,s}$ for some $s\\in\\{1,\\ldots,r\\}$. This resolves Liu and Miao's conjecture and further reveals an interesting phenomenon: even with a weaker spectral condition, $ρ^2\\geq m-1+\\frac2{ρ-1}$, we can still derive the supersaturation of the booksize for non-bipartite graphs."
  },
  {
    "date": "2026-01-15",
    "title": "The BINGO project X. Cosmological parameter constraints from HI Intensity Mapping lognormal simulations",
    "authors": "Pablo Motta, Camila P. Novaes, Elcio Abdalla, Jiajun Zhang, Gabriel A. Hoerning, Alessandro Marins, Eduardo J. de Mericia, Luiza O. Ponte, Amilcar R. Queiroz, Thyrso Villela, Bin Wang, Carlos A. Wuensche, Chang Feng, Edmar C. Gurjão",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10152v1",
    "source": "arXiv",
    "abstract": "Building on the transformative success of optical redshift surveys, the emerging technique of neutral hydrogen (HI) intensity mapping (IM) offers a novel probe of large-scale structure (LSS) growth and the late-time accelerated expansion of the universe. We present cosmological forecasts for the Baryon Acoustic Oscillations from Integrated Neutral Gas Observations (BINGO), a pioneering HI IM experiment, quantifying its potential to constrain the \\textit{Planck}-calibrated $Λ$CDM cosmology and extensions to the $w_0w_a$CDM dark energy model. For BINGO's Phase~1 configuration, we simulate the HI IM signal using a lognormal model and incorporate three dominant systematics: foreground residuals, thermal noise, and beam resolution effects. Using Bayesian inference, we derive joint constraints on six cosmological parameters ($Ω_b h^2$, $Ω_c h^2$, $100θ_s$, $n_s$, $\\ln 10^{10} A_s$, and $τ_r$) alongside 60 HI parameters ($b_{\\rm HI}^i$, $Ω_{\\rm HI}^i b_{\\rm HI}^i$) across 30 frequency channels. Our results demonstrate that combining BINGO with the Planck 2018 CMB dataset tightens the confidence regions of cosmological parameters to $\\sim$40\\% the size of those from Planck alone, significantly improving the precision of parameter estimation. Furthermore, BINGO constrains the redshift evolution of HI density and delivers competitive measurements of the dark energy equation of state parameters ($w_0$, $w_a$). These results demonstrate BINGO's potential to extract significant cosmological information from the HI distribution and provide constraints competitive with current and future cosmological surveys."
  },
  {
    "date": "2026-01-15",
    "title": "Simple Network Graph Comparative Learning",
    "authors": "Qiang Yu, Xinran Cheng, Shiqiang Xu, Chuanyi Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10150v1",
    "source": "arXiv",
    "abstract": "The effectiveness of contrastive learning methods has been widely recognized in the field of graph learning, especially in contexts where graph data often lack labels or are difficult to label. However, the application of these methods to node classification tasks still faces a number of challenges. First, existing data enhancement techniques may lead to significant differences from the original view when generating new views, which may weaken the relevance of the view and affect the efficiency of model training. Second, the vast majority of existing graph comparison learning algorithms rely on the use of a large number of negative samples. To address the above challenges, this study proposes a novel node classification contrast learning method called Simple Network Graph Comparative Learning (SNGCL). Specifically, SNGCL employs a superimposed multilayer Laplace smoothing filter as a step in processing the data to obtain global and local feature smoothing matrices, respectively, which are thus passed into the target and online networks of the siamese network, and finally employs an improved triple recombination loss function to bring the intra-class distance closer and the inter-class distance farther. We have compared SNGCL with state-of-the-art models in node classification tasks, and the experimental results show that SNGCL is strongly competitive in most tasks."
  },
  {
    "date": "2026-01-15",
    "title": "Warm Hybrid Axion Inflation in $α$-Attractor Models Constrained by ACT and Future Plan experiments",
    "authors": "Waqas Ahmed, Waqar Ahmad, Ahsan Illahi, M. Junaid",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10145v1",
    "source": "arXiv",
    "abstract": "We present a comprehensive study of warm hybrid inflation within the framework of $α$-attractor models, where an axionic inflaton is coupled to a waterfall field in the presence of thermal dissipation. The model is analyzed for both linear ($Υ\\propto T$) and cubic ($Υ\\propto T^{3}$) dissipation regimes. Confronting the theoretical predictions with the latest observational data from Planck+BICEP/Keck, P-ACT-LB-BK18 and SPT, and , we find that in the weak dissipative regime ($Q_{*} \\lesssim 10^{-5}$), the scalar spectral index $n_{s} \\simeq 0.965$ lies at the boundary of the combined P-ACT-LB-BK18 constraints, while the tensor-to-scalar ratio $r$ remains within observable ranges. For stronger dissipation ($Q_{*} \\gtrsim 10^{-5}$), the model predicts values of $n_{s}$ well within the $1$--$2σ$ confidence region of all datasets, with tensor modes remaining fully observable in both dissipation scenarios. These results indicate that forthcoming CMB polarization experiments may be capable of detecting primordial gravitational waves, thereby providing a robust observational test of warm hybrid inflation across different dissipative regimes."
  },
  {
    "date": "2026-01-15",
    "title": "Physics-informed neural networks for angular-momentum conservation in computational relativistic spin hydrodynamics",
    "authors": "Hidefumi Matsuda, Koichi Hattori, Koichi Murase",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10136v1",
    "source": "arXiv",
    "abstract": "Theoretical developments in relativistic spin hydrodynamics, which describes the macroscopic transport of spin angular momentum alongside other fundamental conserved quantities, have progressed rapidly since the experimental observation of the global spin polarization of $Λ$ hyperons in relativistic heavy-ion collision experiments. However, numerical simulations of relativistic spin hydrodynamics remain largely unaddressed due to computational challenges, particularly the accurate numerical conservation of total angular momentum. In this work, we propose the use of physics-informed neural networks (PINNs) for computational relativistic spin hydrodynamics. As a concrete application, we consider a rotating fluid confined within a cylindrical container. We show that angular-momentum conservation can be accurately achieved in the PINNs-based numerical framework. Furthermore, we investigate the spin-orbit conversion induced by the rotational viscous effect, which is the intrinsic dissipative process of relativistic spin hydrodynamics. Our analysis numerically identifies the mismatch between the transverse thermal vorticity and the spin potential as the driving mechanism of the spin-orbit conversion."
  },
  {
    "date": "2026-01-15",
    "title": "Function Correcting Codes for Maximally-Unbalanced Boolean Functions",
    "authors": "Rajlaxmi Pandey, Shiven Bajpai, Anjana A Mahesh, B. Sundar Rajan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10135v1",
    "source": "arXiv",
    "abstract": "Function-Correcting Codes (FCCs) enable reliable computation of a function of a $k$-bit message over noisy channels without requiring full message recovery. In this work, we study optimal single-error correcting FCCs (SEFCCs) for maximally-unbalanced Boolean functions, where $k$ denotes the message length and $t$ denotes the error-correction capability. We analyze the structure of optimal SEFCC constructions through their associated codeword distance matrices and identify distinct FCC classes based on this structure. We then examine the impact of these structural differences on error performance by evaluating representative FCCs over the additive white Gaussian noise (AWGN) channel using both soft-decision and hard-decision decoding. The results show that FCCs with different distance-matrix structures can exhibit markedly different Data BER and function error behavior, and that the influence of code structure depends strongly on the decoding strategy."
  },
  {
    "date": "2026-01-15",
    "title": "Curvature-driven manifold fitting under unbounded isotropic noise",
    "authors": "Ruowei Li, Zhigang Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10133v1",
    "source": "arXiv",
    "abstract": "Manifold fitting aims to reconstruct a low-dimensional manifold from high-dimensional data, whose framework is established by Fefferman et al. \\cite{fefferman2020reconstruction,fefferman2021reconstruction}. This paper studies the recovery of a compact $C^3$ submanifold $\\mathcal{M} \\subset \\mathbb{R}^D$ with dimension $d<D$ and positive reach $τ$ from observations $Y = X + ξ$, where $X$ is uniformly distributed on $\\mathcal{M}$ and $ξ\\sim \\mathcal{N}(0, σ^2 I_D)$ denotes isotropic Gaussian noise. To project any points $z$ in a tubular neighborhood $Γ$ of $\\mathcal{M}$ onto $\\mathcal{M}$, we construct a sample-based estimator $F:Γ\\to\\mathbb{R}^D$ by a normalized local kernel with the theoretically derived bandwidth $r = c_Dσ$. Under a sample size of $O(σ^{-3d-5})$, we establish with high probability the uniform asymptotic expansion \\[ F(z) = π(z) + \\frac{d}{2} H_{π(z)} σ^2 + O(σ^3), \\qquad z \\in Γ, \\] where $π(z)$ is the projection of $z$ onto $\\mathcal{M}$ and $H_{π(z)}$ is the mean curvature vector of $\\mathcal{M}$ at $π(z)$. The resulting manifold $F(Γ)$ has reach bounded below by $c τ$ for $c>0$ and achieves a state-of-the-art Hausdorff distance of $O(σ^2)$ to $\\mathcal{M}$. Numerical experiments confirm the quadratic decay of the reconstruction error and demonstrate the computational efficiency of the estimator $F$. Our work provides a curvature-driven framework for denoising and reconstructing manifolds with second-order accuracy."
  },
  {
    "date": "2026-01-15",
    "title": "Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction",
    "authors": "Yanan Cao, Farnaz Fallahi, Murali Mohana Krishna Dandu, Lalitesh Morishetti, Kai Zhao, Luyi Ma, Sinduja Subramaniam, Jianpeng Xu, Evren Korpeoglu, Kaushiki Nag, Sushant Kumar, Kannan Achan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10132v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning and prediction across different domains. Yet, their ability to infer temporal regularities from structured behavioral data remains underexplored. This paper presents a systematic study investigating whether LLMs can predict time intervals between recurring user actions, such as repeated purchases, and how different levels of contextual information shape their predictive behavior. Using a simple but representative repurchase scenario, we benchmark state-of-the-art LLMs in zero-shot settings against both statistical and machine-learning models. Two key findings emerge. First, while LLMs surpass lightweight statistical baselines, they consistently underperform dedicated machine-learning models, showing their limited ability to capture quantitative temporal structure. Second, although moderate context can improve LLM accuracy, adding further user-level detail degrades performance. These results challenge the assumption that \"more context leads to better reasoning\". Our study highlights fundamental limitations of today's LLMs in structured temporal inference and offers guidance for designing future context-aware hybrid models that integrate statistical precision with linguistic flexibility."
  },
  {
    "date": "2026-01-15",
    "title": "Hubble Tension and Dark Energy in Teleparallel Gauss-Bonnet Gravity: New Constraints from DESI BAO, Pantheon$^+$ and Hubble Data",
    "authors": "Santosh V. Lohakare, S. K. Maurya, Aaisha Al Qassabi, B. Mishra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10127v1",
    "source": "arXiv",
    "abstract": "We explore the cosmological dynamics of a teleparallel Gauss-Bonnet gravity model defined by the torsion scalar $T$ and the torsion-based Gauss-Bonnet invariant $T_{\\mathcal{G}}$, deriving modified Friedmann equations for a flat FLRW Universe and corresponding linear scalar perturbation equations. Using a numerical approach, we solve these equations for pressureless matter, predicting the redshift evolution of the Hubble parameter $H(z)$. Bayesian Markov chain Monte Carlo analysis, incorporating late-time observations from Cosmic Chronometers, Pantheon$^+$ with SH0ES, and DESI BAO (Data Release 1 and Data Release 2), constrains the model parameters, revealing that $f(T, T_{\\mathcal{G}})$ mimics dark energy in the absence of a cosmological constant, presenting a viable alternative to $Λ$CDM paradigm. Stability is confirmed via scalar perturbation analysis of Hubble and matter density fluctuations, positioning $f(T, T_{\\mathcal{G}})$ gravity as a robust framework to address cosmic acceleration challenges. The model yields a present-day effective equation of state $ω_{\\mathrm{eff}}(z=0) \\approx -0.664$ to \\(-0.693\\), consistent with observations, and partially alleviates the Hubble tension with $H_0$ estimates of 69 to 71.5\\kms. These findings highlight the potential of $f(T, T_{\\mathcal{G}})$ gravity to resolve fundamental cosmological puzzles while aligning with late-time observational data."
  },
  {
    "date": "2026-01-15",
    "title": "Role-Playing Agents Driven by Large Language Models: Current Status, Challenges, and Future Trends",
    "authors": "Ye Wang, Jiaxing Chen, Hongjiang Xiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10122v1",
    "source": "arXiv",
    "abstract": "In recent years, with the rapid advancement of large language models (LLMs), role-playing language agents (RPLAs) have emerged as a prominent research focus at the intersection of natural language processing (NLP) and human-computer interaction. This paper systematically reviews the current development and key technologies of RPLAs, delineating the technological evolution from early rule-based template paradigms, through the language style imitation stage, to the cognitive simulation stage centered on personality modeling and memory mechanisms. It summarizes the critical technical pathways supporting high-quality role-playing, including psychological scale-driven character modeling, memory-augmented prompting mechanisms, and motivation-situation-based behavioral decision control. At the data level, the paper further analyzes the methods and challenges of constructing role-specific corpora, focusing on data sources, copyright constraints, and structured annotation processes. In terms of evaluation, it collates multi-dimensional assessment frameworks and benchmark datasets covering role knowledge, personality fidelity, value alignment, and interactive hallucination, while commenting on the advantages and disadvantages of methods such as human evaluation, reward models, and LLM-based scoring. Finally, the paper outlines future development directions of role-playing agents, including personality evolution modeling, multi-agent collaborative narrative, multimodal immersive interaction, and integration with cognitive neuroscience, aiming to provide a systematic perspective and methodological insights for subsequent research."
  },
  {
    "date": "2026-01-15",
    "title": "Casimir interactions as a probe of broadband optical response",
    "authors": "Calum F. Shelden, Jeremy N. Munday",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10118v1",
    "source": "arXiv",
    "abstract": "Casimir forces arise from quantum electromagnetic fluctuations and depend on the dielectric response of interacting materials across the entire frequency spectrum. Although this dependence is central to Lifshitz theory of the Casimir effect, the formulation of the force in terms of dielectric functions evaluated at imaginary frequencies has largely obscured its connection to real-frequency optical properties, limiting the use of Casimir interactions as a probe of materials. Here we demonstrate that Casimir force measurements encode sufficient information to reconstruct a material's broadband optical response. Using supervised machine learning to invert Lifshitz theory, we determine the complex permittivity of a material over more than seven orders of magnitude in frequency from a single force-distance curve. We show that measurements at different separations selectively constrain distinct frequency ranges of the dielectric response, providing direct physical insight into how quantum fluctuations sample the electromagnetic spectrum. These results establish Casimir interactions as a physically constrained, broadband spectroscopic tool and open new opportunities for optical characterization in regimes inaccessible to conventional techniques."
  },
  {
    "date": "2026-01-15",
    "title": "Bayesian Model Selection for Complex Flows of Yield Stress Fluids",
    "authors": "Aricia Rinkens, Clemens V. Verhoosel, Alexandra Alicke, Patrick D. Anderson, Nick O. Jaensson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10115v1",
    "source": "arXiv",
    "abstract": "Modeling yield stress fluids in complex flow scenarios presents significant challenges, particularly because conventional rheological characterization methods often yield material parameters that are not fully representative of the intricate constitutive behavior observed in complex conditions. We propose a Bayesian uncertainty quantification framework for the calibration and selection of constitutive models for yield stress fluids, explicitly accounting for uncertainties in both modeling accuracy and experimental observations. The framework addresses the challenge of complex flow modeling by making discrepancies that emanate from rheological measurements explicit and quantifiable. We apply the Bayesian framework to rheological measurements and squeeze flow experiments on Carbopol 980. Our analysis demonstrates that Bayesian model selection yields robust probabilistic predictions and provides an objective assessment of model suitability through evaluated plausibilities. The framework naturally penalizes unnecessary complexity and shows that the optimal model choice depends on the incorporated physics, the prior information, and the availability of data. In rheological settings, the Herschel-Bulkley and biviscous power law models perform well. However, when these rheological outcomes are used as prior information for a rheo-informed squeeze flow analysis, a significant mismatch with the experimental data is observed. This is due to the yield stress inferred from rheological measurements not being representative of the complex squeeze flow case. In contrast, an expert-informed squeeze flow analysis, based on broader priors, yields accurate predictions. These findings highlight the limitations of translating rheological measurements to complex flows and underscore the value of Bayesian approaches in quantifying model bias and guiding model selection under uncertainty."
  },
  {
    "date": "2026-01-15",
    "title": "Following the Teacher's Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs",
    "authors": "Cheng Feng, Chaoliang Zhong, Jun Sun, Yusuke Oishi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10114v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are challenging to deploy for domain-specific tasks due to their massive scale. While distilling a fine-tuned LLM into a smaller student model is a promising alternative, the capacity gap between teacher and student often leads to suboptimal performance. This raises a key question: when and how can a student model match or even surpass its teacher on domain-specific tasks? In this work, we propose a novel theoretical insight: a student can outperform its teacher if its advantage on a Student-Favored Subdomain (SFS) outweighs its deficit on the Teacher-Favored Subdomain (TFS). Guided by this insight, we propose Scheduled Checkpoint Distillation (SCD), which reduces the TFS deficit by emulating the teacher's convergence process during supervised fine-tuning (SFT) on the domain task, and a sample-wise Adaptive Weighting (AW) mechanism to preserve student strengths on SFS. Experiments across diverse domain tasks--including QA, NER, and text classification in multiple languages--show that our method consistently outperforms existing distillation approaches, allowing the student model to match or even exceed the performance of its fine-tuned teacher."
  },
  {
    "date": "2026-01-15",
    "title": "SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature",
    "authors": "Yiming Ren, Junjie Wang, Yuxin Meng, Yihang Shi, Zhiqiang Lin, Ruihang Chu, Yiran Xu, Ziming Li, Yunfei Zhao, Zihan Wang, Yu Qiao, Ruiming Tang, Minghao Liu, Yujiu Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10108v1",
    "source": "arXiv",
    "abstract": "Evaluating whether multimodal large language models truly understand long-form scientific papers remains challenging: answer-only metrics and synthetic \"Needle-In-A-Haystack\" tests often reward answer matching without requiring a causal, evidence-linked reasoning trace in the document. We propose the \"Fish-in-the-Ocean\" (FITO) paradigm, which requires models to construct explicit cross-modal evidence chains within native scientific documents. To operationalize FITO, we build SIN-Data, a scientific interleaved corpus that preserves the native interleaving of text and figures. On top of it, we construct SIN-Bench with four progressive tasks covering evidence discovery (SIN-Find), hypothesis verification (SIN-Verify), grounded QA (SIN-QA), and evidence-anchored synthesis (SIN-Summary). We further introduce \"No Evidence, No Score\", scoring predictions when grounded to verifiable anchors and diagnosing evidence quality via matching, relevance, and logic. Experiments on eight MLLMs show that grounding is the primary bottleneck: Gemini-3-pro achieves the best average overall score (0.573), while GPT-5 attains the highest SIN-QA answer accuracy (0.767) but underperforms on evidence-aligned overall scores, exposing a gap between correctness and traceable support."
  },
  {
    "date": "2026-01-15",
    "title": "When Personas Override Payoffs: Role Identity Bias in Multi-Agent LLM Decision-Making",
    "authors": "Viswonathan Manoranjan, Snehalkumar `Neil' S. Gaikwad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10102v1",
    "source": "arXiv",
    "abstract": "Large language models are increasingly deployed in multi-agent systems for strategic tasks, yet how design choices such as role-based personas and payoff visibility affect reasoning remains poorly understood. We investigate whether multi-agent systems function as strategic reasoners capable of payoff optimization or as identity-driven actors that prioritize role alignment over explicit incentives. Using Nash equilibrium achievement as a diagnostic for strategic reasoning, we conduct systematic experiments across four LLM architectures (Qwen-7B, Qwen-32B, Llama-8B, Mistral-7B) in complex environmental decision-making games involving four agents. We show that role identity bias fundamentally alters strategic reasoning even when payoff-optimal equilibria exist and complete payoff information is available. Removing personas and providing explicit payoffs enables Qwen models to achieve high Nash equilibrium rates, indicating that both conditions are necessary for strategic reasoning. In contrast, personas systematically bias equilibrium selection toward socially preferred outcomes: with personas present, all of the achieved equilibria correspond to Green Transition, while models entirely fail to reach equilibrium when Tragedy of the Commons is payoff-optimal. The effect of explicit payoffs depends entirely on persona presence, revealing strong interactions between representational design choices. We also observe clear model-dependent patterns. Qwen architectures are highly sensitive to both personas and payoff visibility, whereas Llama and Mistral exhibit rigid reasoning behavior across conditions. These findings demonstrate that representational choices are substantive governance decisions that determine whether multi-agent systems act as strategic reasoners or identity-driven actors, with important implications for real-world deployment."
  },
  {
    "date": "2026-01-15",
    "title": "Admissibility Breakdown in High-Dimensional Sparse Regression with L1 Regularization",
    "authors": "Guo Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10100v1",
    "source": "arXiv",
    "abstract": "The choice of the tuning parameter in the Lasso is central to its statistical performance in high-dimensional linear regression. Classical consistency theory identifies the rate of the Lasso tuning parameter, and numerous studies have established non-asymptotic guarantees. Nevertheless, the question of optimal tuning within a non-asymptotic framework has not yet been fully resolved. We establish tuning criteria above which the Lasso becomes inadmissible under mean squared prediction error. More specifically, we establish thresholds showing that certain classical tuning choices yield Lasso estimators strictly dominated by a simple Lasso-Ridge refinement. We also address how the structure of the design matrix and the noise vector influences the inadmissibility phenomenon."
  },
  {
    "date": "2026-01-15",
    "title": "LeMoF: Level-guided Multimodal Fusion for Heterogeneous Clinical Data",
    "authors": "Jongseok Kim, Seongae Kang, Jonghwan Shin, Yuhan Lee, Ohyun Jo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10092v1",
    "source": "arXiv",
    "abstract": "Multimodal clinical prediction is widely used to integrate heterogeneous data such as Electronic Health Records (EHR) and biosignals. However, existing methods tend to rely on static modality integration schemes and simple fusion strategies. As a result, they fail to fully exploit modality-specific representations. In this paper, we propose Level-guided Modal Fusion (LeMoF), a novel framework that selectively integrates level-guided representations within each modality. Each level refers to a representation extracted from a different layer of the encoder. LeMoF explicitly separates and learns global modality-level predictions from level-specific discriminative representations. This design enables LeMoF to achieve a balanced performance between prediction stability and discriminative capability even in heterogeneous clinical environments. Experiments on length of stay prediction using Intensive Care Unit (ICU) data demonstrate that LeMoF consistently outperforms existing state-of-the-art multimodal fusion techniques across various encoder configurations. We also confirmed that level-wise integration is a key factor in achieving robust predictive performance across various clinical conditions."
  },
  {
    "date": "2026-01-15",
    "title": "Adaptive Label Error Detection: A Bayesian Approach to Mislabeled Data Detection",
    "authors": "Zan Chaudhry, Noam H. Rotenberg, Brian Caffo, Craig K. Jones, Haris I. Sair",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10084v1",
    "source": "arXiv",
    "abstract": "Machine learning classification systems are susceptible to poor performance when trained with incorrect ground truth labels, even when data is well-curated by expert annotators. As machine learning becomes more widespread, it is increasingly imperative to identify and correct mislabeling to develop more powerful models. In this work, we motivate and describe Adaptive Label Error Detection (ALED), a novel method of detecting mislabeling. ALED extracts an intermediate feature space from a deep convolutional neural network, denoises the features, models the reduced manifold of each class with a multidimensional Gaussian distribution, and performs a simple likelihood ratio test to identify mislabeled samples. We show that ALED has markedly increased sensitivity, without compromising precision, compared to established label error detection methods, on multiple medical imaging datasets. We demonstrate an example where fine-tuning a neural network on corrected data results in a 33.8% decrease in test set errors, providing strong benefits to end users. The ALED detector is deployed in the Python package statlab."
  },
  {
    "date": "2026-01-15",
    "title": "Sharp propagation of chaos in Rényi divergence",
    "authors": "Matthew S. Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10076v1",
    "source": "arXiv",
    "abstract": "We establish sharp rates for propagation of chaos in Rényi divergences for interacting diffusion systems at stationarity. Building upon the entropic hierarchy established in Lacker (2023), we show that under strong isoperimetry and weak interaction conditions, one can achieve $\\mathsf R_q(μ^1 \\,\\lVert\\, π) = \\widetilde O(\\frac{d q^2}{N^2})$ bounds on the $q$-Rényi divergence."
  },
  {
    "date": "2026-01-15",
    "title": "Efficient Content-based Recommendation Model Training via Noise-aware Coreset Selection",
    "authors": "Hung Vinh Tran, Tong Chen, Hechuan Wen, Quoc Viet Hung Nguyen, Bin Cui, Hongzhi Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10067v1",
    "source": "arXiv",
    "abstract": "Content-based recommendation systems (CRSs) utilize content features to predict user-item interactions, serving as essential tools for helping users navigate information-rich web services. However, ensuring the effectiveness of CRSs requires large-scale and even continuous model training to accommodate diverse user preferences, resulting in significant computational costs and resource demands. A promising approach to this challenge is coreset selection, which identifies a small but representative subset of data samples that preserves model quality while reducing training overhead. Yet, the selected coreset is vulnerable to the pervasive noise in user-item interactions, particularly when it is minimally sized. To this end, we propose Noise-aware Coreset Selection (NaCS), a specialized framework for CRSs. NaCS constructs coresets through submodular optimization based on training gradients, while simultaneously correcting noisy labels using a progressively trained model. Meanwhile, we refine the selected coreset by filtering out low-confidence samples through uncertainty quantification, thereby avoid training with unreliable interactions. Through extensive experiments, we show that NaCS produces higher-quality coresets for CRSs while achieving better efficiency than existing coreset selection techniques. Notably, NaCS recovers 93-95\\% of full-dataset training performance using merely 1\\% of the training data. The source code is available at \\href{https://github.com/chenxing1999/nacs}{https://github.com/chenxing1999/nacs}."
  },
  {
    "date": "2026-01-15",
    "title": "CoF-T2I: Video Models as Pure Visual Reasoners for Text-to-Image Generation",
    "authors": "Chengzhuo Tong, Mingkun Chang, Shenglong Zhang, Yuran Wang, Cheng Liang, Zhizheng Zhao, Ruichuan An, Bohan Zeng, Yang Shi, Yifan Dai, Ziming Zhao, Guanbin Li, Pengfei Wan, Yuanxing Zhang, Wentao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10061v1",
    "source": "arXiv",
    "abstract": "Recent video generation models have revealed the emergence of Chain-of-Frame (CoF) reasoning, enabling frame-by-frame visual inference. With this capability, video models have been successfully applied to various visual tasks (e.g., maze solving, visual puzzles). However, their potential to enhance text-to-image (T2I) generation remains largely unexplored due to the absence of a clearly defined visual reasoning starting point and interpretable intermediate states in the T2I generation process. To bridge this gap, we propose CoF-T2I, a model that integrates CoF reasoning into T2I generation via progressive visual refinement, where intermediate frames act as explicit reasoning steps and the final frame is taken as output. To establish such an explicit generation process, we curate CoF-Evol-Instruct, a dataset of CoF trajectories that model the generation process from semantics to aesthetics. To further improve quality and avoid motion artifacts, we enable independent encoding operation for each frame. Experiments show that CoF-T2I significantly outperforms the base video model and achieves competitive performance on challenging benchmarks, reaching 0.86 on GenEval and 7.468 on Imagine-Bench. These results indicate the substantial promise of video models for advancing high-quality text-to-image generation."
  },
  {
    "date": "2026-01-15",
    "title": "Kovács' conjecture on characterisation of projective space and hyperquadrics",
    "authors": "Soham Ghosh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10055v1",
    "source": "arXiv",
    "abstract": "We prove Kovács' conjecture that claims that if the $p^{th}$ exterior power of the tangent bundle of a smooth complex projective variety contains the $p^{th}$ exterior power of an ample vector bundle then the variety is either projective space or the $p$-dimensional quadric hypersurface. This provides a common generalization of Mori, Wahl, Cho-Sato, Andreatta-Wiśniewski, Kobayashi-Ochiai, and Araujo-Druel-Kovács type characterizations of such varieties."
  },
  {
    "date": "2026-01-15",
    "title": "Recurrence relations for the coefficients of the confluent and Gauss hypergeometric functions in the complex plane",
    "authors": "Zi-Qiao Xu, Zhong-Xuan Mao, Jing-Feng Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10040v1",
    "source": "arXiv",
    "abstract": "For $a,b,c,z,p, θ\\in \\mathbb{C}$, where $\\mathbb{C}$ is the complex plane, $-c\\notin \\mathbb{N\\cup }\\left\\{ 0\\right\\} $, let \\begin{equation*} \\mathcal{M}\\left( z\\right) =\\left( 1-θz\\right) ^{p}M\\left(a;c;z\\right) =\\sum_{n=0}^{\\infty }u_{n}z^{n}, \\end{equation*} where $|z| <\\frac{1}θ$, $|\\arg (1-θz)| < π$, and let \\begin{equation*} \\mathcal{G}\\left( z\\right) =(1-θz) ^{p}F(a,b;c;z) =\\sum_{n=0}^{\\infty }v_{n} z^{n}, \\end{equation*} where $|z| < 1$, $|\\arg (1-θz)| < π$. In this paper, we prove that the coefficients $u_{n}$ and $v_{n}$ for $n\\geq 0$ satisfy a 3-order recurrence relation. These offer a new way to study confluent hypergeometric function $M(a;c;z)$ and Gauss hypergeometric function $F(a,b;c;z)$. And we provide other special functions' recurrence relations of their coefficients, such as error function, Bessel function, incomplete gamma function, complete elliptic integral and Chebyshev polynomials."
  },
  {
    "date": "2026-01-15",
    "title": "Resistive Memory based Efficient Machine Unlearning and Continual Learning",
    "authors": "Ning Lin, Jichang Yang, Yangu He, Zijian Ye, Kwun Hang Wong, Xinyuan Zhang, Songqi Wang, Yi Li, Kemi Xu, Leo Yu Zhang, Xiaoming Chen, Dashan Shang, Han Wang, Xiaojuan Qi, Zhongrui Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10037v1",
    "source": "arXiv",
    "abstract": "Resistive memory (RM) based neuromorphic systems can emulate synaptic plasticity and thus support continual learning, but they generally lack biologically inspired mechanisms for active forgetting, which are critical for meeting modern data privacy requirements. Algorithmic forgetting, or machine unlearning, seeks to remove the influence of specific data from trained models to prevent memorization of sensitive information and the generation of harmful content, yet existing exact and approximate unlearning schemes incur prohibitive programming overheads on RM hardware owing to device variability and iterative write-verify cycles. Analogue implementations of continual learning face similar barriers. Here we present a hardware-software co-design that enables an efficient training, deployment and inference pipeline for machine unlearning and continual learning on RM accelerators. At the software level, we introduce a low-rank adaptation (LoRA) framework that confines updates to compact parameter branches, substantially reducing the number of trainable parameters and therefore the training cost. At the hardware level, we develop a hybrid analogue-digital compute-in-memory system in which well-trained weights are stored in analogue RM arrays, whereas dynamic LoRA updates are implemented in a digital computing unit with SRAM buffer. This hybrid architecture avoids costly reprogramming of analogue weights and maintains high energy efficiency during inference. Fabricated in a 180 nm CMOS process, the prototype achieves up to a 147.76-fold reduction in training cost, a 387.95-fold reduction in deployment overhead and a 48.44-fold reduction in inference energy across privacy-sensitive tasks including face recognition, speaker authentication and stylized image generation, paving the way for secure and efficient neuromorphic intelligence at the edge."
  },
  {
    "date": "2026-01-15",
    "title": "Contextuality Derived from Minimal Decision Dynamics: Quantum Tug-of-War Decision Making",
    "authors": "Song-Ju Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10034v1",
    "source": "arXiv",
    "abstract": "Decision making often exhibits context dependence that challenges classical probability theory. While quantum cognition has successfully modeled such phenomena, it remains unclear whether quantum probability is merely a convenient assumption or a necessary consequence of decision dynamics. Here we present a theoretical framework in which contextuality arises generatively from physically grounded constraints on decision making. By developing a quantum extension of the Tug-of-War (TOW) model, we show that conservation-based internal state updates and measurement-induced disturbance preclude any non-contextual classical description with a single, unified internal state. Contextuality therefore emerges as a structural consequence of adaptive learning dynamics. We further show that the resulting measurement structure admits Klyachko-Can-Binicioglu-Shumovsky (KCBS)-type contextuality witnesses in a minimal single-system setting. These results indicate that quantum probability is not merely a descriptive convenience, but an unavoidable effective theory for adaptive decision dynamics."
  },
  {
    "date": "2026-01-15",
    "title": "Stability and instability of small BGK waves",
    "authors": "Dongfen Bian, Emmanuel Grenier, Wenrui Huang, Benoit Pausader",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10030v1",
    "source": "arXiv",
    "abstract": "The aim of this article is to prove that the linear stability or instability of small Bernstein-Green-Kruskal (BGK) waves is determined by the sign of the derivative of their energy distributions at $0$ energy."
  },
  {
    "date": "2026-01-15",
    "title": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization",
    "authors": "Tingyue Pan, Jie Ouyang, Mingyue Cheng, Qingchuan Li, Zirui Liu, Mingfan Pan, Shuo Yu, Qi Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10029v1",
    "source": "arXiv",
    "abstract": "Academic paper search is a fundamental task in scientific research, yet most existing approaches rely on rigid, predefined workflows that struggle with complex, conditional queries. To address this limitation, we propose PaperScout, an autonomous agent that reformulates paper search as a sequential decision-making process. Unlike static workflows, PaperScout dynamically decides whether, when, and how to invoke search and expand tools based on accumulated retrieval context. However, training such agents presents a fundamental challenge: standard reinforcement learning methods, typically designed for single-turn tasks, suffer from a granularity mismatch when applied to multi-turn agentic tasks, where token-level optimization diverges from the granularity of sequence-level interactions, leading to noisy credit assignment. We introduce Proximal Sequence Policy Optimization (PSPO), a process-aware, sequence-level policy optimization method that aligns optimization with agent-environment interaction. Comprehensive experiments on both synthetic and real-world benchmarks demonstrate that PaperScout significantly outperforms strong workflow-driven and RL baselines in both recall and relevance, validating the effectiveness of our adaptive agentic framework and optimization strategy."
  },
  {
    "date": "2026-01-15",
    "title": "Fundamental Limits of Coded Polynomial Aggregation",
    "authors": "Xi Zhong, Jörg Kliewer, Mingyue Ji",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10028v1",
    "source": "arXiv",
    "abstract": "Coded polynomial aggregation (CPA) enables the master to directly recover a weighted aggregation of polynomial evaluations without individually decoding each term, thereby reducing the number of required worker responses. In this paper, we extend CPA to straggler-aware distributed computing systems and introduce a straggler-aware CPA framework with pre-specified non-straggler patterns, where exact recovery is required only for a given collection of admissible non-straggler sets. Our main result shows that exact recovery of the desired aggregation is achievable with fewer worker responses than required by polynomial coded computing based on individual decoding, and that feasibility is fundamentally characterized by the intersection structure of the non-straggler patterns. In particular, we establish necessary and sufficient conditions for exact recovery in straggler-aware CPA and identify an intersection-size threshold that is sufficient to guarantee exact recovery. We further prove that this threshold becomes both necessary and sufficient when the number of admissible non-straggler sets is sufficiently large. We also provide an explicit construction of feasible CPA schemes whenever the intersection size exceeds the derived threshold. Finally, simulations reveal a sharp feasibility transition at the predicted threshold, providing empirical evidence that the bound is tight in practice."
  },
  {
    "date": "2026-01-15",
    "title": "STCRank: Spatio-temporal Collaborative Ranking for Interactive Recommender System at Kuaishou E-shop",
    "authors": "Boyang Xia, Ruilin Bao, Hanjun Jiang, Jun Wang, Wenwu Ou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10027v1",
    "source": "arXiv",
    "abstract": "As a popular e-commerce platform, Kuaishou E-shop provides precise personalized product recommendations to tens of millions of users every day. To better respond real-time user feedback, we have deployed an interactive recommender system (IRS) alongside our core homepage recommender system. This IRS is triggered by user click on homepage, and generates a series of highly relevant recommendations based on the clicked item to meet focused browsing demands. Different from traditional e-commerce RecSys, the full-screen UI and immersive swiping down functionality present two distinct challenges for regular ranking system. First, there exists explicit interference (overlap or conflicts) between ranking objectives, i.e., conversion, view and swipe down. This is because there are intrinsic behavioral co-occurrences under the premise of immersive browsing and swiping down functionality. Second, the ranking system is prone to temporal greedy traps in sequential recommendation slot transitions, which is caused by full-screen UI design. To alleviate these challenges, we propose a novel Spatio-temporal collaborative ranking (STCRank) framework to achieve collaboration between multi-objectives within one slot (spatial) and between multiple sequential recommondation slots. In multi-objective collaboration (MOC) module, we push Pareto frontier by mitigating the objective overlaps and conflicts. In multi-slot collaboration (MSC) module, we achieve global optima on overall sequential slots by dual-stage look-ahead ranking mechanism. Extensive experiments demonstrate our proposed method brings about purchase and DAU co-growth. The proposed system has been already deployed at Kuaishou E-shop since 2025.6."
  },
  {
    "date": "2026-01-15",
    "title": "A New Overture to Classical Simple Type Theory, Ketonen-type Gentzen and Tableau Systems",
    "authors": "Tadayoshi Miwa, Takao Inoué",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10026v1",
    "source": "arXiv",
    "abstract": "In this paper, we introduce a Ketonen-type Gentzen-style classical simple type theory $\\bf KCT$. Also the tableau system $\\bf KCTT$ corresponding to $\\bf KCT$ is introduced. Further inference-preserving Gentzen system $\\bf KCT_h$ (equivalent to $\\bf KCT$) and tableau system $\\bf KCTT_h$ (equivalent to $\\bf KCTT$) is introduced. We introduce the notion of Hintikka sequents for $\\bf KCTT_h$.The completeness theorem and Takahashi-Prawitz's theorem are proved for $\\bf KCTT_h$."
  },
  {
    "date": "2026-01-15",
    "title": "An introduction to weightings along submanifolds",
    "authors": "Eckhard Meinrenken",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10021v1",
    "source": "arXiv",
    "abstract": "This article is based on a talk given at the Ghent Geometric Analysis Seminar in 2023. We review basic notions from the theory of weightings along submanifolds, with special emphasis on multiplicative weightings for Lie groupoids along subgroupoids."
  },
  {
    "date": "2026-01-15",
    "title": "Empowering Older Adults in Digital Technology Use with Foundation Models",
    "authors": "Hasti Sharifi, Homaira Huda Shomee, Sourav Medya, Debaleena Chattopadhyay",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10018v1",
    "source": "arXiv",
    "abstract": "While high-quality technology support can assist older adults in using digital applications, many struggle to articulate their issues due to unfamiliarity with technical terminology and age-related cognitive changes. This study examines these communication challenges and explores AI-based approaches to mitigate them. We conducted a diary study with English-speaking, community-dwelling older adults to collect asynchronous, technology-related queries and used reflexive thematic analysis to identify communication barriers. To address these barriers, we evaluated how foundation models can paraphrase older adults' queries to improve solution accuracy. Two controlled experiments followed: one with younger adults evaluating AI-rephrased queries and another with older adults evaluating AI-generated solutions. We also developed a pipeline using large language models to generate the first synthetic dataset of how older adults request tech support (OATS). We identified four key communication challenges: verbosity, incompleteness, over-specification, and under-specification. Our prompt-chaining approach using the large language model, GPT-4o, elicited contextual details, paraphrased the original query, and generated a solution. AI-rephrased queries significantly improved solution accuracy (69% vs. 46%) and Google search results (69% vs. 35%). Younger adults better understood AI-rephrased queries (93.7% vs. 65.8%) and reported greater confidence and ease. Older adults reported high perceived ability to answer contextual questions (89.8%) and follow solutions (94.7%), with high confidence and ease. OATS demonstrated strong fidelity and face validity. This work shows how foundation models can enhance technology support for older adults by addressing age-related communication barriers. The OATS dataset offers a scalable resource for developing equitable AI systems that better serve aging populations."
  },
  {
    "date": "2026-01-15",
    "title": "VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models",
    "authors": "Zefan Zhang, Kehua Zhu, Shijie Jiang, Hongyuan Lu, Shengkai Sun, Tian Bai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10010v1",
    "source": "arXiv",
    "abstract": "Video Large Language Models (VideoLLMs) exhibit various types of hallucinations. Existing research has primarily focused on hallucinations involving the presence of events, objects, and scenes in videos, while largely neglecting event relation hallucination. In this paper, we introduce a novel benchmark for evaluating the Video Event Relation Hallucination, named VERHallu. This benchmark focuses on causal, temporal, and subevent relations between events, encompassing three types of tasks: relation classification, question answering, and counterfactual question answering, for a comprehensive evaluation of event relation hallucination. Additionally, it features counterintuitive video scenarios that deviate from typical pretraining distributions, with each sample accompanied by human-annotated candidates covering both vision-language and pure language biases. Our analysis reveals that current state-of-the-art VideoLLMs struggle with dense-event relation reasoning, often relying on prior knowledge due to insufficient use of frame-level cues. Although these models demonstrate strong grounding capabilities for key events, they often overlook the surrounding subevents, leading to an incomplete and inaccurate understanding of event relations. To tackle this, we propose a Key-Frame Propagating (KFP) strategy, which reallocates frame-level attention within intermediate layers to enhance multi-event understanding. Experiments show it effectively mitigates the event relation hallucination without affecting inference speed."
  },
  {
    "date": "2026-01-15",
    "title": "The \"I\" in FAIR: Translating from Interoperability in Principle to Interoperation in Practice",
    "authors": "Evan Morris, Gaurav Vaidya, Phil Owen, Jason Reilly, Karamarie Fecho, Patrick Wang, Yaphet Kebede, E. Kathleen Carter, Chris Bizon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10008v1",
    "source": "arXiv",
    "abstract": "The FAIR (Findable, Accessible, Interoperable, and Reusable) data principles [1] promote the interoperability of scientific data by encouraging the use of persistent identifiers, standardized vocabularies, and formal metadata structures. Many resources are created using vocabularies that are FAIR-compliant and well-annotated, yet the collective ecosystem of these resources often fails to interoperate effectively in practice. This continued challenge is mainly due to variation in identifier schemas and data models used in these resources. We have created two tools to bridge the chasm between interoperability in principle and interoperation in practice. Babel solves the problem of multiple identifier schemes by producing a curated set of identifier mappings to create cliques of equivalent identifiers that are exposed through high-performance APIs. ORION solves the problems of multiple data models by ingesting knowledge bases and transforming them into a common, community-managed data model. Here, we describe Babel and ORION and demonstrate their ability to support data interoperation. A library of fully interoperable knowledge bases created through the application of Babel and ORION is available for download and use at https://robokop.renci.org."
  },
  {
    "date": "2026-01-15",
    "title": "Same Activity, Divergent Impacts: Representing Paths Towards Physics Computational Literacy and Physics Identity with Conjecture Mapping-Based Narrative Analysis",
    "authors": "Sarah McHale, Tor Ole B. Odden, Ken Heller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10005v1",
    "source": "arXiv",
    "abstract": "Integrating computation into physics teaching is a curricular move that, at present, has been predominately studied for its cognitive impacts. However, if this modality of instruction shifts how students engage with physics, we argue there is room for students to redefine what it means to do physics and how they perceive themselves relative to the field. To investigate this, we situate a comparative case study in the context of a computationally integrated physics course. We study two students' experiences with a multi-day activity to understand how and why they came to affectively divergent self-perceptions. We propose a modified use of conjecture mapping to visualize the production of affective outcomes and connect narrative analysis to activity design. Our analysis highlights how different interpretations of and engagement with activity design reflect students' epistemic framing of code, which, in turn, drives engagement with scaffolding in manners that shape self-perception."
  },
  {
    "date": "2026-01-15",
    "title": "DW-DGAT: Dynamically Weighted Dual Graph Attention Network for Neurodegenerative Disease Diagnosis",
    "authors": "Chengjia Liang, Zhenjiong Wang, Chao Chen, Ruizhi Zhang, Songxi Liang, Hai Xie, Haijun Lei, Zhongwei Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10001v1",
    "source": "arXiv",
    "abstract": "Parkinson's disease (PD) and Alzheimer's disease (AD) are the two most prevalent and incurable neurodegenerative diseases (NDs) worldwide, for which early diagnosis is critical to delay their progression. However, the high dimensionality of multi-metric data with diverse structural forms, the heterogeneity of neuroimaging and phenotypic data, and class imbalance collectively pose significant challenges to early ND diagnosis. To address these challenges, we propose a dynamically weighted dual graph attention network (DW-DGAT) that integrates: (1) a general-purpose data fusion strategy to merge three structural forms of multi-metric data; (2) a dual graph attention architecture based on brain regions and inter-sample relationships to extract both micro- and macro-level features; and (3) a class weight generation mechanism combined with two stable and effective loss functions to mitigate class imbalance. Rigorous experiments, based on the Parkinson Progression Marker Initiative (PPMI) and Alzhermer's Disease Neuroimaging Initiative (ADNI) studies, demonstrate the state-of-the-art performance of our approach."
  },
  {
    "date": "2026-01-15",
    "title": "Gatekeeping: a Partial History of Cold Fusion",
    "authors": "Jonah F Messinger, Florian Metzler, Huw Price",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09996v1",
    "source": "arXiv",
    "abstract": "One of the most public episodes of gatekeeping in modern science was the case of so-called 'cold fusion'. At a news conference in 1989 the electrochemists Martin Fleischmann and Stanley Pons announced that they had found evidence of nuclear fusion in palladium electrodes loaded with deuterium. There was worldwide interest. Many groups sought to reproduce the results, most unsuccessfully. Within months, the prevailing view became strongly negative. The claims of Fleischmann and Pons came to be regarded as disreputable, as well as false. As the Caltech physicist David Goldstein put it, cold fusion became 'a pariah field, cast out by the scientific establishment' (Goldstein 1994). The case would already be interesting for students of gatekeeping if the story had ended at that point. Even more interestingly, however, the field survived and persisted. It has been enjoying a modest renaissance, with recent government funding both in the US and the EU. This piece offers an opinionated introduction to cold fusion as a case study of scientific gatekeeping, discussing both its early and recent history"
  },
  {
    "date": "2026-01-15",
    "title": "Double Markovity for quantum systems",
    "authors": "Masahito Hayashi, Jinpei Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09995v1",
    "source": "arXiv",
    "abstract": "The subadditivity-doubling-rotation (SDR) technique is a powerful route to Gaussian optimality in classical information theory and relies on strict subadditivity and its equality-case analysis, where double Markovity is a standard tool. We establish quantum analogues of double Markovity. For tripartite states, we characterize the simultaneous Markov conditions A-B-C and A-C-B via compatible projective measurements on B and C that induce a common classical label J yielding A-J-(BC). For strictly positive four-party states, we show that A-(BD)-C and A-(CD)-B hold if and only if A-D-(BC) holds. These results remove a key bottleneck in extending SDR-type arguments to quantum systems."
  },
  {
    "date": "2026-01-15",
    "title": "On directional second-order tangent sets of analytic sets and applications in optimization",
    "authors": "Le Cong Trinh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09991v1",
    "source": "arXiv",
    "abstract": "In this paper we study directional second-order tangent sets of real and complex analytic sets. For an analytic set $X\\subseteq\\mathbb{K}^n$ and a nonzero tangent direction $u\\in T_0X$, we compare the geometric second-order tangent set $T^2_{0,u}X$, defined via second-order expansions of analytic arcs, with the algebraic second-order tangent set $T^{2,a}_{0,u}X$, defined by initial forms of the defining equations. We prove the general inclusion $T^2_{0,u}X\\subseteq T^{2,a}_{0,u}X$ and construct explicit real and complex analytic examples showing that the inclusion is strict. We introduce a second-jet formulation along fixed tangent directions and show that $T^2_{0,u}X=T^{2,a}_{0,u}X$ if and only if the natural second-jet map from analytic arcs in $X$ to jets on the tangent cone $C_0X$ is surjective. This surjectivity is established for smooth analytic germs, homogeneous analytic cones, hypersurfaces with nondegenerate tangent directions, and nondegenerate analytic complete intersections. As an application, we derive second-order necessary and sufficient optimality conditions for $C^2$ optimization problems on analytic sets."
  },
  {
    "date": "2026-01-15",
    "title": "FaTRQ: Tiered Residual Quantization for LLM Vector Search in Far-Memory-Aware ANNS Systems",
    "authors": "Tianqi Zhang, Flavio Ponzina, Tajana Rosing",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09985v1",
    "source": "arXiv",
    "abstract": "Approximate Nearest-Neighbor Search (ANNS) is a key technique in retrieval-augmented generation (RAG), enabling rapid identification of the most relevant high-dimensional embeddings from massive vector databases. Modern ANNS engines accelerate this process using prebuilt indexes and store compressed vector-quantized representations in fast memory. However, they still rely on a costly second-pass refinement stage that reads full-precision vectors from slower storage like SSDs. For modern text and multimodal embeddings, these reads now dominate the latency of the entire query. We propose FaTRQ, a far-memory-aware refinement system using tiered memory that eliminates the need to fetch full vectors from storage. It introduces a progressive distance estimator that refines coarse scores using compact residuals streamed from far memory. Refinement stops early once a candidate is provably outside the top-k. To support this, we propose tiered residual quantization, which encodes residuals as ternary values stored efficiently in far memory. A custom accelerator is deployed in a CXL Type-2 device to perform low-latency refinement locally. Together, FaTRQ improves the storage efficiency by 2.4$\\times$ and improves the throughput by up to 9$ \\times$ than SOTA GPU ANNS system."
  },
  {
    "date": "2026-01-15",
    "title": "Estimating the effect of lymphovascular invasion on 2-year survival probability under endogeneity: a recursive copula-based approach",
    "authors": "Yang Ou, Lan Xue, Carmen Tekwe, Kedir N. Turi, Roger S. Zoh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09984v1",
    "source": "arXiv",
    "abstract": "Lymphovascular invasion (LVI) is an important prognostic marker for head and neck squamous cell carcinoma (HNSC), but the true effect of LVI on survival may be distorted by endogeneity arising from unmeasured confounding. Conventional one-stage conditional models and instrument-based two-stage estimators are prone to bias under endogeneity, and sufficiently strong instruments are often unavailable in practice. To address these challenges, we propose a semiparametric recursive copula framework that jointly specifies marginal models for both LVI, treated as an endogenous exposure, and a binary 2-year survival outcome, and links them through a flexible copula to account for latent confounding and accommodate censoring without requiring strong instruments. In two simulation studies, we systematically varied sample sizes, censoring rates from 0% to 60%, and endogeneity strengths, and assessed robustness under moderate model misspecification. The proposed copula framework exhibited reduced bias and improved interval coverage compared with both one-stage and two-stage approaches while maintaining robustness to moderate misspecification. We applied the method to HNSC cases with associated clinical and microRNA data from The Cancer Genome Atlas (n = 215), and found that LVI significantly reduced 2-year survival probability by approximately 47%, with a 95% confidence interval of -0.61 to -0.29 on the probability scale. The estimated positive dependence parameter indicates that the attenuation is driven by residual dependence between unobserved components of LVI and survival. Overall, the proposed copula framework yields more credible effect estimates for survival outcomes in the absence of strong instruments, mitigating biases due to endogeneity and censoring and strengthening quantitative evidence for HNSC research."
  },
  {
    "date": "2026-01-15",
    "title": "DR$^2$Seg: Decomposed Two-Stage Rollouts for Efficient Reasoning Segmentation in Multimodal Large Language Models",
    "authors": "Yulin He, Wei Chen, Zhikang Jian, Tianhang Guo, Wenjuan Zhou, Minglong Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09981v1",
    "source": "arXiv",
    "abstract": "Reasoning segmentation is an emerging vision-language task that requires reasoning over intricate text queries to precisely segment objects. However, existing methods typically suffer from overthinking, generating verbose reasoning chains that interfere with object localization in multimodal large language models (MLLMs). To address this issue, we propose DR$^2$Seg, a self-rewarding framework that improves both reasoning efficiency and segmentation accuracy without requiring extra thinking supervision. DR$^2$Seg employs a two-stage rollout strategy that decomposes reasoning segmentation into multimodal reasoning and referring segmentation. In the first stage, the model generates a self-contained description that explicitly specifies the target object. In the second stage, this description replaces the original complex query to verify its self-containment. Based on this design, two self-rewards are introduced to strengthen goal-oriented reasoning and suppress redundant thinking. Extensive experiments across MLLMs of varying scales and segmentation models demonstrate that DR$^2$Seg consistently improves reasoning efficiency and overall segmentation performance."
  },
  {
    "date": "2026-01-15",
    "title": "Einstein and Yang-Mills implies conformal Yang-Mills",
    "authors": "Samuel Blitz, A. Rod Gover, Jarosław Kopiński, Andrew Waldron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09975v1",
    "source": "arXiv",
    "abstract": "There exist conformally invariant, higher-derivative, variational analogs of the Yang-Mills condition for connections on vector bundles over a conformal manifold of even dimension greater than or equal to six. We give a compact formula for these analogs and prove that they are a strict weakening of the Yang-Mills condition with respect to an Einstein metric. We also show that the conformal Yang-Mills condition for the tractor connection of an even dimensional conformal manifold is equivalent to vanishing of its Fefferman-Graham obstruction tensor. This result uses that the tractor connection on a Poincaré-Einstein manifold is itself Yang-Mills."
  },
  {
    "date": "2026-01-15",
    "title": "SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation",
    "authors": "Seoyeon Kim, Jaehyung Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09974v1",
    "source": "arXiv",
    "abstract": "Personalizing Large Language Models typically relies on static retrieval or one-time adaptation, assuming user preferences remain invariant over time. However, real-world interactions are dynamic, where user interests continuously evolve, posing a challenge for models to adapt to preference drift without catastrophic forgetting. Standard continual learning approaches often struggle in this context, as they indiscriminately update on noisy interaction streams, failing to distinguish genuine preference shifts from transient contexts. To address this, we introduce SPRInG, a novel semi-parametric framework designed for effective continual personalization. During training, SPRInG employs drift-driven selective adaptation, which utilizes a likelihood-based scoring function to identify high-novelty interactions. This allows the model to selectively update the user-specific adapter on drift signals while preserving hard-to-learn residuals in a replay buffer. During inference, we apply strict relevance gating and fuse parametric knowledge with retrieved history via logit interpolation. Experiments on the long-form personalized generation benchmark demonstrate that SPRInG outperforms existing baselines, validating its robustness for real-world continual personalization."
  },
  {
    "date": "2026-01-15",
    "title": "Correspondences in computational and dynamical complexity II: forcing complex reductions",
    "authors": "Samuel Everett",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09973v1",
    "source": "arXiv",
    "abstract": "An algebraic telic problem is a decision problem in $\\textsf{NP}_\\mathbb{R}$ formalizing finite-time reachability questions for one-dimensional dynamical systems. We prove that the existence of \"natural\" mapping reductions between algebraic telic problems coming from distinct dynamical systems implies the two dynamical systems exhibit similar behavior (in a precise sense). As a consequence, we obtain explicit barriers for algorithms solving algebraic telic problems coming from complex dynamical systems, such as those with positive topological entropy. For example, some telic problems cannot be decided by uniform arithmetic circuit families with only $+$ and $\\times$ gates."
  },
  {
    "date": "2026-01-15",
    "title": "An Exploratory Study to Repurpose LLMs to a Unified Architecture for Time Series Classification",
    "authors": "Hansen He, Shuheng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09971v1",
    "source": "arXiv",
    "abstract": "Time series classification (TSC) is a core machine learning problem with broad applications. Recently there has been growing interest in repurposing large language models (LLMs) for TSC, motivated by their strong reasoning and generalization ability. Prior work has primarily focused on alignment strategies that explicitly map time series data into the textual domain; however, the choice of time series encoder architecture remains underexplored. In this work, we conduct an exploratory study of hybrid architectures that combine specialized time series encoders with a frozen LLM backbone. We evaluate a diverse set of encoder families, including Inception, convolutional, residual, transformer-based, and multilayer perceptron architectures, among which the Inception model is the only encoder architecture that consistently yields positive performance gains when integrated with an LLM backbone. Overall, this study highlights the impact of time series encoder choice in hybrid LLM architectures and points to Inception-based models as a promising direction for future LLM-driven time series learning."
  },
  {
    "date": "2026-01-15",
    "title": "Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series",
    "authors": "Griffin Kearney",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09949v1",
    "source": "arXiv",
    "abstract": "Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations (raw values, patches, finite differences) can be brittle in low signal-to-noise regimes, especially when downstream objectives impose asymmetric penalties that rationally encourage abstention. We introduce Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients (position, velocity, acceleration, jerk). This is applied to financial time series data in the form of asset prices in conjunction with trading volume profiles. Across a multi-asset daily-equity testbed, we use a risk-averse asymmetric classification objective as a stress test for learnability. Under this objective, several discrete baselines collapse to an absorbing cash policy (the Liquidation Equilibrium), whereas the continuous spline tokens sustain calibrated, non-trivial action distributions and stable policies. These results suggest that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses."
  },
  {
    "date": "2026-01-15",
    "title": "Reconstructing Reed-Solomon Codes from Multiple Noisy Channel Outputs",
    "authors": "Shubhransh Singhvi, Han Mao Kiah, Eitan Yaakobi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09947v1",
    "source": "arXiv",
    "abstract": "The sequence reconstruction problem, introduced by Levenshtein in 2001, considers a communication setting in which a sender transmits a codeword and the receiver observes K independent noisy versions of this codeword. In this work, we study the problem of efficient reconstruction when each of the $K$ outputs is corrupted by a $q$-ary discrete memoryless symmetric (DMS) substitution channel with substitution probability $p$. Focusing on Reed-Solomon (RS) codes, we adapt the Koetter-Vardy soft-decision decoding algorithm to obtain an efficient reconstruction algorithm. For sufficiently large blocklength and alphabet size, we derive an explicit rate threshold, depending only on $(p, K)$, such that the transmitted codeword can be reconstructed with arbitrarily small probability of error whenever the code rate $R$ lies below this threshold."
  },
  {
    "date": "2026-01-15",
    "title": "On the reconstruction of kinematic distributions computed with Monte Carlo methods using orthogonal basis functions",
    "authors": "Kirill Melnikov, Ivan Novikov, Ivan Pedron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10420v1",
    "source": "arXiv",
    "abstract": "Reconstruction of one-dimensional kinematic distributions from calculations based on high-dimensional Monte-Carlo integration is a standard problem in high-energy physics. Traditionally, this is done by collecting randomly-generated events in histograms. In this article, we explore an alternative approach, whose main idea is to approximate the target distribution by a weighted sum of orthogonal basis functions whose coefficients are calculated using the Monte-Carlo integration. This method has the advantage of directly yielding smooth approximations to target distributions. Furthermore, in the context of high-order perturbative calculations with local subtractions, it eliminates the so-called bin-to-bin fluctuations, which often severely affect the quality of conventional histograms. We also demonstrate that the availability of a high-quality approximation to the target distribution, for example the leading-order result in the perturbative expansion, can be exploited to construct an optimized orthonormal basis. We compare the performance of this method to conventional histograms in both toy-model and real Monte-Carlo settings, applying it to Higgs boson production in weak boson fusion as an example."
  },
  {
    "date": "2026-01-15",
    "title": "On the Canonical Construction of Simple Lie Superalgebras",
    "authors": "J. Dhamothiran, Saudamini Nayak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10419v1",
    "source": "arXiv",
    "abstract": "Axioms for the generalization of root systems were defined and classified (irreducible) by V. Serganova, which precisely correspond to the root systems of basic classical Lie Superalgebras. Here, we present a unified method for constructing simple Lie Superalgebras from the abstract root system, with the choice of base having the minimal number of isotropic roots."
  },
  {
    "date": "2026-01-15",
    "title": "Optimality in nonlocal time-dependent obstacle problems",
    "authors": "Ioannis Athanasopoulos, Luis Caffarelli, Emmanouil Milakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10417v1",
    "source": "arXiv",
    "abstract": "This paper showcases the effectiveness of the quasiconvexity property in addressing the optimal regularity of the temporal derivative and establishes conditions for its continuity in nonlocal time-dependent obstacle problems."
  },
  {
    "date": "2026-01-15",
    "title": "Bounding many-body properties under partial information and finite measurement statistics",
    "authors": "Luke Mortimer, Leonardo Zambrano, Antonio Acín, Donato Farina",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10408v1",
    "source": "arXiv",
    "abstract": "Calculating bounds of properties of many-body quantum systems is of paramount importance, since they guide our understanding of emergent quantum phenomena and complement the insights obtained from estimation methods. Recent semidefinite programming approaches enable probabilistic bounds from finite-shot measurements of easily accessible, yet informationally incomplete, observables. Here we render these methods scalable in the number of qubits by instead utilizing moment-matrix relaxations. After introducing the general formalism, we show how the approach can be adapted with specific knowledge of the system, such as it being the ground state of a given Hamiltonian, possessing specific symmetries or being the steady state of a given Lindbladian. Our approach defines a scalable real-world certification scheme leveraging semidefinite programming relaxations and experimental estimations which, unavoidably, contain shot noise."
  },
  {
    "date": "2026-01-15",
    "title": "A Predictive Model for Synergistic Oncolytic Virotherapy: Unveiling the Ping-Pong Mechanism and Optimal Timing of Combined Vesicular Stomatitis and Vaccinia Viruses",
    "authors": "Joseph Malinzi, Amina Eladdadi, Rachid Ouifki, Raluca Eftimie, Anotida Madzvamuse, Helen M. Byrne",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10405v1",
    "source": "arXiv",
    "abstract": "We present a mathematical model that describes the synergistic mechanism of combined Vesicular Stomatitis Virus (VSV) and Vaccinia Virus (VV). The model captures the dynamic interplay between tumor cells, viral replication, and the interferon-mediated immune response, revealing a `ping-pong' synergy where VV-infected cells produce B18R protein that neutralizes interferon-$α$, thereby enhancing VSV replication within the tumor. Numerical simulations demonstrate that this combination achieves complete tumor clearance in approximately 50 days, representing an 11\\% acceleration compared to VV monotherapy (56 days), while VSV alone fails to eradicate tumors. Through bifurcation analysis, we identify critical thresholds for viral burst size and B18R inhibition, while sensitivity analysis highlights infection rates and burst sizes as the most influential parameters for treatment efficacy. Temporal optimization reveals that therapeutic outcomes are maximized through immediate VSV administration followed by delayed VV injection within a 1-19 day window, offering a strategic approach to overcome the timing and dosing challenges inherent in OVT."
  },
  {
    "date": "2026-01-15",
    "title": "A Collection of Pinsker-type Inequalities for Quantum Divergences",
    "authors": "Kläre Wienecke, Gereon Koßmann, René Schwonnek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10395v1",
    "source": "arXiv",
    "abstract": "Pinsker's inequality sets a lower bound on the Umegaki divergence of two quantum states in terms of their trace distance. In this work, we formulate corresponding estimates for a variety of quantum and classical divergences including $f$-divergences like Hellinger and $χ^2$-divergences as well as Rényi divergences and special cases thereof like the Umegaki divergence, collision divergence, max divergence. We further provide a strategy on how to adapt these bounds to smoothed divergences."
  },
  {
    "date": "2026-01-15",
    "title": "Codebook Design for Limited Feedback in Near-Field XL-MIMO Systems",
    "authors": "Liujia Yao, Changsheng You, Zixuan Huang, Chao Zhou, Zhaohui Yang, Xiaoyang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10391v1",
    "source": "arXiv",
    "abstract": "In this paper, we study efficient codebook design for limited feedback in extremely large-scale multiple-input-multiple-output (XL-MIMO) frequency division duplexing (FDD) systems. It is worth noting that existing codebook designs for XL-MIMO, such as polar-domain codebook, have not well taken into account user (location) distribution in practice, thereby incurring excessive feedback overhead. To address this issue, we propose in this paper a novel and efficient feedback codebook tailored to user distribution. To this end, we first consider a typical scenario where users are uniformly distributed within a specific polar-region, based on which a sum-rate maximization problem is formulated to jointly optimize angle-range samples and bit allocation among angle/range feedback. This problem is challenging to solve due to the lack of a closed-form expression for the received power in terms of angle and range samples. By leveraging a Voronoi partitioning approach, we show that uniform angle sampling is optimal for received power maximization. For more challenging range sampling design, we obtain a tight lower-bound on the received power and show that geometric sampling, where the ratio between adjacent samples is constant, can maximize the lower bound and thus serves as a high-quality suboptimal solution. We then extend the proposed framework to accommodate more general non-uniform user distribution via an alternating sampling method. Furthermore, theoretical analysis reveals that as the array size increases, the optimal allocation of feedback bits increasingly favors range samples at the expense of angle samples. Finally, numerical results validate the superior rate performance and robustness of the proposed codebook design under various system setups, achieving significant gains over benchmark schemes, including the widely used polar-domain codebook."
  },
  {
    "date": "2026-01-15",
    "title": "The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models",
    "authors": "Christina Lu, Jack Gallagher, Jonathan Michala, Kyle Fish, Jack Lindsey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10387v1",
    "source": "arXiv",
    "abstract": "Large language models can represent a variety of personas but typically default to a helpful Assistant identity cultivated during post-training. We investigate the structure of the space of model personas by extracting activation directions corresponding to diverse character archetypes. Across several different models, we find that the leading component of this persona space is an \"Assistant Axis,\" which captures the extent to which a model is operating in its default Assistant mode. Steering towards the Assistant direction reinforces helpful and harmless behavior; steering away increases the model's tendency to identify as other entities. Moreover, steering away with more extreme values often induces a mystical, theatrical speaking style. We find this axis is also present in pre-trained models, where it primarily promotes helpful human archetypes like consultants and coaches and inhibits spiritual ones. Measuring deviations along the Assistant Axis predicts \"persona drift,\" a phenomenon where models slip into exhibiting harmful or bizarre behaviors that are uncharacteristic of their typical persona. We find that persona drift is often driven by conversations demanding meta-reflection on the model's processes or featuring emotionally vulnerable users. We show that restricting activations to a fixed region along the Assistant Axis can stabilize model behavior in these scenarios -- and also in the face of adversarial persona-based jailbreaks. Our results suggest that post-training steers models toward a particular region of persona space but only loosely tethers them to it, motivating work on training and steering strategies that more deeply anchor models to a coherent persona."
  },
  {
    "date": "2026-01-15",
    "title": "Experimental Realization of Rabi-Driven Reset for Fast Cooling of a High-Q Cavity",
    "authors": "Eliya Blumenthal, Natan Karaev, Shay Hacohen-Gourgy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10385v1",
    "source": "arXiv",
    "abstract": "High-Q bosonic memories are central to hardware-efficient quantum error correction, but their isolation makes fast, high-fidelity reset a persistent bottleneck. Existing approaches either rely on weak intermode cross-Kerr conversion or on measurement-based sequences with substantial latency. Here we demonstrate a hardware-efficient Rabi-Driven Reset (RDR) that implements continuous, measurement-free cooling of a superconducting cavity mode. A strong resonant Rabi drive on a transmon, together with sideband drives on the memory and readout modes detuned by the Rabi frequency, converts the dispersive interaction into an effective Jaynes-Cummings coupling between the qubit dressed states and each mode. This realizes a tunable dissipation channel from the memory to the cold readout bath. Crucially, the engineered coupling scales with the qubit-mode dispersive interaction and the drive amplitude, rather than with the intermode cross-Kerr, enabling fast cooling even in very weakly coupled architectures that deliberately suppress direct mode-mode coupling. We demonstrate RDR of a single photon with a decay time of $1.2 μs$, more than two orders of magnitude faster than the intrinsic lifetime. Furthermore, we reset about 30 thermal photons in about $80 μs$ to a steady-state average photon number of $\\bar{n} = 0.045 \\pm 0.025$."
  },
  {
    "date": "2026-01-15",
    "title": "A Hybrid Reliability--Weight Framework for Construction of Polar Codes",
    "authors": "Mohammad Rowshan, Vlad-Florin Dragoi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10376v1",
    "source": "arXiv",
    "abstract": "Polar codes are usually constructed by ranking synthetic bit-channels according to reliability, which guarantees capacity-achieving behavior but can yield poor low-weight spectra at short and moderate lengths. Recent algebraic results express the contribution of individual bit-channels to the multiplicities of minimum and near-minimum weight codewords in closed form. In this work we combine these insights into a mixed (reliability--weight) bit-channel ordering. We define a per-bit cost whose distance term is derived from orbit enumeration of minimum-weight codewords and scaled by a Bhattacharyya-type factor, and show that the resulting mixed construction minimises a truncated SC/ML union-bound surrogate within a class of decreasing monomial codes. We relate the mixed metric to error events in SCL decoding via a pruning/ML decomposition, and prove that mixed designs act as local perturbations of reliability-based constructions whose asymptotic impact vanishes as code-length approaches infinity. Numerical results for short and moderate lengths on BPSK-AWGN, implemented via Gaussian approximation and closed-form weight contributions, illustrate the trade-off between pure reliability-based and mixed constructions in terms of minimum distance, multiplicity, and union-bound approximations. All proofs are deferred to the appendices."
  },
  {
    "date": "2026-01-15",
    "title": "Two-Loop DGLAP Splitting Functions from Light Cone Perturbation Theory",
    "authors": "Tuomas Lappi, Risto Paatelainen, Mikko Seppälä",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10374v1",
    "source": "arXiv",
    "abstract": "We perform a two-loop calculation in Light Cone Perturbation Theory (LCPT) to evaluate the next-to-leading order nonsinglet splitting function. Our calculation demonstrates the methodology and feasibility of performing higher order calculations in LCPT. Since in Hamiltonian perturbation theory the longitudinal $k^+$ momentum is always positive, poles in $1/k^+$ can be regularized by a simple cutoff which cancels in physical results, without any associated ambiguities. For transverse momentum integrals we use dimensional regularization. Developing methods for loop calculations in LCPT paves the way for a systematical, automatizable procedure for precision calculations in this framework with a transparent physical partonic interpretation. This can provide a standard framework in higher order calculations in the gluon saturation regime of QCD."
  },
  {
    "date": "2026-01-15",
    "title": "The Direct-Product Decomposition Approach for Symmetry Exploitation in Many-Body Methods in Case of Non-Abelian Point Groups",
    "authors": "Malte Hellmann, Jürgen Gauss",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10371v1",
    "source": "arXiv",
    "abstract": "We demonstrate for the specific case of $C_{3v}$ how the direct-product decomposition scheme for the treatment of symmetry in coupled-cluster (CC) calculations can be extended to non-Abelian point groups. We show that for the two-electron integrals and CC amplitudes a block structure can be obtained by resolving the reducible products of two irreducible representations into their irreducible representations. To deal with the necessary resorts of the ordering of the two-electron integrals and amplitudes, spin-adaptation, and the O(M$^5$) contractions (with M as the number of basis functions) of a CC calculation, we suggest a strategy that uses both the reduced and non-reduced representation of the corresponding quantities and switches back and forth between them. While the reduced representations are the ones used in the O(M$^6$) contractions, the other steps are better carried out in the non-reduced representation. Our pilot implementation of the CC singles and doubles method confirms in test calculations for NH$_3$ and PH$_3$ using different basis sets that significant savings (of more than 20 compared to treatments without symmetry and about 5 compared to treatments using $C_s$ symmetry) are possible and suggest that the exploitation of non-Abelian symmetry would render CC computations on large highly symmetric molecules possible"
  },
  {
    "date": "2026-01-15",
    "title": "Generalized Weight Structure of Polar Codes: Selected Template Polynomials",
    "authors": "Mohammad Rowshan, Vlad-Florin Dragoi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10362v1",
    "source": "arXiv",
    "abstract": "Polar codes can be viewed as decreasing monomial codes, revealing a rich algebraic structure governed by the lower-triangular affine (LTA) group. We develop a general framework to compute the Hamming weight of codewords generated by sums of monomials, express these weights in a canonical dyadic form, and derive closed expressions for key structural templates (disjoint sums, nested blocks, complementary flips) that generate the low and intermediate weight spectrum. Combining these templates with the LTA group action, we obtain explicit multiplicity formulas, yielding a unified algebraic method to characterize and enumerate codewords."
  },
  {
    "date": "2026-01-15",
    "title": "EvoMorph: Counterfactual Explanations for Continuous Time-Series Extrinsic Regression Applied to Photoplethysmography",
    "authors": "Mesut Ceylan, Alexis Tabin, Patrick Langer, Elgar Fleisch, Filipe Barata",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10356v1",
    "source": "arXiv",
    "abstract": "Wearable devices enable continuous, population-scale monitoring of physiological signals, such as photoplethysmography (PPG), creating new opportunities for data-driven clinical assessment. Time-series extrinsic regression (TSER) models increasingly leverage PPG signals to estimate clinically relevant outcomes, including heart rate, respiratory rate, and oxygen saturation. For clinical reasoning and trust, however, single point estimates alone are insufficient: clinicians must also understand whether predictions are stable under physiologically plausible variations and to what extent realistic, attainable changes in physiological signals would meaningfully alter a model's prediction. Counterfactual explanations (CFE) address these \"what-if\" questions, yet existing time series CFE generation methods are largely restricted to classification, overlook waveform morphology, and often produce physiologically implausible signals, limiting their applicability to continuous biomedical time series. To address these limitations, we introduce EvoMorph, a multi-objective evolutionary framework for generating physiologically plausible and diverse CFE for TSER applications. EvoMorph optimizes morphology-aware objectives defined on interpretable signal descriptors and applies transformations to preserve the waveform structure. We evaluated EvoMorph on three PPG datasets (heart rate, respiratory rate, and oxygen saturation) against a nearest-unlike-neighbor baseline. In addition, in a case study, we evaluated EvoMorph as a tool for uncertainty quantification by relating counterfactual sensitivity to bootstrap-ensemble uncertainty and data-density measures. Overall, EvoMorph enables the generation of physiologically-aware counterfactuals for continuous biomedical signals and supports uncertainty-aware interpretability, advancing trustworthy model analysis for clinical time-series applications."
  },
  {
    "date": "2026-01-15",
    "title": "Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text",
    "authors": "Zhihao Xu, Rumei Li, Jiahuan Li, Rongxiang Weng, Jingang Wang, Xunliang Cai, Xiting Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10355v1",
    "source": "arXiv",
    "abstract": "Enabling Large Language Models (LLMs) to effectively utilize tools in multi-turn interactions is essential for building capable autonomous agents. However, acquiring diverse and realistic multi-turn tool-use data remains a significant challenge. In this work, we propose a novel text-based paradigm. We observe that textual corpora naturally contain rich, multi-step problem-solving experiences, which can serve as an untapped, scalable, and authentic data source for multi-turn tool-use tasks. Based on this insight, we introduce GEM, a data synthesis pipeline that enables the generation and extraction of multi-turn tool-use trajectories from text corpora through a four-stage process: relevance filtering, workflow & tool extraction, trajectory grounding, and complexity refinement. To reduce the computational cost, we further train a specialized Trajectory Synthesizer via supervised fine-tuning. This model distills the complex generation pipeline into an efficient, end-to-end trajectory generator. Experiments demonstrate that our GEM-32B achieve a 16.5% improvement on the BFCL V3 Multi-turn benchmark. Our models partially surpass the performance of models trained on τ - bench (Airline and Retail) in-domain data, highlighting the superior generalization capability derived from our text-based synthesis paradigm. Notably, our Trajectory Synthesizer matches the quality of the full pipeline while significantly reducing inference latency and costs."
  },
  {
    "date": "2026-01-15",
    "title": "A New Construction Structure on MISO Coded Caching with Linear Subpacketization: Half-Sum Disjoint Packing",
    "authors": "Bowen Zheng, Minquan Cheng, Kai Wan, Giuseppe Caire",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10353v1",
    "source": "arXiv",
    "abstract": "In the $(L,K,M,N)$ cache-aided multiple-input single-output (MISO) broadcast channel (BC) system, the server is equipped with $L$ antennas and communicates with $K$ single-antenna users through a wireless broadcast channel where the server has a library containing $N$ files, and each user is equipped with a cache of size $M$ files. Under the constraints of uncoded placement and one-shot linear delivery strategies, many schemes achieve the maximum sum Degree-of-Freedom (sum-DoF). However, for general parameters $L$, $M$, and $N$, their subpacketizations increase exponentially with the number of users. We aim to design a MISO coded caching scheme that achieves a large sum-DoF with low subpacketization $F$. An interesting combinatorial structure, called the multiple-antenna placement delivery array (MAPDA), can be used to generate MISO coded caching schemes under these two strategies; moreover, all existing schemes with these strategies can be represented by the corresponding MAPDAs. In this paper, we study the case with $F=K$ (i.e., $F$ grows linearly with $K$) by investigating MAPDAs. Specifically, based on the framework of Latin squares, we transform the design of MAPDA with $F=K$ into the construction of a combinatorial structure called the $L$-half-sum disjoint packing (HSDP). It is worth noting that a $1$-HSDP is exactly the concept of NHSDP, which is used to generate the shared-link coded caching scheme with $F=K$. By constructing $L$-HSDPs, we obtain a class of new schemes with $F=K$. Finally, theoretical and numerical analyses show that our $L$-HSDP schemes significantly reduce subpacketization compared to existing schemes with exponential subpacketization, while only slightly sacrificing sum-DoF, and achieve both a higher sum-DoF and lower subpacketization than the existing schemes with linear subpacketization."
  },
  {
    "date": "2026-01-15",
    "title": "Characteristic free Galois rings and generalized Weyl algebras",
    "authors": "Joao Schwarz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10346v1",
    "source": "arXiv",
    "abstract": "This paper develops from scratch a theory of Galois rings and orders over arbitrary fields. Our approach is different from others in the literature in that there is no non-modularity assumption. We prove, when the field is algebraically closed, the analogue of the Main Theorem of the representation theory of Galois orders by V. Futorny and S. Ovsienko. Then we develop a theory of infinite rank generalized Weyl algebras, which was never explicitly introduced in the literature before, and prove its basic properties. We expect their representation theory to be of interest for future works. Finally we show that under very mild assumptions, the invariants of generalized Weyl algebras under the action of non-exceptional irreducible complex reflection groups are a principal Galois orders, greatly generalizing, in an elementary fashion, results obtained previously for the Weyl algebras."
  },
  {
    "date": "2026-01-15",
    "title": "Convertible Codes for Data and Device Heterogeneity",
    "authors": "Anina Gruica, Benjamin Jany, Stanislav Kruglik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10341v1",
    "source": "arXiv",
    "abstract": "Distributed storage systems must handle both data heterogeneity, arising from non-uniform access demands, and device heterogeneity, caused by time-varying node reliability. In this paper, we study convertible codes, which enable the transformation of one code into another with minimum cost in the merge regime, addressing the latter. We derive general lower bounds on the read and write costs of linear code conversion, applicable to arbitrary linear codes. We then focus on Reed-Muller codes, which efficiently handle data heterogeneity, addressing the former issue, and construct explicit conversion procedures that, for the first time, combine both forms of heterogeneity for distributed data storage."
  },
  {
    "date": "2026-01-15",
    "title": "Distinguishing Quantum Matter by Gravity with Differential Scattering Cross Section at Tree Level",
    "authors": "Xue-Nan Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10339v1",
    "source": "arXiv",
    "abstract": "The definition of weak equivalence principle of quantum matter is an open problem at present. In order to reflect the probability of quantum system in the quantum version of weak equivalence principle, we proposed a quantum weak equivalence principle based on differential scattering cross section at tree level, that is, the differential scattering cross section does not depend on the mass and properties of the scattered particles when the target particles take the large mass limit. This version of the quantum equivalence principle we proposed will be broken by the spin properties of quantum matter. In the non-relativistic case, the difference of differential scattering cross sections of scattered particles with different spin properties scattered by target particles is mainly reflected in the order of $ \\mathcal O (p _ {\\mathrm{cm}} ^2) $. In the relativistic case , we studied the asymptotic behavior of differential scattering cross sections at small angles. When the target particles are scalar particles, the difference of light particles with different spin properties is mainly reflected in the $ \\mathcal O (1/θ^2) $ order. When the target particles are Dirac particles, the difference of light particles with different spin properties is mainly reflected in the $ \\mathcal O (1/θ^4) $ order. The polarization of differential scattering cross section when scattered particles are Dirac particles is investigated. The result of the degree of polarization depends on the polarization direction of the incident particles."
  },
  {
    "date": "2026-01-15",
    "title": "Polymultiplicative maps associated with the algebra of Iterated Laurent series and the higher-dimensional Contou-Carrere Symbol",
    "authors": "Levashev Vladislav",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10335v1",
    "source": "arXiv",
    "abstract": "We study functorial polymultiplicative maps from the multiplicative group of the algebra of $n$-times iterated Laurent series over a commutative ring in $n+1$ variables into the multiplicative group of the ring. It is proven that if such a map is invariant under continuous automorphisms of this algebra, then it coincides, up to a sign, with an integer power of the $n$-dimensional Contou-Carrère symbol."
  },
  {
    "date": "2026-01-15",
    "title": "Think-Then-Generate: Reasoning-Aware Text-to-Image Diffusion with LLM Encoders",
    "authors": "Siqi Kou, Jiachun Jin, Zetong Zhou, Ye Ma, Yugang Wang, Quan Chen, Peng Jiang, Xiao Yang, Jun Zhu, Kai Yu, Zhijie Deng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10332v1",
    "source": "arXiv",
    "abstract": "Recent progress in text-to-image (T2I) diffusion models (DMs) has enabled high-quality visual synthesis from diverse textual prompts. Yet, most existing T2I DMs, even those equipped with large language model (LLM)-based text encoders, remain text-pixel mappers -- they employ LLMs merely as text encoders, without leveraging their inherent reasoning capabilities to infer what should be visually depicted given the textual prompt. To move beyond such literal generation, we propose the think-then-generate (T2G) paradigm, where the LLM-based text encoder is encouraged to reason about and rewrite raw user prompts; the states of the rewritten prompts then serve as diffusion conditioning. To achieve this, we first activate the think-then-rewrite pattern of the LLM encoder with a lightweight supervised fine-tuning process. Subsequently, the LLM encoder and diffusion backbone are co-optimized to ensure faithful reasoning about the context and accurate rendering of the semantics via Dual-GRPO. In particular, the text encoder is reinforced using image-grounded rewards to infer and recall world knowledge, while the diffusion backbone is pushed to produce semantically consistent and visually coherent images. Experiments show substantial improvements in factual consistency, semantic alignment, and visual realism across reasoning-based image generation and editing benchmarks, achieving 0.79 on WISE score, nearly on par with GPT-4. Our results constitute a promising step toward next-generation unified models with reasoning, expression, and demonstration capacities."
  },
  {
    "date": "2026-01-15",
    "title": "Neural-network-based high-speed and high-definition full-field dynamic optical coherence tomography",
    "authors": "Suzuyo Komeda, Nobuhisa Tateno, Yusong Liu, Rion Morishita, Xibo Wang, Ibrahim Abd El-Sadek, Atsuko Furukawa, Satoshi Matsusaka, Shuichi Makita, Yoshiaki Yasuno",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10327v1",
    "source": "arXiv",
    "abstract": "A neural-network (NN)-based method for high-speed, high-definition dynamic optical coherence tomography (DOCT) using full-field swept-source optical coherence microscopy (FF-SS-OCM) is demonstrated. FF-SS-OCM provides high-definition OCT images, but, particularly in DOCT imaging, it results in a significant enlargement of the data size and subsequently long data streaming and processing time, which prevents high-throughput imaging. We address this issue by introducing an NN-based DOCT method that generates high-definition logarithmic intensity variance (LIV) -based DOCT images from only four OCT volumes, whereas the conventional method required 32 volumes. The NN model successfully generates an LIV image that is qualitatively and quantitatively similar to the LIV image computed from 32 volumes. This approach significantly reduces data size, transfer time, and processing time for DOCT imaging by a factor of eight. Specifically, these were reduced from 42 GB to 5.3 GB, 7 min to 55 s, and 4 hours to 30 min, respectively."
  },
  {
    "date": "2026-01-15",
    "title": "Principles of Optics in the Fock Space: Scalable Manipulation of Giant Quantum States",
    "authors": "Yifang Xu, Yilong Zhou, Ziyue Hua, Lida Sun, Jie Zhou, Weiting Wang, Weizhou Cai, Hongwei Huang, Lintao Xiao, Guangming Xue, Haifeng Yu, Ming Li, Chang-Ling Zou, Luyan Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10325v1",
    "source": "arXiv",
    "abstract": "The manipulation of distinct degrees of freedom of photons plays a critical role in both classical and quantum information processing. While the principles of wave optics provide elegant and scalable control over classical light in spatial and temporal domains, engineering quantum states in Fock space has been largely restricted to few-photon regimes, hindered by the computational and experimental challenges of large Hilbert spaces. Here, we introduce ``Fock-space optics\", establishing a conceptual framework of wave propagation in the quantum domain by treating photon number as a synthetic dimension. Using a superconducting microwave resonator, we experimentally demonstrate Fock-space analogues of optical propagation, refraction, lensing, dispersion, and interference with up to 180 photons. These results establish a fundamental correspondence between Schrödinger evolution in a single bosonic mode and classical paraxial wave propagation. By mapping intuitive optical concepts onto high-dimensional quantum state engineering, our work opens a path toward scalable control of large-scale quantum systems with thousands of photons and advanced bosonic information processing."
  },
  {
    "date": "2026-01-15",
    "title": "Multimessenger Prospects for Low-Luminosity Gamma-Ray Bursts: Joint Neutrino and X-Ray Observations",
    "authors": "Wenkang Lian, He Gao, Shunke Ai, B. Theodore Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10317v1",
    "source": "arXiv",
    "abstract": "Low--luminosity gamma-ray bursts (LLGRBs) are promising candidates for high-energy neutrinos, yet no coincident neutrino events have been detected so far. Recent advances in X-ray time-domain astronomy, together with the development of next-generation neutrino telescopes, open new opportunities for joint X-ray and neutrino observations of these transients. We calculate the jet dynamical evolution and the associated neutrino production for both non-magnetized and magnetized outflows. For individual events, joint X-ray and neutrino detection is generally limited to nearby LLGRBs or sources with high luminosities. Thus, we consider a next-generation neutrino telescope with an effective area enhanced by a factor of $\\sim30$ relative to IceCube. In the non-magnetized scenario, joint detection of individual events is enabled for sources with typical isotropic luminosities of $L_{\\mathrm{iso}}\\sim10^{47}\\,\\mathrm{erg\\,s^{-1}}$ out to luminosity distances of $D_L\\sim1.6\\times10^{2}\\,\\mathrm{Mpc}$, corresponding to an expected detection rate of order $1$ per year. In contrast, for the magnetized scenario at the same luminosity, the accessible distance is significantly reduced, with joint observations confined to sources within $D_L\\sim6.5\\times10^{1}\\,\\mathrm{Mpc}$ and an expected detection rate of order $0.5$ per year. For stacked samples of $\\sim100$ magnetized LLGRBs, stacking substantially enlarges the accessible distance range, enabling joint observations for sources with representative luminosities of $L_{\\mathrm{iso}}\\sim1\\times10^{47}\\,\\mathrm{erg\\,s^{-1}}$ out to $D_L\\lesssim7.0\\times10^{2}\\,\\mathrm{Mpc}$ and corresponding to an expected detection rate of order $2$ per year. These results demonstrate that joint X-ray and next-generation neutrino observations enable a practical multimessenger probe of LLGRBs."
  },
  {
    "date": "2026-01-15",
    "title": "We Need a More Robust Classifier: Dual Causal Learning Empowers Domain-Incremental Time Series Classification",
    "authors": "Zhipeng Liu, Peibo Duan, Xuan Tang, Haodong Jing, Mingyang Geng, Yongsheng Huang, Jialu Xu, Bin Zhang, Binwu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10312v1",
    "source": "arXiv",
    "abstract": "The World Wide Web thrives on intelligent services that rely on accurate time series classification, which has recently witnessed significant progress driven by advances in deep learning. However, existing studies face challenges in domain incremental learning. In this paper, we propose a lightweight and robust dual-causal disentanglement framework (DualCD) to enhance the robustness of models under domain incremental scenarios, which can be seamlessly integrated into time series classification models. Specifically, DualCD first introduces a temporal feature disentanglement module to capture class-causal features and spurious features. The causal features can offer sufficient predictive power to support the classifier in domain incremental learning settings. To accurately capture these causal features, we further design a dual-causal intervention mechanism to eliminate the influence of both intra-class and inter-class confounding features. This mechanism constructs variant samples by combining the current class's causal features with intra-class spurious features and with causal features from other classes. The causal intervention loss encourages the model to accurately predict the labels of these variant samples based solely on the causal features. Extensive experiments on multiple datasets and models demonstrate that DualCD effectively improves performance in domain incremental scenarios. We summarize our rich experiments into a comprehensive benchmark to facilitate research in domain incremental time series classification."
  },
  {
    "date": "2026-01-15",
    "title": "Kummer-faithful fields with finitely generated absolute Galois group",
    "authors": "Takuya Asayama",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10298v1",
    "source": "arXiv",
    "abstract": "This paper studies the structure of the Mordell--Weil groups of semiabelian varieties over algebraic extensions of number fields whose absolute Galois group is finitely generated, with particular emphasis on that generated by a single element. A probabilistic argument using the Haar measure on the absolute Galois group of a number field shows that almost all such fields are Kummer-faithful, i.e., the Mordell--Weil group of any semiabelian variety over any finite extension of such a field has trivial divisible part. This result implies that there exists a Kummer-faithful field algebraic over a number field whose absolute Galois group is abelian."
  },
  {
    "date": "2026-01-15",
    "title": "SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks",
    "authors": "Jose Marie Antonio Minoza",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10282v1",
    "source": "arXiv",
    "abstract": "Physics-Informed Neural Networks (PINNs) provide a mesh-free approach for solving differential equations by embedding physical constraints into neural network training. However, PINNs tend to overfit within the training domain, leading to poor generalization when extrapolating beyond trained spatiotemporal regions. This work presents SPIKE (Sparse Physics-Informed Koopman-Enhanced), a framework that regularizes PINNs with continuous-time Koopman operators to learn parsimonious dynamics representations. By enforcing linear dynamics $dz/dt = Az$ in a learned observable space, both PIKE (without explicit sparsity) and SPIKE (with L1 regularization on $A$) learn sparse generator matrices, embodying the parsimony principle that complex dynamics admit low-dimensional structure. Experiments across parabolic, hyperbolic, dispersive, and stiff PDEs, including fluid dynamics (Navier-Stokes) and chaotic ODEs (Lorenz), demonstrate consistent improvements in temporal extrapolation, spatial generalization, and long-term prediction accuracy. The continuous-time formulation with matrix exponential integration provides unconditional stability for stiff systems while avoiding diagonal dominance issues inherent in discrete-time Koopman operators."
  },
  {
    "date": "2026-01-15",
    "title": "Optimal control of a dissipative micromaser quantum battery in the ultrastrong coupling regime",
    "authors": "Maristella Crotti, Luca Razzoli, Luigi Giannelli, Giuseppe A. Falci, Giuliano Benenti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10281v1",
    "source": "arXiv",
    "abstract": "We investigate the open system dynamics of a micromaser quantum battery operating in the ultrastrong coupling (USC) regime under environmental dissipation. The battery consists of a single-mode electromagnetic cavity sequentially interacting, via the Rabi Hamiltonian, with a stream of qubits acting as chargers. Dissipative effects arise from the weak coupling of the qubit-cavity system to a thermal bath. Non-negligible in the USC regime, the counter-rotating terms substantially improve the charging speed, but also lead, in the absence of dissipation, to unbounded energy growth and highly mixed cavity states. Dissipation during each qubit-cavity interaction mitigates these detrimental effects, yielding steady-state of finite energy and ergotropy. Optimal control on qubit preparation and interaction times enhances battery's performance in: (i) Maximizing the stored ergotropy trhough an optimized charging protocol; (ii) Stabilizing the stored ergotropy against dissipative losses through an optimized measurement-based passive-feedback strategy. Overall, our numerical results demonstrate that the interplay of ultrastrong light-matter coupling, controlled dissipation, and optimized control strategies enables micromaser quantum batteries to achieve both enhanced charging performance and long-term stability under realistic conditions."
  },
  {
    "date": "2026-01-15",
    "title": "The impact of tactile sensor configurations on grasp learning efficiency -- a comparative evaluation in simulation",
    "authors": "Eszter Birtalan, Miklós Koller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10268v1",
    "source": "arXiv",
    "abstract": "Tactile sensors are breaking into the field of robotics to provide direct information related to contact surfaces, including contact events, slip events and even texture identification. These events are especially important for robotic hand designs, including prosthetics, as they can greatly improve grasp stability. Most presently published robotic hand designs, however, implement them in vastly different densities and layouts on the hand surface, often reserving the majority of the available space. We used simulations to evaluate 6 different tactile sensor configurations with different densities and layouts, based on their impact on reinforcement learning. Our two-setup system allows for robust results that are not dependent on the use of a given physics simulator, robotic hand model or machine learning algorithm. Our results show setup-specific, as well as generalized effects across the 6 sensorized simulations, and we identify one configuration as consistently yielding the best performance across both setups. These results could help future research aimed at robotic hand designs, including prostheses."
  },
  {
    "date": "2026-01-15",
    "title": "Asymptotic Theory of Tail Dependence Measures for Checkerboard Copula and the Validity of Multiplier Bootstrap",
    "authors": "Mayukh Choudhury, Debraj Das, Sujit Ghosh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10252v1",
    "source": "arXiv",
    "abstract": "Nonparametric estimation and inference for lower and upper tail copulas under unknown marginal distributions are considered. To mitigate the inherent discreteness and boundary irregularities of the empirical tail copula, a checkerboard smoothed tail copula estimator based on local bilinear interpolation is introduced. Almost sure uniform consistency and weak convergence of the centered and scaled empirical checkerboard tail copula process are established in the space of bounded functions. The resulting Gaussian limit differs from its known-marginal counterpart and incorporates additional correction terms that account for first-order stochastic errors arising from marginal estimation. Since the limiting covariance structure depends on the unknown tail copula and its partial derivatives, direct asymptotic inference is generally infeasible. To address this challenge, a direct multiplier bootstrap procedure tailored to the checkerboard tail copula is developed. By combining multiplier reweighting with checkerboard smoothing, the bootstrap preserves the extremal dependence structure of the data and consistently captures both joint tail variability and the effects of marginal estimation. Conditional weak convergence of the bootstrap process to the same Gaussian limit as the original estimator is established, yielding asymptotically valid inference for smooth functionals of the tail copula, including the lower and upper tail dependence coefficient. The proposed approach provides a fully feasible framework for confidence regions and hypothesis testing in tail dependence analysis without requiring explicit estimation of the limiting covariance structure. A simulation study illustrates the finite-sample performance of the proposed estimator and demonstrates the accuracy and reliability of the bootstrap confidence intervals under various dependence structures and tuning parameter choices."
  },
  {
    "date": "2026-01-15",
    "title": "Model order reduction of piecewise linear mechanical systems using invariant cones",
    "authors": "A. Yassine Karoui, Remco I. Leine",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10241v1",
    "source": "arXiv",
    "abstract": "We present a methodology that extends invariant manifold theory to a class of autonomous piecewise linear systems with nonsmoothness at the equilibrium, providing a framework for model order reduction in mechanical structures with compliant contact laws. The key idea is to make the absence of a local linearization around the equilibrium tractable by leveraging the positive homogeneity property. This property simplifies the invariance equations defining the geometry of the invariant cones, from a set of partial differential equations to a system of ordinary differential equations, enabling their effective solution. We introduce two techniques to compute these invariant cones. First, an intuitive graph-style parametrization is proposed that utilizes Fourier expansions and Chebyshev polynomials to derive explicit reduced-order models in closed form. Second, an arc-length parametrization is introduced to robustly compute invariant cones with complex folding geometries, which are intractable with a standard graph-style technique. The approach is demonstrated on mechanical oscillators with unilateral visco-elastic supports, showcasing its applicability for systems with both continuous (unilateral elastic) and discontinuous (unilateral visco-elastic) unilateral force laws."
  },
  {
    "date": "2026-01-15",
    "title": "Nuclear Toeplitz operators between Fock spaces",
    "authors": "Tengfei Ma, Yufeng Lu, Chao Zu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10217v1",
    "source": "arXiv",
    "abstract": "We study Toeplitz operators with measure-valued symbols acting between Fock spaces. Given $1\\le p,q\\le\\infty$ and a Borel measure $μ$ on $\\mathbb C$, we investigate when the associated Toeplitz operator \\[ T_μ: F^p_α\\to F^q_α\\] belongs to the nuclear class. For positive measures $μ$ and in the range $1\\le q\\le p\\le\\infty$, we obtain necessary and sufficient conditions for the nuclearity of $T_μ$ in terms of the Berezin transform of $μ$. As a consequence, nuclearity in this setting exhibits a rigidity property: if $T_μ$ is nuclear from $F^p_α$ to $F^q_α$ for some $q\\le p$, then it is nuclear for all such $q$. In the case $p<q$, we show that the situation is more delicate. We provide separate necessary and sufficient conditions for nuclearity, indicating that the Berezin transform alone does not yield a complete characterization. The proofs rely on tools from Banach space operator theory combined with kernel estimates on Fock spaces. Our results extend naturally to Fock spaces on $\\mathbb C^n$."
  },
  {
    "date": "2026-01-15",
    "title": "Beyond Inpainting: Unleash 3D Understanding for Precise Camera-Controlled Video Generation",
    "authors": "Dong-Yu Chen, Yixin Guo, Shuojin Yang, Tai-Jiang Mu, Shi-Min Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10214v1",
    "source": "arXiv",
    "abstract": "Camera control has been extensively studied in conditioned video generation; however, performing precisely altering the camera trajectories while faithfully preserving the video content remains a challenging task. The mainstream approach to achieving precise camera control is warping a 3D representation according to the target trajectory. However, such methods fail to fully leverage the 3D priors of video diffusion models (VDMs) and often fall into the Inpainting Trap, resulting in subject inconsistency and degraded generation quality. To address this problem, we propose DepthDirector, a video re-rendering framework with precise camera controllability. By leveraging the depth video from explicit 3D representation as camera-control guidance, our method can faithfully reproduce the dynamic scene of an input video under novel camera trajectories. Specifically, we design a View-Content Dual-Stream Condition mechanism that injects both the source video and the warped depth sequence rendered under the target viewpoint into the pretrained video generation model. This geometric guidance signal enables VDMs to comprehend camera movements and leverage their 3D understanding capabilities, thereby facilitating precise camera control and consistent content generation. Next, we introduce a lightweight LoRA-based video diffusion adapter to train our framework, fully preserving the knowledge priors of VDMs. Additionally, we construct a large-scale multi-camera synchronized dataset named MultiCam-WarpData using Unreal Engine 5, containing 8K videos across 1K dynamic scenes. Extensive experiments show that DepthDirector outperforms existing methods in both camera controllability and visual quality. Our code and dataset will be publicly available."
  },
  {
    "date": "2026-01-15",
    "title": "Coherence Limits in Interference-Based cos(2$\\varphi$) Qubits",
    "authors": "S. Messelot, A. Leblanc, J. -S. Tettekpoe, F. Lefloch, Q. Ficheux, J. Renard, É. Dumur",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10209v1",
    "source": "arXiv",
    "abstract": "We investigate the coherence properties of parity-protected $\\cos(2\\varphi)$ qubits based on interferences between two Josephson elements in a superconducting loop. We show that qubit implementations of a $\\cos(2\\varphi)$ potential using a single loop, such as those employing semiconducting junctions, rhombus circuits, flowermon and KITE structures, can be described by the same Hamiltonian as two multi-harmonic Josephson junctions in a SQUID geometry. We find that, despite the parity protection arising from the suppression of single Cooper pair tunneling, there exists a fundamental trade-off between charge and flux noise dephasing channels. Using numerical simulations, we examine how relaxation and dephasing rates depend on external flux and circuit parameters, and we identify the best compromise for maximum coherence. With currently existing circuit parameters, the qubit lifetime $T_1$ can exceed milliseconds while the dephasing time $T_\\varphi$ remains limited to only a few microseconds due to either flux or charge noise. Our findings establish practical limits on the coherence of this class of qubits and raise questions about the long-term potential of this approach."
  },
  {
    "date": "2026-01-15",
    "title": "BeamCKMDiff: Beam-Aware Channel Knowledge Map Construction via Diffusion Transformer",
    "authors": "Le Zhao, Yining Wang, Xinyi Wang, Zesong Fei, Yong Zeng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10207v1",
    "source": "arXiv",
    "abstract": "Channel knowledge map (CKM) is emerging as a critical enabler for environment-aware 6G networks, offering a site-specific database to significantly reduce pilot overhead. However, existing CKM construction methods typically rely on sparse sampling measurements and are restricted to either omnidirectional maps or discrete codebooks, hindering the exploitation of beamforming gain. To address these limitations, we propose BeamCKMDiff, a generative framework for constructing high-fidelity CKMs conditioned on arbitrary continuous beamforming vectors without site-specific sampling. Specifically, we incorporate a novel adaptive layer normalization (adaLN) mechanism into the noise prediction network of the Diffusion Transformer (DiT). This mechanism injects continuous beam embeddings as {global control parameters}, effectively steering the generative process to capture the complex coupling between beam patterns and environmental geometries. Simulation results demonstrate that BeamCKMDiff significantly outperforms state-of-the-art baselines, achieving superior reconstruction accuracy in capturing main lobes and side lobes."
  },
  {
    "date": "2026-01-15",
    "title": "Autonomous Quantum Simulation through Large Language Model Agents",
    "authors": "Weitang Li, Jiajun Ren, Lixue Cheng, Cunxi Gong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10194v1",
    "source": "arXiv",
    "abstract": "We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks. Tensor network methods are powerful tools for quantum simulation, but their effective use requires expertise typically acquired through years of graduate training. By combining in-context learning with curated documentation and multi-agent decomposition, we create autonomous AI agents that can be trained in specialized computational domains within minutes. We benchmark three configurations (baseline, single-agent with in-context learning, and multi-agent with in-context learning) on problems spanning quantum phase transitions, open quantum system dynamics, and photochemical reactions. Systematic evaluation using DeepSeek-V3.2, Gemini 2.5 Pro, and Claude Opus 4.5 demonstrates that both in-context learning and multi-agent architecture are essential. Analysis of failure modes reveals characteristic patterns across models, with the multi-agent configuration substantially reducing implementation errors and hallucinations compared to simpler architectures."
  },
  {
    "date": "2026-01-15",
    "title": "HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning",
    "authors": "Ziang Cui, Mengran Yu, Tianjiao Li, Chenyu Shi, Yingxuan Shi, Lusheng Zhang, Hongwei Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10187v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have achieved remarkable strides in multilingual translation but are hindered by a systemic cross-lingual verbosity bias, rendering them unsuitable for strict time-constrained tasks like subtitling and dubbing. Current prompt-engineering approaches struggle to resolve this conflict between semantic fidelity and rigid temporal feasibility. To bridge this gap, we first introduce Sand-Glass, a benchmark specifically designed to evaluate translation under syllable-level duration constraints. Furthermore, we propose HOMURA, a reinforcement learning framework that explicitly optimizes the trade-off between semantic preservation and temporal compliance. By employing a KL-regularized objective with a novel dynamic syllable-ratio reward, HOMURA effectively \"tames\" the output length. Experimental results demonstrate that our method significantly outperforms strong LLM baselines, achieving precise length control that respects linguistic density hierarchies without compromising semantic adequacy."
  },
  {
    "date": "2026-01-15",
    "title": "Effect of Number of Bilayers on the Anomalous Hall Effect in [Si/Fe]N Multilayers",
    "authors": "Sudhansu Sekhar Das, M. Senthil Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10182v1",
    "source": "arXiv",
    "abstract": "The influence of varying the number of bilayers (N) on the anomalous Hall effect (AHE) in sputtered Si/Fe multilayers has been investigated. Both the AHE and magnetisation data reveal the in-plane magnetic anisotropy in the samples. Large enhancement of about 24 times in the saturation anomalous Hall resistance (R_Ahs) and anomalous Hall sensitivity (S) has been observed upon decreasing N from 20 to 1. When compared with the bulk Fe, the values of R_Ahs and anomalous Hall coefficient, Rs obtained for N= 1 were enhanced by about 5 and 3 orders of magnitude, respectively. The Rs follows the longitudinal electrical resistivity Rho as Rs proportional to Rho^2.1, suggesting side jump as the dominant mechanism of the AHE. The S as high as 22 Ohm/T over a wide operational field range of -8 to +8 kOe has been obtained for N = 1."
  },
  {
    "date": "2026-01-15",
    "title": "Bias in the Shadows: Explore Shortcuts in Encrypted Network Traffic Classification",
    "authors": "Chuyi Wang, Xiaohui Xie, Tongze Wang, Yong Cui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10180v1",
    "source": "arXiv",
    "abstract": "Pre-trained models operating directly on raw bytes have achieved promising performance in encrypted network traffic classification (NTC), but often suffer from shortcut learning-relying on spurious correlations that fail to generalize to real-world data. Existing solutions heavily rely on model-specific interpretation techniques, which lack adaptability and generality across different model architectures and deployment scenarios. In this paper, we propose BiasSeeker, the first semi-automated framework that is both model-agnostic and data-driven for detecting dataset-specific shortcut features in encrypted traffic. By performing statistical correlation analysis directly on raw binary traffic, BiasSeeker identifies spurious or environment-entangled features that may compromise generalization, independent of any classifier. To address the diverse nature of shortcut features, we introduce a systematic categorization and apply category-specific validation strategies that reduce bias while preserving meaningful information. We evaluate BiasSeeker on 19 public datasets across three NTC tasks. By emphasizing context-aware feature selection and dataset-specific diagnosis, BiasSeeker offers a novel perspective for understanding and addressing shortcut learning in encrypted network traffic classification, raising awareness that feature selection should be an intentional and scenario-sensitive step prior to model training."
  },
  {
    "date": "2026-01-15",
    "title": "Distributed Linearly Separable Computation with Arbitrary Heterogeneous Data Assignment",
    "authors": "Ziting Zhang, Kai Wan, Minquan Cheng, Shuo Shao, Giuseppe Caire",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10177v1",
    "source": "arXiv",
    "abstract": "Distributed linearly separable computation is a fundamental problem in large-scale distributed systems, requiring the computation of linearly separable functions over different datasets across distributed workers. This paper studies a heterogeneous distributed linearly separable computation problem, including one master and N distributed workers. The linearly separable task function involves Kc linear combinations of K messages, where each message is a function of one dataset. Distinguished from the existing homogeneous settings that assume each worker holds the same number of datasets, where the data assignment is carefully designed and controlled by the data center (e.g., the cyclic assignment), we consider a more general setting with arbitrary heterogeneous data assignment across workers, where `arbitrary' means that the data assignment is given in advance and `heterogeneous' means that the workers may hold different numbers of datasets. Our objective is to characterize the fundamental tradeoff between the computable dimension of the task function and the communication cost under arbitrary heterogeneous data assignment. Under the constraint of integer communication costs, for arbitrary heterogeneous data assignment, we propose a universal computing scheme and a universal converse bound by characterizing the structure of data assignment, where they coincide under some parameter regimes. We then extend the proposed computing scheme and converse bound to the case of fractional communication costs."
  },
  {
    "date": "2026-01-15",
    "title": "A Low-Complexity Architecture for Multi-access Coded Caching Systems with Arbitrary User-cache Access Topology",
    "authors": "Ting Yang, Minquan Cheng, Xinping Yi, Robert Caiming Qiu, Giuseppe Caire",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10175v1",
    "source": "arXiv",
    "abstract": "This paper studies the multi-access coded caching (MACC) problem under arbitrary user-cache access topologies, extending existing models that rely on highly structured and combinatorially designed connectivity. We consider a MACC system consisting of a single server, multiple cache nodes, and multiple user nodes. Each user can access an arbitrary subset of cache nodes to retrieve cached content. The objective is to design a general and low-complexity delivery scheme under fixed cache placement for arbitrary access topologies. We propose a universal graph-based framework for modeling the MACC delivery problem, where decoding conflicts among requested packets are captured by a conflict graph and the delivery design is reduced to a graph coloring problem. In this formulation, a lower transmission load corresponds to using fewer colors. The classical greedy coloring algorithm DSatur achieves a transmission load close to the index-coding converse bound, providing a tight benchmark, but its computational complexity becomes prohibitive for large-scale graphs. To overcome this limitation, we develop a learning-based framework using graph neural networks that efficiently constructs near-optimal coded multicast transmissions and generalizes across diverse access topologies and varying numbers of users. In addition, we extend the index-coding converse bound for uncoded cache placement to arbitrary access topologies and propose a low-complexity greedy approximation. Numerical results demonstrate that the proposed learning-based scheme achieves transmission loads close to those of DSatur and the converse bound while significantly reducing computational time."
  },
  {
    "date": "2026-01-15",
    "title": "ReasAlign: Reasoning Enhanced Safety Alignment against Prompt Injection Attack",
    "authors": "Hao Li, Yankai Yang, G. Edward Suh, Ning Zhang, Chaowei Xiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10173v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have enabled the development of powerful agentic systems capable of automating complex workflows across various fields. However, these systems are highly vulnerable to indirect prompt injection attacks, where malicious instructions embedded in external data can hijack agent behavior. In this work, we present ReasAlign, a model-level solution to improve safety alignment against indirect prompt injection attacks. The core idea of ReasAlign is to incorporate structured reasoning steps to analyze user queries, detect conflicting instructions, and preserve the continuity of the user's intended tasks to defend against indirect injection attacks. To further ensure reasoning logic and accuracy, we introduce a test-time scaling mechanism with a preference-optimized judge model that scores reasoning steps and selects the best trajectory. Comprehensive evaluations across various benchmarks show that ReasAlign maintains utility comparable to an undefended model while consistently outperforming Meta SecAlign, the strongest prior guardrail. On the representative open-ended CyberSecEval2 benchmark, which includes multiple prompt-injected tasks, ReasAlign achieves 94.6% utility and only 3.6% ASR, far surpassing the state-of-the-art defensive model of Meta SecAlign (56.4% utility and 74.4% ASR). These results demonstrate that ReasAlign achieves the best trade-off between security and utility, establishing a robust and practical defense against prompt injection attacks in real-world agentic systems. Our code and experimental results could be found at https://github.com/leolee99/ReasAlign."
  },
  {
    "date": "2026-01-15",
    "title": "PACEvolve: Enabling Long-Horizon Progress-Aware Consistent Evolution",
    "authors": "Minghao Yan, Bo Peng, Benjamin Coleman, Ziqi Chen, Zhouhang Xie, Zhankui He, Noveen Sachdeva, Isabella Ye, Weili Wang, Chi Wang, Ed H. Chi, Wang-Cheng Kang, Derek Zhiyuan Cheng, Beidou Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10657v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have emerged as powerful operators for evolutionary search, yet the design of efficient search scaffolds remains ad hoc. While promising, current LLM-in-the-loop systems lack a systematic approach to managing the evolutionary process. We identify three distinct failure modes: Context Pollution, where experiment history biases future candidate generation; Mode Collapse, where agents stagnate in local minima due to poor exploration-exploitation balance; and Weak Collaboration, where rigid crossover strategies fail to leverage parallel search trajectories effectively. We introduce Progress-Aware Consistent Evolution (PACEvolve), a framework designed to robustly govern the agent's context and search dynamics, to address these challenges. PACEvolve combines hierarchical context management (HCM) with pruning to address context pollution; momentum-based backtracking (MBB) to escape local minima; and a self-adaptive sampling policy that unifies backtracking and crossover for dynamic search coordination (CE), allowing agents to balance internal refinement with cross-trajectory collaboration. We demonstrate that PACEvolve provides a systematic path to consistent, long-horizon self-improvement, achieving state-of-the-art results on LLM-SR and KernelBench, while discovering solutions surpassing the record on Modded NanoGPT."
  },
  {
    "date": "2026-01-15",
    "title": "Symmetry-based Perspectives on Hamiltonian Quantum Search Algorithms and Schrodinger's Dynamics between Orthogonal States",
    "authors": "Carlo Cafaro, James Schneeloch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10655v1",
    "source": "arXiv",
    "abstract": "It is known that the continuous-time variant of Grover's search algorithm is characterized by quantum search frameworks that are governed by stationary Hamiltonians, which result in search trajectories confined to the two-dimensional subspace of the complete Hilbert space formed by the source and target states. Specifically, the search approach is ineffective when the source and target states are orthogonal. In this paper, we employ normalization, orthogonality, and energy limitations to demonstrate that it is unfeasible to breach time-optimality between orthogonal states with constant Hamiltonians when the evolution is limited to the two-dimensional space spanned by the initial and final states. Deviations from time-optimality for unitary evolutions between orthogonal states can only occur with time-dependent Hamiltonian evolutions or, alternatively, with constant Hamiltonian evolutions in higher-dimensional subspaces of the entire Hilbert space. Ultimately, we employ our quantitative analysis to provide meaningful insights regarding the relationship between time-optimal evolutions and analog quantum search methods. We determine that the challenge of transitioning between orthogonal states with a constant Hamiltonian in a sub-optimal time is closely linked to the shortcomings of analog quantum search when the source and target states are orthogonal and not interconnected by the search Hamiltonian. In both scenarios, the fundamental cause of the failure lies in the existence of an inherent symmetry within the system."
  },
  {
    "date": "2026-01-15",
    "title": "A note on strong similarity and the Connes embedding problem",
    "authors": "Gilles Pisier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10654v1",
    "source": "arXiv",
    "abstract": "We show that there exists a completely bounded (c.b. in short) homomorphism $u$ from a $C^*$-algebra $C$ with the lifting property (in short LP) into a QWEP von Neumann algebra $N$ that is not strongly similar to a $*$-homomorphism, i.e. the similarities that ``orthogonalize\" $u$ (which exist since $u$ is c.b.) cannot belong to the von Neumann algebra $N$. Moreover, the map $u$ does not admit any c.b. lifting up into the WEP $C^*$-algebra of which $N$ is a quotient. We can take $C=C^*(G)$ (full $C^*$-algebra) where $G$ is any nonabelian free group and $N= B(H)\\bar \\otimes M$ where $M$ is the von Neumann algebra generated by the reduced $C^*$-algebra of $G$."
  },
  {
    "date": "2026-01-15",
    "title": "Quantifying the properties of evolutionary quantum states of the XXZ spin model using quantum computing",
    "authors": "M. P. Tonne, Kh. P. Gnatenko",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10650v1",
    "source": "arXiv",
    "abstract": "The entanglement distance of evolutionary quantum states of a two-spin system with the XXZ model has been studied. The analysis has been conducted both analytically and using quantum computing. An analytical dependence of the entanglement distance on the values of the model coupling constants and the parameters of the initial states has been obtained. The speed of evolution of a two-spin system has been investigated. The analysis has been performed analytically and using quantum computing. An explicit dependence of the speed of evolution on the coupling constants and on the parameters of the initial state has been obtained. The results of quantum computations are in good agreement with the theoretical predictions."
  },
  {
    "date": "2026-01-15",
    "title": "Medium-Induced Quarkonium Dissociation at Finite Chemical Potential and Weak Magnetic Field",
    "authors": "Indrani Nilima, Mujeeb Hasan, Mohammad Yousuf Jamal, Salman Ahamad Khan, B. K. Singh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10634v1",
    "source": "arXiv",
    "abstract": "We investigate the in-medium modification and dissociation of heavy quarkonium in a hot QCD medium at finite quark chemical potential and in the weak magnetic-field regime. Starting from the one-loop resummed gluon propagator in the imaginary-time formalism, and incorporating non-perturbative effects through a phenomenological correction to the HTL description, we compute the real and imaginary parts of the dielectric permittivity. This, in turn, leads to a complex heavy-quark potential: the real part is used to determine binding energies by solving the nonrelativistic Schrödinger equation, while the imaginary part generates thermal decay widths, dominated by Landau damping. Within the explored parameter range, temperature has the greatest control over Debye screening, potential modification, and quarkonium stability, whereas finite density and weak magnetic fields introduce comparatively smaller quantitative changes. As the temperature increases, binding energies decrease and thermal widths grow, giving rise to the expected hierarchy between ground and excited states and a sequential suppression pattern in the dissociation temperatures. Overall, our results indicate that while finite chemical potential and weak magnetic fields can shift quarkonium properties in a measurable way, thermal effects remain the primary driver of dissociation, with direct relevance for heavy-ion collision phenomenology."
  },
  {
    "date": "2026-01-15",
    "title": "VoiceSculptor: Your Voice, Designed By You",
    "authors": "Jingbin Hu, Huakang Chen, Linhan Ma, Dake Guo, Qirui Zhan, Wenhao Li, Haoyu Zhang, Kangxiang Xia, Ziyu Zhang, Wenjie Tian, Chengyou Wang, Jinrui Liang, Shuhan Guo, Zihang Yang, Bengu Wu, Binbin Zhang, Pengcheng Zhu, Pengyuan Xie, Chuan Xie, Qiang Zhang, Jie Liu, Lei Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10629v1",
    "source": "arXiv",
    "abstract": "Despite rapid progress in text-to-speech (TTS), open-source systems still lack truly instruction-following, fine-grained control over core speech attributes (e.g., pitch, speaking rate, age, emotion, and style). We present VoiceSculptor, an open-source unified system that bridges this gap by integrating instruction-based voice design and high-fidelity voice cloning in a single framework. It generates controllable speaker timbre directly from natural-language descriptions, supports iterative refinement via Retrieval-Augmented Generation (RAG), and provides attribute-level edits across multiple dimensions. The designed voice is then rendered into a prompt waveform and fed into a cloning model to enable high-fidelity timbre transfer for downstream speech synthesis. VoiceSculptor achieves open-source state-of-the-art (SOTA) on InstructTTSEval-Zh, and is fully open-sourced, including code and pretrained models, to advance reproducible instruction-controlled TTS research."
  },
  {
    "date": "2026-01-15",
    "title": "Massless-Massive Amplitude Correspondence II: Constructive Massive Amplitudes in Standard Model",
    "authors": "Yu-Han Ni, Chao Wu, Jiang-Hao Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10622v1",
    "source": "arXiv",
    "abstract": "In the minimal helicity-chirality formalism, we systematically construct higher-point massive amplitudes from the fundamental building blocks: the contact three-point and four-point massive amplitudes. The inclusion of four-point contact amplitudes is essential to maintain gauge invariance in the spontaneously broken Standard Model. We construct all the standard model massive contact amplitudes and identify the physical light-cone gauge nature of massive amplitudes. Then only using the contact minimal helicity-chirality amplitudes at the leading order, we show both bootstrap techniques and on-shell recursion relations can be utilized to compute higher-point massive amplitudes. This provides a systematic framework for constructing various higher-point electroweak amplitudes, analogous to established on-shell methods for massless theories. Finally by deforming the gauge-invariant $n$-point amplitudes, we extend the massless-massive correspondence from three-and-four point contact amplitudes to general $n$-point factorized amplitudes."
  },
  {
    "date": "2026-01-15",
    "title": "Extrinsic Vector Field Processing",
    "authors": "Hongyi Liu, Oded Stein, Amir Vaxman, Mirela Ben-Chen, Misha Kazhdan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10621v1",
    "source": "arXiv",
    "abstract": "We propose a novel discretization of tangent vector fields for triangle meshes. Starting with a Phong map continuously assigning normals to all points on the mesh, we define an extrinsic bases for continuous tangent vector fields by using the Rodrigues rotation to transport tangent vectors assigned to vertices to tangent vectors in the interiors of the triangles. As our vector fields are continuous and weakly differentiable, we can use them to define a covariant derivative field that is evaluatable almost-everywhere on the mesh. Decomposing the covariant derivative in terms of diagonal multiple of the identity, anti-symmetric, and trace-less symmetric components, we can define the standard operators used for vector field processing including the Hodge Laplacian energy, Connection Laplacian energy, and Killing energy. Additionally, the ability to perform point-wise evaluation of the covariant derivative also makes it possible for us to define the Lie bracket."
  },
  {
    "date": "2026-01-15",
    "title": "A young progenitor for the most common planetary systems in the Galaxy",
    "authors": "John H. Livingston, Erik A. Petigura, Trevor J. David, Kento Masuda, James Owen, David Nesvorný, Konstantin Batygin, Jerome de Leon, Mayuko Mori, Kai Ikuta, Akihiko Fukui, Noriharu Watanabe, Jaume Orell Miquel, Felipe Murgas, Hannu Parviainen, Judith Korth, Florence Libotte, Néstor Abreu García, Pedro Pablo Meni Gallardo, Norio Narita, Enric Pallé, Motohide Tamura, Atsunori Yonehara, Andrew Ridden-Harper, Allyson Bieryla, Alessandro A. Trani, Eric E. Mamajek, David R. Ciardi, Varoujan Gorjian, Lynne A. Hillenbrand, Luisa M. Rebull, Elisabeth R. Newton, Andrew W. Mann, Andrew Vanderburg, Guðmundur Stefánsson, Suvrath Mahadevan, Caleb Cañas, Joe Ninan, Jesus Higuera, Kamen Todorov, Jean-Michel Désert, Lorenzo Pino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10598v1",
    "source": "arXiv",
    "abstract": "The Galaxy's most common known planetary systems have several Earth-to-Neptune-size planets in compact orbits. At small orbital separations, larger planets are less common than their smaller counterparts by an order of magnitude. The young star V1298 Tau hosts one such compact planetary system, albeit with four planets that are uncommonly large (5 to 10 Earth radii). The planets form a chain of near-resonances that result in transit-timing variations of several hours. Here we present a multi-year campaign to characterize this system with transit-timing variations, a method insensitive to the intense magnetic activity of the star. Through targeted observations, we first resolved the previously unknown orbital period of the outermost planet. The full 9-year baseline from these and archival data then enabled robust determination of the masses and orbital parameters for all four planets. We find the planets have low, sub-Neptune masses and nearly circular orbits, implying a dynamically tranquil history. Their low masses and large radii indicate that the inner planets underwent a period of rapid cooling immediately after dispersal of the protoplanetary disk. Still, they are much less dense than mature planets of comparable size. We predict the planets will contract to 1.5-4.0 Earth radii and join the population of super-Earths and sub-Neptunes that nature produces in abundance."
  },
  {
    "date": "2026-01-15",
    "title": "Supergravity with Lagrange Multiplier Fields in 2 + 1 Dimensions",
    "authors": "D. G. C. McKeon, F. T. Brandt, J. Frenkel, S. Martins-Filho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10593v1",
    "source": "arXiv",
    "abstract": "We examine the first-order Einstein-Cartan (EC) action in 2+1 dimensions, including a cosmological term and its supersymmetric extension. In this setting the spin connection can be expressed as an axial vector, yielding an action that is bilinear in the quantum fields and allows quantization without background fields. We identify the complete set of first-class constraints and derive the associated gauge transformations, which differ from the standard diffeomorphism and local Lorentz invariances. Using the closed gauge algebra, we construct the Faddeev-Popov-Nielsen path integral and show how a Lagrange multiplier field can be introduced to remove higher-loop contributions while preserving unitarity and gauge invariance."
  },
  {
    "date": "2026-01-15",
    "title": "Combinatorial Optimization Augmented Machine Learning",
    "authors": "Maximilian Schiffer, Heiko Hoppe, Yue Su, Louis Bouvier, Axel Parmentier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10583v1",
    "source": "arXiv",
    "abstract": "Combinatorial optimization augmented machine learning (COAML) has recently emerged as a powerful paradigm for integrating predictive models with combinatorial decision-making. By embedding combinatorial optimization oracles into learning pipelines, COAML enables the construction of policies that are both data-driven and feasibility-preserving, bridging the traditions of machine learning, operations research, and stochastic optimization. This paper provides a comprehensive overview of the state of the art in COAML. We introduce a unifying framework for COAML pipelines, describe their methodological building blocks, and formalize their connection to empirical cost minimization. We then develop a taxonomy of problem settings based on the form of uncertainty and decision structure. Using this taxonomy, we review algorithmic approaches for static and dynamic problems, survey applications across domains such as scheduling, vehicle routing, stochastic programming, and reinforcement learning, and synthesize methodological contributions in terms of empirical cost minimization, imitation learning, and reinforcement learning. Finally, we identify key research frontiers. This survey aims to serve both as a tutorial introduction to the field and as a roadmap for future research at the interface of combinatorial optimization and machine learning."
  },
  {
    "date": "2026-01-15",
    "title": "Achievable Degrees of Freedom Analysis and Optimization in Massive MIMO via Characteristic Mode Analysis",
    "authors": "Shaohua Yue, Siyu Miao, Shuhao Zeng, Fenghan Lin, Boya Di",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10576v1",
    "source": "arXiv",
    "abstract": "Massive multiple-input multiple-output (MIMO) is esteemed as a critical technology in 6G communications, providing large degrees of freedom (DoF) to improve multiplexing gain. This paper introduces characteristic mode analysis (CMA) to derive the achievable DoF. Unlike existing works primarily focusing on the DoF of the wireless channel,the excitation and radiation properties of antennas are also involved in our DoF analysis, which influences the number of independent data streams for communication of a MIMO system. Specifically, we model the excitation and radiation properties of transceiver antennas using CMA to analyze the excitation and radiation properties of antennas. The CMA-based DoF analysis framework is established and the achievable DoF is derived. A characteristic mode optimization problem of antennas is then formulated to maximize the achievable DoF. A case study where the reconfigurable holographic surface (RHS) antennas are deployed at the transceiver is investigated, and a CMA-based genetic algorithm is later proposed to solve the above problem. By changing the characteristic modes electric field and surface current distribution of RHS, the achievable DoF is enhanced. Full-wave simulation verifies the theoretical analysis on the the achievable DoF and shows that, via the reconfiguration of RHS based on the proposed algorithm, the achievable DoF is improved."
  },
  {
    "date": "2026-01-15",
    "title": "Long-term Monitoring of Kernel and Hardware Events to Understand Latency Variance",
    "authors": "Fang Zhou, Yuyang Huang, Miao Yu, Sixiang Ma, Tongping Liu, Yang Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10572v1",
    "source": "arXiv",
    "abstract": "This paper presents our experience to understand latency variance caused by kernel and hardware events, which are often invisible at the application level. For this purpose, we have built VarMRI, a tool chain to monitor and analyze those events in the long term. To mitigate the \"big data\" problem caused by long-term monitoring, VarMRI selectively records a subset of events following two principles: it only records events that are affecting the requests recorded by the application; it records coarse-grained information first and records additional information only when necessary. Furthermore, VarMRI introduces an analysis method that is efficient on large amount of data, robust on different data set and against missing data, and informative to the user. VarMRI has helped us to carry out a 3,000-hour study of six applications and benchmarks on CloudLab. It reveals a wide variety of events causing latency variance, including interrupt preemption, Java GC, pipeline stall, NUMA balancing etc.; simple optimization or tuning can reduce tail latencies by up to 31%. Furthermore, the impacts of some of these events vary significantly across different experiments, which confirms the necessity of long-term monitoring."
  },
  {
    "date": "2026-01-15",
    "title": "Corrections for systematic errors in slit-profiler transverse phase space measurements",
    "authors": "C. Richard, M. Krasilnikov, N. Aftab, Z. Amirkhanyan, D. Dmytriiev, A. Hoffmann, M. Gross, X. -K. Li, Z. Lotfi, F. Stephan, G. Vashchenko, S. Zeeshan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10571v1",
    "source": "arXiv",
    "abstract": "In photo injectors, the transverse emittance is one of the key measures of beam quality as it defines the possible performance of the whole facility. As such it is important to measure the emittance in photo injectors and ensure the accuracy of these measurements. While there are many different methods of measuring the emittance, this paper focuses on quantifying the systematic errors present in transverse phase space measurements taken with slit-profiler methods, i.e. scanning a narrow slit over the beam and continually measuring the passed beamlets' divergence with a downstream profiler. The measurement errors include effects of the slit size, beamlet imaging, and residual space charge. While these effects are generally small, they can have significant impact on the measured emittance when the 2D phase space is strongly coupled. The systematic effects studied and corrections are demonstrated with simulations and measurements from the Photo Injector Test facility at DESY in Zeuthen (PITZ) using a slit-screen emittance scanner."
  },
  {
    "date": "2026-01-15",
    "title": "Sparse Signal Recovery from Random Measurements",
    "authors": "Siu-Wing Cheng, Man Ting Wong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10569v1",
    "source": "arXiv",
    "abstract": "Given the compressed sensing measurements of an unknown vector $z \\in \\mathbb{R}^n$ using random matrices, we present a simple method to determine $z$ without solving any optimization problem or linear system. Our method uses $Θ(\\log n)$ random sensing matrices in $\\mathbb{R}^{k \\times n}$ and runs in $O(kn\\log n)$ time, where $k = Θ(s\\log n)$ and $s$ is the number of nonzero coordinates in $z$. We adapt our method to determine the support set of $z$ and experimentally compare with some optimization-based methods on binary signals."
  },
  {
    "date": "2026-01-15",
    "title": "Inferring signed social networks from contact patterns",
    "authors": "Dávid Ferenczi, Jean-Gabriel Young, Leto Peel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10565v1",
    "source": "arXiv",
    "abstract": "Social networks are typically inferred from indirect observations, such as proximity data; yet, most methods cannot distinguish between absent relationships and actual negative ties, as both can result in few or no interactions. We address the challenge of inferring signed networks from contact patterns while accounting for whether lack of interactions reflect a lack of opportunity as opposed to active avoidance. We develop a Bayesian framework with MCMC inference that models interaction groups to separate chance from choice when no interactions are observed. Validation on synthetic data demonstrates superior performance compared to natural baselines, particularly in detecting negative edges. We apply our method to French high school contact data to reveal a structure consistent with friendship surveys and demonstrate the model's adequacy through posterior predictive checks."
  },
  {
    "date": "2026-01-15",
    "title": "Rewriting Systems on Arbitrary Monoids",
    "authors": "Eduardo Magalhães",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10564v1",
    "source": "arXiv",
    "abstract": "In this paper, we introduce monoidal rewriting systems (MRS), an abstraction of string rewriting in which reductions are defined over an arbitrary ambient monoid rather than a free monoid of words. This shift is partly motivated by logic: the class of free monoids is not first-order axiomatizable, so \"working in the free setting\" cannot be treated internally when applying first-order methods to rewriting presentations. To analyze these systems categorically, we define $\\mathbf{NCRS_2}$ as the 2-category of Noetherian Confluent MRS. We then prove the existence of a canonical biadjunction between $\\mathbf{NCRS_2}$ and $\\mathbf{Mon}$. Finally, we classify all Noetherian Confluent MRS that present a given fixed monoid. For this, we introduce Generalized Elementary Tietze Transformations (GETTs) and prove that any two presentations of a monoid are connected by a (possibly infinite) sequence of these transformations, yielding a complete characterization of generating systems up to GETT-equivalence."
  },
  {
    "date": "2026-01-15",
    "title": "(a,b)-Fibonacci-Legendre Cordial Graphs and k-Pisano-Legendre Primes",
    "authors": "J. D. Andoyo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10561v1",
    "source": "arXiv",
    "abstract": "Let $p$ be an odd prime and let $F_i$ be the $i$th $(a,b)$-Fibonacci number with initial values $F_0=a$ and $F_1=b$. For a simple connected graph $G=(V,E)$, define a bijective function $f:V(G)\\to \\{0,1,\\ldots,|V|-1\\}$. If the induced function $f_p^*:E(G)\\to \\{0,1\\}$, defined by $f_p^*(uv)=\\frac{1+([F_{f(u)}+F_{f(v)}]/p)}{2}$ whenever $F_{f(u)}+F_{f(v)}\\not\\equiv 0\\pmod{p}$ and $f_p^*(uv)=0$ whenever $F_{f(u)}+F_{f(v)}\\equiv 0\\pmod{p}$, satisfies the condition $|e_{f_p^*}(0)-e_{f_p^*}(1)|\\leq 1$ where $e_{f_p^*}(i)$ is the number of edges labeled $i$ ($i=0,1$), then $f$ is called $(a,b)$-Fibonacci-Legendre cordial labeling modulo $p$. In this paper, the $(a,b)$-Fibonacci-Legendre cordial labeling of path graphs, star graphs, wheel graphs, and graphs under the operations join, corona, lexicographic product, cartesian product, tensor product, and strong product is explored in relation to $k$-Pisano-Legendre primes relative to $(a,b)$. We also present some properties of $k$-Pisano-Legendre primes relative to $(a,b)$ and numerical observations on its distribution, leading to several conjectures concerning their density and growth behavior."
  },
  {
    "date": "2026-01-15",
    "title": "HeartMuLa: A Family of Open Sourced Music Foundation Models",
    "authors": "Dongchao Yang, Yuxin Xie, Yuguo Yin, Zheyu Wang, Xiaoyu Yi, Gongxi Zhu, Xiaolong Weng, Zihan Xiong, Yingzhe Ma, Dading Cong, Jingliang Liu, Zihang Huang, Jinghan Ru, Rongjie Huang, Haoran Wan, Peixu Wang, Kuoxi Yu, Helin Wang, Liming Liang, Xianwei Zhuang, Yuanyuan Wang, Haohan Guo, Junjie Cao, Zeqian Ju, Songxiang Liu, Yuewen Cao, Heming Weng, Yuexian Zou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10547v1",
    "source": "arXiv",
    "abstract": "We present a family of open-source Music Foundation Models designed to advance large-scale music understanding and generation across diverse tasks and modalities. Our framework consists of four major components: (1) HeartCLAP, an audio-text alignment model; (2) HeartTranscriptor, a robust lyric recognition model optimized for real-world music scenarios; and (3) HeartCodec, a low-frame-rate (12.5 Hz) yet high-fidelity music codec tokenizer that captures long-range musical structure while preserving fine-grained acoustic details and enabling efficient autoregressive modeling; (4) HeartMuLa, an LLM-based song generation model capable of synthesizing high-fidelity music under rich, user-controllable conditions (e.g., textual style descriptions, lyrics, and reference audio). In addition, it provides two specialized modes: (i) fine-grained musical attribute control, which allows users to specify the style of different song sections (e.g., intro, verse, chorus) using natural language prompts; and (ii) short, engaging music generation, which is suitable as background music for short videos. Lastly, HeartMuLa improves significantly when scaled to 7B parameters. For the first time, we show that a Suno-level, commercial-grade system can be reproduced using academic-scale data and GPU resources. We expect these foundation models to serve as strong baselines for future research and to facilitate practical applications in multimodal content production."
  },
  {
    "date": "2026-01-15",
    "title": "Spatio-spectrally tailored multimode metasurface lasers in the visible range",
    "authors": "Ayesheh Bashiri, Aleksandr Vaskin, Katsuya Tanaka, Muyi Yang, Thomas Pertsch, Isabelle Staude",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10546v1",
    "source": "arXiv",
    "abstract": "Spectrally engineered multifrequency nanolasers are highly desirable for on-chip photonics, multiplexed biosensing, and display technologies; yet, achieving them within a single compact platform remains challenging. Here, we demonstrate multimode lasing from symmetry-broken TiO2 metasurfaces integrated with an SU8 slab waveguide containing Rhodamine 6G. By co-engineering guided-mode resonances, surface lattice resonances near Rayleigh anomalies, and quasi-bound states in the continuum, we realize complementary high-Q feedback pathways that overlap with the gain spectrum. The direction of the lasing emission is tailored through outcoupling via second-order Bragg diffraction and Rayleigh anomaly conditions, supporting both normal and oblique emission. Experiments reveal discrete lasing outputs across ~100 nm bandwidth (548-648 nm), spanning nearly the full Rhodamine 6G emission band, with thresholds as low as ~7 nJ per pulse (35.7 uJ/cm^2) and up to four concurrent lasing peaks from a single device. These results establish a metasurface-dye platform for multifrequency and angle-selective lasing, opening new opportunities for compact, multifunctional nanophotonic sources."
  },
  {
    "date": "2026-01-15",
    "title": "CoGen: Creation of Reusable UI Components in Figma via Textual Commands",
    "authors": "Ishani Kanapathipillai, Obhasha Priyankara",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10536v1",
    "source": "arXiv",
    "abstract": "The evolution of User Interface design has emphasized the need for efficient, reusable, and editable components to ensure an efficient design process. This research introduces CoGen, a system that uses machine learning techniques to generate reusable UI components directly in Figma, one of the most popular UI design tools. Addressing gaps in current systems, CoGen focuses on creating atomic components such as buttons, labels, and input fields using structured JSON and natural language prompts. The project integrates Figma API data extraction, Seq2Seq models, and fine-tuned T5 transformers for component generation. The key results demonstrate the efficiency of the T5 model in prompt generation, with an accuracy of 98% and a BLEU score of 0.2668, which ensures the mapping of JSON to descriptive prompts. For JSON creation, CoGen achieves a success rate of up to 100% in generating simple JSON outputs for specified component types."
  },
  {
    "date": "2026-01-15",
    "title": "Shock Signatures of the Successive Type-II Solar Radio Bursts at Meter Wavelength",
    "authors": "V. Vasanth",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10528v1",
    "source": "arXiv",
    "abstract": "The successive type-II solar radio bursts observed on 31 July 2012 by the Bruny Island Radio Spectrometer (BIRS) in the frequency range between 62 - 6 MHz is reported and analyzed. The first type-II radio burst shows clear fundamental and harmonic band structures, while only one band is observed for the second type-II radio burst and is considered as the harmonic band. The first type-II radio burst is observed in the frequency range of 57 - 27 MHz between 00:03 - 00:09 UT at the harmonic band. The second type-II burst is observed between 00:18 - 00:27 UT in the frequency range of 43 - 17 MHz. The type-II radio bursts are associated with a C6 class flare located at the south-eastern limb (S24E87) and a CME observed from STEREO and LASCO observations. The EUVI signatures of the CME is observed in the ST-B EUVI FOV between 23:56 (on 30 July 2012) to 00:06 UT (on 31 July 2012), and are observed in the ST-B COR1 FOV between 00:10 - 00:35 UT moving within an average speed of 725 + or - 101 km/s. The CME is observed in the LASCO C2 FOV after 00:12 UT as a partial halo CME moving with an average speed of 486 km/s. The height-time plot shows that the first type-II radio burst was formed by the CME-shock along the shock front and the second type-II radio burst along the shock-dip structure, probably the dip structure results from the shock transiting across the high dense streamer structure. The successive type-II bursts are most likely produced by the single CME shock and their interactions with the streamer structures. The first type-II radio burst by the CME shock and the second type-II radio burst by the CME shock-streamer interactions."
  },
  {
    "date": "2026-01-15",
    "title": "Twisted Cherednik spectrum as a $q,t$-deformation",
    "authors": "A. Mironov, A. Morozov, A. Popolitov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10500v1",
    "source": "arXiv",
    "abstract": "The common eigenfunctions of the twisted Cherednik operators can be first analyzed in the limit of $q\\longrightarrow 1$. Then, the polynomial eigenfunctions form a simple set originating from the symmetric ground state of non-vanishing degree and excitations over it, described by non-symmetric polynomials of higher degrees and enumerated by weak compositions. This pattern is inherited by the full spectrum at $q\\neq 1$, which can be considered as a deformation. The whole story looks like a typical NP problem: the Cherednik equations are difficult to solve, but easy to check the solution once it is somehow found."
  },
  {
    "date": "2026-01-15",
    "title": "CROCS: A Two-Stage Clustering Framework for Behaviour-Centric Consumer Segmentation with Smart Meter Data",
    "authors": "Luke W. Yerbury, Ricardo J. G. B. Campello, G. C. Livingston, Mark Goldsworthy, Lachlan O'Neil",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10494v1",
    "source": "arXiv",
    "abstract": "With grid operators confronting rising uncertainty from renewable integration and a broader push toward electrification, Demand-Side Management (DSM) -- particularly Demand Response (DR) -- has attracted significant attention as a cost-effective mechanism for balancing modern electricity systems. Unprecedented volumes of consumption data from a continuing global deployment of smart meters enable consumer segmentation based on real usage behaviours, promising to inform the design of more effective DSM and DR programs. However, existing clustering-based segmentation methods insufficiently reflect the behavioural diversity of consumers, often relying on rigid temporal alignment, and faltering in the presence of anomalies, missing data, or large-scale deployments. To address these challenges, we propose a novel two-stage clustering framework -- Clustered Representations Optimising Consumer Segmentation (CROCS). In the first stage, each consumer's daily load profiles are clustered independently to form a Representative Load Set (RLS), providing a compact summary of their typical diurnal consumption behaviours. In the second stage, consumers are clustered using the Weighted Sum of Minimum Distances (WSMD), a novel set-to-set measure that compares RLSs by accounting for both the prevalence and similarity of those behaviours. Finally, community detection on the WSMD-induced graph reveals higher-order prototypes that embody the shared diurnal behaviours defining consumer groups, enhancing the interpretability of the resulting clusters. Extensive experiments on both synthetic and real Australian smart meter datasets demonstrate that CROCS captures intra-consumer variability, uncovers both synchronous and asynchronous behavioural similarities, and remains robust to anomalies and missing data, while scaling efficiently through natural parallelisation. These results..."
  },
  {
    "date": "2026-01-15",
    "title": "Plasmon dynamics in graphene",
    "authors": "Suheng Xu, Birui Yang, Nishchhal Verma, Rocco A. Vitalone, Brian Vermilyea, Miguel Sánchez Sánchez, Julian Ingham, Ran Jing, Yinming Shao, Tobias Stauber, Angel Rubio, Milan Delor, Mengkun Liu, Michael M. Fogler, Cory R. Dean, Andrew Millis, Raquel Queiroz, D. N. Basov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10493v1",
    "source": "arXiv",
    "abstract": "Plasmons are collective oscillations of mobile electrons. Using terahertz spacetime metrology, we probe plasmon dynamics of mono- and bi-layer graphene. In both systems, the experimentally measured Drude weight systematically exceeds the prediction based on non-interacting electronic system. This enhancement is most pronounced at ultra-low carrier densities. We attribute the observed deviation to pseudospin dynamics of the Dirac fermions in multi-layer graphene, which leads to a breakdown of Galilean invariance. Our results establish that pseudospin structure of the single-particle electronic wave function can directly govern collective excitations, with implications that extend beyond graphene to a broad class of quantum materials."
  },
  {
    "date": "2026-01-15",
    "title": "A proof of the soliton resolution conjecture for the Benjamin--Ono equation",
    "authors": "Louise Gassot, Patrick Gérard, Peter D. Miller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10488v1",
    "source": "arXiv",
    "abstract": "We give a proof of the soliton resolution conjecture for the Benjamin--Ono equation, namely every solution with sufficiently regular and decaying initial data can be written as a finite sum of soliton solutions with different velocities up to a radiative remainder term in the long--time asymptotics. We provide a detailed correspondence between the spectral theory of the Lax operator associated to the initial data and the different terms of the soliton resolution expansion. The proof is based on a new use of a representation formula of the solution due to the second author, and on a detailed analysis of the distorted Fourier transform associated to the Lax operator."
  },
  {
    "date": "2026-01-15",
    "title": "Mesh Denoising",
    "authors": "Constantin Vaillant Tenzer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10487v1",
    "source": "arXiv",
    "abstract": "In this paper, we study four mesh denoising methods: linear filtering, a heat diffusion method, Sobolev regularization, and, to a lesser extent, a barycentric approach based on the Sinkhorn algorithm. We illustrate that, for a simple image denoising task, a naive choice of a Gibbs kernel can lead to unsatisfactory results. We demonstrate that while Sobolev regularization is the fastest method in our implementation, it produces slightly less faithful denoised meshes than the best results obtained with iterative filtering or heat diffusion. We empirically show that, for the large mesh considered, the heat diffusion method is slower and not more effective than filtering, whereas on a small mesh an appropriate choice of diffusion parameters can improve the quality. Finally, we observe that all three mesh-based methods perform markedly better on the large mesh than on the small one."
  },
  {
    "date": "2026-01-15",
    "title": "A Construction Framework of Coded Caching Scheme for Multi-Access MIMO Systems via Knapsack Problem",
    "authors": "Siying Luo, Youlong Wu, Mingming Zhang, Minquan Cheng, Dianhua Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10484v1",
    "source": "arXiv",
    "abstract": "This paper investigates the coded caching problem in a multi-access multiple-input single-output (MAMISO) network with the combinatorial topology. The considered system consists of a server containing $N$ files, $Λ$ cache nodes, and $K$ cache-less users, where each user can access a unique subset of $r$ cache nodes. The server is equipped with $L$ transmit antennas. Our objective is to design a caching scheme that simultaneously achieves a high sum Degree of Freedom (sum-DoF) and low subpacketization complexity. To address this challenge, we formulate the design of multi-antenna placement delivery arrays (MAPDA) as a $0$--$1$ knapsack problem to maximize the achievable DoF, thereby transforming the complex combinatorial caching structure into a tractable optimization framework that yields efficient cache placement and flexible delivery strategies. Theoretical and numerical analyses demonstrate that: for networks with combinatorial topologies, the proposed scheme achieves a higher sum-DoF than existing schemes. Under identical cache size constraints, the subpacketization level remains comparable to existing linear subpacketization schemes. Moreover, under specific system conditions, the proposed scheme attains the theoretical maximum sum-DoF of $\\min\\{L+KM/N, K\\}$ while achieving further reductions subpacketization. For particular combinatorial structures, we further derive optimized constructions that achieve even higher sum-DoF with lower subpacketization. ```"
  },
  {
    "date": "2026-01-15",
    "title": "Convex Efficient Coding",
    "authors": "William Dorrell, Peter E. Latham, James Whittington",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10482v1",
    "source": "arXiv",
    "abstract": "Why do neurons encode information the way they do? Normative answers to this question model neural activity as the solution to an optimisation problem; for example, the celebrated efficient coding hypothesis frames neural activity as the optimal encoding of information under efficiency constraints. Successful normative theories have varied dramatically in complexity, from simple linear models (Atick & Redlich '90), to complex deep neural networks (Lindsay '21). What complex models gain in flexibility, they lose in tractability and often understandability. Here, we split the difference by constructing a set of tractable but flexible normative representational theories. Instead of optimising the neural activities directly, following Sengupta et al. '18, we optimise the representational similarity, a matrix formed from the dot products of each pair of neural responses. Using this, we show that a large family of interesting optimisation problems are convex. This family includes problems corresponding to linear and some non-linear neural networks, and problems from the literature not previously recognised as convex, such as modified versions of semi-nonnegative matrix factorisation or nonnegative sparse coding. We put these findings to work in three ways. First, we provide the first necessary and sufficient identifiability result for a form of semi-nonnegative matrix factorisation. Second, we show that if neural tunings are `different enough' then they are uniquely linked to the optimal representational similarity, partially justifying the use of single neuron tuning analysis in neuroscience. Finally, we use the tractable nonlinearity of some of our problems to explain why dense retinal codes, but not sparse cortical codes, optimally split the coding of a single variable into ON & OFF channels. In sum, we identify a space of convex problems, and use them to derive neural coding results."
  },
  {
    "date": "2026-01-15",
    "title": "H-EFT-VA: An Effective-Field-Theory Variational Ansatz with Provable Barren Plateau Avoidance",
    "authors": "Eyad I. B Hamid",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10479v1",
    "source": "arXiv",
    "abstract": "Variational Quantum Algorithms (VQAs) are critically threatened by the Barren Plateau (BP) phenomenon. In this work, we introduce the H-EFT Variational Ansatz (H-EFT-VA), an architecture inspired by Effective Field Theory (EFT). By enforcing a hierarchical \"UV-cutoff\" on initialization, we theoretically restrict the circuit's state exploration, preventing the formation of approximate unitary 2-designs. We provide a rigorous proof that this localization guarantees an inverse-polynomial lower bound on the gradient variance: $Var[\\partial θ] \\in Ω(1/poly(N))$. Crucially, unlike approaches that avoid BPs by limiting entanglement, we demonstrate that H-EFT-VA maintains volume-law entanglement and near-Haar purity, ensuring sufficient expressibility for complex quantum states. Extensive benchmarking across 16 experiments -- including Transverse Field Ising and Heisenberg XXZ models -- confirms a 109x improvement in energy convergence and a 10.7x increase in ground-state fidelity over standard Hardware-Efficient Ansatze (HEA), with a statistical significance of $p < 10^{-88}$."
  },
  {
    "date": "2026-01-15",
    "title": "Urban Socio-Semantic Segmentation with Vision-Language Reasoning",
    "authors": "Yu Wang, Yi Wang, Rui Dai, Yujie Wang, Kaikui Liu, Xiangxiang Chu, Yansheng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10477v1",
    "source": "arXiv",
    "abstract": "As hubs of human activity, urban surfaces consist of a wealth of semantic entities. Segmenting these various entities from satellite imagery is crucial for a range of downstream applications. Current advanced segmentation models can reliably segment entities defined by physical attributes (e.g., buildings, water bodies) but still struggle with socially defined categories (e.g., schools, parks). In this work, we achieve socio-semantic segmentation by vision-language model reasoning. To facilitate this, we introduce the Urban Socio-Semantic Segmentation dataset named SocioSeg, a new resource comprising satellite imagery, digital maps, and pixel-level labels of social semantic entities organized in a hierarchical structure. Additionally, we propose a novel vision-language reasoning framework called SocioReasoner that simulates the human process of identifying and annotating social semantic entities via cross-modal recognition and multi-stage reasoning. We employ reinforcement learning to optimize this non-differentiable process and elicit the reasoning capabilities of the vision-language model. Experiments demonstrate our approach's gains over state-of-the-art models and strong zero-shot generalization. Our dataset and code are available in https://github.com/AMAP-ML/SocioReasoner."
  },
  {
    "date": "2026-01-15",
    "title": "Optimal error estimates for a discontinuous Galerkin method on curved boundaries with polygonal meshes",
    "authors": "Adérito Araújo, Milene Santos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10474v1",
    "source": "arXiv",
    "abstract": "We consider a discontinuous Galerkin method for the numerical solution of boundary value problems in two-dimensional domains with curved boundaries. A key challenge in this setting is the potential loss of convergence order due to approximating the physical domain by a polygonal mesh. Unless boundary conditions can be accurately transferred from the true boundary to the computational one, such geometric approximation errors generally lead to suboptimal convergence. To overcome this limitation, a higher-order strategy based on polynomial reconstruction of boundary data was introduced for classical finite element methods in [28, 29] and in the finite volume context in [7, 11]. More recently, this approach was extended to discontinuous Galerkin methods in [32], leading to the DG-ROD method, which restores optimal convergence rates on polygonal approximations of domains with curved boundaries. In this work, we provide a rigorous theoretical analysis of the DG-ROD method, establishing existence and uniqueness of the discrete solution and deriving error estimates for a two-dimensional linear advection-diffusion-reaction problem with homogeneous Dirichlet boundary conditions on both convex and non-convex domains. Following and extending techniques from classical finite element methods [29], we prove that, under suitable regularity assumptions on the exact solution, the DG-ROD method achieves optimal convergence despite polygonal approximations. Finally, we illustrate and confirm the theoretical results with a numerical benchmark."
  },
  {
    "date": "2026-01-15",
    "title": "Symmetric spaces, non-formal star products and Drinfel'd twists",
    "authors": "Pierre Bieliavsky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10456v1",
    "source": "arXiv",
    "abstract": "These notes refer to a minicourse I gave at the occasion of the conference meeting ``Applications of Noncommutative Geometry to Gauge Theories, Field Theories, and Quantum Space-Time'' to be held from 7 April to 11 April 2025 at the Centre International de Rencontres Mathématiques in Luminy. They consist in a review of a long standing work of mine and collaborators (see references therein) in the field of non-formal deformation quantization admitting a large group of symmetries. But they also contain new material and results. More precisely, in a first part, I present a method (called the Retract Method) to define quantizations/symbolic calculi and associated operator symbol composition formulae (non-formal deformations/star products) of symplectic symmetric spaces such as the hyperbolic plane (Kahler) or symmetric co-adjoint orbits of the Poincaré group (non-metric). In a second part, I explain how to derive non-formal Drinfel'd twists for actions of non-Abelian solvable Lie groups (non-Abelian Universal Deformation Formulae) on or Fr échet algebras from the non-formal noncommutative symmetric spaces defined in the first part."
  },
  {
    "date": "2026-01-15",
    "title": "SurgGoal: Rethinking Surgical Planning Evaluation via Goal-Satisfiability",
    "authors": "Ruochen Li, Kun Yuan, Yufei Xia, Yue Zhou, Qingyu Lu, Weihang Li, Youxiang Zhu, Nassir Navab",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10455v1",
    "source": "arXiv",
    "abstract": "Surgical planning integrates visual perception, long-horizon reasoning, and procedural knowledge, yet it remains unclear whether current evaluation protocols reliably assess vision-language models (VLMs) in safety-critical settings. Motivated by a goal-oriented view of surgical planning, we define planning correctness via phase-goal satisfiability, where plan validity is determined by expert-defined surgical rules. Based on this definition, we introduce a multicentric meta-evaluation benchmark with valid procedural variations and invalid plans containing order and content errors. Using this benchmark, we show that sequence similarity metrics systematically misjudge planning quality, penalizing valid plans while failing to identify invalid ones. We therefore adopt a rule-based goal-satisfiability metric as a high-precision meta-evaluation reference to assess Video-LLMs under progressively constrained settings, revealing failures due to perception errors and under-constrained reasoning. Structural knowledge consistently improves performance, whereas semantic guidance alone is unreliable and benefits larger models only when combined with structural constraints."
  },
  {
    "date": "2026-01-15",
    "title": "Minimal-Energy Optimal Control of Tunable Two-Qubit Gates in Superconducting Platforms Using Continuous Dynamical Decoupling",
    "authors": "Adonai Hilário da Silva, Octávio da Motta, Leonardo Kleber Castelano, Reginaldo de Jesus Napolitano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10446v1",
    "source": "arXiv",
    "abstract": "We present a unified scheme for generating high-fidelity entangling gates in superconducting platforms by continuous dynamical decoupling (CDD) combined with variational minimal-energy optimal control. During the CDD stage, we suppress residual couplings, calibration drifting, and quasistatic noise, resulting in a stable effective Hamiltonian that preserves the designed ZZ interaction intended for producing tunable couplers. In this stable $\\mathrm{SU}(4)$ manifold, we calculate smooth low-energy single-quibt control functions using a variational geodesic optimization process that directly minimizes gate infidelity. We illustrate the methodology by applying it to CZ, CX, and generic engangling gates, achieving virtually unit fidelity and robustness under restricted single-qubit action, with experimentally realistic control fields. These results establish CDD-enhanced variational geometric optimal control as a practical and noise-resilient scheme for designing superconducting entangling gates."
  },
  {
    "date": "2026-01-15",
    "title": "Submesoscale and boundary layer turbulence under mesoscale forcing in the upper ocean",
    "authors": "S. Peng, S. Silvestri, A. Bodner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10441v1",
    "source": "arXiv",
    "abstract": "The interaction among quasi-geostrophic mesoscale eddies, submesoscale fronts, and boundary layer turbulence (BLT) is a central problem in upper ocean dynamics. We investigate these multiscale dynamics using a novel large-eddy simulation on a 100km-scale domain with meter-scale resolution. The simulation resolves BLT energized by uniform surface wind and convective forcing. A front interacts with BLT within a prescribed, spatially inhomogeneous mesoscale eddy field, representing a canonical eddy quadrupole. Using a triple flow decomposition, we analyze the dynamic coupling and kinetic energy budgets among the large-scale field, submesoscale field, and the resolved BLT. Our analysis reveals significant heterogeneity in the structure and intensity of submesoscales and BLT under varying mesoscale forcing. Turbulent kinetic energy and production rates can vary by an order of magnitude along the front, creating distinct turbulent hotspots whose locations are tied to the underlying large-scale flow. The region under stronger mesoscale convergence holds stronger horizontal and vertical geostrophic shear productions for BLT, and stronger self-production and BLT-destruction for submesoscales. In contrast, the region under dominant mesoscale divergence holds dramatic distortion of the front isotherm, along with dominant submesoscale vertical buoyancy production and self-destruction. These results provide a direct characterization of BLT and submesoscales in the ocean mixed layer modulated by a mesoscale eddy field, which can better inform future parameterization developments."
  },
  {
    "date": "2026-01-15",
    "title": "AgentGuardian: Learning Access Control Policies to Govern AI Agent Behavior",
    "authors": "Nadya Abaev, Denis Klimov, Gerard Levinov, David Mimran, Yuval Elovici, Asaf Shabtai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10440v1",
    "source": "arXiv",
    "abstract": "Artificial intelligence (AI) agents are increasingly used in a variety of domains to automate tasks, interact with users, and make decisions based on data inputs. Ensuring that AI agents perform only authorized actions and handle inputs appropriately is essential for maintaining system integrity and preventing misuse. In this study, we introduce the AgentGuardian, a novel security framework that governs and protects AI agent operations by enforcing context-aware access-control policies. During a controlled staging phase, the framework monitors execution traces to learn legitimate agent behaviors and input patterns. From this phase, it derives adaptive policies that regulate tool calls made by the agent, guided by both real-time input context and the control flow dependencies of multi-step agent actions. Evaluation across two real-world AI agent applications demonstrates that AgentGuardian effectively detects malicious or misleading inputs while preserving normal agent functionality. Moreover, its control-flow-based governance mechanism mitigates hallucination-driven errors and other orchestration-level malfunctions."
  },
  {
    "date": "2026-01-15",
    "title": "ASTRA: A Python Package for Cross-Instrument Stellar and Telluric Template Construction",
    "authors": "André M. Silva, J. P. Faria, N. C. Santos, S. G. Sousa, P. T. P. Viana, J. H. C. Martins",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10439v1",
    "source": "arXiv",
    "abstract": "ASTRA is a Python package that provides a modular, instrument-independent interface for working with high-resolution stellar spectra. Designed to support data from multiple spectrographs, including ESPRESSO (Pepe et al., 2021), HARPS (Mayor et al., 2003; Pepe et al., 2002), MAROON-X (Seifahrt et al., 2022), and CARMENES (Quirrenbach et al., 2014). ASTRA offers a unified abstraction over their data formats, enabling consistent access to fluxes, wavelengths, uncertainties, and metadata across instruments. Furthermore, it applies the necessary wavelength and flux calibrations that are needed, as described by the official pipelines of each instrument."
  },
  {
    "date": "2026-01-15",
    "title": "Geometric characterization of frictional impacts by means of breakable kinetic constraints",
    "authors": "Stefano Pasquero",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10432v1",
    "source": "arXiv",
    "abstract": "In the context of geometric Impulsive Mechanics of systems with a finite number of degrees of freedom, we model the roughness of a unilateral constraint ${\\mathcal S\\/}$ by introducing a suitable instantaneous kinetic constraint ${\\mathcal B\\/}\\subset {\\mathcal S\\/}$. A constitutive characterization of ${\\mathcal B\\/}$ based only on the geometric properties of the setup and on the dry friction laws can then be introduced to model the frictional behavior of ${\\mathcal S\\/}$ in an impact of the system. Such a model restores determinism and avoids the analysis of frictional forces in the contact point, with all its associated theoretical problems of causality. Three examples of increasing complexity, showing a natural stick--slip behavior of the impact, are presented."
  },
  {
    "date": "2026-01-15",
    "title": "Untangling Input Language from Reasoning Language: A Diagnostic Framework for Cross-Lingual Moral Alignment in LLMs",
    "authors": "Nan Li, Bo Kang, Tijl De Bie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.10257v1",
    "source": "arXiv",
    "abstract": "When LLMs judge moral dilemmas, do they reach different conclusions in different languages, and if so, why? Two factors could drive such differences: the language of the dilemma itself, or the language in which the model reasons. Standard evaluation conflates these by testing only matched conditions (e.g., English dilemma with English reasoning). We introduce a methodology that separately manipulates each factor, covering also mismatched conditions (e.g., English dilemma with Chinese reasoning), enabling decomposition of their contributions. To study \\emph{what} changes, we propose an approach to interpret the moral judgments in terms of Moral Foundations Theory. As a side result, we identify evidence for splitting the Authority dimension into a family-related and an institutional dimension. Applying this methodology to English-Chinese moral judgment with 13 LLMs, we demonstrate its diagnostic power: (1) the framework isolates reasoning-language effects as contributing twice the variance of input-language effects; (2) it detects context-dependency in nearly half of models that standard evaluation misses; and (3) a diagnostic taxonomy translates these patterns into deployment guidance. We release our code and datasets at https://anonymous.4open.science/r/CrossCulturalMoralJudgement."
  }
]