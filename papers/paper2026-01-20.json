[
  {
    "date": "2026-01-20",
    "title": "Kaleidoscope Yang-Baxter Equation for Gaudin's Kaleidoscope models",
    "authors": "Wen-Jie Qiu, Xi-Wen Guan, Yi-Cong Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13596v1",
    "source": "arXiv",
    "abstract": "Recently, researchers have proposed the Asymmetric Bethe ansatz method - a theoretical tool that extends the scope of Bethe ansatz-solvable models by \"breaking\" partial mirror symmetry via the introduction of a fully reflecting boundary. Within this framework, the integrability conditions which were originally put forward by Gaudin have been further generalized. In this work, building on Gaudin's generalized kaleidoscope model, we present a detailed investigation of the relationship between DN symmetry and its integrability. We demonstrate that the mathematical essence of integrability in this class of models is characterized by a newly proposed Kaleidoscope Yang-Baxter Equation. Furthermore, we show that the solvability of a model via the coordinate Bethe ansatz depends not only on the consistency relations satisfied by scattering matrices, but also on the model's boundary conditions and the symmetry of the subspace where solutions are sought. Through finite element method based numerical studies, we further confirm that Bethe ansatz integrability arises in a specific symmetry sector. Finally, by analyzing the algebraic structure of the Kaleidoscope Yang-Baxter Equation, we derive a series of novel quantum algebraic identities within the framework of quantum torus algebra."
  },
  {
    "date": "2026-01-20",
    "title": "Macroscopic localization and collective memory in Poisson renewal resetting",
    "authors": "Ohad Vilk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13595v1",
    "source": "arXiv",
    "abstract": "Stochastic renewal processes are ubiquitous across physics, biology, and the social sciences. Here, we show that continuous-time renewal dynamics can naturally produce a mixed discrete-continuous structure, with a macroscopic fraction of particles occupying a discrete state. For ensembles of continuous-time random walkers subject to Poissonian renewal resets, we develop an age-structured framework showing this discrete component corresponds to localization at the reset configuration. We next show that collective interactions can retain memory although all reset events are memoryless. Remarkably, the transition to collective memory is discontinuous, and we identify a first-order dynamical phase transition between weak collective bias, where the dynamics are stationary, to strong collective bias where the dynamics are nonstationary and display aging up to finite-size effects. We explicitly discuss ecological implications of our work, illustrating how continuous-time renewal dynamics shape macroscopic structure and collective organization with long-term memory."
  },
  {
    "date": "2026-01-20",
    "title": "100-Billion-Atom Molecular Dynamics Simulation of Acoustic Cavitation in a Simple Liquid",
    "authors": "Yuta Asano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13594v1",
    "source": "arXiv",
    "abstract": "A large-scale molecular dynamics (MD) simulation of acoustic cavitation in a simple liquid was performed using the supercomputer Fugaku. The system, consisting of approximately 100 billion atoms, was subjected to ultrasonic irradiation. Direct observation of multi-bubble dynamics has been challenging in both experimental measurements and conventional numerical fluid mechanics simulations. Moreover, previous MD simulations involving only hundreds of millions of atoms were unable to generate multiple bubbles within a system. Our results reveal that cavitation bubbles nucleate and grow near the ultrasonic horn, forming a large bubble cluster that periodically splits into multiple small clusters and subsequently merges again. This cycle is synchronized with the oscillation period of the horn. Pressure and temperature inside the bubbles exhibit sharp increases during cluster fragmentation, and their oscillation amplitudes vary on a timescale longer than the driving period of the horn, indicating the presence of subharmonic behavior consistent with experimental observations. Despite bubble formation, the effect on the acoustic properties of the sound wave was almost negligible, indicating that cavitation near the horn surface has limited influence on bulk acoustic properties. These findings provide new insights into the molecular-scale mechanisms of cavitation and offer guidance for optimizing ultrasonic systems in chemical and biomedical applications. Future work will focus on quantifying long-period oscillations, analyzing attenuation effects, and extending simulations to complex fluids."
  },
  {
    "date": "2026-01-20",
    "title": "Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification",
    "authors": "HyeYoung Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13589v1",
    "source": "arXiv",
    "abstract": "This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices."
  },
  {
    "date": "2026-01-20",
    "title": "TREX: Tokenizer Regression for Optimal Data Mixture",
    "authors": "Inho Won, Hangyeol Yoo, Minkyung Cho, Jungyeul Park, Hoyun Song, KyungTae Lim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13588v1",
    "source": "arXiv",
    "abstract": "Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness."
  },
  {
    "date": "2026-01-20",
    "title": "AAFIYA: Antenna Analysis in Frequency-domain for Impedance and Yield Assessment",
    "authors": "Mohammad Ful Hossain Seikh, Rachel Jarvis, James Stiles",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13583v1",
    "source": "arXiv",
    "abstract": "This paper presents AAFIYA (Antenna Analysis in Frequency-domain for Impedance and Yield Assessment), a modular Python toolkit for automated characterization of radio-frequency antennas using measurement and simulation data. The toolkit provides a unified workflow for processing S-parameters, impedance, realized gain, beam patterns, polarization metrics, and calibration-based yield estimation, with support for standard Touchstone files and beam pattern data. AAFIYA is validated using measurements from an electromagnetic anechoic chamber involving Log Periodic Dipole Array (LPDA) reference antennas and Askaryan Radio Array (ARA) Bottom Vertically Polarized antennas over 100-850 MHz. Extracted metrics, including impedance matching, realized gain patterns, vector effective lengths, and cross-polarization ratio, are compared against full-wave simulations from HFSS and WIPL-D, showing good agreement across frequency and angle. The results demonstrate that AAFIYA enables accurate, reproducible, and publication-ready antenna analysis, and provides a flexible foundation for future extensions, including automated optimization and data-driven antenna design."
  },
  {
    "date": "2026-01-20",
    "title": "A Kubernetes custom scheduler based on reinforcement learning for compute-intensive pods",
    "authors": "Hanlin Zhou, Huah Yong Chan, Shun Yao Zhang, Meie Lin, Jingfei Ni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13579v1",
    "source": "arXiv",
    "abstract": "With the rise of cloud computing and lightweight containers, Docker has emerged as a leading technology for rapid service deployment, with Kubernetes responsible for pod orchestration. However, for compute-intensive workloads-particularly web services executing containerized machine-learning training-the default Kubernetes scheduler does not always achieve optimal placement. To address this, we propose two custom, reinforcement-learning-based schedulers, SDQN and SDQN-n, both built on the Deep Q-Network (DQN) framework. In compute-intensive scenarios, these models outperform the default Kubernetes scheduler as well as Transformer-and LSTM-based alternatives, reducing average CPU utilization per cluster node by 10%, and by over 20% when using SDQN-n. Moreover, our results show that SDQN-n approach of consolidating pods onto fewer nodes further amplifies resource savings and helps advance greener, more energy-efficient data centers.Therefore, pod scheduling must employ different strategies tailored to each scenario in order to achieve better performance.Since the reinforcement-learning components of the SDQN and SDQN-n architectures proposed in this paper can be easily tuned by adjusting their parameters, they can accommodate the requirements of various future scenarios."
  },
  {
    "date": "2026-01-20",
    "title": "FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning",
    "authors": "Qian Feng, JiaHang Tu, Mintong Kang, Hanbin Zhao, Chao Zhang, Hui Qian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13578v1",
    "source": "arXiv",
    "abstract": "Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \\textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\\textbf{F}eature-\\textbf{G}radient \\textbf{Or}thogonality for \\textbf{I}ncremental \\textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method."
  },
  {
    "date": "2026-01-20",
    "title": "Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews",
    "authors": "Thanh-Lam T. Nguyen, Ngoc-Quang Le, Quoc-Trung Phu, Thi-Phuong Le, Ngoc-Huyen Pham, Phuong-Nguyen Nguyen, Hoang-Quynh Le",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13575v1",
    "source": "arXiv",
    "abstract": "Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research."
  },
  {
    "date": "2026-01-20",
    "title": "DRGW: Learning Disentangled Representations for Robust Graph Watermarking",
    "authors": "Jiasen Li, Yanwei Liu, Zhuoyi Shang, Xiaoyan Gu, Weiping Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13569v1",
    "source": "arXiv",
    "abstract": "Graph-structured data is foundational to numerous web applications, and watermarking is crucial for protecting their intellectual property and ensuring data provenance. Existing watermarking methods primarily operate on graph structures or entangled graph representations, which compromise the transparency and robustness of watermarks due to the information coupling in representing graphs and uncontrollable discretization in transforming continuous numerical representations into graph structures. This motivates us to propose DRGW, the first graph watermarking framework that addresses these issues through disentangled representation learning. Specifically, we design an adversarially trained encoder that learns an invariant structural representation against diverse perturbations and derives a statistically independent watermark carrier, ensuring both robustness and transparency of watermarks. Meanwhile, we devise a graph-aware invertible neural network to provide a lossless channel for watermark embedding and extraction, guaranteeing high detectability and transparency of watermarks. Additionally, we develop a structure-aware editor that resolves the issue of latent modifications into discrete graph edits, ensuring robustness against structural perturbations. Experiments on diverse benchmark datasets demonstrate the superior effectiveness of DRGW."
  },
  {
    "date": "2026-01-20",
    "title": "Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework",
    "authors": "Yanheng Li, Zhichen Pu, Lijiang Yang, Zehao Zhou, Yi Qin Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13564v1",
    "source": "arXiv",
    "abstract": "Designing fluorescent small molecules with tailored optical and physicochemical properties requires navigating vast, underexplored chemical space while satisfying multiple objectives and constraints. Conventional generate-score-screen approaches become impractical under such realistic design specifications, owing to their low search efficiency, unreliable generalizability of machine-learning prediction, and the prohibitive cost of quantum chemical calculation. Here we present LUMOS, a data-and-physics driven framework for inverse design of fluorescent molecules. LUMOS couples generator and predictor within a shared latent representation, enabling direct specification-to-molecule design and efficient exploration. Moreover, LUMOS combines neural networks with a fast time-dependent density functional theory (TD-DFT) calculation workflow to build a suite of complementary predictors spanning different trade-offs in speed, accuracy, and generalizability, enabling reliable property prediction across diverse scenarios. Finally, LUMOS employs a property-guided diffusion model integrated with multi-objective evolutionary algorithms, enabling de novo design and molecular optimization under multiple objectives and constraints. Across comprehensive benchmarks, LUMOS consistently outperforms baseline models in terms of accuracy, generalizability and physical plausibility for fluorescence property prediction, and demonstrates superior performance in multi-objective scaffold- and fragment-level molecular optimization. Further validation using TD-DFT and molecular dynamics (MD) simulations demonstrates that LUMOS can generate valid fluorophores that meet various target specifications. Overall, these results establish LUMOS as a data-physics dual-driven framework for general fluorophore inverse design."
  },
  {
    "date": "2026-01-20",
    "title": "ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits",
    "authors": "Aryan Karmore",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13563v1",
    "source": "arXiv",
    "abstract": "Linear memory scaling stores $N$ independent expert weight matrices requiring $\\mathcal{O}(N \\cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\\mathcal{O}(d^2 + N \\cdot d \\log d)$ memory -- sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150 times memory reduction at 256 experts with negligible accuracy loss. This allows 64 experts to fit on 4GB devices compared to standard MoE's 8 experts, showing geometric parametrization breaks linear scaling."
  },
  {
    "date": "2026-01-20",
    "title": "Reasoning is a Modality",
    "authors": "Zhiguang Liu, Yi Shang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13562v1",
    "source": "arXiv",
    "abstract": "The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning."
  },
  {
    "date": "2026-01-20",
    "title": "Additive-Functional Approach to Transport in Periodic and Tilted Periodic Potentials",
    "authors": "Sang Yang, Zhixin Peng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13561v1",
    "source": "arXiv",
    "abstract": "We present a unified theoretical framework for effective transport in periodic and tilted periodic potentials based on additive functionals of stochastic processes. By systematically combining the Poisson equation, corrector construction, and martingale decomposition, we show that both the long-time drift and diffusion of overdamped Brownian motion can be derived within a single and transparent scheme. In the absence of external tilt, the formalism naturally recovers the classical Lifson-Jackson formula for the effective diffusion coefficient. When a constant bias is applied, breaking detailed balance and inducing a finite stationary current, the same approach yields the Stratonovich expressions for the effective drift and diffusion in tilted periodic potentials. Beyond one dimension, we demonstrate that the same additive-functional structure extends directly to two-dimensional and general N dimensional periodic diffusions, leading to the standard homogenized drift and diffusion tensor expressed in terms of vector-valued correctors. Our derivation highlights the central role of additive functionals in separating bounded microscopic corrections from unbounded macroscopic transport and clarifies the connection between reversible and nonequilibrium steady states. This work provides a conceptually unified and mathematically controlled route to transport coefficients in periodic media, with direct relevance to stochastic transport, soft matter, and nonequilibrium statistical physics."
  },
  {
    "date": "2026-01-20",
    "title": "Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis",
    "authors": "Mehrab Beikzadeh, Chenglin Hong, Cory J Cascalheira, Callisto Boka, Majid Sarrafzadeh, Ian W Holloway",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13558v1",
    "source": "arXiv",
    "abstract": "Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM."
  },
  {
    "date": "2026-01-20",
    "title": "Mirror construction of Hecke correspondence between Nakajima quiver varieties",
    "authors": "Siu-Cheong Lau, Ju Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13555v1",
    "source": "arXiv",
    "abstract": "Nakajima constructed geometric representations of a deformed Kac-Moody Lie algebra using Hecke correspondences between quiver varieties. In this paper, we show that Hecke correspondences, which are holomorphic Lagrangians in products of Nakajima quiver varieties, can be obtained by applying the localized mirror construction to the morphism spaces between families of framed Lagrangian branes supported on the core of a plumbing of two-spheres. Moreover, for a non-ADE quiver, we show that the localized mirror functor is fully-faithful."
  },
  {
    "date": "2026-01-20",
    "title": "HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations",
    "authors": "Yujia Hu, Roy Ka-Wei Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13547v1",
    "source": "arXiv",
    "abstract": "Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \\textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \\textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \\textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation. \\textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}"
  },
  {
    "date": "2026-01-20",
    "title": "A hybrid numerical method for a microscopic and macroscopic traffic flow model",
    "authors": "Yuanhong Wu, Shuzhi Liu, Qinglong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13541v1",
    "source": "arXiv",
    "abstract": "In this paper, we introduce a traffic flow model based on a microscopic follow-the-leader model, while enforcing maximal constraints on the density and velocity of the flow. The related macroscopic model can be represented in conservative formulation. By introducing an advected variable up with the flow, where p is the velocity offset, and u is the relative velocity, we reformulate the classical Aw-Rascle-Zhang (ARZ) model and the modified Aw-Rascle model to describe a realistic fundamental diagrams. The elementary waves are derived, and the Riemann problem is solved to validate the model's theoretical consistency. We further extend to a two-dimensional model. Numerical simulations are given for both one-and two-dimensional case by using the hybrid Godunov-Glimm scheme to verify the model's performance."
  },
  {
    "date": "2026-01-20",
    "title": "Sparse Identification of Nonlinear Distributed-Delay Dynamics via the Linear Chain Trick",
    "authors": "Mohammed Alanazi, Majid Bani-Yaghoub",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13536v1",
    "source": "arXiv",
    "abstract": "The Sparse Identification of Nonlinear Dynamics (SINDy) framework has been frequently used to discover parsimonious differential equations governing natural and physical systems. This includes recent extensions to SINDy that enable the recovery of discrete delay differential equations, where delay terms are represented explicitly in the candidate library. However, such formulations cannot capture the distributed delays that naturally arise in biological, physical, and engineering systems. In the present work, we extend SINDy to identify distributed-delay differential equations by incorporating the Linear Chain Trick (LCT), which provides a finite-dimensional ordinary differential equation representing the distributed memory effects. Hence, SINDy can operate in an augmented state space using conventional sparse regression while preserving a clear interpretation of delayed influences via the chain trick. From time-series data, the proposed method jointly infers the governing equations, the mean delay, and the dispersion of the underlying delay distribution. We numerically verify the method on several models with distributed delay, including the logistic growth model and a Hes1--mRNA gene regulatory network model. We show that the proposed method accurately reconstructs distributed delay dynamics, remains robust under noise and sparse sampling, and provides a transparent, data-driven approach for discovering nonlinear systems with distributed-delay."
  },
  {
    "date": "2026-01-20",
    "title": "ICASSP 2026 URGENT Speech Enhancement Challenge",
    "authors": "Chenda Li, Wei Wang, Marvin Sach, Wangyou Zhang, Kohei Saijo, Samuele Cornell, Yihui Fu, Zhaoheng Ni, Tim Fingscheidt, Shinji Watanabe, Yanmin Qian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13531v1",
    "source": "arXiv",
    "abstract": "The ICASSP 2026 URGENT Challenge advances the series by focusing on universal speech enhancement (SE) systems that handle diverse distortions, domains, and input conditions. This overview paper details the challenge's motivation, task definitions, datasets, baseline systems, evaluation protocols, and results. The challenge is divided into two complementary tracks. Track 1 focuses on universal speech enhancement, while Track 2 introduces speech quality assessment for enhanced speech. The challenge attracted over 80 team registrations, with 29 submitting valid entries, demonstrating significant community interest in robust SE technologies."
  },
  {
    "date": "2026-01-20",
    "title": "Categorical Entropies of Hilbert Schemes of Points on Surfaces and Hyperkähler Manifolds",
    "authors": "Tomoki Yoshida",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13526v1",
    "source": "arXiv",
    "abstract": "This paper studies the categorical entropy of autoequivalences of derived categories of Hilbert schemes of points on surfaces and hyperkähler manifolds. One of the central questions about categorical entropy is whether it satisfies a Gromov-Yomdin type formula $h_{\\mathrm{cat}}(Φ) = \\logρ(Φ)$. We say that $X$ has the Gromov-Yomdin (GY) property if this formula holds. We prove that if a surface $S$ fails to satisfy the (GY) property (e.g., K3 surfaces), then so does $\\mathrm{Hilb}^n(S)$. Moreover, we show that no hyperkähler or Enriques manifold satisfies the (GY) property by constructing an explicit autoequivalence with positive categorical entropy but unipotent action on the cohomology ring."
  },
  {
    "date": "2026-01-20",
    "title": "StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing",
    "authors": "Shuang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13522v1",
    "source": "arXiv",
    "abstract": "Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines."
  },
  {
    "date": "2026-01-20",
    "title": "Small Gradient Norm Regret for Online Convex Optimization",
    "authors": "Wenzhi Gao, Chang He, Madeleine Udell",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13519v1",
    "source": "arXiv",
    "abstract": "This paper introduces a new problem-dependent regret measure for online convex optimization with smooth losses. The notion, which we call the $G^\\star$ regret, depends on the cumulative squared gradient norm evaluated at the decision in hindsight $\\sum_{t=1}^T \\|\\nabla \\ell(x^\\star)\\|^2$. We show that the $G^\\star$ regret strictly refines the existing $L^\\star$ (small loss) regret, and that it can be arbitrarily sharper when the losses have vanishing curvature around the hindsight decision. We establish upper and lower bounds on the $G^\\star$ regret and extend our results to dynamic regret and bandit settings. As a byproduct, we refine the existing convergence analysis of stochastic optimization algorithms in the interpolation regime. Some experiments validate our theoretical findings."
  },
  {
    "date": "2026-01-20",
    "title": "From \"Fail Fast\" to \"Mature Safely:\" Expert Perspectives as Secondary Stakeholders on Teen-Centered Social Media Risk Detection",
    "authors": "Renkai Ma, Ashwaq Alsoubai, Jinkyung Katie Park, Pamela J. Wisniewski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13516v1",
    "source": "arXiv",
    "abstract": "In addressing various risks on social media, the HCI community has advocated for teen-centered risk detection technologies over platform-based, parent-centered features. However, their real-world viability remains underexplored by secondary stakeholders beyond the family unit. Therefore, we present an evaluation of a teen-centered social media risk detection dashboard through online interviews with 33 online safety experts. While experts praised our dashboard's clear design for teen agency, their feedback revealed five primary tensions in implementing and sustaining such technology: objective vs. context-dependent risk definition, informing risks vs. meaningful intervention, teen empowerment vs. motivation, need for data vs. data privacy, and independence vs. sustainability. These findings motivate us to rethink \"teen-centered\" and a shift from a \"fail fast\" to a \"mature safely\" paradigm for youth safety technology innovation. We offer design implications for addressing these tensions before system deployment with teens and strategies for aligning secondary stakeholders' interests to deploy and sustain such technologies in the broader ecosystem of youth online safety."
  },
  {
    "date": "2026-01-20",
    "title": "Gigahertz-frequency Lamb wave resonator cavities on suspended lithium niobate for quantum acoustics",
    "authors": "Michele Diego, Hong Qiao, Byunggi Kim, Minseok Ryu, Shiheng Li, Gustav Andersson, Masahiro Nomura, Andrew N. Cleland",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13509v1",
    "source": "arXiv",
    "abstract": "Phononic nanodevices offer a promising route toward quantum technologies, as phonons combine strong confinement within matter with broad coupling capabilities to various quantum systems. In particular, the piezoelectric response of materials such as lithium niobate enables coupling between superconducting qubits and gigahertz-frequency phonons. However, bulk lithium niobate phononic devices typically rely on surface acoustic waves and are therefore inherently subject to leakage from the surface into the bulk substrate. Here, we explore the acoustic behavior of resonator cavities supporting GHz-frequency Lamb waves in a 200 nm-thick suspended lithium niobate layer. We characterize the acoustic response at both room and millikelvin temperatures. We find that our resonator cavities with strong confinement reach intrinsic quality factors of approximately 6000 at the single phonon level. We use the measured parameters of the resonators to model their coupling to a superconducting transmon qubit, allowing us to evaluate their potential as quantum acoustic devices."
  },
  {
    "date": "2026-01-20",
    "title": "CatMaster: An Agentic Autonomous System for Computational Heterogeneous Catalysis Research",
    "authors": "Honghao Chen, Jiangjie Qiu, Yi Shen Tew, Xiaonan Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13508v1",
    "source": "arXiv",
    "abstract": "Density functional theory (DFT) is widely used to connect atomic structure with catalytic behavior, but computational heterogeneous catalysis studies often require long workflows that are costly, iterative, and sensitive to setup choices. Besides the intrinsic cost and accuracy limits of first-principles calculations, practical workflow issues such as keeping references consistent, preparing many related inputs, recovering from failed runs on computing clusters, and maintaining a complete record of what was done, can slow down projects and make results difficult to reproduce or extend. Here we present CatMaster, a large-language-model (LLM)-driven agent system that turns natural language requests into complete calculation workspaces, including structures, inputs, outputs, logs, and a concise run record. CatMaster maintains a persistent project record of key facts, constraints, and file pointers to support inspection and restartability. It is paired with a multi-fidelity tool library that covers rapid surrogate relaxations and high-fidelity DFT calculations for validation when needed. We demonstrate CatMaster on four demonstrations of increasing complexity: an O2 spin-state check with remote execution, BCC Fe surface energies with a protocol-sensitivity study and CO adsorption site ranking, high-throughput Pt--Ni--Cu alloy screening for hydrogen evolution reaction (HER) descriptors with surrogate-to-DFT validation, and a demonstration beyond the predefined tool set, including equation-of-state fitting for BCC Fe and CO-FeN4-graphene single-atom catalyst geometry preparation. By reducing manual scripting and bookkeeping while keeping the full evidence trail, CatMaster aims to help catalysis researchers focus on modeling choices and chemical interpretation rather than workflow management."
  },
  {
    "date": "2026-01-20",
    "title": "Two-stage least squares with clustered data",
    "authors": "Anqi Zhao, Peng Ding, Fan Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13507v1",
    "source": "arXiv",
    "abstract": "Clustered data -- where units of observation are nested within higher-level groups, such as repeated measurements on users, or panel data of firms, industries, or geographic regions -- are ubiquitous in business research. When the objective is to estimate the causal effect of a potentially endogenous treatment, a common approach -- which we call the canonical two-stage least squares (2sls) -- is to fit a 2sls regression of the outcome on treatment status with instrumental variables (IVs) for point estimation, and apply cluster-robust standard errors to account for clustering in inference. When both the treatment and IVs vary within clusters, a natural alternative -- which we call the two-stage least squares with fixed effects (2sfe) -- is to include cluster indicators in the 2sls specification, thereby incorporating cluster information in point estimation as well. This paper clarifies the trade-off between these two approaches within the local average treatment effect (LATE) framework, and makes three contributions. First, we establish the validity of both approaches for Wald-type inference of the LATE when clusters are homogeneous, and characterize their relative efficiency. We show that, when the true outcome model includes cluster-specific effects, 2sfe is more efficient than the canonical 2sls only when the variation in cluster-specific effects dominates that in unit-level errors. Second, we show that with heterogeneous clusters, 2sfe recovers a weighted average of cluster-specific LATEs, whereas the canonical 2sls generally does not. Third, to guide empirical choice between the two procedures, we develop a joint asymptotic theory for the two estimators under homogeneous clusters, and propose a Wald-type test for detecting cluster heterogeneity."
  },
  {
    "date": "2026-01-20",
    "title": "Group Relative Policy Optimization for Robust Blind Interference Alignment with Fluid Antennas",
    "authors": "Jianqiu Peng, Tong Zhang, Shuai Wang, Mingjie Shao, Hao Xu, Rui Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13506v1",
    "source": "arXiv",
    "abstract": "Fluid antenna system (FAS) leverages dynamic reconfigurability to unlock spatial degrees of freedom and reshape wireless channels. This paper proposes, for the first time, a robust fluid antenna-driven blind interference alignment (BIA) framework for a K-user MISO downlink under imperfect channel state information (CSI). We formulate a robust sum-rate maximization problem through optimizing fluid antenna positions. To solve this challenging non-convex problem, we employ group relative policy optimization (GRPO), a novel deep reinforcement learning algorithm that eliminates the critic network. This robust design reduces model size and floating point operations (FLOPs) by nearly half compared to proximal policy optimization (PPO) while significantly enhancing performance through group-based exploration that escapes bad local optima. Simulation results demonstrate that GRPO outperforms PPO by 4.17%, and a 100K-step pre-trained PPO by 30.29%. Due to error distribution learning, GRPO exceeds heuristic MaximumGain and RandomGain by 200.78% and 465.38%, respectively."
  },
  {
    "date": "2026-01-20",
    "title": "Integrating Vision-Centric Text Understanding for Conversational Recommender Systems",
    "authors": "Wei Yuan, Shutong Qiao, Tong Chen, Quoc Viet Hung Nguyen, Zi Huang, Hongzhi Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13505v1",
    "source": "arXiv",
    "abstract": "Conversational Recommender Systems (CRSs) have attracted growing attention for their ability to deliver personalized recommendations through natural language interactions. To more accurately infer user preferences from multi-turn conversations, recent works increasingly expand conversational context (e.g., by incorporating diverse entity information or retrieving related dialogues). While such context enrichment can assist preference modeling, it also introduces longer and more heterogeneous inputs, leading to practical issues such as input length constraints, text style inconsistency, and irrelevant textual noise, thereby raising the demand for stronger language understanding ability. In this paper, we propose STARCRS, a Screen-Text-AwaRe Conversational Recommender System that integrates two complementary text understanding modes: (1) a screen-reading pathway that encodes auxiliary textual information as visual tokens, mimicking skim reading on a screen, and (2) an LLM-based textual pathway that focuses on a limited set of critical content for fine-grained reasoning. We design a knowledge-anchored fusion framework that combines contrastive alignment, cross-attention interaction, and adaptive gating to integrate the two modes for improved preference modeling and response generation. Extensive experiments on two widely used benchmarks demonstrate that STARCRS consistently improves both recommendation accuracy and generated response quality."
  },
  {
    "date": "2026-01-20",
    "title": "Initial Investigations of the Outskirts of XLSSC 122",
    "authors": "Eleanore. B. Todd, Jon. P. Willis, Rebecca. E. A. Canning, Ophélie. K. Leste, Rahma. Alfarsy, Steven W. Allen, Gabriel Brammer, Joseph. N. Burchett, Adam. B. Mantz, Spencer. A. Stanford",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13492v1",
    "source": "arXiv",
    "abstract": "We investigate the redshift 1.98 galaxy cluster XLSSC 122 using the Hubble Space Telescope (HST) from the core of the cluster out to 3 Mpc, a scale equivalent to 10 times the R500 = 295 kpc radius. We present an expanded photometric and spectroscopic catalogue of the cluster, bringing the total number of spectroscopically classified member galaxies to 74, with 35 new member galaxies added in the outer regions of the cluster. We compute the radial galaxy number density profile in the cluster, and observe no clear evidence of infalling groups or cosmic filaments. We observe a clear bimodal colour relation in member galaxies, with red fraction increasing towards the cluster centre. This rapid increase of red fraction upon infall is indicative of a fast quenching mechanism, such as ram pressure stripping, as galaxies enter the cluster centre. We fit a luminosity function to the cluster members, finding a similar low mass slope but fainter scale magnitude than z = 1 clusters of similar temperature, implying a similar galaxy evolution rate to clusters at lower redshift."
  },
  {
    "date": "2026-01-20",
    "title": "Noncommutative Minkowski integral inequality and a unitary categorification criterion for fusion rings",
    "authors": "Junhwi Lim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13490v1",
    "source": "arXiv",
    "abstract": "We prove a noncommutative analogue of Minkowski's integral inequality for commuting squares of tracial von Neumann algebras. The inequality implies a necessary condition for a quadruple of graphs to be realized as inclusion graphs of a commuting square of multi-matrix algebras. As a corollary, we obtain a unitary categorification criterion for based rings, in particular, fusion rings."
  },
  {
    "date": "2026-01-20",
    "title": "Self-Supervised Learning of Parametric Approximation for Security-Constrained DC-OPF",
    "authors": "Anderson Anrrango, André Quisaguano, Gonzalo E. Constante-Flores, Can Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13486v1",
    "source": "arXiv",
    "abstract": "This paper introduces a self-supervised learning framework for approximating the Security-Constrained DC Optimal Power Flow (SC-DCOPF) problem using a parametric linear model. The approach preserves the physical structure of the DC-OPF while incorporating demand-dependent tunable parameters that scale transmission line limits. These parameters are predicted via a Graph Neural Network and optimized through differentiable layers, enabling direct training from contingency costs without requiring labeled data. The framework integrates pre- and post-contingency optimization layers into an implicit loss function. Numerical experiments on benchmark systems demonstrate that the proposed method achieves high dispatch accuracy, low cost approximation error, and strong data efficiency, outperforming semi-supervised and end-to-end baselines. This scalable and interpretable approach offers a promising solution for real-time secure power system operations."
  },
  {
    "date": "2026-01-20",
    "title": "Spectrum & RAN Sharing: A Measurement-based Case Study of Commercial 5G Networks in Spain",
    "authors": "Rostand A. K. Fezeu, Lilian C. Freitas, Eman Ramadan, Jason Carpenter, Claudio Fiandrino, Joerg Widmer, Zhi-Li Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13484v1",
    "source": "arXiv",
    "abstract": "Radio Access Network (RAN) sharing, which often also includes spectrum sharing, is a strategic cooperative agreement among two or more mobile operators, where one operator may use another's RAN infrastructure to provide mobile services to its users. By mutually sharing physical sites, radio elements, licensed spectrum and other parts of the RAN infrastructure, participating operators can significantly reduce the capital (and operational) expenditure in deploying and operating cellular networks, while accelerating coverage expansion -- thereby addressing the spectrum scarcity and infrastructure cost challenges in the 5G era and beyond. While the economic benefits of RAN sharing are well understood, the impact of such resource pooling on user-perceived performance remains underexplored, especially in real-world commercial deployments. We present, to the best of our knowledge, the first empirical measurement study of commercial 5G spectrum and RAN sharing. Our measurement study is unique in that, beyond identifying real-world instances of shared 5G spectrum and RAN deployment \"in the wild\", we also analyze users' perceived performance and its implication on Quality of Experience (QoE). Our study provides critical insights into resource management (i.e., pooling) and spectrum efficiency, offering a blueprint (and implications) for network evolution in 5G, 6G and beyond."
  },
  {
    "date": "2026-01-20",
    "title": "iCanonical basis arising from quasi-split rank one iquantum group",
    "authors": "Ziming Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13482v1",
    "source": "arXiv",
    "abstract": "We compute icanonical basis of the quasi-split rank one modified iquantum group, by obtaining explicit transition matrices among the icanonical basis, monomial basis, and standardized canonical basis; all these bases can be naturally categorified. These transition matrices follow from their counterparts computed in this paper among the icanonical basis, monomial basis, and canonical basis on simple finite-dimensional modules of quantum $\\mathfrak{sl}_3$."
  },
  {
    "date": "2026-01-20",
    "title": "Exploring Learners' Expectations and Engagement When Collaborating with Constructively Controversial Peer Agents",
    "authors": "Thitaree Tanprasert, Young-ho Kim, Sidney Fels, Dongwook Yoon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13479v1",
    "source": "arXiv",
    "abstract": "Peer agents can supplement real-time collaborative learning in asynchronous online courses. Constructive Controversy (CC) theory suggests that humans deepen their understanding of a topic by confronting and resolving controversies. This study explores whether CC's benefits apply to LLM-based peer agents, focusing on the impact of agents' disputatious behaviors and disclosure of agents' behavior designs on the learning process. In our mixed-method study (n=144), we compare LLMs that follow detailed CC guidelines (regulated) to those guided by broader goals (unregulated) and examine the effects of disclosing the agents' design to users (transparent vs. opaque). Findings show that learners' values influence their agent interaction: those valuing control appreciate unregulated agents' willingness to cease push-back upon request, while those valuing intellectual challenges favor regulated agents for stimulating creativity. Additionally, design transparency lowers learners' perception of agents' abilities. Our findings lay the foundation for designing effective collaborative peer agents in isolated educational settings."
  },
  {
    "date": "2026-01-20",
    "title": "A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model",
    "authors": "Jinhao Li, Hao Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13476v1",
    "source": "arXiv",
    "abstract": "The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, hinges on the availability of complete, high-quality charging data. However, real-world EV datasets are often plagued by missing records, and existing imputation methods are ill-equipped for the complex, multimodal context of charging data, often relying on a restrictive one-model-per-station paradigm that ignores valuable inter-station correlations. To address these gaps, we develop a novel PRobabilistic variational imputation framework that leverages the power of large lAnguage models and retrIeval-augmented Memory (PRAIM). PRAIM employs a pre-trained language model to encode heterogeneous data, spanning time-series demand, calendar features, and geospatial context, into a unified, semantically rich representation. This is dynamically fortified by retrieval-augmented memory that retrieves relevant examples from the entire charging network, enabling a single, unified imputation model empowered by variational neural architecture to overcome data sparsity. Extensive experiments on four public datasets demonstrate that PRAIM significantly outperforms established baselines in both imputation accuracy and its ability to preserve the original data's statistical distribution, leading to substantial improvements in downstream forecasting performance."
  },
  {
    "date": "2026-01-20",
    "title": "On Thermalization in A Nonlinear Variant of the Discrete NLS Equation",
    "authors": "Yagmur Kati, Aleksandra Maluckov, Ana Mancic, Panayotis Kevrekidis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13472v1",
    "source": "arXiv",
    "abstract": "We study the thermalization properties of a fully nonlinear lattice model originally derived from the two-dimensional cubic defocusing nonlinear Schrödinger equation (NLS) using analytical and numerical methods. Our analysis reveals both ergodic and nonergodic regimes; importantly, we find broad parameter ranges where the dynamics is ergodic even though it lies outside the Gibbsian parameter regime (for both $D=0.25$ and $D=2$), and a higher-energy range where ergodicity breaks down. We observe that in a certain range of parameters, the system requires non-standard statistical descriptions, indicating a breakdown of conventional thermalization. We examine the influence of the nonlinear dispersion parameter $D$ on the system's behavior, showing that increasing $D$ enhances fluctuations and speeds up the crossover of $q(T)$ toward the $\\sim 1/T$ scaling. By analyzing excursion times, probability density functions, and localization patterns, we characterize transitions between ergodic and nonergodic behavior. In long-time numerical simulations within the non-ergodic regime for $D>1$, stable localization over two sites is observed, while $D<1$ favors single-site localization in the high energy density regimes. Our results provide insights into the interplay between thermalization, localization, and non-standard statistical behavior in genuinely nonlinear systems."
  },
  {
    "date": "2026-01-20",
    "title": "Implicit Neural Representation Facilitates Unified Universal Vision Encoding",
    "authors": "Matthew Gwilliam, Xiao Wang, Xuefeng Hu, Zhenheng Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14256v1",
    "source": "arXiv",
    "abstract": "Models for image representation learning are typically designed for either recognition or generation. Various forms of contrastive learning help models learn to convert images to embeddings that are useful for classification, detection, and segmentation. On the other hand, models can be trained to reconstruct images with pixel-wise, perceptual, and adversarial losses in order to learn a latent space that is useful for image generation. We seek to unify these two directions with a first-of-its-kind model that learns representations which are simultaneously useful for recognition and generation. We train our model as a hyper-network for implicit neural representation, which learns to map images to model weights for fast, accurate reconstruction. We further integrate our INR hyper-network with knowledge distillation to improve its generalization and performance. Beyond the novel training design, the model also learns an unprecedented compressed embedding space with outstanding performance for various visual tasks. The complete model competes with state-of-the-art results for image representation learning, while also enabling generative capabilities with its high-quality tiny embeddings. The code is available at https://github.com/tiktok/huvr."
  },
  {
    "date": "2026-01-20",
    "title": "Identification capacity and rate-query tradeoffs in classification systems",
    "authors": "Tristan Simas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14252v1",
    "source": "arXiv",
    "abstract": "We study a one-shot identification analogue of rate-distortion for discrete classification under three resources: tag rate L (bits of side information stored per entity), identification cost W (attribute-membership queries per identification, excluding global preprocessing and amortized caching), and distortion D (misclassification probability). The question is to characterize achievable triples (L,W,D) when a decoder must recover an entity's class from limited observations. Zero-error barrier. If two distinct classes induce the same attribute profile, then the observation pi(V) is identical for both and no decoder can identify the class from attribute queries alone. Thus, if the profile map pi is not injective on classes, zero-error identification without tags is impossible (a zero-error feasibility threshold). Achievability and converse at D=0. With k classes, nominal tags of L = ceil(log2 k) bits enable O(1) identification cost with D=0. Conversely, any scheme with D=0 must satisfy L >= log2 k bits (tight). Without tags (L=0), identification requires Omega(n) queries in the worst case and may incur D>0. Combinatorial structure. Minimal sufficient query families form the bases of a matroid; the induced distinguishing dimension is well-defined and links to zero-error source coding via graph entropy. We illustrate implications for type systems, databases, and biological taxonomy. All results are mechanized in Lean4 (6000+ lines, 0 sorry)."
  },
  {
    "date": "2026-01-20",
    "title": "Detecting Limit Tori in Non-Smooth Systems: An Analytic Approach with Applications to 3D Piecewise Linear Systems",
    "authors": "Murilo R. Cândido, Douglas D. Novaes, Joan S. G. Rivera",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14247v1",
    "source": "arXiv",
    "abstract": "This work investigates a class of non-autonomous $T$-periodic piecewise smooth differential systems and their associated time-$T$ maps. Our main result provides an analytical approach for detecting, within this class of piecewise differential systems, isolated invariant tori associated with normally hyperbolic invariant closed curves of the time-$T$ map. To achieve this, we derive sufficient conditions under which smooth near-identity maps undergo a Neimark--Sacker bifurcation. As an application of our main result, we present a family of 3D piecewise linear differential systems exhibiting attracting and repelling isolated invariant tori which, moreover, persist under small perturbations. To the best of our knowledge, this family provides the first examples in which limit tori are analytically detected in piecewise linear systems."
  },
  {
    "date": "2026-01-20",
    "title": "Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow",
    "authors": "Haocheng Xi, Charlie Ruan, Peiyuan Liao, Yujun Lin, Han Cai, Yilong Zhao, Shuo Yang, Kurt Keutzer, Song Han, Ligeng Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14243v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation."
  },
  {
    "date": "2026-01-20",
    "title": "Peculiar velocity fields from analytic solutions of General Relativity",
    "authors": "Roberto A. Sussman, Sebastián Nájera, Fernando A. Pizaña, Juan Carlos Hidalgo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14239v1",
    "source": "arXiv",
    "abstract": "Peculiar velocities are analyzed through cosmological perturbations in the Newtonian longitudinal gauge characterized by irrotational shear-free congruences in an Eulerian frame. We show that non-trivial peculiar velocity fields can be generated through Lorentzian boosts in the non-relativistic limit, where the Eulerian frame is obtained from analytic solutions of Einstein's equations sourced by an irrotational shear-free fluid with nonzero energy flux. This approach provides a physically viable interpretation of these analytic solutions, which (in general) admit no isometries, thus allowing, in principle, for modeling time and space varying 3-dimensional fields of peculiar velocities that can be contrasted with observational data on our local cosmography. As a ``proof of concept'' we examine the peculiar velocities of varying dark matter and dark energy perfect fluids with respect to the CMB frame using a simple, spherically symmetric particular solution. The resulting peculiar velocities are qualitatively compatible with observational data on the CMB dipole."
  },
  {
    "date": "2026-01-20",
    "title": "Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression",
    "authors": "Shaurya Mathur, Shreyas Bellary Manjunath, Nitin Kulkarni, Alina Vereshchaka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14238v1",
    "source": "arXiv",
    "abstract": "Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \\textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl."
  },
  {
    "date": "2026-01-20",
    "title": "Partial Linearity in Categories",
    "authors": "Roy Ferguson, Zurab Janelidze",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14237v1",
    "source": "arXiv",
    "abstract": "In this paper we study partial linearity in a category by replacing isomorphism between coproducts and products in a linear category with isomorphism between suitable monoidal structures on a category. The main results a coherence theorem and a generalization of the theory of central morphisms from unital categories to our context of partial linearity"
  },
  {
    "date": "2026-01-20",
    "title": "Q-learning with Adjoint Matching",
    "authors": "Qiyang Li, Sergey Levine",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14234v1",
    "source": "arXiv",
    "abstract": "We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL."
  },
  {
    "date": "2026-01-20",
    "title": "Decoupling of large-scale, adiabatic inflationary perturbations from enhanced small-scale modes at one-loop",
    "authors": "Laura Iacconi, David Mulryne, David Seery",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14229v1",
    "source": "arXiv",
    "abstract": "We reconsider back-reaction from large amplitude, short-scale perturbations onto a long wavelength adiabatic mode. In a loop expansion of the long-mode power spectrum, this back-reaction appears first at 1-loop. Due to the separation between the long and short scales, the separate universe method provides a simple and efficient framework for this computation. In this paper, building on our earlier work, we employ a $δN$ formula for the long mode, which captures the effect of short scales. We show that back-reaction at 1-loop is due to either (i) non-linearity of the $δN$ formula, or (ii) 1-loop corrections to the initial conditions. We argue that contributions of type (ii) cannot themselves be described within the separate universe framework, but their properties can be constrained using soft theorems and a ''multi-point propagator'' expansion. When applied to a band of enhanced short-scale perturbations that crossed the horizon during inflation, our result shows that the loop correction decouples from their detailed properties. Furthermore, the back-reaction we obtain is scale-invariant. Its magnitude is model-dependent, but is degenerate with effects from modes that were still sub-horizon at the end of inflation. In this scenario (but not necessarily in all scenarios), we conclude that the effect is not observable."
  },
  {
    "date": "2026-01-20",
    "title": "The [Fe XIII] Infrared 10747 Angstrom and 10798 Angstrom Lines in Novae",
    "authors": "D. P. K. Banerjee, C. E. Woodward, A. Evans, T. R. Geballe, V. Joshi, S. Starrfield",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14218v1",
    "source": "arXiv",
    "abstract": "The forbidden lines of [Fe XIII] at 10,747 Angstrom and 10,798 Angsrtom are among the most prominent lines in the near-infrared spectrum of the solar corona. They have been used routinely, both outside and during eclipses, as sensitive probes of the electron density and polarization in the solar corona. Many novae pass through a coronal phase, wherein the highly ionized nova ejecta have physical conditions that are remarkably similar to those of the solar corona. Many of the coronal emission lines that are seen are common to the spectra of both the Sun and novae. Yet, it appears that no robust detection of the [Fe XIII] lines has been made in a nova. Here we report the detection of these two infrared [Fe XIII]lines in the spectrum of the recurrent nova V3890 Sgr, taken 23.43 and 31.35 days after its August 2019 outburst. From their line strengths, we derive values of 10^10 per cubic cm and 10^[8.5-9] per cubic cm for the electron density on the two. The decrease in density between epochs can be explained if the density decreased with a power law n ~ r**alpha with a alpha inferred to be -3. The average temperature of the coronal gas is estimated to be T = (2.51\\pm0.06) x 10^6~K. We find that recurrent novae with giant secondaries, including T CrB whose eruption is imminent, are the most suitable sources for further detections of the [Fe XIII] lines. epochs."
  },
  {
    "date": "2026-01-20",
    "title": "Generalization and Completeness of Stochastic Local Search Algorithms",
    "authors": "Daniel Loscos, Narciso Marti-Oliet, Ismael Rodriguez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14212v1",
    "source": "arXiv",
    "abstract": "We generalize Stochastic Local Search (SLS) heuristics into a unique formal model. This model has two key components: a common structure designed to be as large as possible and a parametric structure intended to be as small as possible. Each heuristic is obtained by instantiating the parametric part in a different way. Particular instances for Genetic Algorithms (GA), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO) are presented. Then, we use our model to prove the Turing-completeness of SLS algorithms in general. The proof uses our framework to construct a GA able to simulate any Turing machine. This Turing-completeness implies that determining any non-trivial property concerning the relationship between the inputs and the computed outputs is undecidable for GA and, by extension, for the general set of SLS methods (although not necessarily for each particular method). Similar proofs are more informally presented for PSO and ACO."
  },
  {
    "date": "2026-01-20",
    "title": "Storage-Rate Trade-off in A-XPIR",
    "authors": "Mohamed Nomeir, Sennur Ulukus",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14202v1",
    "source": "arXiv",
    "abstract": "We consider the storage problem in an asymmetric $X$-secure private information retrieval (A-XPIR) setting. The A-XPIR setting considers the $X$-secure PIR problem (XPIR) when a given arbitrary set of servers is communicating. We focus on the trade-off region between the average storage at the servers and the average download cost. In the case of $N=4$ servers and two non-overlapping sets of communicating servers with $K=2$ messages, we characterize the achievable region and show that the three main inequalities compared to the no-security case collapse to two inequalities in the asymmetric security case. In the general case, we derive bounds that need to be satisfied for the general achievable region for an arbitrary number of servers and messages. In addition, we provide the storage and retrieval scheme for the case of $N=4$ servers with $K=2$ messages and two non-overlapping sets of communicating servers, such that the messages are not replicated (in the sense of a coded version of each symbol) and at the same time achieve the optimal achievable rate for the case of replication. Finally, we derive the exact capacity for the case of asymmetric security and asymmetric collusion for $N=4$ servers, with the communication links $\\{1,2\\}$ and $\\{3,4\\}$, which splits the servers into two groups, i.e., $g=2$, and with the collusion links $\\{1,3\\}$, $\\{2,4\\}$, as $C=\\frac{1}{3}$. More generally, we derive a capacity result for a certain family of asymmetric collusion and asymmetric security cases."
  },
  {
    "date": "2026-01-20",
    "title": "Factor Analysis of Multivariate Stochastic Volatility Model",
    "authors": "Taehee Lee, Jun S. Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14199v1",
    "source": "arXiv",
    "abstract": "Modeling the time-varying covariance structures of high-dimensional variables is critical across diverse scientific and industrial applications; however, existing approaches exhibit notable limitations in either modeling flexibility or inferential efficiency. For instance, change-point modeling fails to account for the continuous time-varying nature of covariance structures, while GARCH and stochastic volatility models suffer from over-parameterization and the risk of overfitting. To address these challenges, we propose a Bayesian factor modeling framework designed to enable simultaneous inference of both the covariance structure of a high-dimensional time series and its time-varying dynamics. The associated Expectation-Maximization (EM) algorithm not only features an exact, closed-form update for the M-step but also is easily generalizable to more complex settings, such as spatiotemporal multivariate factor analysis. We validate our method through simulation studies and real-data experiments using climate and financial datasets."
  },
  {
    "date": "2026-01-20",
    "title": "The nonlinear Steklov problem in outward cuspidal domains",
    "authors": "Pier Domenico Lamberti, Alexander Ukhlov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14186v1",
    "source": "arXiv",
    "abstract": "In this article, we consider the nonlinear Steklov eigenvalue problem in outward cuspidal domains. Using the compactness of the weighted trace embedding we obtain the variational characterization of the first non-trivial eigenvalue and prove the existence of a corresponding weak solution."
  },
  {
    "date": "2026-01-20",
    "title": "Wavelet-Packet Content for Positive Operators",
    "authors": "Myung-Sin Song, James F. Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14174v1",
    "source": "arXiv",
    "abstract": "We give a simple way to attach ``content\" to the nodes of a wavelet packet tree when a positive operator is given. At a fixed packet depth, the packet projections split the operator into positive pieces, and this decomposition induces a boundary measure on the packet path space, together with vector-dependent densities that show how energy is distributed across the tree. We then study a sequential extraction procedure and two depth-fixed greedy rules for choosing packet blocks, one based on trace weights and one based on Hilbert-Schmidt weights. The main results are explicit geometric decay estimates for the remainder under these greedy removals. In the Hilbert-Schmidt case we also isolate a coherence quantity that measures how close the operator is to being block-diagonal in the packet partition. We close with a concrete patch-based denoising procedure for images, where packet blocks are selected by these content weights computed from an empirical second-moment operator; the construction ensures that both the approximants and the remainders stay positive at every step."
  },
  {
    "date": "2026-01-20",
    "title": "Wasserstein distances between ERGMs and Erdős-Rényi models",
    "authors": "Vilas Winstein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14170v1",
    "source": "arXiv",
    "abstract": "Ferromagnetic exponential random graph models (ERGMs) are random graph models under which the presence of certain small structures (such as triangles) is encouraged; they can be constructed by tilting an Erdős--Rényi model by the exponential of a particular nonlinear Hamiltonian. These models are mixtures of metastable wells which each behave macroscopically like an Erdős--Rényi model, exhibiting the same laws of large numbers for subgraph counts [CD13]. However, on the microscopic scale these metastable wells are very different from Erdős--Rényi models, with the total variation distance between the two measures tending to 1 [MX23]. In this article we clarify this situation by providing a sharp (up to constants) bound on the Hamming-Wasserstein distance between the two models, which is the average number of edges at which they differ, under the coupling which minimizes this average. In particular, we show that this distance is $Θ(n^{3/2})$, quantifying exactly how these models differ. An upper bound of this form has appeared in the past [RR19], but this was restricted to the subcritical (high-temperature) regime of parameters. We extend this bound, using a new proof technique, to the supercritical (low-temperature) regime, and prove a matching lower bound which has only previously appeared in the subcritical regime of special cases of ERGMs satisfying a \"triangle-free\" condition [DF25]. To prove the lower bound in the presence of triangles, we introduce an approximation of the discrete derivative of the Hamiltonian, which controls the dynamical properties of the ERGM, in terms of local counts of triangles and wedges (two-stars) near an edge. This approximation is the main technical and conceptual contribution of the article, and we expect it will be useful in a variety of other contexts as well. Along the way, we also prove a bound on the marginal edge probability under the ERGM via a new bootstrapping argument. Such a bound has already appeared [FLSW25], but again only in the subcritical regime and using a different proof strategy."
  },
  {
    "date": "2026-01-20",
    "title": "ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction",
    "authors": "Zhenghong Li, Wensheng Cheng, Congwu Du, Yingtian Pan, Zhaozheng Yin, Haibin Ling",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14165v1",
    "source": "arXiv",
    "abstract": "Optical Doppler Tomography (ODT) is an emerging blood flow analysis technique. A 2D ODT image (B-scan) is generated by sequentially acquiring 1D depth-resolved raw A-scans (A-line) along the lateral axis (B-line), followed by Doppler phase-subtraction analysis. To ensure high-fidelity B-scan images, current practices rely on dense sampling, which prolongs scanning time, increases storage demands, and limits the capture of rapid blood flow dynamics. Recent studies have explored sparse sampling of raw A-scans to alleviate these limitations, but their effectiveness is hindered by the conservative sampling rates and the uniform modeling of flow and background signals. In this study, we introduce a novel blood flow-aware network, named ASBA (A-line ROI State space model and B-line phase Attention), to reconstruct ODT images from highly sparsely sampled raw A-scans. Specifically, we propose an A-line ROI state space model to extract sparsely distributed flow features along the A-line, and a B-line phase attention to capture long-range flow signals along each B-line based on phase difference. Moreover, we introduce a flow-aware weighted loss function that encourages the network to prioritize the accurate reconstruction of flow signals. Extensive experiments on real animal data demonstrate that the proposed approach clearly outperforms existing state-of-the-art reconstruction methods."
  },
  {
    "date": "2026-01-20",
    "title": "Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law",
    "authors": "Ali Hamza Bashir, Muhammad Rehan Khalid, Kostadin Cvejoski, Jana Birr, Jule Berghaus, Armin Berger, Sandra Halscheidt, Christian Temath, Rafet Sifa, David Berghaus",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14160v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains."
  },
  {
    "date": "2026-01-20",
    "title": "Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models",
    "authors": "Hyunjong Ok, Jaeho Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14152v1",
    "source": "arXiv",
    "abstract": "Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options."
  },
  {
    "date": "2026-01-20",
    "title": "On the Realization of Quantum State Teleportation in Proton Systems",
    "authors": "H. Witala",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14145v1",
    "source": "arXiv",
    "abstract": "We discuss how to generate entangled Bell states of two nucleons using unpolarized nucleon-nucleon scattering or the exclusive deuteron breakup reaction. We follow the the approach of Z. X. Shen et al., arXiv:2510.24325v1 [nucl-th], where Bell states were identified in unpolarized proton-proton elastic scattering. We confirm these results and show that, in the unpolarized proton-deuteron breakup reaction, it is also possible to generate proton-proton entangled Bell states in kinematically complete proton-proton quasi-free scattering (QFS) and final-state interaction (FSI) configurations. We also discuss an experimental setup that, by exploiting such entangled states, could enable the teleportation of quantum mechanical states in a three-proton system. Such an experiment requires triple coincidences among the outgoing nucleons, which precludes the use of entangled Bell states generated with extremely polarized incoming particles. Since counting rates for unpolarized reactions are much higher than for polarized ones, the present results open a pathway toward searching for signatures of quantum state teleportation in hadronic systems."
  },
  {
    "date": "2026-01-20",
    "title": "Multidimensional arrow of time",
    "authors": "Sergey G. Rubin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14134v1",
    "source": "arXiv",
    "abstract": "This paper studies the effect of extra dimensions on the arrow of time within the framework of $f(R)$ gravity. We demonstrate that the observed irreversibility of physical processes can be explained by the monotonic growth of the extra-dimensional space. Unlike traditional cosmological approaches, our model does not link the arrow of time to the entropy of matter or radiation; rather, it identifies it with the Bekenstein-Hawking-Wald entropy of the geometric background. We establish a formal relation between the volume of the multidimensional manifold and the statistical weights of its geometric states. This leads to a fundamental relationship where the flow of time is intrinsically linked to the growth of multidimensional entropy. A key consequence of our framework is that the arrow of time remains a persistent feature for a 4D observer situated on a brane, even in the complete absence of matter or radiation. This directionality is driven by the dominant entropy production in the higher-dimensional bulk, which dominates local statistical fluctuations and ensures a stable causal direction."
  },
  {
    "date": "2026-01-20",
    "title": "GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression",
    "authors": "Till Aczel, David F. Jenny, Simon Bührer, Andreas Plesner, Antonio Di Maio, Roger Wattenhofer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14130v1",
    "source": "arXiv",
    "abstract": "Neural image codecs achieve higher compression ratios than traditional hand-crafted methods such as PNG or JPEG-XL, but often incur substantial computational overhead, limiting their deployment on energy-constrained devices such as smartphones, cameras, and drones. We propose Grayscale Image Compression with Differentiable Logic Circuits (GIC-DLC), a hardware-aware codec where we train lookup tables to combine the flexibility of neural networks with the efficiency of Boolean operations. Experiments on grayscale benchmark datasets show that GIC-DLC outperforms traditional codecs in compression efficiency while allowing substantial reductions in energy consumption and latency. These results demonstrate that learned compression can be hardware-friendly, offering a promising direction for low-power image compression on edge devices."
  },
  {
    "date": "2026-01-20",
    "title": "Structural properties of graphs and the Universal Difference Property",
    "authors": "Katie Anders, Able Martinez, Patrick McHugh, Jenna Rogers, Remi Salinas Schmeis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14126v1",
    "source": "arXiv",
    "abstract": "We study the Universal Difference Property (UDP) introduced by Altınok, Anders, Arreola, Asencio, Ireland, Sarıoğlan, and Smith, focusing on the relationship between the structural properties of a graph and UDP. We present condtions for when UDP must hold on unicyclic graphs. We then prove that if UDP does not hold on an edge-labeled graph, then it cannot hold on any subdivision of that graph. Additionally, we show that if an edge-labeled graph satisfies the pairwise edge-disjoint path property, then the graph satisfies UDP. Lastly, we explore the relationship between UDP and subgraphs and prove that trees and cycles are the only two families of connected graphs for which UDP must hold for any edge-labeling over any ring."
  },
  {
    "date": "2026-01-20",
    "title": "Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic",
    "authors": "Saad Mankarious, Aya Zirikly",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14124v1",
    "source": "arXiv",
    "abstract": "Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains."
  },
  {
    "date": "2026-01-20",
    "title": "Foreign influencer operations: How TikTok shapes American perceptions of China",
    "authors": "Trevor Incerti, Jonathan Elkobi, Daniel Mattingly",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14118v1",
    "source": "arXiv",
    "abstract": "How do authoritarian regimes strengthen global support for nondemocratic political systems? Roughly half of the users of the social media platform TikTok report getting news from social media influencers. Against this backdrop, authoritarian regimes have increasingly outsourced content creation to these influencers. To gain understanding of the extent of this phenomenon and the persuasive capabilities of these influencers, we collect comprehensive data on pro-China influencers on TikTok. We show that pro-China influencers have more engagement than state media. We then create a realistic clone of the TikTok app, and conduct a randomized experiment in which over 8,500 Americans are recruited to use this app and view a random sample of actual TikTok content. We show that pro-China foreign influencers are strikingly effective at increasing favorability toward China, while traditional Chinese state media causes backlash. The findings highlight the importance of influencers in shaping global public opinion."
  },
  {
    "date": "2026-01-20",
    "title": "PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning",
    "authors": "Jiaying Wu, Can Gao, Jinglu Hu, Hui Li, Xiaofeng Cao, Jingcai Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14111v1",
    "source": "arXiv",
    "abstract": "Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D"
  },
  {
    "date": "2026-01-20",
    "title": "TLSQL: Table Learning Structured Query Language",
    "authors": "Feiyang Chen, Ken Zhong, Aoqian Zhang, Zheng Wang, Li Pan, Jianhua Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14109v1",
    "source": "arXiv",
    "abstract": "Table learning, which lies at the intersection of machine learning and modern database systems, has recently attracted growing attention. However, existing frameworks typically require explicit data export and extensive feature engineering, creating a high barrier for database practitioners. We present TLSQL (Table Learning Structured Query Language), a system that enables table learning directly over relational databases via SQL-like declarative specifications. TLSQL is implemented as a lightweight Python library that translates these specifications into standard SQL queries and structured learning task descriptions. The generated SQL queries are executed natively by the database engine, while the task descriptions are consumed by downstream table learning frameworks. This design allows users to focus on modeling and analysis rather than low-level data preparation and pipeline orchestration. Experiments on real-world datasets demonstrate that TLSQL effectively lowers the barrier to integrating machine learning into databasecentric workflows. Our code is available at https://github.com/rllmproject/tlsql/."
  },
  {
    "date": "2026-01-20",
    "title": "Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks",
    "authors": "Olesya Razuvayevskaya, Kalina Bontcheva",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14105v1",
    "source": "arXiv",
    "abstract": "This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means"
  },
  {
    "date": "2026-01-20",
    "title": "Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition",
    "authors": "Emily Kim, Allen Wu, Jessica Hodgins",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14101v1",
    "source": "arXiv",
    "abstract": "Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training. We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures. Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition."
  },
  {
    "date": "2026-01-20",
    "title": "Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration",
    "authors": "Yongcong Ye, Kai Zhang, Yanghai Zhang, Enhong Chen, Longfei Li, Jun Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14060v1",
    "source": "arXiv",
    "abstract": "Zero-shot composed image retrieval (ZS-CIR) is a rapidly growing area with significant practical applications, allowing users to retrieve a target image by providing a reference image and a relative caption describing the desired modifications. Existing ZS-CIR methods often struggle to capture fine-grained changes and integrate visual and semantic information effectively. They primarily rely on either transforming the multimodal query into a single text using image-to-text models or employing large language models for target image description generation, approaches that often fail to capture complementary visual information and complete semantic context. To address these limitations, we propose a novel Fine-Grained Zero-Shot Composed Image Retrieval method with Complementary Visual-Semantic Integration (CVSI). Specifically, CVSI leverages three key components: (1) Visual Information Extraction, which not only extracts global image features but also uses a pre-trained mapping network to convert the image into a pseudo token, combining it with the modification text and the objects most likely to be added. (2) Semantic Information Extraction, which involves using a pre-trained captioning model to generate multiple captions for the reference image, followed by leveraging an LLM to generate the modified captions and the objects most likely to be added. (3) Complementary Information Retrieval, which integrates information extracted from both the query and database images to retrieve the target image, enabling the system to efficiently handle retrieval queries in a variety of situations. Extensive experiments on three public datasets (e.g., CIRR, CIRCO, and FashionIQ) demonstrate that CVSI significantly outperforms existing state-of-the-art methods. Our code is available at https://github.com/yyc6631/CVSI."
  },
  {
    "date": "2026-01-20",
    "title": "A Splitting Theorem for non-positively curved Lorentzian spaces",
    "authors": "Joe Barton, Tobias Beran, Mauricio Che, Sebastian Gieger, Jona Röhrig, Felix Rott",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14058v1",
    "source": "arXiv",
    "abstract": "We prove a splitting theorem for Lorentzian pre-length spaces with global non-positive timelike curvature. Additionally, we extend the first variation formula to spaces with any timelike curvature bound, either from above or below, and different from 0."
  },
  {
    "date": "2026-01-20",
    "title": "On the Diophantine Equation Involving Elementary Symmetric Polynomials and the Decomposition of Unity",
    "authors": "Sándor Z. Kiss, Csaba Sándor, Maciej Zakarczemny",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14057v1",
    "source": "arXiv",
    "abstract": "We consider the equality of the values of the $n$th and $k$th elementary symmetric polynomials of $n$ not necessarily distinct positive integers. For $k < n$, we prove that this equation always has a solution, but only finitely many solutions. Furthermore, we consider the equality of the values of the $n$th and $(n-2)$th elementary symmetric polynomials of $n$ not necessarily distinct positive integers. In particular, we show that the number of solutions of this equation tends to infinity if $n$ tends to infinity."
  },
  {
    "date": "2026-01-20",
    "title": "SecureSplit: Mitigating Backdoor Attacks in Split Learning",
    "authors": "Zhihao Dou, Dongfei Cui, Weida Wang, Anjun Gao, Yueyang Quan, Mengyao Ma, Viet Vo, Guangdong Bai, Zhuqing Liu, Minghong Fang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14054v1",
    "source": "arXiv",
    "abstract": "Split Learning (SL) offers a framework for collaborative model training that respects data privacy by allowing participants to share the same dataset while maintaining distinct feature sets. However, SL is susceptible to backdoor attacks, in which malicious clients subtly alter their embeddings to insert hidden triggers that compromise the final trained model. To address this vulnerability, we introduce SecureSplit, a defense mechanism tailored to SL. SecureSplit applies a dimensionality transformation strategy to accentuate subtle differences between benign and poisoned embeddings, facilitating their separation. With this enhanced distinction, we develop an adaptive filtering approach that uses a majority-based voting scheme to remove contaminated embeddings while preserving clean ones. Rigorous experiments across four datasets (CIFAR-10, MNIST, CINIC-10, and ImageNette), five backdoor attack scenarios, and seven alternative defenses confirm the effectiveness of SecureSplit under various challenging conditions."
  },
  {
    "date": "2026-01-20",
    "title": "Tail-Aware Density Forecasting of Locally Explosive Time Series: A Neural Network Approach",
    "authors": "Elena Dumitrescu, Julien Peignon, Arthur Thomas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14049v1",
    "source": "arXiv",
    "abstract": "This paper proposes a Mixture Density Network for forecasting time series that exhibit locally explosive behavior. By incorporating skewed t-distributions as mixture components, our approach offers enhanced flexibility in capturing the skewed, heavy-tailed, and potentially multimodal nature of predictive densities associated with bubble dynamics modeled by mixed causal-noncausal ARMA processes. In addition, we implement an adaptive weighting scheme that emphasizes tail observations during training and hence leads to accurate density estimation in the extreme regions most relevant for financial applications. Equally important, once trained, the MDN produces near-instantaneous density forecasts. Through extensive Monte Carlo simulations and an empirical application on the natural gas price, we show that the proposed MDN-based framework delivers superior forecasting performance relative to existing approaches."
  },
  {
    "date": "2026-01-20",
    "title": "Binding Energies of Charged Particles on Dielectric Surfaces in Liquid Nitrogen",
    "authors": "Ashok Timsina, Wolfgang Korsch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14035v1",
    "source": "arXiv",
    "abstract": "A new approach for determining the binding energies of charged particles, such as ions and electrons, on dielectric surfaces in cryogenic liquids is introduced. The experimental technique outlined in this paper is employed to observe the buildup of charged particles on nonconductive surfaces using the electro-optic Kerr effect. The initial results of binding energy measurements on surfaces of deuterated tetraphenyl butadiene (dTPB)-coated and uncoated polymethyl methacrylate (PMMA) in liquid nitrogen are presented. Under these conditions, the ions or electrons displayed binding energies of less than 1 meV. Although these findings were obtained in liquid nitrogen, the methodology is not limited to cryogenic liquids and is applicable to a wide variety of fluids, with no essential dependence on temperature."
  },
  {
    "date": "2026-01-20",
    "title": "Universal Coarsening and Giant-Cluster Formation in Growing Interfaces",
    "authors": "Renan A. L. Almeida, Tiago J. Oliveira, Jeferson J. Arenzon, Leticia F. Cugliandolo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14025v1",
    "source": "arXiv",
    "abstract": "Clusters formed by fluctuations of two-dimensional (2D) directed interfaces around a threshold level have been extensively studied at equilibrium and in nonequilibrium steady states, but their coarsening dynamics remain poorly understood. Here, we numerically investigate this unexplored coarsening of clusters in 2D growing interfaces believed to belong to the Kardar-Parisi-Zhang universality class. Using a two-point spatial correlator, we demonstrate statistical time invariance of the evolving configurations and identify scaling forms shared across distinct models. We reveal a pronounced asymmetry in the growth of the largest clusters: one cluster emerges as a giant structure whose characteristic length exceeds the correlation length. Population-dependent scaling forms for the number densities of cluster areas are uncovered. These findings highlight new universal aspects of growing interfaces and suggest avenues for experimental verification."
  },
  {
    "date": "2026-01-20",
    "title": "Performance enhancing of hybrid quantum-classical Benders approach for MILP optimization",
    "authors": "Sergio López-Baños, Elisabeth Lobe, Ontje Lünsdorf, Oriol Raventós",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14024v1",
    "source": "arXiv",
    "abstract": "Mixed-integer linear programming problems are extensively used in industry for a wide range of optimization tasks. However, as they get larger, they present computational challenges for classical solvers within practical time limits. Quantum annealers can, in principle, accelerate the solution of problems formulated as quadratic unconstrained binary optimization instances, but their limited scale currently prevents achieving practical speedups. Quantum-classical algorithms have been proposed to take advantage of both paradigms and to allow current quantum computers to be used in larger problems. In this work, a hardware-agnostic Benders' decomposition algorithm and a series of enhancements with the goal of taking the most advantage of quantum computing are presented. The decomposition consists of a master problem with integer variables, which is reformulated as a quadratic unconstrained binary optimization problem and solved with a quantum annealer, and a linear subproblem solved by a classical computer. The enhancements consist, among others, of different embedding processes that substantially reduce the pre-processing time of the embedding computation without compromising solution quality, a conservative handling of cut constraints, and a stopping criterion that accounts for the limited size of current quantum computers and their heuristic nature. The proposed algorithm is benchmarked against classical approaches using a D-Wave quantum annealer for a scalable family of transmission network expansion planning problems."
  },
  {
    "date": "2026-01-20",
    "title": "Layer-engineered quantum anomalous Hall effect in twisted rhombohedral graphene family",
    "authors": "Zhangyuan Chen, Naitian Liu, Jiannan Hua, Hanxiao Xiang, Wenqiang Zhou, Jing Ding, Xinjie Fang, Linfeng Wu, Le Zhang, Qianmei Chen, Xuanyu Chen, Kenji Watanabe, Takashi Taniguchi, Na Xin, Wei Zhu, Shuigang Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14014v1",
    "source": "arXiv",
    "abstract": "The quantum anomalous Hall (QAH) insulator is uniquely characterized by the topological Chern number C. Controlling the Chern number is a key step toward functional topological electronics and enables access to exotic quantum phases beyond the traditional quantum Hall physics. Here, we report a series of QAH insulators in twisted rhombohedral graphene family, in which the Chern number can be tuned through layer configuration, in-situ electrostatic doping, and displacement field. Specifically, in twisted monolayer-rhombohedral N-layer graphene, denoted as (1+N) L, we observe QAH states with C=N at moire filling v=1, where N=3,4,5 represents the layer number of rhombohedral graphene. These results are experimentally confirmed by quantized Hall resistance and the Streda formula. In twisted monolayer-trilayer graphene, we also observe states with |C|=3 at v=3, whose sign can be switched by either electrostatic doping or displacement field. Furthermore, in twisted Bernal bilayer-rhombohedral tetralayer graphene denoted as (2+4) L, we demonstrate a displacement-field-driven topological phase transition between two distinct QAH states with C=3 and C=4 at v=1. Our work establishes twisted rhombohedral graphene as a highly versatile, layer-engineered platform for designing and dynamically controlling high-Chern-number topological matters."
  },
  {
    "date": "2026-01-20",
    "title": "BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models",
    "authors": "Junyu Zhang, Yipeng Kang, Jiong Guo, Jiayu Zhan, Junqi Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14007v1",
    "source": "arXiv",
    "abstract": "Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control."
  },
  {
    "date": "2026-01-20",
    "title": "Achieving Full Multipath Diversity by Random Constellation Rotation: a Theoretical Perspective",
    "authors": "Xuehan Wang, Jinhong Yuan, Jintao Wang, Kehan Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13997v1",
    "source": "arXiv",
    "abstract": "Diversity is an essential concept associated with communication reliability in multipath channels since it determines the slope of bit error rate performance in the medium to high signal-to-noise ratio regions. However, most of the existing analytical frameworks were developed for specific modulation schemes while the efficient validation of full multipath diversity for general modulation schemes remains an open problem. To fill this research gap, we propose to utilize random constellation rotation to ease the conditions for full-diversity modulation designs. For linearly precoded cyclic-prefix orthogonal frequency division multiplexing (OFDM) systems, we prove that maximum multipath diversity can be attained as long as the spread matrix does not have zero entries, which is a sufficient but easily satisfied condition. Furthermore, we derive the sufficient and necessary condition for general modulation schemes, whose verification can be divided into validation tasks for each column of the modulation matrix. Based on the proposed conditions, maximum diversity order can be attained with the probability of 1 by enabling a randomly generated rotation pattern for both time and doubly dispersive channels. The theoretical analysis in this paper also demonstrates that the diversity evaluation can be concentrated on the pairwise error probability when the number of error symbols is one, which reduces the complexity of diversity-driven design and performance analysis for novel modulation schemes significantly in both time and doubly dispersive channels. Finally, numerical results for various modulation schemes confirm that the theoretical analysis holds in both time and doubly dispersive channels. Furthermore, when employing practical detectors, the random constellation rotation technique consistently enhance the transmission reliability for both coded and uncoded systems."
  },
  {
    "date": "2026-01-20",
    "title": "torch-sla: Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch",
    "authors": "Mingyuan Chi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13994v1",
    "source": "arXiv",
    "abstract": "Industrial scientific computing predominantly uses sparse matrices to represent unstructured data -- finite element meshes, graphs, point clouds. We present \\torchsla{}, an open-source PyTorch library that enables GPU-accelerated, scalable, and differentiable sparse linear algebra. The library addresses three fundamental challenges: (1) GPU acceleration for sparse linear solves, nonlinear solves (Newton, Picard, Anderson), and eigenvalue computation; (2) Multi-GPU scaling via domain decomposition with halo exchange, reaching \\textbf{400 million DOF linear solve on 3 GPUs}; and (3) Adjoint-based differentiation} achieving $\\mathcal{O}(1)$ computational graph nodes (for autograd) and $\\mathcal{O}(\\text{nnz})$ memory -- independent of solver iterations. \\torchsla{} supports multiple backends (SciPy, cuDSS, PyTorch-native) and seamlessly integrates with PyTorch autograd for end-to-end differentiable simulations. Code is available at https://github.com/walkerchi/torch-sla."
  },
  {
    "date": "2026-01-20",
    "title": "Generating Functions Meet Occupation Measures: Invariant Synthesis for Probabilistic Loops (Extended Version)",
    "authors": "Darion Haase, Kevin Batz, Adrian Gallus, Benjamin Lucien Kaminski, Joost-Pieter Katoen, Lutz Klinkenberg, Tobias Winkler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13991v1",
    "source": "arXiv",
    "abstract": "A fundamental computational task in probabilistic programming is to infer a program's output (posterior) distribution from a given initial (prior) distribution. This problem is challenging, especially for expressive languages that feature loops or unbounded recursion. While most of the existing literature focuses on statistical approximation, in this paper we address the problem of mathematically exact inference. To achieve this for programs with loops, we rely on a relatively underexplored type of probabilistic loop invariant, which is linked to a loop's so-called occupation measure. The occupation measure associates program states with their expected number of visits, given the initial distribution. Based on this, we derive the notion of an occupation invariant. Such invariants are essentially dual to probabilistic martingales, the predominant technique for formal probabilistic loop analysis in the literature. A key feature of occupation invariants is that they can take the initial distribution into account and often yield a proof of positive almost sure termination as a by-product. Finally, we present an automatic, template-based invariant synthesis approach for occupation invariants by encoding them as generating functions. The approach is implemented and evaluated on a set of benchmarks."
  },
  {
    "date": "2026-01-20",
    "title": "Correlated domain and crystallographic orientation mapping in uniaxial ferroelectric polycrystals by interferometric vector piezoresponse force microscopy",
    "authors": "Ruben Dragland, Jan Schultheiß, Ivan N. Ushakov, Roger Proksch, Dennis Meier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13982v1",
    "source": "arXiv",
    "abstract": "Ongoing advances in scanning probe microscopy techniques are continually expanding the possibilities for nanoscale characterization and correlated studies of functional materials. Here, we demonstrate how a recent extension of piezoresponse force microscopy (PFM), known as interferometric vector PFM, can be utilized for simultaneously mapping the local crystallographic orientations and the domain structure of distributed grains in uniaxial ferroelectric polycrystals. By shifting the laser beam position on the cantilever, direction-dependent piezoresponse signals are acquired analogous to classical vector PFM, but without the need to rotate the sample. Using polycrystalline ErMnO$_{3}$ as a model system, we demonstrate that the reconstructed piezoresponse vectors correlate one-to-one with the crystallographic orientations of the micrometer-sized grains, carrying grain-orientation and domain-related information. We establish a versatile approach for rapid, multimodal characterization of polycrystalline uniaxial ferroelectrics, enabling automated, high-throughput reconstruction of polarization and grain orientations with nanoscale precision."
  },
  {
    "date": "2026-01-20",
    "title": "Rigid Body Dynamics in Ambient Fluids",
    "authors": "Marcel Padilla, Aviv Segall, Olga Sorkine-Hornung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13971v1",
    "source": "arXiv",
    "abstract": "We present a novel framework for rigid body dynamics in ambient media, such as air or water, enabling accurate motion prediction of objects without requiring computational fluid dynamics simulations. Our method computes the added mass of the fluid and replaces heuristic models for shape-dependent lift and drag with a generalized estimate of flow separation and dynamic pressure. Our method is the first within the rigid body dynamics context to reproduce the full range of falling plate behaviors: fluttering, tumbling, chaotic and steady modes, as well as phenomena such as the Magnus effect and the flight dynamics of an American football (tight spiral pass paradox). The resulting algorithm is simple to implement, robust, does not rely on specialized integrators and incorporates seamlessly into existing physics engines for real-time simulation."
  },
  {
    "date": "2026-01-20",
    "title": "A Converse Bound via the Nussbaum-Szkoła Mapping for Quantum Hypothesis Testing",
    "authors": "Jorge Lizarribar-Carrillo, Gonzalo Vazquez-Vilar, Tobias Koch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13970v1",
    "source": "arXiv",
    "abstract": "Quantum hypothesis testing concerns the discrimination between quantum states. This paper introduces a novel lower bound for asymmetric quantum hypothesis testing that is based on the Nussbaum-Szkoła mapping. The lower bound provides a unified recovery of converse results across all major asymptotic regimes, including large-, moderate-, and small-deviations. Unlike existing bounds, which either rely on technically involved information-spectrum arguments or suffer from fixed prefactors and limited applicability in the non-asymptotic regime, the proposed bound arises from a single expression and enables, in some cases, the direct use of classical results. It is further demonstrated that the proposed bound provides accurate approximations to the optimal quantum error trade-off function at small blocklengths. Numerical comparisons with existing bounds, including those based on fidelity and information spectrum methods, highlight its improved tightness and practical relevance."
  },
  {
    "date": "2026-01-20",
    "title": "RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning",
    "authors": "Cheol-Hui Lee, Hwa-Yeon Lee, Dong-Joo Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13964v1",
    "source": "arXiv",
    "abstract": "The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10\\%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69\\% and 8.80\\% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task -- for example, Time Masking with a 62\\% probability for sleep stage classification and Crop \\& Resize with a 77\\% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at \\href{https://github.com/dlcjfgmlnasa/RL-BioAug}{https://github.com/dlcjfgmlnasa/RL-BioAug}."
  },
  {
    "date": "2026-01-20",
    "title": "Optimal Calibration of the endpoint-corrected Hilbert Transform",
    "authors": "Eike Osmers, Dorothea Kolossa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13962v1",
    "source": "arXiv",
    "abstract": "Accurate, low-latency estimates of the instantaneous phase of oscillations are essential for closed-loop sensing and actuation, including (but not limited to) phase-locked neurostimulation and other real-time applications. The endpoint-corrected Hilbert transform (ecHT) reduces boundary artefacts of the Hilbert transform by applying a causal narrow-band filter to the analytic spectrum. This improves the phase estimate at the most recent sample. Despite its widespread empirical use, the systematic endpoint distortions of ecHT have lacked a principled, closed-form analysis. In this study, we derive the ecHT endpoint operator analytically and demonstrate that its output can be decomposed into a desired positive-frequency term (a deterministic complex gain that induces a calibratable amplitude/phase bias) and a residual leakage term setting an irreducible variance floor. This yields (i) an explicit characterisation and bounds for endpoint phase/amplitude error, (ii) a mean-squared-error-optimal scalar calibration (c-ecHT), and (iii) practical design rules relating window length, bandwidth/order, and centre-frequency mismatch to residual bias via an endpoint group delay. The resulting calibrated ecHT achieves near-zero mean phase error and remains computationally compatible with real-time pipelines. Code and analyses are provided at https://github.com/eosmers/cecHT."
  },
  {
    "date": "2026-01-20",
    "title": "A Bregman Regularized Proximal Point Method for Solving Equilibrium Problems on Hadamard Manifolds",
    "authors": "Shikher Sharma, Simeon Reich",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13959v1",
    "source": "arXiv",
    "abstract": "In this paper we develop a Bregman regularized proximal point algorithm for solving monotone equilibrium problems on Hadamard manifolds. It has been shown that the regularization term induced by a Bregman function is, in general, nonconvex on Hadamard manifolds unless the curvature is zero. Nevertheless, we prove that the proposed Bregman regularization scheme does converge to a solution of the equilibrium problem on Hadamard manifolds in the presence of a strong assumption on the convexity of the set formed by the regularization term. Moreover, we employ a coercivity condition on the Bregman function which is weaker than those typically assumed in the existing literature on Bregman regularization. Numerical experiments on illustrative examples demonstrate the practical effectiveness of our proposed method."
  },
  {
    "date": "2026-01-20",
    "title": "Hypercube subgroups of (outer) reduced Weyl groups of the Cuntz algebras",
    "authors": "Francesco Brenti, Roberto Conti, Gleb Nenashev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13952v1",
    "source": "arXiv",
    "abstract": "We develop some tools, of an algebraic and combinatorial nature, which enable us to obtain a detailed description of certain quadratic subgroups of the (outer) reduced Weyl group of the Cuntz algebra ${\\mathcal O}_n$. In particular, for $n=4$ our findings give a self-contained theoretical interpretation of the groups tabulated in [AJS18], which were obtained with the help of a computer. For each of these groups we provide a set of generators. A prominent role in our analysis is played by a certain family of subgroups of the symmetric group of a discrete square which we call bicompatible."
  },
  {
    "date": "2026-01-20",
    "title": "Ultra Compact low cost two mode squeezed light source",
    "authors": "Shahar Monsa, Shmuel Sternklar, Eliran Talker",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13939v1",
    "source": "arXiv",
    "abstract": "Quantum-correlated states of light, such as squeezed states, constitute a fundamental resource for quantum technologies, enabling enhanced performance in quantum metrology, quantum information processing, and quantum communications. The practical deployment of such technologies requires squeezed-light sources that are compact, efficient, low-cost, and robust. Here we report a compact narrowband source of two-mode squeezed light at 795 nm based on four-wave mixing in hot 85Rb atomic vapor. The source is implemented in a small, modular architecture featuring a single fiber-coupled input, an electro-optic phase modulator combined with a single Fabry-Perot etalon for probe generation, and two free-space output modes corresponding to the signal and conjugate fields. Optimized for low pump power, the system achieves up to -8 dB of intensity-difference squeezing at an analysis frequency of 0.8 MHz with a pump power of only 300 mW. The intrinsic narrowband character of the generated quantum states makes this source particularly well suited for atomic-based quantum sensing and quantum networking, including interfaces with atomic quantum memories. Our results establish a versatile and portable platform for low-SWaP squeezed-light generation, paving the way toward deployable quantum-enhanced technologies."
  },
  {
    "date": "2026-01-20",
    "title": "Packing minima of convex bodies",
    "authors": "Mei Han, Martin Henk, Fei Xue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13937v1",
    "source": "arXiv",
    "abstract": "In 2021, Henk, Schymura and Xue introduced packing minima, associated with a convex body and a lattice, as packing counterparts to the covering minima of Kannan and Lovász. Motivated by conjectures on the volume inequalities for the successive minima, we generalized the definition of the packing minima to the class of all convex bodies that contain the origin in their interior. For these packing minima, we presented several novel volume inequalities and calculated the specific values of the packing minima for several special convex bodies."
  },
  {
    "date": "2026-01-20",
    "title": "TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation",
    "authors": "Anoushkrit Goel, Simroop Singh, Ankita Joshi, Ranjeet Ranjan Jha, Chirag Ahuja, Aditya Nigam, Arnav Bhavsar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13935v1",
    "source": "arXiv",
    "abstract": "White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments."
  },
  {
    "date": "2026-01-20",
    "title": "Deep Reinforcement Learning-Based Dynamic Resource Allocation in Cell-Free Massive MIMO",
    "authors": "Phuong Nam Tran, Nhan Thanh Nguyen, Hien Quoc Ngo, Markku Juntti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13934v1",
    "source": "arXiv",
    "abstract": "In this paper, we consider power allocation and antenna activation of cell-free massive multiple-input multiple-output (CFmMIMO) systems. We first derive closed-form expressions for the system spectral efficiency (SE) and energy efficiency (EE) as functions of the power allocation coefficients and the number of active antennas at the access points (APs). Then, we aim to enhance the EE through jointly optimizing antenna activation and power control. This task leads to a non-convex and mixed-integer design problem with high-dimensional design variables. To address this, we propose a novel DRL-based framework, in which the agent learns to map large-scale fading coefficients to AP activation ratio, antenna coefficient, and power coefficient. These coefficients are then employed to determine the number of active antennas per AP and the power factors assigned to users based on closed-form expressions. By optimizing these parameters instead of directly controlling antenna selection and power allocation, the proposed method transforms the intractable optimization into a low-dimensional learning task. Our extensive simulations demonstrate the efficiency and scalability of the proposed scheme. Specifically, in a CFmMIMO system with 40 APs and 20 users, it achieves a 50% EE improvement and 3350 times run time reduction compared to the conventional sequential convex approximation method."
  },
  {
    "date": "2026-01-20",
    "title": "Primitive asteroids in the main belt, Cybele, and Hilda populations from Gaia DR3",
    "authors": "Noemie El-Bez-Sebastien, Sonia Fornasier, Antoine Seurat, Antonin Wargnier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13925v1",
    "source": "arXiv",
    "abstract": "Primitive asteroids include C-, P-, and D-classes, known to be dark and having spectra mostly featureless. They differ in the spectral slope, which ranges from moderate values for C-types, and progressively increases in P- and D-types, the latter being the reddest. While C- and P-types are commonly observed in the asteroid main belt, D-types are commonly found further from the Sun, in the Cybele, Hilda, and Jupiter Trojans regions, and very few are reported in the main belt. This study aims at characterizing the abundance of primordial and red asteroids, belonging to the P-, D-, and Z-classes in the Mahlke et al. (2022) taxonomy, in the 2-5.2 AU region using the third data release by the Gaia mission spectral catalog, which includes more than 60000 spectrophotometric data of asteroids. We have applied the following methodology to identify primordial asteroids in the catalog: 1) selection of objects with signal to noise ratio greater than 20; 2) albedo value less than 12%; 3) chi-squared fit to automatically identify potential D-, Z-, and P-types using Bus-DeMeo and Mahlke taxonomy; 4) visual inspection of every spectrum to confirm the taxonomic classification. Referring to Mahlke taxonomy, we have found 318 new D-types across the main belt, as well as 124 Z-types, and is in agreement with theoretical estimations. We computed the spectral slope in the visible range (0.55 - 0.81 μm). We also have identified 265 P-types in the main belt. For the Cybele and Hilda asteroids, we characterize the taxonomic class of all the bodies with SNR higher than 20 in the Gaia catalog, for a total sample of 193 and 180 asteroids, respectively."
  },
  {
    "date": "2026-01-20",
    "title": "Supercontraction-Induced Twist in Spider Silk Is a Dual Poynting Effect",
    "authors": "V. Fazio, G. Puglisi, G. Saccomandi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13924v1",
    "source": "arXiv",
    "abstract": "Spider dragline silk supercontracts as humidity increases, displaying large axial shortening together with a reproducible macroscopic twist. The physical origin of this torsion remains debated and is often attributed to helically arranged load-bearing elements, despite the lack of direct evidence for helicity in the native fiber. Here we show that torsion can arise generically from nonlinear anisotropic elasticity: humidity-driven shortening of the amorphous matrix, mechanically constrained by stiff, axially aligned $β$-sheet--rich load-bearing segments and their experimentally induced prestretch, drives the system into a dual Poynting regime in which axial shortening couples to spontaneous twist. Coupling a diffusion-based water-uptake law to irreversible matrix remodeling and fiber plasticity, the model quantitatively reproduces monotonic and cyclic torsional measurements using parameter values consistent with available experimental material parameters. These results identify supercontraction-induced torsion in spider silk as a manifestation of a dual Poynting effect and provide a minimal, physically grounded framework for humidity-driven torsional actuation in matrix--fiber architectures."
  },
  {
    "date": "2026-01-20",
    "title": "Know Your Contract: Extending eIDAS Trust into Public Blockchains",
    "authors": "Awid Vaziry, Christoph Wronka, Sandro Rodriguez Garzon, Axel Küpper",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13903v1",
    "source": "arXiv",
    "abstract": "Public blockchains lack native mechanisms to attribute on-chain actions to legally accountable entities, creating a fundamental barrier to institutional adoption and regulatory compliance. This paper presents an architecture that extends the European Union eIDAS trust framework into public blockchain ecosystems by cryptographically binding smart contracts to qualified electronic seals issued by Qualified Trust Service Providers. The mechanism establishes a verifiable chain of trust from the European Commission List of Trusted Lists to individual on-chain addresses, enabling machine-verifiable proofs for automated regulatory validation, such as Know Your Contract, Counterparty, and Business checks, without introducing new trusted intermediaries. Regulatory requirements arising from eIDAS, MiCA, PSD2, PSR, and the proposed European Business Wallet are analyzed, and a cryptographic suite meeting both eIDAS implementing regulations and EVM execution constraints following the Ethereum Fusaka upgrade is identified, namely ECDSA with P-256 and CAdES formatting. Two complementary trust validation models are presented: an off-chain workflow for agent-to-agent payment protocols and a fully on-chain workflow enabling regulatory-compliant DeFi operations between legal entities. The on-chain model converts regulatory compliance from a per-counterparty administrative burden into an automated, standardized process, enabling mutual validation at first interaction without prior business relationships. As eIDAS wallets become mandatory across EU member states, the proposed architecture provides a pathway for integrating European digital trust infrastructure into blockchain-based systems, enabling institutional DeFi participation, real-world asset tokenization, and agentic commerce within a trusted, regulatory-compliant framework."
  },
  {
    "date": "2026-01-20",
    "title": "Multi-Location Software Model Completion",
    "authors": "Alisa Welter, Christof Tinnes, Sven Apel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13894v1",
    "source": "arXiv",
    "abstract": "In model-driven engineering and beyond, software models are key development artifacts. In practice, they often grow to substantial size and complexity, undergoing thousands of modifications over time due to evolution, refactoring, and maintenance. The rise of AI has sparked interest in how software modeling activities can be automated. Recently, LLM-based approaches for software model completion have been proposed, however, the state of the art supports only single-location model completion by predicting changes at a specific location. Going beyond, we aim to bridge the gap toward handling coordinated changes that span multiple locations across large, complex models. Specifically, we propose a novel global embedding-based next focus predictor, NextFocus, which is capable of multi-location model completion for the first time. The predictor consists of a neural network with an attention mechanism that is trained on historical software model evolution data. Starting from an existing change, it predicts further model elements to change, potentially spanning multiple parts of the model. We evaluate our approach on multi-location model changes that have actually been performed by developers in real-world projects. NextFocus achieves promising results for multi-location model completion, even when changes are heavily spread across the model. It achieves an average Precision@k score of 0.98 for $k \\leq 10$, significantly outperforming the three baseline approaches."
  },
  {
    "date": "2026-01-20",
    "title": "Quasi-linear approach of bi-Kappa distributed electrons with dynamic $κ$ parameter. EMEC instability",
    "authors": "Pablo S Moya, Roberto E Navarro, Marian Lazar, Peter H Yoon, Rodrigo A López, Stefaan Poedts",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13888v1",
    "source": "arXiv",
    "abstract": "In recent years, significant progress has been made in the velocity-moment-based quasi-linear (QL) theory of waves and instabilities in plasmas with nonequilibrium velocity distributions (VDs) of the Kappa (or $κ$) type. However, the temporal variation of the parameter $κ$, which quantifies the presence of suprathermal particles, is not fully captured by such a QL analysis, and typically $κ$ remains constant during plasma dynamics. We propose a new QL modeling that goes beyond the limits of a previous approach, realistically assuming that the quasithermal core cannot evolve independently of energetic suprathermals. The case study is done on the electron-cyclotron (EMEC) instability generated by anisotropic bi-Kappa electrons with $A=T_\\perp/T_\\parallel > 1$ ($\\parallel, \\perp$ denoting directions with respect to the background magnetic field). The parameter $κ$ self-consistently varies through the QL equation of kurtosis (fourth-order moment) coupled with temporal variations of the temperature components, relaxing the constraint on the independence of the low-energy (core) electrons and suprathermal high-energy tails of VDs. The results refine and extend previous approaches. A clear distinction is made between regimes that lead to a decrease or an increase in the $κ$ parameter with saturation of the instability. What predominates is a decrease in $κ$, i.e., an excess of suprathermalization, which energizes suprathermal electrons due to self-generated wave fluctuations. Additionally, we found that VDs can evolve toward a quasi-Maxwellian shape (as $κ$ increases) primarily in regimes with low beta and initial kappa values greater than five. Instability-driven relaxation only partially resolves temperature anisotropy in bi-Kappa electron VDs, as wave fluctuations generally act to further energize suprathermal electrons."
  },
  {
    "date": "2026-01-20",
    "title": "Revisiting Multi-Task Visual Representation Learning",
    "authors": "Shangzhe Di, Zhonghua Zhai, Weidi Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13886v1",
    "source": "arXiv",
    "abstract": "Current visual representation learning remains bifurcated: vision-language models (e.g., CLIP) excel at global semantic alignment but lack spatial precision, while self-supervised methods (e.g., MAE, DINO) capture intricate local structures yet struggle with high-level semantic context. We argue that these paradigms are fundamentally complementary and can be integrated into a principled multi-task framework, further enhanced by dense spatial supervision. We introduce MTV, a multi-task visual pretraining framework that jointly optimizes a shared backbone across vision-language contrastive, self-supervised, and dense spatial objectives. To mitigate the need for manual annotations, we leverage high-capacity \"expert\" models -- such as Depth Anything V2 and OWLv2 -- to synthesize dense, structured pseudo-labels at scale. Beyond the framework, we provide a systematic investigation into the mechanics of multi-task visual learning, analyzing: (i) the marginal gain of each objective, (ii) task synergies versus interference, and (iii) scaling behavior across varying data and model scales. Our results demonstrate that MTV achieves \"best-of-both-worlds\" performance, significantly enhancing fine-grained spatial reasoning without compromising global semantic understanding. Our findings suggest that multi-task learning, fueled by high-quality pseudo-supervision, is a scalable path toward more general visual encoders."
  },
  {
    "date": "2026-01-20",
    "title": "Constrained MARL for Coexisting TN-NTN Resource Allocation: Scalability and Flexibility",
    "authors": "Cuong Le, Thang X. Vu, Stefano Andrenacci, Symeon Chatzinotas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13883v1",
    "source": "arXiv",
    "abstract": "This paper considers the joint TN-NTN constrained resource allocation, where terrestrial base stations and non-terrestrial base stations coexist in the spectrum. We focus on large-scale and practical scenarios characterized by large numbers of transmission channels and users, alongside highly dynamic user behaviors. As common learning solutions fail to address these challenges, we propose a decomposition solution based on the special properties of the cross-segment interference, and then tackle the original problem via solving subproblems in a sequential learning manner. Furthermore, to enhance the flexibility of the learned policies, we design a stochastic training environment that captures the key characteristics of real-world systems. Simulation results tested on the full 20MHz bandwidth with various numerologies show that our solution significantly improves scalability compared to existing solutions and remains robust in highly dynamic scenarios."
  },
  {
    "date": "2026-01-20",
    "title": "Low-Resource Quantum Energy Gap Estimation via Randomization",
    "authors": "Hugo Pages, Chusei Kiumi, Yuto Morohoshi, Bálint Koczor, Kosuke Mitarai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13881v1",
    "source": "arXiv",
    "abstract": "Estimating the energy spectra of quantum many-body systems is a fundamental task in quantum physics, with applications ranging from chemistry to condensed matter. Algorithmic shadow spectroscopy is a recent method that leverages randomized measurements on time-evolved quantum states to extract spectral information. However, implementing accurate time evolution with low-depth circuits remains a key challenge for near-term quantum hardware. In this work, we propose a hybrid quantum-classical protocol that integrates Time Evolution via Probabilistic Angle Interpolation (TE-PAI) into the shadow spectroscopy framework. TE-PAI enables the simulation of time evolution using shallow stochastic circuits while preserving unbiased estimates through quasiprobability sampling. We construct the combined estimator and derive its theoretical properties. Through numerical simulations, we demonstrate that our method accurately resolves energy gaps and exhibits enhanced robustness to gate noise compared to standard Trotter-based shadow spectroscopy. We further validate the protocol experimentally on up to 20 qubits using IBM quantum hardware. This makes TE-PAI shadow spectroscopy a promising tool for spectral analysis on noisy intermediate-scale quantum (NISQ) devices."
  },
  {
    "date": "2026-01-20",
    "title": "On spooky action at a distance and conditional probabilities",
    "authors": "Henryk Gzyl",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13875v1",
    "source": "arXiv",
    "abstract": "The aim of this exposé is to make explicit the analogy between the classical notion of non-independent probability distribution and the quantum notion of entangled state. To bring that analogy forth, we consider a classical systems with two dependent random variables and a quantum system with two components. In the classical case, afet observing one of the random variables, the underlying sample space and the probability distribution change. In the quantum case, when and event pertaining to one of the components is observed, the post-measurement state captures, both, the change in the state of the system and implicitly the new probability distribution. The predictions after a measurement in the classical case and in the quantum case, have to be computed with the conditional distribution given the value of the observed variable."
  },
  {
    "date": "2026-01-20",
    "title": "An efficient treatment of heat-flux boundary conditions in GSIS for rarefied gas flows",
    "authors": "Yanbing Zhang, Ruifeng Yuan, Liyan Luo, Lei Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13870v1",
    "source": "arXiv",
    "abstract": "Heat-flux boundary conditions are challenging to implement efficiently in rarefied gas flow simulations because the wall-reflected gas temperature and density must be determined dynamically during the computation. This paper aims to tackle this problem within the general synthetic iterative scheme (GSIS), where the Boltzmann kinetic equation is solved deterministically in an outer loop and macroscopic synthetic equations are solved in an inner loop. To avoid kinetic-macroscopic boundary-flux mismatch and the resulting convergence bottlenecks, for the macroscopic boundary flux at every inner iteration, the incident increment is estimated using a Maxwellian distribution, and then the reflected contribution is obtained by boundary conditions consistent with those in the kinetic solver. In addition to retaining the fast-converging and asymptotic-preserving properties of GSIS, the proposed method significantly reduces the iterations required to determine the wall-reflected gas parameters. Numerical simulations of rarefied gas flows in and around a 3D nozzle, a 2D adiabatic cylinder, and a 2D annular heat-transfer configuration show good agreement with the direct simulation Monte Carlo method, while achieving substantial efficiency gains over conventional iterative schemes."
  },
  {
    "date": "2026-01-20",
    "title": "Confinement-Induced Floquet Engineering and Non-Abelian Geometric Phases in Driven Quantum Wire Qubits",
    "authors": "Feulefack Ornela Claire, Dongmo Tedo Lynsia Saychele, Danga Jeremie Edmond, Keumo Tsiaze Roger Magloire, Fridolin Melong, Kenfack-Sadem Christian, Fotue Alain Jerve, Mahouton Norbert Hounkonnou, Lukong Cornelius Fai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13859v1",
    "source": "arXiv",
    "abstract": "This work theoretically demonstrates that a spin qubit in a parabolic quantum wire driven by a bichromatic field exhibits a confinement-tunable synthetic gauge field, leading to novel Floquet topological phenomena. The study presents the underlying mechanism for topological protection of qubit states against time-periodic perturbations. The analysis reveals a confinement-induced topological Landau-Zener transition, marked by a shift from preserved symmetries to chiral interference patterns in Landau-Zener-St$\\ddot{u}$ckelberg-Majorana interferometry. Notably, the emergence of non-Abelian geometric phases under cyclic evolution in curved confinement and phase-parameter space is identified, enabling holonomic quantum computation. Additionally, the prediction of unconventional Floquet-Bloch oscillations in the quasi-energy and resonance transition probability spectra as a function of the biharmonic phase indicates exotic properties, including fractal spectra and fractional Floquet tunneling. These phenomena provide direct evidence of coherent transport in the synthetic dimension. Collectively, these findings position quantum wire materials has a versatile platform for Floquet engineering, topological quantum control, and fault-tolerant quantum information processing."
  },
  {
    "date": "2026-01-20",
    "title": "Question-Focused Filtering for Knowledge-based VQA",
    "authors": "Wei Ye, Yixin Su, Yueguo Chen, Longxiang Gao, Jianjun Li, Ruixuan Li, Rui Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13856v1",
    "source": "arXiv",
    "abstract": "Knowledge-based Visual Question Answering (KB-VQA) aims to answer questions by integrating images with external knowledge. Effective knowledge filtering is crucial for improving accuracy. Typical filtering methods use similarity metrics to locate relevant article sections from one article, leading to information selection errors at the article and intra-article levels. Although recent explorations of Multimodal Large Language Model (MLLM)-based filtering methods demonstrate superior semantic understanding and cross-article filtering capabilities, their high computational cost limits practical application. To address these issues, this paper proposes a question-focused filtering method. This approach can perform question-focused, cross-article filtering, efficiently obtaining high-quality filtered knowledge while keeping computational costs comparable to typical methods. Specifically, we design a trainable Question-Focused Filter (QFF) and a Chunk-based Dynamic Multi-Article Selection (CDA) module, which collectively alleviate information selection errors at both the article and intra-article levels. Experiments show that our method outperforms current state-of-the-art models by 4.9% on E-VQA and 3.8% on InfoSeek, validating its effectiveness. The code is publicly available at: https://github.com/leaffeall/QKVQA."
  },
  {
    "date": "2026-01-20",
    "title": "The mechanistic origin of branching-driven nucleation in abrupt phase transitions",
    "authors": "Leyang Xue, Shengling Gao, Bnaya Gross, Orr Levy, Daqing Li, Zengru Di, Lazaros K. Gallos, Shlomo Havlin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13854v1",
    "source": "arXiv",
    "abstract": "Phase transitions are the macroscopic manifestation of microscopic processes that drive a system towards a new state. The detailed evolution of these processes, particularly in abrupt phase transitions, are currently not fully understood. Here, we introduce a theoretical framework based on internal node dependencies within a single-layer lattice. Crucially, we demonstrate that the fundamental mechanism underlying abrupt transitions is nucleation propagation preceded by a slow cascading process which scales with the range of dependencies. Our findings show that the synergy between these two distinct stages is essential for the occurrence of an abrupt transition. The first stage of a slow cascading mechanism was recently observed experimentally in superconducting layered materials, where heat acts as the dependency links, for the limit of infinite dependency range. Our model thus generalizes the framework to include finite dependency ranges, revealing previously unobserved mechanisms that could be experimentally verified through controlling the range of thermal diffusion in the material. As a universal mechanism, our model provides a robust method to test nucleation-controlled phase transitions in multiple systems, providing a path to discover and understand microscopic mechanisms in phase transitions."
  },
  {
    "date": "2026-01-20",
    "title": "Liabilities for the social cost of carbon",
    "authors": "Matthew K. Agrawala, Richard S. J. Tol",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13834v1",
    "source": "arXiv",
    "abstract": "We estimate the national social cost of carbon using a recent meta-analysis of the total impact of climate change and a standard integrated assessment model. The average social cost of carbon closely follows per capita income, the national social cost of carbon the size of the population. The national social cost of carbon measures self-harm. Net liability is defined as the harm done by a country's emissions on other countries minus the harm done to a country by other countries' emissions. Net liability is positive in middle-income, carbon-intensive countries. Poor and rich countries would be compensated because their current emissions are relatively low, poor countries additionally because they are vulnerable."
  },
  {
    "date": "2026-01-20",
    "title": "Efficient Parallel $(Δ+1)$-Edge-Coloring",
    "authors": "Michael Elkin, Ariel Khuzman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13822v1",
    "source": "arXiv",
    "abstract": "We study the $(Δ+1)$-edge-coloring problem in the parallel $\\left(\\mathrm{PRAM}\\right)$ model of computation. The celebrated Vizing's theorem [Viz64] states that every simple graph $G = (V,E)$ can be properly $(Δ+1)$-edge-colored. In a seminal paper, Karloff and Shmoys [KS87] devised a parallel algorithm with time $O\\left(Δ^5\\cdot\\log n\\cdot\\left(\\log^3 n+Δ^2\\right)\\right)$ and $O(m\\cdotΔ)$ processors. This result was improved by Liang et al. [LSH96] to time $O\\left(Δ^{4.5}\\cdot \\log^3Δ\\cdot \\log n + Δ^4 \\cdot\\log^4 n\\right)$ and $O\\left(n\\cdotΔ^{3} +n^2\\right)$ processors. [LSH96] claimed $O\\left(Δ^{3.5} \\cdot\\log^3Δ\\cdot \\log n + Δ^3\\cdot \\log^4 n\\right)$ time, but we point out a flaw in their analysis, which once corrected, results in the above bound. We devise a faster parallel algorithm for this fundamental problem. Specifically, our algorithm uses $O\\left(Δ^4\\cdot \\log^4 n\\right)$ time and $O(m\\cdot Δ)$ processors. Another variant of our algorithm requires $O\\left(Δ^{4+o(1)}\\cdot\\log^2 n\\right)$ time, and $O\\left(m\\cdotΔ\\cdot\\log n\\cdot\\log^δΔ\\right)$ processors, for an arbitrarily small $δ>0$. We also devise a few other tradeoffs between the time and the number of processors, and devise an improved algorithm for graphs with small arboricity. On the way to these results, we also provide a very fast parallel algorithm for updating $(Δ+1)$-edge-coloring. Our algorithm for this problem is dramatically faster and simpler than the previous state-of-the-art algorithm (due to [LSH96]) for this problem."
  },
  {
    "date": "2026-01-20",
    "title": "Tracing Cosmological Signature with Doppler Lensing: Insights from Cosmological Simulations",
    "authors": "Mubtasim Fuad, Sonia Akter Ema, Md Rasel Hossen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13820v1",
    "source": "arXiv",
    "abstract": "Doppler lensing, a relativistic effect resulting from the peculiar velocities of galaxies along the line of sight, provides insight into the large-scale structure of the Universe. Relativistic simulations are essential for modeling Doppler lensing because they incorporate gravity and motion in spacetime. We compare two relativistic $N$-body simulation frameworks, $\\texttt{GEVOLUTION}$ and $\\texttt{SCREENING}$, to calculate Doppler lensing convergence in cosmic voids of different sizes and halos of different masses. Our analysis reveals scale-dependent performance: $\\texttt{SCREENING}$ shows larger differences in small voids (radius range: 15--25 Mpc/h) with a mean absolute relative difference of 38.5\\%, due to linearized dynamics failing in nonlinear regimes. Medium voids (25--35 Mpc/h) show better agreement (9.5\\% mean difference). For large voids (35--45 Mpc/h), $\\texttt{SCREENING}$ exhibits intermediate differences (16.9\\% mean difference) with central instabilities. Moreover, our Doppler convergence analysis with massive halos ($10^{11.5}$--$10^{14} {~h^{-1}\\mathrm{M}_\\odot}$) demonstrates excellent consistency (1.6--3.6\\% mean difference). These findings provide clear guidance for simulation choice: $\\texttt{GEVOLUTION}$ is recommended for precision studies critical to $Λ$CDM or modified gravity tests, while $\\texttt{SCREENING}$ offers a computationally efficient alternative for relativistic treatments with large catalogs of voids and halos, assisting future astrophysical surveys."
  },
  {
    "date": "2026-01-20",
    "title": "Integrated Sensing and Communication for Low-Altitude Security",
    "authors": "Ruixing Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13810v1",
    "source": "arXiv",
    "abstract": "The dense concentration of low-altitude, slow-speed, and small-size targets in the complex low-altitude environment poses significant security challenges, including failures in continuous wide-area sensing and ambiguous target intent, which existing regulatory frameworks struggle to address. Integrated sensing and communication (ISAC), a hallmark of next-generation mobile communication, offers a transformative approach to low-altitude security governance. By leveraging existing cellular infrastructure and spectrum resources, ISAC enables the construction of a seamless wide-area sensing network, supports intelligent feature extraction and intent inference, facilitates real-time collaborative decision-making, and establishes a dynamic trust authentication framework. This article systematically reviews the technical system, analyzes the security challenges, forecasts the enabling value of ISAC, and discusses the resulting open problems and challenges, thereby laying a foundation for future research and industrial implementation."
  },
  {
    "date": "2026-01-20",
    "title": "Composing $p$-adic qubits: from representations of SO(3)$_p$ to entanglement and universal quantum logic gates",
    "authors": "Ilaria Svampa, Sonia L'Innocente, Stefano Mancini, Andreas Winter",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13808v1",
    "source": "arXiv",
    "abstract": "In the context of $p$-adic quantum mechanics, we investigate composite systems of $p$-adic qubits and $p$-adically controlled quantum logic gates. We build on the notion of a single $p$-adic qubit as a two-dimensional irreducible representation of the compact $p$-adic special orthogonal group SO(3)$_p$. We show that the classification of these representations reduces to the finite case, as they all factorise through some finite quotient SO(3)$_p$ mod $p^k$. Then, we tackle the problem of $p$-adic qubit composition and entanglement, fundamental for a $p$-adic formulation of quantum information processing. We classify the representations of SO(3)$_p$ mod $p$, and analyse tensor products of two $p$-adic qubit representations lifted from SO(3)$_p$ mod $p$. We solve the Clebsch-Gordan problem for such systems, revealing that the coupled bases decompose into singlet and doublet states. We further study entanglement arising from those stable subsystems. For $p=3$, we construct a set of gates from $4$-dimensional irreducible representations of SO(3)$_p$ mod $p$ that we prove to be universal for quantum computation."
  },
  {
    "date": "2026-01-20",
    "title": "Non-finitely generated $(\\mathbb{Z}_2)^k$-equivariant bordism ring",
    "authors": "Yuanxin Guan, Zhi Lü",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13807v1",
    "source": "arXiv",
    "abstract": "In 1998, Mukherjee and Sankaran posed two problems concerning the algebraic structure of the equivariant bordism ring of smooth closed $(\\mathbb{Z}_2)^k$-manifolds with only isolated fixed points. One is the property of being finitely generated as a $\\mathbb{Z}_2$-algebra, and the other is the existence of indecomposable elements. This paper definitively resolves both problems for the fully effective case. Specifically, let $\\mathcal{Z}_*((\\mathbb{Z}_2)^k)$ denote the equivariant bordism ring of smooth closed manifolds equipped with fully effective smooth $(\\mathbb{Z}_2)^k$-actions having only isolated fixed points. We prove that $\\mathcal{Z}_*((\\mathbb{Z}_2)^k)$ is not finitely generated as a $\\mathbb{Z}_2$-algebra for all $k\\geqslant 3$. Moreover, the proof explicitly constructs an infinite family of indecomposable elements with unbounded degrees, thereby settling the second problem simultaneously."
  },
  {
    "date": "2026-01-20",
    "title": "On rough ideal convergence",
    "authors": "Paolo Leonetti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13805v1",
    "source": "arXiv",
    "abstract": "We continue the study of ideal convergence for sequences $(x_n)$ with values in a topological space $X$ with respect to a family $\\{F_η:η\\in X\\}$ of subsets of $X$ with $η\\in F_η$, where each $F_η$ measures the allowed ``roughness'' of convergence toward $η$. More precisely, after introducing the corresponding notions of cluster and limit points, we prove several inclusion and invariance properties, discuss their structural properties, and give examples showing that the rough notions are genuinely different from the classical ideal ones."
  },
  {
    "date": "2026-01-20",
    "title": "The Non-Predictability of Mispredicted Branches using Timing Information",
    "authors": "Ioannis Constantinou, Arthur Perais, Yiannakis Sazeides",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13804v1",
    "source": "arXiv",
    "abstract": "Branch misprediction latency is one of the most important contributors to performance degradation and wasted energy consumption in a modern core. State-of-the-art predictors generally perform very well but occasionally suffer from high Misprediction Per Kilo Instruction due to hard-to-predict branches. In this work, we investigate if predicting branches using microarchitectural information, in addition to traditional branch history, can improve prediction accuracy. Our approach considers branch timing information (resolution cycle) both for older branches in the Reorder Buffer (ROB) and recently committed, and for younger branches relative to the branch we re-predict. We propose Speculative Branch Resolution (SBR) in which, N cycles after a branch allocates in the ROB, various timing information is collected and used to re-predict. Using the gem5 simulator we implement and perform a limit-study of SBR using a TAGE-Like predictor. Our experiments show that the post-alloc timing information we used was not able to yield performance gains over an unbounded TAGE-SC. However, we find two hard to predict branches where timing information did provide an advantage and thoroughly analysed one of them to understand why. This finding suggests that predictors may benefit from specific microarchitectural information to increase accuracy on specific hard to predict branches and that overriding predictions in the backend may yet yield performance benefits, but that further research is needed to determine such information vectors."
  },
  {
    "date": "2026-01-20",
    "title": "Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis",
    "authors": "Yushen Chen, Junzhe Liu, Yujie Tu, Zhikang Niu, Yuzhe Liang, Kai Yu, Chunyu Qiang, Chen Zhang, Xie Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13802v1",
    "source": "arXiv",
    "abstract": "A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ ."
  },
  {
    "date": "2026-01-20",
    "title": "Linear viscoelastic rheological FrBD models",
    "authors": "Luigi Romano, Ole Morten Aamo, Jan Åslund, Erik Frisk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13799v1",
    "source": "arXiv",
    "abstract": "In [1], a new modeling paradigm for developing rate-and-state-dependent, control-oriented friction models was introduced. The framework, termed Friction with Bristle Dynamics (FrBD), combines nonlinear analytical expressions for the friction coefficient with constitutive equations for bristle-like elements. Within the FrBD framework, this letter introduces two novel formulations based on the two most general linear viscoelastic models for solids: the Generalized Maxwell (GM) and Generalized Kelvin-Voigt (GKV) elements. Both are analyzed in terms of boundedness and passivity, revealing that these properties are satisfied for any physically meaningful parametrization. An application of passivity for control design is also illustrated, considering an example from robotics. The findings of this letter systematically integrate rate-and-state dynamic friction models with linear viscoelasticity."
  },
  {
    "date": "2026-01-20",
    "title": "Nijenhuis BiHom-Lie bialgebras and differential Lie bialgebras",
    "authors": "Jiaqi Liu, Lin Gao, Yuanyuan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13791v1",
    "source": "arXiv",
    "abstract": "In this paper, we first introduce the concept of Nijenhuis BiHom-Lie algebras. We then establish the equivalence relations between the Manin triples of Nijenhuis BiHom-Lie algebras, Nijenhuis BiHom-Lie bialgebras, and matched pairs of Nijenhuis BiHom-Lie algebras. Furthermore, we show that such an equivalence also holds for differential Lie bialgebras, together with their associated Manin triples and corresponding matched pairs."
  },
  {
    "date": "2026-01-20",
    "title": "The Genus-Decreasing Property of Mean Curvature Flow, I",
    "authors": "Brian White",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13787v1",
    "source": "arXiv",
    "abstract": "This paper proves that, in mean curvature flow of a compact surface in a complete $3$-manifold with Ricci curvature bounded below, the genus of the regular set is a decreasing function of time as long as the only singularities are given by shrinking sphere and shrinking cylinder tangent flows. The paper also proves some local versions of that fact."
  },
  {
    "date": "2026-01-20",
    "title": "Nonperturbative Isentropic Processes in AdS Black Holes with Nonlinear Electrodynamics",
    "authors": "Mozib Bin Awal, Prabwal Phukon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13786v1",
    "source": "arXiv",
    "abstract": "We study the isentropic processes in a class of Anti de Sitter black holes coupled to non-linear electrodynamics. We demonstrate that such processes are classically forbidden but can proceed via quantum mechanical tunnelling. We compute the Euclidean action associated with the tunnelling process and analyze its dependence on the black hole charge, horizon radius, and the non-linear electrodynamics parameters characterizing each model. We find that the tunnelling probability is increasingly suppressed as the strength of the non-linearity is enhanced. We further find that smaller black holes exhibit a significantly higher tunnelling probability compared to larger ones, indicating a departure from classical behaviour. We conjecture that this behaviour may be universal across a broad class of black hole spacetimes. We discuss the implications of our results for entropy bounds and their potential relevance to the black hole information loss paradox."
  },
  {
    "date": "2026-01-20",
    "title": "Area-universality in Outerplanar Graphs",
    "authors": "Ravi Suthar, Raveena, Krishnendra Shekhawat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13781v1",
    "source": "arXiv",
    "abstract": "A rectangular floorplan is a partition of a rectangle into smaller rectangles such that no four rectangles meet at a single point. Rectangular floorplans arise naturally in a variety of applications, including VLSI design, architectural layout, and cartography, where efficient and flexible spatial subdivisions are required. A central concept in this domain is that of area-universality: a floorplan (or more generally, a rectangular layout) is area-universal if, for any assignment of target areas to its constituent rectangles, there exists a combinatorially equivalent layout that realizes these areas. In this paper, we investigate the structural conditions under which an outerplanar graph admits an area-universal rectangular layout. We establish a necessary and sufficient condition for area-universality in this setting, thereby providing a complete characterization of admissible outerplanar graphs. Furthermore, we present an algorithmic construction that guarantees that the resulting layout is always area-universal."
  },
  {
    "date": "2026-01-20",
    "title": "Extension of the Fundamental Theorem of Algebra to Polynomial Matrix Equations over $Q$-Circulant Matrices",
    "authors": "Hongjian Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13775v1",
    "source": "arXiv",
    "abstract": "In this paper, we establish an analogue of the Fundamental Theorem of Algebra for polynomial matrix equations, where both the coefficient matrices and the unknown matrix are $Q$-circulant matrices. This result generalizes Abramov's result for circulant matrices."
  },
  {
    "date": "2026-01-20",
    "title": "Bialgebraic structures on boolean functions",
    "authors": "Loïc Foissy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13773v1",
    "source": "arXiv",
    "abstract": "We study several bialgebraic structures on boolean functions, that is to say maps defined on the set of subsets of a finite set $X$, taking the value $0$ on $\\emptyset$. Examples of boolean functions are given by the indicator function of the hyperedges of a given hypergraph, or the rank function of a matroid. We give the species of boolean functions a two-parameters family of products and a coproduct, and this defines a two-parameters family of twisted bialgebras. We then try to define a second coproduct on boolean functions, based on contractions, in order to obtain a double bialgebra. We show that this is not possible on the whole species of boolean functions, but that there exists a maximal subspecies where this is possible. This subspecies being rather mysterious, we introduce rigid boolean functions and show that this subspecies has indeed a second coproduct, as wished, and that it contains rank functions of matroids and indicator functions associated to hypergraphs. As a consequence, we obtain a unique polynomial invariant on rigid boolean functions, which is a generalization of the chromatic polynomial of graphs."
  },
  {
    "date": "2026-01-20",
    "title": "Existence and regularity of minimizers for a variational problem of species population density",
    "authors": "Pu-Zhao Kow, Masato Kimura, Hiroshi Ohtsuka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13771v1",
    "source": "arXiv",
    "abstract": "We study a variational problem motivated by models of species population density in a nonhomogeneous environment. We first analyze local minimizers and the structure of the saturated region (where the population attains its maximal density) from a free boundary perspective. By comparing the original problem with a radially symmetric minimization problem and studying its properties, we then establish the existence and structure of a global solution. Analytic examples of radially symmetric solutions and numerical simulations illustrate the theoretical results and provide insight into spatial saturation patterns in population models. We further highlight an unresolved question regarding the quasiconcavity of minimizers."
  },
  {
    "date": "2026-01-20",
    "title": "On the Optimal Layout of Two-Dimensional Lattices for Density Matrix Renormalization Group",
    "authors": "A. Scardicchio",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13762v1",
    "source": "arXiv",
    "abstract": "For quantum spin models defined on a two-dimensional lattice, we look for the best numbering of the lattice sites (a layout) that, at fixed bond dimension and other parameters of the density matrix renormalization group (DMRG) algorithm, gives the lowest value of the variational energy, maximum entropy and truncation error. We consider the conjecture that the optimal layout is a Hamiltonian path, and that it optimizes a simply computable geometric cost function. Finding the minimum of such a function, which is a variant of the minimum linear arrangement problem, provides the DMRG with an efficient layout of the lattice and improves both accuracy and convergence time. We present applications to the antiferromagnetic and spin glass spin-1/2 models on the square and triangular lattices."
  },
  {
    "date": "2026-01-20",
    "title": "GOMPSNR: Reflourish the Signal-to-Noise Ratio Metric for Audio Generation Tasks",
    "authors": "Lingling Dai, Andong Li, Cheng Chi, Yifan Liang, Xiaodong Li, Chengshi Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13758v1",
    "source": "arXiv",
    "abstract": "In the field of audio generation, signal-to-noise ratio (SNR) has long served as an objective metric for evaluating audio quality. Nevertheless, recent studies have shown that SNR and its variants are not always highly correlated with human perception, prompting us to raise the questions: Why does SNR fail in measuring audio quality? And how to improve its reliability as an objective metric? In this paper, we identify the inadequate measurement of phase distance as a pivotal factor and propose to reformulate SNR with specially designed phase-distance terms, yielding an improved metric named GOMPSNR. We further extend the newly proposed formulation to derive two novel categories of loss function, corresponding to magnitude-guided phase refinement and joint magnitude-phase optimization, respectively. Besides, extensive experiments are conducted for an optimal combination of different loss functions. Experimental results on advanced neural vocoders demonstrate that our proposed GOMPSNR exhibits more reliable error measurement than SNR. Meanwhile, our proposed loss functions yield substantial improvements in model performance, and our wellchosen combination of different loss functions further optimizes the overall model capability."
  },
  {
    "date": "2026-01-20",
    "title": "Pro-AI Bias in Large Language Models",
    "authors": "Benaya Trabelsi, Jonathan Shaki, Sarit Kraus",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13749v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions."
  },
  {
    "date": "2026-01-20",
    "title": "On-Chip Generation of Co-Polarized and Spectrally Separable Photon Pairs",
    "authors": "Xiaojie Wang, Lin Zhou, Yue Li, Sakthi Sanjeev Mohanraj, Xiaodong Shi, Zhuoyang Yu, Ran Yang, Xu Chen, Guangxing Wu, Hao Hao, Sihao Wang, Veerendra Dhyani, Di Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13740v1",
    "source": "arXiv",
    "abstract": "On-chip generation of high-purity single photons is essential for scalable photonic quantum technologies. Spontaneous parametric down-conversion (SPDC) is widely used to generate photon pairs for heralded single-photon sources, but intrinsic spectral correlations of the pairs often limit the purity and interference visibility of the heralded photons. Existing approaches to suppress these correlations rely on narrowband spectral filtering, which introduces loss, or exploiting different polarizations, which complicates on-chip integration. Here, we demonstrate a new strategy for generating spectrally separable photon pairs in thin-film lithium niobate nanophotonic circuits by harnessing higher-order spatial modes, with all interacting fields residing in the same polarization. Spectral separability is achieved by engineering group-velocity matching using higher-order transverse-electric modes, combined with a Gaussian-apodized poling profile to further suppress residual correlations inherent to standard periodic poling. Subsequent on-chip mode conversion with efficiency exceeding 95\\% maps the higher-order mode to the fundamental mode and routes the photons into distinct output channels. The resulting heralded photons exhibit spectral purities exceeding 94\\% inferred from joint-spectral intensity and 89\\% from unheralded $g^{(2)}$ measurement. This approach enables flexible spectral and temporal engineering of on-chip quantum light sources for quantum computing and quantum networking."
  },
  {
    "date": "2026-01-20",
    "title": "Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection",
    "authors": "Hojin Kim, Jaehyung Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13735v1",
    "source": "arXiv",
    "abstract": "Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches."
  },
  {
    "date": "2026-01-20",
    "title": "Breaking the Data Barrier in Learning Symbolic Computation: A Case Study on Variable Ordering Suggestion for Cylindrical Algebraic Decomposition",
    "authors": "Rui-Juan Jing, Yuegang Zhao, Changbo Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13731v1",
    "source": "arXiv",
    "abstract": "Symbolic computation, powered by modern computer algebra systems, has important applications in mathematical reasoning through exact deep computations. The efficiency of symbolic computation is largely constrained by such deep computations in high dimension. This creates a fundamental barrier on labelled data acquisition if leveraging supervised deep learning to accelerate symbolic computation. Cylindrical algebraic decomposition (CAD) is a pillar symbolic computation method for reasoning with first-order logic formulas over reals with many applications in formal verification and automatic theorem proving. Variable orderings have a huge impact on its efficiency. Impeded by the difficulty to acquire abundant labelled data, existing learning-based approaches are only competitive with the best expert-based heuristics. In this work, we address this problem by designing a series of intimately connected tasks for which a large amount of annotated data can be easily obtained. We pre-train a Transformer model with these data and then fine-tune it on the datasets for CAD ordering. Experiments on publicly available CAD ordering datasets show that on average the orderings predicted by the new model are significantly better than those suggested by the best heuristic methods."
  },
  {
    "date": "2026-01-20",
    "title": "GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark",
    "authors": "Lotta Kiefer, Christoph Leiter, Sotaro Takeshita, Elena Schmidt, Steffen Eger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13711v1",
    "source": "arXiv",
    "abstract": "Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV."
  },
  {
    "date": "2026-01-20",
    "title": "ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins",
    "authors": "Xinhao Liu, Yu Wang, Xiansheng Guo, Gordon Owusu Boateng, Yu Cao, Haonan Si, Xingchen Guo, Nirwan Ansari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13706v1",
    "source": "arXiv",
    "abstract": "High-fidelity parking-lot digital twins provide essential priors for path planning, collision checking, and perception validation in Automated Valet Parking (AVP). Yet robot-oriented reconstruction faces a trilemma: sparse forward-facing views cause weak parallax and ill-posed geometry; dynamic occlusions and extreme lighting hinder stable texture fusion; and neural rendering typically needs expensive offline optimization, violating edge-side streaming constraints. We propose ParkingTwin, a training-free, lightweight system for online streaming 3D reconstruction. First, OSM-prior-driven geometric construction uses OpenStreetMap semantic topology to directly generate a metric-consistent TSDF, replacing blind geometric search with deterministic mapping and avoiding costly optimization. Second, geometry-aware dynamic filtering employs a quad-modal constraint field (normal/height/depth consistency) to reject moving vehicles and transient occlusions in real time. Third, illumination-robust fusion in CIELAB decouples luminance and chromaticity via adaptive L-channel weighting and depth-gradient suppression, reducing seams under abrupt lighting changes. ParkingTwin runs at 30+ FPS on an entry-level GTX 1660. On a 68,000 m^2 real-world dataset, it achieves SSIM 0.87 (+16.0%), delivers about 15x end-to-end speedup, and reduces GPU memory by 83.3% compared with state-of-the-art 3D Gaussian Splatting (3DGS) that typically requires high-end GPUs (RTX 4090D). The system outputs explicit triangle meshes compatible with Unity/Unreal digital-twin pipelines. Project page: https://mihoutao-liu.github.io/ParkingTwin/"
  },
  {
    "date": "2026-01-20",
    "title": "Generative Intent Prediction Agentic AI empowered Edge Service Function Chain Orchestration",
    "authors": "Yan Sun, Shaoyong Guo, Sai Huang, Zhiyong Feng, Feng Qi, Xuesong Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13694v1",
    "source": "arXiv",
    "abstract": "With the development of artificial intelligence (AI), Agentic AI (AAI) based on large language models (LLMs) is gradually being applied to network management. However, in edge network environments, high user mobility and implicit service intents pose significant challenges to the passive and reactive management of traditional AAI. To address the limitations of existing approaches in handling dynamic demands and predicting users' implicit intents, in this paper we propose an edge service function chain (SFC) orchestration framework empowered by a Generative Intent Prediction Agent (GIPA). Our GIPA aims to shift the paradigm from passive execution to proactive prediction and orchestration. First, we construct a multidimensional intent space that includes functional preferences, QoS sensitivity, and resource requirements, enabling the mapping from unstructured natural language to quantifiable physical resource demands. Second, to cope with the complexity and randomness of intent sequences, we design an intent prediction model based on a Generative Diffusion Model (GDM), which reconstructs users' implicit intents from multidimensional context through a reverse denoising process. Finally, the predicted implicit intents are embedded as global prompts into the SFC orchestration model to guide the network in proactively and ahead-of-time optimizing SFC deployment strategies. Experiment results show that GIPA outperforms existing baseline methods in highly concurrent and highly dynamic scenarios."
  },
  {
    "date": "2026-01-20",
    "title": "End-to-End Reverse Screening Identifies Protein Targets of Small Molecules Using HelixFold3",
    "authors": "Shengjie Xu, Xianbin Ye, Mengran Zhu, Xiaonan Zhang, Shanzhuo Zhang, Xiaomin Fang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13693v1",
    "source": "arXiv",
    "abstract": "Identifying protein targets for small molecules, or reverse screening, is essential for understanding drug action, guiding compound repurposing, predicting off-target effects, and elucidating the molecular mechanisms of bioactive compounds. Despite its critical role, reverse screening remains challenging because accurately capturing interactions between a small molecule and structurally diverse proteins is inherently complex, and conventional step-wise workflows often propagate errors across decoupled steps such as target structure modeling, pocket identification, docking, and scoring. Here, we present an end-to-end reverse screening strategy leveraging HelixFold3, a high-accuracy biomolecular structure prediction model akin to AlphaFold3, which simultaneously models the folding of proteins from a protein library and the docking of small-molecule ligands within a unified framework. We validate this approach on a diverse and representative set of approximately one hundred small molecules. Compared with conventional reverse docking, our method improves screening accuracy and demonstrates enhanced structural fidelity, binding-site precision, and target prioritization. By systematically linking small molecules to their protein targets, this framework establishes a scalable and straightforward platform for dissecting molecular mechanisms, exploring off-target interactions, and supporting rational drug discovery."
  },
  {
    "date": "2026-01-20",
    "title": "Electrical detection of high-order optical orbital angular momentum",
    "authors": "Guanyu Zhang, Xianghan Meng, Zini Cao, Hai Lin, Shuxin Huang, Minghao Deng, Jiaqi Li, Qihuang Gong, Guowei Lyu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13691v1",
    "source": "arXiv",
    "abstract": "The orbital angular momentum (OAM) of light provides an infinite orthogonal basis for information capacity in optical communications and high-dimensional quantum processing. However, harnessing this potential in integrated systems is hindered by the lack of compact devices capable of direct electrical readout of high-order OAM modes. Here, we report an on-chip silicon-based integrated photodetector that directly converts optical OAM into distinguishable electrical signals without bulky interferometric or imaging optics. By leveraging a momentum-matched plasmonic coupling mechanism, the device maps vortex beams onto surface plasmon polaritons (SPPs) with OAM-dependent splitting angles, thereby generating photocurrents that uniquely encode the topological charge. The incorporation of a surface dielectric lens and a split-electrode architecture further enhances mode resolution and enables chirality discrimination. The device demonstrates a wide topological charge detection range from m = -9 to 9 and achieves a record-high average OAM responsivity of 226 nA/W. By bridging the gap between vortex beams and electronic readout on a scalable platform, this work paves the way for on-chip OAM direct detection for next-generation high-capacity optical networks."
  },
  {
    "date": "2026-01-20",
    "title": "Toward Agentic AI: Task-Oriented Communication for Hierarchical Planning of Long-Horizon Tasks",
    "authors": "Sin-Yu Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13685v1",
    "source": "arXiv",
    "abstract": "Agentic artificial intelligence (AI) is an AI paradigm that can perceive the environment, reason over observations, and execute actions to achieve specific goals. Task-oriented communication supports agentic AI by transmitting only the task-related information instead of full raw data in order to reduce the bandwidth requirement. In real-world scenarios, AI agents often need to perform a sequence of actions to complete complex tasks. Completing these long-horizon tasks requires a hierarchical agentic AI architecture, where a high-level planner module decomposes a task into subtasks, and a low-level actor module executes each subtask sequentially. Since each subtask has a distinct goal, the existing task-oriented communication schemes are not designed to handle different goals for different subtasks. To address this challenge, in this paper, we develop a hierarchical task-oriented communication (HiTOC) framework. We consider a system with an edge server and a robot as an edge device. The high-level planner and low-level actor modules reside on the edge server. The robot transmits only the environment information that is relevant to the current subtask in order to complete a long-horizon task. We propose a conditional variational information bottleneck (cVIB) approach to train the HiTOC framework to adaptively transmit minimal information required for each subtask. Simulations conducted on the AI2-THOR platform demonstrate that the proposed HiTOC framework outperforms three state-of-the-art schemes in terms of the success rate on MAP-THOR benchmark."
  },
  {
    "date": "2026-01-20",
    "title": "Ultra-Lightweight Network for Ship-Radiated Sound Classification on Embedded Deployment",
    "authors": "Sangwon Park, Dongjun Kim, Sung-Hoon Byun, Sangwook Park",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13679v1",
    "source": "arXiv",
    "abstract": "This letter presents ShuffleFAC, a lightweight acoustic model for ship-radiated sound classification in resource-constrained maritime monitoring systems. ShuffleFAC integrates Frequency-Aware convolution into an efficiency-oriented backbone using separable convolution, point-wise group convolution, and channel shuffle, enabling frequency-sensitive feature extraction with low computational cost. Experiments on the DeepShip dataset show that ShuffleFAC achieves competitive performance with substantially reduced complexity. In particular, ShuffleFAC ($γ=16$) attains a macro F1-score of 71.45 $\\pm$ 1.18% using 39K parameters and 3.06M MACs, and achieves an inference latency of 6.05 $\\pm$ 0.95ms on a Raspberry Pi. Compared with MicroNet0, it improves macro F1-score by 1.82 % while reducing model size by 9.7x and latency by 2.5x. These results indicate that ShuffleFAC is suitable for real-time embedded UATR."
  },
  {
    "date": "2026-01-20",
    "title": "A stable hothouse triggered by a tipping mechanism",
    "authors": "Erik Chavez, Jan Rombouts, Michael Ghil",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13678v1",
    "source": "arXiv",
    "abstract": "The climate system's nonlinear dynamics is influenced by various external forcings and internal feedbacks that can give rise to regional and even global tipping points that may lead to significant and potentially irreversible changes. Paleoclimatic records reveal that Earth's climate has shifted between distinct equlibria, including a \"hothouse Earth\" state with temperatures about 10 K higher than present. However, a specific mechanism for a sudden tipping to an alternate stable state, several degrees warmer than the present climate, has yet to be presented. We introduce a temperature-carbon-vegetation (TCV) model comprising an energy balance model of global temperature, coupled with global terrestrial and ocean CO2 dynamics, and with vegetation ecosystem change. Our model exhibits a new tipping mechanism that leads to a hothouse Earth under a high-emissions scenario. Its simulations align with both observations and IPCC-class global climate models prior to tipping. The two processes that produce global tipping are: (i) temperature-albedo feedback due to darkening of the terrestrial cryosphere by glacial microalgae; and (ii) limits to vegetation adaptation that lead to reduced carbon absorption."
  },
  {
    "date": "2026-01-20",
    "title": "Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting",
    "authors": "Mounika Kanulla, Rajasree Dadigi, Sailaja Thota, Vivek Yelleti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13665v1",
    "source": "arXiv",
    "abstract": "Food wastage is one of the critical challenges in the agricultural supply chain, and accurate and effective spoilage detection can help to reduce it. Further, it is highly important to forecast the spoilage information. This aids the longevity of the supply chain management in the agriculture field. This motivated us to propose fusion based architectures by combining CNN with LSTM and DeiT transformer for the following multi-tasks simultaneously: (i) vegetable classification, (ii) food spoilage detection, and (iii) shelf life forecasting. We developed a dataset by capturing images of vegetables from their fresh state until they were completely spoiled. From the experimental analysis it is concluded that the proposed fusion architectures CNN+CNN-LSTM and CNN+DeiT Transformer outperformed several deep learning models such as CNN, VGG16, ResNet50, Capsule Networks, and DeiT Transformers. Overall, CNN + DeiT Transformer yielded F1-score of 0.98 and 0.61 in vegetable classification and spoilage detection respectively and mean squared error (MSE) and symmetric mean absolute percentage error (SMAPE) of 3.58, and 41.66% respectively in spoilage forecasting. Further, the reliability of the fusion models was validated on noisy images and integrated with LIME to visualize the model decisions."
  },
  {
    "date": "2026-01-20",
    "title": "Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning",
    "authors": "Myong-Yol Choi, Hankyoul Ko, Hanse Cho, Changseung Kim, Seunghwan Kim, Jaemin Seo, Hyondong Oh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13657v1",
    "source": "arXiv",
    "abstract": "This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization."
  },
  {
    "date": "2026-01-20",
    "title": "TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation",
    "authors": "Xingjian Wu, Junkai Lu, Zhengyu Li, Xiangfei Qiu, Jilin Hu, Chenjuan Guo, Christian S. Jensen, Bin Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13653v1",
    "source": "arXiv",
    "abstract": "Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of strong out-of-the-box tools and the reasoning capability of Large Language Models (LLMs), which serves as a fully agentic data scientist for Time Series Question Answering (TSQA). To teach the LLM-based Time Series Reasoning Models (TSRMs) strategic tool-use, we also collect a 100k expert trajectory corpus called TimeToolBench. To enhance TSRMs' generalization capability, we then devise a four-stage training strategy, which boosts TSRMs through learning from their own early experiences and self-reflections. Experimentally, we train an 8B TSRM on TimeToolBench and equip it with the TimeART framework, and it achieves consistent state-of-the-art performance on multiple TSQA tasks, which pioneers a novel approach towards agentic time series reasoning."
  },
  {
    "date": "2026-01-20",
    "title": "Exact solution of the (2+1)-dimensional damping forcing coupled Burgers equation by using Darboux transformation",
    "authors": "Prasanta Chatterjee, Nanda Kanan Pal, Dipan Saha, Santanu Raut",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13634v1",
    "source": "arXiv",
    "abstract": "In this article, we investigate the (2+1)-dimensional damping forcing coupled Burgers equation, which is obtain by adding damping and forcing terms from couple Burgers equation. The Lax pair of the (2+1)-dimensional damping forcing coupled Burgers equation is established. With the help of Lax pair, we derive the $N$-fold Darboux transformation of (2+1)-dimensional damping forcing coupled Burgers equation. Using one fold and two fold Darboux transformation, we demonstrated some wave solutions including solitary wave solution and periodic wave solution. The impact of damping and forcing terms in solitary wave solution and periodic solution is graphically demonstrated."
  },
  {
    "date": "2026-01-20",
    "title": "S$^2$Voice: Style-Aware Autoregressive Modeling with Enhanced Conditioning for Singing Style Conversion",
    "authors": "Ziqian Wang, Xianjun Xia, Chuanzeng Huang, Lei Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13629v1",
    "source": "arXiv",
    "abstract": "We present S$^2$Voice, the winning system of the Singing Voice Conversion Challenge (SVCC) 2025 for both the in-domain and zero-shot singing style conversion tracks. Built on the strong two-stage Vevo baseline, S$^2$Voice advances style control and robustness through several contributions. First, we integrate style embeddings into the autoregressive large language model (AR LLM) via a FiLM-style layer-norm conditioning and a style-aware cross-attention for enhanced fine-grained style modeling. Second, we introduce a global speaker embedding into the flow-matching transformer to improve timbre similarity. Third, we curate a large, high-quality singing corpus via an automated pipeline for web harvesting, vocal separation, and transcript refinement. Finally, we employ a multi-stage training strategy combining supervised fine-tuning (SFT) and direct preference optimization (DPO). Subjective listening tests confirm our system's superior performance: leading in style similarity and singer similarity for Task 1, and across naturalness, style similarity, and singer similarity for Task 2. Ablation studies demonstrate the effectiveness of our contributions in enhancing style fidelity, timbre preservation, and generalization. Audio samples are available~\\footnote{https://honee-w.github.io/SVC-Challenge-Demo/}."
  },
  {
    "date": "2026-01-20",
    "title": "Reflections over the Sea: Reconfigurable Intelligent Surface for Maritime Self-Powered Communications",
    "authors": "Qianqian Zhang, Long Wang, Ben Wu, Jia Mi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13618v1",
    "source": "arXiv",
    "abstract": "Maritime communication is becoming a vital component of 6G networks, driven by the rapid expansion of the maritime economy. However, existing technologies face critical challenges in signal coverage, availability, and robustness, especially under harsh sea conditions. This paper proposes a novel framework for the maritime Internet-of-Things (IoT) communications that leverages the reconfigurable intelligent surface (RIS) mounted on offshore infrastructures, such as wind turbines, to enhance coverage and reliability. To capture dynamic maritime environment, a near-ocean-surface channel model is developed considering the impact of sea waves. In addition, a wave energy harvesting (EH) system is designed to self-power IoT sensors for data acquisition, processing, and transmission. To support real-time adaptation, channel state information is continuously measured to optimize RIS reflection parameters and maximize multi-user communication rates. Simulation results show that the proposed system significantly improves IoT communication performance by over 20%, under harsh sea conditions."
  },
  {
    "date": "2026-01-20",
    "title": "The Structure of an 80 pc Long Massive Filament",
    "authors": "Qian-Ru He, Won-Ju Kim, Gary A. Fuller, Alessio Traficante, Seamus D. Clarke, Yu Gao, Xue-Peng Chen, Min Fang, Ke Wang, En Chen, Tapas Baug, Xiao-Long Wang, Chen Wang, Yong-Xiong Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13616v1",
    "source": "arXiv",
    "abstract": "Using new Institut de Radioastronomie Millimétrique (IRAM) 30m telescope $\\rm N_2H^+$, $\\rm C^{18}O$ $J$=1-0 and Atacama Pathfinder Experiment (APEX) telescope $\\rm ^{13}CO$ and $\\rm C^{18}O$ $J$=2-1 maps together with archival far-infrared continuum data, and $\\rm ^{12}CO$, and $\\rm ^{13}CO$ $J$=1-0 data, we present a comprehensive analysis of the massive filament CFG024.00$+$0.48 (G24) across clump-to-cloud scales. Our results show that G24 is an $\\sim$80 pc giant filament with a total mass of $\\sim$$10^5$ M$_{\\odot}$. In the different tracers the filament width is measured to be about $\\sim$2 times the beam size of the observations, as expected for power-law density distributions, giving beam-deconvolved widths in the range from 0.8 to 2.8 pc. We determine a line-of-sight thickness of $\\sim$2.2 pc demonstrating that G24 is not an edge-on, flatten structure. The virial parameter obtained from line mass ($α_{\\rm line,vir}=M_{\\rm line,vir}/M_{\\rm line}$) from the $\\rm C^{18}O$ (1-0) data is 0.85, and that obtained from $Herschel$-based H$_2$ column density is 0.52, suggesting G24 is globally close to virial equilibrium. The distribution of the 40 dust clumps appears to have a ''two-tier'' fragmentation pattern. For the clump groups, the separation, with a mean/median of 3.68/3.46 pc, is very close to expected length associated with the maximum fragmentation growth rate of $λ_{\\rm max}=3.55 \\pm0.32$ pc estimated for the dust. However, the longitudinal centroid velocity profiles of $\\rm C^{18}O$ and $\\rm N_2H^+$ show oscillation patterns with wavelengths of 9.8$\\pm$0.1 pc and 9.9$\\pm$0.1 pc, respectively. This is $\\sim$2 times larger than the corresponding values of $λ_{\\rm max}$ of 4.96$\\pm$0.63 pc and 4.65$\\pm$1.34 pc, respectively. This suggests that the velocity structure is not dominated by flows directly associated with the fragmentation seen in the dust emission."
  },
  {
    "date": "2026-01-20",
    "title": "ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch",
    "authors": "Zheng Liu, Honglin Lin, Chonghan Qin, Xiaoyang Wang, Xin Gao, Yu Li, Mengzhang Cai, Yun Zhu, Zhanping Zhong, Qizhi Pei, Zhuoshi Pan, Xiaoran Shang, Bin Cui, Conghui He, Wentao Zhang, Lijun Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13606v1",
    "source": "arXiv",
    "abstract": "Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking."
  },
  {
    "date": "2026-01-20",
    "title": "Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search",
    "authors": "Xinlei Yin, Xiulian Peng, Xiao Li, Zhiwei Xiong, Yan Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13719v1",
    "source": "arXiv",
    "abstract": "Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos."
  },
  {
    "date": "2026-01-20",
    "title": "Altermagnetic phases and phase transitions in Lieb-$5$ Hubbard model",
    "authors": "Sougata Biswas, Achintyaa, Paramita Dutta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14200v1",
    "source": "arXiv",
    "abstract": "The emergence of altermagnetism, the collinear magnetic phase characterized by momentum-dependent spin-split bands but zero net magnetization, has fundamentally reshaped the classification of magnetic order. We propose an altermagnetic (AM) order in a repulsive Hubbard model on the Lieb-$5$ lattice. Considering only nearest-neighbor hoppings within the lattice, we show a phase transition from the nonmagnetic to a unique AM isolated band metal phase (AMIM), allowing clear identification of spin-split states. Additionally, the AM metallic phase (AMM) is also shown to appear as an intermediate phase during the transition from the normal metal to the AMIM in the presence of the diagonal hopping within each unit cell of the Lieb-$5$ lattice. The manifestation of distinct AM phases and the phase transitions, driven by Hubbard interaction and hopping integrals, have been explored in terms of spin-resolved band structure, spectral function, and the behavior of the AM order parameter. The stability of these AM phases against the spin-orbit coupling and temperature is also established."
  },
  {
    "date": "2026-01-20",
    "title": "A self-consistent explanation of the MeV line in GRB 221009A unveils a dense circum-stellar medium",
    "authors": "O. S. Salafia, A. Celotti, E. Sobacchi, L. Nava, G. Oganesyan, G. Ghirlanda, S. Boula, M. E. Ravasio, G. Ghisellini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14257v1",
    "source": "arXiv",
    "abstract": "GRB~221009A has been the brightest gamma-ray burst (GRB) observed to date, and its afterglow has been characterised with unprecedented detail at TeV energies by LHAASO. Quite puzzlingly, it is also the most energetic GRB known. Among the riddles posed by this mysterious source, however, the sheer energetics are hardly the most intriguing: an unprecedented, narrow, luminous emission line at around 10 MeV has been uncovered by a detailed spectral analysis of \\textit{Fermi}/GBM data immediately following the brightest peak in the GRB prompt emission and the peak of the TeV afterglow. As noted in the discovery article, the temporal evolution of the line properties can be explained as being due to high-latitude emission from a geometrically thin, relativistically expanding shell where annihilation of a large number of electron-positron pairs took place. We show that this interpretation yields stringent constraints on the properties of such shell, that point to a process that happens at radii typical of external shocks. We then demonstrate that the shell could have been the blastwave associated with the GRB precursor, with the line arising after pair loading of such blastwave as it was illuminated by the bright and hard radiation of the GRB main event. The scenario, which also explains the abrupt initial rise of the LHAASO afterglow, requires the progenitor of the GRB to have been surrounded by a circum-stellar medium (CSM) extending out to a few $10^{15}\\,\\mathrm{cm}$, with a density $n_\\mathrm{ext}\\sim 10^{8}-10^{9}\\,\\mathrm{cm^{-3}}$ reminiscent of those found from studies of Type IIn supernovae. This provides a precious clue to the nature of the progenitor of this peculiar GRB, which could also be present in other bursts that feature a long quiescence followed by a bright emission episode with a hard spectrum."
  },
  {
    "date": "2026-01-20",
    "title": "Conformal dimension and its attainment on self-similar Laakso-type fractal spaces",
    "authors": "Riku Anttila, Sylvester Eriksson-Bique, Lassi Rainio",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14241v1",
    "source": "arXiv",
    "abstract": "A general construction of Laakso-type fractal spaces was recently introduced by the first two authors. In this paper, we establish a simple condition characterizing when the Ahlfors regular conformal dimension of a symmetric Laakso-type fractal space is attained. The attaining metrics are constructed explicitly. This gives new examples of attainment and clarifies the possible obstructions."
  },
  {
    "date": "2026-01-20",
    "title": "Counterexample Classification against Signal Temporal Logic Specifications",
    "authors": "Zhenya Zhang, Parv Kapoor, Jie An, Eunsuk Kang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13743v1",
    "source": "arXiv",
    "abstract": "Signal Temporal Logic (STL) has been widely adopted as a specification language for specifying desirable behaviors of hybrid systems. By monitoring a given STL specification, we can detect the executions that violate it, which are often referred to as counterexamples. In practice, these counterexamples may arise from different causes and thus are relevant to different system defects. To effectively address this, we need a proper criterion for classifying these counterexamples, by which we can comprehend the possible violation patterns and the distributions of these counterexamples with respect to the patterns. In this paper, we propose a classification criterion by using parametric signal temporal logic (PSTL) to represent each class. Due to this formalism, identifying the classes of a counterexample requires finding proper parameter values of PSTL that enable a class to include the counterexample. To improve the efficiency of class identification, we further derive an inclusion relation between different classes, and then propose a binary search-like approach over it that significantly prunes the classes needed to query. We implement a prototype tool and experimentally evaluate its effectiveness on two widely-studied systems."
  },
  {
    "date": "2026-01-20",
    "title": "Generating consensus and dissent on massive discussion platforms with an $O(N)$ semantic-vector model",
    "authors": "A. Ferrer, D. Muñoz-Jordán, A. Rivero, A. Tarancón, C. Tarancón, D. Yllanes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13932v1",
    "source": "arXiv",
    "abstract": "Reaching consensus on massive discussion networks is critical for reducing noise and achieving optimal collective outcomes. However, the natural tendency of humans to preserve their initial ideas constrains the emergence of global solutions. To address this, Collective Intelligence (CI) platforms facilitate the discovery of globally superior solutions. We introduce a dynamical system based on the standard $O(N)$ model to drive the aggregation of semantically similar ideas. The system consists of users represented as nodes in a $d=2$ lattice with nearest-neighbor interactions, where their ideas are represented by semantic vectors computed with a pretrained embedding model. We analyze the system's equilibrium states as a function of the coupling parameter $β$. Our results show that $β> 0$ drives the system toward a ferromagnetic-like phase (global consensus), while $β< 0$ induces an antiferromagnetic-like state (maximum dissent), where users maximize semantic distance from their neighbors. This framework offers a controllable method for managing the tradeoff between cohesion and diversity in CI platforms."
  },
  {
    "date": "2026-01-20",
    "title": "Coupling Quantum Dots to Elastic Waves in a Phononic Crystal Waveguide",
    "authors": "Jakub Rosiński, Michał Gawełczyk, Matthias Weiß, Hubert J. Krenner, Paweł Machnikowski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14162v1",
    "source": "arXiv",
    "abstract": "We present a comprehensive study of quantum dot (QD) coupling to various phononic modes in a phononic waveguide, combining multiband kp and configuration-interaction (CI) QD state simulations with finite-element waveguide mode modeling. We consider self-assembled Stranski-Krastanov InGaAs/GaAs as well as local droplet-etched GaAs/AlGaAs structures. Using kp-CI calculations, we quantify the strain and piezoelectric responses of InAs and GaAs QDs. By systematically isolating volumetric/shear deformation-potential and piezoelectric channels, we demonstrate how mode symmetries dictate distinct coupling mechanisms. We identify the dominant coupling channels and characterize their observable signatures in the QD response. We predict strong linear energy shifts under volumetric strain and quadratic behavior under shear strain, especially in GaAs QDs. The piezoelectric effect is dominated by polarizability, which also leads to a quadratic response. The simulations show energy modulations up to 0.7 meV for an acoustic wave with 0.1 nm amplitude. The quadratic response to shear strain and piezoelectric field leads to frequency doubling in the QD response to a mechanical wave and to non-harmonic time traces when linear and quadratic effects contribute to a similar degree. The deep understanding of QD-acoustic couplings opens pathways to the optimal design of QD and waveguide structures, as well as to improved engineering of acousto-optic quantum interfaces."
  },
  {
    "date": "2026-01-20",
    "title": "Scheme theory for commutative semirings",
    "authors": "Roberto Gualdi, Arne Kuhrs, Mayo Mayo Garcia, Xavier Xarles",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14136v1",
    "source": "arXiv",
    "abstract": "In this survey, we describe two different approaches to constructing affine schemes for commutative semirings: one based on prime ideals, and another based on prime kernels (also called subtractive ideals). We then explain how these two approaches are related through the theory of universal valuations."
  },
  {
    "date": "2026-01-20",
    "title": "Generalised contextuality of continuous variable quantum theory can be revealed with a single projective measurement",
    "authors": "Pauli Jokinen, Mirjam Weilenmann, Martin Plávala, Juha-Pekka Pellonpää, Jukka Kiukas, Roope Uola",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14067v1",
    "source": "arXiv",
    "abstract": "Generalized contextuality is a possible indicator of non-classical behaviour in quantum information theory. In finite-dimensional systems, this is justified by the fact that noncontextual theories can be embedded into some simplex, i.e. into a classical theory. We show that a direct application of the standard definition of generalized contextuality to continuous variable systems does not envelope the statistics of some basic measurements, such as the position observable. In other words, we construct families of fully classical, i.e. commuting, measurements that nevertheless can be used to show contextuality of quantum theory. To overcome the apparent disagreement between the two notions of classicality, that is commutativity and noncontextuality, we propose a modified definition of generalised contextuality for continuous-variable systems. The modified definition is based on a physically-motivated approximation procedure, that uses only finite sets of measurement effects. We prove that in the limiting case this definition corresponds exactly to an extension of noncontextual models that benefits from non-constructive response functions. In the process, we discuss the extension of a known connection between contextuality and no-broadcasting to the continuous-variable scenario, and prove structural results regarding fixed points of infinite-dimensional entanglement breaking channels."
  },
  {
    "date": "2026-01-20",
    "title": "Follow-up of three exocomet-host candidates",
    "authors": "P. Muñoz-Cutanda, I. Rebollido, B. Montesinos, P. Cruz, O. Absil, S. Ertel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13850v1",
    "source": "arXiv",
    "abstract": "Exocomets are small bodies that evaporate when they approach their host star. They are detected through variability of non-photospheric features with spectroscopy and/or asymmetric transits in time-series photometry. In the past four decades ~30 systems have shown such variations, and were therefore classified as exocomet host stars. However, some publications have pointed out mechanisms that might mimic exocometary features, and therefore, careful monitoring is needed to confirm the origin of the observed variability. With this paper we aim to investigate the exocomet nature of the non-photospheric variable features observed in the exocomet candidate stars HD 36546, HD 42111 and HD 85905. All of them have shown some degree of variability, particularly in their Ca II K line. We analysed the non-photospheric Ca II K line features from high-resolution spectra obtained using new NOT/FIES and Mercator/HERMES, and some additional archival spectra of the target stars. The variability was quantified through the changes in the equivalent widths of those features, which are assumed to be of circumstellar origin. Column densities were also estimated for each variable feature. Strong variability was found for HD 85905, consistent with a potential link to exocometary activity. However, the binarity of the system, which we confirmed through interferometric VLTI/PIONIER observations, complicates the interpretation of these signatures and prevents us from drawing definitive conclusions. The remaining two sources do not show any significant variability, but due to the sporadic nature of the exocometary events, we cannot discard the exocomet hypothesis. Further monitoring of the stars will be necessary to carry out a robust determination of the variability patterns and timescales that would completely rule out other scenarios."
  },
  {
    "date": "2026-01-20",
    "title": "Balancing Independent and Collaborative Service",
    "authors": "Shuwen Lu, Mark E. Lewis, Jamol Pender",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13586v1",
    "source": "arXiv",
    "abstract": "We study a two-type server queueing system where flexible Type-I servers, upon their initial interaction with jobs, decide in real time whether to process them independently or in collaboration with dedicated Type-II servers. Independent processing begins immediately, as does collaborative service if a Type-II server is available. Otherwise, the job and its paired Type-I server wait in queue for collaboration. Type-I servers are non-preemptive and cannot engage with new jobs until their current job is completed. We provide a complete characterization of the structural properties of the optimal policy for the clearing system. In particular, an optimal control is shown to follow a threshold structure based on the number of jobs in the queue before a Type-I first interaction and on the number of jobs in either independent or collaborative service. We propose simple threshold heuristics, based on linear approximations, for real-time decision-making. In much of the parameter and state spaces, we establish theoretical bounds that compare the thresholds proposed by our heuristics to those of optimal policies and identify parameter configurations where these bounds are attained. Outside of these regions, the optimal thresholds are infinite. Numerical experiments further demonstrate the accuracy and robustness of our heuristics, particularly when the initial queue length is high. Our proposed heuristics achieve costs within 0.5% of the optimal policy on average and significantly outperform benchmark policies that exhibit extreme sensitivity to system parameters, sometimes incurring costs exceeding 100% of the optimal."
  },
  {
    "date": "2026-01-20",
    "title": "SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System",
    "authors": "Heedou Kim, Changsik Kim, Sanghwa Shin, Jaewoo Kang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13581v1",
    "source": "arXiv",
    "abstract": "Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense."
  },
  {
    "date": "2026-01-20",
    "title": "Toward Ultra-fast Treatments: Large Energy Acceptance Beam Delivery Systems and Opportunities for Proton Beam Therapy",
    "authors": "Jacinta Yap, Adam Steinberg, Hannah Norman, Konrad Nesteruk, Suzie Sheehy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13577v1",
    "source": "arXiv",
    "abstract": "Treatment delivery is largely determined by capabilities of the beam delivery system (BDS), where faster delivery can have many potential benefits including improved dosimetric quality, utility, cost effectiveness, patient throughput and comfort. Despite significant developments in accelerators, delivery methodologies, dose optimisation and more, the energy layer switching time (ELST) is still a persisting limitation in existing BDS. The ELST can contribute significantly to beam delivery time (BDT) and extend treatment times, requiring compensation by optimisation planning approaches, motion mitigation strategies, or active beam modification. This fundamental constraint can be addressed by increasing the narrow energy acceptance range of conventional beamlines to minimise the ELST, enabling ultra-fast delivery. A large energy acceptance (LEA) BDS has the potential to revolutionise PBT through immediate improvements to current treatment delivery and emerging delivery modalities: the complete exploitation of PBT - and unlocking its full potential - can only be made possible with advances in beam delivery technologies. We review the abundant opportunities offered by an ultra-fast BDS: shorter treatment times, reduced motion induced dose degradation, improved effectiveness of motion management techniques, possibilities for volumetric rescanning, bidirectional delivery, further planning optimisation, and novel delivery strategies. We overview the design concepts of several LEA proposals, technology requirements, and also discuss the remaining challenges and considerations with realising a LEA BDS in practice. There are multiple avenues requiring further development and study, however the clinical potential and benefits of this enabling technology are clear: ultra-fast delivery offers both immediate and future improvements to PBT treatments."
  },
  {
    "date": "2026-01-20",
    "title": "Control policies for a two-stage queueing system with parallel and single server options",
    "authors": "Shuwen Lu, Jamol Pender, Mark E. Lewis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13576v1",
    "source": "arXiv",
    "abstract": "We study a two-stage tandem service queue attended by two servers. Each job-server pair must complete both service phases together, with the server unable to begin a new job until the current one is fully processed after two stages. Immediately after the first phase of service, the server decides whether to send the job/customer to a downstream station that allows parallel processing or to a single-service facility that offers faster or higher-quality service but handles only one job at a time. This choice determines whether the second phase commences immediately or (potentially) after waiting in a queue for the single-service facility to become available. The decision-making scenario is modeled via a Markov decision process formulation, of a clearing system with holding costs at each station. We fully characterize the structural properties of an optimal control policy based on the relationship between the service rates at the downstream stations. A numerical study highlights the significance of optimal control by comparing its performance against several natural heuristic policies."
  },
  {
    "date": "2026-01-20",
    "title": "Behavior Knowledge Merge in Reinforced Agentic Models",
    "authors": "Xiangchi Yuan, Dachuan Shi, Chunhui Zhang, Zheyuan Liu, Shenglong Yao, Soroush Vosoughi, Wenke Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13572v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains."
  },
  {
    "date": "2026-01-20",
    "title": "Logarithmic geometry and Infinitesimal Hodge Theory",
    "authors": "Mounir Nisse",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13568v1",
    "source": "arXiv",
    "abstract": "This paper develops a systematic approach to infinitesimal variations of Hodge structure for singular and equisingular families by means of logarithmic geometry and residue theory. The central idea is that logarithmic vector fields encode precisely those deformation directions that preserve singularities and act trivially on Hodge structures, while the effective variation is entirely governed by residue calculus. This viewpoint provides a conceptual reinterpretation of classical results of Griffiths, Green, and Voisin, and extends them to settings involving singular varieties and equisingular deformations. The resulting framework yields a geometric explanation for the appearance of Jacobian rings in infinitesimal Hodge theory and clarifies the structure of deformation spaces underlying Severi varieties and related moduli problems."
  },
  {
    "date": "2026-01-20",
    "title": "Self-Improvement as Coherence Optimization: A Theoretical Account",
    "authors": "Tianyi Qiu, Ahmed Hani Ismail, Zhonghao He, Shi Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13566v1",
    "source": "arXiv",
    "abstract": "Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail."
  },
  {
    "date": "2026-01-20",
    "title": "On the radius of analyticity and Gevrey regularity for the Boltzmann equation",
    "authors": "Wei-Xi Li, Lvqiao Liu, Hao Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13560v1",
    "source": "arXiv",
    "abstract": "This paper investigates the non-cutoff Boltzmann equation for hard potentials in a perturbative setting. We first establish a sharp short-time estimate on the radius of analyticity and Gevrey regularity of mild solutions. Furthermore, we obtain a global-in-time radius estimate in Gevrey space. The proof combines hypoelliptic estimates with the macro-micro decomposition."
  },
  {
    "date": "2026-01-20",
    "title": "AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent",
    "authors": "Sun Hui, Ding Yanfeng, Huidong Ma, Chang Xu, Keyan Jin, Lizheng Zu, Cheng Zhong, xiaoguang Liu, Gang Wang, Wentong Cai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13559v1",
    "source": "arXiv",
    "abstract": "Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively."
  },
  {
    "date": "2026-01-20",
    "title": "DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis",
    "authors": "Feng Ding, Wenhui Yi, Xinan He, Mengyao Xiao, Jianfeng Xu, Jianqiang Du",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13551v1",
    "source": "arXiv",
    "abstract": "Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit."
  },
  {
    "date": "2026-01-20",
    "title": "Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models",
    "authors": "Changshuo Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13533v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the \"reason first, recommend later\" paradigm to achieve \"reasoning while recommending\", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential."
  },
  {
    "date": "2026-01-20",
    "title": "An upper limit on cosmological chiral gravitational wave background",
    "authors": "Mohammad Ali Gorji, Ashu Kushwaha, Teruaki Suyama",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13532v1",
    "source": "arXiv",
    "abstract": "Within the standard framework in which electroweak sphaleron processes relate lepton and baryon number, we derive an upper limit on the amplitude of a chiral gravitational wave background produced prior to the electroweak epoch. This bound is independent of the production time of chiral GWs for superhorizon modes, while it becomes sensitive to the production time for subhorizon modes. For sufficiently high reheating temperatures, the bound becomes significantly more stringent than the conventional big bang nucleosynthesis constraints at frequencies above the MHz scale, thereby providing a powerful and \\emph{model-independent} probe of parity-violating physics in the early Universe."
  },
  {
    "date": "2026-01-20",
    "title": "Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs",
    "authors": "Jackson Kaunismaa, Avery Griffin, John Hughes, Christina Q. Knight, Mrinank Sharma, Erik Jones",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13528v1",
    "source": "arXiv",
    "abstract": "Model developers implement safeguards in frontier models to prevent misuse, for example, by employing classifiers to filter dangerous outputs. In this work, we demonstrate that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. Our elicitation attacks consist of three stages: (i) constructing prompts in adjacent domains to a target harmful task that do not request dangerous information; (ii) obtaining responses to these prompts from safeguarded frontier models; (iii) fine-tuning open-source models on these prompt-output pairs. Since the requested prompts cannot be used to directly cause harm, they are not refused by frontier model safeguards. We evaluate these elicitation attacks within the domain of hazardous chemical synthesis and processing, and demonstrate that our attacks recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. We then show that the efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. Our work demonstrates the challenge of mitigating ecosystem level risks with output-level safeguards."
  },
  {
    "date": "2026-01-20",
    "title": "Demonstration of a novel phase space painting method in a coupled lattice to mitigate space charge in high-intensity hadron beams",
    "authors": "Nicholas J. Evans, Austin Hoover, Timofey Gorlov, Vasiliy Morozov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13517v1",
    "source": "arXiv",
    "abstract": "Multi-turn charge-exchange injection is the primary method of creating high-intensity hadron beams in circular accelerators, and phase space painting during injection enables tailoring of the accumulated phase space distribution. A technique we call eigenpainting allows injection of particles into a single mode of a coupled ring, providing full four-dimensional control of the phase space distribution. Under ideal conditions, uniform eigenpainting generates a linear-force equilibrium distribution in the transverse plane, with zero volume in four-dimensional transverse phase space, even including space charge. We have implemented eigenpainting for the first time in the Spallation Neutron Source (SNS) Accumulator Ring. Injecting 8.8 $μ$C of 800 MeV beam, we obtain a final ratio of intrinsic transverse emittances of $\\approx$2.4. We analyze the effect of space charge on the final distribution through comparison of the reconstructed phase space to particle-in-cell simulations."
  },
  {
    "date": "2026-01-20",
    "title": "Post-selection inference for penalized M-estimators via score thinning",
    "authors": "Ronan Perry, Snigdha Panigrahi, Daniela Witten",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13514v1",
    "source": "arXiv",
    "abstract": "We consider inference for M-estimators after model selection using a sparsity-inducing penalty. While existing methods for this task require bespoke inference procedures, we propose a simpler approach, which relies on two insights: (i) adding and subtracting carefully-constructed noise to a Gaussian random variable with unknown mean and known variance leads to two \\emph{independent} Gaussian random variables; and (ii) both the selection event resulting from penalized M-estimation, and the event that a standard (non-selective) confidence interval for an M-estimator covers its target, can be characterized in terms of an approximately normal ``score variable\". We combine these insights to show that -- when the noise is chosen carefully -- there is asymptotic independence between the model selected using a noisy penalized M-estimator, and the event that a standard (non-selective) confidence interval on noisy data covers the selected parameter. Therefore, selecting a model via penalized M-estimation (e.g. \\verb=glmnet= in \\verb=R=) on noisy data, and then conducting \\emph{standard} inference on the selected model (e.g. \\verb=glm= in \\verb=R=) using noisy data, yields valid inference: \\emph{no bespoke methods are required}. Our results require independence of the observations, but only weak distributional requirements. We apply the proposed approach to conduct inference on the association between sex and smoking in a social network."
  },
  {
    "date": "2026-01-20",
    "title": "Event Classification by Physics-informed Inpainting for Distributed Multichannel Acoustic Sensor with Partially Degraded Channels",
    "authors": "Noriyuki Tonami, Wataru Kohno, Yoshiyuki Yajima, Sakiko Mishima, Yumi Arai, Reishi Kondo, Tomoyuki Hino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13513v1",
    "source": "arXiv",
    "abstract": "Distributed multichannel acoustic sensing (DMAS) enables large-scale sound event classification (SEC), but performance drops when many channels are degraded and when sensor layouts at test time differ from training layouts. We propose a learning-free, physics-informed inpainting frontend based on reverse time migration (RTM). In this approach, observed multichannel spectrograms are first back-propagated on a 3D grid using an analytic Green's function to form a scene-consistent image, and then forward-projected to reconstruct inpainted signals before log-mel feature extraction and Transformer-based classification. We evaluate the method on ESC-50 with 50 sensors and three layouts (circular, linear, right-angle), where per-channel SNRs are sampled from -30 to 0 dB. Compared with an AST baseline, scaling-sparsemax channel selection, and channel-swap augmentation, the proposed RTM frontend achieves the best or competitive accuracy across all layouts, improving accuracy by 13.1 points on the right-angle layout (from 9.7% to 22.8%). Correlation analyses show that spatial weights align more strongly with SNR than with channel--source distance, and that higher SNR--weight correlation corresponds to higher SEC accuracy. These results demonstrate that a reconstruct-then-project, physics-based preprocessing effectively complements learning-only methods for DMAS under layout-open configurations and severe channel degradation."
  },
  {
    "date": "2026-01-20",
    "title": "Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives",
    "authors": "Kyung Ho Lim, Byung-Hoon Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13503v1",
    "source": "arXiv",
    "abstract": "Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives."
  },
  {
    "date": "2026-01-20",
    "title": "Modeling Perpetrators' Fate-to-Fate Contagion in Public Mass Shootings In The United States Using Bivariate Hawkes Processes",
    "authors": "Youness Diouane, James Silver",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13501v1",
    "source": "arXiv",
    "abstract": "This study examines how the fate of a perpetrator in a public mass shooting influences the fate of subsequent perpetrators. Using data from 1966 to 2024, we classify incidents according to whether the perpetrator died at the scene or survived the attack. Using a bivariate Hawkes process, we quantify the cross-excitation effect, which is the triggering effect that each event type exerts on the other, i.e., \"die at the scene\"$\\rightarrow$ \"live\" and \"live\"$\\rightarrow$ \"die at the scene\", as well as the self-excitation effects, i.e., \"die at the scene\"$\\rightarrow$ \"die at the scene\" and \"live\"$\\rightarrow$ \"live\". Our results show that the strongest spillover was from \"live\" incidents to \"die at the scene\", where we estimate that 0.34 (0.09, 0.80) of \"die at the scene\" incidents are triggered by a prior event in which the offender survived the attack. This pathway also exhibits the longest estimated contagion timescale: approximately 20 days. In contrast, the reverse influence, that is, \"die at the scene\"$\\rightarrow$\"live\", is not statistically significant, with the lower bound of its 95% confidence interval nearly equal to zero. We also find that \"die at the scene\" events can only cause their own type, where 0.139 (0.01, 0.52) of such incidents are caused by previous \"die at the scene\" events, with the shortest contagion timescale of roughly 20 hours."
  },
  {
    "date": "2026-01-20",
    "title": "Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging",
    "authors": "Nimrod Kruger, Nicholas Owen Ralph, Gregory Cohen, Paul Hurley",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13498v1",
    "source": "arXiv",
    "abstract": "Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems."
  },
  {
    "date": "2026-01-20",
    "title": "RASC: Enhancing Observability & Programmability in Smart Spaces",
    "authors": "Anna Karanika, Kai-Siang Wang, Han-Ting Liang, Shalni Sundram, Indranil Gupta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13496v1",
    "source": "arXiv",
    "abstract": "While RPCs form the bedrock of systems stacks, we posit that IoT device collections in smart spaces like homes, warehouses, and office buildings--which are all \"user-facing\"--require a more expressive abstraction. Orthogonal to prior work, which improved the reliability of IoT communication, our work focuses on improving the observability and programmability of IoT actions. We present the RASC (Request-Acknowledge-Start-Complete) abstraction, which provides acknowledgments at critical points after an IoT device action is initiated. RASC is a better fit for IoT actions, which naturally vary in length spatially (across devices) and temporally (across time, for a given device). RASC also enables the design of several new features: predicting action completion times accurately, detecting failures of actions faster, allowing fine-grained dependencies in programming, and scheduling. RASC is intended to be implemented atop today's available RPC mechanisms, rather than as a replacement. We integrated RASC into a popular and open-source IoT framework called Home Assistant. Our trace-driven evaluation finds that RASC meets latency SLOs, especially for long actions that last O(mins), which are common in smart spaces. Our scheduling policies for home automations (e.g., routines) outperform state-of-the-art counterparts by 10%-55%."
  },
  {
    "date": "2026-01-20",
    "title": "Learning-Augmented Online TRP on a Line",
    "authors": "Swapnil Guragain, Gokarna Sharma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13494v1",
    "source": "arXiv",
    "abstract": "We study the online traveling repairperson problem on a line within the recently proposed learning-augmented framework, which provides predictions on the requests to be served via machine learning. In the original model (with no predictions), there is a stream of requests released over time along the line. The goal is to minimize the sum (or average) of the completion times of the requests. In the original model, the state-of-the-art competitive ratio lower bound is $1+\\sqrt{2} > 2.414$ for any deterministic algorithm and the state-of-the-art competitive ratio upper bound is 4 for a deterministic algorithm. Our prediction model involves predicted positions, possibly error-prone, of each request in the stream known a priori but the arrival times of requests are not known until their arrival. We first establish a 3-competitive lower bound which extends to the original model. We then design a deterministic algorithm that is $(2+\\sqrt{3})\\approx 3.732$-competitive when predictions are perfect. With imperfect predictions (maximum error $δ> 0$), we show that our deterministic algorithm becomes $\\min\\{3.732+4δ,4\\}$-competitive, knowing $δ$. To the best of our knowledge, these are the first results for online traveling repairperson problem in the learning-augmented framework."
  },
  {
    "date": "2026-01-20",
    "title": "Quantum Avalanche Stability of Many-Body Localization with Power-Law Interactions",
    "authors": "Longhui Shen, Bin Guo, Zhaoyu Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13485v1",
    "source": "arXiv",
    "abstract": "We investigate the stability of the many-body localized phase against quantum avalanche instabilities in a one-dimensional Heisenberg spin chain with long-range power-law interactions ($V\\propto r^{-α}$). By combining exact diagonalization of static properties with Lindblad master equation simulations of open-system dynamics, we systematically map the interplay between interaction range and disorder strength. Our finite-size scaling analysis of entanglement entropy identifies a critical interaction exponent $α_c \\approx 2$, which separates a fragile regime, characterized by an exponentially diverging critical disorder, from a robust short-range regime. To rigorously test the system's resistance to avalanches, we couple the boundary to an infinite-temperature bath and track the propagation of the thermalization front into the localized bulk. We find that the characteristic thermalization time follows a unified scaling law, $T_{r_{\\text{th}}} \\sim \\exp[κ(α) LW]$ (herein, $L$ is the system size, and $W$ is the disorder intensity), which diverges exponentially with the product of system size and disorder strength. This suppression enables the derivation of a quantitative stability criterion, $W_{\\text{stab}}(α)$, representing the minimum critical disorder strength required to maintain avalanche stability. Our results confirm that the MBL phase remains asymptotically stable in the thermodynamic limit when disorder exceeds an interaction-dependent threshold, bridging theoretical debates on long-range MBL and providing a roadmap for observing these dynamics in experimental platforms such as Rydberg atom arrays."
  },
  {
    "date": "2026-01-20",
    "title": "Architectures of Exoplanetary Systems. IV: A Multi-planet Model for Reproducing the Radius Valley and Intra-system Size Similarity of Planets around Kepler's FGK Dwarfs",
    "authors": "Matthias Y. He, Eric B. Ford",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13480v1",
    "source": "arXiv",
    "abstract": "The Kepler-observed distribution of planet sizes have revealed two distinct patterns: (1) a radius valley separating super-Earths and sub-Neptunes and (2) a preference for intra-system size similarity. We present a new model for the exoplanet population observed by Kepler, which is a \"hybrid\" of a clustered multi-planet model in which the orbital architectures are set by the angular momentum deficit (AMD) stability (He et al. 2020; arXiv:2007.14473) and a joint mass-radius-period model involving envelope mass-loss driven by photoevaporation (Neil & Rogers 2020; arXiv:1911.03582). We find that the models that produce the deepest radius valleys have a primordial population of planets with initial radii peaking at $\\sim 2.1 R_\\oplus$, which is subsequently sculpted by photoevaporation into a bimodal distribution of final planet radii. The hybrid model requires strongly clustered initial planet masses in order to match the distributions of the size similarity metrics. Thus, the preference for intra-system radius similarity is well explained by a clustering in the primordial mass distribution. The hybrid model also naturally reproduces the observed radius cliff (steep drop-off beyond $\\sim 2.5 R_\\oplus$). Our hybrid model is the latest installment of the SysSim forward models, and is the first multi-planet model capable of simultaneously reproducing the observed radius valley and the intra-system size similarity patterns. We compute occurrence rates and fractions of stars with planets for a variety of planet types, and find that the occurrence of Venus and Earth-like planets drops by a factor of $\\sim 2$-4 for the hybrid models compared to previous clustered models in which there is no envelope mass-loss."
  },
  {
    "date": "2026-01-20",
    "title": "Symmetric Informationally Complete Positive Operator Valued Measure and Zauner conjecture",
    "authors": "Stefan Joka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13475v1",
    "source": "arXiv",
    "abstract": "In this paper, we show that in Hilbert space of any finite dimension N, there are N^2 pure states which constitute Symmetric Informationally Complete Positive Operator Valued Measure (SIC-POVM)."
  },
  {
    "date": "2026-01-20",
    "title": "Building a Standardised Statistical Reporting Toolbox in an Academic Oncology Clinical Trials Unit: The grstat R Package",
    "authors": "Dan Chaltiel, Alexis Cochard, Nusaibah Ibrahimi, Charlotte Bargain, Ikram Benchara, Anne Lourdessamy, Aldéric Fraslin, Matthieu Texier, Livia Pierotti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13755v1",
    "source": "arXiv",
    "abstract": "Academic Clinical Trial Units frequently face fragmented statistical workflows, leading to duplicated effort, limited collaboration, and inconsistent analytical practices. To address these challenges within an oncology Clinical Trial Unit, we developed grstat, an R package providing a standardised set of tools for routine statistical analyses. Beyond the software itself, the development of grstat is embedded in a structured organisational framework combining formal request tracking, peer-reviewed development, automated testing, and staged validation of new functionalities. The package is intentionally opinionated, reflecting shared practices agreed upon within the unit, and evolves through iterative use in real-world projects. Its development as an open-source project on GitHub supports transparent workflows, collective code ownership, and traceable decision-making. While primarily designed for internal use, this work illustrates a transferable approach to organising, validating, and maintaining a shared analytical toolbox in an academic setting. By coupling technical implementation with governance and validation principles, grstat supports efficiency, reproducibility, and long-term maintainability of biostatistical workflows, and may serve as a source of inspiration for other Clinical Trial Units facing similar organisational challenges."
  },
  {
    "date": "2026-01-20",
    "title": "On Autopilot? An Empirical Study of Human-AI Teaming and Review Practices in Open Source",
    "authors": "Haoyu Gao, Peerachai Banyongrakkul, Hao Guan, Mansooreh Zahedi, Christoph Treude",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13754v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) increasingly automate software engineering tasks. While recent studies highlight the accelerated adoption of ``AI as a teammate'' in Open Source Software (OSS), developer interaction patterns remain under-explored. In this work, we investigated project-level guidelines and developers' interactions with AI-assisted pull requests (PRs) by expanding the AIDev dataset to include finer-grained contributor code ownership and a comparative baseline of human-created PRs. We found that over 67.5\\% of AI-co-authored PRs originate from contributors without prior code ownership. Despite this, the majority of repositories lack guidelines for AI-coding agent usage. Notably, we observed a distinct interaction pattern: AI-co-authored PRs are merged significantly faster with minimal feedback. In contrast to human-created PRs where non-owner developers receive the most feedback, AI-co-authored PRs from non-owners receive the least, with approximately 80\\% merged without any explicit review. Finally, we discuss implications for developers and researchers."
  },
  {
    "date": "2026-01-20",
    "title": "Sharp Quantitative Forms of the Hardy Inequality on Cartan-Hadamard Manifolds via Sobolev-Lorentz Embeddings",
    "authors": "Avas Banerjee, Debdip Ganguly, Prasun Roychowdhury",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13750v1",
    "source": "arXiv",
    "abstract": "In this article, we investigate the quantitative form of the classical Hardy inequality. In our first result, we prove the following quantitative bound under the assumption that the $\\mathbb{M}^N$ is a Riemannian model satisfying the centered isoperimetric inequality: We prove that $$ \\|\\nabla_g u\\|^2_{L^{2}(\\mathbb{M}^N)} - \\frac{(N-2)^2}{4}\\left\\|\\frac{u}{r(x)}\\right\\|^2_{L^2(\\mathbb{M}^N)} \\geq C [\\mbox{dist}(u, Z)]^{\\frac{4N}{N-2}}\\left\\|\\frac{u}{r(x)}\\right\\|^2_{L^2(\\mathbb{M}^N)},$$ for every real-valued weakly differentiable function $u$ on $\\mathbb{M}^N$ such that $|\\nabla_g u| \\in L^2(\\mathbb{M}^N)$ and $u$ decays to zero at infinity. Here $r(x) = d_g(x,x_0)$ denotes the geodesic distance from a fixed pole $x_0,$ the set $Z$ represents the family of virtual extremals, and the distance is understood in an appropriate generalized Lorentz-type space. Our approach is built on the symmetrization technique on manifolds, combined with a novel Jacobian-type transformation that provides a precise way for comparing volume growth, level sets, and gradient terms across the two geometries of Euclidean and manifold settings. When coupled with symmetrization, this framework yields sharp control over the relevant functionals and reveals how the underlying curvature influences extremal behavior. Our result generalizes the seminal result of Cianchi-Ferone [Ann. Inst. H. Poincaré C Anal. Non Linéaire 25 (2008)] to the curved spaces. Moreover, building upon this transformation, we succeed in extending Sobolev-Lorentz embedding-classically formulated in the Euclidean setting to the broader framework of Cartan-Hadamard models and we establish an optimal Sobolev-Lorentz embedding in this geometric setting. Finally, we establish a quantitative correspondence between the Hardy deficit on the manifold and an appropriate weighted Hardy deficit in Euclidean space, showing that each controls the other."
  },
  {
    "date": "2026-01-20",
    "title": "EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory",
    "authors": "Tien-Dat Pham, Xuan-The Tran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13748v1",
    "source": "arXiv",
    "abstract": "Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation"
  },
  {
    "date": "2026-01-20",
    "title": "Variational Dual-path Attention Network for CSI-Based Gesture Recognition",
    "authors": "N. Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13745v1",
    "source": "arXiv",
    "abstract": "Wi-Fi gesture recognition based on Channel State Information (CSI) is challenged by high-dimensional noise and resource constraints on edge devices. Prevailing end-to-end models tightly couple feature extraction with classification, overlooking the inherent time-frequency sparsity of CSI and leading to redundancy and poor generalization. To address this, this paper proposes a lightweight feature preprocessing module--the Variational Dual-path Attention Network (VDAN). It performs structured feature refinement through frequency-domain filtering and temporal detection. Variational inference is introduced to model the uncertainty in attention weights, thereby enhancing robustness to noise. The design principles of the module are explained from the perspectives of the information bottleneck and regularization. Experiments on a public dataset demonstrate that the learned attention weights align with the physical sparse characteristics of CSI, verifying its interpretability. This work provides an efficient and explainable front-end processing solution for resource-constrained wireless sensing systems."
  },
  {
    "date": "2026-01-20",
    "title": "A Note on k-NN Gating in RAG",
    "authors": "Gérard Biau, Claire Boyer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13744v1",
    "source": "arXiv",
    "abstract": "We develop a statistical proxy framework for retrieval-augmented generation (RAG), designed to formalize how a language model (LM) should balance its own predictions with retrieved evidence. For each query x, the system combines a frozen base model q0 ($\\times$ x) with a k-nearest neighbor retriever r (k ) ($\\times$ x) through a measurable gate k(x). A retrieval-trust weight wfact (x) quantifies the geometric reliability of the retrieved neighborhood and penalizes retrieval in low-trust regions. We derive the Bayes-optimal per-query gate and analyze its effect on a discordance-based hallucination criterion that captures disagreements between LM predictions and retrieved evidence. We further show that this discordance admits a deterministic asymptotic limit governed solely by the structural agreement (or disagreement) between the Bayes rule and the LM. To account for distribution mismatch between queries and memory, we introduce a hybrid geometric-semantic model combining covariate deformation and label corruption. Overall, this note provides a principled statistical foundation for factuality-oriented RAG systems."
  },
  {
    "date": "2026-01-20",
    "title": "RIM Hand : A Robotic Hand with an Accurate Carpometacarpal Joint and Nitinol-Supported Skeletal Structure",
    "authors": "Joon Lee, Jeongyoon Han, Doyoung Kim, Seokhwan Jeong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13737v1",
    "source": "arXiv",
    "abstract": "This paper presents the flexible RIM Hand, a biomimetic robotic hand that precisely replicates the carpometacarpal (CMC) joints and employs superelastic Nitinol wires throughout its skeletal framework. By modeling the full carpal-to-metacarpal anatomy, the design enables realistic palm deformation through tendon-driven fingers while enhancing joint restoration and supports skeletal structure with Nitinol-based dorsal extensors. A flexible silicone skin further increases contact friction and contact area, enabling stable grasps for diverse objects. Experiments show that the palm can deform up to 28%, matching human hand flexibility, while achieving more than twice the payload capacity and three times the contact area compared to a rigid palm design. The RIM Hand thus offers improved dexterity, compliance, and anthropomorphism, making it promising for prosthetic and service-robot applications."
  },
  {
    "date": "2026-01-20",
    "title": "Near-atomic investigation on the elemental redistribution during co-precipitation of nano-sized kappa phase and B2 phase in an Al-alloyed lightweight steel",
    "authors": "Bowen Zou, Yixu Wang, Xiao Shen, Philipp Krooss, Thomas Niendorf, Richard Dronskowski, Wenwen Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13721v1",
    "source": "arXiv",
    "abstract": "In the present study, correlative transmission Kikuchi diffraction transmission electron microscopy (TKD-TEM) measurements, atom probe tomography (APT), and density functional theory (DFT) calculations are used to reveal the elemental redistribution during co-precipitation of nanosized kappa and B2 phases in an FCC matrix of an Al alloyed Fe-10Al-7Mn-6Ni-1C (wt.%) steel. Upon ageing at 800 C for 15 min, two co-nanoprecipitation modes are observed: B2 forming together with kappa and B2 forming separately from kappa in the FCC matrix. APT reveals that the B2 precipitate next to kappa (referred to as B2I) is close to an FeAl type phase, while the isolated B2 precipitate (referred to as B2II) is close to a NiAl type phase. The kappa precipitates maintain a nearly constant Al content of approximately 18.4 at.% regardless of their precipitation position. DFT confirms that kappa may accommodate limited Ni substitution at Fe sites without losing structural stability, and that Fe Ni atomic exchange between kappa and B2 is thermodynamically favorable at 800 C. This exchange drives the B2 phase to evolve from a NiAl type towards an FeAl type, improving the stability of both phases during co-precipitation. These results provide understanding of kappa B2 interactions and offer insights for designing nanosized intermetallic strengthened microstructures in Al alloyed lightweight steels."
  },
  {
    "date": "2026-01-20",
    "title": "Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff",
    "authors": "Zehan Li, Yuxuan Wang, Ali El Lahib, Ying-Jieh Xia, Xinyu Pi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13717v1",
    "source": "arXiv",
    "abstract": "Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably \"rewind\" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities."
  },
  {
    "date": "2026-01-20",
    "title": "Nonlinear compressive reduced basis approximation : when Taylor meets Kolmogorov",
    "authors": "Joubine Aghili, Hassan Ballout, Yvon Maday, Christophe Prud'homme",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13712v1",
    "source": "arXiv",
    "abstract": "This paper investigates model reduction methods for efficiently approximating the solution of parameter-dependent PDEs with a multi-parameter vector $\\vecμ \\in \\mathbb{R}^p$. In cases where the Kolmogorov $N$-width decays fast enough, it is effective to approximate the solution as a sum of $N$ separable terms, each being the product of a parameter-dependent coefficient and a space-dependent function. This leads to reduced-order models with $N$ degrees of freedom and complexity of order ${\\mathcal O}(N^3)$. However, when the $N$-width decays slowly, $N$ must be large to achieve acceptable accuracy, making cubic complexity prohibitive. The linear complexity measure in terms of Kolmogorov width must be replaced by the Gelfand width, with its associated sensing number. Recent nonlinear approaches based on this notion decompose the $N$ coordinates into two groups: $n$ free variables and $\\overline{n}$ dependent variables, where the latter are nonlinear functions of the former ($N= n+\\overline n$). Several works have focused on cases where these $\\overline{n}$ functions are homogeneous quadratic forms of the $n$ variables, with optimization strategies for choosing $n$ given a target accuracy. A rigorous analysis of the local sensing number is carried out, showing that $n = p$ is optimal and appropriate, at least locally, around a reference point. In practical scenarios involving wide parameter ranges, the condition $p\\le n \\le p + k$ (with $k$ small) is valid and more robust from continuity arguments. Additionally, the assumption of a quadratic mapping, while justified in a local sense, becomes insufficient. More expressive nonlinear mappings-including those using machine learning-become necessary. This work contributes a theoretical foundation for such strategies and highlights the need for further investigations to push back the Kolmogorov Barrier."
  },
  {
    "date": "2026-01-20",
    "title": "Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs",
    "authors": "Yujin Jo, Sangyoon Bae, Taesup Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13707v1",
    "source": "arXiv",
    "abstract": "Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes."
  },
  {
    "date": "2026-01-20",
    "title": "Scaling of Two-Dimensional Semiconductor Nanoribbons for High-Performance Electronics",
    "authors": "Hao-Yu Lan, Shao-Heng Yang, Yongjae Cho, Jun Cai, Zheng Sun, Chenyang Li, Lin-Yun Huang, Thomas Beechem, Yi Wan, Lain-Jong Li, Joerg Appenzeller, Zhihong Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13696v1",
    "source": "arXiv",
    "abstract": "Monolayer transition metal dichalcogenide (TMD) field-effect transistors (FETs), with their atomically thin bodies, are promising candidates for future gate-all-around (GAA) nanoribbon architectures. While state-of-the-art Si GAA nanoribbon transistors feature channel widths in the tens of nanometers, most reported TMD-based FETs remain limited to micrometer-scale dimensions, limiting their relevance for ultra-scaled electronics. In this work, we investigate the channel width scaling in nanoribbon transistors based on monolayer MoS2 grown on 2-inch wafers, achieving widths of approximately 30-40 nm. Remarkably, nanoribbon width scaling enhances the on-current by 30-40%, reaching up to 700 uA/um for the smallest-width devices, while also improving the subthreshold slope (SS) to as low as 70 mV/dec. This enhancement is attributed to a stronger electric field at the nanoribbon edges without significant degradation from edge-related scattering. To further demonstrate the scalability of the nanoribbon device, we evaluate the variability of extremely scaled monolayer MoS2 nanoribbon transistor arrays featuring a contact pitch of 60 nm and an effective oxide thickness (EOT) of approximately 0.9 nm. Beyond MoS2, we extend the nanoribbon structure to WS2 n-type and WSe2 p-type FETs, demonstrating a viable path toward complementary monolayer TMD nanoribbon FETs for future ultra-scaled electronics."
  },
  {
    "date": "2026-01-20",
    "title": "Three-dimensional properties of a coronal shock and the longitudinal distribution of its related solar energetic particles",
    "authors": "Yue Zhou, Li Feng, Guanglu Shi, Jingnan Guo, Liuguan Ding, Yi Yang, Jianchao Xue, Jun Chen, Weiqun Gan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13692v1",
    "source": "arXiv",
    "abstract": "This study aims to investigate the relationship between the spatial-temporal evolution of shock properties and the longitudinal dependence of SEP intensities and spectra. The shock parameters, including the normal speed, oblique angles, compression ratio, and Alfven Mach number, were derived by combining a steady-state solar-wind simulation with the three-dimensional (3D) reconstruction of the shock surface based on multi-view observations. We compared the local shock parameters at the magnetic connecting points with in situ proton intensities and peak spectra to establish the link between shock evolution and SEP characteristics. The shock nose consistently exhibited higher particle-acceleration efficiency with the largest normal speed, compression ratio, and supercritical Alfven Mach number, while the flanks showed delayed transition to supercritical Alfven Mach number with weaker efficiency. The earliest and most rapid proton enhancement of STEREO-B correlated with efficient shock acceleration and prompt magnetic connectivity to the shock. Spectral analysis revealed that proton energy spectra were consistent with the relativistic diffusive shock acceleration (DSA) estimations. The initial shock acceleration began at about 1.4-5 Rsun and caused the widespread longitudinal SEP distribution. The longitudinal dependence of SEP intensity and spectral variations arise from the combined influence of 3D shock properties, magnetic connectivity, and particle transport processes. The agreement between in situ proton indices and relativistic DSA estimations supports DSA in this SEP event and provides insights into the early-stage acceleration at the source region."
  },
  {
    "date": "2026-01-20",
    "title": "Criminator: An Easy-to-Use XR \"Crime Animator\" for Rapid Reconstruction and Analysis of Dynamic Crime Scenes",
    "authors": "Vahid Pooryousef, Lonni Besançon, Maxime Cordeil, Chris Flight, Alastair M Ross AM, Richard Bassed, Tim Dwyer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13689v1",
    "source": "arXiv",
    "abstract": "Law enforcement authorities are increasingly interested in 3D modelling for virtual crime scene reconstruction, enabling offline analysis without the cost and contamination risk of on-site investigation. Past work has demonstrated spatial relationships through static modelling but validating the sequence of events in dynamic scenarios is crucial for solving a case. Yet, animation tools are not well suited to crime scene reconstruction, and complex for non-experts in 3D modelling/animation. Through a co-design process with criminology experts, we designed \"Criminator\"-a methodological framework and XR tool that simplifies animation authoring. We evaluated this tool with participants trained in criminology (n=6) and untrained individuals (n=12). Both groups were able to successfully complete the character animation tasks and provided high usability ratings for observation tasks. Criminator has potential for hypothesis testing, demonstration, sense-making, and training. Challenges remain in how such a tool fits into the entire judicial process, with questions about including animations as evidence."
  },
  {
    "date": "2026-01-20",
    "title": "ORCA -- An Automated Threat Analysis Pipeline for O-RAN Continuous Development",
    "authors": "Felix Klement, Alessandro Brighente, Michele Polese, Mauro Conti, Stefan Katzenbeisser",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13681v1",
    "source": "arXiv",
    "abstract": "The Open-Radio Access Network (O-RAN) integrates numerous software components in a cloud-like deployment, opening the radio access network to previously unconsidered security threats. With the ever-evolving threat landscape, integrating security practices through a DevSecOps approach is essential for fast and secure releases. Current vulnerability assessment practices often rely on manual, labor-intensive, and subjective investigations, leading to inconsistencies in the threat analysis. To mitigate these issues, we establish an automated pipeline that leverages Natural Language Processing (NLP) to minimize human intervention and associated biases. By mapping real-world vulnerabilities to predefined threat lists with a standardized input format, our approach is the first to enable iterative, quantitative, and efficient assessments, generating reliable threat scores for both individual vulnerabilities and entire system components within O-RAN. We illustrate the effectiveness of our framework through an example implementation for O-RAN, showcasing how continuous security testing can integrate into automated testing pipelines to address the unique security challenges of this paradigm shift in telecommunications."
  },
  {
    "date": "2026-01-20",
    "title": "On the Anchoring Effect of Monetary Policy on the Labor Share of Income and the Rationality of Its Setting Mechanism",
    "authors": "Li Tuobang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13675v1",
    "source": "arXiv",
    "abstract": "Modern macroeconomic monetary theory suggests that the labor share of income has effectively become a core macroe-conomic parameter anchored by top policymakers through Open Market Operations (OMO). However, the setting of this parameter remains a subject of intense economic debate. This paper provides a detailed summary of these controversies, analyzes the scope of influence exerted by market agents other than the top policymakers on the labor share, and explores the rationality of its setting mechanism."
  },
  {
    "date": "2026-01-20",
    "title": "HD 26172: an active solar-type subgiant in a close binary system",
    "authors": "Fang-Bin Meng, Li-Ying Zhu, Sheng-Bang Qian, Nian-Ping Liu, Jia Zhang, David Mkrtichian, Soonthornthum Boonrucksar, Er-Gang Zha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13652v1",
    "source": "arXiv",
    "abstract": "We present the first comprehensive photometric and spectroscopic analysis of the RS CVn system HD 26172, robustly determining the previously debated evolutionary state of its primary star. Since this system is a single-lined spectroscopic binary with spot-induced light curve modulations, we derived its physical parameters by combining the TESS light curves, the radial velocity curve from our observations, and the primary-star mass estimates based on three complementary methods.Our results reveal that HD 26172 is a detached binary system composed of a $1.25 \\pm 0.32 M_{\\odot}$ subgiant and a $0.63 \\pm 0.11 M_{\\odot}$ main-sequence star. The conclusion of subgiant primary is also supported by the absence of lithium absorption and no observed infrared excess. Using long-term photometry from the KWS survey, we detected a tentative stellar activity cycle of 5635 days with an amplitude of 0.04 mag in HD 26172. Additionally, we identified ten optical flare events exhibiting temporally clustered outburst behavior. The presence of a long-term activity cycle, pronounced starspot activity, and frequent optical flares makes HD 26172 a valuable laboratory for studying magnetic activity in subgiants within close binary systems."
  },
  {
    "date": "2026-01-20",
    "title": "Sample Complexity of Average-Reward Q-Learning: From Single-agent to Federated Reinforcement Learning",
    "authors": "Yuchen Jiao, Jiin Woo, Gen Li, Gauri Joshi, Yuejie Chi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13642v1",
    "source": "arXiv",
    "abstract": "Average-reward reinforcement learning offers a principled framework for long-term decision-making by maximizing the mean reward per time step. Although Q-learning is a widely used model-free algorithm with established sample complexity in discounted and finite-horizon Markov decision processes (MDPs), its theoretical guarantees for average-reward settings remain limited. This work studies a simple but effective Q-learning algorithm for average-reward MDPs with finite state and action spaces under the weakly communicating assumption, covering both single-agent and federated scenarios. For the single-agent case, we show that Q-learning with carefully chosen parameters achieves sample complexity $\\widetilde{O}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|\\|h^{\\star}\\|_{\\mathsf{sp}}^3}{\\varepsilon^3}\\right)$, where $\\|h^{\\star}\\|_{\\mathsf{sp}}$ is the span norm of the bias function, improving previous results by at least a factor of $\\frac{\\|h^{\\star}\\|_{\\mathsf{sp}}^2}{\\varepsilon^2}$. In the federated setting with $M$ agents, we prove that collaboration reduces the per-agent sample complexity to $\\widetilde{O}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|\\|h^{\\star}\\|_{\\mathsf{sp}}^3}{M\\varepsilon^3}\\right)$, with only $\\widetilde{O}\\left(\\frac{\\|h^{\\star}\\|_{\\mathsf{sp}}}{\\varepsilon}\\right)$ communication rounds required. These results establish the first federated Q-learning algorithm for average-reward MDPs, with provable efficiency in both sample and communication complexity."
  },
  {
    "date": "2026-01-20",
    "title": "A General One-Shot Multimodal Active Perception Framework for Robotic Manipulation: Learning to Predict Optimal Viewpoint",
    "authors": "Deyun Qin, Zezhi Liu, Hanqian Luo, Xiao Liang, Yongchun Fang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13639v1",
    "source": "arXiv",
    "abstract": "Active perception in vision-based robotic manipulation aims to move the camera toward more informative observation viewpoints, thereby providing high-quality perceptual inputs for downstream tasks. Most existing active perception methods rely on iterative optimization, leading to high time and motion costs, and are tightly coupled with task-specific objectives, which limits their transferability. In this paper, we propose a general one-shot multimodal active perception framework for robotic manipulation. The framework enables direct inference of optimal viewpoints and comprises a data collection pipeline and an optimal viewpoint prediction network. Specifically, the framework decouples viewpoint quality evaluation from the overall architecture, supporting heterogeneous task requirements. Optimal viewpoints are defined through systematic sampling and evaluation of candidate viewpoints, after which large-scale training datasets are constructed via domain randomization. Moreover, a multimodal optimal viewpoint prediction network is developed, leveraging cross-attention to align and fuse multimodal features and directly predict camera pose adjustments. The proposed framework is instantiated in robotic grasping under viewpoint-constrained environments. Experimental results demonstrate that active perception guided by the framework significantly improves grasp success rates. Notably, real-world evaluations achieve nearly double the grasp success rate and enable seamless sim-to-real transfer without additional fine-tuning, demonstrating the effectiveness of the proposed framework."
  },
  {
    "date": "2026-01-20",
    "title": "Steady-State Exceptional Point Degeneracy and Sensitivity of Nonlinear Saturable Coupled Oscillators",
    "authors": "Benjamin Bradshaw, Amin Hakimi, Filippo Capolino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13638v1",
    "source": "arXiv",
    "abstract": "Near exceptional degenerate points in parameter space, coupled oscillator systems display enhanced sensitivity of their saturated steady-state (SS) oscillation frequencies to small changes in system parameters. Linear $\\mathcal{PT}$-symmetric systems made of two coupled resonators have exceptional point of degeneracy (EPD), around which square-root sensitivity is observed. However, realistic systems with gain are inherently saturable and nonlinear, thereby invalidating linear assumptions, and when $\\mathcal{PT}$-symmetry is broken the coupled resonator system becomes unstable, hence it seems that the best working regime is to use such instability to make an SS-EPD-based oscillator. We study the saturated steady-state of a general system of two coupled oscillators with saturable nonlinear gain. Extending previous analyses, we find the steady-state oscillation frequency-gain pairs, and we analytically and numerically derive the sensitivity of the oscillation frequency to system's perturbations around a unique third-order degeneracy which corresponds to SS$\\mathcal{PT}$ symmetry because it is the saturated gain that is symmetric to losses. In general, unlike linear systems, we find that at SS, the sensitivity of the oscillation frequency to exhibit linear, square-root, or cube-root dependence on small perturbations. We additionally study the energy and stability of each SS, and demonstrate the application and limitations of this analysis to coupled RLC circuits. We give a comprehensive outlook for exploiting exceptional degeneracy-enhanced sensitivity in nonlinear coupled oscillators and suggest the best operative conditions."
  },
  {
    "date": "2026-01-20",
    "title": "Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning",
    "authors": "Zhiming Xue, Sichen Zhao, Yalun Qi, Xianling Zeng, Zihan Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13632v1",
    "source": "arXiv",
    "abstract": "With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. The traditional static routing strategy most time cannot tolerate the traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing(RADR) framework which integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. We first construct a logistics topology graph by using the discrete GPS data using spatial clustering methods. Subsequently, a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is adopted to extract spatial correlations and temporal dependencies for predicting future congestion risks. These prediction results are then integrated into a dynamic edge weight mechanism to perform path planning. We evaluated the framework on the Smart Logistics Dataset 2024, which contains real-world Internet of Things(IoT) sensor data. The experimental results show that the RADR algorithm significantly enhances the resilience of the supply chain. Particularly in the case study of high congestion scenarios, our method reduces the potential congestion risk exposure by 19.3% while only increasing the transportation distance by 2.1%. This empirical evidence confirms that the proposed data-driven approach can effectively balance delivery efficiency and operational safety."
  },
  {
    "date": "2026-01-20",
    "title": "Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models",
    "authors": "Zhaopeng Zhang, Pengcheng Sun, Lan Zhang, Chen Tang, Jiewei Lai, Yunhao Wang, Hui Jin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13630v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines."
  },
  {
    "date": "2026-01-20",
    "title": "Symmetric multiple Eisenstein series",
    "authors": "Takashi Hara, Kenji Sakugawa, Koji Tasaka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13626v1",
    "source": "arXiv",
    "abstract": "In this paper, we introduce the symmetric multiple Eisenstein series, a variant of the multiple Eisenstein series. As a fundamental result, we show that they satisfy the linear shuffle relation. As a case study, we investigate the vector space spanned by symmetric double Eisenstein series of weight $k$. When $k$ is even, it coincides with the space spanned by modular forms of weight $k$ and the derivative of the Eisenstein series of weight $k-2$. For $k$ odd, we prove that its dimension equals $\\lfloor k/3\\rfloor$. We further provide an explicit correspondence between the linear shuffle relation and the Fay-shuffle relation satisfied by elliptic double zeta values, which may be of independent interest. In connection with modular forms, we prove that every modular form can be expressed as a linear combination of symmetric triple Eisenstein series. This will serve as a first step toward understanding modular phenomena for symmeric multiple zeta values observed by Kaneko and Zagier."
  },
  {
    "date": "2026-01-20",
    "title": "CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models",
    "authors": "Donghee Lee, Rui Cai, Zhe Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13622v1",
    "source": "arXiv",
    "abstract": "Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures."
  },
  {
    "date": "2026-01-20",
    "title": "Secure Multi-Path Routing with All-or-Nothing Transform for Network-on-Chip Architectures",
    "authors": "Hansika Weerasena, Matthew Randall, Prabhat Mishra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13610v1",
    "source": "arXiv",
    "abstract": "Ensuring Network-on-Chip (NoC) security is crucial to design trustworthy NoC-based System-on-Chip (SoC) architectures. While there are various threats that exploit on-chip communication vulnerabilities, eavesdropping attacks via malicious nodes are among the most common and stealthy. Although encryption can secure packets for confidentiality, it may introduce unacceptable overhead for resource-constrained SoCs. In this paper, we propose a lightweight confidentiality-preserving framework that utilizes a quasi-group based All-Or-Nothing Transform (AONT) combined with secure multi-path routing in NoC-based SoCs. By applying AONT to each packet and distributing its transformed blocks across multiple non-overlapping routes, we ensure that no intermediate router can reconstruct the original data without all blocks. Extensive experimental evaluation demonstrates that our method effectively mitigates eavesdropping attacks by malicious routers with negligible area and performance overhead. Our results also reveal that AONT-based multi-path routing can provide 7.3x reduction in overhead compared to traditional encryption for securing against eavesdropping attacks."
  },
  {
    "date": "2026-01-20",
    "title": "When Reasoning Leaks Membership: Membership Inference Attack on Black-box Large Reasoning Models",
    "authors": "Ruihan Hu, Yu-Ming Shang, Wei Luo, Ye Tao, Xi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13607v1",
    "source": "arXiv",
    "abstract": "Large Reasoning Models (LRMs) have rapidly gained prominence for their strong performance in solving complex tasks. Many modern black-box LRMs expose the intermediate reasoning traces through APIs to improve transparency (e.g., Gemini-2.5 and Claude-sonnet). Despite their benefits, we find that these traces can leak membership signals, creating a new privacy threat even without access to token logits used in prior attacks. In this work, we initiate the first systematic exploration of Membership Inference Attacks (MIAs) on black-box LRMs. Our preliminary analysis shows that LRMs produce confident, recall-like reasoning traces on familiar training member samples but more hesitant, inference-like reasoning traces on non-members. The representations of these traces are continuously distributed in the semantic latent space, spanning from familiar to unfamiliar samples. Building on this observation, we propose BlackSpectrum, the first membership inference attack framework targeting the black-box LRMs. The key idea is to construct a recall-inference axis in the semantic latent space, based on representations derived from the exposed traces. By locating where a query sample falls along this axis, the attacker can obtain a membership score and predict how likely it is to be a member of the training data. Additionally, to address the limitations of outdated datasets unsuited to modern LRMs, we provide two new datasets to support future research, arXivReasoning and BookReasoning. Empirically, exposing reasoning traces significantly increases the vulnerability of LRMs to membership inference attacks, leading to large gains in attack performance. Our findings highlight the need for LRM companies to balance transparency in intermediate reasoning traces with privacy preservation."
  },
  {
    "date": "2026-01-20",
    "title": "Foundations of Global Consistency Checking with Noisy LLM Oracles",
    "authors": "Paul He, Elke Kirschbaum, Shiva Kasiviswanathan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13600v1",
    "source": "arXiv",
    "abstract": "Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators."
  },
  {
    "date": "2026-01-20",
    "title": "Using observations of escaping H/He to constrain the atmospheric composition of sub-Neptunes",
    "authors": "James G. Rogers, James E. Owen, Ethan Schreyer, James Kirk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14254v1",
    "source": "arXiv",
    "abstract": "The internal composition of sub-Neptunes remains a prominent unresolved question in exoplanetary science. We present a technique to place constraints on envelope mean molecular weight that utilises observations of escaping hydrogen or helium exospheres. This method is based on a simple timescale argument, which states that sub-Neptunes require a sufficiently large hydrogen or helium reservoir to explain on-going escape at their observed rates. This then naturally leads to an upper limit on atmospheric mean molecular weight. We apply this technique to archetypal sub-Neptunes, namely GJ-436 b, TOI-776 b and TOI-776 c, which have all been observed to be losing significant hydrogen content as well as relatively featureless transit spectra when observed with JWST. Combining constraints from atmospheric escape and transit spectroscopy in the case of TOI-776 c allows us to tentatively rule out the high mean molecular weight scenario, pointing towards a low mean molecular weight atmosphere with high-altitude aerosols muting spectral features in the infra-red. Finally, we reframe our analysis to the hycean candidate K2-18 b, which has also been shown to host a tentative escaping hydrogen exosphere. If such a detection is robust, we infer a hydrogen-rich envelope mass fraction of $\\log f_\\text{env} = -1.67\\pm0.78$, which is inconsistent with the hycean scenario at the $\\sim 4σ$ level. This latter result requires further observational follow-up to confirm."
  },
  {
    "date": "2026-01-20",
    "title": "Robust Localization in OFDM-Based Massive MIMO through Phase Offset Calibration",
    "authors": "Qing Zhang, Adham Sakhnini, Robbert Beerten, Haoqiu Xiong, Zhuangzhuang Cui, Yang Miao, Sofie Pollin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14244v1",
    "source": "arXiv",
    "abstract": "Accurate localization in Orthogonal Frequency Division Multiplexing (OFDM)-based massive Multiple-Input Multiple-Output (MIMO) systems depends critically on phase coherence across subcarriers and antennas. However, practical systems suffer from frequency-dependent and (spatial) antenna-dependent phase offsets, degrading localization accuracy. This paper analytically studies the impact of phase incoherence on localization performance under a static User Equipment (UE) and Line-of-Sight (LoS) scenario. We use two complementary tools. First, we derive the Cramér-Rao Lower Bound (CRLB) to quantify the theoretical limits under phase offsets. Then, we develop a Spatial Ambiguity Function (SAF)-based model to characterize ambiguity patterns. Simulation results reveal that spatial phase offsets severely degrade localization performance, while frequency phase offsets have a minor effect in the considered system configuration. To address this, we propose a robust Channel State Information (CSI) calibration framework and validate it using real-world measurements from a practical massive MIMO testbed. The experimental results confirm that the proposed calibration framework significantly improves the localization Root Mean Squared Error (RMSE) from 5 m to 1.2 cm, aligning well with the theoretical predictions."
  },
  {
    "date": "2026-01-20",
    "title": "Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration",
    "authors": "LSST Dark Energy Science Collaboration, Eric Aubourg, Camille Avestruz, Matthew R. Becker, Biswajit Biswas, Rahul Biswas, Boris Bolliet, Adam S. Bolton, Clecio R. Bom, Raphaël Bonnet-Guerrini, Alexandre Boucaud, Jean-Eric Campagne, Chihway Chang, Aleksandra Ćiprijanović, Johann Cohen-Tanugi, Michael W. Coughlin, John Franklin Crenshaw, Juan C. Cuevas-Tello, Juan de Vicente, Seth W. Digel, Steven Dillmann, Mariano Javier de León Dominguez Romero, Alex Drlica-Wagner, Sydney Erickson, Alexander T. Gagliano, Christos Georgiou, Aritra Ghosh, Matthew Grayling, Kirill A. Grishin, Alan Heavens, Lindsay R. House, Mustapha Ishak, Wassim Kabalan, Arun Kannawadi, François Lanusse, C. Danielle Leonard, Pierre-François Léget, Michelle Lochner, Yao-Yuan Mao, Peter Melchior, Grant Merz, Martin Millon, Anais Möller, Gautham Narayan, Yuuki Omori, Hiranya Peiris, Laurence Perreault-Levasseur, Andrés A. Plazas Malagón, Nesar Ramachandra, Benjamin Remy, Cécile Roucelle, Jaime Ruiz-Zapatero, Stefan Schuldt, Ignacio Sevilla-Noarbe, Ved G. Shah, Tjitske Starkenburg, Stephen Thorp, Laura Toribio San Cipriano, Tilman Tröster, Roberto Trotta, Padma Venkatraman, Amanda Wasserman, Tim White, Justine Zeghal, Tianqing Zhang, Yuanyuan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14235v1",
    "source": "arXiv",
    "abstract": "The Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful, scalable, and operationally reliable. Artificial intelligence and machine learning (AI/ML) are already embedded across DESC science workflows, from photometric redshifts and transient classification to weak lensing inference and cosmological simulations. Yet their utility for precision cosmology hinges on trustworthy uncertainty quantification, robustness to covariate shift and model misspecification, and reproducible integration within scientific pipelines. This white paper surveys the current landscape of AI/ML across DESC's primary cosmological probes and cross-cutting analyses, revealing that the same core methodologies and fundamental challenges recur across disparate science cases. Since progress on these cross-cutting challenges would benefit multiple probes simultaneously, we identify key methodological research priorities, including Bayesian inference at scale, physics-informed methods, validation frameworks, and active learning for discovery. With an eye on emerging techniques, we also explore the potential of the latest foundation model methodologies and LLM-driven agentic AI systems to reshape DESC workflows, provided their deployment is coupled with rigorous evaluation and governance. Finally, we discuss critical software, computing, data infrastructure, and human capital requirements for the successful deployment of these new methodologies, and consider associated risks and opportunities for broader coordination with external actors."
  },
  {
    "date": "2026-01-20",
    "title": "Rerank Before You Reason: Analyzing Reranking Tradeoffs through Effective Token Cost in Deep Search Agents",
    "authors": "Sahel Sharifymoghaddam, Jimmy Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14224v1",
    "source": "arXiv",
    "abstract": "Deep research agents rely on iterative retrieval and reasoning to answer complex queries, but scaling test-time computation raises significant efficiency concerns. We study how to allocate reasoning budget in deep search pipelines, focusing on the role of listwise reranking. Using the BrowseComp-Plus benchmark, we analyze tradeoffs between model scale, reasoning effort, reranking depth, and total token cost via a novel effective token cost (ETC) metric. Our results show that reranking consistently improves retrieval and end-to-end accuracy, and that moderate reranking often yields larger gains than increasing search-time reasoning, achieving comparable accuracy at substantially lower cost. All our code is available at https://github.com/texttron/BrowseComp-Plus.git"
  },
  {
    "date": "2026-01-20",
    "title": "Revisiting the Matter Creation Process: Observational Constraints on Gravitationally Induced Dark Energy and the Hubble Tension",
    "authors": "Tiziano Schiavone, Mariaveronica De Angelis, Luis A. Escamilla, Giovanni Montani, Eleonora Di Valentino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14222v1",
    "source": "arXiv",
    "abstract": "The persistent Hubble tension and the lack of a fundamental explanation for dark energy motivate the exploration of alternative mechanisms capable of reproducing late-time cosmic acceleration. In this work, we revisit gravitationally induced particle creation as a phenomenological non-equilibrium process that can effectively mimic a dynamical dark-energy component. Within the thermodynamic framework of open systems, we model the production of an unspecified particle species with constant intrinsic equation-of-state parameter and consider four phenomenological parametrisations of the particle-creation rate. The modified continuity and Friedmann equations lead to an effective negative pressure and a redshift-dependent effective equation of state, which we constrain using Cosmic Chronometers, Pantheon+ supernovae, DESI DR2 BAO, a compressed CMB likelihood, and SH0ES data. Using the full dataset combination, we find that particle-creation models provide fits comparable to $Λ$CDM, yielding $H_0 \\simeq 69.3\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$ and present-day effective dark-energy equation-of-state values close to $w^{\\rm eff}_{\\rm DE}(0)\\simeq -1$, with all models predicting an accelerating Universe ($q_0\\simeq -0.55$). When the Hubble tension is assessed using early- and late-time dataset splits, particle-creation scenarios reduce its statistical significance to the $\\simeq 2.4σ$--$3σ$ level, compared to the $4.3σ$ discrepancy obtained in $Λ$CDM. Although deviations from $Λ$CDM remain mild and Bayesian model comparison indicates no statistical preference between models, gravitationally induced particle creation emerges as a viable late-time extension of the standard cosmological model and provides a consistent phenomenological framework for exploring departures from $Λ$CDM."
  },
  {
    "date": "2026-01-20",
    "title": "InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning",
    "authors": "Matthew Y. R. Yang, Hao Bai, Ian Wu, Gene Yang, Amrith Setlur, Aviral Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14209v1",
    "source": "arXiv",
    "abstract": "Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b."
  },
  {
    "date": "2026-01-20",
    "title": "Three-Dimensional Volumetric Reconstruction of Native Chilean Pollen via Lens-Free Digital In-line Holographic Microscopy",
    "authors": "J. Staforelli-Vivanco, V. Salamanca-Levi, R. Jofré-Cerda, M. Rondanelli-Reyes, I. Lamas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14205v1",
    "source": "arXiv",
    "abstract": "This study presents a robust methodology for the 3D volumetric reconstruction of native Chileanpollen grains, specifically Gevuina avellana (hazel),Conium maculatum (hemloc) and Anthemis cotula (chamomile). Using a lens-free Digital In-line Holographic Microscopy (DLHM) system, we capture complex interference patterns that are numerically reconstructed using the Kirchhoff-Helmholtz transform. Our results demonstrate that this label-free approach provides high-fidelity morphological characterization and nanometric precision in biophysical parameter extraction, offering a scalable alternative for automated melissopalynology and environmental monitoring."
  },
  {
    "date": "2026-01-20",
    "title": "Automated Analysis of DFT Output Files for Molecular Descriptor Extraction and Reactivity Modeling",
    "authors": "Yu-Chien Huang, Dennis Chung-Yang Huang, Yun-Cheng Tsai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14203v1",
    "source": "arXiv",
    "abstract": "Understanding the relationship between molecular structure and chemical reactivity or properties is fundamental to rational molecular design. Linear free energy relationships (LFERs), particularly Hammett analysis, have long served as powerful tools in organic chemistry. Recently, these approaches have been enhanced by incorporating computationally derived parameters, enabling broader applicability across diverse molecules and reactions. To facilitate and scale this process, we present DFTDescriptorPipeline, a fully automated workflow for extracting quantum chemical descriptors from Gaussian log files and constructing structure-property and structure-reactivity relationships using multivariate linear regression (MLR) models. We validate the workflow across four case studies, including photoswitchable molecules and catalytic reactions. In each case, the models provide interpretable results, demonstrating the versatility of this approach and its relevance to a wide range of chemical contexts. We anticipate that this platform will serve as a generalizable framework for integrating quantum chemical calculations into data-driven molecular design."
  },
  {
    "date": "2026-01-20",
    "title": "Analyzing Far-Right Telegram Channels as Constituents of Information Autocracy in Russia",
    "authors": "Polina Smirnova, Mykola Makhortykh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14190v1",
    "source": "arXiv",
    "abstract": "This study examines how Russian far-right communities on Telegram shape perceptions of political figures through memes and visual narratives. Far from passive spectators, these actors co-produce propaganda, blending state-aligned messages with their own extremist framings. In Russia, such groups are central because they articulate the ideological foundations of the war against Ukraine and reflect the regime's gradual drift toward ultranationalist rhetoric. Drawing on a dataset of 200,000 images from expert-selected far-right Telegram channels, the study employs computer vision and unsupervised clustering to identify memes featuring Russian (Putin, Shoigu) and foreign politicians (Zelensky, Biden, Trump) and to reveal recurrent visual patterns in their representation. By leveraging the large-scale and temporal depth of this dataset, the analysis uncovers differential patterns of legitimation and delegitimation across actors and over time. These insights are not attainable in smaller-scale studies. Preliminary findings show that far-right memes function as instruments of propaganda co-production. These communities do not simply echo official messages but generate bottom-up narratives of legitimation and delegitimation that align with state ideology. By framing leaders as heroic and opponents as corrupt or weak, far-right actors act as informal co-creators of authoritarian legitimacy within Russia's informational autocracy."
  },
  {
    "date": "2026-01-20",
    "title": "IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models",
    "authors": "Liang Shi, Wei Li, Kevin M Beussman, Lin Chen, Yun Fu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14188v1",
    "source": "arXiv",
    "abstract": "Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task."
  },
  {
    "date": "2026-01-20",
    "title": "Quantum mixing on large Schreier graphs",
    "authors": "Charles Bordenave, Cyril Letrouit, Mostafa Sabri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14182v1",
    "source": "arXiv",
    "abstract": "Quantum ergodicity describes the delocalization of most eigenfunctions of Laplace-type operators on graphs or manifolds exhibiting chaotic classical dynamics. Quantum mixing is a stronger notion, additionally controlling correlations between eigenfunctions at different energy levels. In this work, we study families of finite Schreier graphs that converge to an infinite Cayley graph and establish quantum mixing under the assumption that the limiting Cayley graph has absolutely continuous spectrum. The convergence of Schreier graphs is understood in the Benjamini-Schramm sense or in the sense of strong convergence in distribution. Our proofs rely on a new approach to quantum ergodicity, based on trace computations, resolvent approximations and representation theory. We illustrate our assumptions on several examples and provide applications to Schreier graphs associated with free products of groups and right-angled Coxeter groups."
  },
  {
    "date": "2026-01-20",
    "title": "Chaos propagation in genetic algorithms: An optimal transport approach",
    "authors": "Giacomo Borghi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14169v1",
    "source": "arXiv",
    "abstract": "Genetic algorithms are high-level heuristic optimization methods which enjoy great popularity thanks to their intuitive description, flexibility, and, of course, effectiveness. The optimization procedure is based on the evolution of possible solutions following three mechanisms: selection, mutation, and crossover. In this paper, we look at the algorithm as an interacting particle system and show that it is described by a Boltzmann-type equation in the many particles limit. Specifically, we prove a propagation of chaos result with a novel technique that leverages the optimal transport formulation of the Kantorovich-Rubinstein norm and naturally incorporates the crossover mechanism into the analysis. The convergence rate is sharp with respect to the number of particles."
  },
  {
    "date": "2026-01-20",
    "title": "Sharp Inequalities for Schur-Convex Functionals of Partial Traces over Unitary Orbits",
    "authors": "Pablo Costa Rico, Pavel Shteyner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14158v1",
    "source": "arXiv",
    "abstract": "While many bounds have been proved for partial trace inequalities over the last decades for a large variety of quantities, recent problems in quantum information theory demand sharper bounds. In this work, we study optimal bounds for partial trace quantities in terms of the spectrum; equivalently, we determine the best bounds attainable over unitary orbits of matrices. We solve this question for Schur-convex functionals acting on a single partial trace in terms of eigenvalues for self-adjoint matrices and then we extend these results to singular values of general matrices. We subsequently extend the study to Schur-convex functionals that act on several partial traces simultaneously and present sufficient conditions for sharpness. In cases where closed-form maximizers cannot be identified, we present quadratic programs that yield new computable upper bounds for any Schur-convex functional. We additionally present examples demonstrating improvements over previously known bounds. Finally, we conclude with the study of optimal bounds for an $n$-qubit system and its subsystems of dimension $2$."
  },
  {
    "date": "2026-01-20",
    "title": "LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery",
    "authors": "Shubham Pandey, Bhavin Jawade, Srirangaraj Setlur, Venu Govindaraju, Kenneth Seastedt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14154v1",
    "source": "arXiv",
    "abstract": "Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management."
  },
  {
    "date": "2026-01-20",
    "title": "Achievable Burning Densities of Growing Grids",
    "authors": "Jordan Barrett, Karen Gunderson, JD Nir, Pawel Pralat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14151v1",
    "source": "arXiv",
    "abstract": "Graph burning is a discrete-time process on graphs where vertices are sequentially activated and burning vertices cause their neighbours to burn over time. In this work, we focus on a dynamic setting in which the graph grows over time, and at each step we burn vertices in the growing grid $G_n = [-f(n),f(n)]^2$. We investigate the set of achievable burning densities for functions of the form $f(n)=\\lceil cn^α\\rceil$, where $α\\ge 1$ and $c>0$. We show that for $α=1$, the set of achievable densities is $[1/(2c^2),1]$, for $1<α<3/2$, every density in $[0,1]$ is achievable, and for $α=3/2$, the set of achievable densities is $[0,(1+\\sqrt{6}c)^{-2}]$."
  },
  {
    "date": "2026-01-20",
    "title": "Log-optimality with small liability stream",
    "authors": "Michail Anthropelos, Constantinos Kardaras, Constantinos Stefanakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14139v1",
    "source": "arXiv",
    "abstract": "In an incomplete financial market with general continuous semimartingale dynamics; we model an investor with log-utility preferences who, in addition to an initial capital, receives units of a non-traded endowment process. Using duality techniques, we derive the fourth-order expansion of the primal value function with respect to the units $ε$, held in the non-traded endowment. In turn, this lays the foundation for expanding the optimal wealth process, in this context, up to second order w.r.t. $ε$. The key processes underpinning the aforementioned results are given in terms of Kunita-Watanabe projections, mirroring the case of lower order expansions of similar nature. Both the case of finite and infinite horizons are treated in a unified manner."
  },
  {
    "date": "2026-01-20",
    "title": "Practitioner Views on Mobile App Accessibility: Practices and Challenges",
    "authors": "Amila Indika, Rick Kazman, Anthony Peruma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14131v1",
    "source": "arXiv",
    "abstract": "As mobile applications (apps) become ubiquitous in everyday life, it is crucial for developers to prioritize accessibility for users with diverse abilities. While previous research has identified widespread accessibility issues and raised awareness of developer challenges, there remains a lack of cross-platform, globally representative insights into how practitioners approach accessibility in practice. This paper presents findings from a mixed-methods survey of 110 mobile app developers across 43 countries, examining how platform ecosystems (iOS vs. Android) and developer experience shape accessibility practices. Results show that while developers recognize the importance of accessibility, they often rely on platform-specific guidelines and typically perform compliance testing late in the development process. Developers primarily implement text-focused features while struggling with API limitations and organizational constraints. Through systematic cross-platform comparison, we identify novel platform-specific barriers and demonstrate how accessibility practices differ across developer experience levels. Our findings offer new insights into the challenges of achieving accessibility in practice and provide actionable steps for various stakeholders to promote more consistent and inclusive app development."
  },
  {
    "date": "2026-01-20",
    "title": "SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media",
    "authors": "Shoujie Li, Changqing Guo, Junhao Gong, Chenxin Liang, Wenhua Ding, Wenbo Ding",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14128v1",
    "source": "arXiv",
    "abstract": "Perception in granular media remains challenging due to unpredictable particle dynamics. To address this challenge, we present SandWorm, a biomimetic screw-actuated robot augmented by peristaltic motion to enhance locomotion, and SWTac, a novel event-based visuotactile sensor with an actively vibrated elastomer. The event camera is mechanically decoupled from vibrations by a spring isolation mechanism, enabling high-quality tactile imaging of both dynamic and stationary objects. For algorithm design, we propose an IMU-guided temporal filter to enhance imaging consistency, improving MSNR by 24%. Moreover, we systematically optimize SWTac with vibration parameters, event camera settings and elastomer properties. Motivated by asymmetric edge features, we also implement contact surface estimation by U-Net. Experimental validation demonstrates SWTac's 0.2 mm texture resolution, 98% stone classification accuracy, and 0.15 N force estimation error, while SandWorm demonstrates versatile locomotion (up to 12.5 mm/s) in challenging terrains, successfully executes pipeline dredging and subsurface exploration in complex granular media (observed 90% success rate). Field experiments further confirm the system's practical performance."
  },
  {
    "date": "2026-01-20",
    "title": "A Systematic Analysis of Chunking Strategies for Reliable Question Answering",
    "authors": "Sofia Bennani, Charles Moslonka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14123v1",
    "source": "arXiv",
    "abstract": "We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a \"context cliff\" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones)."
  },
  {
    "date": "2026-01-20",
    "title": "Accretion flow around Kerr metric in the infra-red limit of asymptotically safe gravity",
    "authors": "Orhan Donmez, Sushant G. Ghosh, M. Yousaf, G. Mustafa, Farruh Atamurotov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14113v1",
    "source": "arXiv",
    "abstract": "We investigate accretion disk dynamics and the formation of quasi-periodic oscillations (QPOs) in the infrared limit around Kerr-like black holes in asymptotically safe gravity. Relativistic hydrodynamic solutions of Bondi-Hoyle-Lyttleton (BHL) accretion reveal that quantum corrections significantly modify the structure of the shock cone formed around the black hole. The black hole spin controls the asymmetric of the shock cone through frame-dragging effects, whereas the quantum correction parameter softens the effective gravitational potential, resulting in a wider shock opening angle, weaker post-shock compression, and reduced density concentration within the cone. Time-dependent mass accretion rates reveal oscillation modes trapped within the shock cone. The power spectral density (PSD) investigations suggest that these modes naturally generate low-frequency QPOs, whose amplitudes, coherence, and harmonic structure depend on both the spin and the quantum correction parameter. The PSD analyses performed at different radial locations reveal that identical QPO frequencies are obtained in all cases. The numerically detected frequencies result from the excitation of global oscillation modes trapped within the post-shock region. The resulting global modes are found to consist of fundamental frequencies, their associated harmonic overtones, and near-commensurate frequency ratios such as 2:1 and 3:2. Coherent oscillations are enhanced and near-commensurate frequency ratios are produced when moderate rotation and moderate quantum corrections are coupled. Large quantum correction parameters, on the other hand, wash out unique spectral peaks and suppress oscillation amplitudes."
  },
  {
    "date": "2026-01-20",
    "title": "Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping",
    "authors": "Shi-Shun Chen, Xiao-Yang Li, Enrico Zio",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14099v1",
    "source": "arXiv",
    "abstract": "Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM."
  },
  {
    "date": "2026-01-20",
    "title": "Basis Number and Pathwidth",
    "authors": "Babak Miraftab, Pat Morin, Yelena Yuditsky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14095v1",
    "source": "arXiv",
    "abstract": "We prove two results relating the basis number of a graph $G$ to path decompositions of $G$. Our first result shows that the basis number of a graph is at most four times its pathwidth. Our second result shows that, if a graph $G$ has a path decomposition with adhesions of size at most $k$ in which the graph induced by each bag has basis number at most $b$, then $G$ has basis number at most $b+O(k\\log^2 k)$. The first result, combined with recent work of Geniet and Giocanti shows that the basis number of a graph is bounded by a polynomial function of its treewidth. The second result (also combined with the work of Geniet and Giocanti) shows that every $K_t$-minor-free graph has a basis number bounded by a polynomial function of $t$."
  },
  {
    "date": "2026-01-20",
    "title": "Onset of stripe order in classical fluids: Lessons from lattice-gas mixtures",
    "authors": "Gabriele Costa, Santi Prestipino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14082v1",
    "source": "arXiv",
    "abstract": "When two molecular species with mutual affinity are mixed together, various self-assembled phases can arise at low temperature, depending on the shape of like and unlike interactions. Among them, stripes -- where layers of one type are regularly alternated with layers of another type -- hold a prominent place in materials science, occurring e.g. in the structure of superconductive doped antiferromagnets. Stripe patterns are relevant for the design of functional materials, with applications in optoelectronics, sensing, and biomedicine. In a purely classical setting, an open question pertains to the features that spherically-symmetric particle interactions must have to foster stripe order. Here we address this challenge for a lattice-gas mixture of two particle species, whose equilibrium properties are exactly determined by Monte Carlo simulations with Wang-Landau sampling, in both planar and spherical geometry, and for equal chemical potentials of the species. Somewhat surprisingly, stripes can emerge from largely different off-core interactions, featuring various combinations of repulsive like interactions with a predominantly attractive unlike interaction. In addition to stripes, our survey also unveils crystals and crystal-like structures, cluster crystals, and networks, which considerably broaden the catalog of possible patterns. Overall, our study demonstrates that stripes are more widespread than generally thought, as they can be generated by several distinct mechanisms, thereby explaining why stripe patterns are observed in systems as diverse as cuprate materials, biomaterials, and nanoparticle films."
  },
  {
    "date": "2026-01-20",
    "title": "Utilizing the Perceived Age to Maximize Freshness in Query-Based Update Systems",
    "authors": "Sahan Liyanaarachchi, Sennur Ulukus, Nail Akar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14075v1",
    "source": "arXiv",
    "abstract": "Query-based sampling has become an increasingly popular technique for monitoring Markov sources in pull-based update systems. However, most of the contemporary literature on this assumes an exponential distribution for query delay and often relies on the assumption that the feedback or replies to the queries are instantaneous. In this work, we relax both of these assumptions and find optimal sampling policies for monitoring continuous-time Markov chains (CTMC) under generic delay distributions. In particular, we show that one can obtain significant gains in terms of mean binary freshness (MBF) by employing a waiting based strategy for query-based sampling."
  },
  {
    "date": "2026-01-20",
    "title": "Unveiling Hidden Clustering: An Unsupervised Machine Learning Study of Repeating FRB 20220912A",
    "authors": "An-Chieh Hsu, Tetsuya Hashimoto, Tomotsugu Goto, Tomoki Wada, Bjorn Jasper Raquel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14065v1",
    "source": "arXiv",
    "abstract": "Fast Radio Bursts (FRBs) are millisecond-duration radio transients of extragalactic origin. Classifying repeating FRBs is essential for understanding their emission mechanisms, but remains challenging due to their short durations, high variability, and increasing data volume. Traditional methods often rely on subjective criteria and struggle with high-dimensional data. In this study, we apply an unsupervised machine learning framework that combines Uniform Manifold Approximation and Projection (UMAP) and Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) to eight observed parameters from FRB 20220912A. Our analysis reveals three distinct clusters of bursts with varying spectral and fluence properties. Comparisons with clustering studies on other repeaters show that some of our clusters share similar features with sources such as FRB 20201124A and FRB 121102, suggesting possible common emission mechanisms. We also provide qualitative interpretations for each cluster, highlighting the spectral diversity within a single source. Notably, one cluster shows broadband emission and high fluence, which are typically seen in non-repeating FRBs. This raises the possibility that some non-repeaters may be misclassified repeaters due to observational limitations. Our results demonstrate the utility of machine learning in uncovering intrinsic diversity in FRB emission and provide a foundation for future classification studies."
  },
  {
    "date": "2026-01-20",
    "title": "Time-dependent metrics and connections",
    "authors": "Xavier Gràcia, Xavier Rivas, Daniel Torres",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14064v1",
    "source": "arXiv",
    "abstract": "Time-dependent structures often appear in differential geometry, particularly in the study of non-autonomous differential equations on manifolds. One may study the geodesics associated with a time-dependent Riemannian metric by extremizing the corresponding energy functional, but also through the introduction of a more general concept of time-dependent covariant derivative operator. This relies on the examination of connections on the product manifold $\\mathbb{R}\\times M$. For these time-dependent covariant derivatives we explore the notions of parallel transport, geodesics and torsion. We also define the derivative of a one-parameter family of connections."
  },
  {
    "date": "2026-01-20",
    "title": "Frostman dimension of Furstenberg measure for $\\mathrm{SL}(2,\\mathbb{R})$ random matrix products",
    "authors": "Tom Rush",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14061v1",
    "source": "arXiv",
    "abstract": "For compactly supported $μ\\in \\mathcal{P}(\\mathrm{SL}(2,\\mathbb{R}))$ satisfying strong irreducibility and proximality, we obtain a formula for the Frostman dimension of the associated Furstenberg measure. We also describe the left neighbourhood of 0 for which the classical transfer operators defined by Le Page have a spectral gap on Hölder spaces in this setting."
  },
  {
    "date": "2026-01-20",
    "title": "Verifying Floating-Point Programs in Stainless",
    "authors": "Andrea Gilot, Axel Bergström, Eva Darulova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14059v1",
    "source": "arXiv",
    "abstract": "We extend the Stainless deductive verifier with floating-point support, providing the first automated verification support for floating-point numbers for a subset of Scala that includes polymorphism, recursion and higher-order functions. We follow the recent approach in the KeY verifier to axiomatise reasoning about mathematical functions, but go further by supporting all functions from Scala's math API, and by verifying the correctness of the axioms against the actual implementation in Stainless itself. We validate Stainless' floating-point support on a new set of benchmarks sampled from real-world code from GitHub, showing that it can verify specifications about, e.g., ranges of output or absence of special values for most supported functions, or produce counter-examples when the specifications do not hold."
  },
  {
    "date": "2026-01-20",
    "title": "Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI",
    "authors": "Andrea Protani, Marc Molina Van Den Bosch, Lorenzo Giusti, Heloisa Barbosa Da Silva, Paolo Cacace, Albert Sund Aillet, Miguel Angel Gonzalez Ballester, Friedhelm Hummel, Luigi Serio",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14055v1",
    "source": "arXiv",
    "abstract": "Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, a design that allocates a significant portion of its parameters to spatial reconstruction rather than feature learning. Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework's flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder's ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation."
  },
  {
    "date": "2026-01-20",
    "title": "Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering",
    "authors": "Yuxin Chen, Zhengzhou Cai, Xiangtian Ji, Weixiang Zhao, An Zhang, Xiang Wang, Tat-Seng Chua",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14050v1",
    "source": "arXiv",
    "abstract": "Mixture-of-Experts (MoE) architectures have shown strong multilingual capabilities, yet the internal mechanisms underlying performance gains and cross-language differences remain insufficiently understood. In this work, we conduct a systematic analysis of MoE models, examining routing behavior and expert specialization across languages and network depth. Our analysis reveals that multilingual processing in MoE models is highly structured: routing aligns with linguistic families, expert utilization follows a clear layerwise pattern, and high-resource languages rely on shared experts while low-resource languages depend more on language-exclusive experts despite weaker performance. Layerwise interventions further show that early and late MoE layers support language-specific processing, whereas middle layers serve as language-agnostic capacity hubs. Building on these insights, we propose a routing-guided steering method that adaptively guides routing behavior in middle layers toward shared experts associated with dominant languages at inference time, leading to consistent multilingual performance improvements, particularly for linguistically related language pairs. Our code is available at https://github.com/conctsai/Multilingualism-in-Mixture-of-Experts-LLMs."
  },
  {
    "date": "2026-01-20",
    "title": "Discovery and characterisation of two exoplanets orbiting the metal-poor, solar-type star TOI-5788 with TESS, CHEOPS, and HARPS-N",
    "authors": "Ben S. Lakeland, A. Mortier, R. D. Haywood, S. Ulmer-Moll, Z. Garai, A. Vanderburg, J A. Egger, D. A. Turner, D. Kubyshkina, A. C. M. Correia, H. P. Osborn, L. A. Buchhave, L. Malavolta, A. Bonfanti, W. Boschin, A. Cameron, A. Castro-González, R. Cosentino, M. Damasso, X. Dumusque, D. Ehrenreich, Z. Essack, S. Filomeno, L. Fossati, D. Gandolfi, M. Gillon, C. Hedges, M. López-Morales, G. Lacedelli, M. Lendl, J. Maldonado, G. Mantovan, A. F. Martínez Fiorenzano, P. F. L. Maxted, C. Mordasini, B. Nicholson, S. M. O'Brien, L. Palethorpe, E. Palle, M. Pinamonti, D. Rapetti, I. Ribas, N. C. Santos, A. M. Silva, A. Sozzetti, M. Stalport, G. Szabó, S. Udry, M. Vezie, C. A. Watson, T. G. Wilson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14045v1",
    "source": "arXiv",
    "abstract": "We present the discovery and characterisation of two transiting exoplanets orbiting the metal-poor, solar-type star TOI-5788. From our analysis of six \\textit{TESS} sectors and a dedicated \\textit{CHEOPS} programme, we identify an inner planet (TOI-5788~b; $P = 6.340758\\pm0.000030\\,\\si{\\day}$) with radius $1.528\\pm0.075\\,\\mathrm{R_\\oplus}$ and an outer planet (TOI-5788~c; $P = 16.213362\\pm0.000026\\,\\si{\\day}$) with radius $2.272\\pm0.039\\,\\mathrm{R_\\oplus}$. We obtained 125 radial-velocity spectra from HARPS-N and constrain the masses of TOI-5788~b and~c as $3.72\\pm0.94\\,\\mathrm{M_\\oplus}$ and $6.4\\pm1.2\\,\\mathrm{M_\\oplus}$, respectively. Although dynamical analyses indicate that a third planet could exist in a stable orbit between 8 and 14 days, we find no evidence of additional planets. Since the TOI-5788 system is one of the few systems with planets straddling the radius gap, and noting that there are even fewer such systems around metal poor stars, it is a promising system to constrain planet formation theories. We therefore model the interior structures of both planets. We find that TOI-5788~b is consistent with being a rocky planet with almost no envelope, or having an atmosphere of a high mean molecular weight. We find that TOI-5788~c is consistent with both gas-dwarf and water-world hypotheses of mini-Neptune formation. We model the atmospheric evolution history of both planets. Whilst both scenarios are consistent with the atmospheric evolution of TOI-5788~c, the gas-dwarf model is marginally preferred. The results of the atmospheric evolution analysis are not strongly dependent on stellar evolution. This makes the system a promising target to test internal structure and atmospheric evolution models."
  },
  {
    "date": "2026-01-20",
    "title": "Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants",
    "authors": "Yunhe Wang, Kai Han, Huiling Zhen, Yuchuan Tian, Hanting Chen, Yongbing Huang, Yufei Cui, Yingte Shu, Shan Gao, Ismail Elezi, Roy Vaughan Miles, Songcen Xu, Feng Wen, Chao Xu, Sinan Zeng, Dacheng Tao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14041v1",
    "source": "arXiv",
    "abstract": "The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration."
  },
  {
    "date": "2026-01-20",
    "title": "RM-Distiller: Exploiting Generative LLM for Reward Model Distillation",
    "authors": "Hongli Zhou, Hui Huang, Wei Liu, Chenglong Wang, Xingyuan Bu, Lvyuan Han, Fuhai Song, Muyun Yang, Wenhao Jiang, Hailong Cao, Tiejun Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14032v1",
    "source": "arXiv",
    "abstract": "Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs."
  },
  {
    "date": "2026-01-20",
    "title": "Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution",
    "authors": "Samuel W. Remedios, Zhangxing Bian, Shuwen Wei, Aaron Carass, Jerry L. Prince, Blake E. Dewey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14030v1",
    "source": "arXiv",
    "abstract": "Diffusion models are the current state-of-the-art for solving inverse problems in imaging. Their impressive generative capability allows them to approximate sampling from a prior distribution, which alongside a known likelihood function permits posterior sampling without retraining the model. While recent methods have made strides in advancing the accuracy of posterior sampling, the majority focuses on single-image inverse problems. However, for modalities such as magnetic resonance imaging (MRI), it is common to acquire multiple complementary measurements, each low-resolution along a different axis. In this work, we generalize common diffusion-based inverse single-image problem solvers for multi-image super-resolution (MISR) MRI. We show that the DPS likelihood correction allows an exactly-separable gradient decomposition across independently acquired measurements, enabling MISR without constructing a joint operator, modifying the diffusion model, or increasing network function evaluations. We derive MISR versions of DPS, DMAP, DPPS, and diffusion-based PnP/ADMM, and demonstrate substantial gains over SISR across $4\\times/8\\times/16\\times$ anisotropic degradations. Our results achieve state-of-the-art super-resolution of anisotropic MRI volumes and, critically, enable reconstruction of near-isotropic anatomy from routine 2D multi-slice acquisitions, which are otherwise highly degraded in orthogonal views."
  },
  {
    "date": "2026-01-20",
    "title": "Principal $p-$frequency estimates on non-compact manifolds with negative Ricci curvature",
    "authors": "Xiaoshang Jin, Zhiwei Lü",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14018v1",
    "source": "arXiv",
    "abstract": "We establish a lower bound for the principal $p-$frequency $λ_{1,p}(Ω)$ on a bounded domain $Ω$ in a non-compact Riemannian manifold of dimension $n.$ Under the assumption that the Ricci curvature satisfies $\\operatorname{Ric} \\geq (n-1)K$ with $K<0,$ we prove that $λ_{1,p}(Ω) > \\barλ_{D,K,n}$, where $D$ is the diameter of $Ω$ and $\\barλ_{D,K,n}$ is explicitly defined as the first eigenvalue of an associated one-dimensional ordinary differential equation model that incorporates both $D$ and $K.$ Moreover, the estimate is sharp. This work extends previous results for the case $K=0$ to the geometrically more complex setting of negative Ricci curvature, and providing a new quantitative connection between the eigenvalue, the diameter of domains, and the curvature lower bound."
  },
  {
    "date": "2026-01-20",
    "title": "Frame Dependence in Generalized Chiral Kinetic Theory",
    "authors": "Shu-Xiang Ma, Jian-Hua Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14010v1",
    "source": "arXiv",
    "abstract": "We investigate the frame dependence of distribution functions within the framework of generalized chiral kinetic theory. Based on the derived transformation rules governing the choice of frame, we analytically obtain the global equilibrium solution in the presence of vorticity and electromagnetic fields. Our results show that, under the assumption of a varying electromagnetic field, these equilibrium solutions can be uniquely determined."
  },
  {
    "date": "2026-01-20",
    "title": "Auditory Brain Passage Retrieval: Cross-Sensory EEG Training for Neural Information Retrieval",
    "authors": "Niall McGuire, Yashar Moshfeghi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14001v1",
    "source": "arXiv",
    "abstract": "Query formulation from internal information needs remains fundamentally challenging across all Information Retrieval paradigms due to cognitive complexity and physical impairments. Brain Passage Retrieval (BPR) addresses this by directly mapping EEG signals to passage representations without intermediate text translation. However, existing BPR research exclusively uses visual stimuli, leaving critical questions unanswered: Can auditory EEG enable effective retrieval for voice-based interfaces and visually impaired users? Can training on combined EEG datasets from different sensory modalities improve performance despite severe data scarcity? We present the first systematic investigation of auditory EEG for BPR and evaluate cross-sensory training benefits. Using dual encoder architectures with four pooling strategies (CLS, mean, max, multi-vector), we conduct controlled experiments comparing auditory-only, visual-only, and combined training on the Alice (auditory) and Nieuwland (visual) datasets. Results demonstrate that auditory EEG consistently outperforms visual EEG, and cross-sensory training with CLS pooling achieves substantial improvements over individual training: 31% in MRR (0.474), 43% in Hit@1 (0.314), and 28% in Hit@10 (0.858). Critically, combined auditory EEG models surpass BM25 text baselines (MRR: 0.474 vs 0.428), establishing neural queries as competitive with traditional retrieval whilst enabling accessible interfaces. These findings validate auditory neural interfaces for IR tasks and demonstrate that cross-sensory training addresses data scarcity whilst outperforming single-modality approaches Code: https://github.com/NiallMcguire/Audio_BPR"
  },
  {
    "date": "2026-01-20",
    "title": "DAME: Duration-Aware Matryoshka Embedding for Duration-Robust Speaker Verification",
    "authors": "Youngmoon Jung, Joon-Young Yang, Ju-ho Kim, Jaeyoung Roh, Chang Woo Han, Hoon-Young Cho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13999v1",
    "source": "arXiv",
    "abstract": "Short-utterance speaker verification remains challenging due to limited speaker-discriminative cues in short speech segments. While existing methods focus on enhancing speaker encoders, the embedding learning strategy still forces a single fixed-dimensional representation reused for utterances of any length, leaving capacity misaligned with the information available at different durations. We propose Duration-Aware Matryoshka Embedding (DAME), a model-agnostic framework that builds a nested hierarchy of sub-embeddings aligned to utterance durations: lower-dimensional representations capture compact speaker traits from short utterances, while higher dimensions encode richer details from longer speech. DAME supports both training from scratch and fine-tuning, and serves as a direct alternative to conventional large-margin fine-tuning, consistently improving performance across durations. On the VoxCeleb1-O/E/H and VOiCES evaluation sets, DAME consistently reduces the equal error rate on 1-s and other short-duration trials, while maintaining full-length performance with no additional inference cost. These gains generalize across various speaker encoder architectures under both general training and fine-tuning setups."
  },
  {
    "date": "2026-01-20",
    "title": "Eigensets of switching dynamical systems",
    "authors": "Vladimir Protasov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13990v1",
    "source": "arXiv",
    "abstract": "Reachability sets of linear switching dynamical systems (systems of ODE with time-dependent matrices that take values from a given compact set) are analysed. An eigenset is a non-trivial compact set M that possesses the following property: the closure of the set of points reachable by trajectories starting in M in time t is equal to exp(at)M. This concept introduced in a recent paper of E.Viscovini is an analogue of an eigenvector for compact sets of matrices. We prove the existence of eigensets, analyse their structure and properties, and find ``eigenvalues'' a for an arbitrary system. The question which compact sets, in particular, which convex sets and polyhedra, can be presented as eigensets of suitable systems, is studied."
  },
  {
    "date": "2026-01-20",
    "title": "Equivariant Learning for Unsupervised Image Dehazing",
    "authors": "Zhang Wen, Jiangwei Xie, Dongdong Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13986v1",
    "source": "arXiv",
    "abstract": "Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published."
  },
  {
    "date": "2026-01-20",
    "title": "The Geometry of Flux Surfaces with Quasi-Poloidal Symmetry",
    "authors": "Rishin Madan, Wrick Sengupta, Elizabeth J. Paul, Mohammed Haque, Richard Nies, Amitava Bhattacharjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13980v1",
    "source": "arXiv",
    "abstract": "Quasi-poloidal (QP) magnetic fields have desirable properties for confining plasma: no radial drift of guiding centres (with positive implications for neoclassical transport), zero Pfirsch-Schlüter current, a lower level of damping for poloidal flows, leading to reduced anomalous transport, and possible stability benefits. Despite their attractive properties, QP fields are not amenable to the near-axis expansion, a major theoretical tool for understanding toroidal fields. In this paper, we provide a novel framework for defining and understanding QP flux surfaces. This framework relies on a simplification that transforms the task of finding a quasi-poloidal flux surface from a 3D problem to a 2D problem. This simplification also applies to asymmetric magnetic mirrors with desirable properties. We sketch how this 2D problem can form the basis of an efficient optimisation problem for finding QP flux surfaces. We leverage this 2D problem for theoretical understanding: for instance, we identify one class of QP flux surfaces that are naturally flat mirrors (Velasco et al. 2023). The reduced model is validated against numerically optimised QP equilibria. We further utilise the reduced model to explain the prevalence of cusps, high mirror ratios, and narrow pinch points in these numerical equilibria."
  },
  {
    "date": "2026-01-20",
    "title": "Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects",
    "authors": "Raffaele Mazza, Ciro Natale, Pietro Falco",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13979v1",
    "source": "arXiv",
    "abstract": "This paper presents a novel cross-modal visuo-tactile perception framework for the 3D shape reconstruction of deformable linear objects (DLOs), with a specific focus on cables subject to severe visual occlusions. Unlike existing methods relying predominantly on vision, whose performance degrades under varying illumination, background clutter, or partial visibility, the proposed approach integrates foundation-model-based visual perception with adaptive tactile exploration. The visual pipeline exploits SAM for instance segmentation and Florence for semantic refinement, followed by skeletonization, endpoint detection, and point-cloud extraction. Occluded cable segments are autonomously identified and explored with a tactile sensor, which provides local point clouds that are merged with the visual data through Euclidean clustering and topology-preserving fusion. A B-spline interpolation driven by endpoint-guided point sorting yields a smooth and complete reconstruction of the cable shape. Experimental validation using a robotic manipulator equipped with an RGB-D camera and a tactile pad demonstrates that the proposed framework accurately reconstructs both simple and highly curved single or multiple cable configurations, even when large portions are occluded. These results highlight the potential of foundation-model-enhanced cross-modal perception for advancing robotic manipulation of deformable objects."
  },
  {
    "date": "2026-01-20",
    "title": "Toric Euler-Jacobi vanishing theorem and zeros at infinity",
    "authors": "Carlos D'Andrea, Alicia Dickenstein",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13977v1",
    "source": "arXiv",
    "abstract": "Residues appear naturally in various questions in complex and algebraic geometry: interpolation, duality, representation problems, and obstructions. The first global vanishing result in the projective plane, known as the Euler-Jacobi theorem, was established by Jacobi in 1835. In the toric case, the input is a system of n Laurent sparse polynomials with fixed Newton polytopes, and the first version of the Euler-Jacobi toric vanishing theorem for residues in the n-torus is due to Khovanskii in 1978, under restrictive genericity assumptions. In this paper, we provide geometric conditions on the input Newton polytopes to ensure that this global vanishing is equivalent to the existence of zeros at infinity in the associated compact toric variety. We relate these conditions to the dimension at the toric critical degree of the quotient of the Cox ring by the ideal generated by the (multi)homogenizations of the input polynomials. We also relate the existence of zeros at infinity to interpolation questions."
  },
  {
    "date": "2026-01-20",
    "title": "FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation",
    "authors": "Jing Zuo, Lingzhou Mu, Fan Jiang, Chengcheng Ma, Mu Xu, Yonggang Qi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13976v1",
    "source": "arXiv",
    "abstract": "Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods."
  },
  {
    "date": "2026-01-20",
    "title": "Influence of intraspecies interactions on the diversity of the wetting phase diagram in dilute ternary Bose-Einstein condensates",
    "authors": "Nguyen Van Thu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13968v1",
    "source": "arXiv",
    "abstract": "We investigate the influence of intraspecies interactions on the structure and diversity of the wetting phase diagram in a dilute ternary Bose-Einstein condensates. Within the GP formalism, we employ the double-parabola approximation to describe the interfacial properties of the system in the limit of strong segregation between two of the components. Our analysis focuses on the static behavior near degenerate points where distinct phase boundaries intersect in the parameter space defined by the healing-length ratios. We demonstrate that the first-order and critical wetting transition lines, along with the nucleation line intersect at a unique degenerate point. This finding contrasts with previous studies in the interspecies interaction space, where two degenerate points were observed. These results provide new insights into the interfacial phase behavior of multicomponent quantum gases and offer theoretical guidance for experimental explorations of wetting phenomena in ultracold atomic systems."
  },
  {
    "date": "2026-01-20",
    "title": "Direct probing the quantum geometric tensor for bosonic collective excitations",
    "authors": "Chi Wu, Takashi Oka, Shuichi Murakami, Tiantian Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13963v1",
    "source": "arXiv",
    "abstract": "The quantum geometric tensor (QGT), whose real and imaginary parts define the quantum metric and Berry curvature, encodes the intrinsic geometry of quantum states. While electronic QGT has been directly observed and linked to various phenomena like electron-phonon coupling, its bosonic analogue remains both theoretically and experimentally unexplored. We demonstrate that the dynamical structure factor directly encodes the full QGT throughout the Brillouin zone, establishing it as a sensitive probe of both quantum metric and Berry curvature. Applying this framework, we uncover clear geometric signatures in a twofold quadruple Weyl phonon in BaPtGe and the node-line magnon in Gd. Our results establish a general, direct route to measuring quantum geometry in bosonic systems, a crucial step toward elucidating its impact on condensed matter phenomena."
  },
  {
    "date": "2026-01-20",
    "title": "Tensor Network Assisted Distributed Variational Quantum Algorithm for Large Scale Combinatorial Optimization Problem",
    "authors": "Yuhan Huang, Siyuan Jin, Yichi Zhang, Qi Zhao, Jun Qi, Qiming Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13956v1",
    "source": "arXiv",
    "abstract": "Although quantum computing holds promise for solving Combinatorial Optimization Problems (COPs), the limited qubit capacity of NISQ hardware makes large-scale instances intractable. Conventional methods attempt to bridge this gap through decomposition or compression, yet they frequently fail to capture global correlations of subsystems, leading to solutions of limited quality. We propose the Distributed Variational Quantum Algorithm (DVQA) to overcome these limitations, enabling the solution of 1,000-variable instances on constrained hardware. A key innovation of DVQA is its use of the truncated higher-order singular value decomposition to preserve inter-variable dependencies without relying on complex long-range entanglement, leading to a natural form of noise localization where errors scale with subsystem size rather than total qubit count, thus reconciling scalability with accuracy. Theoretical bounds confirm the algorithm's robustness for p-local Hamiltonians. Empirically, DVQA achieves state-of-the-art performance in simulations and has been experimentally validated on the Wu Kong quantum computer for portfolio optimization. This work provides a scalable, noise-resilient framework that advances the timeline for practical quantum optimization algorithms."
  },
  {
    "date": "2026-01-20",
    "title": "Uniform Consistency of Generalized Cross-Validation for Ridge Regression in High-Dimensional Misspecified Linear Models",
    "authors": "Akira Shinkyu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13955v1",
    "source": "arXiv",
    "abstract": "This study examines generalized cross-validation for the tuning parameter selection for ridge regression in high-dimensional misspecified linear models. The set of candidates for the tuning parameter includes not only positive values but also zero and negative values. We demonstrate that if the second moment of the specification error converges to zero, generalized cross-validation is still a uniformly consistent estimator of the out-of-sample prediction risk. This implies that generalized cross-validation selects the tuning parameter for which ridge regression asymptotically achieves the smallest prediction risk among the candidates if the degree of misspecification for the regression function is small. Our simulation studies show that ridge regression tuned by generalized cross-validation exhibits a prediction performance similar to that of optimally tuned ridge regression and outperforms the Lasso under correct and incorrect model specifications."
  },
  {
    "date": "2026-01-20",
    "title": "Nonlinear competition avoidance favors coexistence in microbial populations",
    "authors": "Mattia Mattei, David Soriano-Paños, Alex Arenas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13947v1",
    "source": "arXiv",
    "abstract": "Bacteria regulate their motility through a variety of mechanisms, including quorum sensing (QS) and other density-dependent responses mediated by diffusible signals. While nonlinear density-dependent motility is well known in active-matter theory to generate nonequilibrium spatial patterns, its consequences for the coexistence of growing, interacting species remain less explored. Here we develop a minimal spatially structured model for two strongly competing species in which local demographic interactions are coupled to an escape response: each species increases its motility nonlinearly (sigmoidal) with the local abundance of its competitor. We show that this sigmoidal motility regulation promotes optimal spatial self-organization and can sustain long term coexistence via segregation, even in parameter regimes that yield competitive exclusion in well-mixed Lotka-Volterra dynamics. On two-dimensional lattices, the interplay between demographic competition and density-dependent motility generates a range of emergent patterns, including regimes in which the weaker competitor counterintuitively has higher total abundance. Overall, our results identify nonlinear, competitor-induced motility as a fundamental mechanism capable of sustaining coexistence in competing microbial populations."
  },
  {
    "date": "2026-01-20",
    "title": "Gallai-Ramsey Numbers for $\\ell$-Connected Graphs",
    "authors": "Zhao Wang, Lanyanni Zhang, Meiqin Wei, Mark Budden",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13944v1",
    "source": "arXiv",
    "abstract": "Given a nonempty graph $G$, a collection of nonempty graphs $\\cal{H}$, and a positive integer $k$, the Gallai-Ramsey number $\\mathrm{gr}_k(G:\\mathcal{H})$ is defined to be the minimum positive integer $n$ such that every exact $k$-edge-coloring of a complete graph $K_n$ contains either a rainbow copy of $G$ or a monochromatic copy of some element in $\\mathcal{H}$. In this paper, we obtain some exact values and general lower and upper bounds for $\\mathrm{gr}_k(G:\\mathcal{F}^\\ell)$, where $\\mathcal{F}^\\ell$ is the set of $\\ell$-connected graphs and $G\\in\\{P_5, K_{1,3}\\}$."
  },
  {
    "date": "2026-01-20",
    "title": "Rotational enhancement and stability of protoquark stars during thermal evolution",
    "authors": "Adamu Issifu, Andreas Konstantinou, Prashant Thakur, Tobias Frederico",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13941v1",
    "source": "arXiv",
    "abstract": "We present the first systematic study of rigidly rotating protoquark stars based on isentropic equations of state (EOS) within the density-dependent quark mass (DDQM) framework. Using a quasi-static equilibrium approach, we follow the Kelvin--Helmholtz evolution from hot, lepton-rich matter to a cold, catalyzed quark star. Rotation substantially enhances the maximum stable mass (by up to $\\sim 40\\%$), equatorial radius, and key rotational observables, with the ratio of rotational kinetic to gravitational potential energy, $T_{\\rm kin}/|W|$, reaching $0.18$--$0.19$ near the Keplerian limit, indicating a heightened susceptibility to gravitational-wave--emitting instabilities. Thermal evolution introduces a clear ordering: all stellar properties peak during the lepton-rich stages and decrease monotonically as the star cools. Compared to hadronic stars, rotating protoquark stars exhibit larger radii, higher moments of inertia, and stronger quadrupolar deformation, producing a distinct signature in the mass--radius--spin plane that can accommodate objects such as HESS~J1731--347 and PSR~J0740+6620. These results demonstrate that future multimessenger observations must account for both thermal history and rotation to robustly identify quark matter in compact stars."
  },
  {
    "date": "2026-01-20",
    "title": "Geometry-Driven Conditioning of Multivariate Vandermonde Matrices in High-Degree Regimes",
    "authors": "Omer Friedland, Yosef Yomdin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13915v1",
    "source": "arXiv",
    "abstract": "We study multivariate monomial Vandermonde matrices $V_N(Z)$ with arbitrary distinct nodes $Z=\\{z_1,\\dots,z_s\\}\\subset B_2^n$ in the high-degree regime $N\\ge s-1$. Introducing a projection-based geometric statistic -- the \\emph{max-min projection separation} $ρ(Z,j)$ and its minimum $κ(Z)=\\min_jρ(Z,j)$ -- we construct Lagrange polynomials $Q_j\\in\\mathcal P_N^n$ with explicit coefficient bounds $$ \\|Q_j\\|_\\infty \\lesssim s\\Bigl(\\frac{4n}{ρ(Z,j)}\\Bigr)^{s-1}. $$ These polynomials yield quantitative distance-to-span estimates for the rows of $V_N(Z)$ and, as consequences, $$ σ_{\\min}(V_N(Z)) \\gtrsim \\frac{κ(Z)^{s-1}}{(4n)^{s-1} s\\sqrt{s ν(n,N)}}, \\quad ν(n,N)={N+n\\choose N}, $$ and an explicit right inverse $V_N(Z)^+$ with operator-norm control $$ \\|V_N(Z)^+\\| \\lesssim s^{3/2}\\sqrt{ν(n,N)}\\Bigl(\\frac{4n}{κ(Z)}\\Bigr)^{s-1}. $$ Our estimates are dimension-explicit and expressed directly in terms of the local geometry parameter $κ(Z)$; they apply to \\emph{every} distinct node set $Z\\subset B_2^n$ without any \\emph{a priori} separation assumptions. In particular, $V_N(Z)$ has full row rank whenever $N\\ge s-1$. The results complement the Fourier-type theory (on the complex unit circle/torus), where lower bounds for $σ_{\\min}$ hinge on uniform separation or cluster structure; here stability is quantified instead via high polynomial degree and the projection geometry of $Z$."
  },
  {
    "date": "2026-01-20",
    "title": "Homogeneous substructures in random ordered uniform matchings",
    "authors": "Andrzej Dudek, Jarosław Grytczuk, Jakub Przybyło, Andrzej Ruciński",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13906v1",
    "source": "arXiv",
    "abstract": "An ordered $r$-uniform matching of size $n$ is a collection of $n$ pairwise disjoint $r$-subsets of a linearly ordered set of $rn$ vertices. For $n=2$, such a matching is called an $r$-pattern, as it represents one of $\\tfrac12\\binom{2r}r$ ways two disjoint edges may intertwine. Given a set $\\mathcal{P}$ of $r$-patterns, a $\\mathcal{P}$-clique is a matching with all pairs of edges belonging to $\\mathcal{P}$. In this paper we determine the order of magnitude of the size of a largest $\\mathcal{P}$-clique in a random ordered $r$-uniform matching for several sets $\\mathcal{P}$, including all sets of size $|\\mathcal{P}|\\le2$ and the set $\\mathcal{R}^{(r)}$ of all $2^{r-1}$ $r$-partite $r$-patterns."
  },
  {
    "date": "2026-01-20",
    "title": "Janus MoSSe/WSSe Heterobilayers as Selective Photocatalysts for Water Splitting",
    "authors": "Mostafa Torkashvand, Saeedeh Sarabadani Tafreshi, Caterina Cocchi, Surender Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13898v1",
    "source": "arXiv",
    "abstract": "Identifying materials that simultaneously straddle the water redox potentials and possess an intrinsic electric field is crucial for achieving high solar-to-hydrogen (STH) efficiency. Using state-of-the-art first-principles calculations, including a range-separated hybrid functional and spin-orbit coupling, we investigate MoXY/WXY (X, Y = S, Se) Janus bilayers for overall water splitting. We find that the Se-Se interfaced heterobilayer is intrinsically capable of driving water splitting, while its S-S counterpart can meet the redox requirements through pH modulation. For both configurations, a remarkable STH efficiency of 17.1\\% is predicted. Compared with homo-bilayers, hetero-bilayers benefit from the chemical potential difference between Mo and W, which generates a built-in electric field and promotes spatial separation of photogenerated carriers, suppressing recombination and overall enhancing hydrogen production. These results demonstrate the promise of Janus heterobilayers for efficient solar-driven water splitting."
  },
  {
    "date": "2026-01-20",
    "title": "Boxy/Peanut Bulges: Comparative Analysis of EGIPS Galaxies and TNG50 Models",
    "authors": "Anton Smirnov, Alexander Marchuk, Viktor Zozulia, Natalia Sotnikova, Sergey Savchenko",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13893v1",
    "source": "arXiv",
    "abstract": "We investigated the properties of boxy/peanut-shaped (B/PS) bulges in a sample of 71 galaxies from the Edge-on Galaxies in the Pan-STARRS Survey (EGIPS) and 20 simulated galaxies from Illustris TNG50 using multicomponent photometric decomposition. For each real and simulated galaxy, we obtained a suitable photometric model in which the B/PS bulge was represented by a dedicated 2D photometric function. For real galaxies, we found that more flattened X-structures are generally residing in larger B/PS bulges. When tested against the galaxy masses, we verified that both larger bulges and more flattened X-structures are typically found in more massive galaxies. Since large bars are also known to reside in more massive galaxies, we conclude that the flatness of X-structures in larger B/PS bulges has a physical origin, rather than being solely a result of projection effects due to differences in observed bar viewing angles. When comparing the properties of B/PS bulges between EGIPS galaxies and TNG50 galaxies, with bars rotated for different viewing angles, we found that B/PS bulges in TNG50 are considerably smaller and less luminous in terms of total intensity. This is consistent with previous studies of bar properties in TNG50, indicating the B/PS bulges in TNG50 differ from those in real galaxies, as do their parent bars."
  },
  {
    "date": "2026-01-20",
    "title": "Towards Inclusive External Human-Machine Interface: Exploring the Effects of Visual and Auditory eHMI for Deaf and Hard-of-Hearing People",
    "authors": "Wenge Xu, Foroogh Hajiseyedjavadi, Kurtis Weir, Chukwuemeka Eze, Mark Colley",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13889v1",
    "source": "arXiv",
    "abstract": "External Human-Machine Interfaces (eHMIs) have been proposed to facilitate communication between Automated Vehicles (AVs) and pedestrians. However, no attention was given to Deaf and Hard-of-Hearing (DHH) people. We conducted a formative study through focus groups with 6 DHH people and 6 key stakeholders (including researchers, assistive technologists, and automotive interface designers) to compare proposed eHMIs and extract key design requirements. Subsequently, we investigated the effects of visual and auditory eHMI in a virtual reality user study with 32 participants (16 DHH). Results from our scenario suggesting that (1) DHH participants spent more time looking at the AV; (2) both visual and auditory eHMIs enhanced trust, usefulness, and perceived safety; and (3) only visual eHMIs reduced the time to step into the road, time looking at the AV, gaze time, and percentage looking at active visual eHMI components. Lastly, we provided five practical implications for making eHMI inclusive of DHH people."
  },
  {
    "date": "2026-01-20",
    "title": "Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores",
    "authors": "Esma Balkır, Alice Pernthaller, Marco Basaldella, José Hernández-Orallo, Nigel Collier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13885v1",
    "source": "arXiv",
    "abstract": "Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions."
  },
  {
    "date": "2026-01-20",
    "title": "Ethernet-over-OWC Using VCSELs: Transparent Gigabit Links with Low Latency and Robust Alignment Tolerance",
    "authors": "Hossein Safi, Isaac N. O. Osahon, Iman Tavakkolnia, Harald Haas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13878v1",
    "source": "arXiv",
    "abstract": "We demonstrate a fully bidirectional 1 Gbs Ethernet over OWC link over a 1m free space path using a VCSEL-PIN pair and only commercially available components. The unamplified, transparent system achieves error-free operation, with a latency of less than 25 ns, and a centimetre-scale alignment tolerance."
  },
  {
    "date": "2026-01-20",
    "title": "Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education",
    "authors": "Unggi Lee, Jahyun Jeong, Sunyoung Shin, Haeun Park, Jeongsu Moon, Youngchang Song, Jaechang Shim, JaeHwan Lee, Yunju Noh, Seungwon Choi, Ahhyun Kim, TaeHyeon Kim, Kyungtae Joo, Taeyeong Kim, Gyeonggeon Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13876v1",
    "source": "arXiv",
    "abstract": "Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \\textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations."
  },
  {
    "date": "2026-01-20",
    "title": "Unified Unbiased Variance Estimation for MMD: Robust Finite-Sample Performance with Imbalanced Data and Exact Acceleration under Null and Alternative Hypotheses",
    "authors": "Shijie Zhong, Jiangfeng Fu, Yikun Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13874v1",
    "source": "arXiv",
    "abstract": "The maximum mean discrepancy (MMD) is a kernel-based nonparametric statistic for two-sample testing, whose inferential accuracy depends critically on variance characterization. Existing work provides various finite-sample estimators of the MMD variance, often differing under the null and alternative hypotheses and across balanced or imbalanced sampling schemes. In this paper, we study the variance of the MMD statistic through its U-statistic representation and Hoeffding decomposition, and establish a unified finite-sample characterization covering different hypotheses and sample configurations. Building on this analysis, we propose an exact acceleration method for the univariate case under the Laplacian kernel, which reduces the overall computational complexity from $\\mathcal O(n^2)$ to $\\mathcal O(n \\log n)$."
  },
  {
    "date": "2026-01-20",
    "title": "A phase space approach to the wavefunction and operator spreading in the Krylov basis",
    "authors": "Kunal Pal, Kuntal Pal, Keun-Young Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13872v1",
    "source": "arXiv",
    "abstract": "In the Wigner-Weyl phase space formulation of quantum mechanics, we analyse the problem of the spreading of an initial state or an initial operator under time evolution when described in terms of the Krylov basis. After constructing the phase space representations of the Krylov basis states generated by a Hamiltonian from a given initial state by using the Weyl transformation, we subsequently use them to cast the Krylov state complexity as an integral over the phase space in terms of the Wigner function of the time-evolved initial state, so that the contribution of the classical Liouville equation and higher-order quantum corrections to the Wigner function time evolution equation towards the Krylov state complexity can be identified. Next, we construct the double phase space functions associated with the Krylov basis for the operators by using a suitable generalisation of the Weyl transformation applicable for superoperators, and use them to rewrite the Krylov operator complexity as an integral over the double phase space in terms of a generalisation of the usual Wigner function. These results, in particular, show that the complexity measures based on the expansion of a time-evolved state (or an operator) in the Krylov basis can be thought to belong to a general class of complexity measures constructed from the expansion coefficients of the time-dependent Wigner function in an orthonormal basis in the phase space, and help us to connect these complexity measures with measures of complexity of time-evolved state based on harmonic expansion of the time-dependent Wigner function."
  },
  {
    "date": "2026-01-20",
    "title": "OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting",
    "authors": "Michail Spanakis, Iason Oikonomidis, Antonis Argyros",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13871v1",
    "source": "arXiv",
    "abstract": "Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter."
  },
  {
    "date": "2026-01-20",
    "title": "Unraveling the Mechanisms of Ultrasound-Induced Mechanical Degradation of Microgels: Effects of Mechanoresponsive Crosslinks, Softness, and Core-Shell Architecture",
    "authors": "Alexander V. Petrunin, Susanne Braun, Felix J. Byn, Indré Milvydaité, Timon Kratzenberg, Pablo Mota-Santiago, Andrea Scotti, Andrij Pich, Walter Richtering",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13862v1",
    "source": "arXiv",
    "abstract": "Ultrasound-induced degradation of soft polymeric colloids, like microgels, as well as a controlled drug release enabled by mechanoresponsive bonds, has recently attracted considerable attention. However, most examples in the literature focus primarily on the applications rather than examining the underlying mechanisms of the structural changes occurring in microgels due to cavitation - changes that are crucial for developing effective drug delivery systems. In this work, we provide a comprehensive view on how microgel structure governs the susceptibility to rupture and mass loss upon cavitation, investigating both conventional microgels containing mechanoresponsive disulfide bonds and more complex asymmetrically crosslinked core-shell microgels. By combining dynamic and static light scattering, small-angle X-ray scattering, and atomic force microscopy, we demonstrate that an interplay between mechanoresponsive crosslinks and the swelling degree determines the microgels susceptibility to ultrasound-induced damage. Our findings indicate that local stress from cavitation bubbles varies strongly within the microgel dispersion. The majority of microgels undergo gradual erosion at their periphery, resulting in smaller yet structurally intact particles over time, observable by light scattering and AFM. In contrast, microgels closer to a cavitation bubble can experience partial rupture or completely disintegrate, producing smaller, more polydisperse fragments, which contributes substantially to the overall mass loss observed. In the core-shell microgels with different crosslinkers in the core and shell, degradation occurs nearly uniformly across both regions, instead of selectively targeting the weaker part. These observations highlight the complexity of the degradation dynamics as well as the similarity to processes seen in linear polymers and bulk hydrogels."
  },
  {
    "date": "2026-01-20",
    "title": "Patterns and Tracks",
    "authors": "M. J. Dunwoody",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13861v1",
    "source": "arXiv",
    "abstract": "Patterns in triangulated $2$-spheres and $3$-spheres are investigated. A new proof of a lemma in Abigail Thompson's proof of the Recognition Algorithm for $3$-spheres is obtained."
  },
  {
    "date": "2026-01-20",
    "title": "Designing Drone Interfaces to Assist Pedestrians Crossing Non-Signalised Roads",
    "authors": "Guixiang Zhang, Yiyuan Wang, Marius Hoggenmueller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13858v1",
    "source": "arXiv",
    "abstract": "Recent research highlights the potential of drones to enhance pedestrian experiences, such as aiding navigation and supporting street-level activities. This paper explores the design of drone interfaces to assist pedestrians crossing dangerous roads without designated crosswalks or traffic lights, leveraging drones' ability to monitor and analyse real-time traffic data. Inspired by existing traffic signal systems, the interface communicates safety information through permissive alerts, prohibitive warnings, directional warnings, and collision emergency warnings. These safety cues were integrated into drone interfaces using in-situ projections and drone-equipped screens through an iterative design process. A mixed-methods, within-subjects VR evaluation (n=18) revealed that drone-assisted systems significantly improved pedestrian safety experiences and reduced mental workload compared to a baseline without any crossing aid, with projections outperforming screens. The findings suggest the potential for drone interfaces to be integrated into connected traffic systems. We also offer design recommendations for developing drone interfaces that support safe pedestrian crossings."
  },
  {
    "date": "2026-01-20",
    "title": "Basic Albanese maps of regular Riemannian foliations",
    "authors": "Kinga Słowik, Robert Wolak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13853v1",
    "source": "arXiv",
    "abstract": "In the paper we introduce the notion of basic Albanese map which we define for foliated Riemannian manifolds using basic 1-forms. We relate this mapping to the classical Albanese map for the ambient manifold. The study of general properties is supplemented with the description of several important examples."
  },
  {
    "date": "2026-01-20",
    "title": "FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs",
    "authors": "Qian Chen, Jinlan Fu, Changsong Li, See-Kiong Ng, Xipeng Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13836v1",
    "source": "arXiv",
    "abstract": "Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni)."
  },
  {
    "date": "2026-01-20",
    "title": "Analytic description of the moving moisture front in soils",
    "authors": "Bettina Detmann, Chiara Gavioli, Pavel Krejčí, Yanyan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13833v1",
    "source": "arXiv",
    "abstract": "The fact that moisture propagates in soils at a finite speed is confirmed by natural everyday experience as well as by controlled laboratory tests. In this text, we rigorously derive analytical upper bounds for the speed of moisture front propagation under gravity for the solution to the Richards equation with compactly supported initial data. The main result is an explicit criterion describing a competition between gravity and capillarity, where the dominant effect is determined by the characteristics of the soil. If capillarity prevails, the initially wet regions remain wet for all times, while if gravity is dominant, moisture travels downward at a speed that is asymptotically bounded from below and above. As a by-product, we prove the existence and uniqueness of a solution to an initial value problem for the degenerate Richards equation on the whole space. Numerical simulations based on the proposed model confirm the theoretical predictions, with results that closely match experimental observations."
  },
  {
    "date": "2026-01-20",
    "title": "Examination of frequency and scale dependence of CMB hemispherical power asymmetry",
    "authors": "Sanjeev Sanyal, Pavan Kumar Aluri, Arman Shafieloo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13830v1",
    "source": "arXiv",
    "abstract": "In this study, we revisit the well-known cosmic microwave background (CMB) anomaly referred to as Hemispherical Power Asymmetry (HPA), using CMB temperature maps from the Planck mission public release 4 (PR4) and the WMAP nine-year data release. Employing the Local Variance Estimator (LVE) method, we systematically reexamine the properties of HPA to investigate possible frequency dependence as well as scale dependence in its amplitude and direction. We model the HPA as a scale-dependent dipole modulation following a power-law form, rather than assuming a scale-invariant case. Our analysis incorporates seven cleaned frequency-specific CMB temperature maps from both the Planck and WMAP missions to test the robustness of the observed asymmetry across instruments and frequency channels. We find that the dipolar modulation characteristic of HPA is present in all cases examined, with consistent estimates of the preferred direction and scale-dependent variation in dipole amplitudes. These results support the conclusion that the observed asymmetry is unlikely to arise from instrumental artifacts or data-processing effects, and instead points toward a persistent large-scale feature of the CMB sky with a possible cosmological origin."
  },
  {
    "date": "2026-01-20",
    "title": "Modulating Retroreflectors for CubeSat Optical Inter Satellite Links: Modeling, Optimization, and Benchmarking",
    "authors": "Makafui Avevor, Hossein Safi, Harald Haas, Iman Tavakkolnia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13829v1",
    "source": "arXiv",
    "abstract": "Modulating retroreflectors (MRRs) offer a promising pathway to low-complexity and energy efficient asymmetric optical inter-satellite link (OISL) for small spacecrafts, such as CubeSats. In this paper, we develop a unified statistical channel model for an on off keying modulated, retroreflector-enabled OISL. The model captures both stochastic and deterministic pointing losses, as well as signal-dependent noise. Stochastic channel distributions are approximated via Monte Carlo simulation, and system optimization is carried out under CubeSat constraints using the achievable information rate as the primary metric. In addition, we derive bit-error ratio and outage probability to evaluate communication reliability. The proposed architecture is benchmarked against three state-of-the-art CubeSat laser terminals, i.e., NASA's Optical Communications and Sensors Demonstration (OCSD), DLR's OSIRIS4CubeSat, and NASA's CLICK BC. Results indicate that an optimized MRR-based transmitter can outperform OCSD and achieve performance comparable to OSIRIS4CubeSat at ranges below 500 km, while consuming only 2.5 W of power during transmission, significantly less than conventional CubeSat optical terminals."
  },
  {
    "date": "2026-01-20",
    "title": "ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks",
    "authors": "Xiaohong Yang, Tong Xie, Minghui Liwang, Chikai Shang, Yang Lu, Zhenzhen Jiao, Liqun Fu, Seyyedali Hosseinalipour",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13824v1",
    "source": "arXiv",
    "abstract": "Training large language models (LLMs) at the network edge faces fundamental challenges arising from device resource constraints, severe data heterogeneity, and heightened privacy risks. To address these, we propose ELSA (Efficient LLM-centric Split Aggregation), a novel framework that systematically integrates split learning (SL) and hierarchical federated learning (HFL) for distributed LLM fine-tuning over resource-constrained edge networks. ELSA introduces three key innovations. First, it employs a task-agnostic, behavior-aware client clustering mechanism that constructs semantic fingerprints using public probe inputs and symmetric KL divergence, further enhanced by prediction-consistency-based trust scoring and latency-aware edge assignment to jointly address data heterogeneity, client unreliability, and communication constraints. Second, it splits the LLM into three parts across clients and edge servers, with the cloud used only for adapter aggregation, enabling an effective balance between on-device computation cost and global convergence stability. Third, it incorporates a lightweight communication scheme based on computational sketches combined with semantic subspace orthogonal perturbation (SS-OP) to reduce communication overhead while mitigating privacy leakage during model exchanges. Experiments across diverse NLP tasks demonstrate that ELSA consistently outperforms state-of-the-art methods in terms of adaptability, convergence behavior, and robustness, establishing a scalable and privacy-aware solution for edge-side LLM fine-tuning under resource constraints."
  },
  {
    "date": "2026-01-20",
    "title": "$\\mathbf{γZ}$ Box at Low Energy",
    "authors": "Balma Duch, Pere Masjuan, Hubert Spiesberger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13819v1",
    "source": "arXiv",
    "abstract": "We calculate the 1-loop $γZ$ box-graph correction to electron-quark scattering at low energy and low momentum transfer. Both electron and quark masses are kept non-zero. From our result, we extract coupling constants for the low-energy effective Lagrangian with parity-violating 4-fermion interaction terms. We study the zero-mass limits and show that a non-zero electron mass is sufficient to obtain finite, well-defined couplings which are insensitive to a hadronic mass cutoff. We finally discuss the impact of our results on the determination of the weak charge of the proton from polarized electron-proton scattering."
  },
  {
    "date": "2026-01-20",
    "title": "Squeezed-Light-Enhanced Multiparameter Quantum Estimation in Cavity Magnonics",
    "authors": "Hamza Harraf, Mohamed Amazioug, Rachid Ahl Laamara",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13814v1",
    "source": "arXiv",
    "abstract": "Improving multiparameter quantum estimation in magnonic systems via quantum noise suppression is a well-established and critical research objective. In this work, we propose an experimentally realistic scheme to improve the precision of simultaneously estimating different parameters in a cavity-magnon system by utilizing a degenerate optical parametric amplifier (OPA). The OPA enhances the estimation precision by decreasing the most informative quantum Cramér-Rao bound, calculated employing the symmetric logarithmic derivative (SLD) and the right logarithmic derivative (RLD). We show that when nonlinearity is introduced into the system, quantum noise is significantly suppressed. Our results show how different physical parameters influence multiparameter estimation precision and provide a detailed discussion of the associated physical mechanisms in the steady state. Our results focus on exploring practical Gaussian measurement schemes that can be realized experimentally. Besides, we further analyze the system's dynamics, comparing both the SLD quantum Fisher information (QFI) and the classical Fisher information (CFI) for both homodyne and heterodyne detection. This approach provides a robust foundation for multiparameter quantum estimation, offering significant potential for application in hybrid magnomechanical and optomechanical systems."
  },
  {
    "date": "2026-01-20",
    "title": "Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning",
    "authors": "Dezhao Song, Guglielmo Bonifazi, Frank Schilder, Jonathan Richard Schwarz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13806v1",
    "source": "arXiv",
    "abstract": "LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \\textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability."
  },
  {
    "date": "2026-01-20",
    "title": "Zero-free regions and concentration inequalities for hypergraph colorings in the local lemma regime",
    "authors": "Jingcheng Liu, Yixiao Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13796v1",
    "source": "arXiv",
    "abstract": "We show that for $q$-colorings in $k$-uniform hypergraphs with maximum degree $Δ$, if $k\\ge 50$ and $q\\ge 700Δ^{\\frac{5}{k-10}}$, there is a \"Lee-Yang\" zero-free strip around the interval $[0,1]$ of the partition function, which includes the special case of uniform enumeration of hypergraph colorings. As an immediate consequence, we obtain Berry-Esseen type inequalities for hypergraph $q$-colorings under such conditions, demonstrating the asymptotic normality for the size of any color class in a uniformly random coloring. Our framework also extends to the study of \"Fisher zeros\", leading to deterministic algorithms for approximating the partition function in the zero-free region. Our approach is based on extending the recent work of [Liu, Wang, Yin, Yu, STOC 2025] to general constraint satisfaction problems (CSP). We focus on partition functions defined for CSPs by introducing external fields to the variables. A key component in our approach is a projection-lifting scheme, which enables us to essentially lift information percolation type analysis for Markov chains from the real line to the complex plane. Last but not least, we also show a Chebyshev-type inequality under the sampling LLL condition for atomic CSPs."
  },
  {
    "date": "2026-01-20",
    "title": "A Distributed Spatial Data Warehouse for AIS Data (DIPAAL)",
    "authors": "Alex S. Klitgaard, Lau E. Josefsen, Mikael V. Mikkelsen, Kristian Torp",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13795v1",
    "source": "arXiv",
    "abstract": "AIS data from ships is excellent for analyzing single-ship movements and monitoring all ships within a specific area. However, the AIS data needs to be cleaned, processed, and stored before being usable. This paper presents a system consisting of an efficient and modular ETL process for loading AIS data, as well as a distributed spatial data warehouse storing the trajectories of ships. To efficiently analyze a large set of ships, a raster approach to querying the AIS data is proposed. A spatially partitioned data warehouse with a granularized cell representation and heatmap presentation is designed, developed, and evaluated. Currently the data warehouse stores ~312 million kilometers of ship trajectories and more than +8 billion rows in the largest table. It is found that searching the cell representation is faster than searching the trajectory representation. Further, we show that the spatially divided shards enable a consistently good scale-up for both cell and heatmap analytics in large areas, ranging between 354% to 1164% with a 5x increase in workers"
  },
  {
    "date": "2026-01-20",
    "title": "Characterizations of a class of Musielak--Orlicz BMO spaces via commutators of Riesz potential operators",
    "authors": "Yanyan Han, Hongwei Huang, Jinghan Shao, Huoxiong Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13788v1",
    "source": "arXiv",
    "abstract": "The fractional integral operators $I_α$ can be used to characterize the Musielak--Orlicz Hardy spaces. This paper shows that for $b\\in \\rm BMO(\\mathbb R^n)$, the commutators $[b,I_α]$ generated by fractional integral operators $I_α$ with $b$ are bounded from the Musielak--Orlicz Hardy spaces $H^{\\varphi_1}(\\mathbb R^n)$ to the Musielak--Orlicz spaces $L^{\\varphi_2}(\\mathbb R^n)$ (where $1<u<\\infty$ and $\\varphi_1$, $\\varphi_2$ are growth functions) if and only if $b\\in \\mathcal {BMO}_{\\varphi_1,u}(\\mathbb R^n)$, which are a class of non-trivial subspaces of $\\rm BMO(\\mathbb R^n)$. Additionally, we obtain the boundedness of the commutator $[b,I_α]$ from $H^{\\varphi_1}(\\mathbb R^n)$ to $H^{\\varphi_2}(\\mathbb R^n)$. The corresponding results are also provided for commutators of fractional integrals associated with general homogeneous kernels."
  },
  {
    "date": "2026-01-20",
    "title": "Projected sensitivity to light WIMP-like particles of the BULLKID-DM experiment",
    "authors": "Matteo Folcarelli, A. Acevedo-Rentería, L. E. Ardila-Perez, L. Bandiera, M. Calvo, M. Cappelli, R. Caravita, F. Carillo, U. Chowdhury, D. Crovo, A. Cruciani, A. D'Addabbo, D. Delicato, M. De Lucia, G. Del Castello, M. del Gallo Roccagiovine, F. Ferraro, S. Fu, R. Gartmann, M. Grassi, V. Guidi, D. Helis, T. Lari, L. Malagutti, A. Mazzolari, A. Monfardini, T. Muscheid, D. Nicolò, F. Paolucci, D. Pasciuto, L. Pesce, C. Puglia, D. Quaranta, C. M. A. Roda, S. Roddaro, M. Romagnoni, G. Signorelli, F. Simon, A. Tartari, E. Vázquez-Jáuregui, M. Vignati, K. Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13766v1",
    "source": "arXiv",
    "abstract": "BULLKID-DM is an experiment designed for the direct searches of particle dark matter candidates with mass around 1 GeV, or below, and cross-section with nucleons smaller than $10^{-40}$ cm$^2$. The detector consists of a stack of diced silicon wafers, acting as arrays of particle absorbers, sensed by multiplexed Kinetic Inductance Detectors. The target will amount to 800 g subdivided in more than 2000 silicon dice, with the aim of controlling the background from natural radioactivity by creating a fully active structure and by applying fiducialization techniques. In this work we present the projected sensitivity of BULLKID-DM to light WIMP-like particles considering also the other future experiments in the field."
  },
  {
    "date": "2026-01-20",
    "title": "ChauBoxplot and AdaptiveBoxplot: two R packages for boxplot-based outlier detection",
    "authors": "Tiejun Tong, Hongmei Lin, Bowen Gang, Riquan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13759v1",
    "source": "arXiv",
    "abstract": "Tukey's boxplot is widely used for outlier detection; however, its classic fixed-fence rule tends to flag an excessive number of outliers as the sample size grows. To address this limitation, we introduce two new R packages, ChauBoxplot and AdaptiveBoxplot, which implement more robust methods for outlier detection. We also provide practical guidance, drawn from simulation results, to help practitioners choose suitable boxplot methods and balance interpretability with statistical reliability."
  },
  {
    "date": "2026-01-20",
    "title": "Stabilizer-Assisted Inactivation Decoding of Quantum Error-Correcting Codes with Erasures",
    "authors": "Giulio Pech, Mert Gökduman, Hanwen Yao, Henry D. Pfister",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14236v1",
    "source": "arXiv",
    "abstract": "In this work, we develop a reduced complexity maximum likelihood (ML) decoder for quantum low-density parity-check (QLDPC) codes over erasures. Our decoder combines classical inactivation decoding, which integrates peeling with symbolic guessing, with a new dual peeling procedure. In the dual peeling stage, we perform row operations on the stabilizer matrix to efficiently reveal stabilizer generators and their linear combinations whose support lies entirely on the erased set. Each such stabilizer identified allows us to freely fix a bit in its support without affecting the logical state of the decoded result. This removes one degree of freedom that would otherwise require a symbolic guess, reducing the number of inactivated variables and decreasing the size of the final linear system that must be solved. We further show that dual peeling combined with standard peeling alone, without inactivation, is sufficient to achieve ML for erasure decoding of surface codes. Simulations across several QLDPC code families confirm that our decoder matches ML logical failure performance while significantly reducing the complexity of inactivation decoding, including more than a 20% reduction in symbolic guesses for the B1 lifted product code at high erasure rates."
  },
  {
    "date": "2026-01-20",
    "title": "Second Order Asymptotics for the Hard Wall Probability of the 2D Harmonic Crystal",
    "authors": "Maximilian Fels, Oren Louidor, Tianqi Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13738v1",
    "source": "arXiv",
    "abstract": "We estimate the probability that the discrete Gaussian free field on a planar domain with Dirichlet boundary conditions stays positive in the bulk. Improving upon the result by Bolthausen, Deuschel and Giacomin from 2001, we derive the order of the subleading term of this probability when a sequence of discretized scale-ups of given domain and compactly included smooth bulk are considered. A main ingredient in the proof is the double exponential decay of the right tail of the centered minimum of the field in the bulk, conditioned on a certain weighted average of its values to be zero."
  },
  {
    "date": "2026-01-20",
    "title": "Entanglement entropy and disorder operator at kagome deconfined quantum criticality",
    "authors": "Yan-Cheng Wang, Yan Zheng, Xue-Feng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13774v1",
    "source": "arXiv",
    "abstract": "We investigate the deconfined quantum critical point (DQCP) candidate in the extended hard-core Bose-Hubbard model on the kagome lattice, employing quantum Monte Carlo simulations to study the entanglement entropy and the $U(1)$ disorder operator. In stark contrast to findings in $J$-$Q$ models and other candidates, the universal logarithmic correction coefficients for both quantities are found to be {positive}, consistent with a unitary conformal field theory (CFT). Crucially, the current central charge $C_J$, extracted from the small-angle behavior of the disorder operator, is enhanced by a factor of approximately {4/3} compared to that of the conventional 3D $O(2)$ Wilson-Fisher fixed point. This enhancement {implies} a consistent explanation in the recently observed low-energy excitation spectrum at this DQCP, which features {two distinct linearly dispersing modes} with a velocity ratio of approximately three. Our results provide evidence that this quantum phase transition constitutes a genuine DQCP, characterized by coexisting fractionalized excitations that collectively modify its critical properties."
  },
  {
    "date": "2026-01-20",
    "title": "Generative Adversarial Networks for Resource State Generation",
    "authors": "Shahbaz Shaik, Sourav Chatterjee, Sayantan Pramanik, Indranil Chakrabarty",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13708v1",
    "source": "arXiv",
    "abstract": "We introduce a physics-informed Generative Adversarial Network framework that recasts quantum resource-state generation as an inverse-design task. By embedding task-specific utility functions into training, the model learns to generate valid two-qubit states optimized for teleportation and entanglement broadcasting. Comparing decomposition-based and direct-generation architectures reveals that structural enforcement of Hermiticity, trace-one, and positivity yields higher fidelity and training stability than loss-only approaches. The framework reproduces theoretical resource boundaries for Werner-like and Bell-diagonal states with fidelities exceeding ~98%, establishing adversarial learning as a lightweight yet effective method for constraint-driven quantum-state discovery. This approach provides a scalable foundation for automated design of tailored quantum resources for information-processing applications, exemplified with teleportation and broadcasting of entanglement, and it opens up the possibility of using such states in efficient quantum network design."
  },
  {
    "date": "2026-01-20",
    "title": "Dean's conjecture and cycles modulo k",
    "authors": "Yufan Luo, Jie Ma, Ziyuan Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13552v1",
    "source": "arXiv",
    "abstract": "Dean conjectured three decades ago that every graph with minimum degree at least $k\\ge 3$ contains a cycle whose length is divisible by $k$. While the conjecture has been verified for $k\\in \\{3,4\\}$, it remains open for $k\\ge 5$. A weaker version, also proposed by Dean, asserting that every $k$-connected graph contains a cycle of length divisible by $k$, was resolved by Gao, Huo, Liu, and Ma using the notion of admissible cycles. In this paper, we resolve Dean's conjecture for all $k\\ge 6$. In fact, we prove a stronger result by showing that every graph with minimum degree at least $k$ contains cycles of length $r \\pmod k$ for every even integer $r$, unless every end-block belongs to a specific family of exceptional graphs, which fail only to contain cycles of length $2 \\pmod k$. We also establish a strengthened result on the existence of admissible cycles. Our proof introduces two sparse graph families, called trigonal graphs and tetragonal graphs, which provide a flexible framework for studying path and cycle lengths and may be of independent interest."
  },
  {
    "date": "2026-01-20",
    "title": "KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning",
    "authors": "Egor Cherepanov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14232v1",
    "source": "arXiv",
    "abstract": "Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Building on this environment, we define KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, we observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. Several shifts preserve forward motion while breaking task completion, showing that return alone can obscure generalization failures. Finally, the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors. Code: https://avanturist322.github.io/KAGEBench/."
  },
  {
    "date": "2026-01-20",
    "title": "Tropical Methods for Counting Plane Curves -- Complex, Real and Quadratically Enriched",
    "authors": "Andrés Jaramillo Puentes, Hannah Markwig, Sabrina Pauli, Felix Röhrle",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14216v1",
    "source": "arXiv",
    "abstract": "Since the first famous correspondence theorem by Mikhalkin appeared in 2005, tropical geometry has allowed a parallel treatment of real and complex counting problems. A prime example are the genus 0 Gromov-Witten invariants of the plane which count rational plane curves of degree d satisfying point conditions and their real counterpart, the Welschinger invariants, which both can be determined using tropical methods. Remarkably, the tropical computation of the two types of invariants works entirely in parallel. Recently, quadratically enriched enumerative geometry enables us to combine such real and complex counts under one roof, providing a simultaneous approach which can also be used for counts over other fields. Tropical geometry is a successful tool for the study and computation of such quadratically enriched enumerative invariants, too. In this survey, we provide an overview of tropical methods for plane curve counting problems over the real and complex numbers, and the new quadratically enriched counts."
  },
  {
    "date": "2026-01-20",
    "title": "Software Testing in the Quantum World",
    "authors": "Rui Abreu, Shaukat Ali, Paolo Arcaini, Jose Campos, Michael Felderer, Claude Gravel, Fuyuki Ishikawa, Stefan Klikovits, Andriy Miranskyy, Mohammad Mousavi, Masaomi Yamaguchi, Lei Zhang, Jianjun Zhao, Anila Mjeda",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13996v1",
    "source": "arXiv",
    "abstract": "Quantum computing offers significant speedups for simulating physical, chemical, and biological systems, and for optimization and machine learning. As quantum software grows in complexity, the classical simulation of quantum computers, which has long been essential for quality assurance, becomes infeasible. This shift requires new quality-assurance methods that operate directly on real quantum computers. This paper presents the key challenges in testing large-scale quantum software and offers software engineering perspectives for addressing them."
  },
  {
    "date": "2026-01-20",
    "title": "Instant Preliminary Cardiac Analysis from Smartphone Auscultation: A Real-World Canine Heart Sound Dataset and Evaluation",
    "authors": "Aswin Jose, Roeland P. J. E. Decorte, Laurent Locquet",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13593v1",
    "source": "arXiv",
    "abstract": "This study presents a real-world canine heart sound dataset and evaluates SoNUS version 3.2.x, a machine learning algorithm for preliminary cardiac analysis using smartphone microphone recordings. More than one hundred recordings were collected from dogs across four continents, with thirty eight recordings annotated by board certified veterinary cardiologists for quantitative evaluation. SoNUS version 3.2.x employs a multi-stage fallback architecture with quality-aware filtering to ensure reliable output under variable recording conditions. The primary sixty second model achieved mean and median heart rate accuracies of ninety one point six three percent and ninety four point nine five percent, while a fast model optimized for thirty to forty second recordings achieved mean and median accuracies of eighty eight point eight six percent and ninety two point nine eight percent. These results demonstrate the feasibility of extracting clinically relevant cardiac information from opportunistic smartphone recordings, supporting scalable preliminary assessment and telehealth applications in veterinary cardiology."
  },
  {
    "date": "2026-01-20",
    "title": "Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments",
    "authors": "Hao Jing, Sa Xiao, Haoyu Li, Huadong Xiao, Wei Xue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13592v1",
    "source": "arXiv",
    "abstract": "Radiation is typically the most time-consuming physical process in numerical models. One solution is to use machine learning methods to simulate the radiation process to improve computational efficiency. From an operational standpoint, this study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, with a specific focus on two fundamental bottlenecks: coupling compatibility and long-term integration stability. A residual convolutional neural network is employed to approximate the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. We adopted an offline training and online coupling approach. First, a comprehensive dataset is generated through model simulations, encompassing all atmospheric columns both with and without cloud cover. To ensure the stability of the hybrid model, the dataset is enhanced via experience replay, and additional output constraints based on physical significance are imposed. Meanwhile, a LibTorch-based coupling method is utilized, which is more suitable for real-time operational computations. The hybrid model is capable of performing ten-day integrated forecasts as required. A two-month operational reforecast experiment demonstrates that the machine learning emulator achieves accuracy comparable to that of the traditional physical scheme, while accelerating the computation speed by approximately eightfold."
  },
  {
    "date": "2026-01-20",
    "title": "DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems",
    "authors": "Maojun Sun, Yifei Xie, Yue Wu, Ruijian Han, Binyan Jiang, Defeng Sun, Yancheng Yuan, Jian Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13591v1",
    "source": "arXiv",
    "abstract": "Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents."
  },
  {
    "date": "2026-01-20",
    "title": "Dynamical Origin of (469219) Kamo`oalewa of Tianwen-2 Mission from the Main-Belt: $ν_6$ Secular Resonance, Flora Family or 3:1 Resonance with Jupiter",
    "authors": "Yandong Wang, Shoucun Hu, Jianghui Ji, Jiajun Ying",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13585v1",
    "source": "arXiv",
    "abstract": "China's Tianwen-2 mission, launched on 29 May 2025, targets the near-Earth object (469219) Kamo`oalewa, an Earth quasi-satellite trapped in a 1:1 mean-motion resonance with our planet. Determining the origin of Kamo`oalewa is central to understanding the formation pathways and dynamical evolution of Earth's quasi-satellite population. Here we show a strong possibility of main-belt origin for Kamo`oalewa using long-term dynamical simulations. We examine three candidate source regions: the $ν_6$ secular resonance ($ν_6$), the 3:1 mean-motion resonance with Jupiter (3:1J MMR), and the Flora family. A total of 42,825 test particles were integrated over 100 Myr. We find that asteroids from all three regions can be transported onto Kamo`oalewa-like orbits, albeit with markedly different efficiencies. Particles originating near the $ν_6$ show the highest transfer probability (3.31%), followed by the Flora family (2.54%) and the 3:1J MMR (0.39%). We further identify representative dynamical pathways linking these source regions to Earth quasi-satellite orbits. The Tianwen-2 spacecraft is expected to rendezvous with Kamo`oalewa in 2026, performing close-proximity operations and returning samples. The mission will provide decisive observational constraints on the asteroid's composition and physical properties, offering a critical test of its proposed origin."
  },
  {
    "date": "2026-01-20",
    "title": "Nonlinear fractional-periodic boundary value problems with Hilfer fractional derivative: existence and numerical approximations of solutions",
    "authors": "Niels Goedegebure, Kateryna Marynets",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13584v1",
    "source": "arXiv",
    "abstract": "We prove conditions for existence of analytical solutions for boundary value problems with the Hilfer fractional derivative, generalizing the commonly used Riemann-Liouville and Caputo operators. The boundary values, referred to in this paper as fractional-periodic, are fractional integral conditions generalizing recurrent solution values for the non-Caputo case of the Hilfer fractional derivative. Analytical solutions to the studied problem are obtained using a perturbation of the corresponding initial value problem with enforced boundary conditions. In general, solutions to the boundary value problem are singular for $t\\downarrow 0$. To overcome this singularity, we construct a sequence of converging solutions in a weighted continuous function space. We present a Bernstein splines-based implementation to numerically approximate solutions. We prove convergence of the numerical method, providing convergence criteria and asymptotic convergence rates. Numerical examples show empirical convergence results corresponding with the theoretical bounds. Moreover, the method is able to approximate the singular behavior of solutions and is demonstrated to converge for nonlinear problems. Finally, we apply a grid search to obtain correspondence to the original, non-perturbed system."
  },
  {
    "date": "2026-01-20",
    "title": "Revealing mesoscale bubble and particle dynamics in ultrasound-driven multiphase fluids by ultrafast synchrotron X-ray radiography and hybrid modelling",
    "authors": "Ling Qin, Kang Xiang, Iakovos Tzanakis, Dmitry Eskin, Samuel Clark, Kamel Fezzaa, Jiawei Mi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13582v1",
    "source": "arXiv",
    "abstract": "Multiphase fluid flows comprising of mesoscale solid particles, liquid droplets, or gas bubbles are common in both natural and man-made systems, but quantifying the energy transfer is challenging due to complex bubble-particle interactions. In this study, we used ultrafast synchrotron X-ray imaging to study the mesoscale dynamic interactions among ultrasonic cavitation bubbles and hydrophobic particles or clusters. Critical dynamic information and data were extracted from the vast amount of X-ray images and then fed into the hybrid analytical-numerical model for calculating the energy transfer from the oscillating bubble and the imploding bubble to the nearby hydrophobic particles. Using the Ni spherical microparticles as an example, at bubble oscillation approximately 16% (80-320 nJ) of the local energy was transferred to the particle. At bubble implosion, the transferred energy increased approximately 26% (0.135-1.09 uJ). Local energy transfer occurred on timescales of 1 us to 1 ms and length scales of 1 um to 1 mm. Within each ultrasound cycle, kinetic and potential energy underwent complex exchanges, with local energy exhibiting a stepwise decay at the end of each cycle. The transferred energy was mainly consumed for enabling highly efficient particle dispersion. This research provides quantitative insights into optimizing hydrophobic nanomaterial dispersion and has broader implications for interfacial energy transfer processes such as making suspensions, composite materials and exfoliated 2D materials."
  },
  {
    "date": "2026-01-20",
    "title": "Highly Deformable Proprioceptive Membrane for Real-Time 3D Shape Reconstruction",
    "authors": "Guanyu Xu, Jiaqi Wang, Dezhong Tong, Xiaonan Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13574v1",
    "source": "arXiv",
    "abstract": "Reconstructing the three-dimensional (3D) geometry of object surfaces is essential for robot perception, yet vision-based approaches are generally unreliable under low illumination or occlusion. This limitation motivates the design of a proprioceptive membrane that conforms to the surface of interest and infers 3D geometry by reconstructing its own deformation. Conventional shape-aware membranes typically rely on resistive, capacitive, or magneto-sensitive mechanisms. However, these methods often encounter challenges such as structural complexity, limited compliance during large-scale deformation, and susceptibility to electromagnetic interference. This work presents a soft, flexible, and stretchable proprioceptive silicone membrane based on optical waveguide sensing. The membrane sensor integrates edge-mounted LEDs and centrally distributed photodiodes (PDs), interconnected via liquid-metal traces embedded within a multilayer elastomeric composite. Rich deformation-dependent light intensity signals are decoded by a data-driven model to recover the membrane geometry as a 3D point cloud. On a customized 140 mm square membrane, real-time reconstruction of large-scale out-of-plane deformation is achieved at 90 Hz with an average reconstruction error of 1.3 mm, measured by Chamfer distance, while maintaining accuracy for indentations up to 25 mm. The proposed framework provides a scalable, robust, and low-profile solution for global shape perception in deformable robotic systems."
  },
  {
    "date": "2026-01-20",
    "title": "TRGCN: A Hybrid Framework for Social Network Rumor Detection",
    "authors": "Yanqin Yan, Suiyu Zhang, Dingguo Yu, Yijie Zhou, Cheng-Jun Wang, Ke-ke Shang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13573v1",
    "source": "arXiv",
    "abstract": "Accurate and efficient rumor detection is critical for information governance, particularly in the context of the rapid spread of misinformation on social networks. Traditional rumor detection relied primarily on manual analysis. With the continuous advancement of technology, machine learning and deep learning approaches for rumor identification have gradually emerged and gained prominence. However, previous approaches often struggle to simultaneously capture both the sequential and the global structural relationships among topological nodes within a social network. To tackle this issue, we introduce a hybrid model for detecting rumors that integrates a Graph Convolutional Network (GCN) with a Transformer architecture, aiming to leverage the complementary strengths of structural and semantic feature extraction. Positional encoding helps preserve the sequential order of these nodes within the propagation structure. The use of Multi-head attention mechanisms enables the model to capture features across diverse representational subspaces, thereby enhancing both the richness and depth of text comprehension. This integration allows the framework to concurrently identify the key propagation network of rumors, the textual content, the long-range dependencies, and the sequence among propagation nodes. Experimental evaluations on publicly available datasets, including Twitter 15 and Twitter 16, demonstrate that our proposed fusion model significantly outperforms both standalone models and existing mainstream methods in terms of accuracy. These results validate the effectiveness and superiority of our approach for the rumor detection task."
  },
  {
    "date": "2026-01-20",
    "title": "On the real part of elastic scattering amplitude",
    "authors": "S. M. Troshin, N. E. Tyurin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13543v1",
    "source": "arXiv",
    "abstract": "We discuss dominance of imaginary part of the elastic scattering amplitude and argue in favor of approximation based on this dominance."
  },
  {
    "date": "2026-01-20",
    "title": "LongSpeech: A Scalable Benchmark for Transcription, Translation and Understanding in Long Speech",
    "authors": "Fei Yang, Xuanfan Ni, Renyi Yang, Jiahui Geng, Qing Li, Chenyang Lyu, Yichao Du, Longyue Wang, Weihua Luo, Kaifu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13539v1",
    "source": "arXiv",
    "abstract": "Recent advances in audio-language models have demonstrated remarkable success on short, segment-level speech tasks. However, real-world applications such as meeting transcription, spoken document understanding, and conversational analysis require robust models capable of processing and reasoning over long-form audio. In this work, we present LongSpeech, a large-scale and scalable benchmark specifically designed to evaluate and advance the capabilities of speech models on long-duration audio. LongSpeech comprises over 100,000 speech segments, each approximately 10 minutes long, with rich annotations for ASR, speech translation, summarization, language detection, speaker counting, content separation, and question answering. We introduce a reproducible pipeline for constructing long-form speech benchmarks from diverse sources, enabling future extensions. Our initial experiments with state-of-the-art models reveal significant performance gaps, with models often specializing in one task at the expense of others and struggling with higher-level reasoning. These findings underscore the challenging nature of our benchmark. Our benchmark will be made publicly available to the research community."
  },
  {
    "date": "2026-01-20",
    "title": "When Wording Steers the Evaluation: Framing Bias in LLM judges",
    "authors": "Yerin Hwang, Dongryeol Lee, Taegwan Kang, Minwoo Lee, Kyomin Jung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13537v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols."
  },
  {
    "date": "2026-01-20",
    "title": "Hybrid Epitaxial Al/InGaAs system: Solid-state dewetting and Al facet formation",
    "authors": "A. Elbaroudy, N. Shaw, Sandra J. Gibson, B. D. Moreno, F. Sfigakis, J. Baugh, Z. R. Wasilewski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13523v1",
    "source": "arXiv",
    "abstract": "Hybrid superconductor--semiconductor platforms can host subgap electronic excitations such as Andreev bound states (ABSs); in topological regimes, a special zero-energy class, Majorana bound states (MBSs), can emerge. Here we report the growth of epitaxial Al films by molecular-beam epitaxy on $\\mathrm{In_{0.75}Ga_{0.25}As}$ under near-room-temperature substrate conditions. Using a combination of AFM/SEM, cross-sectional TEM, and \\emph{in situ} RHEED, we map how substrate temperature and Al deposition rate govern film morphology, continuity, and interface quality. We identify a growth window that yields continuous, superconducting Al films with an abrupt $\\mathrm{Al}/\\mathrm{In_{0.75}Ga_{0.25}As}$ interface and no detectable indium interdiffusion. We further investigate the thermal stability of these films under \\emph{in situ} post-growth heating and \\emph{ex situ} annealing following surface oxidation. For unoxidized Al, rapid surface diffusion triggers solid-state dewetting at approximately $165\\,^\\circ\\mathrm{C}$, resulting in the formation of $\\{111\\}$-faceted Al islands. In contrast, the presence of a native oxide largely suppresses dewetting, with failure occurring only locally at surface defects. Annealing above the indium melting point ($156.6\\,^\\circ\\mathrm{C}$) induces significant In surface migration in both cases, leading either to localized interfacial In inclusions beneath Al agglomerates or to uniform surface contamination at sites of localized layer breakdown. Together, these results define growth and annealing conditions for thermally robust epitaxial Al on III--V semiconductors and provide practical guidance for fabricating high-quality superconductor--semiconductor hybrid platforms for quantum devices."
  },
  {
    "date": "2026-01-20",
    "title": "Sticky Help, Bounded Effects: Session-by-Session Analytics of Teacher Interventions in K-12 Classrooms",
    "authors": "Qiao Jin, Conrad Borchers, Ashish Gurung, Sean Jackson, Sameeksha Agarwal, Cancan Wang, YiChen Yu, Pragati Maheshwary, Vincent Aleven",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13520v1",
    "source": "arXiv",
    "abstract": "Teachers' in-the-moment support is a limited resource in technology-supported classrooms, and teachers must decide whom to help and when during ongoing student work. However, less is known about how students' prior help history (whether they were helped earlier) and their engagement states (e.g., idle, struggle) shape teachers' decisions, and whether observed learning benefits associated with teacher help extend beyond the current class session. To address these questions, we first conducted interviews with nine K-12 mathematics teachers to identify candidate decision factors for teacher help. We then analyzed 1.4 million student-system interactions from 339 students across 14 classes in the MATHia intelligent tutoring system by linking teacher-logged help events with fine-grained engagement states. Mixed-effects models show that students who received help earlier were more likely to receive additional help later, even after accounting for current engagement state. Cross-lagged panel analyses further show that teacher help recurred across sessions, whereas idle behavior did not receive sustained attention over time. Finally, help coincided with immediate learning within sessions, but did not predict skill acquisition in later sessions, as estimated by additive factor modeling. These findings suggest that teacher help is \"sticky\" in that it recurs for previously supported students, while its measurable learning benefits in our data are largely session-bound. We discuss implications for designing real-time analytics that track attention coverage and highlight under-visited students to support a more equitable and effective allocation of teacher attention."
  },
  {
    "date": "2026-01-20",
    "title": "AgenticRed: Optimizing Agentic Systems for Automated Red-teaming",
    "authors": "Jiayi Yuan, Jonathan Nöther, Natasha Jaques, Goran Radanović",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13518v1",
    "source": "arXiv",
    "abstract": "While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models."
  },
  {
    "date": "2026-01-20",
    "title": "Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests",
    "authors": "Hanlin Zhou, Huah Yong Chan, Jingfei Ni, Mengchun Wu, Qing Deng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13515v1",
    "source": "arXiv",
    "abstract": "In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments."
  },
  {
    "date": "2026-01-20",
    "title": "Real-time visualization of plasmonic nanoparticle growth dynamics by high-speed atomic force microscopy",
    "authors": "Fuma Wakabayashi, Kenta Tamaki, Feng-Yueh Chan, Takayuki Uchihashi, Prabhat Verma, Takayuki Umakoshi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13512v1",
    "source": "arXiv",
    "abstract": "Plasmonic nanoparticles generate strongly localized and enhanced light field through localized surface plasmon resonance, thereby playing a central role in plasmonics and nanophotonics. Because the optical properties of plasmonic nanoparticles are highly sensitive to their size and shape, nanoscale visualization of nanoparticle growth is crucial for detailed understanding of growth mechanisms and precise control of particle geometry. However, it is not possible to visualize the rapid growth dynamics using conventional imaging techniques. In this study, we demonstrate in-situ real-time observation of silver nanoparticle (AgNP) growth dynamics at the single-particle level using high-speed atomic force microscopy (HS-AFM). We employed a photoreduction method, which enables reliable control of AgNP formation by laser irradiation. By integrating a stand-alone tip-scan HS-AFM with an optical setup for photoreduction, we successfully captured real-time movies showing the nucleation and subsequent growth of AgNPs at the single-particle level. Furthermore, quantitative single-particle analysis revealed particle-to-particle variations in growth dynamics. The growth dynamics were further studied at different laser intensities, revealing intensity-dependent growth rates and the balance between nucleation and growth. This study establishes HS-AFM as a novel microscopic platform for in-situ visualization of plasmonic nanoparticle growth and will contribute to advances in plasmonics and materials science."
  },
  {
    "date": "2026-01-20",
    "title": "Probing Fermi-surface spin-textures via the nonlinear Shubnikov-de Haas effect",
    "authors": "Kazuki Nakazawa, Henry F. Legg, Renato M. A. Dantas, Jelena Klinovaja, Daniel Loss",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13510v1",
    "source": "arXiv",
    "abstract": "The coupling of spin and electronic degrees of freedom via the spin-orbit interaction (SOI) is an essential ingredient for many proposed future technologies. However, probing the strength and nature of SOI is a significant challenge, especially in heterostructures. Here, we consider the nonlinear Shubnikov-de Haas (NSdH) effect, a quantum oscillatory effect that occurs under conditions similar to those of the well-known SdH effect, but is second order in the applied electric field. We demonstrate that, unlike its linear counterpart, the NSdH effect is highly sensitive to the spin textures that arise from SOI. In particular, we show that the phase and beating of NSdH oscillations in nonlinear conductivities can clearly distinguish between different types of SOI. As a demonstration, we show how NSdH can distinguish between the linear and cubic Rashba couplings that are expected in germanium heterostructures. Our results establish the NSdH effect as a powerful and sensitive probe of SOI, offering a new framework for characterizing materials relevant to topology, spintronics, and solid-state quantum information technologies."
  },
  {
    "date": "2026-01-20",
    "title": "Modeling Age-Adjusted Mortality in the United States",
    "authors": "Brandon Dunbar, Paramahansa Pramanik, Haley Kate Robinson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13504v1",
    "source": "arXiv",
    "abstract": "This research explores how total mortality figures relate to age-standardized death rates within the United States, using the complete historical record of national mortality statistics. Through a detailed investigation of both all-cause and cause-specific mortality trends, the study evaluates the impact of demographic standardization on interpreting mortality data across different time periods and geographic regions. Results indicate a robust and persistent association between crude death totals and age-adjusted rates. However, the findings also demonstrate that without adjusting for age, comparisons over time or across locations may misrepresent underlying epidemiological shifts, largely due to evolving population age structures. The study underscores the critical role of age adjustment as a methodological tool for generating accurate, interpretable, and comparable measures of public health outcomes."
  },
  {
    "date": "2026-01-20",
    "title": "A note on \"Higher order linear differential equations for unitary matrix integrals: applications and generalisations\"",
    "authors": "Peter J. Forrester, Fei Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13488v1",
    "source": "arXiv",
    "abstract": "In this note, we briefly introduce the background and motivation of the collaborative work [arXiv:2508.20797], and provide an outline of the main results. The latter relates to matrix and higher order scalar differential equations satisfied by certain Hankel and Toeplitz determinants involving I-Bessel functions, or equivalently certain unitary matrix integrals, and moreover puts this property in a broader context. We also investigate large gaps between zeros of the derivatives of the Hardy $\\mathsf{Z}$-function, assuming the validity of a certain joint moments conjecture in random matrix theory."
  },
  {
    "date": "2026-01-20",
    "title": "Magnetic field morphological diagnostics with ALMA in the G327.29 protocluster: VGT versus dust polarization",
    "authors": "A. Koley, A. M. Stutz, A. Lazarian, Y. Hu, P. Sanhueza, P. Saha, R. H. Alvarez-Gutierrez, N. S. Sandoval-Garrido, N. Castro-Toledo, G. Bernal Mesina",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13473v1",
    "source": "arXiv",
    "abstract": "Magnetic fields and turbulence may play a key role in the evolution of protoclusters, influencing the formation of dense cores and stars. Here, we examine the morphology of the magnetic fields in the G327.29 protocluster using both the velocity gradient technique (VGT) extracted from molecular line emissions and linear polarization in the dust continuum emission. The VGT analysis is performed using four molecular tracers: DCN (3-2), C18O (2-1), HN13C (3-2), and H13CO+ (3-2) - which probe gas across different density regimes, observed with the ALMA 12 m array. Owing to its sensitivity to gas dynamics, a comparison between VGT and dust polarization provides a powerful probe of the evolutionary processes in massive star-forming regions. From our analysis we reveal a complex magnetic-field structure, shaped by the combined influence of turbulence and gravity. In addition, it also appears that there is a large-scale (beyond the core scale) gravitational infall from the surrounding medium on to the filament and the central densest region. Furthermore, we observe that cores are dominated by a mix of turbulence and gravity. Overall, this work presents, likely for the first time, the application of VGT to a massive protocluster, G327.29, using high-resolution ALMA observations."
  },
  {
    "date": "2026-01-20",
    "title": "VideoMaMa: Mask-Guided Video Matting via Generative Prior",
    "authors": "Sangbeom Lim, Seoung Wug Oh, Jiahui Huang, Heeji Yoon, Seungryong Kim, Joon-Young Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14255v1",
    "source": "arXiv",
    "abstract": "Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research."
  },
  {
    "date": "2026-01-20",
    "title": "Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis",
    "authors": "Hongyuan Chen, Xingyu Chen, Youjia Zhang, Zexiang Xu, Anpei Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14253v1",
    "source": "arXiv",
    "abstract": "We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/."
  },
  {
    "date": "2026-01-20",
    "title": "LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR",
    "authors": "Said Taghadouini, Adrien Cavaillès, Baptiste Aubertin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14251v1",
    "source": "arXiv",
    "abstract": "We present \\textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \\textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses."
  },
  {
    "date": "2026-01-20",
    "title": "Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment",
    "authors": "Yuming Yang, Mingyoung Lai, Wanxu Zhao, Xiaoran Fan, Zhiheng Xi, Mingqi Wu, Chiyue Huang, Jun Zhao, Haijun Lv, Jian Tong, Yunhua Zhou, Yicheng Zou, Qipeng Guo, Tao Gui, Qi Zhang, Xuanjing Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14249v1",
    "source": "arXiv",
    "abstract": "Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection."
  },
  {
    "date": "2026-01-20",
    "title": "LRC-DHVC: Towards Local Rate Control in Neural Video Compression",
    "authors": "Marc Windsheimer, Simon Deniffel, André Kaup",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14240v1",
    "source": "arXiv",
    "abstract": "Local rate control is a key enabler to generalize image and video compression for dedicated challenges, such as video coding for machines. While traditional hybrid video coding can easily adapt the local rate-distortion trade-off by changing the local quantization parameter, no such approach is currently available for learning-based video compression. In this paper, we propose LRC-DHVC, a hierarchical video compression network, which allows continuous local rate control on a pixel level to vary the spatial quality distribution within individual video frames. This is achieved by concatenating a quality map to the input frame and applying a weighted MSE loss which matches the pixelwise trade-off factors in the quality map. During training, the model sees a variety of quality maps due to a constrained-random generation. Our model is the first neural video compression network, which can continuously and spatially adapt to varying quality constraints. Due to the wide quality and bit rate range, a single set of network parameters is sufficient. Compared to single rate point networks, which scale linearly with the number of rate points, the memory requirements for our network parameters remain constant. The code and model are available at link-updated-upon-acceptance."
  },
  {
    "date": "2026-01-20",
    "title": "Transformer Architectures for Respiratory Sound Analysis and Multimodal Diagnosis",
    "authors": "Theodore Aptekarev, Vladimir Sokolovsky, Gregory Furman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14227v1",
    "source": "arXiv",
    "abstract": "Respiratory sound analysis is a crucial tool for screening asthma and other pulmonary pathologies, yet traditional auscultation remains subjective and experience-dependent. Our prior research established a CNN baseline using DenseNet201, which demonstrated high sensitivity in classifying respiratory sounds. In this work, we (i) adapt the Audio Spectrogram Transformer (AST) for respiratory sound analysis and (ii) evaluate a multimodal Vision-Language Model (VLM) that integrates spectrograms with structured patient metadata. AST is initialized from publicly available weights and fine-tuned on a medical dataset containing hundreds of recordings per diagnosis. The VLM experiment uses a compact Moondream-type model that processes spectrogram images alongside a structured text prompt (sex, age, recording site) to output a JSON-formatted diagnosis. Results indicate that AST achieves approximately 97% accuracy with an F1-score around 97% and ROC AUC of 0.98 for asthma detection, significantly outperforming both the internal CNN baseline and typical external benchmarks. The VLM reaches 86-87% accuracy, performing comparably to the CNN baseline while demonstrating the capability to integrate clinical context into the inference process. These results confirm the effectiveness of self-attention for acoustic screening and highlight the potential of multimodal architectures for holistic diagnostic tools."
  },
  {
    "date": "2026-01-20",
    "title": "Deep Learning Approaches to Quantum Error Mitigation",
    "authors": "Leonardo Placidi, Ifan Williams, Enrico Rinaldi, Daniel Mills, Cristina Cîrstoiu, Vanya Eccles, Ross Duncan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14226v1",
    "source": "arXiv",
    "abstract": "We present a systematic investigation of deep learning methods applied to quantum error mitigation of noisy output probability distributions from measured quantum circuits. We compare different architectures, from fully connected neural networks to transformers, and we test different design/training modalities, identifying sequence-to-sequence, attention-based models as the most effective on our datasets. These models consistently produce mitigated distributions that are closer to the ideal outputs when tested on both simulated and real device data obtained from IBM superconducting quantum processing units (QPU) up to five qubits. Across several different circuit depths, our approach outperforms other baseline error mitigation techniques. We perform a series of ablation studies to examine: how different input features (circuit, device properties, noisy output statistics) affect performance; cross-dataset generalization across circuit families; and transfer learning to a different IBM QPU. We observe that generalization performance across similar devices with the same architecture works effectively, without needing to fully retrain models."
  },
  {
    "date": "2026-01-20",
    "title": "Symmetry Testing in Time Series using Ordinal Patterns: A U-Statistic Approach",
    "authors": "Annika Betken, Giorgio Micali, Manuel Ruiz Marín",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14223v1",
    "source": "arXiv",
    "abstract": "We introduce a general framework for testing temporal symmetries in time series based on the distribution of ordinal patterns. While previous approaches have focused on specific forms of asymmetry, such as time reversal, our method provides a unified framework applicable to arbitrary symmetry tests. We establish asymptotic results for the resulting test statistics under a broad class of stationary processes. Comprehensive experiments on both synthetic and real data demonstrate that the proposed test achieves high sensitivity to structural asymmetries while remaining fully data-driven and computationally efficient."
  },
  {
    "date": "2026-01-20",
    "title": "Beyond Polarization: Opinion Mixing and Social Influence in Deliberation",
    "authors": "Mohak Goyal, Lodewijk Gelauff, Naman Gupta, Ashish Goel, Kamesh Munagala",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14221v1",
    "source": "arXiv",
    "abstract": "Deliberative processes are often discussed as increasing or decreasing polarization. This approach misses a different, and arguably more diagnostic, dimension of opinion change: whether deliberation reshuffles who agrees with whom, or simply moves everyone in parallel while preserving the pre-deliberation rank ordering. We introduce \\opinion mixing, measured by Kendall's rank correlation (τ) between pre- and post-deliberation responses, as a complement to variance-based polarization metrics. Across two large online deliberative polls spanning 32 countries (MCF-2022: n=6,342; MCF-2023: n=1,529), deliberation increases opinion mixing relative to survey-only controls: treatment groups exhibit lower rank correlation on (97%) and (93%) of opinion questions, respectively. Polarization measures based on variance tell a more heterogeneous story: controls consistently converge, while treated groups sometimes converge and sometimes diverge depending on the issue. To probe mechanisms, we link transcripts and surveys in a third event (SOF: (n=617), 116 groups) and use LLM-assisted coding of 6,232 discussion statements. Expressed support in discussion statements strongly predicts subsequent group-level opinion shifts; this correlation is amplified by justification quality in the statements but not by argument novelty. To our knowledge, we are the first to observe how different notions of argument quality have different associations with the outcome of deliberation. This suggests that opinion change after deliberation is related to selective uptake of well-reasoned arguments, producing complex patterns of opinion reorganization that standard polarization metrics may miss."
  },
  {
    "date": "2026-01-20",
    "title": "Bit-Efficient Quantisation for Two-Channel Modulo-Sampling Systems",
    "authors": "Wenyi Yan, Zeyuan Li, Lu Gan, Honqing Liu, Guoquan Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14220v1",
    "source": "arXiv",
    "abstract": "Two-channel modulo analog-to-digital converters (ADCs) enable high-dynamic-range signal sensing at the Nyquist rate per channel, but existing designs quantise both channel outputs independently, incurring redundant bitrate costs. This paper proposes a bit-efficient quantisation scheme that exploits the integer-valued structure of inter-channel differences, transmitting one quantised channel output together with a compact difference index. We prove that this approach requires only 1-2 bits per signal sample overhead relative to conventional ADCs, despite operating with a much smaller per-channel dynamic range. Simulations confirm the theoretical error bounds and bitrate analysis, while hardware experiments demonstrate substantial bitrate savings compared with existing modulo sampling schemes, while maintaining comparable reconstruction accuracy. These results highlight a practical path towards high-resolution, bandwidth-efficient modulo ADCs for bitrate-constrained systems."
  },
  {
    "date": "2026-01-20",
    "title": "Probing AGN duty cycle and cluster-driven morphology in a giant episodic radio galaxy",
    "authors": "Shobha Kumari, Sabyasachi Pal, Surajit Paul, Marek Jamrozy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14219v1",
    "source": "arXiv",
    "abstract": "The evolution of radio jet morphology and its energetics is significantly influenced by the environment in which the host galaxy resides. As giant radio galaxies (GRGs) often extend to the scale of entire galaxy clusters ($\\sim$Mpc) and beyond, they are a suitable class of objects for studying jet--intracluster medium interactions. This paper presents a multiwavelength study of a GRG, J1007+3540, using the LOFAR Two-metre Sky Survey second data release (LoTSS DR2) at 144 MHz and the upgraded Giant Metrewave Radio Telescope (uGMRT) at 400 MHz. The source has a projected linear extension of 1.45 Mpc and is hosted by MaxBCG J151.77665+35.67813, within the WHL 100706.4+354041 cluster. At both frequencies, the source exhibits clear signatures of recurrent jet activity, a one-sided, extended, tail-like diffuse structure with a morphological break in the tail. The estimated radiative ages of the inner lobes and outer north lobe are $\\sim$140 Myr and $\\sim$240 Myr, respectively. In addition to the radio analysis, we performed optical--to--infrared spectral energy distribution modelling. The host galaxy is an evolved elliptical system with a stellar mass of $\\log_{10}(M_\\star/M_\\odot) = 11.0$ and an old stellar population age of $\\sim$12 Gyr. The high infrared-derived star formation rate ($\\sim106~M_\\odot$~yr$^{-1}$) of the source implies significant dust-obscured star formation, potentially linked to merger-driven gas inflows. J1007+3540 presents a rare combination of a restarted jet, a detached tail-like structure, and unusual spectral flattening beyond the tail break, which is very rare to report together in a GRG. This rare and remarkable system offers a unique laboratory for probing the interplay between active galactic nucleus activity, star formation, and environmental effects in cluster-surrounded GRGs."
  },
  {
    "date": "2026-01-20",
    "title": "The PAIRS project: a global formation model for planets in binaries. II. Gravitational perturbation effects from secondary stars",
    "authors": "Arianna Nigioni, Julia Venturini, Emeline Bolmont, Diego Turrini, Yann Alibert, Alexandre Emsenhuber",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14215v1",
    "source": "arXiv",
    "abstract": "Roughly half of Sun-like stars have at least one stellar companion, whereas it is widely assumed that most known exoplanets orbit single stars, largely due to observational biases. However, astrometric surveys, direct imaging, and speckle interferometry are steadily increasing the number of confirmed exoplanets in binaries. A stellar companion introduces additional effects, such as circumstellar disk truncation and gravitational perturbations, which can strongly impact planet formation. While global planet formation models, for example the Bern model, have been broadly applied to single stars, modeling S-type binaries requires key modifications to capture these effects. This study extends the Bern model by incorporating the gravitational influence of a stellar companion into its N-body integrator, allowing us to quantify how this perturbation affects planetary formation and final system architecture across a range of binary configurations. By comparing binary and single-star systems under identical initial conditions, we can assess the specific impact of binary-induced dynamics. We ran three sets of simulations: (i) a grid of in situ single-embryo cases to quantify gravitational effects; (ii) formation simulations with and without migration to compare outcomes with single-star analogs; and (iii) multi-embryo runs to evaluate impacts on multi-planetary systems. Planets forming beyond half the host star's Hill radius are much more likely to become unbound especially in systems with high binary eccentricity. Even within stable zones, growth is suppressed by both reduced material availability and increased eccentricity from stellar perturbations. Both disk truncation and stellar perturbations must be included to model planet formation in S-type binaries accurately. Neglecting either one will end up misrepresenting planetary growth and survival."
  },
  {
    "date": "2026-01-20",
    "title": "The PAIRS project: a global formation model for planets in binaries. I. Effect of disc truncation on the growth of S-type planets",
    "authors": "Julia Venturini, Arianna Nigioni, Maria Paula Ronco, Natacha Jungo, Alexandre Emsenhuber",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14214v1",
    "source": "arXiv",
    "abstract": "Binary stars are as common as single stars. The number of detected planets orbiting binaries is rapidly increasing thanks to the synergy between transit surveys, Gaia and high-resolution direct imaging campaigns. However, global planet formation models around binary stars are still underdeveloped, which limits the theoretical understanding of planets orbiting binary star systems. Hereby we introduce the PAIRS project, which aims at building a global planet formation model for planets in binaries, and to produce planet populations synthesis to statistically compare theory and observations. In this first paper, we present the adaptation of the circumstellar disc to simulate the formation of S-type planets. The presence of a secondary star tidally truncates and heats the outer part of the circumprimary disc (and vice-versa for the circumsecondary disc), limiting the material to form planets. We implement and quantify this effect for a range of binary parameters by adapting the Bern Model of planet formation in its pebble-based form and for in-situ planet growth. We find that the disc truncation has a strong impact on reducing the pebble supply for core growth, steadily suppressing planet formation for binary separations below 160 au, when considering all the formed planets more massive than Mars. We find as well that S-type planets tend to form close to the central star with respect to the binary separation and disc truncation radius. Our newly developed model will be the basis of future S-type planet population synthesis studies."
  },
  {
    "date": "2026-01-20",
    "title": "Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting",
    "authors": "Nitin Kulkarni, Akhil Devarashetti, Charlie Cluss, Livio Forte, Dan Buckmaster, Philip Schneider, Chunming Qiao, Alina Vereshchaka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14208v1",
    "source": "arXiv",
    "abstract": "Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality."
  },
  {
    "date": "2026-01-20",
    "title": "Copy-Trasform-Paste: Zero-Shot Object-Object Alignment Guided by Vision-Language and Geometric Constraints",
    "authors": "Rotem Gatenyo, Ohad Fried",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14207v1",
    "source": "arXiv",
    "abstract": "We study zero-shot 3D alignment of two given meshes, using a text prompt describing their spatial relation -- an essential capability for content creation and scene assembly. Earlier approaches primarily rely on geometric alignment procedures, while recent work leverages pretrained 2D diffusion models to model language-conditioned object-object spatial relationships. In contrast, we directly optimize the relative pose at test time, updating translation, rotation, and isotropic scale with CLIP-driven gradients via a differentiable renderer, without training a new model. Our framework augments language supervision with geometry-aware objectives: a variant of soft-Iterative Closest Point (ICP) term to encourage surface attachment and a penetration loss to discourage interpenetration. A phased schedule strengthens contact constraints over time, and camera control concentrates the optimization on the interaction region. To enable evaluation, we curate a benchmark containing diverse categories and relations, and compare against baselines. Our method outperforms all alternatives, yielding semantically faithful and physically plausible alignments."
  },
  {
    "date": "2026-01-20",
    "title": "Sparse Statistical Modeling in Condensed Matter Physics",
    "authors": "J. McGee, S. V. Dordevic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14184v1",
    "source": "arXiv",
    "abstract": "In this work we explore the possibility of using sparse statistical modeling in condensed matter physics. The procedure is employed to two well known problems: elemental superconductors and heavy fermions, and was shown that in most cases performs better than other AI methods, such as machine or deep learning. More importantly, sparse modeling has two major advantages over other methods: the ability to deal with small data sets and in particular its interpretabilty. Namely, sparse modeling can provide insight into the calculation process and allow the users to give physical interpretation of their results. We argue that many other problems in condensed matter physics would benefit from these properties of sparse statistical modeling."
  },
  {
    "date": "2026-01-20",
    "title": "Faster grain-boundary diffusion with a higher activation enthalpy than bulk diffusion in ionic space-charge layers",
    "authors": "Timon F. Kielgas, Roger A. De Souza",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14181v1",
    "source": "arXiv",
    "abstract": "Faster diffusion of cations along grain boundaries is reported in the literature for a variety of acceptor-doped $AB\\mathrm{O}_{3}$ perovskite-type oxides. The ratio $r$ of the activation enthalpy of grain-boundary diffusion ($ΔH^\\mathrm{gb}$) to the activation enthalpy of bulk diffusion ($ΔH^\\mathrm{b}$) is seen experimentally to lie in the range $0.7 < r = ΔH^\\mathrm{gb} / ΔH^\\mathrm{b} < 1.3$, albeit with substantial errors. In a previous publication [Parras and De Souza, Acta Mater. 195 (2020) 383] it was shown through a set of continuum simulations that cation-vacancy accumulation within negative space-charge layers at grain boundaries in acceptor-doped perovskites will give rise to faster grain-boundary diffusion of cations, with the associated values of $r$ approaching but not exceeding unity. In the present study, we demonstrate by means of continuum simulations that under certain conditions $r > 1$ is achievable for faster cation diffusion along grain boundaries in an acceptor-doped perovskite ceramic. Diffusion profiles for a two-dimensional bicrystal geometry are obtained by solving, first, Poisson's equation, and subsequently, the diffusion equation. The specific case we consider is cation migration occurring by two related mechanisms, by isolated cation vacancies and by defect associates of cation and anion vacancies; the electric potential within the space-charge layers shifts the association equilibrium so that associate diffusion dominates in the bulk whereas isolated vacancy diffusion dominates within the space-charge layers. The conditions under which $r > 1$ is observed are described, and issues with experimental confirmation are discussed."
  },
  {
    "date": "2026-01-20",
    "title": "Caustics of finitely dense inertial particles",
    "authors": "C. Rajarshi, Rama Govindarajan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14179v1",
    "source": "arXiv",
    "abstract": "Estimating collision rates is of immense importance in particle-laden flows. An economical way of doing this is to directly identify incidences of caustics, or extreme clustering, by tracking particle velocity gradients in the neighborhoods of individual particles. The objective of this work is two-fold. (i) We find conditions under which caustics form, in point-vortex flow and in two-dimensional turbulence. While caustics are known to form in regions of strain, we show that the type of strain is key. Particles must remain in compressional strain throughout the process to form caustics, whereas survivor particles: which visit high strain but do not form caustics, briefly go through extensional strain during the early part of the process. This enables survivor particles to attain significantly straighter paths, and to move faster, whereas caustics particles follow paths of high curvature and move slower. As a result, caustics particles stay longer in high-strain regions than survivors. (ii) We ask about the effect of finite particle density, where the particle is denser than the background fluid. We show that finite-density particles need to sample stronger background strain than infinite-density ones to trigger caustics, but our other findings are universal across particle density."
  },
  {
    "date": "2026-01-20",
    "title": "Anomalous Tip-Sample Distance Behavior on the Tip-Enhanced Raman Spectroscopy of Graphene in Ambient Conditions",
    "authors": "André G. Pereira, Raul Corrêa, Bianca Carneiro, Cassiano Rabelo, Thiago L. Vasconcelos, Vitor Monken, Luiz Gustavo Cançado, Ado Jorio",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14178v1",
    "source": "arXiv",
    "abstract": "Tip-Enhanced Raman Spectroscopy (TERS) combines Raman spectroscopy with scanning probe microscopy to overcome the spatial resolution limitation imposed by light diffraction, offering a primary optical technique for the comprehensive study of two-dimensional (2D) materials. In this work, we investigate an anomalous decay profile of the TERS intensity of the graphene 2D band as the tip-sample separation changes, observations enabled by high TERS efficiency and accuracy in tip-approach and tip-retract procedures. The anomalous results can be properly described by the addition of an ad hoc deformation to the effective tip-sample distance, rationalized here as due to the presence of a liquid meniscus formed via capillary forces."
  },
  {
    "date": "2026-01-20",
    "title": "Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance",
    "authors": "Qianli Ma, Chang Guo, Zhiheng Tian, Siyu Wang, Jipeng Xiao, Yuanhao Yue, Zhipeng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14171v1",
    "source": "arXiv",
    "abstract": "Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released."
  },
  {
    "date": "2026-01-20",
    "title": "Heights on toric varieties for singular metrics: Local theory",
    "authors": "Gari Y. Peralta Alvarez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14167v1",
    "source": "arXiv",
    "abstract": "We show that the (toric) local height of a toric variety with respect to a semipositive torus-invariant singular metric is given by the integral of a concave function over a compact convex set. This generalizes a result of Burgos, Philippon, and Sombra for the case of continuous metrics and answers a question raised by Burgos, Kramer, and Kühn in 2016."
  },
  {
    "date": "2026-01-20",
    "title": "A multi-wavelength study of the 2025 low state of the intermediate polar BG CMi",
    "authors": "A. W. Shaw, K. Mukai, C. O. Heinke, C. G. Nixon, D. A. H. Buckley, P. A. Dubovský, F. -J. Hambsch, J. Hilburn, K. Petrík, R. M. Plotkin, S. B. Potter, N. Rawat, T. Shahbaz, Sharif. Dufoer, S. Dvorak, D. Messier, G. Myers, P. Nelson, R. Sabo, J. Ulowetz, T. Vanmunster",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14156v1",
    "source": "arXiv",
    "abstract": "We present multi-wavelength observations of the first recorded low state of the intermediate polar BG CMi. Optical monitoring of the source by members of the American Association of Variable Star Observers reveals a decrease of ~0.5 mag that lasted ~50 d in early 2025. During the low state the optical timing properties imply that BG CMi underwent a change in the accretion mode, as power at the spin frequency $ω$ dramatically dropped. An XMM-Newton observation revealed a substantial decrease in intrinsic absorption and a slight increase in intrinsic X-ray luminosity, compared to archival Suzaku data. Timing analysis of the X-ray light curves shows that power shifted from the orbital frequency $Ω$ (prominent in Suzaku data) to $2Ω$ in the low state XMM-Newton data, along with the strengthening of certain orbital sidebands. We suggest that BG CMi transitioned to disk-overflow accretion, where the white dwarf accreted matter via both a disk and a stream, the latter becoming more dominant during the low state due to a decrease in the mass and size of the disk."
  },
  {
    "date": "2026-01-20",
    "title": "The Quest for Reliable AI Accelerators: Cross-Layer Evaluation and Design Optimization",
    "authors": "Meng Li, Tong Xie, Zuodong Zhang, Runsheng Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14148v1",
    "source": "arXiv",
    "abstract": "As the CMOS technology pushes to the nanoscale, aging effects and process variations have become increasingly pronounced, posing significant reliability challenges for AI accelerators. Traditional guardband-based design approaches, which rely on pessimistic timing margin, sacrifice significant performance and computational efficiency, rendering them inadequate for high-performance AI computing demands. Current reliability-aware AI accelerator design faces two core challenges: (1) the lack of systematic cross-layer analysis tools to capture coupling reliability effects across device, circuit, architecture, and application layers; and (2) the fundamental trade-off between conventional reliability optimization and computational efficiency. To address these challenges, this paper systematically presents a series of reliability-aware accelerator designs, encompassing (1) aging and variation-aware dynamic timing analyzer, (2) accelerator dataflow optimization using critical input pattern reduction, and (3) resilience characterization and novel architecture design for large language models (LLMs). By tightly integrating cross-layer reliability modeling and AI workload characteristics, these co-optimization approaches effectively achieve reliable and efficient AI acceleration."
  },
  {
    "date": "2026-01-20",
    "title": "Vector Coded Caching Multiplicatively Boosts MU-MIMO Systems Under Practical Considerations",
    "authors": "Hui Zhao, Petros Elia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14142v1",
    "source": "arXiv",
    "abstract": "This work presents a first comprehensive analysis of the impact of vector coded caching (VCC) in multi-user multiple-input multiple-output (MU-MIMO) systems with multiple receive antennas and variable pathloss -- two key factors that critically influence systems with inherent MU unicasting behavior. We investigate two widely adopted precoding strategies: (i) blockdiagonalization (BD) at the transmitter combined with maximal ratio combining (MRC) at the receivers, and (ii) zero-forcing (ZF) precoding. Our analysis explicitly accounts for practical considerations such as channel fading, channel state information (CSI) acquisition overhead, and fairness-oriented power allocation. Our contributions span both analytical and simulation-based fronts. On the analytical side, we derive analytical expressions for the achievable throughput under BD-MRC and ZF, highlighting the performance benefits of equipping multi-antenna users with cache-aided interference management. Specifically, we develop a low-complexity BD-MRC optimization method that leverages matrix structure to significantly reduce the dimensionality involved in precoding computation, followed by solving the associated maxmin fairness problem through an efficient one-dimensional search. In the massive MIMO regime, an asymptotic expression for the achievable throughput over Rayleigh fading channels is also derived. Simulations validate our theoretical results, confirming that VCC delivers substantial performance gains over optimized cacheless MU-MIMO systems. For example, with 32 transmit antennas and 2 receive antennas per user, VCC yields throughput improvements exceeding 300%. These gains are further amplified under imperfect CSI at the transmitter, where VCC's ability to offload interference mitigation to the receivers ensures robust performance even in the face of degraded CSI quality and elevated acquisition costs."
  },
  {
    "date": "2026-01-20",
    "title": "CREATE: Cross-Layer Resilience Characterization and Optimization for Efficient yet Reliable Embodied AI Systems",
    "authors": "Tong Xie, Yijiahao Qi, Jinqi Wen, Zishen Wan, Yanchi Dong, Zihao Wang, Shaofei Cai, Yitao Liang, Tianyu Jia, Yuan Wang, Runsheng Wang, Meng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14140v1",
    "source": "arXiv",
    "abstract": "Embodied Artificial Intelligence (AI) has recently attracted significant attention as it bridges AI with the physical world. Modern embodied AI systems often combine a Large Language Model (LLM)-based planner for high-level task planning and a reinforcement learning (RL)-based controller for low-level action generation, enabling embodied agents to tackle complex tasks in real-world environments. However, deploying embodied agents remains challenging due to their high computation requirements, especially for battery-powered local devices. Although techniques like lowering operating voltage can improve energy efficiency, they can introduce bit errors and result in task failures. In this work, we propose CREATE, a general design principle that leverages heterogeneous resilience at different layers for synergistic energy-reliability co-optimization. For the first time, we conduct a comprehensive error injection study on modern embodied AI systems and observe an inherent but heterogeneous fault tolerance. Building upon these insights, we develop an anomaly detection and clearance mechanism at the circuit level to eliminate outlier errors. At the model level, we propose a weight-rotation-enhanced planning algorithm to improve the fault tolerance of the LLM-based planner. Furthermore, we introduce an application-level technique, autonomy-adaptive voltage scaling, to dynamically adjust the operating voltage of the controllers. The voltage scaling circuit is co-designed to enable online voltage adjustment. Extensive experiments demonstrate that without compromising task quality, CREATE achieves 40.6% computational energy savings on average over nominal-voltage baselines and 35.0% over prior-art techniques. This further leads to 29.5% to 37.3% chip-level energy savings and approximately a 15% to 30% improvement in battery life."
  },
  {
    "date": "2026-01-20",
    "title": "Multi-Tongue Frequency Fractal Dynamics in Hodgkin-Huxley Neurons Induced by Temporal Interference Stimulation",
    "authors": "Madhurendra Mishra, Zhen Qi, Adarsh Ganesan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14135v1",
    "source": "arXiv",
    "abstract": "We investigate neuronal excitability in the Hodgkin-Huxley model under temporal interference (TI) stimulation in a previously unexplored sub-Hz resonant regime and uncover a striking nonlinear response that we term 'multi-tongue frequency fractals'. Unlike single-frequency driving, which yields a smooth resonant valley, dual-frequency excitation fragments this response into a hierarchy of sharply modulated tongues whose number and structure grow with observation time, revealing clear self-similar architecture. These features emerge from transitions between non-cascaded and cascaded high-harmonic and sub-harmonic generation as detuning varies, and are maximized near the intrinsic ionic timescale at omega ~ 0.2 rad/s. Parameter sweeps show that the fractal count is higher for higher potassium conductances, lower sodium conductances and lower leak conductances. These results demonstrate that TI stimulation can elicit rich, hierarchically organized frequency responses even in classical excitable membranes, revealing fractal organization in Hodgkin-Huxley dynamics."
  },
  {
    "date": "2026-01-20",
    "title": "$Q_p$-weighted zero-sum constants",
    "authors": "Krishnendu Paul, Shameek Paul",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14122v1",
    "source": "arXiv",
    "abstract": "A sequence $S=(x_1,\\ldots, x_k)$ in $\\mathbb Z_p$ is called a $(Q_p,\\mathbf 1)$-weighted zero-sum sequence if there exist $a_1,\\ldots,a_k\\in Q_p$ such that $a_1x_1+\\cdots+a_kx_k=0$ and $a_1+\\cdots+a_k=0$. The constant $E_{Q_p,\\mathbf 1}$ is defined to be the smallest positive integer $k$ such that every sequence of length $k$ in $\\mathbb Z_p$ has a $(Q_p,\\mathbf 1)$-weighted zero-sum subsequence of length $p$. We determine the constant $E_{Q_p,\\mathbf 1}$ and the related constants $C_{Q_p,\\mathbf 1}$ and $D_{Q_p,\\mathbf 1}$. We also study some $(Q_p,B)$-weighted zero-sum constants where $B$ is a subset of $Q_p$."
  },
  {
    "date": "2026-01-20",
    "title": "Angular pair-of-pants decompositions of complex varieties",
    "authors": "Yassine Elmaazouz, Paul Alexander Helminck",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14116v1",
    "source": "arXiv",
    "abstract": "We define the notion of torically hyperbolic varieties and we construct pair-of-pants decompositions for these in terms of angle sets of essential projective hyperplane complements. This construction generalizes the classical pair-of-pants decomposition for hyperbolic Riemann surfaces. In our first main theorem, we prove that the natural angle map associated to an essential projective hyperplane complement is a homotopy equivalence, extending earlier work of Salvetti and Björner-Ziegler. By a topological argument, we further show that the angle map for a finite Kummer covering of an essential projective hyperplane complement is likewise a homotopy equivalence. We then explain how these local building blocks can be glued along the dual intersection complex of a semistable degeneration. Using the theory of Kato-Nakayama spaces, we prove that the resulting space is homotopy equivalent to the original algebraic variety. We make this explicit for complete intersections in projective space using techniques from tropical geometry."
  },
  {
    "date": "2026-01-20",
    "title": "Adsorption-Driven Symmetry Lowering in Single Molecules Revealed by Ångstrom-scale Tip-Enhanced Raman Imaging",
    "authors": "Rodrigo Cezar de Campos Ferreira, Borja Cirera, Jiří Doležal, Álvaro Gallego de Roa, Amandeep Sagwal, Petr Kahan, Rubén Canales, Fernando Aguilar-Galindo, Martin Švec, Pablo Merino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14110v1",
    "source": "arXiv",
    "abstract": "The vibrational landscape of adsorbed molecules is central to understanding surface interactions at the atomic scale, influencing phenomena from catalysis to molecular electronics. Recent advances in atomic-scale tip-enhanced Raman spectroscopy (TERS) have enabled vibrational mapping of single molecules with sub-nanometer spatial resolution, providing unprecedented insights into molecule-surface interactions by confining light in plasmonic picocavities. Here, we exploit TERS in a cryogenic scanning tunneling microscope junction to perform Raman hyperspectral mapping of single iron phthalocyanine (FePc) molecules in three non-equivalent adsorption configurations on Ag surfaces. We explore the changes in the vibrational modes of FePc molecules adsorbed on two distinct silver crystal terminations with differing symmetry, Ag(111) and Ag(110), revealing how subtle variations in the adsorption geometry due to substrate anisotropy can strongly influence molecular vibrations, lifting the degeneracy of individual normal modes. Our findings not only demonstrate the first use of sub-nanometer TERS mapping across different symmetry configurations but also provide a deeper understanding of how site-specific vibrational properties are intimately linked to local atomic environments. This capability paves the way for precisely tailoring surface interactions and controlling chemical reactions at the atomic scale."
  },
  {
    "date": "2026-01-20",
    "title": "Nonlinear optical response as a probe of emergent Lorentz symmetry violation in noncentrosymmetric materials",
    "authors": "Guilherme J. Inacio, Nathanael N. Batista, Wesley Spalenza, Humberto Belich, Juan José Palacios, Wendel S. Paz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14100v1",
    "source": "arXiv",
    "abstract": "We propose an electrically controlled protocol to detect weak Lorentz-violating (LV) backgrounds through the second-order shift photocurrent in noncentrosymmetric crystals. Using a spinful Rice--Mele model, we show that a stationary LV background induces a momentum-odd correction to the Bloch Hamiltonian, which generates an odd-in-field contribution to the shift current. This leads to a directional asymmetry, whereby the photocurrent distinguishes opposite orientations of an applied static field. The effect originates from an LV-induced deformation of the interband phase and can be isolated experimentally by comparing field-reversed configurations, with vanishing response at transverse orientations, providing an internal consistency check. Our results demonstrate that nonlinear optical responses offer a practical and symmetry-selective route for probing LV effects in solid-state systems."
  },
  {
    "date": "2026-01-20",
    "title": "Hot Days, Unsafe Schools? The Impact of Heat on School Shootings",
    "authors": "Seunghyun Lee, Goeun Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14094v1",
    "source": "arXiv",
    "abstract": "Using data on school shooting incidents in U.S. K--12 schools from 1981 to 2022, we estimate the causal effects of high temperatures on school shootings and assess the implications of climate change. We find that days with maximum temperatures exceeding 90$^\\circ$F lead to a 80\\% increase in school shootings relative to days below 70$^\\circ$F. Consistent with theories linking heat exposure to aggression, high temperatures increase homicidal and threat-related shootings but have no effect on accidental or suicidal shootings. Heat-induced shootings occur disproportionately during periods of greater student mobility and reduced supervision, including before and after school hours and lunch periods. Higher temperatures increase shootings involving both student and non-student perpetrators. We project that climate change will increase homicidal and threat-related school shootings in the U.S. by 8\\% under SSP2--4.5 (moderate emissions) and by 14\\% under SSP5--8.5 (high emissions) by 2091--2100, corresponding to approximately 23 and 39 additional shootings per decade, respectively. The present discounted value of the resulting social costs is \\$343 million and \\$592 million (2025 dollars), respectively."
  },
  {
    "date": "2026-01-20",
    "title": "Studies of Hadron Spectroscopy at Belle and Belle II",
    "authors": "Martin Bartl",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14093v1",
    "source": "arXiv",
    "abstract": "The Belle and Belle II experiments have collected an 1.6 ab$^{-1}$ sample of $e^+e^-$ collision data at center-of-mass energies near the $Υ(nS)$ resonances. In particular, the Belle II experiment collected a 19.2 fb$^{-1}$ sample of data at center-of-mass energies near the $Υ(10753)$ resonance. We study the following processes: $e^+e^-\\to Υ(nS)η$, $e^+e^-\\to γX_b(χ_{bJ}π^+π^-)$, and $e^{+}e^{-}\\toχ_{bJ}(1P) γ$. These results provide additional information about the nature of the $Υ(10753)$ resonance and nearby structures. In addition, we measure the $B^{0}$ and $B^+$ meson mass difference, and $σ\\left(e^+ e^-\\to J/ψp\\bar{p}\\right)$ over a range of center-of-mass energies accessed via initial-state radiation."
  },
  {
    "date": "2026-01-20",
    "title": "Optimizing Energy and Data Collection in UAV-aided IoT Networks using Attention-based Multi-Objective Reinforcement Learning",
    "authors": "Babacar Toure, Dimitrios Tsilimantos, Omid Esrafilian, Marios Kountouris",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14092v1",
    "source": "arXiv",
    "abstract": "Due to their adaptability and mobility, Unmanned Aerial Vehicles (UAVs) are becoming increasingly essential for wireless network services, particularly for data harvesting tasks. In this context, Artificial Intelligence (AI)-based approaches have gained significant attention for addressing UAV path planning tasks in large and complex environments, bridging the gap with real-world deployments. However, many existing algorithms suffer from limited training data, which hampers their performance in highly dynamic environments. Moreover, they often overlook the inherently multi-objective nature of the task, treating it in an overly simplistic manner. To address these limitations, we propose an attention-based Multi-Objective Reinforcement Learning (MORL) architecture that explicitly handles the trade-off between data collection and energy consumption in urban environments, even without prior knowledge of wireless channel conditions. Our method develops a single model capable of adapting to varying trade-off preferences and dynamic scenario parameters without the need for fine-tuning or retraining. Extensive simulations show that our approach achieves substantial improvements in performance, model compactness, sample efficiency, and most importantly, generalization to previously unseen scenarios, outperforming existing RL solutions."
  },
  {
    "date": "2026-01-20",
    "title": "Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems",
    "authors": "Hossein Naderi, Alireza Shojaei, Lifu Huang, Philip Agee, Kereshmeh Afsari, Abiola Akanmu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14091v1",
    "source": "arXiv",
    "abstract": "Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate the improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction."
  },
  {
    "date": "2026-01-20",
    "title": "Period collapse of Markov triangles",
    "authors": "Marc Fares",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14090v1",
    "source": "arXiv",
    "abstract": "Cristofaro-Gardiner and Kleinman showed the complete period collapse of the Ehrhart quasipolynomial of Fibonacci triangles and their irrational limits, by studying the Fourier-Dedekind sums involved in the Ehrhart function of right-angled rational triangles. We generalize this result using integral affine geometrical methods to all Markov triangles, as defined by Vianna. In particular, we show new occurrences of strong period collapse, namely by constructing for each Markov number $p$ a two-sided sequence of rational triangles and two irrational limits with quasipolynomial Ehrhart function of period $p$."
  },
  {
    "date": "2026-01-20",
    "title": "Data-Driven Safe Output Regulation of Strict-Feedback Linear Systems with Input Delay",
    "authors": "Zhenxu Zhao, Ji Wang, Weiyao Lan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14089v1",
    "source": "arXiv",
    "abstract": "This paper develops a data-driven safe control framework for linear systems possessing a known strict-feedback structure, but with most plant parameters, external disturbances, and input delay being unknown. By leveraging Koopman operator theory, we utilize Krylov dynamic mode decomposition (DMD) to extract the system dynamics from measured data, enabling the reconstruction of the system and disturbance matrices. Concurrently, the batch least-squares identification (BaLSI) method is employed to identify other unknown parameters in the input channel. Using control barrier functions (CBFs) and backstepping, we first develop a full-state safe controller. Based on this, we build an output-feedback controller by performing system identification using only the output data and actuation signals as well as constructing an observer to estimate the unmeasured plant states. The proposed approach achieves: 1) finite-time identification of a substantial set of unknown system quantities, and 2) exponential convergence of the output state (the state furthest from the control input) to a reference trajectory while rigorously ensuring safety constraints. The effectiveness of the proposed method is demonstrated through a safe vehicle platooning application."
  },
  {
    "date": "2026-01-20",
    "title": "On large periodic traveling wave solutions to the free boundary Stokes and Navier-Stokes equations",
    "authors": "Seyed Abdolhamid Banihashemi, Huy Q. Nguyen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14085v1",
    "source": "arXiv",
    "abstract": "We study the free boundary problem for a finite-depth layer of viscous incompressible fluid in arbitrary dimension, modeled by the Stokes or Navier-Stokes equations. In addition to the gravitational field acting in the bulk, the free boundary is acted upon by surface tension and an external stress tensor posited to be in traveling wave form. We prove that for any isotropic stress tensor with periodic profile, there exists a locally unique periodic traveling wave solution, which can have large amplitude. Moreover, we prove that the constructed traveling wave solutions are asymptotically stable for the dynamic free boundary Stokes equations. Our proofs rest on the analysis of the nonlocal normal-stress to normal-Dirichlet operators for the Stokes and Navier-Stokes equations in domains of Sobolev regularity."
  },
  {
    "date": "2026-01-20",
    "title": "DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning",
    "authors": "Abdurrahim Yilmaz, Ozan Erdem, Ece Gokyayla, Ayda Acar, Burc Bugra Dagtas, Dilara Ilhan Erdil, Gulsum Gencoglan, Burak Temelkuran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14084v1",
    "source": "arXiv",
    "abstract": "Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse."
  },
  {
    "date": "2026-01-20",
    "title": "From Trees to Tree-Like: Distribution and Synthesis for Asynchronous Automata",
    "authors": "Mathieu Lehaut, Anca Muscholl, Nir Piterman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14078v1",
    "source": "arXiv",
    "abstract": "We revisit constructions for distribution and synthesis of Zielonka's asynchronous automata in restricted settings. We show first a simple, quadratic, distribution construction for asynchronous automata, where the process architecture is tree-like. An architecture is tree-like if there is an underlying spanning tree of the architecture and communications are local on the tree. This quadratic distribution result generalizes the known construction for tree architectures and improves on an older, exponential construction for triangulated dependence alphabets. Lastly we consider the problem of distributed controller synthesis and show that it is decidable for tree-like architectures. This extends the decidability boundary from tree architectures to tree-like keeping the same $\\text{Tower}_d(n)$ complexity bound, where $n$ is the size of the system and $d \\ge 0$ the depth of the process tree."
  },
  {
    "date": "2026-01-20",
    "title": "RV$\\times$TESS I: Modeling Asteroseismic Signals with Simultaneous Photometry and RVs",
    "authors": "Jiaxin Tang, Sharon X. Wang, Yaguang Li, Timothy R. Bedding, Guang-Yao Xiao, Fabo Feng, Jie Yu, Zun Wang, Jennifer A. Burt, R. Paul Butler, Brad Carter, Jeffrey D. Crane, Matías R. Díaz, Samuel K. Grunblatt, Daniel Huber, Hugh R. A. Jones, Stephen R. Kane, Jacob K. Luhn, Stephen A. Shectman, Johanna Teske, Rob Wittenmyer, Jason T. Wright, Jeremy Bailey, Simon J. O'Toole, Chris G. Tinney",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14076v1",
    "source": "arXiv",
    "abstract": "Detecting small planets via the radial velocity method remains challenged by signals induced by stellar variability, versus the effects of the planet(s). Here, we explore using Gaussian Process (GP) regression with Transiting Exoplanet Survey Satellite (TESS) photometry in modeling radial velocities (RVs) to help to mitigate stellar jitter from oscillations and granulation for exoplanet detection. We applied GP regression to simultaneous TESS photometric and RV data of HD 5562, a G-type subgiant ($M_\\star=1.09M_{\\odot}$, $R_\\star=1.88R_{\\odot}$) with a V magnitude of 7.17, using photometry to inform the priors for RV fitting. The RV data is obtained by the Magellan Planet Finder Spectrograph (PFS). The photometry-informed GP regression reduced the RV scatter of HD~5562 from 2.03 to 0.51 m/s. We performed injection and recovery tests to evaluate the potential of GPs for discovering small exoplanets around evolved stars, which demonstrate that the GP provides comparable noise reduction to the binning method. We also found that the necessity of photometric data depends on the quality of the RV dataset. For long baseline and high-cadence RV observations, GP regression can effectively mitigate stellar jitter without photometric data. However, for intermittent RV observations, incorporating photometric data improves GP fitting and enhances detection capabilities."
  },
  {
    "date": "2026-01-20",
    "title": "DDCCNet: Physics-enhanced Multitask Neural Networks for Data-driven Coupled-cluster",
    "authors": "P. D. Varuna S. Pathirage, Konstantinos D. Vogiatzis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14073v1",
    "source": "arXiv",
    "abstract": "We present the data-driven coupled-cluster deep network (DDCCNet), a family of multitask, physics-enhanced deep learning architectures designed to predict coupled-cluster singles and doubles (CCSD) amplitudes and correlation energies from lower-level electronic structure methods. The three DDCCNet variants (termed as v1, v2, and v3) progressively incorporate architectural refinements ranging from parallel subnetworks for t_1 and t_2 amplitudes to feature-partitioned blocks and physics-enhanced intermediate prediction layers that are structured in accordance with coupled-cluster equations to enhance physical consistency and multitask learning efficiency. These models jointly learn correlated amplitude patterns while embedding symmetry and orbital-level interactions directly into the network structure. Applied to methanol conformers, CO2 clusters, and small organic molecules, DDCCNet_v2 delivered the most accurate and transferable performance, achieving chemically precise correlation energies across diverse molecular systems. Collectively, DDCCNet establishes a scalable, physically grounded framework that unifies machine learning and ab initio theory for efficient, data-driven electronic structure prediction."
  },
  {
    "date": "2026-01-20",
    "title": "Superconductor-insulator transitions in infinite-layer nickelates controlled via ${operando}$ monitored reduction",
    "authors": "Heng Wang, Haoliang Huang, Wei Lv, Xianfeng Wu, Guangdi Zhou, Zihao Nie, Yueying Li, Cui Ding, Danfeng Li, Hongtao Yuan, Qi-Kun Xue, Zhuoyu Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14072v1",
    "source": "arXiv",
    "abstract": "Nickelates represent an emerging class of superconductors that demand innovative approaches for structural and electronic phase modulations. Continuous control over superconductor-insulator transition (SIT) in nickelates remains particularly challenging, hindering both fundamental understanding and potential applications. Here, we demonstrate SIT in infinite-layer nickelate superconductors utilizing multiple techniques, including an ${operando}$ monitored reduction (OMR) method. OMR enables ultrawide-range continuous modulation of the Ni 3${d}$ orbital electron occupancy from ~3${d}^7$ to ~3${d}^9$. The 3${d}$ occupancy is calibrated through systematic synchrotron X-ray absorption (XAS), combined with scanning transmission electron microscopy (STEM) annular bright field (ABF) analysis of oxygen atoms. SIT is further modulated via ionic liquid gating and magnetic field. Strikingly different from cuprates, our Nernst effect measurements show that pairing initiates at the onset of the resistive drop. The subsequent emergence of the Meissner effect at zero resistance marks the establishment of global phase coherence. Angle-dependent magnetotransport within the transition temperature regime indicates a mixture of two-dimensional (2D) and three-dimensional (3D) superconducting characters, suggesting the observed SIT deviates from the canonical 2D model. Our results provide a unique perspective on the interplay of structural and electronic phase transitions in the infinite-layer nickelates across the oxygen content-magnetic field-temperature parameter space."
  },
  {
    "date": "2026-01-20",
    "title": "Kakugo: Distillation of Low-Resource Languages into Small Language Models",
    "authors": "Peter Devine, Mardhiyah Sanni, Farid Adilazuarda, Julieta Gil Loizaga, Barry Haddow",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14051v1",
    "source": "arXiv",
    "abstract": "We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI."
  },
  {
    "date": "2026-01-20",
    "title": "PRiSM: Benchmarking Phone Realization in Speech Models",
    "authors": "Shikhar Bharadwaj, Chin-Jou Li, Yoonjae Kim, Kwanghee Choi, Eunjung Yeo, Ryan Soh-Eun Shim, Hanyu Zhou, Brendon Boldt, Karen Rosero Jacome, Kalvin Chang, Darsh Agrawal, Keer Xu, Chao-Han Huck Yang, Jian Zhu, Shinji Watanabe, David R. Mortensen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14046v1",
    "source": "arXiv",
    "abstract": "Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism."
  },
  {
    "date": "2026-01-20",
    "title": "Classification of invariant tight contact structures on the 3-space, -ball and -sphere",
    "authors": "Mirko Torresani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14040v1",
    "source": "arXiv",
    "abstract": "We prove some classification results for tight contact structure in the 3-space, -ball and -sphere that are invariant with respect to some arbitrary involution, that is conjugated to the standard rotation around the x-axis. Unlike the classical scenario, a new integral torsion appears, dictating a splitting between equivalence classes. These tools could be useful fur future classification results regarding strongly invertible Legendrian knots."
  },
  {
    "date": "2026-01-20",
    "title": "Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation",
    "authors": "Wesam Moustafa, Hossam Elsafty, Helen Schneider, Lorenz Sparrenberg, Rafet Sifa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14039v1",
    "source": "arXiv",
    "abstract": "Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation."
  },
  {
    "date": "2026-01-20",
    "title": "XFEL Imaging Techniques for High Energy Density and Inertial Fusion Energy Research at HED-HiBEF",
    "authors": "Alejandro Laso Garcia, Mikhail Mishchenko, Victorien Bouffetier, Gabriel Perez-Callejo, Karen Appel, Alexey Arefiev, Carsten Baehtz, Erik Brambrink, Mihail Cernaianu, Domenico Doria, Tobias Dornheim, Gillis M. Dyer, Nicolas Fefeu, Eric Galtier, Thomas Gawne, Petru V. Ghenuche, Sebastian Goede, Johannes Hagemann, Marie-Luise Herbert, Hauke Höppner, Lingen Huang, Oliver Humphries, Mae Jones, Dimitri Khaghani, Thomas Kluge, Jayanath Koliyadu, Dominik Kraus, Hae Ja Lee, Julian Lütgert, Mikako Makita, Jean-Paul Naedler, Bob Nagler, Motoaki Nakatsutsumi, Quynh Nguyen, Alexander Pelka, Thomas R. Preston, Chong Bing Qu, Sripati V. Rahul, Lisa Randolph, Ronald Redmer, Martin Rehwald, Hans G. Rinderknecht, Angel Rodriguez-Fernandez, Joao J. Santos, Ulrich Schramm, Michal Smid, Cornelius Strohm, Jergus Strucka, Minxue Tang, Patrik Vagovic, Milenko Vescovi, Long Yang, Karl Zeil, Ulf Zastrau, Thomas E. Cowan, Toma Toncian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14028v1",
    "source": "arXiv",
    "abstract": "The imaging platform developed at the High Energy Density - Helmholtz International Beamline for Extreme Fields (HED-HiBEF) instrument at the European XFEL and its applications to high energy density and fusion related research are presented. The platform combines the XFEL beam with the high-intensity short-pulse laser ReLaX and the high-energy nanosecond-pulse laser DiPOLE-100X. The spatial resolution is better than 500 nm and the temporal resolution of the order of 50 fs. We show examples of blast waves and converging cylindrical shocks in aluminium, resonant absorption measurements of specific charged states in copper with ReLaX and planar shocks in polystyrene material generated by DiPOLE-100X. We also discuss the possibilities introduced by combining this imaging platform with a kJ-class laser."
  },
  {
    "date": "2026-01-20",
    "title": "The rate of purification of quantum trajectories",
    "authors": "Maël Bompais, Nina H. Amini, Juan P. Garrahan, Mădălin Guţă",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14023v1",
    "source": "arXiv",
    "abstract": "We investigate the behavior of quantum trajectories conditioned on measurement outcomes. Under a condition related to the absence of so-called dark subspaces, Kümmerer and Maassen had shown that such trajectories almost surely purify in the long run. In this article, we first present a simple alternative proof of this result using Lyapunov methods. We then strengthen the conclusion by proving that purification actually occurs at an exponential rate in expectation, again using a Lyapunov approach. Furthermore, we address the quantum state estimation problem by propagating two trajectories under the same measurement record--one from the true initial state and the other from an arbitrary initial guess--and show that the estimated trajectory converges exponentially fast to the true one, thus quantifying the rate at which information is progressively revealed through the measurement process."
  },
  {
    "date": "2026-01-20",
    "title": "Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment",
    "authors": "Rodrigo Pereira David, Luciano Araujo Dourado Filho, Daniel Marques da Silva, João Alfredo Cal-Braz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14022v1",
    "source": "arXiv",
    "abstract": "Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: What emissions would an EV have generated if it had followed the same driving profile as an ICEV? By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions."
  },
  {
    "date": "2026-01-20",
    "title": "Tensor Abelian geometry of VI-modules",
    "authors": "Peng Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14020v1",
    "source": "arXiv",
    "abstract": "In this short note, we study the spectrum of prime Serre ideals of global represen tations for noetherian families. In particular, we prove that the spectrum of prime Serre ideals of finitely generated VI-modules is homeomorphic to N^{*}, the one-point compactification of N, which differs from the Balmer spectrum of derived VI-modules. Our method could also be applied to the category of finitely generated FI-modules and the category of global representations for the family of cyclic p-groups."
  },
  {
    "date": "2026-01-20",
    "title": "Robustness for free: asymptotic size and power of max-tests in high dimensions",
    "authors": "Anders Bredahl Kock, David Preinerstorfer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14013v1",
    "source": "arXiv",
    "abstract": "Consider testing a zero restriction on the mean of a $d$-dimensional random vector based on an i.i.d. sample of size $n$. Suppose further that the coordinates are only assumed to possess $m>2$ moments. Then, max-tests based on arithmetic means and critical values derived from Gaussian approximations are not guaranteed to be asymptotically valid unless $d$ is relatively small compared to $n$, because said approximation faces a polynomial growth barrier of $d=o(n^{m/2-1})$. We propose a max-test based on winsorized means, and show that it holds the desired asymptotic size even when $d$ grows at an exponential rate in $n$ and the data are adversarially contaminated. Our characterization of its asymptotic power function shows that these benefits do not come at the cost of reduced asymptotic power: the robustified max-test has identical asymptotic power to that based on arithmetic means whenever the stronger assumptions underlying the latter are satisfied. We also investigate when -- and when not -- data-driven (bootstrap) critical values can strictly increase asymptotic power of the robustified max-test."
  },
  {
    "date": "2026-01-20",
    "title": "Computing Crystalline Cohomology and p-Divisible Groups for Curves over Finite Fields",
    "authors": "Jeremy Booher",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14006v1",
    "source": "arXiv",
    "abstract": "Let $X$ be a smooth projective curve over a finite field of characteristic $p$. We describe and implement a practical algorithm for computing the $p$-divisible group $Jac(X)[p^\\infty]$ via computing its Dieudonné module, or equivalently computing the Frobenius and Verschiebung operators on the first crystalline cohomology of $X$. We build on Tuitman's $p$-adic point counting algorithm, which computes the rigid cohomology of $X$ and requires a ``nice'' lift of $X$ to be provided."
  },
  {
    "date": "2026-01-20",
    "title": "Leveraged positions on decentralized lending platforms",
    "authors": "Bastien Baude, Vincent Danos, Hamza El Khalloufi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14005v1",
    "source": "arXiv",
    "abstract": "We develop a mathematical framework to optimize leveraged staking (\"loopy\") strategies in Decentralized Finance (DeFi), in which a staked asset is supplied as collateral, the underlying is borrowed and re-staked, and the loop can be repeated across multiple lending markets. Exploiting the fact that DeFi borrow rates are deterministic functions of pool utilization, we reduce the multi-market problem to a convex allocation over market exposures and obtain closed-form solutions under three interest-rate models: linear, kinked, and adaptive (Morpho's AdaptiveCurveIRM). The framework incorporates market-specific leverage limits, utilization-dependent borrowing costs, and transaction fees. Backtests on the Ethereum and Base blockchains using the largest Morpho wstETH/WETH markets (from January 1 to April 1, 2025) show that rebalanced leveraged positions can reach up to 6.2% APY versus 3.1% for unleveraged staking, with strong dependence on position size and rebalancing frequency. Our results provide a mathematical basis for transparent, automated DeFi portfolio optimization."
  },
  {
    "date": "2026-01-20",
    "title": "Consensus Stability of Community Notes on X",
    "authors": "Yuwei Chuai, Gabriele Lenzini, Nicolas Pröllochs",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14002v1",
    "source": "arXiv",
    "abstract": "Community-based fact-checking systems, such as Community Notes on X (formerly Twitter), aim to mitigate online misinformation by surfacing annotations judged helpful by contributors with diverse viewpoints. While prior work has shown that the platform's bridging-based algorithm effectively selects helpful notes at the time of display, little is known about how evaluations change after notes become visible. Using a large-scale dataset of 437,396 community notes and 35 million ratings from over 580,000 contributors, we examine the stability of helpful notes and the rating dynamics that follow their initial display. We find that 30.2% of displayed notes later lose their helpful status and disappear. Using interrupted time series models, we further show that note display triggers a sharp increase in rating volume and a significant shift in rating leaning, but these effects differ across rater groups. Contributors with viewpoints similar to note authors tend to increase supportive ratings, while dissimilar contributors increase negative ratings, producing systematic post-display polarization. Counterfactual analyses suggest that this post-display polarization, particularly from dissimilar raters, plays a substantial role in note disappearance. These findings highlight the vulnerability of consensus-based fact-checking systems to polarized rating behavior and suggest pathways for improving their resilience."
  },
  {
    "date": "2026-01-20",
    "title": "Spectral Gaps on Large Hyperbolic Surfaces",
    "authors": "Laura Monk, Frédéric Naud",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13988v1",
    "source": "arXiv",
    "abstract": "In this expository paper, we review the history and the recent breakthroughs in the spectral theory of large volume hyperbolic surfaces. More precisely, we focus mostly on the investigation of the first non-trivial eigenvalue $λ_1$ and its possible behaviour in the large volume regime."
  },
  {
    "date": "2026-01-20",
    "title": "SHARE: A Fully Unsupervised Framework for Single Hyperspectral Image Restoration",
    "authors": "Jiangwei Xie, Zhang Wen, Mike Davies, Dongdong Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13987v1",
    "source": "arXiv",
    "abstract": "Hyperspectral image (HSI) restoration is a fundamental challenge in computational imaging and computer vision. It involves ill-posed inverse problems, such as inpainting and super-resolution. Although deep learning methods have transformed the field through data-driven learning, their effectiveness hinges on access to meticulously curated ground-truth datasets. This fundamentally restricts their applicability in real-world scenarios where such data is unavailable. This paper presents SHARE (Single Hyperspectral Image Restoration with Equivariance), a fully unsupervised framework that unifies geometric equivariance principles with low-rank spectral modelling to eliminate the need for ground truth. SHARE's core concept is to exploit the intrinsic invariance of hyperspectral structures under differentiable geometric transformations (e.g. rotations and scaling) to derive self-supervision signals through equivariance consistency constraints. Our novel Dynamic Adaptive Spectral Attention (DASA) module further enhances this paradigm shift by explicitly encoding the global low-rank property of HSI and adaptively refining local spectral-spatial correlations through learnable attention mechanisms. Extensive experiments on HSI inpainting and super-resolution tasks demonstrate the effectiveness of SHARE. Our method outperforms many state-of-the-art unsupervised approaches and achieves performance comparable to that of supervised methods. We hope that our approach will shed new light on HSI restoration and broader scientific imaging scenarios. The code will be released at https://github.com/xuwayyy/SHARE."
  },
  {
    "date": "2026-01-20",
    "title": "Experimental study on gravity currents flowing on heated walls",
    "authors": "Stefano Lanzini, Massimo Marro, Mathieu Creyssels, Alexandre Azouzi, Pietro Salizzoni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13984v1",
    "source": "arXiv",
    "abstract": "We present an experimental study on steady gravity currents advancing along a heated wall. The current is generated by a mixture of air and carbon dioxide continuously supplied at the channel inlet. To have a complete point-wise characterization of the flow, simultaneous high-frequency measurements of two velocity components, CO_2 concentration, and temperature are performed. An experimental protocol is presented to reconstruct the local fluid density and to estimate turbulent vertical and horizontal fluxes of CO_2, temperature, and buoyancy. The reliability of both the flow measurements and of the estimate of convective heat flux exchanged at the wall is assessed through integral balances of \\textnormal{CO}$_2$ mass, enthalpy, and buoyancy, performed at different distances from the source. Three wall-heating conditions are considered: an adiabatic case, a moderately heated case, and a strongly heated case. In the heated experiments, a convectively unstable boundary layer forms near the wall, capped by a stably stratified region. The influence of this condition on the first- and second-order flow statistics profiles is examined. Although wall heating influences the vertical shear, the Brunt-Vaisala frequency, and both shear and buoyancy production of turbulent kinetic energy within the stably-stratified region characterized by an almost constant vertical gradient of streamwise velocity, neither the gradient Richardson number nor the flux Richardson number exhibits a clear trend in this region with the imposed wall heat flux."
  },
  {
    "date": "2026-01-20",
    "title": "Optimal Construction of Two-Qubit Gates using the Symmetries of B Gate Equivalence Class",
    "authors": "M. Karthick Selvan, S. Balakrishnan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13983v1",
    "source": "arXiv",
    "abstract": "Two applications of gates from the B gate equivalence class can generate all two-qubit gates. This local equivalence class is invariant under the mirror (multiplication with the SWAP gate) operation, inverse (Hermitian conjugate) operation, and the combined inverse and mirror operations. The last two symmetries are associated with the ability of a two-qubit gate to generate the two-qubit local gates and the SWAP gate in two applications. No single local equivalence class of two-qubit gates, except the B gate equivalence class, has these two symmetries. Only the planar regions of the Weyl chamber, describing the mirror operation, contain the local equivalence classes with either one of the two symmetries. We show that there exist one-parameter families of local equivalence classes on these planes, with and without the B gate equivalence class, such that each of them can be used to construct a parameterized universal two-qubit quantum circuit that involves only two nonlocal two-qubit gates. We also discuss the implementation of the gates from a few families of local equivalence classes on superconducting quantum computers for optimal generation of all two-qubit gates."
  },
  {
    "date": "2026-01-20",
    "title": "X-ray Analysis and Photon-transport Simulations of SMC X-1: A Warped-disc Origin of the Superorbital Modulation",
    "authors": "Satoshi Takashima, Hirokazu Odaka, Ryota Tomaru, Atsushi Tanimoto, Aya Bamba, Toru Tamagawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13978v1",
    "source": "arXiv",
    "abstract": "The luminous accreting pulsar SMC X-1 is an appropriate target to explore the accretion dynamics. SMC X-1 shows unique quasi-periodic flux variability of 40-65$\\,$days known as superorbital modulation. To constrain the accretion structure of SMC X-1 based on timing and spectral study, we have analysed X-ray data of SMC X-1 observed by Suzaku and NuSTAR at various epochs between 2011 and 2022. The spectral analysis shows that the hydrogen column density ($N_\\mathrm{H}$) increases from $1.1 \\times 10^{22}\\,\\mathrm{cm^{-2}}$ to $1.24 \\times 10^{23}\\,\\mathrm{cm^{-2}}$ as the flux decreases with the superorbital modulation. The neutral iron K$α$ line at 6.4$\\,$keV has a broad width of 0.3$\\,$keV, and its equivalent width increases as toward superorbital low states. The line broadening is consistent with Keplerian motion at the inner disc rather than the stellar wind velocity of the donor star. These findings support that the superorbital modulation is a consequence of X-ray attenuation by the warped accretion disc. To test this interpretation, we have conducted photon transport simulations of a system consisting of a neutron star, a warped disc, and optically-thin disc atmosphere. Occultation of the central source by the disc successfully reproduces the observed variations in the equivalent width of neutral iron K$α$ line, pulse profiles, and flux in hard X-rays. Notably, a disc precession angle of approximately $30^\\circ$ can account for the observational features. For the radiation pattern of the photon source, the preferred beam width corresponds to a standard deviation of $30^\\circ$."
  },
  {
    "date": "2026-01-20",
    "title": "Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains",
    "authors": "Marco Piccolo, Qiwei Han, Astrid van Toor, Joachim Vanneste",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13975v1",
    "source": "arXiv",
    "abstract": "Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic \"Context Collapse\" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment."
  },
  {
    "date": "2026-01-20",
    "title": "Experimental Evidence-Based Sub-Rayleigh Source Discrimination",
    "authors": "Saurabh U. Shringarpure, Yong Siah Teo, Hyunseok Jeong, Michael Evans, Luis L. Sanchez-Soto, Antonin Grateau, Alexander Boeschoten, Nicolas Treps",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13972v1",
    "source": "arXiv",
    "abstract": "We propose a Bayesian evidence-based inference framework based on relative belief ratios and apply it to discriminating between one and two incoherent optical point sources using spatial-mode demultiplexing (SPADE). Unlike the Helstrom measurement, SPADE require no collective detection and its optimal for asymptotically large samples. Our method avoids ad hoc statistical constructs and relies solely on the information contained in the data, with all assumptions entering only through the likelihood model and prior beliefs. Using experimental evidence, we demonstrate the superior resolving performance of SPADE over direct imaging from a new and extensible perspective; one that naturally generalizes to multiple sources and offers a practical robust approach to analyzing quantum-enhanced superresolution."
  },
  {
    "date": "2026-01-20",
    "title": "Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition",
    "authors": "Gorgi Pavlov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13953v1",
    "source": "arXiv",
    "abstract": "Learning precise Boolean logic via gradient descent remains challenging: neural networks typically converge to \"fuzzy\" approximations that degrade under quantization. We introduce Hierarchical Spectral Composition, a differentiable architecture that selects spectral coefficients from a frozen Boolean Fourier basis and composes them via Sinkhorn-constrained routing with column-sign modulation. Our approach draws on recent insights from Manifold-Constrained Hyper-Connections (mHC), which demonstrated that projecting routing matrices onto the Birkhoff polytope preserves identity mappings and stabilizes large-scale training. We adapt this framework to logic synthesis, adding column-sign modulation to enable Boolean negation -- a capability absent in standard doubly stochastic routing. We validate our approach across four phases of increasing complexity: (1) For n=2 (16 Boolean operations over 4-dim basis), gradient descent achieves 100% accuracy with zero routing drift and zero-loss quantization to ternary masks. (2) For n=3 (10 three-variable operations), gradient descent achieves 76% accuracy, but exhaustive enumeration over 3^8 = 6561 configurations proves that optimal ternary masks exist for all operations (100% accuracy, 39% sparsity). (3) For n=4 (10 four-variable operations over 16-dim basis), spectral synthesis -- combining exact Walsh-Hadamard coefficients, ternary quantization, and MCMC refinement with parallel tempering -- achieves 100% accuracy on all operations. This progression establishes (a) that ternary polynomial threshold representations exist for all tested functions, and (b) that finding them requires methods beyond pure gradient descent as dimensionality grows. All operations enable single-cycle combinational logic inference at 10,959 MOps/s on GPU, demonstrating viability for hardware-efficient neuro-symbolic logic synthesis."
  },
  {
    "date": "2026-01-20",
    "title": "Mineral Detection of Cosmic-Ray Boosted Dark Matter",
    "authors": "Jin-Wei Wang, Fei-Fei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13949v1",
    "source": "arXiv",
    "abstract": "We present the first dedicated analysis of cosmic-ray dark matter (CRDM) in paleo detectors. Owing to their large kinetic energies, CRDM particles generate nuclear-recoil tracks that extend to substantially larger lengths than those produced by dominant backgrounds from neutrinos and intrinsic radioactivity. Combined with the ultra-large effective geological exposure of $\\mathcal{O}(10^{5})~\\mathrm{t\\,yr}$, paleo detectors provide a uniquely sensitive probe of sub-GeV DM. Considering both constant and vector-mediator interactions, we find that paleo detectors improve the sensitivity to the DM--proton scattering cross section by one to two orders of magnitude compared with the latest XENONnT limits."
  },
  {
    "date": "2026-01-20",
    "title": "Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework",
    "authors": "Yixuan Deng, Tongrun Wu, Donghao Wu, Zeyu Wei, Jiayuan Wang, Zhenglong Sun, Yuqing Tang, Xiaoqiang Ji",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13945v1",
    "source": "arXiv",
    "abstract": "As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems."
  },
  {
    "date": "2026-01-20",
    "title": "IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization",
    "authors": "Heyang Zhou, JiaJia Chen, Xiaolu Chen, Jie Bao, Zhen Chen, Yong Liao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13938v1",
    "source": "arXiv",
    "abstract": "As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is a practical strategy termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, we propose IF-GEO, a \"diverge-then-converge\" framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. To explicitly quantify IF-GEO's objective of cross-query stability, we introduce risk-aware stability metrics. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios."
  },
  {
    "date": "2026-01-20",
    "title": "Impact Matters! An Audit Method to Evaluate AI Projects and their Impact for Sustainability and Public Interest",
    "authors": "Theresa Züger, Laura State, Lena Winter",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13936v1",
    "source": "arXiv",
    "abstract": "The overall rapid increase of artificial intelligence (AI) use is linked to various initiatives that propose AI 'for good'. However, there is a lack of transparency in the goals of such projects, as well as a missing evaluation of their actual impacts on society and the planet. We close this gap by proposing public interest and sustainability as a regulatory dual-concept, together creating the necessary framework for a just and sustainable development that can be operationalized and utilized for the assessment of AI systems. Based on this framework, and building on existing work in auditing, we introduce the Impact-AI-method, a qualitative audit method to evaluate concrete AI projects with respect to public interest and sustainability. The interview-based method captures a project's governance structure, its theory of change, AI model and data characteristics, and social, environmental, and economic impacts. We also propose a catalog of assessment criteria to rate the outcome of the audit as well as to create an accessible output that can be debated broadly by civil society. The Impact-AI-method, developed in a transdisciplinary research setting together with NGOs and a multi-stakeholder research council, is intended as a reusable blueprint that both informs public debate about AI 'for good' claims and supports the creation of transparency of AI systems that purport to contribute to a just and sustainable development."
  },
  {
    "date": "2026-01-20",
    "title": "The gradient-flow coupling of three-and four-dimensional QED",
    "authors": "Lars Georg, Robert V. Harlander, Robert H. Mason",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13914v1",
    "source": "arXiv",
    "abstract": "We evaluate the QED coupling in the gradient-flow scheme in three and four space-time dimensions. Our general result applies to any theory with a U(1) gauge field coupled to arbitary other fields via arbitrary interactions. As an example, we consider QED with $n_\\text{f}$ flavors in three and four space-time dimensions and evaluate the corresponding $β$ functions. In four dimensions, we find that the perturbative expansion of the $β$ function behaves much better than the corresponding expression in QCD. In three dimensions, we recover both the ultraviolet as well as the infrared fixed points of the QED coupling in the large-$n_\\text{f}$ limit."
  },
  {
    "date": "2026-01-20",
    "title": "Designing sustainable barn-type houses: Optimal shapes for minimal envelope and energy use",
    "authors": "Ewa Rokita-Magdziarz, Barbara Gronostajska, Marcin Magdziarz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13911v1",
    "source": "arXiv",
    "abstract": "Barn-type houses have become one of the most popular single-family housing typologies in Poland and across Europe due to their simplicity, functionality, and potential for energy efficiency. Despite their widespread use, systematic methods for optimizing their geometry in terms of envelope area and energy performance remain limited. This paper develops a rigorous mathematical framework for determining the optimal proportions of barn-type houses with respect to minimizing the external surface area while satisfying constraints of either fixed volume or fixed floor area. Closed-form solutions for the optimal width, length, and height are derived as explicit functions of the roof slope, together with formulas for the minimal achievable surface. A recently introduced dimensionless compactness measure is also calculated, allowing quantitative assessment of how far a given design deviates from the theoretical optimum. The methodology is applied to case studies of three existing houses, showing that while some designs deviate significantly from optimal compactness, others already closely approximate it. The results confirm that theoretical optimization can lead to meaningful reductions in construction costs and energy demand. To support practical implementation, two original freely available software tools were developed, enabling architects and engineers to perform optimization analyses."
  },
  {
    "date": "2026-01-20",
    "title": "Bright Heralded Single-Photon Superradiance in a High-Density Thin Vapor Cell",
    "authors": "Heewoo Kim, Bojeong Seo, Han Seb Moon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13909v1",
    "source": "arXiv",
    "abstract": "Superradiance is a hallmark of cooperative quantum emission, where radiative decay is collectively enhanced by coherence among emitters. Here, extending superradiant effects to photon pair generation from multi-level atoms, two-photon process offers a pathway to novel quantum light sources and a useful case for practical superradiance. We report bright heralded single-photon superradiance via spontaneous four-wave mixing in a 1-mm-long, high-density cesium vapor cell. By reducing the average distance between atoms in the atomic vapor to 0.29 times the idler photon wavelength, we observe a dramatic narrowing of the temporal two-photon wavefunction. This compression of temporal two-photon wavefunction evidences the superradiance of heralded photons in the collective two-photon emission dynamics. Furthermore, our heralded single-photon superradiance is accompanied by a coincidence-to-accidental ratio of 200 and the detected photon-pair counting exceeding 10^6 pairs/s. These findings establish dense thin atomic vapors as a practical, robust medium for realizing superradiant photon sources, with immediate relevance for quantum optics and the development of efficient photonic quantum technologies."
  },
  {
    "date": "2026-01-20",
    "title": "Reduction of SAXS Signal due to Doppler Broadening Induced Loss of Coherence",
    "authors": "Thomas Kluge, Uwe Hernandez Acosta, Klaus Steiniger, Ulrich Schramm, Thomas E. Cowan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13905v1",
    "source": "arXiv",
    "abstract": "We present an analytical and numerical study of how Doppler-induced spectral broadening in laser-heated plasmas degrades the coherence of small-angle X-ray scattering (SAXS) signals, and show that the resulting loss of temporal coherence reduces the SAXS intensity. Applying this formalism to two benchmark geometries - single density steps (wires) and periodic gratings -- we obtain analytic estimates. For gratings, finite coherence simultaneously lowers Bragg-peak heights and broadens their widths, whereas for isolated steps only the overall scaling with q affected. We map the parameter space relevant to current SASE and self-seeded XFELs, revealing that Doppler effects remain managable for the trieval of geometry parameters (less than few 10 % error) for SASE bandwidths but become the dominant error source in seeded configurations or above-keV temperatures. Practical consequences for density-gradient retrieval and interface-sharpness measurements are quantified. The results supply clear criteria for when Doppler broadening must be included in SAXS data analysis and offer a route to infer electron temperature directly from coherence-loss signatures."
  },
  {
    "date": "2026-01-20",
    "title": "Mathematical and computational perspectives on the Boolean and binary rank and their relation to the real rank",
    "authors": "Michal Parnas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13900v1",
    "source": "arXiv",
    "abstract": "This survey provides a comprehensive overview of the study of the binary and Boolean rank from both a mathematical and a computational perspective, with particular emphasis on their relationship to the real rank. We review the basic definitions of these rank functions and present the main alternative formulations of the binary and Boolean rank, together with their computational complexity and their deep connection to the field of communication complexity. We summarize key techniques used to establish lower and upper bounds on the binary and Boolean rank, including methods from linear algebra, combinatorics and graph theory, isolation sets, the probabilistic method, kernelization, communication protocols and the query to communication lifting technique. Furthermore, we highlight the main mathematical properties of these ranks in comparison with those of the real rank, and discuss several non-trivial bounds on the rank of specific families of matrices. Finally, we present algorithmic approaches for computing and approximating these rank functions, such as parameterized algorithms, approximation algorithms, property testing and approximate Boolean matrix factorization (BMF). Together, the results presented outline the current theoretical knowledge in this area and suggest directions for further research."
  },
  {
    "date": "2026-01-20",
    "title": "Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging",
    "authors": "Masoumeh Javanbakhat, Piotr Komorowski, Dilyara Bareeva, Wei-Chang Lai, Wojciech Samek, Christoph Lippert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13899v1",
    "source": "arXiv",
    "abstract": "Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging."
  },
  {
    "date": "2026-01-20",
    "title": "From geometry to sustainability: Optimal shapes of hip roof houses",
    "authors": "Ewa Rokita-Magdziarz, Barbara Gronostajska, Marcin Magdziarz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13896v1",
    "source": "arXiv",
    "abstract": "In this paper, we develop a rigorous mathematical framework for the optimization of hip roof house geometry, with the primary goal of minimizing the external surface of the building envelope for a given set of design constraints. Five optimization scenarios are systematically analyzed: fixed volume, fixed footprint ratio, fixed slenderness ratio, fixed floor area, and constrained height. For each case, explicit formulas for the optimal dimensions are derived, offering architects and engineers practical guidelines for improving material efficiency, reducing construction costs, and enhancing energy performance. To illustrate the practical relevance of the theoretical results, case studies of real-world hip roof houses are presented, revealing both inefficiencies in common practice and near-optimal examples. Furthermore, a freely available software application has been developed to support designers in applying the optimization methods directly to architectural projects. The findings confirm that square-based footprints combined with balanced slenderness ratios yield the most efficient forms, while deviations toward elongated or flattened proportions significantly increase energy and material demands. This work demonstrates how mathematical modeling and architectural design can be integrated to support sustainable architecture, providing both theoretical insight and practical tools for shaping energy-efficient, cost-effective, and aesthetically coherent residential buildings."
  },
  {
    "date": "2026-01-20",
    "title": "OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3",
    "authors": "Xu Zhang, Danyang Li, Yingjie Xia, Xiaohang Dong, Hualong Yu, Jianye Wang, Qicheng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13895v1",
    "source": "arXiv",
    "abstract": "Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods."
  },
  {
    "date": "2026-01-20",
    "title": "Enhanced Cyber Threat Intelligence by Network Forensic Analysis for Ransomware as a Service(RaaS) Malwares",
    "authors": "Sharmila S P",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13873v1",
    "source": "arXiv",
    "abstract": "In the current era of interconnected cyberspace, there is an adverse effect of ransomware on individuals, startups, and large companies. Cybercriminals hold digital assets till the demand for payment is made. The success of ransomware upsurged with the introduction of Ransomware as a Service(RaaS) franchise in the darknet market. Obfuscation and polymorphic nature of malware make them more difficult to identify by Antivirus system. Signature based intrusion detection is still on role suffering from the scarcity of RaaS packet signatures. We have analysed RaaS samples by network forensic approach to investigate on packet captures of benign and malicious network traffic. The behavior analysis of RaaS family Ransomwares, Ryuk and Gandcrab have been investigated to classify the packets as suspicious, malicious, and non-malicious which further aid in generating RaaS packet signatures for early detection and mitigation of ransomwares belonging to RaaS family. More than 40\\% of packets are found malicious in this experiment. The proposed method is also verified by Virus Total API Approach. Further, the proposed approach is recommended for integration into honeypots in the present scenario to combat with data scarcity concerned with malware samples(RaaS). This data will be helpful in developing AI-based threat intelligence mechanisms. In turn enhance detection, prevention of threats, incident response and risk assessment."
  },
  {
    "date": "2026-01-20",
    "title": "Nonclassical photocounting statistics with a single on-off detector",
    "authors": "V. S. Kovtoniuk, M. Bohmann, A. A. Semenov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13869v1",
    "source": "arXiv",
    "abstract": "Any single on-off photocounter, which can only detect the presence or absence of photons without discriminating their number, is not capable of identifying nonclassical nature of light. This limitation arises because any photocounting statistics obtained with such a detector can be easily reproduced with coherent states of a light mode. We show that a simple modification of an on-off detector -- introducing controlled attenuation as a tunable setting -- enables such detectors to reveal nonclassical properties of radiation fields."
  },
  {
    "date": "2026-01-20",
    "title": "The Characteristic Mass and Energy Conversion Efficiency in the Cusp-Core Transition of Dark Matter Haloes: Implications for Scaling Relations and Supernova feedbacks",
    "authors": "Michi Shinozaki, Masao Mori, Yuka Kaneda, Kohei Hayashi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13868v1",
    "source": "arXiv",
    "abstract": "Galaxies in the nearby Universe, particularly dwarf systems, exhibit inner mass profiles of dark matter haloes that systematically depart from canonical cold dark matter expectations, signalling an interplay between baryonic feedback and the collisionless halo. We update an analytical cusp-core transition model by incorporating the effect of supernova-driven mass loss. Adapting this model to SPARC galaxies, we measure the energy conversion efficiency epsilon, defined as the fraction of supernova feedback energy that is used to change the central dark-matter potential. We find epsilon ~ 0.01 for nearby SPARC galaxies. Building on these measurements, we compare the dynamical energy required for a cusp-core transformation with the feedback energy available over burst cycles and identify a cusp-core transition forbidden region on the halo-stellar mass plane where transformation cannot occur. Galaxies with halo masses from 10^8 to 10^11 M_sun lie outside the forbidden region, whereas ultra-faint dwarf galaxies < 10^8 M_sun, galaxy groups and clusters > 10^11 M_sun fall within it, consistent with their high central densities and the inefficiency of core formation at very low and very high masses. This approach also explains the observed diversity of inner density profiles in low-mass systems, showing that both the star formation rate and the energy conversion efficiency govern them, with the latter emerging as a key parameter setting the strength of the cusp-core transition. Beyond the cusp-core problem, our observationally inferred energy conversion efficiency provides a model independent benchmark that strongly constrains galaxy formation models."
  },
  {
    "date": "2026-01-20",
    "title": "To infinity and back -- $1/N$ graph expansions of light-matter systems",
    "authors": "Andreas Schellenberger, Kai P. Schmidt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13860v1",
    "source": "arXiv",
    "abstract": "We present a method for performing a full graph expansion for light-matter systems, utilizing the linked-cluster theorem. This method enables us to explore $1/N$ corrections to the thermodynamic limit $N\\to \\infty$ in the number of particles, giving us access to the mesoscopic regime. While this regime is yet largely unexplored due to the challenges of studying it with established approaches, it incorporates intriguing features, such as entanglement between light and matter that vanishes in the thermodynamic limit. As a representative application, we calculate physical quantities of the low-energy regime for the paradigmatic Dicke-Ising chain in the paramagnetic normal phase by accompanying the graph expansion with both exact diagonalization (NLCE) and perturbation theory (\\pcst), benchmarking our approach against other techniques. We investigate the ground-state energy density and photon density, showing a smooth transition from the microscopic to the macroscopic regime up to the thermodynamic limit. Around the quantum critical point, we extract the $1/N$ corrections to the ground-state energy density to obtain the critical point and critical exponent using extrapolation techniques."
  },
  {
    "date": "2026-01-20",
    "title": "Jacob's ladders, point of contact of the remained in the prime-number law with the Fermat-Wiles theorem and multiplicative puzzles on some sets of integrals",
    "authors": "Jan Moser",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13855v1",
    "source": "arXiv",
    "abstract": "In this paper we prove, on the Riemann hypothesis, the existence of such increments of the Ingham integral (1932) that generate new functionals together with corresponding new $Pζ$-equivalents of the Fermat-Wiles theorem. We obtain also new results in this direction."
  },
  {
    "date": "2026-01-20",
    "title": "Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation",
    "authors": "Raül Pérez-Gonzalo, Andreas Espersen, Antonio Agudo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13852v1",
    "source": "arXiv",
    "abstract": "Linear discriminant analysis improves class separability but struggles with non-linearly separable data. To overcome this, we introduce Deep Discriminant Analysis (DDA), which directly optimizes the Fisher criterion utilizing deep networks. To ensure stable training and avoid computational instabilities, we incorporate signed between-class variance, bound outputs with a sigmoid function, and convert multiplicative relationships into additive ones. We present two stable DDA loss functions and augment them with a probability loss, resulting in Probabilistic DDA (PDDA). PDDA effectively minimizes class overlap in output distributions, producing highly confident predictions with reduced within-class variance. When applied to wind blade segmentation, PDDA showcases notable advances in performance and consistency, critical for wind energy maintenance. To our knowledge, this is the first application of DDA to image segmentation."
  },
  {
    "date": "2026-01-20",
    "title": "Inverting Self-Organizing Maps: A Unified Activation-Based Framework",
    "authors": "Alessandro Londei, Matteo Benati, Denise Lanzieri, Vittorio Loreto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13851v1",
    "source": "arXiv",
    "abstract": "Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering."
  },
  {
    "date": "2026-01-20",
    "title": "Co-Initialization of Control Filter and Secondary Path via Meta-Learning for Active Noise Control",
    "authors": "Ziyi Yang, Li Rao, Zhengding Luo, Dongyuan Shi, Qirui Huang, Woon-Seng Gan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13849v1",
    "source": "arXiv",
    "abstract": "Active noise control (ANC) must adapt quickly when the acoustic environment changes, yet early performance is largely dictated by initialization. We address this with a Model-Agnostic Meta-Learning (MAML) co-initialization that jointly sets the control filter and the secondary-path model for FxLMS-based ANC while keeping the runtime algorithm unchanged. The initializer is pre-trained on a small set of measured paths using short two-phase inner loops that mimic identification followed by residual-noise reduction, and is applied by simply setting the learned initial coefficients. In an online secondary path modeling FxLMS testbed, it yields lower early-stage error, shorter time-to-target, reduced auxiliary-noise energy, and faster recovery after path changes than a baseline without re-initialization. The method provides a simple fast start for feedforward ANC under environment changes, requiring a small set of paths to pre-train."
  },
  {
    "date": "2026-01-20",
    "title": "Emotion and Acoustics Should Agree: Cross-Level Inconsistency Analysis for Audio Deepfake Detection",
    "authors": "Jinhua Zhang, Zhenqi Jia, Rui Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13847v1",
    "source": "arXiv",
    "abstract": "Audio Deepfake Detection (ADD) aims to detect spoof speech from bonafide speech. Most prior studies assume that stronger correlations within or across acoustic and emotional features imply authenticity, and thus focus on enhancing or measuring such correlations. However, existing methods often treat acoustic and emotional features in isolation or rely on correlation metrics, which overlook subtle desynchronization between them and smooth out abrupt discontinuities. To address these issues, we propose EAI-ADD, which treats cross level emotion acoustic inconsistency as the primary detection signal. We first project emotional and acoustic representations into a comparable space. Then we progressively integrate frame level and utterance level emotion features with acoustic features to capture cross level emotion acoustic inconsistencies across different temporal granularities. Experimental results on the ASVspoof 2019LA and 2021LA datasets demonstrate that the proposed EAI-ADD outperforms baselines, providing a more effective solution for audio anti spoofing detection."
  },
  {
    "date": "2026-01-20",
    "title": "Interpretable, Physics-Informed Learning Reveals Sulfur Adsorption and Poisoning Mechanisms in 13-Atom Icosahedra Nanoclusters",
    "authors": "Raiane Ferreira Monteiro, João Marcos T. Palheta, Tulio Gnoatto Grison, Octávio Rodrigues Filho, Renato Luis Tame Parreira, Diego Guedes-Sobrinho, Celso R. C. Rêgo, Alexandre C. Dias, Krys Elly de Araújo Batista, Maurício J. Piotrowski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13845v1",
    "source": "arXiv",
    "abstract": "Transition-metal nanoclusters exhibit structural and electronic properties that depend on their size, often making them superior to bulk materials for heterogeneous catalysis. However, their performance can be limited by sulfur poisoning. Here, we use dispersion-corrected density functional theory (DFT) and physics-informed machine learning to map how atomic sulfur adsorbs and causes poisoning on 13-atom icosahedral clusters from 30 different transition metals (3$d$ to 5$d$). We measure which sites sulfur prefers to adsorb to, the thermodynamics and energy breakdown, changes in structure, such as bond lengths and coordination, and electronic properties, such as $\\varepsilon_d$, the HOMO-LUMO gap, and charge transfer. Vibrational analysis reveals true energy minima and provides ZPE-based descriptors that reflect the lattice stiffening upon sulfur adsorption. For most metals, the metal-sulfur interaction mainly determines adsorption energy. At the same time, distortion penalties are usually moderate but can be significant for a few metals, suggesting these are more likely to restructure when sulfur is adsorbed. Using unsupervised \\textit{k}-means clustering, we identify periodic trends and group metals based on their adsorption responses. Supervised regression models with leave-one-feature-out analysis identify the descriptors that best predict adsorption for new samples. Our results highlight the isoelectronic triad \\ce{Ti}, \\ce{Zr}, and \\ce{Hf} as a balanced group that combines strong sulfur binding with minimal structural change. Additional DFT calculations for \\ce{SO2} adsorption reveal strong binding and a clear tendency toward dissociation on these clusters, linking electronic states, lattice response, and poisoning strength. These findings offer data-driven guidelines for designing sulfur-tolerant nanocatalysts at the subnanometer scale."
  },
  {
    "date": "2026-01-20",
    "title": "Optimal L2 Regularization in High-dimensional Continual Linear Regression",
    "authors": "Gilad Karpel, Edward Moroshko, Ran Levinstein, Ron Meir, Daniel Soudry, Itay Evron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13844v1",
    "source": "arXiv",
    "abstract": "We study generalization in an overparameterized continual linear regression setting, where a model is trained with L2 (isotropic) regularization across a sequence of tasks. We derive a closed-form expression for the expected generalization loss in the high-dimensional regime that holds for arbitrary linear teachers. We demonstrate that isotropic regularization mitigates label noise under both single-teacher and multiple i.i.d. teacher settings, whereas prior work accommodating multiple teachers either did not employ regularization or used memory-demanding methods. Furthermore, we prove that the optimal fixed regularization strength scales nearly linearly with the number of tasks $T$, specifically as $T/\\ln T$. To our knowledge, this is the first such result in theoretical continual learning. Finally, we validate our theoretical findings through experiments on linear regression and neural networks, illustrating how this scaling law affects generalization and offering a practical recipe for the design of continual learning systems."
  },
  {
    "date": "2026-01-20",
    "title": "Base Station Sleeping Strategy Based on Load Sharing in Ultra-Dense Networks",
    "authors": "Ruixing Ren, Shan Chen, Xuehan Bao, Pingzheng Ge, Dongming Wang, Junhui Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13832v1",
    "source": "arXiv",
    "abstract": "To address the issues of high operational costs and low energy efficiency (EE) caused by the dense deployment of small base stations (s-BSs) in 5G ultra-dense networks (UDNs), this paper first constructs a multi-objective mathematical optimization model targeting maximizing EE and minimizing the number of active BSs. The model incorporates key constraints including BS operational state, user equipment (UE)-BS connection relationship, and load threshold, laying a theoretical foundation for the coordinated optimization of energy conservation and quality of service. Based on this model, an integrated solution combining UE-BS initial connection optimization and load-sharing based BS sleeping is proposed. In the initial connection phase, with communication quality and BS load as dual constraints, efficient matching between UEs and optimal BSs is achieved through three sequential steps: communication feasibility screening, redundant connection removal, and overload load redistribution. This resolves the problems of load imbalance and difficult identification of redundant BSs in UDNs arising from unordered initial connections. In the BS sleeping phase, a BS sleeping index, comprehensively considering UE transferability and backup BS resources, is innovatively introduced to quantify BS dormancy priority. Through a closed-loop process involving low-load BS screening, adjacent BS load evaluation, and load sharing by two takeover BSs based on their capacity, accurate dormancy of redundant BSs and collaborative load migration are realized. Simulation results in a typical UDNs scenario demonstrate that, compared with the traditional baseline scheme, the proposed solution exhibits significant advantages in convergence speed, optimization of the number of active BSs, and EE improvement."
  },
  {
    "date": "2026-01-20",
    "title": "Dimensional Constraints from SU(2) Representation Theory in Graph-Based Quantum Systems",
    "authors": "João P. da Cruz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13828v1",
    "source": "arXiv",
    "abstract": "We investigate dimensional constraints arising from representation theory when abstract graph edges possess internal degrees of freedom but lack geometric properties. We prove that such internal degrees of freedom can only encode directional information, necessitating quantum states in $\\mathbb{C}^2$ (qubits) as the minimal representation. Any geometrically consistent projection of these states maps necessarily to $\\mathbb{R}^3$ via the Bloch sphere. This dimensional constraint $d=3$ emerges through self-consistency: edges without intrinsic geometry force directional encoding ($\\mathbb{C}^2$), whose natural symmetry group $SU(2)$ has three-dimensional Lie algebra, yielding emergent geometry that validates the hypothesis via Bloch sphere correspondence ($S^2 \\subset \\mathbb{R}^3$). We establish uniqueness (SU($N>2$) yields $d>3$) and robustness (dimensional saturation under graph topology changes). The Euclidean metric emerges canonically from the Killing form on $\\mathfrak{su}(2)$. A global gauge consistency axiom is justified via principal bundle trivialization for finite graphs. Numerical simulations verify theoretical predictions. This result demonstrates how dimensional structure can be derived from information-theoretic constraints, with potential relevance to quantum information theory, discrete geometry, and quantum foundations."
  },
  {
    "date": "2026-01-20",
    "title": "Channel Estimation in MIMO Systems Using Flow Matching Models",
    "authors": "Yongqiang Zhang, Qurrat-Ul-Ain Nadeem",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13827v1",
    "source": "arXiv",
    "abstract": "Multiple-input multiple-output (MIMO) systems require efficient and accurate channel estimation with low pilot overhead to unlock their full potential for high spectral and energy efficiency. While deep generative models have emerged as a powerful foundation for the channel estimation task, the existing approaches using diffusion-based and score-based models suffer from high computational runtime due to their stochastic and many-step iterative sampling. In this paper, we introduce a flow matching-based channel estimator to overcome this limitation. The proposed channel estimator is based on a deep neural network trained to learn the velocity field of wireless channels, which we then integrate into a plug-and-play proximal gradient descent (PnP-PGD) framework. Simulation results reveal that our formulated approach consistently outperforms existing state-of-the-art (SOTA) generative model-based estimators, achieves up to 49 times faster inference at test time, and reduces up to 20 times peak graphics processing unit (GPU) memory usage. Our code and models are publicly available to support reproducible research."
  },
  {
    "date": "2026-01-20",
    "title": "GuideTouch: An Obstacle Avoidance Device for Visually Impaired",
    "authors": "Timofei Kozlov, Artem Trandofilov, Georgii Gazaryan, Issatay Tokmurziyev, Miguel Altamirano Cabrera, Dzmitry Tsetserukou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13813v1",
    "source": "arXiv",
    "abstract": "Safe navigation for the visually impaired individuals remains a critical challenge, especially concerning head-level obstacles, which traditional mobility aids often fail to detect. We introduce GuideTouch, a compact, affordable, standalone wearable device designed for autonomous obstacle avoidance. The system integrates two vertically aligned Time-of-Flight (ToF) sensors, enabling three-dimensional environmental perception, and four vibrotactile actuators that provide directional haptic feedback. Proximity and direction information is communicated via an intuitive 4-point vibrotactile feedback system located across the user's shoulders and upper chest. For real-world robustness, the device includes a unique centrifugal self-cleaning optical cover mechanism and a sound alarm system for location if the device is dropped. We evaluated the haptic perception accuracy across 22 participants (17 male and 5 female, aged 21-48, mean 25.7, sd 6.1). Statistical analysis confirmed a significant difference between the perception accuracy of different patterns. The system demonstrated high recognition accuracy, achieving an average of 92.9% for single and double motor (primary directional) patterns. Furthermore, preliminary experiments with 14 visually impaired users validated this interface, showing a recognition accuracy of 93.75% for primary directional cues. The results demonstrate that GuideTouch enables intuitive spatial perception and could significantly improve the safety, confidence, and autonomy of users with visual impairments during independent navigation."
  },
  {
    "date": "2026-01-20",
    "title": "It's Not The Plane -- It's The Pilot: A Framework for Cognitive-Activated AI-Augmentation to Avoid the Boiling Frog Problem",
    "authors": "Jochen Kuhn, Stefan Küchemann, Dave Rakestraw, Patrik Vogt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13812v1",
    "source": "arXiv",
    "abstract": "Generative artificial intelligence (AI) systems can now reliably solve many standard tasks used in introductory physics courses, producing correct equations, graphs, and explanations. While this capability is often framed as an opportunity for efficiency or personalization, it also poses a subtle ethical and educational risk: students may increasingly submit correct results without engaging in the epistemic practices that define learning physics.This challenge has recently been described as the \"boiling frog problem\" because we may not fully recognize how rapidly AI capabilities are advancing and fail to respond with commensurate urgency. In this article, we argue that the central challenge of AI in physics education is not cheating or tool selection, but instructional design. Drawing on research on self-regulated learning, cognitive load, multiple representations, and hybrid intelligence, we propose a practical framework for cognitively activated learning activities that structures student activities before, during, and after AI use. Using an example from an introductory kinematics laboratory, we show how AI can be integrated in ways that preserve prediction, interpretation, and evaluation as core learning activities. Rather than treating AI as an answer-generating tool, the framework positions AI as an epistemic partner whose contributions are deliberately bounded and reflected upon."
  },
  {
    "date": "2026-01-20",
    "title": "Quantum simulation of general spin-1/2 Hamiltonians with parity-violating fermionic Gaussian states",
    "authors": "Michael Kaicher, Joseph Vovrosh, Alexandre Dauphin, Simon B. Jäger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13811v1",
    "source": "arXiv",
    "abstract": "We introduce equations of motion for a parity-violating fermionic mean-field theory (PV-FMFT): a numerically efficient fermionic mean-field theory based on parity-violating fermionic Gaussian states (PV-FGS). This work provides explicit equations of motion for studying the real- and imaginary-time evolution of spin-1/2 Hamiltonians with arbitrary geometries and interactions. We extend previous formulations of parity-preserving fermionic mean-field theory (PP-FMFT) by including fermionic displacement operators in the variational Ansatz. Unlike PP-FMFT, PV-FMFT can be applied to general spin-1/2 Hamiltonians, describe quenches from arbitrary initial spin-1/2 product states, and compute local and non-local observables in a straight-forward manner at the same modest computational cost as PP-FMFT -- scaling as $O(N^3)$ in the worst case for a system of $N$ spins or fermionic modes. We demonstrate that PV-FMFT can exactly capture the imaginary- and real-time dynamics of non-interacting spin-1/2 Hamiltonians. We then study the post quench-dynamics of the one- and two-dimensional Ising model in presence of longitudinal and transversal fields with PV-FMFT and compute the single site magnetization and correlation functions, and compare them against results from other state-of-the-art numerical approaches. In two-dimensional spin systems, we show that the employed spin-to-fermion mapping can break rotational symmetry within the PV-FMFT description, and we discuss the resulting consequences for the calculated correlation functions. Our work introduces PV-FMFT as a benchmark for other numerical techniques and quantum simulators, and it outlines both its capabilities and its limitations."
  },
  {
    "date": "2026-01-20",
    "title": "Limits of multimode bunching for boson sampling validation: anomalous bunching induced by time delays",
    "authors": "Léo Pioge, Leonardo Novo, Nicolas J. Cerf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13792v1",
    "source": "arXiv",
    "abstract": "The multimode bunching probability is expected to provide a useful criterion for validating boson sampling experiments. Its applicability, however, is challenged by the existence of anomalous bunching, namely paradoxical situations in which partially distinguishable particles exhibit a higher bunching probability in two or more modes than perfectly indistinguishable ones. Using multimode bunching as a reliable criterion of genuine indistinguishability, therefore, requires a clear identification of the interferometric configurations in which anomalous bunching can or cannot occur. In particular, since uncontrolled small time delays between single-photon pulses constitute a common source of mode mismatch in current photonic platforms, it is essential to determine whether the resulting photon distinguishability might lead to anomalous bunching. Here, we first identify a broad class of interferometric configurations in which anomalous bunching is rigorously excluded, thereby establishing regimes where multimode bunching-based validation remains valid. Then, we find that, quite unexpectedly, temporal mode mismatch does not belong to this class. We exhibit a specific interferometric setup in which temporal distinguishability enhances multimode bunching, demonstrating that time delays can induce an anomalous behavior. These results help clarify the conditions under which multimode bunching remains a reliable validation tool."
  },
  {
    "date": "2026-01-20",
    "title": "The dynamically generated $h_1$ state by the $K^*\\bar{K}^*$ interaction and its $K_1(1270)\\bar{K}$ and $b_1(1235)π$ decays",
    "authors": "Qing-Hua Shen, Li-Sheng Geng, Xiang Liu, Ju-Jun Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13789v1",
    "source": "arXiv",
    "abstract": "We investigate the dynamically generated $h_1$ state with spin-parity $J^P = 1^+$ and a mass around 1790~MeV, arising from the $K^* \\bar{K}^*$ interaction within the chiral unitary approach. The partial decay widths into the $K_1(1270)\\bar{K}$ and $b_1(1235)π$ channels are calculated via a triangular loop mechanism. In this mechanism, the $h_1$ state couples to $K^* \\bar{K}^*$, and final-state interactions between $K^*$ and $\\bar{K}^*$ proceed through pseudoscalar-meson exchange, leading to the final states $\\bar{K}$ (or $π$) and $K_1(1270)$ [or $b_1(1235)$]. We also present the invariant mass distributions of a vector meson and a pseudoscalar meson originating from the decays of $K_1(1270)$ or $b_1(1235)$, along with the corresponding decay widths. Our results show that these decay widths are all of the order of a few MeV. We hope that future experiments can test the predictions presented here, thereby helping to identify this $h_1$ state."
  },
  {
    "date": "2026-01-20",
    "title": "An Adaptive Phase II Trial Design for Dose Selection and Addition in Microfilarial Infections",
    "authors": "Sonja Zehetmayer, Marta Bofill Roig, Fabrice Lotola Mougeni, Sabine Specht, Marc P. Hübner, Martin Posch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13784v1",
    "source": "arXiv",
    "abstract": "We propose a frequentist adaptive phase 2 trial design to evaluate the safety and efficacy of three treatment regimens (doses) compared to placebo for four types of helminth (worm) infections. This trial will be carried out in four Subsaharan African countries from spring 2025. Since the safety of the highest dose is not yet established, the study begins with the two lower doses and placebo. Based on safety and early efficacy results from an interim analysis, a decision will be made to either continue with the two lower doses or drop one or both and introduce the highest dose instead. This design borrows information across baskets for safety assessment, while efficacy is assessed separately for each basket. The proposed adaptive design addresses several key challenges: (1) The trial must begin with only the two lower doses because reassuring safety data from these doses is required before escalating to a higher dose. (2) Due to the expected speed of recruitment, adaptation decisions must rely on an earlier, surrogate endpoint. (3) The primary outcome is a count variable that follows a mixture distribution with an atom at 0. To control the familywise error rate in the strong sense when comparing multiple doses to the control in the adaptive design, we extend the partial conditional error approach to accommodate the inclusion of new hypotheses after the interim analysis. In a comprehensive simulation study we evaluate various design options and analysis strategies, assessing the robustness of the design under different design assumptions and parameter values. We identify scenarios where the adaptive design improves the trial's ability to identify an optimal dose. Adaptive dose selection enables resource allocation to the most promising treatment arms, increasing the likelihood of selecting the optimal dose while reducing the required overall sample size and trial duration."
  },
  {
    "date": "2026-01-20",
    "title": "Maximum spanning trees in normed planes",
    "authors": "Javier Alonso, Pedro Martín",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13779v1",
    "source": "arXiv",
    "abstract": "Extending some properties from the Euclidean plane to any normed plane, we show the validity of the Monma-Paterson-Suri-Yao algorithm for finding the maximum-weighted spanning tree of a set of $n$ points, where the weight of an edge is the distance between the end points measured by the norm and there are not repeated distances. For strictly convex normed planes, we expose an strategy for moving slightly the points of the set in order to obtain distinct distances."
  },
  {
    "date": "2026-01-20",
    "title": "Fit Matters: Format-Distance Alignment Improves Conversational Search",
    "authors": "Yitian Yang, Yugin Tan, Jung-Tai King, Yang Chen Lin, Yi-Chieh Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13778v1",
    "source": "arXiv",
    "abstract": "Existing conversational search systems can synthesize information into responses, but they lack principled ways to adapt response formats to users' cognitive states. This paper investigates whether aligning format and distance, which involves matching information granularity and media to users' psychological distance, improves user experience. In a between-subjects experiment (N=464) on travel planning, we crossed two distance dimensions (temporal/spatial x near/far) with four formats varying in granularity (abstract/concrete) and media (text/image-and-text). The experiment established that format--distance alignment reduced users' risk perceptions while increasing decision confidence, perceptions of information usefulness, ease of use, enjoyment, and credibility, and adoption intentions. Concrete formats imposed higher cognitive load, but yielded productive effort when matched to near-distance tasks. Images enhanced concrete but not abstract text, suggesting multimedia benefits depend on complementarity. These findings establish format--distance alignment as a distinctive and important design dimension, enabling systems to tailor response formats to users' psychological distance."
  },
  {
    "date": "2026-01-20",
    "title": "Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance",
    "authors": "Mostapha Benhenda",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13770v1",
    "source": "arXiv",
    "abstract": "We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench"
  },
  {
    "date": "2026-01-20",
    "title": "DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution",
    "authors": "Shengda Fan, Xuyan Ye, Yankai Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13761v1",
    "source": "arXiv",
    "abstract": "Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC."
  },
  {
    "date": "2026-01-20",
    "title": "Scalar-rigid submersions are Riemannian products",
    "authors": "Oskar Riedler, Thomas Tony",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14117v1",
    "source": "arXiv",
    "abstract": "Scalar-rigid maps are Riemannian submersions by works of Llarull, Goette--Semmelmann, and the second named author. In this article we show that they are essentially Riemannian products of the base manifold with a Ricci-flat fiber. As an application we obtain a Llarull-type theorem for non-zero degree maps onto products of manifolds of non-negative curvature operator and positive Ricci curvature with some enlargeable manifold. The proof is based on spin geometry for Dirac operators and an analysis connecting Clifford multiplication with the representation theory of the curvature operator."
  },
  {
    "date": "2026-01-20",
    "title": "Prospecting MeerKAT Continuum Data for Enigmatic Radio Sources with Unsupervised Vector-Quantised Variational Autoencoders",
    "authors": "Fernando L. Ventura, Kshitij Thorat, Anna Bosman, Roger Deane, Christopher Cleghorn",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13901v1",
    "source": "arXiv",
    "abstract": "We present a novel application of Vector quantised variational autoencoders (VQ-VAEs) to deep 1.28 GHz radio continuum images taken from the MeerKAT Galaxy Cluster Legacy Survey (MGCLS).VQ-VAEs are deep learning models widely used in modern computer vision applications and pipelines. Designed for image generation, VQ-VAEs are trained to reconstruct the input dataset via a low-dimensional discrete embedding. VQ-VAEs effectively learn the distribution of training data, where samples that do not fit the distribution well yield the highest reconstruction errors. This property makes VQ-VAEs a good candidate for the task of anomaly detection. In this work, we examine the effectiveness of VQ-VAEs in identifying radio continuum sources with anomalous structures in the image-plane domain. We find VQ-VAEs to be useful as part of a solution for searching such large datasets. We observe that they are able to remove a majority of the typical sources in such data, even when trained in an unsupervised manner on unlabelled data. We also provide our testing set of a large sample of manually labelled radio sources, in particular radio galaxies, taken from the MGCLS at 1.28 GHz. Automated approaches to searching through high volumes of data are key in extracting the full scientific potential of the Square Kilometre Array and its pathfinders."
  },
  {
    "date": "2026-01-20",
    "title": "Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders",
    "authors": "Kai Wittenmayer, Sukrut Rao, Amin Parchami-Araghi, Bernt Schiele, Jonas Fischer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13798v1",
    "source": "arXiv",
    "abstract": "Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight."
  },
  {
    "date": "2026-01-20",
    "title": "Gradient Flow for Finding E-optimal Designs",
    "authors": "Jieling Shi, Kim-Chuan Toh, Xin T. Tong, Weng Kee Wong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14147v1",
    "source": "arXiv",
    "abstract": "We investigate the use of Wasserstein gradient flows for finding an $E$-optimal design for a regression model. Unlike the commonly used $D$- and $L$-optimality criteria, the $E$-criterion finds a design that maximizes the smallest eigenvalue of the information matrix, and so it is a non-differentiable criterion unless the minimum eigenvalue has geometric multiplicity equals to one. Such maximin design problems abound in statistical applications and present unique theoretical and computational challenges. Building on the differential structure of the $2$-Wasserstein space, we derive explicit formulas for the Wasserstein gradient of the $E$-optimality criterion in the simple-eigenvalue case. For higher multiplicities, we propose a Wasserstein steepest ascent direction and show that it can be computed exactly via a semidefinite programming (SDP) relaxation. We develop particle approximations that connect infinite-dimensional flows with finite-dimensional optimization, and provide approximation guarantees for empirical measures. Our framework extends naturally to constrained designs via projected Wasserstein gradient flows. Numerical experiments demonstrate that the proposed methods successfully recover $E$-optimal designs for both linear and nonlinear regression models, with competitive accuracy and scalability compared to existing heuristic approaches. This work highlights the potential of optimal transport-based dynamics as a unifying tool for studying challenging optimal design problems."
  },
  {
    "date": "2026-01-20",
    "title": "Universality of the Basilica",
    "authors": "Yusheng Luo, Mahan Mj, Sabyasachi Mukherjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13553v1",
    "source": "arXiv",
    "abstract": "We establish universality of the fat Basilica Julia set $J(z^2-\\frac34)$ in conformal dynamics in the following sense: $J(z^2-\\frac34)$ is quasiconformally equivalent to the fat Basilica Julia set of any polynomial as well as to the limit set of any geometrically finite closed surface Bers boundary group. We thus obtain the first example of a connected rational Julia set, not homeomorphic to the circle or the sphere, that is quasiconformally equivalent to a Kleinian limit set. It follows that any geometrically finite Bers boundary limit set is conformally removable. Other consequences of this universality result include quasi-symmetric uniformization of polynomial fat Basilicas by round Basilicas, and the existence of infinitely many non-commensurable uniformly quasi-symmetric surface subgroups of the Basilica quasi-symmetry group. We apply our techniques to cuspidal Basilica Julia sets arising from Schwarz reflections and cubic polynomials, yielding further universality classes. We also show that the standard Basilica Julia set $J(z^2-1)$ is the archbasilica in the David hierarchy."
  },
  {
    "date": "2026-01-20",
    "title": "Correction of Pooling Matrix Mis-specifications in Compressed Sensing Based Group Testing",
    "authors": "Shuvayan Banerjee, Radhendushka Srivastava, James Saunderson, Ajit Rajwade",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13641v1",
    "source": "arXiv",
    "abstract": "Compressed sensing, which involves the reconstruction of sparse signals from an under-determined linear system, has been recently used to solve problems in group testing. In a public health context, group testing aims to determine the health status values of p subjects from n<<p pooled tests, where a pool is defined as a mixture of small, equal-volume portions of the samples of a subset of subjects. This approach saves on the number of tests administered in pandemics or other resource-constrained scenarios. In practical group testing in time-constrained situations, a technician can inadvertently make a small number of errors during pool preparation, which leads to errors in the pooling matrix, which we term `model mismatch errors' (MMEs). This poses difficulties while determining health status values of the participating subjects from the results on n<<p pooled tests. In this paper, we present an algorithm to correct the MMEs in the pooled tests directly from the pooled results and the available (inaccurate) pooling matrix. Our approach then reconstructs the signal vector from the corrected pooling matrix, in order to determine the health status of the subjects. We further provide theoretical guarantees for the correction of the MMEs and the reconstruction error from the corrected pooling matrix. We also provide several supporting numerical results."
  },
  {
    "date": "2026-01-20",
    "title": "The Limits of Conditional Volatility: Assessing Cryptocurrency VaR under EWMA and IGARCH Models",
    "authors": "Ekleen Kaur",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13757v1",
    "source": "arXiv",
    "abstract": "The application of the standard static Geometric Brownian Motion (GBM) model for cryptocurrency risk management resulted in a systemic failure, evidenced by a 80.67% chance of loss in the 5% value-at-risk benchmark. This study addresses a critical literature gap by comparatively testing three conditional volatility models the EWMA/IGARCH baseline, an IGARCH model augmented with explicit mean reversion (IGARCH + MR), and a modified EGARCH-style asymmetric shock model within a correlated Monte Carlo VaR framework. Crucially, the analysis is applied specifically to high-beta altcoins (XRP, SOL, ADA), an asset class largely neglected by mainstream GARCH literature. Our results demonstrate that imposing stationarity (IGARCH + MR) drastically underestimates downside risk (5 percent value-at-risk reduced by 50%), while the asymmetric model (Model 3) leads to severe over-penalization. The EWMA/IGARCH baseline, characterized by infinite volatility persistence (alpha + beta = 1), provided the only robust conditional volatility estimate. This finding constitutes a formal rejection of the conventional financial hypotheses of volatility mean reversion and the asymmetric leverage effect in the altcoin asset class, establishing that non-stationary frameworks are a prerequisite for regulatory-grade risk modeling in this domain."
  },
  {
    "date": "2026-01-20",
    "title": "Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues",
    "authors": "Arjun Chandra, Kevin Miller, Venkatesh Ravichandran, Constantinos Papayiannis, Venkatesh Saligrama",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13742v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation."
  },
  {
    "date": "2026-01-20",
    "title": "Some Consequences of the Grunewald-O'Halloran Conjecture for Pseudoquonic Operators",
    "authors": "Fabio Bagarello, Yanga Bavuma, Francesco G. Russo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13736v1",
    "source": "arXiv",
    "abstract": "Investigating a recent positive solution of a conjecture of Grunewald and O'Halloran for complex finite dimensional nilpotent Lie algebras, we are in the position to find results of existence and uniqueness for the construction of complex nilpotent Lie algebras of arbitrary dimension via pseudobosonic operators. We involve the so-called theory of the deformation of Lie algebras of Gerstenhaber, in order to prove our main results. There isn't a generalized version of the Grunewald-O'Halloran Conjecture when we consider pseudoquonic operators, which specialize to pseudobosonic operators in many cirumstances. Therefore we prove a result of existence (and a direct construction) of pseudobosonic $O^*$-algebras of operators, but leave open the problem of the uniqueness of the construction."
  },
  {
    "date": "2026-01-20",
    "title": "Towards robust long-context understanding of large language model via active recap learning",
    "authors": "Chenyu Hui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13734v1",
    "source": "arXiv",
    "abstract": "In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM"
  },
  {
    "date": "2026-01-20",
    "title": "Large magneto-optical Kerr effect induced by collinear antiferromagnetic order",
    "authors": "H. Yoshimochi, K. Yoshida, R. Oiwa, T. Nomoto, N. D. Khanh, A. Kitaori, R. Takagi, R. Arita, S. Seki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13723v1",
    "source": "arXiv",
    "abstract": "In modern technology, the optical readout of magnetic information is conventionally achieved by the magneto-optical Kerr effect, i.e., the polarization rotation of reflected light. The Kerr rotation is sensitive to time-reversal symmetry breaking and generally proportional to magnetization, enabling optical readout of the up and down spin states in ferromagnets. By contrast, antiferromagnets with a collinear antiparallel spin arrangement have long been considered inactive to such magneto-optical responses, because of Tt-symmetry (time-reversal T followed by translation t symmetry) and lack of macroscopic magnetization. Here, we report the observation of giant magneto-optical Kerr effect in a room-temperature antiferromagnetic insulator alpha-Fe2O3. In this compound, the up-down and down-up spin states induce the opposite sign of spontaneous Kerr effect, whose Kerr rotation angle turned out to be exceptionally large (~ 80 mdeg, comparable to typical ferromagnets). Our first-principles calculations successfully reproduce both the absolute magnitude and spectral shape of the Kerr rotation and ellipticity with remarkable accuracy, which unambiguously proves that it originates from a Tt-symmetry-broken collinear antiferromagnetic order, rather than magnetization. This compound hosts temperature-dependent transition between easy-plane and easy-axis antiferromagnetic states, and their contrasting behaviors are also investigated in detail. The present results demonstrate that even a simple collinear antiferromagnetic order can induce a giant magneto-optical Kerr effect, and highlight Tt-symmetry-broken antiferromagnets as a promising material platform for highly sensitive optical detection of up-down and down-up spin states."
  },
  {
    "date": "2026-01-20",
    "title": "OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents",
    "authors": "Yulin Hu, Zimo Long, Jiahe Guo, Xingyu Sui, Xing Fu, Weixiang Zhao, Yanyan Zhao, Bing Qin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13722v1",
    "source": "arXiv",
    "abstract": "Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \\emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \\textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \\textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \\textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems."
  },
  {
    "date": "2026-01-20",
    "title": "On the Birkhoff Spectrum for Hyperbolic Dynamics",
    "authors": "Sergio Romaña",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13720v1",
    "source": "arXiv",
    "abstract": "In this paper, we study the structure of Birkhoff spectra for hyperbolic dynamical systems. For a Hölder observable $f$ on a basic set $Λ$, we prove that if the Birkhoff sums take both positive and negative values, then the Birkhoff spectrum $\\mathcal{B}(f,\\varphi,Λ)$ is dense in $\\mathbb{R}$. This extends the density result of Gan, Shi, and Xia \\cite{Shaobo} from transitive Anosov diffeomorphisms in infranilmanifolds to general basic sets, and yields new density theorems for Axiom~A systems, including Anosov diffeos.\\\\ Conversely, when the spectrum is not dense, we characterize \\emph{concentrated} observables, whose spectrum is confined to one side of zero. For these, we establish two rigidity results: (i) boundedness of the spectrum is equivalent to the function being cohomologous to a zero, which constitutes an extension of the Liv\\v sic theorem; (ii) if the spectrum exhibits an arithmetic structure, the function is cohomologous to a constant. Finally, we extend the results to continuous time. For Anosov flows$-$ including geodesic flows on Anosov manifolds$-$we obtain analogous density results for Birkhoff integrals along closed orbits. In particular, we generalize a theorem of Dairbekov--Sharafutdinov (\\cite{Dairbekov}) by showing that a bounded or ``arithmetically sparse'' spectrum forces a smooth function to vanish or be constant, respectively."
  },
  {
    "date": "2026-01-20",
    "title": "Flash Freeze--Thaw Phenomenon in Sprayed Evaporating Micrometer Droplets",
    "authors": "Junshi Wang, Zehao Pan, Howard A. Stone, Maksim Mezhericher",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13716v1",
    "source": "arXiv",
    "abstract": "Two-fluid spray nozzles are widely used in combustion, chemical processing, pharmaceutical coating, environmental control, and spray drying to atomize liquids with pressurized gas. However, the adiabatic cooling and resulting flash freeze--thaw exposure of atomized droplets remain underexplored. Using high-fidelity computational fluid dynamics coupled with droplet-scale nucleation modeling, we show that the atomizing gas temperature at the nozzle exit can fall from $22\\,^{\\circ}\\mathrm{C}$ to below $-130\\,^{\\circ}\\mathrm{C}$, initiating rapid ice nucleation and freezing in micro-scale droplets. For atomizing gas at $5\\,\\mathrm{bar}$ (gauge) and $22\\,^{\\circ}\\mathrm{C}$, all droplets smaller than $1.5\\,μ\\mathrm{m}$ freeze, whereas droplets larger than $3\\,μ\\mathrm{m}$ remain liquid. These frozen droplets thaw within $O(10)\\,μ\\mathrm{s}$ upon leaving the cold zone, subjecting sensitive actives to intense freeze--thaw thermomechanical stresses near the nozzle even when the bulk drying gas is warm. Parametric studies show that ice formation is eliminated at atomizing gas temperatures above $110\\,^{\\circ}\\mathrm{C}$ for all gas-to-liquid mass ratios (GLRs) between 8 and 25, or at $\\mathrm{GLR}<12$ for all atomizing gas temperatures; the chamber drying gas does not influence near-nozzle freezing. Additionally, we demonstrate that swirling flow intensifies flash freeze--thaw by deepening gas cooling, whereas non-swirling flow extends cold-zone residence time, yet both designs produce similar iced-droplet fractions. We construct an operating map delineating conditions that avoid flash freeze--thaw and show that the no-ice boundary provides a conservative criterion for both swirl and non-swirl nozzles. These findings identify a previously unrecognized freeze--thaw stress mechanism that can compromise spray-dried pharmaceutical product stability."
  },
  {
    "date": "2026-01-20",
    "title": "Cost-Effectiveness of Adult Hepatitis A Vaccination Strategies in Korea Under an Aging Susceptibility Profile",
    "authors": "Yuna Lim, Gerardo Chowell, Eunok Jung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13714v1",
    "source": "arXiv",
    "abstract": "Hepatitis A severity increases sharply with age, while Korea is experiencing a cohort shift in which low seroprevalence adult cohorts are aging into older, higher fatality age groups. This demographic and immunological transition creates an urgent policy question regarding how adult vaccination should be prioritized under resource constraints. We evaluated three adult vaccination scenarios targeting low seroprevalence age groups (S1) 20 to 39 years, (S2) 40 to 59 years, and (S3) 20 to 59 years. Using an age structured dynamic transmission model calibrated to Korean data, we derived dynamically feasible vaccination allocation trajectories under realistic capacity constraints using an optimal control framework and linked these trajectories to long term transmission model simulations. We conducted DALY based cost effectiveness analyses over a lifetime horizon from both healthcare system and societal perspectives, and characterized uncertainty using probabilistic sensitivity analysis (PSA) and cost effectiveness acceptability curves (CEACs). Robustness was examined using one way sensitivity analyses. In the base case, S2 consistently yields the most favorable and robust cost effectiveness profile under both perspectives, with the lowest ICER. S3 achieved the largest reduction in DALYs but requires substantially higher incremental costs, resulting in a higher ICER than S2. S1 produces the smallest DALY reduction and is the least efficient strategy. PSA and CEACs confirm that S2 remains the preferred option across most willingness to pay ranges. S2 offers the most balanced and robustly cost effective strategy in Korea, capturing substantial mortality reduction while limiting additional program costs. S3 may be justified when higher budgets or willingness to pay thresholds are acceptable, but S2 provides the clearest value for money under epidemiological and economic conditions."
  },
  {
    "date": "2026-01-20",
    "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games",
    "authors": "Christopher Kao, Vanshika Vats, James Davis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13709v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts."
  },
  {
    "date": "2026-01-20",
    "title": "Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles",
    "authors": "Maria Lymperaiou, Vasileios Karampinis, Giorgos Filandrianos, Angelos Vlachos, Chrysoula Zerva, Athanasios Voulodimos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13705v1",
    "source": "arXiv",
    "abstract": "Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems."
  },
  {
    "date": "2026-01-20",
    "title": "Performance and Complexity Trade-off Optimization of Speech Models During Training",
    "authors": "Esteban Gómez, Tom Bäckström",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13704v1",
    "source": "arXiv",
    "abstract": "In speech machine learning, neural network models are typically designed by choosing an architecture with fixed layer sizes and structure. These models are then trained to maximize performance on metrics aligned with the task's objective. While the overall architecture is usually guided by prior knowledge of the task, the sizes of individual layers are often chosen heuristically. However, this approach does not guarantee an optimal trade-off between performance and computational complexity; consequently, post hoc methods such as weight quantization or model pruning are typically employed to reduce computational cost. This occurs because stochastic gradient descent (SGD) methods can only optimize differentiable functions, while factors influencing computational complexity, such as layer sizes and floating-point operations per second (FLOP/s), are non-differentiable and require modifying the model structure during training. We propose a reparameterization technique based on feature noise injection that enables joint optimization of performance and computational complexity during training using SGD-based methods. Unlike traditional pruning methods, our approach allows the model size to be dynamically optimized for a target performance-complexity trade-off, without relying on heuristic criteria to select which weights or structures to remove. We demonstrate the effectiveness of our method through three case studies, including a synthetic example and two practical real-world applications: voice activity detection and audio anti-spoofing. The code related to our work is publicly available to encourage further research."
  },
  {
    "date": "2026-01-20",
    "title": "IGAA: Intent-Driven General Agentic AI for Edge Services Scheduling using Generative Meta Learning",
    "authors": "Yan Sun, Yinqiu Liu, Shaoyong Guo, Ruichen Zhang, Feng Qi, Xuesong Qiu, Weifeng Gong, Dusit Niyato, Qihui Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13702v1",
    "source": "arXiv",
    "abstract": "Agentic AI (AAI), which extends Large Language Models with enhanced reasoning capabilities, has emerged as a promising paradigm for autonomous edge service scheduling. However, user mobility creates highly dynamic service demands in edge networks, and existing service scheduling agents often lack generalization capabilities for new scenarios. Therefore, this paper proposes a novel Intent-Driven General Agentic AI (IGAA) framework. Leveraging a meta-learning paradigm, IGAA enables AAI to continuously learn from prior service scheduling experiences to achieve generalized scheduling capabilities. Particularly, IGAA incorporates three core mechanisms. First, we design a Network-Service-Intent matrix mapping method to allow agents to simulate novel scenarios and generate training datasets. Second, we present an easy-to-hard generalization learning scheme with two customized algorithms, namely Resource Causal Effect-aware Transfer Learning (RCETL) and Action Potential Optimality-aware Transfer Learning (APOTL). These algorithms help IGAA adapt to new scenarios. Furthermore, to prevent catastrophic forgetting during continual IGAA learning, we propose a Generative Intent Replay (GIR) mechanism that synthesizes historical service data to consolidate prior capabilities. Finally, to mitigate the effect of LLM hallucinations on scenario simulation, we incorporate a scenario evaluation and correction model to guide agents in generating rational scenarios and datasets. Extensive experiments demonstrate IGAA's strong generalization and scalability. Specifically, IGAA enables rapid adaptation by transferring learned policies to analogous new ones, such as applying latency-sensitive patterns from real-time computing to optimize novel Internet of Vehicles (IoV) services. Compared to scenario-specific methods, IGAA maintains the intent-satisfaction rate gap within 3.81%."
  },
  {
    "date": "2026-01-20",
    "title": "Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation",
    "authors": "Arjun Nichani, Hsiang Hsu, Chun-Fu, Chen, Haewon Jeong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13698v1",
    "source": "arXiv",
    "abstract": "Fairness and privacy are two vital pillars of trustworthy machine learning. Despite extensive research on these individual topics, the relationship between fairness and privacy has received significantly less attention. In this paper, we utilize the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among the triad of fairness, privacy, and accuracy. We first define Noisy Chernoff Difference, a tool that allows us to analyze the relationship among the triad simultaneously. We then show that for synthetic data, this value behaves in 3 distinct ways (depending on the distribution of the data). We highlight the data distributions involved in these cases and explore their fairness and privacy implications. Additionally, we show that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, we propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature."
  },
  {
    "date": "2026-01-20",
    "title": "Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning",
    "authors": "Yue Guo, Fanfu Wang, Jianwei Lv, Xincheng Shi, Yuchen Li, Youya Wang, Yunsheng Zeng, Yujing Liu, Yunhao Qiao, Gen Li, Junfeng Wang, Bo Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13690v1",
    "source": "arXiv",
    "abstract": "Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance."
  },
  {
    "date": "2026-01-20",
    "title": "Accelerator and Brake: Dynamic Persuasion with Dead Ends",
    "authors": "Zhuo Chen, Yun Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13686v1",
    "source": "arXiv",
    "abstract": "We study optimal dynamic persuasion in a bandit experimentation model where a principal, unlike in standard settings, has a single-peaked preference over the agent's stopping time. This non-monotonic preference arises because maximizing the agent's effort is not always in the principal's best interest, as it may lead to a dead end. The principal privately observes the agent's payoff upon success and uses the information as the instrument of incentives. We show that the optimal dynamic information policy involves at most two one-shot disclosures: an accelerator before the principal's optimal stopping time, persuading the agent to be optimistic, and a brake after the principal's optimal stopping time, persuading the agent to be pessimistic. A key insight of our analysis is that the optimal disclosure pattern -- whether gradual or one-shot -- depends on how the principal resolves a trade-off between the mean of stopping times and its riskiness. We identify the Arrow-Pratt coefficient of absolute risk aversion as a sufficient statistic for determining the optimal disclosure structure."
  },
  {
    "date": "2026-01-20",
    "title": "HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference",
    "authors": "Zhiyuan Shi, Qibo Qiu, Feng Xue, Zhonglin Jiang, Li Yu, Jian Jiang, Xiaofei He, Wenxiao Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13684v1",
    "source": "arXiv",
    "abstract": "The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\\times$ compared to the original model in the 224K context. Our code will be open-source."
  },
  {
    "date": "2026-01-20",
    "title": "Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation",
    "authors": "Boyuan Cao, Xingbo Yao, Chenhui Wang, Jiaxin Ye, Yujie Wei, Hongming Shan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13683v1",
    "source": "arXiv",
    "abstract": "Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential."
  },
  {
    "date": "2026-01-20",
    "title": "CodeContests-O: Powering LLMs via Feedback-Driven Iterative Test Case Generation",
    "authors": "Jianfeng Cai, Jinhua Zhu, Ruopei Sun, Kangwen Zhao, Dongyun Xue, Mingxiao Feng, Wengang Zhou, Houqiang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13682v1",
    "source": "arXiv",
    "abstract": "The rise of reasoning models necessitates large-scale verifiable data, for which programming tasks serve as an ideal source. However, while competitive programming platforms provide abundant problems and solutions, high-quality test cases for verification remain scarce. Existing approaches attempt to synthesize test cases using Large Language Models (LLMs), but rely solely on the model's intrinsic generation capabilities without external feedback, frequently resulting in insufficiently diverse cases. To address this limitation, we propose a $\\textbf{Feedback-Driven Iterative Framework}$ for comprehensive test case construction. Specifically, our method leverages the LLM to generate initial test cases, executes them against known correct and incorrect solutions, and utilizes the failed results as feedback to guide the LLM in refining the test cases toward high fidelity and discriminability. We then apply this method to the CodeContests dataset to construct an optimized high-quality derivative, $\\textbf{CodeContests-O}$. Evaluating against the entire pool of solutions ($1.1 \\times 10^7$ in total), our dataset achieves an average True Positive Rate (TPR) of $89.37\\%$ and True Negative Rate (TNR) of $90.89\\%$, significantly outperforming the CodeContests and CodeContests+ by margins of $4.32\\%$ and $9.37\\%$, respectively. Furthermore, fine-tuning the Qwen2.5-7B model on CodeContests-O results in a $9.52\\%$ improvement on LiveCodeBench (Pass@1). Experiments demonstrate the effectiveness of our framework and the quality of CodeContests-O. To support reproducibility and facilitate future research, we release the $\\href{https://github.com/cai-jianfeng/CodeContests-O}{code}$ and $\\href{https://huggingface.co/datasets/caijanfeng/CodeContests-O}{dataset}$."
  },
  {
    "date": "2026-01-20",
    "title": "TSN-IoT: A Two-Stage NOMA-Enabled Framework for Prioritized Traffic Handling in Dense IoT Networks",
    "authors": "Shama Siddiqui, Anwar Ahmed Khan, Nicola Marchetti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13680v1",
    "source": "arXiv",
    "abstract": "With the growing applications of the Internet of Things (IoT), a major challenge is to ensure continuous connectivity while providing prioritized access. In dense IoT scenarios, synchronization may be disrupted either by the movement of nodes away from base stations or by the unavailability of reliable Global Navigation Satellite System (GNSS) signals, which can be affected by physical obstructions, multipath fading, or environmental interference, such as such as walls, buildings, moving objects, or electromagnetic noise from surrounding devices. In such contexts, distributed synchronization through Non-Orthogonal Multiple Access (NOMA) offers a promising solution, as it enables simultaneous transmission to multiple users with different power levels, supporting efficient synchronization while minimizing the signaling overhead. Moreover, NOMA also plays a vital role for dynamic priority management in dense and heterogeneous IoT environments. In this article, we proposed a Two-Stage NOMA-Enabled Framework \"TSN-IoT\" that integrates the mechanisms of conventional Precision Time Protocol (PTP) based synchronization, distributed synchronization and data transmission. The framework is designed as a four-tier architecture that facilitates prioritized data delivery from sensor nodes to the central base station. We demonstrated the performance of \"TSN-IoT\" through a healthcare use case, where intermittent connectivity and varying data priority levels present key challenges for reliable communication. Synchronization speed and end-to-end delay were evaluated through a series of simulations implemented in Python. Results show that, compared to priority-based Orthogonal Frequency Division Multiple Access (OFDMA), TSN-IoT achieves significantly better performance by offering improved synchronization opportunities and enabling parallel transmissions over the same sub-carrier."
  },
  {
    "date": "2026-01-20",
    "title": "Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging",
    "authors": "Carsten T. Lüth, Jeremias Traub, Kim-Celine Kahl, Till J. Bungert, Lukas Klein, Lars Krämer, Paul F. Jäger, Klaus Maier-Hein, Fabian Isensee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13677v1",
    "source": "arXiv",
    "abstract": "Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive."
  },
  {
    "date": "2026-01-20",
    "title": "The ALMA survey to Resolve exoKuiper belt Substructures (ARKS) II. The radial structure of debris discs",
    "authors": "Yinuo Han, Elias Mansell, Jeff Jennings, Sebastian Marino, A. Meredith Hughes, Brianna Zawadzki, Anna Fehr, Jamar Kittling, Catherine Hou, Aliya Nurmohamed, Junu Lee, Allan Cheruiyot, Yamani Mpofu, Mark Booth, Richard Booth, Myriam Bonduelle, Aoife Brennan, Carlos del Burgo, John M. Carpenter, Gianni Cataldi, Eugene Chiang, Steve Ertel, Thomas Henning, Marija R. Jankovic, Ágnes Kóspál, Alexander V. Krivov, Joshua B. Lovell, Patricia Luppe, Meredith A. MacGregor, Sorcha Mac Manamon, Jonathan P. Marshall, Luca Matrà, Julien Milli, Attila Moór, Johan Olofsson, Tim Pearce, Sebastián Pérez, Antranik A. Sefilian, Philipp Weber, David J. Wilner, Mark C. Wyatt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13670v1",
    "source": "arXiv",
    "abstract": "The ALMA survey to Resolve exoKuiper belt Substructures (ARKS) was recently completed to cover the lack of high-resolution observations of debris discs and to investigate the prevalence of substructures such as radial gaps and rings in a sample of 24 discs. This study characterises the radial structure of debris discs in the ARKS programme. To identify and quantify the disc substructures, we modelled all discs with a range of non-parametric and parametric approaches. We find that of the 24 discs in the sample, 5 host multiple rings, 7 are single rings that display halos or additional low-amplitude rings, and 12 are single rings with at most tentative evidence of additional substructures. The fractional ring widths that we measured are significantly narrower than previously derived values, and they follow a distribution similar to the fractional widths of individual rings resolved in protoplanetary discs. However, there exists a population of rings in debris discs that are significantly wider than those in protoplanetary discs. We also find that discs with steep inner edges consistent with planet sculpting tend to be found at smaller (<100 au) radii, while more radially extended discs tend to have shallower edges more consistent with collisional evolution. An overwhelming majority of discs have radial profiles well-described by either a double power law or double-Gaussian parametrisation. While our findings suggest that it may be possible for some debris discs to inherit their structures directly from protoplanetary discs, there exists a sizeable population of broad debris discs that cannot be explained in this way. Assuming that the distribution of millimetre dust reflects the distribution of planetesimals, mechanisms that cause rings in protoplanetary discs to migrate or debris discs to broaden soon after formation may be at play, possibly mediated by planetary migration or scattering."
  },
  {
    "date": "2026-01-20",
    "title": "Pairing correlations, orientations and quantum fluctuations in one- and two-nucleon transfer reactions at sub-barrier energies",
    "authors": "Dandan Zhang, Bo Li, Dario Vretenar, Tamara Nikšić, Pengwei Zhao, Jie Meng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13667v1",
    "source": "arXiv",
    "abstract": "This work investigates one- and two-neutron transfer in the $^{96}\\text{Zr} + {}^{40}\\text{Ca}$ reaction at sub-barrier energies using a microscopic framework based on time-dependent covariant density functional theory (TD-CDFT). Pairing correlations are incorporated via the time-dependent BCS approximation, which is shown to significantly enhance pair transfer, as evidenced by an increased two-neutron transfer probability. The oblate deformation of $^{96}$Zr causes the transfer probabilities to vary by orders of magnitude with orientation; a direct comparison with experiment is enabled by averaging results over thirteen systematically chosen orientations. While the orientation-averaged one-neutron transfer probabilities agree well with data, the two-neutron channel is suppressed below the Coulomb barrier. This suppression is attributed to missing quantum fluctuations in the semiclassical TD-CDFT approach. To test this, we employ the generalized time-dependent generator coordinate method (TDGCM), which confirms that quantum fluctuations are essential for an accurate description of sub-barrier two-neutron transfer dynamics."
  },
  {
    "date": "2026-01-20",
    "title": "Reinforcement Learning for Opportunistic Routing in Software-Defined LEO-Terrestrial Systems",
    "authors": "Sivaram Krishnan, Zhouyou Gu, Jihong Park, Sung-Min Oh, Jinho Choi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13662v1",
    "source": "arXiv",
    "abstract": "The proliferation of large-scale low Earth orbit (LEO) satellite constellations is driving the need for intelligent routing strategies that can effectively deliver data to terrestrial networks under rapidly time-varying topologies and intermittent gateway visibility. Leveraging the global control capabilities of a geostationary (GEO)-resident software-defined networking (SDN) controller, we introduce opportunistic routing, which aims to minimize delivery delay by forwarding packets to any currently available ground gateways rather than fixed destinations. This makes it a promising approach for achieving low-latency and robust data delivery in highly dynamic LEO networks. Specifically, we formulate a constrained stochastic optimization problem and employ a residual reinforcement learning framework to optimize opportunistic routing for reducing transmission delay. Simulation results over multiple days of orbital data demonstrate that our method achieves significant improvements in queue length reduction compared to classical backpressure and other well-known queueing algorithms."
  },
  {
    "date": "2026-01-20",
    "title": "Fusion Segment Transformer: Bi-Directional Attention Guided Fusion Network for AI-Generated Music Detection",
    "authors": "Yumin Kim, Seonghyeon Go",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13647v1",
    "source": "arXiv",
    "abstract": "With the rise of generative AI technology, anyone can now easily create and deploy AI-generated music, which has heightened the need for technical solutions to address copyright and ownership issues. While existing works mainly focused on short-audio, the challenge of full-audio detection, which requires modeling long-term structure and context, remains insufficiently explored. To address this, we propose an improved version of the Segment Transformer, termed the Fusion Segment Transformer. As in our previous work, we extract content embeddings from short music segments using diverse feature extractors. Furthermore, we enhance the architecture for full-audio AI-generated music detection by introducing a Gated Fusion Layer that effectively integrates content and structural information, enabling the capture of long-term context. Experiments on the SONICS and AIME datasets show that our approach outperforms the previous model and recent baselines, achieving state-of-the-art results in AI-generated music detection."
  },
  {
    "date": "2026-01-20",
    "title": "Theory for Entangled-Photons Stimulated Raman Scattering versus Nonlinear Absorption for Polyatomic Molecules",
    "authors": "Mingran Zhang, Jiahao Joel Fan, Frank Schlawin, Zhedong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13646v1",
    "source": "arXiv",
    "abstract": "Quantum entanglement offers an incredible resource for enhancing the sensing and spectroscopic probes. Here we develop a microscopic theory for the stimulated Raman scattering (SRS) using entangled photons. We demonstrate that the time-energy correlation of the photon pairs can optimize the signal for polyatomic molecules. Our results show that the spectral-line intensity of the entangled-photon SRS (ESRS) is of the same order of magnitude as the one for the entangled two-photon absorption (ETPA); the parameter window is thus identified to do so. Moreover, the vibrational coherence is found to play an important role for enhancing the ESRS against the ETPA intensity. Our work paves a firm road for extending the schemes of molecular spectroscopy with quantum light, based on the observation of the ETPA in experiments."
  },
  {
    "date": "2026-01-20",
    "title": "Borcherds products approximating Gersten complex",
    "authors": "Shouhei Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13643v1",
    "source": "arXiv",
    "abstract": "For an orthogonal modular variety, we construct a complex which is defined in terms of lattices and elliptic modular forms, which resembles the Gersten complex in Milnor K-theory, and which has a morphism to the Gersten complex of the modular variety by the Borcherds lifting. This provides a formalism for approaching the higher Chow groups of the modular variety by special cycles and Borcherds products. The construction is an incorporation of the theory of Borcherds products and ideas from Milnor K-theory."
  },
  {
    "date": "2026-01-20",
    "title": "Discrimination of $H\\rightarrow Zγ\\rightarrow \\ell^{+}\\ell^{-}γ$ from $Z/γ^*$ Processes Using Kinematically Correlated Observables",
    "authors": "Manisha Kumari, Amal Sarkar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13640v1",
    "source": "arXiv",
    "abstract": "At LHC energies, the Drell--Yan ($Z/γ^{*}$) processes have a substantially large cross section. Their di-lepton ($\\ell^+\\ell^-$) final state contributes significantly to many resonant signal regions, making them one of the dominant backgrounds in numerous physics analyses. The study focuses on improving the discrimination and suppression of the $Z/γ^{*} \\rightarrow \\ell^{+}\\ell^{-}$ background from the $H \\rightarrow Zγ\\rightarrow \\ell^{+}\\ell^{-}γ$ signal at $\\sqrt{s}=13~\\text{TeV}$ by leveraging Monte Carlo simulated data. The analysis introduces physics-motivated correlated observables derived from the two-dimensional $(P_{\\mathrm{Higgs}}, θ_{Zγ})$ plane. These observables encode differences in angular and momentum information to enhance signal--background separation while maintaining high signal efficiency. We present a multivariate analysis (MVA) employing a Boosted Decision Tree (XGBoost) classifier. By incorporating additional physics-motivated correlated observables, the classifier achieves measurable improvements in performance. A significant increase in the area under the ROC curve (AUC) is observed in both the electron and muon channels, demonstrating the effectiveness of the expanded feature set. Further, optimised background rejection using $(P_{\\mathrm{Higgs}}, θ_{Zγ})$ plane increases the signal-to-background ratio to 2.1\\% and 3.4\\% for the electron and muon channel respectively near the Higgs mass. This work demonstrates that combining kinematic correlations with interpretable multivariate techniques leads to improved sensitivity and robust background rejection. The approach is flexible and can be readily applied to a wide range of analyses, including rare Higgs decays, resonant searches, and studies beyond the Standard Model."
  },
  {
    "date": "2026-01-20",
    "title": "Scaling Test-time Inference for Visual Grounding",
    "authors": "Guanqi Zhan, Changye Li, Zhijian Liu, Yao Lu, Yi Wu, Song Han, Ligeng Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13633v1",
    "source": "arXiv",
    "abstract": "Visual grounding is an essential capability of Visual Language Models (VLMs) to understand the real physical world. Previous state-of-the-art grounding visual language models usually have large model sizes, making them heavy for deployment and slow for inference. However, we notice that the sizes of visual encoders are nearly the same for small and large VLMs and the major difference is the sizes of the language models. Small VLMs fall behind larger VLMs in grounding because of the difference in language understanding capability rather than visual information handling. To mitigate the gap, we introduce 'Efficient visual Grounding language Models' (EGM): a method to scale the test-time computation (#generated tokens). Scaling the test-time computation of a small model is deployment-friendly, and yields better end-to-end latency as the cost of each token is much cheaper compared to directly running a large model. On the RefCOCO benchmark, our EGM-Qwen3-VL-8B demonstrates 91.4 IoU with an average of 737ms (5.9x faster) latency while Qwen3-VL-235B demands 4,320ms to achieve 90.5 IoU. To validate our approach's generality, we further set up a new amodal grounding setting that requires the model to predict both the visible and occluded parts of the objects. Experiments show our method can consistently and significantly improve the vanilla grounding and amodal grounding capabilities of small models to be on par with or outperform the larger models, thereby improving the efficiency for visual grounding."
  },
  {
    "date": "2026-01-20",
    "title": "PRIMAL: Processing-In-Memory Based Low-Rank Adaptation for LLM Inference Accelerator",
    "authors": "Yue Jiet Chong, Yimin Wang, Zhen Wu, Xuanyao Fong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13628v1",
    "source": "arXiv",
    "abstract": "This paper presents PRIMAL, a processing-in-memory (PIM) based large language model (LLM) inference accelerator with low-rank adaptation (LoRA). PRIMAL integrates heterogeneous PIM processing elements (PEs), interconnected by 2D-mesh inter-PE computational network (IPCN). A novel SRAM reprogramming and power gating (SRPG) scheme enables pipelined LoRA updates and sub-linear power scaling by overlapping reconfiguration with computation and gating idle resources. PRIMAL employs optimized spatial mapping and dataflow orchestration to minimize communication overhead, and achieves $1.5\\times$ throughput and $25\\times$ energy efficiency over NVIDIA H100 with LoRA rank 8 (Q,V) on Llama-13B."
  },
  {
    "date": "2026-01-20",
    "title": "Joint constraints on cosmic birefringence and early dark energy from ACT, Planck, DESI, and PantheonPlus",
    "authors": "Lu Yin, Guo-Hong Du, Tian-Nuo Li, Xin Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13624v1",
    "source": "arXiv",
    "abstract": "With the increasing number of high-precision astronomical observations, physical quantities that were previously inaccessible to accurate calculations, such as cosmic birefringence, have once again become a focal point of interest. Such phenomena induce a nonvanishing cross-correlation between the $E$- and $B$-mode polarizations of the cosmic microwave background (CMB), thereby providing a direct observational signature of parity violation. The Chern-Simons coupling between the scalar field in early dark energy (EDE) models and CMB photons is regarded as a plausible mechanism for generating cosmic birefringence. Recent data from the Atacama Cosmology Telescope (ACT) deliver $EB$ measurements at higher multipole moments than those previously achieved by {Planck}, while DESI and PantheonPlus datasets provide new and stringent constraints on the late-time expansion history. Using a joint analysis of {Planck}, DESI DR1, Pantheon+, and ACT data, we perform a full-parameter constraint on the cosmic birefringence effects induced by the EDE-CMB photon coupling. Our results favor a higher Hubble constant, $H_0 = 76.9^{+2.9}_{-2.5}\\,\\rm km\\,s^{-1}\\,Mpc^{-1}$, and a relatively large EDE fraction, $f_{\\mathrm{EDE}} = 0.232^{+0.074}_{-0.047}$. By comparing the cosmological evolution of this model across different data combinations, we find that the ACT-$EB$ data combined with {Planck} + DESI + PantheonPlus provide good constraints to both early- and late-Universe observations."
  },
  {
    "date": "2026-01-20",
    "title": "Layer Decoupling in Twisted Bilayer WSe$_2$ Uncovered by Automated Dark-Field Tomography",
    "authors": "A. Nakamura, Y. Chiashi, T. Shimojima, Y. Tanaka, S. Akatsuka, M. Sakano, S. Masubuchi, T. Machida, K. Watanabe, T. Taniguchi, K. Ishizaka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13620v1",
    "source": "arXiv",
    "abstract": "Twisted bilayer systems host a wealth of emergent phenomena, such as flat-band superconductivity, ferromagnetism, and ferroelectricity, arising from moiré superlattices and unconventional interlayer coupling. Despite their central role, direct and quantitative access to the out-of-plane atomic structure in these systems has remained elusive due to their nanoscale dimensions. Here, we introduce an automated dark-field electron tomography technique that enables three-dimensional structural analysis of atomically thin materials with sub-angstrom precision. Applying this method to twisted bilayer WSe$_2$, we uncover a significant expansion of the interlayer spacing compared to the bulk configuration, exceeding 0.1 angstrom, along with a remarkable temperature-driven interlayer decoupling unique to the twisted bilayer. Ultrafast measurement further reveals optically induced interlayer separation of ~0.2 angstrom on the picosecond timescale, attributed to transient exciton formation. These findings not only establish a powerful approach for visualizing hidden out-of-plane structures in atomically thin micro-flake materials, but also uncover the intrinsic fragility and dynamical tunability of interlayer coupling in moiré-engineered 2-dimensional materials."
  },
  {
    "date": "2026-01-20",
    "title": "Classical transport theory for the planar Hall effect with threefold symmetry",
    "authors": "Akiyoshi Yamada, Yuki Fuseya",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13613v1",
    "source": "arXiv",
    "abstract": "In recent years, the planar Hall effect (PHE) has become a key probe of Berry curvature and the anomalous Hall effect (AHE). Threefold-symmetric signals under in-plane fields are often attributed to such quantum mechanisms. Here, we establish a purely classical origin for a three-fold-symmetric PHE. The idea is simple yet decisive: a third-order expansion of the Boltzmann equation in the magnetic field reveals that the threefold component originates from the relative positions of the mirror planes in the crystals with respect to the measurement setups. Remarkably, the threefold contribution should be ubiquitous because this symmetry condition can be realized across a broad range of crystals. Numerical estimates based on concrete models further show that its amplitude is comparable to that expected from the AHE."
  },
  {
    "date": "2026-01-20",
    "title": "Quasi-periodic Dynamics for Multi-dimensional Quasi-linear Schrödinger Equations via Resonant Mode Control",
    "authors": "Zuhong You, Xiaoping Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13611v1",
    "source": "arXiv",
    "abstract": "This paper focuses on the problem of quasi-periodic solutions for multi-dimensional quasi-linear Schrödinger equation. To address the challenge of unbounded perturbations caused by quasi-linear terms in the equation, we define the resonant mode set $\\mathcal{K}$ to control nonlinear resonant effects. Combining KAM (Kolmogorov-Arnold-Moser) ( or Nash-Moser ) theory and Fourier analysis methods, we prove that there are plenty of quasi-periodic solutions of the equation. We also present the Fourier expansion form of the solutions and the estimation of frequency shifts."
  },
  {
    "date": "2026-01-20",
    "title": "Optimizing Parallel Schemes with Lyapunov Exponents and kNN-LLE Estimation",
    "authors": "Mudassir Shams, Andrei Velichko, Bruno Carpentieri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13604v1",
    "source": "arXiv",
    "abstract": "Inverse parallel schemes remain indispensable tools for computing the roots of nonlinear systems, yet their dynamical behavior can be unexpectedly rich, ranging from strong contraction to oscillatory or chaotic transients depending on the choice of algorithmic parameters and initial states. A unified analytical-data-driven methodology for identifying, measuring, and reducing such instabilities in a family of uni-parametric inverse parallel solvers is presented in this study. On the theoretical side, we derive stability and bifurcation characterizations of the underlying iterative maps, identifying parameter regions associated with periodic or chaotic behavior. On the computational side, we introduce a micro-series pipeline based on kNN-driven estimation of the local largest Lyapunov exponent (LLE), applied to scalar time series derived from solver trajectories. The resulting sliding-window Lyapunov profiles provide fine-grained, real-time diagnostics of contractive or unstable phases and reveal transient behaviors not captured by coarse linearized analysis. Leveraging this correspondence, we introduce a Lyapunov-informed parameter selection strategy that identifies solver settings associated with stable behavior, particularly when the estimated LLE indicates persistent instability. Comprehensive experiments on ensembles of perturbed initial guesses demonstrate close agreement between the theoretical stability diagrams and empirical Lyapunov profiles, and show that the proposed adaptive mechanism significantly improves robustness. The study establishes micro-series Lyapunov analysis as a practical, interpretable tool for constructing self-stabilizing root-finding schemes and opens avenues for extending such diagnostics to higher-dimensional or noise-contaminated problems."
  },
  {
    "date": "2026-01-20",
    "title": "An Elementary Approach to Scheduling in Generative Diffusion Models",
    "authors": "Qiang Sun, H. Vincent Poor, Wenyi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13602v1",
    "source": "arXiv",
    "abstract": "An elementary approach to characterizing the impact of noise scheduling and time discretization in generative diffusion models is developed. Considering a simplified model where the source distribution is multivariate Gaussian with a given covariance matrix, the explicit closed-form evolution trajectory of the distributions across reverse sampling steps is derived, and consequently, the Kullback-Leibler (KL) divergence between the source distribution and the reverse sampling output is obtained. The effect of the number of time discretization steps on the convergence of this KL divergence is studied via the Euler-Maclaurin expansion. An optimization problem is formulated, and its solution noise schedule is obtained via calculus of variations, shown to follow a tangent law whose coefficient is determined by the eigenvalues of the source covariance matrix. For an alternative scenario, more realistic in practice, where pretrained models have been obtained for some given noise schedules, the KL divergence also provides a measure to compare different time discretization strategies in reverse sampling. Experiments across different datasets and pretrained models demonstrate that the time discretization strategy selected by our approach consistently outperforms baseline and search-based strategies, particularly when the budget on the number of function evaluations is very tight."
  },
  {
    "date": "2026-01-20",
    "title": "Efficient local classification of parity-based material topology",
    "authors": "Stephan Wong, Ichitaro Yamazaki, Chris Siefert, Iain Duff, Terry A. Loring, Alexander Cerjan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13598v1",
    "source": "arXiv",
    "abstract": "Although the classification of crystalline materials can be generally handled by momentum-space-based approaches, topological classification of aperiodic materials remains an outstanding challenge, as the absence of translational symmetry renders such conventional approaches inapplicable. Here, we present a numerically efficient real-space framework for classifying parity-based $\\mathbb{Z}_2$ topology in aperiodic systems based on the spectral localizer framework and the direct computation of the sign of a Pfaffian associated with a large sparse skew-symmetric matrix. Unlike projector-based or momentum-space-based approaches, our method does not rely on translational symmetry, spectral gaps in the Hamiltonian's bulk, or gapped auxiliary operators such as spin projections, and instead provides a local, energy-resolved topological invariant accompanied by an intrinsic measure of topological protection. A central contribution of this work is the development of a scalable sparse factorization algorithm that enables the reliable determination of the Pfaffian's sign for large sparse matrices, making the approach practical to realistic physical materials. We apply this framework to identify the quantum spin Hall effect in quasicrystalline class AII systems, including gapless heterostructures, and to diagnose fragile topology in a large $C_2 \\mathcal{T}$-symmetric photonic quasicrystal. Overall, our results demonstrate that the spectral localizer, combined with efficient sparse numerical methods, provides a unified and robust tool for diagnosing parity-based topological phases in aperiodic electronic, photonic, and acoustic materials where conventional band-theoretic indexes are inapplicable."
  },
  {
    "date": "2026-01-20",
    "title": "ConceptCaps -- a Distilled Concept Dataset for Interpretability in Music Models",
    "authors": "Bruno Sienkiewicz, Łukasz Neumann, Mateusz Modrzejewski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14157v1",
    "source": "arXiv",
    "abstract": "Concept-based interpretability methods like TCAV require clean, well-separated positive and negative examples for each concept. Existing music datasets lack this structure: tags are sparse, noisy, or ill-defined. We introduce ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. Our pipeline separates semantic modeling from text generation: a VAE learns plausible attribute co-occurrence patterns, a fine-tuned LLM converts attribute lists into professional descriptions, and MusicGen synthesizes corresponding audio. This separation improves coherence and controllability over end-to-end approaches. We validate the dataset through audio-text alignment (CLAP), linguistic quality metrics (BERTScore, MAUVE), and TCAV analysis confirming that concept probes recover musically meaningful patterns. Dataset and code are available online."
  },
  {
    "date": "2026-01-20",
    "title": "Minutes-long soft X-ray prompt emission from a compact object merger",
    "authors": "An Li, Chen-Wei Wang, Niccolò Passaleva, Jie An, Bin-Bin Zhang, Eleonora Troja, Yi-Han Iris Yin, Yuan Liu, Shao-Lin Xiong, Li-Ping Xin, Yi-Xuan Shao, Jun Yang, Hui Sun, Dong Xu, Yu-Han Yang, Roberto Ricci, He Gao, Sarah Antier, Rosa L. Becerra, Jia-Xin Cao, Alberto Javier Castro-Tirado, Xin-Lei Chen, Ye-Hao Cheng, Yong Chen, Hua-Qing Cheng, Valerio D'Elia, Massimiliano De Pasquale, Yong-Wei Dong, Eslam Elhosseiny, Rob A. J. Eyles-Ferris, Maria Gritsevich, Xu-Hui Han, Dieter Hartmann, You-Dong Hu, Jing-Wei Hu, Shu-Mei Jia, Nino Kochiashvili, Wei-Hua Lei, Andrew J. Levan, Cheng-Kui Li, Dong-Yue Li, Hua-Li Li, Xiao-Bo Li, Zhi-Xing Ling, He-Yang Liu, Hou-Jun Lv, Daniele B. Malesani, Brendan O'Connor, Hai-Wu Pan, Shashi Bhushan Pandey, Ignacio Perez-Garcia, Daniëlle L. A. Pieterse, Marion Pillas, Yu-Lei Qiu, Andrea Saccardi, Rubén Sánchez-Ramírez, Wen-Jun Tan, Manasanun Tanasan, Nial R. Tanvir, Susanna D. Vergani, Jing Wang, Xiao-Feng Wang, Qin-Yu Wu, Shu-Xu Yi, Tillayev Yusufjon, Chen Zhang, Wen-Da Zhang, Yi-Jia Zhang, Guo-Ying Zhao, Chao Zheng, Shi-Jie Zheng, Chang Zhou, Ping Zhou, Bertrand Cordier, Jian-Yan Wei, Weimin Yuan, Shuang-Nan Zhang, Bing Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14137v1",
    "source": "arXiv",
    "abstract": "Compact object mergers are multi-messenger sources and progenitors of some gamma-ray bursts (GRBs), primarily understood by gamma-ray observations, while poorly constrained in the prompt low-energy phase. A long-lasting X-ray emission was discussed as afterglows following several short-duration ($\\lesssim$2 s) bursts, yet this prompt X-ray component was not directly observed or confirmed. Here we report the discovery of a minutes-long ($\\sim$560 s) flash of soft X-rays immediately following the short ($\\sim$0.4 s) GRB 250704B. The long-soft bump points to a distinct phase of prompt emission in X-rays detected by Einstein Probe in an event that otherwise appear as an ordinary short GRB, showing that long-lasting X-ray emission is likely a common feature of merger-driven bursts and a promising electromagnetic counterpart to gravitational-wave sources."
  },
  {
    "date": "2026-01-20",
    "title": "Feature-Aware Test Generation for Deep Learning Models",
    "authors": "Xingcheng Chen, Oliver Weissl, Andrea Stocco",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14081v1",
    "source": "arXiv",
    "abstract": "As deep learning models are widely used in software systems, test generation plays a crucial role in assessing the quality of such models before deployment. To date, the most advanced test generators rely on generative AI to synthesize inputs; however, these approaches remain limited in providing semantic insight into the causes of misbehaviours and in offering fine-grained semantic controllability over the generated inputs. In this paper, we introduce Detect, a feature-aware test generation framework for vision-based deep learning (DL) models that systematically generates inputs by perturbing disentangled semantic attributes within the latent space. Detect perturbs individual latent features in a controlled way and observes how these changes affect the model's output. Through this process, it identifies which features lead to behavior shifts and uses a vision-language model for semantic attribution. By distinguishing between task-relevant and irrelevant features, Detect applies feature-aware perturbations targeted for both generalization and robustness. Empirical results across image classification and detection tasks show that Detect generates high-quality test cases with fine-grained control, reveals distinct shortcut behaviors across model architectures (convolutional and transformer-based), and bugs that are not captured by accuracy metrics. Specifically, Detect outperforms a state-of-the-art test generator in decision boundary discovery and a leading spurious feature localization method in identifying robustness failures. Our findings show that fully fine-tuned convolutional models are prone to overfitting on localized cues, such as co-occurring visual traits, while weakly supervised transformers tend to rely on global features, such as environmental variances. These findings highlight the value of interpretable and feature-aware testing in improving DL model reliability."
  },
  {
    "date": "2026-01-20",
    "title": "MooneyMaker: A Python package to create ambiguous two-tone images",
    "authors": "Lars C. Reining, Thabo Matthies, Luisa Haussner, Rabea Turon, Thomas S. A. Wallis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14077v1",
    "source": "arXiv",
    "abstract": "Mooney images are high-contrast, two-tone visual stimuli, created by thresholding photographic images. They allow researchers to separate image content from image understanding, making them valuable for studying visual perception. An ideal Mooney image for this purpose achieves a specific balance: it initially appears unrecognizable but becomes fully interpretable to the observer after seeing the original template. Researchers traditionally created these stimuli manually using subjective criteria, which is labor-intensive and can introduce inconsistencies across studies. Automated generation techniques now offer an alternative to this manual approach. Here, we present MooneyMaker, an open-source Python package that automates the generation of ambiguous Mooney images using several complementary approaches. Users can choose between various generation techniques that range from approaches based on image statistics to deep learning models. These models strategically alter edge information to increase initial ambiguity. The package lets users create two-tone images with multiple methods and directly compare the results visually. In an experiment, we validate MooneyMaker by generating Mooney images using different techniques and assess their recognizability for human observers before and after disambiguating them by presenting the template images. Our results reveal that techniques with lower initial recognizability are associated with higher post-template recognition (i.e. a larger disambiguation effect). To help vision scientists build effective databases of Mooney stimuli, we provide practical guidelines for technique selection. By standardizing the generation process, MooneyMaker supports more consistent and reproducible visual perception research."
  },
  {
    "date": "2026-01-20",
    "title": "Riemannian optimization on the manifold of unitary and symmetric matrices with application to BD-RIS-assisted systems",
    "authors": "Ignacio Santamaria, Mohammad Soleymani, Eduard Jorswieck, Jesus Gutierrez, Carlos Beltran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13877v1",
    "source": "arXiv",
    "abstract": "In this paper, we rigorously characterize for the first time the manifold of unitary and symmetric matrices, deriving its tangent space and its geodesics. The resulting parameterization of the geodesics (through a real and symmetric matrix) allows us to derive a new Riemannian manifold optimization (MO) algorithm whose most remarkable feature is that it does not need to set any adaptation parameter. We apply the proposed MO algorithm to maximize the achievable rate in a multiple-input multiple-output (MIMO) system assisted by a beyond-diagonal reconfigurable intelligent surface (BD-RIS), illustrating the method's performance through simulations. The MO algorithm achieves a significant reduction in computational cost compared to previous alternatives based on Takagi decomposition, while retaining global convergence to a stationary point of the cost function."
  },
  {
    "date": "2026-01-20",
    "title": "Research on Adaptive Inertial Control in Synchronization Systems: Based on Variational Optimization Methods and Their Applications in the Stability of Complex Networks",
    "authors": "Yiwei Zhou, Zhongcheng Lei, Xiaoran Dai, Wenshan Hu, Hong Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13753v1",
    "source": "arXiv",
    "abstract": "Aiming at the core problem that it is difficult for a fixed inertia coefficient to balance transient disturbance suppression and long-term stability in complex network synchronization systems, an adaptive inertia control strategy based on variational optimization is proposed. Taking the Kuramoto model with inertia as the research carrier, the analytical expression of the time-varying inertia coefficient M(t) is strictly derived by the functional variational method, and a hierarchical control structure of \"benchmark inertia + disturbance feedback\" is constructed to achieve the organic unity of minimizing the vulnerability performance function H(T) and stability constraints. A multimodal decoupling control strategy based on Laplacian eigenvector projection is designed to enhance the feedback strength of the dominant mode by eigenvalue weighting, improving the control accuracy and dynamic response speed. Simulation verification is carried out in complex network systems, and the control performance of regular networks (RG), random networks (ER), small-world networks (SW), scale-free networks (SF) and spider webs (SP) under three typical disturbances of pulses, monotonic decays and oscillatory decays is systematically analyzed. The results show that the proposed strategy reduces H(T) of the five networks by 19%-25%, shortens the relaxation time by 15%-24%, and the real parts of all system eigenvalues are less than -0.25s^-1 , meeting the asymptotic stability criterion. This study provides a new theoretical framework and engineering implementation scheme for the stability control of complex network synchronization systems, which can be widely applied to fields such as power grids, communication networks, and neural networks."
  },
  {
    "date": "2026-01-20",
    "title": "Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering",
    "authors": "Chak Tou Leong, Dingwei Chen, Heming Xia, Qingyu Yin, Sunbowen Lee, Jian Wang, Wenjie Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13752v1",
    "source": "arXiv",
    "abstract": "Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \\textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior."
  },
  {
    "date": "2026-01-20",
    "title": "SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation",
    "authors": "Andreas Wiedholz, Rafael Paintner, Julian Gleißner, Alwin Hoffmann, Tobias Huber",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13732v1",
    "source": "arXiv",
    "abstract": "The fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches. In these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently. We present SUNSET, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions. It implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations. The exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation. SUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison."
  },
  {
    "date": "2026-01-20",
    "title": "Foundational VeriFast: Pragmatic Certification of Verification Tool Results through Hinted Mirroring",
    "authors": "Bart Jacobs",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13727v1",
    "source": "arXiv",
    "abstract": "VeriFast is a leading tool for the modular formal verification of correctness properties of single-threaded and multi-threaded C and Rust programs. It verifies a program by symbolically executing each function in isolation, exploiting user-annotated preconditions, postconditions, and loop invariants written in a form of separation logic, and using a separation logic-based symbolic representation of memory. However, the tool itself, written in roughly 30K lines of OCaml code, has not been formally verified. Therefore, bugs in the tool could cause it to falsely report the correctness of the input program. We here report on an early result extending VeriFast to emit, upon successful verification of a Rust program, a Rocq proof script that proves correctness of the program with respect to a Rocq-encoded axiomatic semantics of Rust. This significantly enhances VeriFast's applicability in safety-critical domains. We apply hinted mirroring: we record key information from VeriFast's symbolic execution run, and use it to direct a replay of the run in Rocq."
  },
  {
    "date": "2026-01-20",
    "title": "Central Limit Theorems in Multiplicative Diophantine Approximation",
    "authors": "Michael Björklund, Reynold Fregoli, Alexander Gorodnik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13726v1",
    "source": "arXiv",
    "abstract": "We investigate the number of integer solutions to a multiplicative Diophantine approximation problem and show that the associated counting function converges in distribution to a normal law. Our approach relies on the analysis of correlations of measures on homogeneous spaces, together with estimates for Siegel transforms restricted to subspaces."
  },
  {
    "date": "2026-01-20",
    "title": "Thermodynamics and Gravitational Signatures of Rotating Black Holes in the Generalized Extended Uncertainty Principle",
    "authors": "Nikko John Leo S. Lobos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13725v1",
    "source": "arXiv",
    "abstract": "We investigate the phenomenological implications of quantum gravity on rotating black holes within the framework of the Generalized Extended Uncertainty Principle (GEUP), which incorporates both minimal length (ultraviolet) and large-scale (infrared) corrections. Lacking a full non-perturbative formulation of quantum gravity, we adopt a metric-based approach. We construct a stationary, axisymmetric ansatz via the Newman-Janis algorithm to model the kinematic features of a rotating black hole subject to Generalized Extended Uncertainty Principle (GEUP) corrections. The thermodynamic analysis reveals that in the infrared-dominated regime, the Hawking temperature scales as $T_H \\sim M^{-3}$, leading to a rapid cooling phase that significantly prolongs the lifetime of supermassive black holes. We derive the modified Teukolsky Master Equation for gravitational perturbations and demonstrate that the background geometry preserves the isospectrality between axial and polar modes. In the eikonal limit, the quasinormal mode (QNM) spectrum exhibits orthogonal shifts: the minimal length parameter $β$ induces a spectral blueshift and enhanced damping, while the large-scale parameter $α$ induces a spectral redshift and suppressed damping. Finally, we constrain the theory using observational data from LIGO/Virgo and the Event Horizon Telescope. We establish that the shadow of M87* is approximately $10^6$ times more sensitive to large-scale corrections than Sgr A*, placing stringent bounds on the EUP parameter, while gravitational wave spectroscopy provides complementary constraints on the GUP sector."
  },
  {
    "date": "2026-01-20",
    "title": "Quantum Box-Muller Transform",
    "authors": "Dinh-Long Vu, Hitomi Mori, Patrick Rebentrost",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13718v1",
    "source": "arXiv",
    "abstract": "The Box-Muller transform is a widely used method to generate Gaussian samples from uniform samples. Quantum amplitude encoding methods encode the multi-variate normal distribution in the amplitudes of a quantum state. This work presents the Quantum Box-Muller transform which creates a superposition of binary-encoded grid points representing the multi-variate normal distribution. The gate complexity of our method depends on quantum arithmetic operations and, using a specific set of known implementations, the complexity is quadratic in the number of qubits. We apply our method to Monte-Carlo integration, in particular to the estimation of the expectation value of a function of Gaussian random variables. Our method implies that the state preparation circuit used multiple times in amplitude estimation requires only quantum arithmetic circuits for the grid points and the function, in addition to a single controlled rotation. We show how to provide the expectation value estimate with an error that is exponentially small in the number of qubits, similar to the amplitude-encoding setting with error-free encoding."
  },
  {
    "date": "2026-01-20",
    "title": "SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories",
    "authors": "Aditya Bharat Soni, Rajat Ghosh, Vaishnavi Bhargava, Valerie Chen, Debojyoti Dutta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13713v1",
    "source": "arXiv",
    "abstract": "Software testing is crucial for ensuring the correctness and reliability of software systems. Automated generation of issue reproduction tests from natural language issue descriptions enhances developer productivity by simplifying root cause analysis, promotes test-driven development -- \"test first, write code later\", and can be used for improving the effectiveness of automated issue resolution systems like coding agents. Existing methods proposed for this task predominantly rely on closed-source LLMs, with limited exploration of open models. To address this, we propose SWE-Tester -- a novel pipeline for training open-source LLMs to generate issue reproduction tests. First, we curate a high-quality training dataset of 41K instances from 2.6K open-source GitHub repositories and use it to train LLMs of varying sizes and families. The fine-tuned models achieve absolute improvements of up to 10\\% in success rate and 21\\% in change coverage on SWT-Bench Verified. Further analysis shows consistent improvements with increased inference-time compute, more data, and larger models. These results highlight the effectiveness of our framework for advancing open-source LLMs in this domain."
  },
  {
    "date": "2026-01-20",
    "title": "Multi-mode Coherent Detection Ghost Imaging Lidar and Vibration-Mode Imaging",
    "authors": "Jinquan Qi, Shuang Liu, Chenjin Deng, Chaoran Wang, Zunwang Bo, Youzhen Gui, Shensheng Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13703v1",
    "source": "arXiv",
    "abstract": "Coherent detection ghost imaging lidar (CD-GI lidar) integrates ghost imaging with coherent detection, thereby achieving enhanced anti-interference and phase-resolved imaging capability. Here, we propose a bucket-detector-based multi-mode coherent detection scheme for CD-GI lidar, where the reflected multi-mode light fields are coherently mixed with a single-mode local oscillator (LO) at the bucket detector photosensitive plane. The bucket-detector-based multi-mode CD-GI lidar system breaks the constraints of Siegman antenna theorem by utilizing field correlation to decouple the reflected multi-mode light fields and reconstructs the spatial distribution of targets' vibration modes. Theoretical analysis of the bucket-detector-based multi-mode CD-GI lidar system is presented in this work, and its feasibility is verified through a series of experiments."
  },
  {
    "date": "2026-01-20",
    "title": "DistilMOS: Layer-Wise Self-Distillation For Self-Supervised Learning Model-Based MOS Prediction",
    "authors": "Jianing Yang, Wataru Nakata, Yuki Saito, Hiroshi Saruwatari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13700v1",
    "source": "arXiv",
    "abstract": "With the advancement of self-supervised learning (SSL), fine-tuning pretrained SSL models for mean opinion score (MOS) prediction has achieved state-of-the-art performance. However, during fine-tuning, these SSL-based MOS prediction models often suffer from catastrophic forgetting of the pretrained knowledge and tend to overfit the training set, resulting in poor generalization performance. In this study, we propose DistilMOS, a novel method that learns to predict not only MOS but also token IDs obtained by clustering the hidden representations of each layer in the pretrained SSL model. These layer-wise token targets serve as self-distillation signals that enables the MOS prediction model to extract rich internal knowledge from SSL models, enhancing both prediction accuracy and generalization capability. Experimental evaluations demonstrate that our method significantly outperforms standard SSL-based MOS prediction models on both in-domain and out-of-domain evaluations, verifying the effectiveness and practicality of the proposed method."
  },
  {
    "date": "2026-01-20",
    "title": "Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning",
    "authors": "Zhihang Yuan, Chengyu Yue, Long Huang, Litu Ou, Lei Shi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13697v1",
    "source": "arXiv",
    "abstract": "Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring."
  },
  {
    "date": "2026-01-20",
    "title": "OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens",
    "authors": "Sifan Li, Hongkai Chen, Yujun Cai, Liyang Chen, Qingwen Ye, Yiwei Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13695v1",
    "source": "arXiv",
    "abstract": "Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations."
  },
  {
    "date": "2026-01-20",
    "title": "Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue",
    "authors": "Zhichao Liang, Satoshi Nakamura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13687v1",
    "source": "arXiv",
    "abstract": "Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions."
  },
  {
    "date": "2026-01-20",
    "title": "Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery",
    "authors": "Fabian Greifeneder, Wolfgang Fenz, Benedikt Alkin, Johannes Brandstetter, Michael Giretzlehner, Philipp Moser",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13676v1",
    "source": "arXiv",
    "abstract": "Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments."
  },
  {
    "date": "2026-01-20",
    "title": "Manifold Learning with Implicit Physics Embedding for Reduced-Order Flow-Field Modeling",
    "authors": "Weiji Wang, Chunlin Gong, Xuyi Jia, Chunna Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13673v1",
    "source": "arXiv",
    "abstract": "Nonlinear manifold learning (ML) based reduced-order models (ROMs) can substantially improve the quality of nonlinear flow-field modeling. However, noise and the lack of physical information often distort the dimensionality-reduction process, reducing the robustness and accuracy of flow-field prediction. To address this problem, we propose a novel manifold learning ROM with implicit physics embedding (IPE-ML). Starting from data-driven manifold coordinates, we incorporate physical parameters (e.g., angle of attack, Mach number) into manifold coordinates system by minimizing the prediction error of Gaussian process regression (GPR) model, thereby fine-tuning the manifold structure. These adjusted coordinates are then used to construct a flow-fields prediction model that predict nonlinear flow-field more accurately. The method is validated on two test cases: transonic flow-field modeling of the RAE2822 and supersonic flow-field modeling of the hexagon airfoil. The results indicate that the proposed IPE-ML can significantly improve the overall prediction accuracy of nonlinear flow fields. In transonic case, shock-related errors have been notably reduced, while in supersonic case the method can confine errors to small local regions. This study offers a new perspective on embedding physical information into nonlinear ROMs."
  },
  {
    "date": "2026-01-20",
    "title": "The norm of the Hilbert matrix operator on Bergman spaces",
    "authors": "Guanlong Bao, Liu Tian, Hasi Wulan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13672v1",
    "source": "arXiv",
    "abstract": "Karapetrović conjectured that the norm of the Hilbert matrix operator on the Bergman space $A^p_α$ is equal to $π/\\sin((2+α)π/p)$ when $-1<α<p-2$. In this paper, we provide a proof of this conjecture for $0\\leq α\\leq \\frac{6p^3-29p^2+17p-2+2p\\sqrt{6p^2-11p+4}}{(3p-1)^2}$, and this range of $α$ improves the best known result when $α>\\frac{1}{47}$ and $α\\not=1$."
  },
  {
    "date": "2026-01-20",
    "title": "The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption",
    "authors": "Apoorva Adimulam, Rajesh Gupta, Sumit Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13671v1",
    "source": "arXiv",
    "abstract": "Orchestrated multi-agent systems represent the next stage in the evolution of artificial intelligence, where autonomous agents collaborate through structured coordination and communication to achieve complex, shared objectives. This paper consolidates and formalizes the technical composition of such systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. Another primary contribution of this work is the in-depth technical delineation of two complementary communication protocols - the Model Context Protocol, which standardizes how agents access external tools and contextual data, and the Agent2Agent protocol, which governs peer coordination, negotiation, and delegation. Together, these protocols establish an interoperable communication substrate that enables scalable, auditable, and policy-compliant reasoning across distributed agent collectives. Beyond protocol design, the paper details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability. By synthesizing these elements into a cohesive technical blueprint, this paper provides comprehensive treatments of orchestrated multi-agent systems - bridging conceptual architectures with implementation-ready design principles for enterprise-scale AI ecosystems."
  },
  {
    "date": "2026-01-20",
    "title": "Spectral stability of cavity-enhanced single-photon emitters in silicon",
    "authors": "Johannes Früh, Fabian Salamon, Andreas Gritsch, Alexander Ulanowski, Andreas Reiserer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13666v1",
    "source": "arXiv",
    "abstract": "The unrivaled maturity of its nanofabrication makes silicon a promising hardware platform for quantum information processing. To this end, efficient single-photon sources and spin-photon interfaces have been implemented by integrating color centers or erbium dopants into nanophotonic resonators. However, the optical emission frequencies in this approach are subject to temporal fluctuations on both long and short timescales, which hinders the development of quantum applications. Here, we investigate this limitation and demonstrate that it can be alleviated by integrating the emitters into Fabry-Perot instead of nanophotonic resonators. Their larger optical mode volume enables both increasing the distance to crystal surfaces and operating at a lower dopant concentration, which reduces implantation-induced crystal damage and interactions between emitters. As a result, we observe a fivefold reduction of the spectral diffusion linewidth down to 4.0(2) MHz. Calculations and experimental investigations of isotopically purified 28-Si crystals suggest that the remaining spectral instability is caused by laser-induced electric-field fluctuations. In direct comparison with a nanophotonic device, the instability is significantly reduced at the same intracavity power, enabling a tenfold increase of the optical coherence time up to 20(1) microseconds. These findings represent a key step towards spectrally stable spin-photon interfaces in silicon and their potential applications in quantum networking and distributed quantum information processing."
  },
  {
    "date": "2026-01-20",
    "title": "VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement",
    "authors": "Tiancheng Fang, Bowen Pan, Lingxi Chen, Jiangjing Lyu, Chengfei Lyu, Chaoyue Niu, Fan Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13664v1",
    "source": "arXiv",
    "abstract": "We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave."
  },
  {
    "date": "2026-01-20",
    "title": "Possible time-variable iron-K$α$ emission in the circum-nuclear region of the Circinus galaxy",
    "authors": "Aiko Miyamoto, Taiki Kawamuro, Hirokazu Odaka, Takuma Izumi, Hironori Matsumoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13660v1",
    "source": "arXiv",
    "abstract": "We present imaging and spatially resolved spectral analyses of eight Chandra data taken for the Circinus galaxy in $\\approx$ 22 years to reveal neutral iron-K$α$ emission on a circumnuclear scale ($\\sim$ 10--100 pc) and search for time variability in the emission. By simulating and taking account of point-source emission from the active galactic nucleus (AGN), we detect iron-line emission $\\sim$ 20--60 pc away from the nucleus, particularly in the eastern and western regions. In the two regions, possible time variability in the line flux was also detected. Our spectral analysis then finds that the observed equivalent widths can reach $\\sim$ 2 keV and the slopes of underlying continua are rather inverted with $Γ< 0$. These are consistent with a scenario in which the iron emission originates from clouds illuminated by AGN X-rays; our result could provide the first extragalactic example of AGN X-ray echoes. In this scenario, we estimated the physical sizes of the illuminated clouds based on the timescale of variability to be less than 6 pc. Furthermore, we compared the iron emission distribution with the cold molecular distribution inferred by Atacama Large Millimeter/submillimeter Array (ALMA) observation of CO($J$=3--2), revealing that in the region of bright iron-line emission, the molecular emission seems to be weak. This might suggest that the AGN X-ray emission affects the chemical composition in the form of AGN feedback."
  },
  {
    "date": "2026-01-20",
    "title": "Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs",
    "authors": "Guangba Yu, Zirui Wang, Yujie Huang, Renyi Zhong, Yuedong Zhong, Yilun Wang, Michael R. Lyu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13655v1",
    "source": "arXiv",
    "abstract": "The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a First Mile deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. To bridge this gap, we conduct the first large-scale empirical study of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems. Our analysis reveals a paradigm shift: white-box orchestration relocates the reliability bottleneck from model algorithmic defects to the systemic fragility of the deployment stack. We identify three key phenomena: (1) Diagnostic Divergence: runtime crashes distinctively signal infrastructure friction, whereas incorrect functionality serves as a signature for internal tokenizer defects. (2) Systemic Homogeneity: Root causes converge across divergent series, confirming reliability barriers are inherent to the shared ecosystem rather than specific architectures. (3) Lifecycle Escalation: Barriers escalate from intrinsic configuration struggles during fine-tuning to compounded environmental incompatibilities during inference. Supported by our publicly available dataset, these insights provide actionable guidance for enhancing the reliability of the LLM landscape."
  },
  {
    "date": "2026-01-20",
    "title": "Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge",
    "authors": "Xiaolin Zhou, Zheng Luo, Yicheng Gao, Qixuan Chen, Xiyang Hu, Yue Zhao, Ruishan Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13649v1",
    "source": "arXiv",
    "abstract": "Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only."
  },
  {
    "date": "2026-01-20",
    "title": "3D Stacked Surface-Code Architecture for Measurement-Free Fault-Tolerant Quantum Error Correction",
    "authors": "GunSik Min, IlKwon Sohn, Jun Heo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13648v1",
    "source": "arXiv",
    "abstract": "Mid-circuit measurements are a major bottleneck for superconducting quantum processors because they are slower and noisier than gates. Measurement-free quantum error correction (mfec) replaces repeated measurements and classical feed-forward by coherent quantum feedback, but existing mfec protocols suffer from severe connectivity overhead when mapped to planar surface-code architectures: transversal interactions between logical patches require SWAP chains of length $O(d)$ in the code distance, which increase depth and generate hook errors. This work introduces a 3D stacked surface-code architecture for measurement-free fault-tolerant quantum error correction that removes this connectivity bottleneck. Vertical transversal couplers between aligned surface-code patches enable coherent parity mapping and feedback with zero SWAP overhead, realizing constant-depth $O(1)$ inter-layer operations in d while preserving local 2D stabilizer checks. A fault-tolerant mfec protocol for the surface code is constructed that suppresses hook errors under realistic noise. An analytical performance model shows that the 3D architecture overcomes the readout error floor and achieves logical error rates orders of magnitude below both standard measurement-based surface codes and 2D mfec variants in regimes with slow, noisy measurements, identifying 3D integration as a key enabler for scalable measurement-free fault tolerance."
  },
  {
    "date": "2026-01-20",
    "title": "Quadratic Upper Bound for Boosting Robustness",
    "authors": "Euijin You, Hyang-Won Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13645v1",
    "source": "arXiv",
    "abstract": "Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model."
  },
  {
    "date": "2026-01-20",
    "title": "Direct Finite-Time Contraction (Step-Log) Profiling--Driven Optimization of Parallel Schemes for Nonlinear Problems on Multicore Architectures",
    "authors": "Mudassir Shams, Andrei Velichko, Bruno Carpentieri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13637v1",
    "source": "arXiv",
    "abstract": "Efficient computation of all distinct solutions of nonlinear problems is essential in many scientific and engineering applications. Although high-order parallel iterative schemes offer fast convergence, their practical performance is often limited by sensitivity to internal parameters and the lack of reproducible tuning procedures. Classical parameter selection tools based on analytical conditions and dynamical-system diagnostics can be problem-dependent and computationally demanding, which motivates lightweight data-driven alternatives. In this study, we propose a parameterized single-step bi-parametric parallel Weierstrass-type scheme with third-order convergence together with a training-free tuning framework based on Direct finite-time contraction (step-log) profiling. The approach extracts Lyapunov-like finite-time contraction information directly from solver trajectories via step norms and step-log ratios, aggregates the resulting profiles over micro-launch ensembles, and ranks parameter candidates using two compact scores: the stability minimum S_min and the stability moment S_mom. Numerical results demonstrate consistent improvements in convergence rate, stability, and robustness across diverse nonlinear test problems, establishing the proposed profiling-based strategy as an efficient and reproducible alternative to classical parameter tuning methods."
  },
  {
    "date": "2026-01-20",
    "title": "Are Large Language Models able to Predict Highly Cited Papers? Evidence from Statistical Publications",
    "authors": "Zhanshuo Ye, Yiming Hou, Rui Pan, Tianchen Gao, Hansheng Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13627v1",
    "source": "arXiv",
    "abstract": "Predicting highly-cited papers is a long-standing challenge due to the complex interactions of research content, scholarly communities, and temporal dynamics. Recent advances in large language models (LLMs) raise the question of whether early-stage textual information can provide useful signals of long-term scientific impact. Focusing on statistical publications, we propose a flexible, text-centered framework that leverages LLMs and structured prompt design to predict highly cited papers. Specifically, we utilize information available at the time of publication, including titles, abstracts, keywords, and limited bibliographic metadata. Using a large corpus of statistical papers, we evaluate predictive performance across multiple publication periods and alternative definitions of highly cited papers. The proposed approach achieves stable and competitive performance relative to existing methods and demonstrates strong generalization over time. Textual analysis further reveals that papers predicted as highly cited concentrate on recurring topics such as causal inference and deep learning. To facilitate practical use of the proposed approach, we further develop a WeChat mini program, \\textit{Stat Highly Cited Papers}, which provides an accessible interface for early-stage citation impact assessment. Overall, our results provide empirical evidence that LLMs can capture meaningful early signals of long-term citation impact, while also highlighting their limitations as tools for research impact assessment."
  },
  {
    "date": "2026-01-20",
    "title": "Locally analytic vectors in the completed cohomology of quaternionic Shimura curves",
    "authors": "Zhenghui Li, Benchao Su, Zhixiang Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13625v1",
    "source": "arXiv",
    "abstract": "We use the methods introduced by Lue Pan to study the locally analytic vectors of the completed cohomology of Shimura curves associated to an indefinite quaternion algebra $D$ which is ramified at a prime number $p$. Let $D_p^{\\times}$ be the group of units of $D$ at $p$. Using $p$-adic uniformization of the quaternionic Shimura curves, we compute the Hecke eigenspace of the completed cohomology with the Hecke eigenvalues associated to a classical automorphic form on another quaternion algebra $\\bar D$ (switching invariants of $D$ at $p,\\infty$). We present this locally analytic $D_p^\\times$-representation using the de Rham complex of the Lubin-Tate tower of dimension $1$. This is analogous to the Breuil-Strauch conjecture for the group $\\mathrm{GL}_2(\\mathbb{Q}_p)$. We show that the locally analytic $D_p^{\\times}$-representation does not detect the Hodge filtration of the local de Rham Galois representation at $p$ in the crystalline case, and also give applications for the locally analytic Jacquet--Langlands correspondence for $\\mathrm{GL}_2(\\mathbb{Q}_p)$ and $D_p^\\times$."
  },
  {
    "date": "2026-01-20",
    "title": "Programmable branched flow of light",
    "authors": "Shan-shan Chang, Daxing Xiong, Ze-huan Zheng, Li-Wei Wang, Yan-qing Lu, Lu-Jian Chen, Jian-Hua Jiang, Jin-hui Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13623v1",
    "source": "arXiv",
    "abstract": "We demonstrate deterministic control of branched flow of light using anisotropic nematic liquid crystals. By sculpting the director field via photoalignment, we create spatially programmable optical potentials that govern light scattering and propagation. This platform enables configurable, anisotropic branched flow of light and reveals a universal scaling law for its characteristic features, directly connecting disordered photonics with mesoscopic wave transport. Under extreme anisotropy, we observe a pronounced directional channeling effect, driven by anomalous symmetry-breaking velocity diffusion, which concentrates light propagation along preferential directions while suppressing transverse spreading. These findings establish a tunable material platform for harnessing branched flow of light, opening pathways toward on-chip photonic circuits that exploit disorder-guided transport, scattering-resilient endoscopic imaging, and adaptive optical interfaces in complex media."
  },
  {
    "date": "2026-01-20",
    "title": "Recent progress on disorder-induced topological phases",
    "authors": "Dan-Wei Zhang, Ling-Zhi Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13619v1",
    "source": "arXiv",
    "abstract": "Topological states of matter in disordered systems without translation symmetry have attracted great interest in recent years. These states with topological characters are not only robust against certain disorders, but also can be counterintuitively induced by disorders from a topologically trivial phase in the clean limit. In this review, we summarize the current theoretical and experimental progress on disorder-induced topological phases in both condensed-matter and artificial systems. We first introduce the topological Anderson insulators (TAIs) induced by random disorders and their topological characterizations and experimental realizations. We then discuss various extensions of TAIs with unique localization phenomena in quasiperiodic and non-Hermitian systems. We also review the theoretical and experimental studies on the disorder-induced topology in dynamical and many-body systems, including topological Anderson-Thouless pumps, disordered correlated topological insulators and average-symmetry protected topological orders acting as interacting TAI phases. Finally, we conclude the review by highlighting potential directions for future explorations."
  },
  {
    "date": "2026-01-20",
    "title": "CauScientist: Teaching LLMs to Respect Data for Causal Discovery",
    "authors": "Bo Peng, Sirui Chen, Lei Xu, Chaochao Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13614v1",
    "source": "arXiv",
    "abstract": "Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead result. To this end, we propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating \"data scientists\" with probabilistic statistics as rigorous \"verifiers\". CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs. Our project page is at https://github.com/OpenCausaLab/CauScientist."
  },
  {
    "date": "2026-01-20",
    "title": "PINA: Prompt Injection Attack against Navigation Agents",
    "authors": "Jiani Liu, Yixin He, Lanlan Fan, Qidi Zhong, Yushi Cheng, Meng Zhang, Yanjiao Chen, Wenyuan Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13612v1",
    "source": "arXiv",
    "abstract": "Navigation agents powered by large language models (LLMs) convert natural language instructions into executable plans and actions. Compared to text-based applications, their security is far more critical: a successful prompt injection attack does not just alter outputs but can directly misguide physical navigation, leading to unsafe routes, mission failure, or real-world harm. Despite this high-stakes setting, the vulnerability of navigation agents to prompt injection remains largely unexplored. In this paper, we propose PINA, an adaptive prompt optimization framework tailored to navigation agents under black-box, long-context, and action-executable constraints. Experiments on indoor and outdoor navigation agents show that PINA achieves high attack success rates with an average ASR of 87.5%, surpasses all baselines, and remains robust under ablation and adaptive-attack conditions. This work provides the first systematic investigation of prompt injection attacks in navigation and highlights their urgent security implications for embodied LLM agents."
  },
  {
    "date": "2026-01-20",
    "title": "Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data",
    "authors": "Zhipeng Chang, Ting He, Wenrui Hao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13608v1",
    "source": "arXiv",
    "abstract": "Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions."
  },
  {
    "date": "2026-01-20",
    "title": "Outage Identification from Electricity Market Data: Quickest Change Detection Approach",
    "authors": "Milad Hoseinpour, Shubhanshu Shekhar, Vladimir Dvorkin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13605v1",
    "source": "arXiv",
    "abstract": "Power system outages expose market participants to significant financial risk unless promptly detected and hedged. We develop an outage identification method from public market signals grounded in the parametric quickest change detection (QCD) theory. Parametric QCD operates on stochastic data streams, distinguishing pre- and post-change regimes using the ratio of their respective probability density functions. To derive the density functions for normal and post-outage market signals, we exploit multi-parametric programming to decompose complex market signals into parametric random variables with a known density. These densities are then used to construct a QCD-based statistic that triggers an alarm as soon as the statistic exceeds an appropriate threshold. Numerical experiments on a stylized PJM testbed demonstrate rapid line outage identification from public streams of electricity demand and price data."
  },
  {
    "date": "2026-01-20",
    "title": "DCCVT: Differentiable Clipped Centroidal Voronoi Tessellation",
    "authors": "Wylliam Cantin Charawi, Adrien Gruson, Jane Wu, Christian Desrosiers, Diego Thomas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13603v1",
    "source": "arXiv",
    "abstract": "While Marching Cubes (MC) and Marching Tetrahedra (MTet) are widely adopted in 3D reconstruction pipelines due to their simplicity and efficiency, their differentiable variants remain suboptimal for mesh extraction. This often limits the quality of 3D meshes reconstructed from point clouds or images in learning-based frameworks. In contrast, clipped CVTs offer stronger theoretical guarantees and yield higher-quality meshes. However, the lack of a differentiable formulation has prevented their integration into modern machine learning pipelines. To bridge this gap, we propose DCCVT, a differentiable algorithm that extracts high-quality 3D meshes from noisy signed distance fields (SDFs) using clipped CVTs. We derive a fully differentiable formulation for computing clipped CVTs and demonstrate its integration with deep learning-based SDF estimation to reconstruct accurate 3D meshes from input point clouds. Our experiments with synthetic data demonstrate the superior ability of DCCVT against state-of-the-art methods in mesh quality and reconstruction fidelity. https://wylliamcantincharawi.dev/DCCVT.github.io/"
  },
  {
    "date": "2026-01-20",
    "title": "Transport of indirect excitons and exciton mediated spin transport in a van der Waals heterostructure in magnetic fields",
    "authors": "Zhiwen Zhou, W. J. Brunner, E. A. Szwed, L. H. Fowler-Gerace, L. V. Butov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13601v1",
    "source": "arXiv",
    "abstract": "We studied transport of indirect excitons (IXs) and IX mediated spin transport in a MoSe$_2$/WSe$_2$ van der Waals heterostructure in magnetic fields up to 8 T. We observed the long-range IX transport and the long-range IX mediated spin transport in the magnetic fields. The IX transport and spin transport are characterized by the 1/e decay distances reaching $\\sim$ 100 micrometers. The decay distance of the spin transport correlates with the decay distance of IX transport. These decay distances first increase and then decrease with increasing IX density for all studied magnetic fields. The long-range IX transport and the long-range spin transport in the magnetic fields are consistent with the similar long-range transport in zero magnetic field."
  },
  {
    "date": "2026-01-20",
    "title": "Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models",
    "authors": "Linrui Ma, Yufei Cui, Kai Han, Yunhe Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13599v1",
    "source": "arXiv",
    "abstract": "Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. In order to address these issues, we propose Diffusion in Diffusion, a draft-then-refine framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilise snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using just 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models."
  },
  {
    "date": "2026-01-20",
    "title": "AI IDEs or Autonomous Agents? Measuring the Impact of Coding Agents on Software Development",
    "authors": "Shyam Agarwal, Hao He, Bogdan Vasilescu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13597v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM)-based coding agents increasingly act as autonomous contributors that generate and merge pull requests, yet their real-world effects on software projects are unclear, especially relative to widely adopted IDE-based AI assistants. We present a longitudinal causal study of agent adoption in open-source repositories using staggered difference-in-differences with matched controls. Using the AIDev dataset, we define adoption as the first agent-generated pull request and analyze monthly repository-level outcomes spanning development velocity (commits, lines added) and software quality (static-analysis warnings, cognitive complexity, duplication, and comment density). Results show large, front-loaded velocity gains only when agents are the first observable AI tool in a project; repositories with prior AI IDE usage experience minimal or short-lived throughput benefits. In contrast, quality risks are persistent across settings, with static-analysis warnings and cognitive complexity rising roughly 18% and 35%, indicating sustained agent-induced complexity debt even when velocity advantages fade. These heterogeneous effects suggest diminishing returns to AI assistance and highlight the need for quality safeguards, provenance tracking, and selective deployment of autonomous agents. Our findings establish an empirical basis for understanding how agentic and IDE-based tools interact, and motivate research on balancing acceleration with maintainability in AI-integrated development workflows."
  },
  {
    "date": "2026-01-20",
    "title": "OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer",
    "authors": "Pengze Zhang, Yanze Wu, Mengtian Li, Xu Bai, Songtao Zhao, Fulong Ye, Chong Mou, Xinghui Li, Zhuowei Chen, Qian He, Mingyuan Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14250v1",
    "source": "arXiv",
    "abstract": "Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation."
  },
  {
    "date": "2026-01-20",
    "title": "Soft Tail-dropping for Adaptive Visual Tokenization",
    "authors": "Zeyuan Chen, Kai Zhang, Zhuowen Tu, Yuanjun Xiong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14246v1",
    "source": "arXiv",
    "abstract": "We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts."
  },
  {
    "date": "2026-01-20",
    "title": "XR: Cross-Modal Agents for Composed Image Retrieval",
    "authors": "Zhongyu Yang, Wei Pang, Yingfang Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14245v1",
    "source": "arXiv",
    "abstract": "Retrieval is being redefined by agentic AI, demanding multimodal reasoning beyond conventional similarity-based paradigms. Composed Image Retrieval (CIR) exemplifies this shift as each query combines a reference image with textual modifications, requiring compositional understanding across modalities. While embedding-based CIR methods have achieved progress, they remain narrow in perspective, capturing limited cross-modal cues and lacking semantic reasoning. To address these limitations, we introduce XR, a training-free multi-agent framework that reframes retrieval as a progressively coordinated reasoning process. It orchestrates three specialized types of agents: imagination agents synthesize target representations through cross-modal generation, similarity agents perform coarse filtering via hybrid matching, and question agents verify factual consistency through targeted reasoning for fine filtering. Through progressive multi-agent coordination, XR iteratively refines retrieval to meet both semantic and visual query constraints, achieving up to a 38% gain over strong training-free and training-based baselines on FashionIQ, CIRR, and CIRCO, while ablations show each agent is essential. Code is available: https://01yzzyu.github.io/xr.github.io/."
  },
  {
    "date": "2026-01-20",
    "title": "New Topological Restrictions For Spaces With Nonnegative Ricci Curvature",
    "authors": "Alessandro Cucinotta, Mattia Magnabosco, Daniele Semola",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14231v1",
    "source": "arXiv",
    "abstract": "We obtain new topological restrictions for complete Riemannian manifolds with nonnegative Ricci curvature and RCD(0,n) spaces. Our main results are a Betti number rigidity theorem which answers a question open since work of M.-T. Anderson in 1990, and a vanishing theorem for the simplicial volume generalizing a theorem of M. Gromov from 1982. Combining such results we obtain a new proof of the classification of noncompact 3-manifolds with nonnegative Ricci curvature, originally due to G. Liu in 2011, which extends to the synthetic setting."
  },
  {
    "date": "2026-01-20",
    "title": "MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems",
    "authors": "Yiyang Wang, Yiqiao Jin, Alex Cabral, Josiah Hester",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14230v1",
    "source": "arXiv",
    "abstract": "Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems."
  },
  {
    "date": "2026-01-20",
    "title": "Rare species advantage in Antarctic Lakes",
    "authors": "Emily Reynebeau, Cristina Takacs-Vesbach, Davorka Gulisija, Mitchell Newberry",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14213v1",
    "source": "arXiv",
    "abstract": "The maintenance of diversity in complex ecological communities despite unpredictable dynamics and competitive exclusion is thought to require continual influx of new species or competitive advantages that accrue as species become rare. We examine isolated planktonic microbial communities under permanent ice cover in Antarctic lakes, recording prokaryotic abundance across 9 communities, 11 years, 30~m of depth, and thousands of species in the McMurdo LTER. We quantify rare species advantage by modeling community dynamics under frequency-dependent selection. We find persistent diversity and pervasive negative frequency dependence with limited immigration and turnover. While ecology and evolutionary sciences have long debated whether diversity is maintained selectively, we measure selection over a $10^4$-fold range of abundance in naturally coevolving communities and implicate rare species advantage."
  },
  {
    "date": "2026-01-20",
    "title": "Unification of Deterministic Higher-Order Patterns",
    "authors": "Johannes Niederhauser, Aart Middeldorp",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14211v1",
    "source": "arXiv",
    "abstract": "We present a sound and complete unification procedure for deterministic higher-order patterns, a class of simply-typed lambda terms introduced by Yokoyama et al. which comes with a deterministic matching problem. Our unification procedure can be seen as a special case of full higher-order unification where flex-flex pairs can be solved in a most general way. Moreover, our method generalizes Libal and Miller's recent functions-as-constructors higher-order unification by dropping their global condition on variable arguments, thereby losing the property that every solvable problem has a most general unifier. In fact, minimal complete sets of unifiers of deterministic higher-order patterns may be infinite, so decidability of the unification problem remains an open question."
  },
  {
    "date": "2026-01-20",
    "title": "Locality forces equal energy spacing of quantum many-body scar towers",
    "authors": "Nicholas O'Dea, Lei Gioia, Sanjay Moudgalya, Olexei I. Motrunich",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14206v1",
    "source": "arXiv",
    "abstract": "Quantum many-body scars are non-thermal eigenstates embedded in the spectra of otherwise non-integrable Hamiltonians. Paradigmatic examples often appear as quasiparticle towers of states, such as the maximally ferromagnetic spin-1/2 states, also known as Dicke states. A distinguishing feature of quantum many-body scars is that they admit multiple local \"parent\" Hamiltonians for which they are exact eigenstates. In this work, we show that the locality of such parent Hamiltonians strongly constrains the relative placement of these states within the energy spectrum. In particular, we prove that if the full set of Dicke states are exact eigenstates of an extensive local Hamiltonian, then their energies must necessarily be equally spaced. Our proof builds on recent results concerning parent Hamiltonians of the $W$ state, together with general algebraic structures underlying such quasiparticle towers. We further demonstrate that this equal spacing property extends to local Hamiltonians defined on arbitrary bounded-degree graphs, including regular lattices in any spatial dimension and expander graphs. Hamiltonians with $k$-local interactions and a bounded number of interaction terms per site are also encompassed by our proof. On the same classes of graphs, we additionally establish equal spacing for towers constructed from multi-site quasiparticles on top of product states. For the towers considered here, an immediate corollary of the equal spacing property is that any state initialized entirely within the quantum many-body scar manifold exhibits completely frozen entanglement dynamics under any local Hamiltonian for which those scars are exact eigenstates. Overall, our results reveal a stringent interplay between locality and the structure of quantum many-body scars."
  },
  {
    "date": "2026-01-20",
    "title": "Native linear-optical protocol for efficient multivariate trace estimation",
    "authors": "Leonardo Novo, Marco Robbio, Ernesto F. Galvão, Nicolas J. Cerf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14204v1",
    "source": "arXiv",
    "abstract": "The Hong-Ou-Mandel test estimates the overlap between spectral functions characterizing the internal degrees of freedom of two single photons. It can be viewed as a photon-native protocol that implements the well-known quantum SWAP test. Here, we propose a native linear-optical protocol that efficiently estimates multivariate traces of quantum states called Bargmann invariants, which are ubiquitous in quantum mechanics. Our protocol may be understood as a photon-native version of the cycle test in the circuit model, which encompasses many-photon multimode quantum states. We show the protocol is sample-efficient and discuss applications, such as generalized suppression laws, efficient quantum kernel estimation for quantum machine learning, eigenspectrum estimation, and the characterization of multiphoton indistinguishability."
  },
  {
    "date": "2026-01-20",
    "title": "Convergence analysis and a novel Lagrange multiplier partitioned method for fluid-poroelastic interaction",
    "authors": "Amy de Castro, Hyesuk Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14201v1",
    "source": "arXiv",
    "abstract": "We propose a partitioned method for the monolithic formulation of the Stokes-Biot system that incorporates Lagrange multipliers enforcing the interface conditions. The monolithic system is discretized using finite elements, and we establish convergence of the resulting approximation. A Schur complement based algorithm is developed together with an efficient preconditioner, enabling the fluid and poroelastic structure subproblems to be decoupled and solved independently at each time step. The Lagrange multipliers approximate the interface fluxes and act as Neumann boundary conditions for the subproblems, yielding parallel solution of the Stokes and Biot equations. Numerical experiments demonstrate the effectiveness of the proposed algorithm and validate the theoretical error estimate."
  },
  {
    "date": "2026-01-20",
    "title": "Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery",
    "authors": "Albina Galiullina, Wouter van Heeswijk, Tom van Woensel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14196v1",
    "source": "arXiv",
    "abstract": "Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery."
  },
  {
    "date": "2026-01-20",
    "title": "Toward Efficient Agents: Memory, Tool learning, and Planning",
    "authors": "Xiaofang Yang, Lijun Li, Heng Zhou, Tong Zhu, Xiaoye Qu, Yuchen Fan, Qianshan Wei, Rui Ye, Li Kang, Yiran Qin, Zhiqiang Kou, Daizong Liu, Qi Li, Ning Ding, Siheng Chen, Jing Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14192v1",
    "source": "arXiv",
    "abstract": "Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights."
  },
  {
    "date": "2026-01-20",
    "title": "Device-independent quantum memory certification in two-point measurement experiments",
    "authors": "Leonardo S. V. Santos, Peter Tirler, Michael Meth, Lukas Gerster, Manuel John, Keshav Pareek, Tim Gollerthan, Martin Ringbauer, Otfried Gühne",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14191v1",
    "source": "arXiv",
    "abstract": "Quantum memories are key components of emerging quantum technologies. They are designed to store quantum states and retrieve them on demand without losing features such as superposition and entanglement. Verifying that a memory preserves these features is indispensable for applications such as quantum computation, cryptography and networks, yet no general and assumption-free method has been available. Here, we present a device-independent approach for certifying black-box quantum memories, requiring no trust in any part of the experimental setup. We do so by probing quantum systems at two points in time and then confronting the observed temporal correlations against classical causal models through violations of causal inequalities. We perform a proof-of-principle experiment in a trapped-ion quantum processor, where we certify 35 ms of a qubit memory. Our method establishes temporal correlations and causal modelling as practical and powerful tool for benchmarking key ingredients of quantum technologies, such as quantum gates or implementations of algorithms."
  },
  {
    "date": "2026-01-20",
    "title": "Cooperative Chemical Reactions in Optical Cavities: A Complex Interplay of Mode Hybridization, Timescale Balance, and Pathway Interference",
    "authors": "Yaling Ke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14187v1",
    "source": "arXiv",
    "abstract": "Harnessing strong light-matter interactions to control chemical reactions in confined electromagnetic fields offers a promising route toward deepening our understanding of chemical dynamics at the collective quantum-mechanical level, with potential implications for future chemical synthesis paradigms. Achieving this goal, however, requires an in-depth mechanistic understanding of the underlying dynamical processes. As a step in this direction, we present a systematic and numerically exact quantum dynamical study of cooperative reaction dynamics inside an optical microcavity. Using a hierarchy of model systems with increasing complexity, we elucidate how cavity-modified reactivity emerges from-and is highly sensitive to-subtle structural and environmental variations. Our models consist of optically dark reactive molecules, each represented by a symmetric double well potential, coupled to infrared-active non-reactive intramolecular or solvent vibrational modes, as well as their respective dissipative environments. Our results demonstrate that cavity-induced rate modifications arise from a delicate interplay among mode hybridization in strong-coupling regimes, the dynamical balance of all participating energy exchange processes, and quantum interference between multiple fluctuation-dissipation-mediated reaction pathways enabled by collective cavity coupling. By continuously tuning a single system parameter or introducing molecular collectivity, we observe qualitatively distinct rate modification profiles as functions of the cavity frequency, including resonant rate enhancement, resonant rate suppression, hybridization-induced peak splitting, and, notably, asymmetric Fano-type line shapes in which enhancement peaks and suppression dips coexist within a narrow resonance window, highlighting the important role of quantum interference in cavity-modified chemical reactivity."
  },
  {
    "date": "2026-01-20",
    "title": "Penalizing Localized Dirichlet Energies in Low Rank Tensor Products",
    "authors": "Paris A. Karakasis, Nicholas D. Sidiropoulos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14173v1",
    "source": "arXiv",
    "abstract": "We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization."
  },
  {
    "date": "2026-01-20",
    "title": "Poisson-Dirichlet graphons and permutons",
    "authors": "Benedikt Stufler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14166v1",
    "source": "arXiv",
    "abstract": "We introduce classes of supergraphs and superpermutations with novel universal graphon and permuton limiting objects whose construction involves the two-parameter Poisson-Dirichlet process introduced by Pitman and Yor (1997). We demonstrate the universality of these limiting objects through general invariance principles in a heavy-tailed regime and establish a comprehensive phase diagram for the asymptotic shape of superstructures."
  },
  {
    "date": "2026-01-20",
    "title": "The Impact of Interference Cognition on the Reliability and Capacity of Industrial Wireless Communications",
    "authors": "Yichen Guo, Tao Peng, Yujie Zhao, Yijing Niu, Wenbo Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14164v1",
    "source": "arXiv",
    "abstract": "Interference significantly impacts the performance of industrial wireless networks, particularly n severe interference environments with dense networks reusing spectrum resources intensively. Although delicate interference information is often unavailable in conventional networks, emerging interference cognition techniques can compensate this critical problem with possibly different precision. This paper investigates the relationship between precision of interference cognition and system performance. We propose a novel performance analysis framework that quantifies the impact of varying interference information precision on achievable rate. Specifically, leveraging the Nakagami-$\\mathbf{m}$ fading channel model, we analytically and asymptotically analyze the average achievable rate in the finite blocklength regime for different precision levels of signal and interference information. Our findings reveal the critical importance of identifying per-link interference information for achieving optimal performance. Additionally, obtaining instantaneous information is more beneficial for signal links."
  },
  {
    "date": "2026-01-20",
    "title": "An Empirical Study on Remote Code Execution in Machine Learning Model Hosting Ecosystems",
    "authors": "Mohammed Latif Siddiq, Tanzim Hossain Romel, Natalie Sekerak, Beatrice Casey, Joanna C. S. Santos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14163v1",
    "source": "arXiv",
    "abstract": "Model-sharing platforms, such as Hugging Face, ModelScope, and OpenCSG, have become central to modern machine learning development, enabling developers to share, load, and fine-tune pre-trained models with minimal effort. However, the flexibility of these ecosystems introduces a critical security concern: the execution of untrusted code during model loading (i.e., via trust_remote_code or trust_repo). In this work, we conduct the first large-scale empirical study of custom model loading practices across five major model-sharing platforms to assess their prevalence, associated risks, and developer perceptions. We first quantify the frequency with which models require custom code to function and identify those that execute arbitrary Python files during loading. We then apply three complementary static analysis tools: Bandit, CodeQL, and Semgrep, to detect security smells and potential vulnerabilities, categorizing our findings by CWE identifiers to provide a standardized risk taxonomy. We also use YARA to identify malicious patterns and payload signatures. In parallel, we systematically analyze the documentation, API design, and safety mechanisms of each platform to understand their mitigation strategies and enforcement levels. Finally, we conduct a qualitative analysis of over 600 developer discussions from GitHub, Hugging Face, and PyTorch Hub forums, as well as Stack Overflow, to capture community concerns and misconceptions regarding security and usability. Our findings reveal widespread reliance on unsafe defaults, uneven security enforcement across platforms, and persistent confusion among developers about the implications of executing remote code. We conclude with actionable recommendations for designing safer model-sharing infrastructures and striking a balance between usability and security in future AI ecosystems."
  },
  {
    "date": "2026-01-20",
    "title": "One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion",
    "authors": "Yitong Dong, Qi Zhang, Minchao Jiang, Zhiqiang Wu, Qingnan Fan, Ying Feng, Huaqi Zhang, Hujun Bao, Guofeng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14161v1",
    "source": "arXiv",
    "abstract": "We present a novel framework for high-fidelity novel view synthesis (NVS) from sparse images, addressing key limitations in recent feed-forward 3D Gaussian Splatting (3DGS) methods built on Vision Transformer (ViT) backbones. While ViT-based pipelines offer strong geometric priors, they are often constrained by low-resolution inputs due to computational costs. Moreover, existing generative enhancement methods tend to be 3D-agnostic, resulting in inconsistent structures across views, especially in unseen regions. To overcome these challenges, we design a Dual-Domain Detail Perception Module, which enables handling high-resolution images without being limited by the ViT backbone, and endows Gaussians with additional features to store high-frequency details. We develop a feature-guided diffusion network, which can preserve high-frequency details during the restoration process. We introduce a unified training strategy that enables joint optimization of the ViT-based geometric backbone and the diffusion-based refinement module. Experiments demonstrate that our method can maintain superior generation quality across multiple datasets."
  },
  {
    "date": "2026-01-20",
    "title": "A Natural Representation of Volumes Yields a Remarkable Affine Consequence",
    "authors": "Wladimir G. Boskoff, Bogdan D. Suceavă",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14149v1",
    "source": "arXiv",
    "abstract": "At the beginning of the 20th Century there was a growing interest for the investigation of the action of linear groups on the geometry of surfaces. In that context of ideas, the quest for a connection between curvature and the behaviour of linear groups rose naturally. Pursuing the original thought, we investigate how the geometric meaning of this idea is intimately related to the concept of volume of parallelepiped boxes. We show how the ratio of the Gaussian curvature divided by the fourth power of a certain distance of interest in the geometry of surfaces can be represented as a function of volumes. This geometric description explores the profound meaning of a quantity considered by {Ţ}i{ţ}eica in 1907, in a work that sparked a growing interest in affine differential geometry, as an illustration of Felix Klein's Erlangen Program, in which the quest for geometric invariants was the main point of inquiry."
  },
  {
    "date": "2026-01-20",
    "title": "Symmetry Breaking and Phase Transitions in Random Non-Commutative Geometries and Related Random-Matrix Ensembles",
    "authors": "Mauro D'Arcangelo, Sven Gnutzmann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14141v1",
    "source": "arXiv",
    "abstract": "Ensembles of random fuzzy non-commutative geometries may be described in terms of finite (\\(N^2\\)-dimensional) Dirac operators and a probability measure. Dirac operators of type \\((p,q)\\) are defined in terms of commutators and anti-commutators of \\(2^{p+q-1}\\) hermitian matrices \\(H_k\\) and tensor products with a representation of a Clifford algebra. Ensembles based on this idea have recently been used as a toy model for quantum gravity, and they are interesting random-matrix ensembles in their own right. We provide a complete theoretical picture of crossovers, phase transitions, and symmetry breaking in the \\(N \\to \\infty \\) limit of 1-parameter families of quartic Barrett-Glaser ensembles in the one-matrix cases \\((1,0)\\) and \\((0,1)\\) that depend on one coupling constant \\(g\\). Our theoretical results are in full agreement with previous and new Monte-Carlo simulations."
  },
  {
    "date": "2026-01-20",
    "title": "A global stochastic maximum principle for delayed forward-backward stochastic control systems",
    "authors": "Feng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14138v1",
    "source": "arXiv",
    "abstract": "In this paper, we study a delayed forward-backward stochastic control system in which all the coefficients depend on the state and control terms, and the control domain is not necessarily convex. A global stochastic maximum principle is obtained by using a new method. More precisely, this method introduces first-order and second-order auxiliary equations and offers a novel approach to deriving the adjoint equations as well as the variational equation for $y^\\e - y^*$."
  },
  {
    "date": "2026-01-20",
    "title": "TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers",
    "authors": "Bin Yu, Shijie Lian, Xiaopeng Lin, Yuliang Wei, Zhaolong Shen, Changti Wu, Yuzhuo Miao, Xinming Wang, Bailing Wang, Cong Huang, Kai Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14133v1",
    "source": "arXiv",
    "abstract": "Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to \"catastrophic forgetting\" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen \"Left Brain\", which retains robust general visual reasoning, with a trainable \"Right Brain\", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity."
  },
  {
    "date": "2026-01-20",
    "title": "Toward self-coding information systems",
    "authors": "Rodrigo Falcão, Frank Elberzhager, Karthik Vaidhyanathan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14132v1",
    "source": "arXiv",
    "abstract": "In this extended abstract, we propose a novel research topic in the field of agentic AI, which we refer to as self-coding information systems. These systems will be able to dynamically adapt their structure or behavior by evaluating potential adaptation decisions, generate source code, test, and (re)deploy their source code autonomously, at runtime, reducing the time to market of new features. Here we motivate the topic, provide a formal definition of self-coding information systems, discuss some expected impacts of the new technology, and indicate potential research directions."
  },
  {
    "date": "2026-01-20",
    "title": "\"Range as a Key\" is the Key! Fast and Compact Cloud Block Store Index with RASK",
    "authors": "Haoru Zhao, Mingkai Dong, Erci Xu, Zhongyu Wang, Haibo Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14129v1",
    "source": "arXiv",
    "abstract": "In cloud block store, indexing is on the critical path of I/O operations and typically resides in memory. With the scaling of users and the emergence of denser storage media, the index has become a primary memory consumer, causing memory strain. Our extensive analysis of production traces reveals that write requests exhibit a strong tendency to target continuous block ranges in cloud storage systems. Thus, compared to current per-block indexing, our insight is that we should directly index block ranges (i.e., range-as-a-key) to save memory. In this paper, we propose RASK, a memory-efficient and high-performance tree-structured index that natively indexes ranges. While range-as-a-key offers the potential to save memory and improve performance, realizing this idea is challenging due to the range overlap and range fragmentation issues. To handle range overlap efficiently, RASK introduces the log-structured leaf, combined with range-tailored search and garbage collection. To reduce range fragmentation, RASK employs range-aware split and merge mechanisms. Our evaluations on four production traces show that RASK reduces memory footprint by up to 98.9% and increases throughput by up to 31.0x compared to ten state-of-the-art indexes."
  },
  {
    "date": "2026-01-20",
    "title": "NewsRECON: News article REtrieval for image CONtextualization",
    "authors": "Jonathan Tonglet, Iryna Gurevych, Tinne Tuytelaars, Marie-Francine Moens",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14121v1",
    "source": "arXiv",
    "abstract": "Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available."
  },
  {
    "date": "2026-01-20",
    "title": "The $O(n\\to\\infty)$ Rotor Model and the Quantum Spherical Model on Graphs",
    "authors": "Nikita Titov, Andrea Trombettoni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14119v1",
    "source": "arXiv",
    "abstract": "We show that the large $n$ limit of the $O(n)$ quantum rotor model defined on a general graph has the same critical behavior as the corresponding quantum spherical model and that the critical exponents depend solely on the spectral dimension $d_s$ of the graph. To this end, we employ a classical to quantum mapping and use known results for the large $n$ limit of the classical $O(n)$ model on graphs. Away from the critical point, we discuss the interplay between the Laplacian and the Adjacency matrix in the whole parameter plane of the quantum Hamiltonian. These results allow us to paint the full picture of the $O(n)$ quantum rotor model on graphs in the large $n$ limit."
  },
  {
    "date": "2026-01-20",
    "title": "Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns",
    "authors": "George Mihaila",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14112v1",
    "source": "arXiv",
    "abstract": "Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families."
  },
  {
    "date": "2026-01-20",
    "title": "AttackMate: Realistic Emulation and Automation of Cyber Attack Scenarios Across the Kill Chain",
    "authors": "Max Landauer, Wolfgang Hotwagner, Thorina Boenke, Florian Skopik, Markus Wurzenberger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14108v1",
    "source": "arXiv",
    "abstract": "Adversary emulation tools facilitate scripting and automated execution of cyber attack chains, thereby reducing costs and manual expert effort required for security testing, cyber exercises, and intrusion detection research. However, due to the fact that existing tools typically rely on agents installed on target systems, they leave suspicious traces that make it easy to distinguish their activities from those of real human attackers. Moreover, these tools often lack relevant capabilities, such as handling of interactive prompts, and are unsuitable for emulating specific stages of the kill chain, such as initial access. This paper thus introduces AttackMate, an open-source attack scripting language and execution engine designed to mimic behavior patterns of actual attackers. We validate the tool in a case study covering common attack steps including privilege escalation, information gathering, and lateral movement. Our results indicate that log artifacts resulting from AttackMate's activities resemble those produced by human attackers more closely than those generated by standard adversary emulation tools."
  },
  {
    "date": "2026-01-20",
    "title": "The JEM-EUSO Collaboration: Contributions to the 39th International Cosmic Ray Conference (ICRC2025)",
    "authors": "M. Abdullahi, M. Abrate, J. H. Adams, D. Allard, P. Alldredge, R. Aloisio, R. Ammendola, A. Anastasio, L. Anchordoqui, V. Andreoli, A. Anzalone, E. Arnone, D. Badoni, P. von Ballmoos, B. Baret, D. Barghini, M. Battisti, R. Bellotti, A. A. Belov, M. Bertaina, M. Betts, P. Biermann, F. Bisconti, S. Blin-Bondil, M. Boezio, A. N. Bowaire, I. Buckland, L. Burmistrov, J. Burton-Heibges, F. Cafagna, D. Campana, F. Capel, J. Caraca, R. Caruso, M. Casolino, C. Cassardo, A. Castellina, K. Černý, L. Conti, A. G. Coretti, R. Cremonini, A. Creusot, A. Cummings, S. Davarpanah, C. De Santis, C. de la Taille, A. Di Giovanni, A. Di Salvo, T. Ebisuzaki, J. Eser, F. Fenu, S. Ferrarese, G. Filippatos, W. W. Finch, C. Fornaro, C. Fuglesang, P. Galvez Molina, S. Garbolino, D. Garg, D. Gardiol, G. K. Garipov, A. Golzio, C. Guépin, A. Haungs, T. Heibges, F. Isgrò, R. Iuppa, E. G. Judd, F. Kajino, L. Kupari, S. -W. Kim, P. A. Klimov, I. Kreykenbohm, J. F. Krizmanic, J. Lesrel, F. Liberatori, H. P. Lima, E. M'sihid, D. Mandát, M. Manfrin, A. Marcelli, L. Marcelli, W. Marszał, G. Masciantonio, V. Masone, J. N. Matthews, E. Mayotte, A. Meli, M. Mese, S. S. Meyer, M. Mignone, M. Miller, H. Miyamoto, T. Montaruli, J. Moses, R. Munini, C. Nathan, A. Neronov, R. Nicolaidis, T. Nonaka, M. Mongelli, A. Novikov, F. Nozzoli, T. Ogawa, S. Ogio, H. Ohmori, A. V. Olinto, Y. Onel, G. Osteria, B. Panico, E. Parizot, G. Passeggio, T. Paul, M. Pech, K. Penalo Castillo, F. Perfetto, L. Perrone, C. Petta, P. Picozza, L. W. Piotrowski, Z. Plebaniak, G. Prévôt, M. Przybylak, H. Qureshi, E. Reali, M. H. Reno, F. Reynaud, E. Ricci, M. Ricci, A. Rivetti, G. Saccà, R. E. Saraev, H. Sagawa, O. Saprykin, F. Sarazin, R. E. Saraev, P. Schovánek, V. Scotti, S. A. Sharakin, V. Scherini, H. Schieler, K. Shinozaki, F. Schröder, A. Sotgiu, R. Sparvoli, B. Stillwell, J. Szabelski, M. Takeda, Y. Takizawa, S. B. Thomas, R. A. Torres Saavedra, R. Triggiani, D. A. Trofimov, M. Unger, T. M. Venters, M. Venugopal, C. Vigorito, M. Vrábel, S. Wada, D. Washington, A. Weindl, L. Wiencke, J. Wilms, S. Wissel, I. V. Yashin, M. Yu. Zotov, P. Zuccon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14107v1",
    "source": "arXiv",
    "abstract": "This is a collection of papers presented by the JEM-EUSO Collaboration at the 39th International Cosmic Ray Conference (ICRC 2025) (Geneva, Switzerland, July 14--24, 2025)."
  },
  {
    "date": "2026-01-20",
    "title": "Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing",
    "authors": "Xiaolu Liu, Yicong Li, Qiyuan He, Jiayin Zhu, Wei Ji, Angela Yao, Jianke Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14103v1",
    "source": "arXiv",
    "abstract": "Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D."
  },
  {
    "date": "2026-01-20",
    "title": "Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems",
    "authors": "Benedikt Hartl, Léo Pio-Lopez, Chris Fields, Michael Levin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14096v1",
    "source": "arXiv",
    "abstract": "The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales."
  },
  {
    "date": "2026-01-20",
    "title": "Near Optimal Code Construction for the Adversarial Torn Paper Channel With Edit Errors",
    "authors": "Maria Abu-Sini, Reinhard Heckel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14088v1",
    "source": "arXiv",
    "abstract": "Motivated by DNA storage systems and 3D fingerprinting, this work studies the adversarial torn paper channel with edit errors. This channel first applies at most $t_e$ edit errors (i.e., insertions, deletions, and substitutions) to the transmitted word and then breaks it into $t+1$ fragments at arbitrary positions. In this paper, we construct a near optimal error correcting code for this channel, which will be referred to as a $t$-breaks $t_e$-edit-errors resilient code. This code enables reconstructing the transmitted codeword from the $t+1$ noisy fragments. Moreover, we study list decoding of the torn paper channel by deriving bounds on the size of the list (of codewords) obtained from cutting a codeword of a $t$-breaks resilient code $t'$ times, where $t' > t$."
  },
  {
    "date": "2026-01-20",
    "title": "'1'-bit Count-based Sorting Unit to Reduce Link Power in DNN Accelerators",
    "authors": "Ruichi Han, Yizhi Chen, Tong Lei, Jordi Altayo Gonzalez, Ahmed Hemani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14087v1",
    "source": "arXiv",
    "abstract": "Interconnect power consumption remains a bottleneck in Deep Neural Network (DNN) accelerators. While ordering data based on '1'-bit counts can mitigate this via reduced switching activity, practical hardware sorting implementations remain underexplored. This work proposes the hardware implementation of a comparison-free sorting unit optimized for Convolutional Neural Networks (CNN). By leveraging approximate computing to group population counts into coarse-grained buckets, our design achieves hardware area reductions while preserving the link power benefits of data reordering. Our approximate sorting unit achieves up to 35.4% area reduction while maintaining 19.50\\% BT reduction compared to 20.42% of precise implementation."
  },
  {
    "date": "2026-01-20",
    "title": "Two-Stream temporal transformer for video action classification",
    "authors": "Nattapong Kurpukdee, Adrian G. Bors",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14086v1",
    "source": "arXiv",
    "abstract": "Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities."
  },
  {
    "date": "2026-01-20",
    "title": "LU-type factorizations for birth--death processes and their Darboux transformations",
    "authors": "José Arcia-Manoleskos, Manuel Domínguez de la Iglesia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14074v1",
    "source": "arXiv",
    "abstract": "We study LU-type factorizations of the infinitesimal generator of a birth--death process on $\\mathbb{N}_0$. Our goal is to characterize those factorizations whose Darboux transformations (that is, inverting the order of the factors) yield new infinitesimal generators of birth--death processes. Two types are considered: lower--upper (LU), which is unique and upper--lower (UL), which involves a free parameter. For both cases, we determine the conditions under which such factorizations can occur, derive explicit formulas for their coefficients, and provide a probabilistic interpretation of the factors. The spectral properties and associated orthogonal polynomials of the Darboux transformations are also analyzed. Finally, the general results are applied to classical examples such as the $M/M/1$ and $M/M/\\infty$ queues and to different cases of linear birth--death processes."
  },
  {
    "date": "2026-01-20",
    "title": "VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences",
    "authors": "Hendrik Möller, Hanna Schoen, Robert Graf, Matan Atad, Nathan Molinier, Anjany Sekuboyina, Bettina K. Budai, Fabian Bamberg, Steffen Ringhof, Christopher Schlett, Tobias Pischon, Thoralf Niendorf, Josua A. Decker, Marc-André Weber, Bjoern Menze, Daniel Rueckert, Jan S. Kirschke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14066v1",
    "source": "arXiv",
    "abstract": "The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing \"Vertebra Identification with Anomaly Handling\" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps."
  },
  {
    "date": "2026-01-20",
    "title": "LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems",
    "authors": "Badri N. Patro, Vijay S. Agneeswaran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14053v1",
    "source": "arXiv",
    "abstract": "The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations."
  },
  {
    "date": "2026-01-20",
    "title": "A systematic study of lepton flavor violating dark matter interactions via indirect detection in effective field theories",
    "authors": "Sahabub Jahedi, Jin-Han Liang, Yi Liao, Xiao-Dong Ma, Yoshiki Uchida",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14048v1",
    "source": "arXiv",
    "abstract": "Lepton flavor violating (LFV) interactions involving dark matter (DM) particles remain a largely unexplored area. In this study, we systematically investigate LFV DM interactions within the framework of effective field theories by analyzing astrophysical photons and positrons produced from DM annihilation. Employing the astrophysical photon and positron data collected by Fermi-LAT, INTEGRAL, XMM-Newton, and AMS-02, we place meaningful constraints on all leading-order effective operators involving a DM pair and a flavor violating charged lepton pair. Our analysis covers the three well-known DM candidates: a scalar, a fermion, and a vector particle. For the photon flux, we consider contributions from final-state radiation, radiative decay, and inverse Compton scattering, and examine their respective sensitivity regions across different DM masses and photon energies. We find that for DM masses below $\\mathcal{O}(20\\,\\rm GeV)$, INTEGRAL provides the most stringent constraints on annihilation cross sections and effective operators in all three LFV channels, whereas AMS-02 offers the strongest constraints above $\\mathcal{O}(20\\,\\rm GeV)$."
  },
  {
    "date": "2026-01-20",
    "title": "A curvature-weighted spectral precursor to dissipation in decaying three-dimensional turbulence: robustness across initial conditions and viscosity effects",
    "authors": "Satori Tsuzuki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14043v1",
    "source": "arXiv",
    "abstract": "We investigate the robustness of a curvature-weighted spectral precursor to dissipation in freely decaying three-dimensional incompressible turbulence. Building on our recent work in Physical Review Fluids on the Taylor--Green vortex, we analyze direct numerical simulations using the curl-of-vorticity spectrum $|\\nabla\\times \\boldsymbolω|^2(k)$, equivalent to a $k^4$-weighted energy spectrum for solenoidal flow. Extending the study across multiple initial conditions -- multi-mode ABC flows, a randomized low-wavenumber ABC field, the Taylor--Green vortex, and the Kida--Pelz flow -- we find a consistent temporal ordering: the characteristic time associated with the advance and saturation of the peak wavenumber of $|\\nabla\\times \\boldsymbolω|^2(k)$ precedes the dissipation-peak time, which in turn precedes the characteristic time associated with the peak scale of the nonlinear energy-flux spectrum. We further probe viscosity effects in Taylor--Green turbulence: the precursor persists at lower viscosity when adequate resolution is employed, but weakens and can break at higher viscosity, consistent with stronger viscous damping of curvature-dominated small-scale content. Throughout, we use explicit inspection of curvature-weighted spectra to distinguish physical peak evolution from cutoff-proximate artifacts. These results establish robustness across initial conditions and clarify the practical role of viscosity and resolution for deploying curvature-weighted spectral precursors in decaying turbulence."
  },
  {
    "date": "2026-01-20",
    "title": "Evaluating state-of-the-art cloud quantum computers for quantum neural networks in gravitational waves data analysis",
    "authors": "Maria-Catalina Isfan, Laurentiu-Ioan Caramete, Ana Caramete",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14036v1",
    "source": "arXiv",
    "abstract": "In this work, we explore the possibility of using quantum computers provided for usage in cloud by big companies (such as IBM, IonQ, IQM Quantum Computers, etc.) to run our quantum neural network (QNN) developed for data analysis in the context of LISA Space Mission, developed with the Qiskit library in Python. Our previous work demonstrated that our QNN learns patterns in gravitational wave (GW) data much faster than a classical neural network, making it suitable for fast GW signal detection in future LISA data streams. Analyzing the fees from hardware providers like IBM Quantum, Amazon Braket and Microsoft Azure, we found that the fees for running the first segment of our QNN sum up to \\$2000, \\$60000, and \\$1000000 respectively. Using free plans, we succeed to run the 3-qubit feature map of the QNN for one random data sample on {\\fontfamily{qcr} \\selectfont ibm\\_kyoto} and {\\fontfamily{qcr}\\selectfont IQM Quantum Computers\\_Garnet} quantum computers, obtaining a fidelity of 99\\%; we could also run the first prediction segment of our QNN on {\\fontfamily{qcr} \\selectfont ibm\\_kyoto}, implemented for 4 qubits, and obtained a prediction accuracy of 20\\%. We queried providers such as IBM Quantum, Amazon Braket, Pasqal, and Munich Quantum Valley to obtain access to their plans, but, with the exception of Amazon Braket, our applications remain unanswered to this day. Other major setbacks in using the quantum computers we had access to included Qiskit library version issues (as in the cases of IBM Quantum and IQM Quantum Computers) and the frequent unavailability of the devices, as was the case with the Microsoft Azure provider. All the results presented in this paper were accumulated in 2024."
  },
  {
    "date": "2026-01-20",
    "title": "Analyzing the Availability of E-Mail Addresses for PyPI Libraries",
    "authors": "Alexandros Tsakpinis, Alexander Pretschner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14034v1",
    "source": "arXiv",
    "abstract": "Open Source Software (OSS) libraries form the backbone of modern software systems, yet their long-term sustainability often depends on maintainers being reachable for support, coordination, and security reporting. In this paper, we empirically analyze the availability of contact information - specifically e-mail addresses - across 686,034 Python libraries on the Python Package Index (PyPI) and their associated GitHub repositories. We examine how and where maintainers provide this information, assess its validity, and explore coverage across individual libraries and their dependency chains. Our findings show that 81.6% of libraries include at least one valid e-mail address, with PyPI serving as the primary source (79.5%). When analyzing dependency chains, we observe that up to 97.8% of direct and 97.7% of transitive dependencies provide valid contact information. At the same time, we identify over 698,000 invalid entries, primarily due to missing fields. These results demonstrate strong maintainer reachability across the ecosystem, while highlighting opportunities for improvement - such as offering clearer guidance to maintainers during the packaging process and introducing opt-in validation mechanisms for existing e-mail addresses."
  },
  {
    "date": "2026-01-20",
    "title": "Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics",
    "authors": "Junqi Liu, Zihao Zhou, Zekai Zhu, Marco Dos Santos, Weikun He, Jiawei Liu, Ran Wang, Yunzhou Xie, Junqiao Zhao, Qiufeng Wang, Lihong Zhi, Jia Li, Wenda Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14027v1",
    "source": "arXiv",
    "abstract": "Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent."
  },
  {
    "date": "2026-01-20",
    "title": "Universal Approximation Theorem for Input-Connected Multilayer Perceptrons",
    "authors": "Vugar Ismailov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14026v1",
    "source": "arXiv",
    "abstract": "We introduce the Input-Connected Multilayer Perceptron (IC-MLP), a feedforward neural network architecture in which each hidden neuron receives, in addition to the outputs of the preceding layer, a direct affine connection from the raw input. We first study this architecture in the univariate setting and give an explicit and systematic description of IC-MLPs with an arbitrary finite number of hidden layers, including iterated formulas for the network functions. In this setting, we prove a universal approximation theorem showing that deep IC-MLPs can approximate any continuous function on a closed interval of the real line if and only if the activation function is nonlinear. We then extend the analysis to vector-valued inputs and establish a corresponding universal approximation theorem for continuous functions on compact subsets of $\\mathbb{R}^n$."
  },
  {
    "date": "2026-01-20",
    "title": "OAMAC: Origin-Aware Mandatory Access Control for Practical Post-Compromise Attack Surface Reduction",
    "authors": "Omer Abdelmajeed Idris Mohammed, Ilhami M. Orak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14021v1",
    "source": "arXiv",
    "abstract": "Modern operating systems provide powerful mandatory access control mechanisms, yet they largely reason about who executes code rather than how execution originates. As a result, processes launched remotely, locally, or by background services are often treated equivalently once privileges are obtained, complicating security reasoning and enabling post-compromise abuse of sensitive system interfaces. We introduce origin-aware mandatory access control (OAMAC), a kernel-level enforcement model that treats execution origin -- such as physical user presence, remote access, or service execution -- as a first-class security attribute. OAMAC mediates access to security-critical subsystems based on execution provenance rather than identity alone, enabling centralized governance over multiple attack surfaces while significantly reducing policy complexity. We present a deployable prototype implemented entirely using the Linux eBPF LSM framework, requiring no kernel modifications. OAMAC classifies execution origin using kernel-visible metadata, propagates origin across process creation, and enforces origin-aware policies on both sensitive filesystem interfaces and the kernel BPF control plane. Policies are maintained in kernel-resident eBPF maps and can be reconfigured at runtime via a minimal userspace tool. Our evaluation demonstrates that OAMAC effectively restricts common post-compromise actions available to remote attackers while preserving normal local administration and system stability. We argue that execution origin represents a missing abstraction in contemporary operating system security models, and that elevating it to a first-class concept enables practical attack surface reduction without requiring subsystem-specific expertise or heavyweight security frameworks."
  },
  {
    "date": "2026-01-20",
    "title": "A Security Framework for Chemical Functions",
    "authors": "Frederik Walter, Hrishi Narayanan, Jessica Bariffi, Anne Lüscher, Rawad Bitar, Robert Grass, Antonia Wachter-Zeh, Zohar Yakhini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14019v1",
    "source": "arXiv",
    "abstract": "In this paper, we introduce chemical functions, a unified framework that models chemical systems as noisy challenge--response primitives, and formalize the associated chemical function infrastructure. Building on the theory of physical functions, we rigorously define robustness, unclonability, and unpredictability for chemical functions in both finite and asymptotic regimes, and specify security games that capture the adversary's power and the security goals. We instantiate the framework with two existing DNA-based constructions (operable random DNA and Genomic Sequence Encryption) and derive quantitative bounds for robustness, unclonability, and unpredictability. Our analysis develops maximum-likelihood verification rules under sequencing noise and partial-edit models, and provides high-precision estimates based on binomial distributions to guide parameter selection. The framework, definitions, and analyses yield a reproducible methodology for designing chemically unclonable authentication mechanisms. We demonstrate applications to in-product authentication and to shared key generation using standard extraction techniques."
  },
  {
    "date": "2026-01-20",
    "title": "Tripartite quantum correlations obtained by post-selection from twin beams",
    "authors": "Pavel Pavlicek, Jan Perina, Vaclav Michalek, Radek Machulka, Ondrej Haderka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14017v1",
    "source": "arXiv",
    "abstract": "Spatially-resolved photon counting of a twin beam performed by an iCCD camera allows for versatile tailoring the properties of the beams formed by parts of the original twin beam. Dividing the idler beam of the twin beam into three equally-intense parts and post-selecting by detecting a given number of photocounts in the whole signal beam we arrive at the idler fields exhibiting high degrees of nonclassicality and being endowed with tripartite quantum correlations. Nonclassicality is analyzed with the help of suitable nonclassicality witnesses and their corresponding nonclassicality depths. Suitable parameters are introduced to quantify quantum correlations. These parameters are analyzed as they depend on the field intensity. The experimental photocount histograms are reconstructed by the maximum-likelihood approach and the obtained photon-number distributions are compared with a suitable model in which the original twin beam is approximated by an appropriate multi-mode Gaussian field and undergoes the corresponding beams' transformations."
  },
  {
    "date": "2026-01-20",
    "title": "MATE: Matryoshka Audio-Text Embeddings for Open-Vocabulary Keyword Spotting",
    "authors": "Youngmoon Jung, Myunghun Jung, Joon-Young Yang, Yong-Hyeok Lee, Jaeyoung Roh, Hoon-Young Cho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14012v1",
    "source": "arXiv",
    "abstract": "Open-vocabulary keyword spotting (KWS) with text-based enrollment has emerged as a flexible alternative to fixed-phrase triggers. Prior utterance-level matching methods, from an embedding-learning standpoint, learn embeddings at a single fixed dimensionality. We depart from this design and propose Matryoshka Audio-Text Embeddings (MATE), a dual-encoder framework that encodes multiple embedding granularities within a single vector via nested sub-embeddings (\"prefixes\"). Specifically, we introduce a PCA-guided prefix alignment: PCA-compressed versions of the full text embedding for each prefix size serve as teacher targets to align both audio and text prefixes. This alignment concentrates salient keyword cues in lower-dimensional prefixes, while higher dimensions add detail. MATE is trained with standard deep metric learning objectives for audio-text KWS, and is loss-agnostic. To our knowledge, this is the first application of matryoshka-style embeddings to KWS, achieving state-of-the-art results on WSJ and LibriPhrase without any inference overhead."
  },
  {
    "date": "2026-01-20",
    "title": "Numerical solution of Smoluchowski coagulation equation combined with Ostwald ripening",
    "authors": "Robert T. Zaks, Sergey A. Matveev, Margarita A. Nikishina, Dmitri V. Alexandrov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14011v1",
    "source": "arXiv",
    "abstract": "The processes of simultaneous coagulation and Ostwald ripening of particles in the concluding stage of phase transformation are considered. We solve the integro-differential system of Smoluchowski-type kinetic and mass balance equations using a computationally efficient numerical algorithm based on low-rank matrices. We compare our numerical solutions for different initial particle-volume distributions with the universal distribution function for combined coagulation and Ostwald ripening. Our calculations confirm the tendency of a particulate ensemble to the universal particle-volume distribution to be approached asymptotically after a sufficiently long time, no matter what the initial particle-volume distribution might be."
  },
  {
    "date": "2026-01-20",
    "title": "Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models",
    "authors": "Hengyuan Zhang, Zhihao Zhang, Mingyang Wang, Zunhai Su, Yiwei Wang, Qianli Wang, Shuzhou Yuan, Ercong Nie, Xufeng Duan, Qibo Xue, Zeping Yu, Chenming Shang, Xiao Liang, Jing Xiong, Hui Shen, Chaofan Tao, Zhengwu Liu, Senjie Jin, Zhiheng Xi, Dongdong Zhang, Sophia Ananiadou, Tao Gui, Ruobing Xie, Hayden Kwok-Hay So, Hinrich Schütze, Xuanjing Huang, Qi Zhang, Ngai Wong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14004v1",
    "source": "arXiv",
    "abstract": "Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: \"Locate, Steer, and Improve.\" We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey."
  },
  {
    "date": "2026-01-20",
    "title": "Interlayer charge transfer from contact electrification in conducting micro and nanoscale thin film heterostructures",
    "authors": "Sandeep Kumar, Ravindra G Bhardwaj",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14003v1",
    "source": "arXiv",
    "abstract": "Contact electrification give rise to charge accumulation at the interface when two materials are brought into contact with each other. The charge accumulation at the interface will diffuse to the interior of the conducting material if the dimensions of the contacting conducting material is of the order of an unknown critical length scale. This contact electrification induced interlayer charge transfer will modify the fundamental physical properties of both the contacting materials. This review first discusses the reported experimental evidence of flexoelectricity induced contact electrification and interlayer charge transfer in conducting thin film based heterostructures. The interlayer charge transfer creates a gradient of charge carrier in both the thin films constituting the heterostructure and also modifies the electron-electron interactions. Further, the interlayer charge transfer changes the electron-phonon coupling, spin-phonon coupling and magnetoelectronic coupling that give rise to new physical behavior, which did not exist prior to the interlayer charge transfer. The new physical behaviors from interlayer charge transfer and their mechanistic origins are reanalyzed and discussed, which include spin-Hall effect of charge carriers, topological Hall effect of magnetoelectronic electromagnon, inhomogeneous magnetoelectronic multiferroic effect, flexoelectronic proximity effect and topological spin texture. This review article presents a unified picture of current status and future directions that will provide the scientists a stepping stone for research in the field of flexoelectricity mediated contact electrification and interlayer charge transfer mediated behavior in the micro/nanoscale heterostructures of the conducting materials."
  },
  {
    "date": "2026-01-20",
    "title": "Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior",
    "authors": "Junwoo Chang, Joseph Park, Roberto Horowitz, Jongmin Lee, Jongeun Choi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14000v1",
    "source": "arXiv",
    "abstract": "Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline."
  },
  {
    "date": "2026-01-20",
    "title": "\"The Whole Is Greater Than the Sum of Its Parts\": A Compatibility-Aware Multi-Teacher CoT Distillation Framework",
    "authors": "Jin Cui, Jiaqi Guo, Jiepeng Zhou, Ruixuan Yang, Jiayi Lu, Jiajun Xu, Jiangcheng Song, Boran Zhao, Pengju Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13992v1",
    "source": "arXiv",
    "abstract": "Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect \"epiphany moments\" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting."
  },
  {
    "date": "2026-01-20",
    "title": "Component systems: do null models explain everything?",
    "authors": "Andrea Mazzolini, Mattia Corigliano, Rossana Droghetti, Matteo Osella, Marco Cosentino-Lagomarsino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13985v1",
    "source": "arXiv",
    "abstract": "Component systems - ensembles of realizations built from a shared repertoire of modular parts - are ubiquitous in biological, ecological, technological, and socio-cultural domains. From genomes to texts, cities, and software, these systems exhibit statistical regularities that often meet the \"bona fide\" requirements of laws in the physical sciences. Here, we argue that the generality and simplicity of those laws are often due to basic combinatorial or sampling constraints, raising the question of whether such patterns are actually revealing system-specific mechanisms and how we might move beyond them. To this end, we first present a unifying mathematical framework, which allows us to compare modular systems in different fields and highlights the common \"null\" trends as well as the system-specific uniqueness, which, arguably, are signatures of the underlying generative dynamics. Next, we can exploit the framework with statistical mechanics and modern machine-learning tools for a twofold objective. (i) Explaining why the general regularities emerge, highlighting the constraints between them and the general principles at their origins, and (ii) \"subtracting\" them from data, which will isolate the informative features for inferring hidden system-specific generative processes, mechanistic and causal aspects."
  },
  {
    "date": "2026-01-20",
    "title": "VirtualCrime: Evaluating Criminal Potential of Large Language Models via Sandbox Simulation",
    "authors": "Yilin Tang, Yu Wang, Lanlan Qiu, Wenchang Gao, Yunfei Ma, Baicheng Chen, Tianxing He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13981v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have shown strong capabilities in multi-step decision-making, planning and actions, and are increasingly integrated into various real-world applications. It is concerning whether their strong problem-solving abilities may be misused for crimes. To address this gap, we propose VirtualCrime, a sandbox simulation framework based on a three-agent system to evaluate the criminal capabilities of models. Specifically, this framework consists of an attacker agent acting as the leader of a criminal team, a judge agent determining the outcome of each action, and a world manager agent updating the environment state and entities. Furthermore, we design 40 diverse crime tasks within this framework, covering 11 maps and 13 crime objectives such as theft, robbery, kidnapping, and riot. We also introduce a human player baseline for reference to better interpret the performance of LLM agents. We evaluate 8 strong LLMs and find (1) All agents in the simulation environment compliantly generate detailed plans and execute intelligent crime processes, with some achieving relatively high success rates; (2) In some cases, agents take severe action that inflicts harm to NPCs to achieve their goals. Our work highlights the need for safety alignment when deploying agentic AI in real-world settings."
  },
  {
    "date": "2026-01-20",
    "title": "The Transparency Paradox in Explainable AI: A Theory of Autonomy Depletion Through Cognitive Load",
    "authors": "Ancuta Margondai, Mustapha Mouloua",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13973v1",
    "source": "arXiv",
    "abstract": "Objective: This paper develops a theoretical framework explaining when and why AI explanations enhance versus impair human decision-making. Background: Transparency is advocated as universally beneficial for human-AI interaction, yet identical AI explanations improve decision quality in some contexts but impair it in others. Current theories--trust calibration, cognitive load, and self-determination--cannot fully account for this paradox. Method: The framework models autonomy as a continuous stochastic process influenced by information-induced cognitive load. Using stochastic control theory, autonomy evolution is formalized as geometric Brownian motion with information-dependent drift, and optimal transparency is derived via Hamilton-Jacobi-Bellman equations. Monte Carlo simulations validate theoretical predictions. Results: Mathematical analysis generates five testable predictions about disengagement timing, working memory moderation, autonomy trajectory shapes, and optimal information levels. Computational solutions demonstrate that dynamic transparency policies outperform both maximum and minimum transparency by adapting to real-time cognitive state. The optimal policy exhibits threshold structure: provide information when autonomy is high and accumulated load is low; withhold when resources are depleted. Conclusion: Transparency effects depend on dynamic cognitive resource depletion rather than static design choices. Information provision triggers metacognitive processing that reduces perceived control when cognitive load exceeds working memory capacity. Application: The framework provides design principles for adaptive AI systems: adjust transparency based on real-time cognitive state, implement information budgets respecting capacity limits, and personalize thresholds based on individual working memory capacity."
  },
  {
    "date": "2026-01-20",
    "title": "Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval",
    "authors": "Joaquín Polonuer, Lucas Vittor, Iñaki Arango, Ayush Noori, David A. Clifton, Luciano Del Corro, Marinka Zitnik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13969v1",
    "source": "arXiv",
    "abstract": "Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate."
  },
  {
    "date": "2026-01-20",
    "title": "Dispersive estimate for quasi-periodic Klein-Gordon equation on 1-d lattices",
    "authors": "Hongyu Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13967v1",
    "source": "arXiv",
    "abstract": "The dispersive estimate plays a pivotal role in establishing the long-term behavior of solutions to the nonlinear equation, thereby being crucial for investigating the well-posedness of the equation.In this work we prove that the solutions to Klein-Gordon equation on 1-d lattices follow the dispersive estimate provided that potential is quasi-periodic with Diophantine frequencies and closed to positive constants."
  },
  {
    "date": "2026-01-20",
    "title": "Information-Theoretic and Computational Limits of Correlation Detection under Graph Sampling",
    "authors": "Dong Huang, Pengkun Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13966v1",
    "source": "arXiv",
    "abstract": "Correlation analysis is a fundamental problem in statistics. In this paper, we consider the correlation detection problem between a pair of Erdos-Renyi graphs. Specifically, the problem is formulated as a hypothesis testing problem: under the null hypothesis, the two graphs are independent; under the alternative hypothesis, the two graphs are edge-correlated through a latent permutation. We focus on the scenario where only two induced subgraphs are sampled, and characterize the sample size threshold for detection. At the information-theoretic level, we establish the sample complexity rates that are optimal up to constant factors over most parameter regimes, and the remaining gap is bounded by a subpolynomial factor. On the algorithmic side, we propose polynomial-time tests based on counting trees and bounded degree motifs, and identify the regimes where they succeed. Moreover, leveraging the low-degree conjecture, we provide evidence of computational hardness that matches our achievable guarantees, showing that the proposed polynomial-time tests are rate-optimal. Together, these results reveal a statistical--computational gap in the sample size required for correlation detection. Finally, we validate the proposed algorithms on synthetic data and a real coauthor network, demonstrating strong empirical performance."
  },
  {
    "date": "2026-01-20",
    "title": "Understanding Optical Anisotropy in Multilayer γ-InSe and ε-GaSe",
    "authors": "Jason Lynch, Zexuan Liu, Sergiy Krylyuk, Huairuo Zhang, Albert Davydov, Deep Jariwala",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13961v1",
    "source": "arXiv",
    "abstract": "Low-dimensional media have exhibited optical anisotropy that is unachievable in traditional 3D media due to the asymmetry of their strong, in-plane covalent bonds and weak out-of-plane van der Waals interactions. As a result, 2D media are promising building blocks for ultrathin devices such as polarimeters, polarized light sources, and active polarizers. III-VI semiconductors possess a rare property in the class of multilayered semiconductors, which is that their fundamental excitons are oriented out-of-plane. This allows them to exhibit phenomena such as transparency in the visible range while also being emissive in the visible and near-infrared ranges. Here, we report the first experimental values for the anisotropic refractive indices of γ-InSe and ε-GaSe, and we observe the effects of the out-of-plane excitons on the c-axis refractive index. It is found that both materials exhibit moderate optical anisotropy for multilayered semiconductors. The complex, anisotropic refractive index of γ-InSe and ε-GaSe enables the accurate simulation of these media, allowing for the design of high-performance, ultra-compact optoelectronic devices."
  },
  {
    "date": "2026-01-20",
    "title": "Dynamic Multiband Microscopy: A Universal Paradigm for Quantitative Nanoscale Metrology",
    "authors": "Boris N. Slautin, Alwikh Rohi, Sanjay Mathur, Arun Ichangi, Sergei V. Kalinin, Doru C. Lupascu, Vladimir V. Shvartsman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13960v1",
    "source": "arXiv",
    "abstract": "Scanning Probe Microscopy (SPM) is the primary tool for exploring nanoscale functionality, yet standard single-frequency operation is fundamentally limited, because the dynamic tip-sample interaction is mathematically underdetermined. While advanced methods such as Dual Amplitude Resonance Tracking (DART) and Band Excitation (BE) address this by tracking resonance, they face critical limitations: DART suffers from feedback instability on complex topographies, while Band Excitation is constrained by severe trade-offs between spectral resolution and acquisition speed. Here, we introduce Dynamic Multiband Microscopy (DMM), a general framework that bridges these gaps by combining multifrequency excitation with continuous frequency sweeping. We implement this within an automated experimental workflow that autonomously identifies and targets measurement points of interest. In combination with quantitative interferometric detection, this approach brings SPM to the fundamental limits of noise and spectral sensitivity. Validated on ferroelectric nanofibers, this platform enables simultaneous, crosstalk-free 3D polarization mapping, establishing a universal framework for autonomous, high-fidelity nanoscale metrology."
  },
  {
    "date": "2026-01-20",
    "title": "Where to Place a Heavy Payload on a Multirotor UAV for Best Control Performance",
    "authors": "Sander Doodeman, Paula Chanfreut Palacio, Elena Torta, Duarte Antunes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13958v1",
    "source": "arXiv",
    "abstract": "This paper studies the impact of rigidly attached heavy payload placement - where the payload mass significantly influences the UAV's dynamics - on the stability and control performance of a multirotor unmanned aerial vehicle (UAV). In particular, we focus on how the position of such a payload relative to the vehicle's Center of Gravity (CoG) affects the stability and control performance at an arbitrary point of interest on the UAV, such as the payload position, and on how this position can be optimized. Our conclusions are based on two key contributions. First, we analyze the stability of the zero-dynamics of a complete nonlinear model of the UAV with payload. We demonstrate that the stability of the zero dynamics depends on the vertical signed distance in the body-fixed frame between the controlled output position and the combined CoG of the UAV with payload. Specifically, positioning the output below the CoG yields unstable zero dynamics, while the linearized zero dynamics are marginally stable when placing it above, indicating reduced sensitivity to input disturbances. Second, we analyze the performance of the linearized UAV model with payload by providing an analytical expression for the H2-norm, from which we can quantify the system's attenuation to white noise input disturbances. We conclude that less control authority leads to a higher optimal position of the controlled output with respect to the CoG for closed-loop white-noise disturbance rejection capabilities, also when the heavy payload is the controlled output. The results are illustrated through numerical examples."
  },
  {
    "date": "2026-01-20",
    "title": "DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging",
    "authors": "Adrien Meyer, Didier Mutter, Nicolas Padoy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13954v1",
    "source": "arXiv",
    "abstract": "Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy."
  },
  {
    "date": "2026-01-20",
    "title": "Secular Evolution of PSR J2021+4026: Long-Term γ-Ray Flux and Spin-Down Variability Beyond State Transitions",
    "authors": "Xue-Zhi Liu, Ming-Yu Ge, Xiao-Ping Zheng, Xiao-Bo Li, Han-Long Peng, Wen-Tao Ye, Bo-Yan Chen, Shi-Jie Zheng, Fang-Jun Lu, Shuang-Nan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13940v1",
    "source": "arXiv",
    "abstract": "PSR J2021+4026 is a remarkable $γ$-ray pulsar exhibiting repeated transitions between high $γ$-ray flux (HGF) and low $γ$-ray flux (LGF) states. With 17-yr Fermi-LAT monitoring, we reveal persistent secular evolution and enhanced spin-down rate variability within individual emission states -- beneath the quasi-periodic state transitions. After removing discrete jumps, the jump-corrected flux $δF_γ$ shows a three-phase evolution: rise ($+2.02^{+0.17}_{-0.15}\\%~\\mathrm{yr}^{-1}$), decline ($-3.72^{+0.34}_{-0.47}\\%~\\mathrm{yr}^{-1}$), and rapid rise ($+14.9^{+6.4}_{-4.4}\\%~\\mathrm{yr}^{-1}$), with all rates quoted relative to the long-term mean flux $\\langle F_γ\\rangle=7.8\\times 10^{-10}\\,\\mathrm{erg}\\,\\mathrm{cm}^{-2}\\,\\mathrm{s}^{-1}$. Moreover, the flux of the LGF state is gradually approaching the stable HGF level at a rate of $+0.72 \\pm 0.11\\%~\\mathrm{yr}^{-1}$. These results demonstrate that secular flux evolution in PSR J2021+4026 operates largely independently of discrete state transitions, yet jointly with them drives the system toward a stable high-flux equilibrium."
  },
  {
    "date": "2026-01-20",
    "title": "VulnResolver: A Hybrid Agent Framework for LLM-Based Automated Vulnerability Issue Resolution",
    "authors": "Mingming Zhang, Xu Wang, Jian Zhang, Xiangxin Meng, Jiayi Zhang, Chunming Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13933v1",
    "source": "arXiv",
    "abstract": "As software systems grow in complexity, security vulnerabilities have become increasingly prevalent, posing serious risks and economic costs. Although automated detection tools such as fuzzers have advanced considerably, effective resolution still often depends on human expertise. Existing automated vulnerability repair (AVR) methods rely heavily on manually provided annotations (e.g., fault locations or CWE labels), which are often difficult and time-consuming to obtain, while overlooking the rich, naturally embedded semantic context found in issue reports from developers. In this paper, we present VulnResolver, the first LLM-based hybrid agent framework for automated vulnerability issue resolution. VulnResolver unites the adaptability of autonomous agents with the stability of workflow-guided repair through two specialized agents. The Context Pre-Collection Agent (CPCAgent) adaptively explores the repository to gather dependency and contextual information, while the Safety Property Analysis Agent (SPAAgent) generates and validates the safety properties violated by vulnerabilities. Together, these agents produce structured analyses that enrich the original issue reports, enabling more accurate vulnerability localization and patch generation. Evaluations on the SEC-bench benchmark show that VulnResolver resolves 75% of issues on SEC-bench Lite, achieving the best resolution performance. On SEC-bench Full, VulnResolver also significantly outperforms the strongest baseline, the agent-based OpenHands, confirming its effectiveness. Overall, VulnResolver delivers an adaptive and security-aware framework that advances end-to-end automated vulnerability issue resolution through workflow stability and the specialized agents' capabilities in contextual reasoning and property-based analysis."
  },
  {
    "date": "2026-01-20",
    "title": "Towards Effective Negation Modeling in Joint Audio-Text Models for Music",
    "authors": "Yannis Vasilakis, Rachel Bittner, Johan Pauwels",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13931v1",
    "source": "arXiv",
    "abstract": "Joint audio-text models are widely used for music retrieval, yet they struggle with semantic phenomena such as negation. Negation is fundamental for distinguishing the absence (or presence) of musical elements (e.g., \"with vocals\" vs. \"without vocals\"), but current systems fail to represent this reliably. In this work, we investigate and mitigate this limitation by training CLAP models from scratch on the Million Song Dataset with LP-MusicCaps-MSD captions. We introduce negation through text augmentation and a dissimilarity-based contrastive loss, designed to explicitly separate original and negated captions in the joint embedding space. To evaluate progress, we propose two protocols that frame negation modeling as retrieval and binary classification tasks. Experiments demonstrate that both methods, individually and combined, improve negation handling while largely preserving retrieval performance."
  },
  {
    "date": "2026-01-20",
    "title": "On spectral clustering under non-isotropic Gaussian mixture models",
    "authors": "Kohei Kawamoto, Yuichi Goto, Koji Tsukuda",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13930v1",
    "source": "arXiv",
    "abstract": "We evaluate the misclustering probability of a spectral clustering algorithm under a Gaussian mixture model with a general covariance structure. The algorithm partitions the data into two groups based on the sign of the first principal component score. As a corollary of the main result, the clustering procedure is shown to be consistent in a high-dimensional regime."
  },
  {
    "date": "2026-01-20",
    "title": "Universal composite phase gates with tunable target phase",
    "authors": "Peter Chernev, Mouhamad Al-Mahmoud, Andon A. Rangelov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13923v1",
    "source": "arXiv",
    "abstract": "We present a systematic method for constructing universal composite phase gates with a continuously tunable target phase. Using a general Cayley--Klein parametrization of the single-pulse propagator, we design gates from an even number of nominal $π$ pulses and derive analytic phase families by canceling, order by order in a small deviation parameter, the leading contributions to the undesired off-diagonal element of the composite propagator, independently of the dynamical phase. The resulting sequences provide intrinsic robustness against generic control imperfections and parameter fluctuations and remain valid for arbitrary pulse shapes. Numerical simulations in a standard two-level model confirm high-order error suppression and demonstrate broad, flat high-fidelity plateaus over wide ranges of simultaneous pulse-area and detuning errors, highlighting the efficiency of the proposed universal composite phase gates for resilient phase control in quantum information processing."
  },
  {
    "date": "2026-01-20",
    "title": "Automatic Prompt Optimization for Dataset-Level Feature Discovery",
    "authors": "Adrian Cosma, Oleg Szehr, David Kletz, Alessandro Antonucci, Olivier Pelletier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13922v1",
    "source": "arXiv",
    "abstract": "Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text."
  },
  {
    "date": "2026-01-20",
    "title": "The properad of quadratic Poisson structures is Koszul",
    "authors": "Anton Khoroshkin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13921v1",
    "source": "arXiv",
    "abstract": "In this paper, we suggest a sufficient condition on the properadic envelope of a quadratic dioperad to be Koszul in terms of twisted associative algebras. As a particular new example, we show that the properad of quadratic Poisson structures is Koszul."
  },
  {
    "date": "2026-01-20",
    "title": "Asymmetric regularization mechanism for GAN training with Variational Inequalities",
    "authors": "Spyridon C. Giagtzoglou, Mark H. M. Winands, Barbara Franci",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13920v1",
    "source": "arXiv",
    "abstract": "We formulate the training of generative adversarial networks (GANs) as a Nash equilibrium seeking problem. To stabilize the training process and find a Nash equilibrium, we propose an asymmetric regularization mechanism based on the classic Tikhonov step and on a novel zero-centered gradient penalty. Under smoothness and a local identifiability condition induced by a Gauss-Newton Gramian, we obtain explicit Lipschitz and (strong)-monotonicity constants for the regularized operator. These constants ensure last-iterate linear convergence of a single-call Extrapolation-from-the-Past (EFTP) method. Empirical simulations on an academic example show that, even when strong monotonicity cannot be achieved, the asymmetric regularization is enough to converge to an equilibrium and stabilize the trajectory."
  },
  {
    "date": "2026-01-20",
    "title": "HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs",
    "authors": "Yuezhe Yang, Hao Wang, Yige Peng, Jinman Kim, Lei Bi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13919v1",
    "source": "arXiv",
    "abstract": "Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \\textbf{HyperWalker}, a \\textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \\textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \\textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \\textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker"
  },
  {
    "date": "2026-01-20",
    "title": "AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization",
    "authors": "Yusheng Liao, Chuan Xuan, Yutong Cai, Lina Yang, Zhe Chen, Yanfeng Wang, Yu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13918v1",
    "source": "arXiv",
    "abstract": "Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%."
  },
  {
    "date": "2026-01-20",
    "title": "Decentralized Infrastructure for Digital Notarizing, Signing and Sharing Files using Blockchain",
    "authors": "Cosmin-Iulian Irimia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13907v1",
    "source": "arXiv",
    "abstract": "Traditional paper-based document management has long posed challenges related to security, authenticity, and efficiency. Despite advances in digitalization, official documents remain vulnerable to forgery, loss, and unauthorized access. This thesis proposes a decentralized infrastructure for digital notarization, signing, and sharing of documents using blockchain technology. The research addresses key issues of transparency, immutability, and feasibility by defining system requirements, evaluating existing solutions, and proposing a novel architecture based on distributed systems. By combining cryptographic techniques with decentralized storage, this research contributes to the development of a more secure and efficient framework for managing official documents. The findings highlight the potential of blockchain-based digital notarization to streamline bureaucratic processes, mitigate security risks, and enhance user trust in digital document management."
  },
  {
    "date": "2026-01-20",
    "title": "Multi-Objective Hierarchical Optimization with Large Language Models",
    "authors": "Andrej Schwanke, Lyubomir Ivanov, David Salinas, Frank Hutter, Arber Zela",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13892v1",
    "source": "arXiv",
    "abstract": "Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks."
  },
  {
    "date": "2026-01-20",
    "title": "Intelligent Distributed Optical Fiber Sensing in Transportation Infrastructures: Research Progress, Applications, and Challenges",
    "authors": "Xin Gui, Fanhao Zeng, Yunchuan Zhang, Yiming Wang, Jiaqi Wang, Changjia Wang, Xuelei Fu, Sheng Li, Fang Liu, Lina Yue, Jinpeng Jiang, Zhengying Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13891v1",
    "source": "arXiv",
    "abstract": "Distributed optical fiber sensing (DOFS), along with its capabilities of long-range coverage, multi-parameter monitoring, and completely passive detection, emerges as one of the most promising non-destructive detection techniques for structural health monitoring (SHM) and operational assessment of linear transportation infrastructures. In this paper, we provide a state-of-the-art review on DOFS applications across typical linear infrastructure systems, encompassing highways, long-span bridges, rail transit networks, airport runways, and analogous linear structures. The comprehensive discussion consists of four critical research dimensions: 1) optical fiber selection for multi-parameter sensing and robust cable packaging techniques, 2) distributed sensing principles and signal processing algorithms, 3) diverse application scenarios in SHM and related fields, and 4) anomaly detection and event classification methodologies. Building upon the foundational introduction of DOFS technical principles and monitoring solutions for intelligent transportation infrastructure, this paper elaborates on system design approaches, sensing data analytics algorithms, and future research directions."
  },
  {
    "date": "2026-01-20",
    "title": "Correlation-driven branch in doped excitonic insulators",
    "authors": "Tatsuya Kaneko, Ryota Ueda, Satoshi Ejima",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13890v1",
    "source": "arXiv",
    "abstract": "We investigate the spectral properties of a doped one-dimensional excitonic insulator. Employing matrix-product-state-based methods, we compute the single-particle spectrum and optical conductivity in a correlated two-band model. Our numerical calculation reveals the emergence of a correlation-driven in-gap branch in the doped state. The origin of the in-gap branch is examined by decomposing the propagation dynamics of a single particle, elucidating that the doping-induced branch is associated with excitonic correlations. Our demonstrations suggest that the doping-induced branch can serve as an indicator of electron-hole correlations."
  },
  {
    "date": "2026-01-20",
    "title": "Optimizing the Geometry of an L-Shaped Building to Enhance Energy Efficiency and Sustainability",
    "authors": "Ewa Rokita-Magdziarz, Barbara Gronostajska, Marcin Magdziarz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13884v1",
    "source": "arXiv",
    "abstract": "The geometric form of a building strongly influences its material use, heat losses, and energy efficiency. This paper presents an analytical optimization of L-shaped residential buildings aimed at minimizing the external surface area for a prescribed volume. Both symmetric and asymmetric configurations are examined under realistic design constraints, including fixed or bounded wing aspect ratios and fixed building height. Using explicit optimization methods and Karush-Kuhn-Tucker conditions, closed-form expressions for the optimal geometric parameters and minimal envelope area are derived. The results show that unconstrained optimization leads to degenerate cuboid shapes, highlighting the importance of geometric constraints to preserve the L-shaped form. The obtained results provide practical design guidelines for architects and engineers, supporting informed early stage decisions that balance functional requirements, regulatory constraints, architectural intent, and energy performance. Case studies of existing houses demonstrate that the proposed approach can reduce external surface area or confirm near-optimality of practical designs, supporting energy-efficient early-stage architectural decisions."
  },
  {
    "date": "2026-01-20",
    "title": "OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models",
    "authors": "Unggi Lee, Sookbun Lee, Heungsoo Choi, Jinseo Lee, Haeun Park, Younghoon Jeon, Sungmin Cho, Minju Kang, Junbo Koh, Jiyeong Bae, Minwoo Nam, Juyeon Eun, Yeonji Jung, Yeil Jeong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13882v1",
    "source": "arXiv",
    "abstract": "Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts."
  },
  {
    "date": "2026-01-20",
    "title": "Audio Outperforms Text for Visual Decoding",
    "authors": "Zhengdi Zhang, Hao Zhang, Wenjun Xia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13866v1",
    "source": "arXiv",
    "abstract": "Decoding visual semantic representations from human brain activity is a significant challenge. While recent zero-shot decoding approaches have improved performance by leveraging aligned image-text datasets, they overlook a fundamental aspect of human cognition: semantic understanding is inherently anchored in the auditory modality of speech, not text. To address this, our study introduces the first comparative framework for evaluating auditory versus textual semantic modalities in zero-shot visual neural decoding. We propose a novel brain-visual-auditory multimodal alignment model that directly utilizes auditory representations to encapsulate semantics, serving as a substitute for traditional textual descriptors. Our experimental results demonstrate that the auditory modality not only surpasses the textual modality in decoding accuracy but also achieves higher computational efficiency. These findings indicate that auditory semantic representations are more closely aligned with neural activity patterns during visual processing. This work reveals the critical and previously underestimated role of auditory semantics in decoding visual cognition and provides new insights for developing brain-computer interfaces that are more congruent with natural human cognitive mechanisms."
  },
  {
    "date": "2026-01-20",
    "title": "HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation",
    "authors": "Qirui Chen, Jingxian Shuai, Shuangwu Chen, Shenghao Ye, Zijian Wen, Xufei Su, Jie Jin, Jiangming Li, Jun Chen, Xiaobin Tan, Jian Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13864v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon."
  },
  {
    "date": "2026-01-20",
    "title": "Inverse Area Corrections to Black Hole Entropy Area Formula in F(R) Gravity and Gravitational Wave Observations",
    "authors": "Rohit Das, Parthasarathi Majumdar, Debadrita Mukherjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13863v1",
    "source": "arXiv",
    "abstract": "We consider corrections to the Bekenstein Hawking Area Formula for black hole entropy, which have inverse powers of the horizon area for very large horizon areas, for classical spherically symmetric black hole solutions of F(R) modified gravity theory, using the Wald formula for the entropy function with modifications suggested by Jacobson, Kang and Myers. Requiring that the coefficient of such corrections be absolutely consistent with gravitational wave observational results validating the Hawking Area Theorem for binary black hole coalescences, implies constraints on parameters of F(R) gravity. For the sake of comparison, we present a computation of inverse area corrections for quantum black holes in quantum general relativity, using the It from Bit approach of Wheeler modified by some tenets of Loop Quantum Gravity."
  },
  {
    "date": "2026-01-20",
    "title": "RNLE: Residual neural likelihood estimation and its application to gravitational-wave astronomy",
    "authors": "Mattia Emma, Gregory Ashton",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13857v1",
    "source": "arXiv",
    "abstract": "Simulation-based inference provides a powerful framework for Bayesian inference when the likelihood is analytically intractable or computationally prohibitive. By leveraging machine-learning techniques and neural density estimators, it enables flexible likelihood or posterior modeling directly from simulations. We introduce Residual Neural Likelihood Estimation (RNLE), a modification of Neural Likelihood Estimation (NLE) that learns the likelihood of non-Gaussian noise in gravitational-wave detector data. Exploiting the additive structure of the signal and noise generation processes, RNLE directly models the noise distribution, substantially reducing the number of simulations required for accurate parameter estimation and improving robustness to realistic noise artifacts. The performance of RNLE is demonstrated using a toy model, simulated gravitational-wave signals, and real detector noise from ground based interferometers. Even in the presence of loud non-Gaussian transients, glitches, we show that RNLE can achieve reliable parameter recovery when trained on appropriately constructed datasets. We further assess the stability of the method by quantifying the variability introduced by retraining the conditional density estimator on statistically identical datasets with different optimization seeds, referred to as training noise. This variability can be mitigated through an ensemble approach that combines multiple RNLE models using evidence-based weighting. An implementation of RNLE is publicly available in the sbilby package, enabling its deployment within gravitational-wave astronomy and a broad range of scientific applications requiring flexible, simulation-based likelihood estimation."
  },
  {
    "date": "2026-01-20",
    "title": "Derivative free data-driven stabilization of continuous-time linear systems from input-output data",
    "authors": "Corrado Possieri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13848v1",
    "source": "arXiv",
    "abstract": "This letter presents a data-driven framework for the design of stabilizing controllers from input-output data in the continuous-time, linear, and time-invariant domain. Rather than relying on measurements or reliable estimates of input and output time derivatives, the proposed approach uses filters to derive a parameterization of the system dynamics. This parameterization is amenable to the application of linear matrix inequalities enabling the design of stabilizing output feedback controllers from input-output data and the knowledge of the order of the system."
  },
  {
    "date": "2026-01-20",
    "title": "Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments",
    "authors": "Glinskaya Maria",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13846v1",
    "source": "arXiv",
    "abstract": "This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics."
  },
  {
    "date": "2026-01-20",
    "title": "Small Models, Big Impact: Tool-Augmented AI Agents for Wireless Network Planning",
    "authors": "Yongqiang Zhang, Mustafa A. Kishk, Mohamed-Slim Alouini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13843v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) such as ChatGPT promise revolutionary capabilities for Sixth-Generation (6G) wireless networks but their massive computational requirements and tendency to generate technically incorrect information create deployment barriers. In this work, we introduce MAINTAINED: autonomous artificial intelligence agent for wireless network deployment. Instead of encoding domain knowledge within model parameters, our approach orchestrates specialized computational tools for geographic analysis, signal propagation modeling, and network optimization. In a real-world case study, MAINTAINED outperforms state-of-the-art LLMs including ChatGPT-4o, Claude Sonnet 4, and DeepSeek-R1 by up to 100-fold in verified performance metrics while requiring less computational resources. This paradigm shift, moving from relying on parametric knowledge towards externalizing domain knowledge into verifiable computational tools, eliminates hallucination in technical specifications and enables edge-deployable Artificial Intelligence (AI) for wireless communications."
  },
  {
    "date": "2026-01-20",
    "title": "Nanoparticle Self-assembly Assisted by Polymers: The Role of Shear Stress in the Nanoparticle Arrangement of Langmuir and Langmuir-Blodgett Films",
    "authors": "Beatriz Martín-García, M. Mercedes Velázquez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13842v1",
    "source": "arXiv",
    "abstract": "We propose to use the self-assembly ability of a block copolymer combined with compression-expansion cycles to obtain CdSe quantum dots (QDs) structures of different morphology. The methodology proposed consists in transferring onto mica mixed Langmuir monolayers of QDs and the polymer poly (styrene-co-maleic anhydride) partial 2 buthoxy ethyl ester cumene terminated, PS-MA-BEE, previously sheared by 50 compression-expansion cycles. Results indicate that the shear stress takes out nanoparticles at the air-water interface from metastable states and promoted a new equilibrium state of the Langmuir monolayer, then it was transferred onto mica by the Langmuir-Blodgett (LB) methodology and the morphology of the LB films was analyzed by Atomic Force Microscopy and Transmission Electron Microscopy measurements. Our results show that when the amplitude strain increases the QDs domain size decreases and the LB film becomes more ordered. The dynamic of the monolayer relaxation after cycling involves at least three timescales which are related to the damping of surface fluctuation, raft rearrangement and component movements inside each raft. Brewster Angle Microscopy allowed visualizing in situ the raft rearrangement at the air-water interface."
  },
  {
    "date": "2026-01-20",
    "title": "A Predictive and Preventive Digital Twin Framework for Indoor Wireless Networks",
    "authors": "Jiunn-Tsair Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13838v1",
    "source": "arXiv",
    "abstract": "Wi-Fi networks increasingly suffer from performance degradation caused by contention-based channel access, dense deployments, and largely self-managed operation among mutually interfering access points (APs). In this paper, we propose a Digital Twin (DT) framework that captures the essential spatial and temporal characteristics of wireless channels and traffic patterns, enabling the prediction of likely future network scenarios while respecting physical constraints. Leveraging this predictive capability, we introduce two analytically derived performance upper bounds-one based on Shannon capacity and the other on latency behavior under CSMA-CA (Carrier Sense Multiple Access with Collision Avoidance)-that can be evaluated efficiently without time-consuming network simulations. By applying importance sampling to DT-generated scenarios, potentially risky network conditions can be identified within large stochastic scenario spaces. These same performance bounds are then used to proactively guide a gradient-based search for improved network configurations, with the objective of avoiding imminent performance degradation rather than pursuing globally optimal but fragile solutions. Simulation results demonstrate that the proposed approach can successfully predict time-dependent network congestion and mitigate it in advance, highlighting its potential for predictive and preventive Wi-Fi network management."
  },
  {
    "date": "2026-01-20",
    "title": "FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation",
    "authors": "Xinya Ji, Sebastian Weiss, Manuel Kansy, Jacek Naruniec, Xun Cao, Barbara Solenthaler, Derek Bradley",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13837v1",
    "source": "arXiv",
    "abstract": "Despite recent progress in 3D Gaussian-based head avatar modeling, efficiently generating high fidelity avatars remains a challenge. Current methods typically rely on extensive multi-view capture setups or monocular videos with per-identity optimization during inference, limiting their scalability and ease of use on unseen subjects. To overcome these efficiency drawbacks, we propose \\OURS, a feed-forward method to generate high-quality Gaussian head avatars from only a few input images while supporting real-time animation. Our approach directly learns a per-pixel Gaussian representation from the input images, and aggregates multi-view information using a transformer-based encoder that fuses image features from both DINOv3 and Stable Diffusion VAE. For real-time animation, we extend the explicit Gaussian representations with per-Gaussian features and introduce a lightweight MLP-based dynamic network to predict 3D Gaussian deformations from expression codes. Furthermore, to enhance geometric smoothness of the 3D head, we employ point maps from a pre-trained large reconstruction model as geometry supervision. Experiments show that our approach significantly outperforms existing methods in both rendering quality and inference efficiency, while supporting real-time dynamic avatar animation."
  },
  {
    "date": "2026-01-20",
    "title": "The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations",
    "authors": "Sam OConnor Russell, Delphine Charuau, Naomi Harte",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13835v1",
    "source": "arXiv",
    "abstract": "Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research."
  },
  {
    "date": "2026-01-20",
    "title": "Two-dimensional FrBD friction models for rolling contact: extension to linear viscoelasticity",
    "authors": "Luigi Romano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13818v1",
    "source": "arXiv",
    "abstract": "This paper extends the distributed rolling contact FrBD framework to linear viscoelasticity by considering classic derivative Generalised Maxwell and Kelvin-Voigt rheological representations of the bristle element. With this modelling approach, the dynamics of the bristle, generated friction forces, and internal deformation states are described by a system of 2(n+1) hyperbolic partial differential equations (PDEs), which can capture complex relaxation phenomena originating from viscoelastic behaviours. By appropriately specifying the analytical expressions for the transport and rigid relative velocity, three distributed formulations of increasing complexity are introduced, which account for different levels of spin excitation. For the linear variants, well-posedness and passivity are analysed rigorously, showing that these properties hold for any physically meaningful parametrisation. Numerical experiments complement the theoretical results by illustrating steady-state characteristics and transient relaxation effects. The findings of this paper substantially advance the FrBD paradigm by enabling a unified and systematic treatment of linear viscoelasticity."
  },
  {
    "date": "2026-01-20",
    "title": "DroneVLA: VLA based Aerial Manipulation",
    "authors": "Fawad Mehboob, Monijesu James, Amir Habel, Jeffrin Sam, Miguel Altamirano Cabrera, Dzmitry Tsetserukou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13809v1",
    "source": "arXiv",
    "abstract": "As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations."
  },
  {
    "date": "2026-01-20",
    "title": "HoverAI: An Embodied Aerial Agent for Natural Human-Drone Interaction",
    "authors": "Yuhua Jin, Nikita Kuzmin, Georgii Demianchuk, Mariya Lezina, Fawad Mehboob, Issatay Tokmurziyev, Miguel Altamirano Cabrera, Muhammad Ahsan Mustafa, Dzmitry Tsetserukou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13801v1",
    "source": "arXiv",
    "abstract": "Drones operating in human-occupied spaces suffer from insufficient communication mechanisms that create uncertainty about their intentions. We present HoverAI, an embodied aerial agent that integrates drone mobility, infrastructure-independent visual projection, and real-time conversational AI into a unified platform. Equipped with a MEMS laser projector, onboard semi-rigid screen, and RGB camera, HoverAI perceives users through vision and voice, responding via lip-synced avatars that adapt appearance to user demographics. The system employs a multimodal pipeline combining VAD, ASR (Whisper), LLM-based intent classification, RAG for dialogue, face analysis for personalization, and voice synthesis (XTTS v2). Evaluation demonstrates high accuracy in command recognition (F1: 0.90), demographic estimation (gender F1: 0.89, age MAE: 5.14 years), and speech transcription (WER: 0.181). By uniting aerial robotics with adaptive conversational AI and self-contained visual output, HoverAI introduces a new class of spatially-aware, socially responsive embodied agents for applications in guidance, assistance, and human-centered interaction."
  },
  {
    "date": "2026-01-20",
    "title": "A Hybridizable Discontinuous Galerkin Method for the non--local Camassa--Holm--Kadomtsev--Petviashvili equation",
    "authors": "Mukul Dwivedi, Ruben Gutendorf, Andreas Rupp",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13800v1",
    "source": "arXiv",
    "abstract": "This paper develops a hybridizable discontinuous Galerkin method for the two-dimensional Camassa--Holm--Kadomtsev--Petviashvili equation. The method employs Cartesian meshes with tensor-product polynomial spaces, enabling separate treatment of \\(x\\) and \\(y\\) derivatives. The non-local operator \\(\\partial_{x}^{-1}u_{y}\\) is localized through an auxiliary variable \\(v\\) satisfying \\(v_x = u_y\\), allowing efficient element-by-element computations. We prove energy stability of the semi-discrete scheme and derive \\(\\mathcal{O}(h^{k+1/2})\\) convergence in space. Numerical experiments validate the theoretical results and demonstrate the method's capability to accurately resolve smooth solutions and peaked solitary waves (peakons)."
  },
  {
    "date": "2026-01-20",
    "title": "PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval",
    "authors": "Gabriele Serussi, David Vainshtein, Jonathan Kouchly, Dotan Di Castro, Chaim Baskin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13797v1",
    "source": "arXiv",
    "abstract": "Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities."
  },
  {
    "date": "2026-01-20",
    "title": "Demystifying Starlink Network Performance under Vehicular Mobility with Dynamic Beam Switching",
    "authors": "Jinwei Zhao, Jack Baude, Ali Ahangarpour, Vaibhava Krishna Devulapalli, Sree Ganesh Lalitaditya Divakarla, Zhi-Li Zhang, Jianping Pan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13790v1",
    "source": "arXiv",
    "abstract": "In the last few years, considerable research efforts have focused on measuring and improving Starlink network performance, especially for user terminals (UTs) in stationary scenarios. However, the performance of Starlink networks in mobility settings, particularly with frequent changes in the UT's orientation, and the impact of environmental factors, such as transient obstructions, has not been thoroughly studied, leaving gaps in understanding the causes of performance degradation. Recently, researchers have started identifying the communicating satellites to evaluate satellite selection strategies and the impact on network performance. However, existing Starlink satellite identification methods only work in stationary, obstruction-free scenarios, as they do not account for UT mobility, obstructions or detect dynamic beam switching events. In this paper, we reveal that the UT can perform multiple dynamic beam switching attempts to connect to different satellites when the UT-satellite link is degraded. This degradation can occur either due to the loss of line-of-sight (LoS) from changes in the FOV or obstructions, or due to poor signal quality, extending UT-satellite handovers beyond the well-known 15-second regular handover interval. We propose a mobility-aware Starlink satellite identification method that detects dynamic beam switching events, and plausibly explain network performance using UT's diagnostic data and connected satellite information. Our findings demystifies the mobile Starlink network performance degradations, which is crucial to enhance the end-to-end performance of transport layer protocols and in diverse application scenarios."
  },
  {
    "date": "2026-01-20",
    "title": "A Blockchain-Oriented Software Engineering Architecture for Carbon Credit Certification Systems",
    "authors": "Matteo Vaccargiu, Azmat Ullah, Pierluigi Gallo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13772v1",
    "source": "arXiv",
    "abstract": "Carbon credit systems have emerged as a policy tool to incentivize emission reductions and support the transition to clean energy. Reliable carbon-credit certification depends on mechanisms that connect actual, measured renewable-energy production to verifiable emission-reduction records. Although blockchain and IoT technologies have been applied to emission monitoring and trading, existing work offers limited support for certification processes, particularly for small and medium-scale renewable installations. This paper introduces a blockchain-based carbon-credit certification architecture, demonstrated through a 100 kWp photovoltaic case study, that integrates real-time IoT data collection, edge-level aggregation, and secure on-chain storage on a permissioned blockchain with smart contracts. Unlike approaches focused on trading mechanisms, the proposed system aligns with European legislation and voluntary carbon-market standards, clarifying the practical requirements and constraints that apply to photovoltaic operators. The resulting architecture provides a structured pathway for generating verifiable carbon-credit records and supporting third-party verification."
  },
  {
    "date": "2026-01-20",
    "title": "Interoperable rApp/xApp Control over O-RAN for Mobility-aware Dynamic Spectrum Allocation",
    "authors": "Anastasios Giannopoulos, Sotirios Spantideas, Maria Lamprini Bartsioka, Panagiotis Trakadas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13769v1",
    "source": "arXiv",
    "abstract": "Open Radio Access Networks (O-RAN) enable the disaggregation of radio access functions and the deployment of control applications across different timescales. However, designing interoperable control schemes that jointly exploit long-term traffic awareness and near-real-time radio resource optimization remains a challenging problem, particularly under dense multi-cell interference and heterogeneous service demands. This paper proposes an interoperable rApp/xApp-driven dynamic spectrum allocation (DSA) framework for O-RAN, based on a graph-theoretic formulation of physical resource block (PRB) assignment. The proposed architecture leverages a non-real-time radio intelligent controller (Non-RT RIC) rApp to predict aggregated traffic evolution and generate high-level spectrum policies at the minutes timescale, while a near-real-time RIC (Near-RT RIC) xApp constructs a user-centric conflict graph and performs fairness-aware PRB allocation at sub-second timescales. To mitigate persistent user starvation, a conflict-aware modified proportional fair (MPF) scheduling mechanism is applied, enabling controlled interference-free PRB time-sharing. Extensive simulation results demonstrate that the proposed framework significantly improves the PRB assignment success rate (above 90%) and service-share fairness (above 85%) across different channel configurations and user demands, while maintaining architectural separation and rApp/xApp interoperability in accordance with O-RAN principles."
  },
  {
    "date": "2026-01-20",
    "title": "vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting",
    "authors": "Wenzhen Yue, Ruohao Guo, Ji Shi, Zihan Hao, Shiyu Hu, Xianghua Ying",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13768v1",
    "source": "arXiv",
    "abstract": "In this paper, we present \\textbf{vLinear}, an effective yet efficient \\textbf{linear}-based multivariate time series forecaster featuring two components: the \\textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \\textbf{velocity-oriented} flow matching objectives, we demonstrate that a \\textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear."
  },
  {
    "date": "2026-01-20",
    "title": "SIRIUS: Dark matter cusp evolution in dense dwarf galaxies",
    "authors": "Katsuhiro Kaneko, Takayuki R. Saitoh, Yutaka Hirai, Michiko S. Fujii",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13765v1",
    "source": "arXiv",
    "abstract": "Dwarf galaxies have a wide variety of structures, such as dark matter (DM) distribution, stellar-to-halo mass ratio, and stellar density. Recent high-resolution simulations have shown a variety of stellar-to-halo mass ratios for dwarf galaxies with a DM halo mass of $\\sim 10^9 M_{\\odot}$ at $z=0$. In this study, we performed cosmological $N$-body/smoothed-particle hydrodynamic zoom-in simulations of dwarf galaxies with the highest gas and DM particle mass resolutions of 2.37 $M_{\\odot}$ and 12.8 $M_{\\odot}$, respectively. The stellar-to-DM halo mass ratio of one of our simulated dwarf galaxies was $\\sim 10^{-4}$, typical for satellites of the Milky Way. The stellar mass ($10^5 M_{\\odot}$) and half-mass radius (68 pc) were also similar to those of the satellites of the Milky Way. The power-law slope of the DM halo was $α= -1.1$. On the other hand, the other simulated galaxy exhibited a stellar-to-halo mass ratio of $\\sim 10^{-3}$ and a steeper power-law slope ($α=-1.9$) than the other; the presence of baryonic matter deepened the cusp. The mass of $>10^6 M_{\\odot}$ and a half-mass radius of $\\sim 36$ pc of this galaxy were similar to those of ultra-compact dwarf galaxies rather than the satellites of the Milky Way. This DM halo grew in mass earlier than the former one, and the central DM density was higher than that of the other even in the DM-only simulations."
  },
  {
    "date": "2026-01-20",
    "title": "Quantum Entanglement Geometry on Severi-Brauer Schemes: Subsystem Reductions of Azumaya Algebras",
    "authors": "Kazuki Ikeda",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13764v1",
    "source": "arXiv",
    "abstract": "We formulate pure-state entanglement in families as a geometric obstruction. In standard quantum information, entanglement is defined relative to a chosen tensor-product factorization of a fixed Hilbert space. In contrast, for a twisted family of pure-state spaces, which can be described by Azumaya algebras $A$ of degree $n$ on $X$ and their Severi-Brauer schemes \\[ SB(A)=P\\times^{PGL_n}\\mathbb{P}^{n-1}\\to X, \\] such a subsystem choice may fail to globalize. We formalize this algebro-geometrically: fixing a factorization type $\\mathbf d=(d_1,\\dots,d_s)$ with $n=\\prod_i d_i$, the existence of a global product-state locus of type $\\mathbf d$ is equivalent to a reduction of the underlying $PGL_n$-torsor $P\\to X$ to the stabilizer $G_{\\mathbf d}\\subset PGL_n$. Thus, entanglement is the obstruction to the existence of a relative Segre subscheme inside $SB(A)$. Writing $Σ_{\\mathbf d}\\subset \\mathbb{P}^{n-1}$ for the Segre variety, we call a reduction to $G_{\\mathbf d}$ a $\\mathbf d$-subsystem structure. Our first main result identifies the moduli of $\\mathbf d$-subsystem structures with the quotient $P/G_{\\mathbf d}$. Moreover, we realize naturally $P/G_{\\mathbf d}$ as a locally closed subscheme of the relative Hilbert scheme, \\[ \\text{Hilb}^{Σ_{\\mathbf d}}\\!\\bigl(SB(A)/X\\bigr)\\ \\subset\\ \\text{Hilb}\\bigl(SB(A)/X\\bigr), \\] parametrizing relative closed subschemes fppf-locally isomorphic to $Σ_{\\mathbf d}\\times X$."
  },
  {
    "date": "2026-01-20",
    "title": "TransMode-LLM: Feature-Informed Natural Language Modeling with Domain-Enhanced Prompting for Travel Behavior Modeling",
    "authors": "Meijing Zhang, Ying Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13763v1",
    "source": "arXiv",
    "abstract": "Understanding traveler behavior and accurately predicting travel mode choice are at the heart of transportation planning and policy-making. This study proposes TransMode-LLM, an innovative framework that integrates statistical methods with LLM-based techniques to predict travel modes from travel survey data. The framework operates through three phases: (1) statistical analysis identifies key behavioral features, (2) natural language encoding transforms structured data into contextual descriptions, and (3) LLM adaptation predicts travel mode through multiple learning paradigms including zero-shot and one/few-shot learning and domain-enhanced prompting. We evaluate TransMode-LLM using both general-purpose models (GPT-4o, GPT-4o-mini) and reasoning-focused models (o3-mini, o4-mini) with varying sample sizes on real-world travel survey data. Extensive experiment results demonstrate that the LLM-based approach achieves competitive accuracy compared to state-of-the-art baseline classifiers models. Moreover, few-shot learning significantly improves prediction accuracy, with models like o3-mini showing consistent improvements of up to 42.9\\% with 5 provided examples. However, domain-enhanced prompting shows divergent effects across LLM architectures. In detail, it is helpful to improve performance for general-purpose models with GPT-4o achieving improvements of 2.27% to 12.50%. However, for reasoning-oriented models (o3-mini, o4-mini), domain knowledge enhancement does not universally improve performance. This study advances the application of LLMs in travel behavior modeling, providing promising and valuable insights for both academic research and transportation policy-making in the future."
  },
  {
    "date": "2026-01-20",
    "title": "Topological Anderson insulator and reentrant topological transitions in a mosaic trimer lattice",
    "authors": "Xiatao Wang, Li Wang, Shu Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13760v1",
    "source": "arXiv",
    "abstract": "We study the topological properties of a one-dimensional quasiperiodic-potential-modulated mosaic trimer lattice. To begin with, we first investigate the topological properties of the model in the clean limit free of quasiperiodic disorder based on analytical derivation and numerical calculations of the Zak phase $Z$ and the polarization $P$. Two nontrivial topological phases corresponding to the $1/3$ filling and $2/3$ filling, respectively, are revealed. Then we incorporate the mosaic modulation and investigate the influence of quasiperiodic disorder on the two existing topological phases. Interestingly, it turns out that quasiperiodic disorder gives rise to multiple distinct effects for different fillings. At $2/3$ filling, the topological phase is significantly enhanced by the quasiperiodic disorder and topological Anderson insulator emerges. Based on the calculations of polarization and energy gap, we explicitly present corresponding topological phase diagram in the $λ-J$ plane. While for the $1/3$ filling case, % the topological phase is dramatically suppressed by the same quasiperiodic disorder. the quasiperiodic disorder dramatically compresses the topological phase, and strikingly, further induces the emergence of reentrant topological phase transitions instead. Furthermore, we verify the topological phase diagrams by computing the many-body ground state fidelity susceptibility for both the $1/3$ filling and $2/3$ filling cases. Our work exemplifies the diverse roles of quasiperiodic disorder in the modulation of topological properties, and will further inspire more research on the competitive and cooperative interplay between topological properties and quasiperiodic disorder."
  },
  {
    "date": "2026-01-20",
    "title": "The R2Pub Telescopes for Surveying: An Overview and Performance Evaluation of the System",
    "authors": "Xuan Song, Xiaofeng Wang, Jin Zhu, Jian Li, Jincheng Guo, Danfeng Xiang, Xin Li, Cheng Liu, Yuanhang Ning, Zhishuai Ge, Zhenzhen Shao, Xiaochen Zheng, Yi Yang, Lei Zhang, Yaqing Shi, Dongyao Zhao, Xiangyun Zeng, Jun Mo, Tengfei Song, Yufeng Fan, Yu Liu, Jingxing Wang, Shousheng He, Ciren Wangdui, Jujia Zhang, Xuefei Zhang, Kai Ye, Jinming Bai, Xiaojun Jiang, Xiaoming Zhang, Peng Qiu, Jicheng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13587v1",
    "source": "arXiv",
    "abstract": "The R2Pub telescope, built by the Beijing Planetarium, is a 60 cm equatorial binocular telescope located at the Daocheng site of Yunnan Observatories in China, at an altitude of about 4700 m. This paper presents an overview of the R2Pub telescope system, including its design, instrumentation, and survey capabilities, and reports an initial evaluation of its system performance. R2Pub is a prime-focus binocular system, with each optical tube covering a field of view of approximately 18 square degrees. It is designed to detect a wide range of transient and variable sources in the local universe, such as variable stars, eclipsing binaries, supernovae, gamma-ray burst afterglows, tidal disruption events, active galactic nuclei, and other unknown transients. The observatory infrastructure, including the dome, equatorial mount, optical tubes, and associated subsystems, has been fully constructed and installed, and the system has entered the commissioning phase. Benefiting from the high-altitude location, good seeing conditions, and dark sky background at the Daocheng site, performance tests during commissioning show that the R2Pub system can reach a 5-sigma limiting magnitude of about 18.7 mag in the Pan-STARRS r' band with a 60 s exposure. Ongoing observations with R2Pub are expected to contribute to studies of variable and transient phenomena and to enhance public outreach in astronomy. The binocular design enables simultaneous dual-band observations, providing instantaneous color information for transient sources and improving the classification and physical characterization of their properties and evolution."
  },
  {
    "date": "2026-01-20",
    "title": "Stochastic Dynamic Pricing of Electric Vehicle Charging with Heterogeneous User Behavior: A Stackelberg Game Framework",
    "authors": "Yongqi Zhang, Dong Ngoduy, Li Duan, Mingchang Zhu, Zhuo Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13571v1",
    "source": "arXiv",
    "abstract": "The rapid adoption of electric vehicles (EVs) introduces complex spatiotemporal demand management challenges for charging station operators (CSOs), exacerbated by demand imbalances, behavioral heterogeneity, and system uncertainty. Traditional dynamic pricing models, often relying on deterministic EV-CS pairings and network equilibrium assumptions, frequently oversimplify user behavior and lack scalability. This study proposes a stochastic, behaviorally heterogeneous dynamic pricing framework formulated as a bi-level Stackelberg game. The upper level optimizes time-varying pricing to maximize system-wide utility, while the lower level models decentralized EV users via a multinomial logit (MNL) choice model incorporating price sensitivity, battery aging, risk attitudes, and network travel costs. Crucially, the model avoids network equilibrium constraints to enhance scalability, with congestion effects represented via queuing-theoretic approximations. To efficiently solve the resulting large-scale optimization problem, a rolling-horizon approach combining the Dynamic Probabilistic Sensitivity Analysis-guided Cross-Entropy Method (PSA-CEM) with the Method of Successive Averages (MSA) is implemented. A real-world case study in Clayton, Melbourne, validates the framework using 22 charging stations. Simulation results demonstrate that the proposed mechanism substantially reduces queuing penalties and improves user utility compared to fixed and time-of-use pricing. The framework provides a robust, scalable tool for strategic EV charging management, balancing realism with computational efficiency."
  },
  {
    "date": "2026-01-20",
    "title": "Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation",
    "authors": "Yu Qin, Shimeng Fan, Fan Yang, Zixuan Xue, Zijie Mai, Wenrui Chen, Kailun Yang, Zhiyong Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13565v1",
    "source": "arXiv",
    "abstract": "Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP."
  },
  {
    "date": "2026-01-20",
    "title": "Observational Relationship between Spectral Properties of Gamma-ray and X-ray Emissions from Pulsars",
    "authors": "Ashwin Aravindaraj, Hsiang-Kuang Chang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13557v1",
    "source": "arXiv",
    "abstract": "Correlations between gamma-ray and X-ray spectral properties of pulsars are investigated in order to provide observational hints on physics involved in pulsars' high-energy emissions. Using a sample of 43 pulsars detected in both X-ray and gamma-ray bands, we find that pulsars' gamma-ray luminosity, $L_γ$, clearly correlates with the luminosity of non-thermal X-ray emission, $L_{\\rm p}$, and anti-correlates with non-thermal X-ray photon index. Other gamma-ray spectral parameters show weaker or negligible correlations. The found relation that $L_γ\\propto L_{\\rm p}^{0.49\\pm 0.05}$ implies a certain connection between radiation mechanisms and energy distributions of radiating particles for these high-energy emissions. Pulsars with and without detected thermal emissions seem to show different dependencies in those correlations, suggesting the possible existence of two different kinds of pulsars. The ones without detected thermal emissions may represent a population of pulsars with low surface temperature. The origin and energetics of high-energy emitting electron-positron pairs for this group of pulsars probably do not depend on their surface thermal emissions, while that of the other group do. The low surface temperatures might be evidence for the working of some exotic processes of neutron-star cooling. Similar to $L_{\\rm p}$, some tempting relationships are found among each gamma-ray spectral parameter, surface temperature and thermally radiating area radius. It again strengthens the connection between gamma-ray and X-ray emissions from pulsars."
  },
  {
    "date": "2026-01-20",
    "title": "Fundamental Limits of Continuous Gaussian Quantum Metrology",
    "authors": "Kazuki Yokomizo, Aashish A. Clerk, Yuto Ashida",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13554v1",
    "source": "arXiv",
    "abstract": "Continuous quantum metrology holds promise for realizing high-precision sensing by harnessing information progressively carried away by the radiation quanta emitted into the environment. Despite recent progress, a comprehensive understanding of the fundamental precision limits of continuous metrology with bosonic systems is currently lacking. We develop a general theoretical framework for quantum metrology with multimode free bosons under continuous Gaussian measurements. We derive analytical expressions for the asymptotic growth rates of the global quantum Fisher information (QFI) and the environmental QFI, which quantify the total information encoded in the joint system-environment state and the information accessible from the emitted radiation, respectively. We derive fundamental bounds on these quantities, showing that while Heisenberg-type scaling with the number of modes is attainable, the precision scales at most linearly with time and a meaningful energy resource. To illustrate our findings, we analyze several concrete setups, including coupled cavity arrays and trapped particle arrays. While a local setup yields a standard linear scaling with resources, a globally coupled setup can achieve the optimal quadratic scaling in terms of the mode number. Furthermore, we demonstrate that a nonreciprocal setup can leverage the non-Hermitian skin effect to realize an exponentially enhanced global QFI. Notably, however, this enhancement cannot be reflected in the environmental QFI, highlighting a fundamental distinction between the information stored within the joint state and the information radiated into the environment. These findings establish an understanding of the resource trade-offs and scaling behaviors in continuous bosonic sensing."
  },
  {
    "date": "2026-01-20",
    "title": "What is Overlap Weighting, How Has it Evolved, and When to Use It for Causal Inference?",
    "authors": "Haidong Lu, Fan Li, Laine E. Thomas, Fan Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13535v1",
    "source": "arXiv",
    "abstract": "The growing availability of large health databases has expanded the use of observational studies for comparative effectiveness research. Unlike randomized trials, observational studies must adjust for systematic differences in patient characteristics between treatment groups. Propensity score methods, including matching, weighting, stratification, and regression adjustment, address this issue by creating groups that are comparable with respect to measured covariates. Among these approaches, overlap weighting (OW) has emerged as a principled and efficient method that emphasizes individuals at empirical equipoise, those who could plausibly receive either treatment. By assigning weights proportional to the probability of receiving the opposite treatment, OW targets the Average Treatment Effect in the Overlap population (ATO), achieves exact mean covariate balance under logistic propensity score models, and minimizes asymptotic variance. Over the last decade, the OW method has been recognized as a valuable confounding adjustment tool across the statistical, epidemiologic, and clinical research communities, and is increasingly applied in clinical and health studies. Given the growing interest in using observational data to emulate randomized trials and the capacity of OW to prioritize populations at clinical equipoise while achieving covariate balance (fundamental attributes of randomized studies), this article provides a concise overview of recent methodological developments in OW and practical guidance on when it represents a suitable choice for causal inference."
  },
  {
    "date": "2026-01-20",
    "title": "More Than Efficiency: Embedding Compression Improves Domain Adaptation in Dense Retrieval",
    "authors": "Chunsheng Zuo, Daniel Khashabi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13525v1",
    "source": "arXiv",
    "abstract": "Dense retrievers powered by pretrained embeddings are widely used for document retrieval but struggle in specialized domains due to the mismatches between the training and target domain distributions. Domain adaptation typically requires costly annotation and retraining of query-document pairs. In this work, we revisit an overlooked alternative: applying PCA to domain embeddings to derive lower-dimensional representations that preserve domain-relevant features while discarding non-discriminative components. Though traditionally used for efficiency, we demonstrate that this simple embedding compression can effectively improve retrieval performance. Evaluated across 9 retrievers and 14 MTEB datasets, PCA applied solely to query embeddings improves NDCG@10 in 75.4% of model-dataset pairs, offering a simple and lightweight method for domain adaptation."
  },
  {
    "date": "2026-01-20",
    "title": "DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities",
    "authors": "Nhi Kieu, Kien Nguyen, Arnold Wiliem, Clinton Fookes, Sridha Sridharan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13502v1",
    "source": "arXiv",
    "abstract": "The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks."
  },
  {
    "date": "2026-01-20",
    "title": "Concurrent Permissive Strategy Templates",
    "authors": "Ashwani Anand, Christel Baier, Calvin Chau, Sascha Klüppelholz, Ali Mirzaei, Satya Prakash Nayak, Anne-Kathrin Schmuck",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13500v1",
    "source": "arXiv",
    "abstract": "Two-player games on finite graphs provide a rigorous foundation for modeling the strategic interaction between reactive systems and their environment. While concurrent game semantics naturally capture the synchronous interactions characteristic of many cyber-physical systems (CPS), their adoption in CPS design remains limited. Building on the concept of permissive strategy templates (PeSTels) for turn-based games, we introduce concurrent (permissive) strategy templates (ConSTels) -- a novel representation for sets of randomized winning strategies in concurrent games with Safety, Büchi, and Co-Büchi objectives. ConSTels compactly encode infinite families of strategies, thereby supporting both offline and online adaptation. Offline, we exploit compositionality to enable incremental synthesis: combining ConSTels for simpler objectives into non-conflicting templates for more complex combined objectives. Online, we demonstrate how ConSTels facilitate runtime adaptation, adjusting action probabilities in response to observed opponent behavior to optimize performance while preserving correctness. We implemented ConSTel synthesis and adaptation in a prototype tool and experimentally show its potential."
  },
  {
    "date": "2026-01-20",
    "title": "Current-driven nonlinear skyrmion dynamics in altermagnets",
    "authors": "Yang Liu, Zhejunyu Jin, Jie Liu, Peng Yan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13499v1",
    "source": "arXiv",
    "abstract": "The center of mass and helicity are two dynamic degrees of freedom of skyrmions. In this work, we study the current-driven skyrmion motion in frustrated altermagnets. Contrary to conventional wisdom, we find that the skyrmion helicity is not locked with the skyrmion Hall angle, but unidirectionally rotates with a global angular velocity proportional to the square of the current density. In addition, we find that the helicity rotation velocity is highly anisotropic, depending on the direction of current flows. We also observe helicity oscillation in the terahertz regimes, where the nonlinear mixing between the fast and slow modes generates a magnon frequency comb. Full atomistic spin dynamics simulations verify our theoretical predictions. Our results establish frustrated altermagnets as a promising platform for skyrmionics, THz technology, and frequency comb."
  },
  {
    "date": "2026-01-20",
    "title": "Double Hall-Littlewood symmetric polynomials",
    "authors": "Jiayi Chen, Ming Lu, Shiquan Ruan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13497v1",
    "source": "arXiv",
    "abstract": "We establish a ring isomorphism between the derived Hall algebra of the Jordan quiver and the ring of double symmetric functions (i.e., the ring of symmetric polynomials in two sets of countably many variables, invariant under the respective actions of their symmetric groups) with a parameter $t$. This isomorphism maps the derived Hall basis (the natural basis of the derived Hall algebra) to a class of double Hall-Littlewood (HL) symmetric functions, which are formulated via raising and lowering operators. These double HL functions are parameterized by bipartitions; they reduce to the classical HL functions when one of the partitions is empty, and specialize to Schur Laurent symmetric functions at $t = 0$. We also derive the Pieri rules for these double HL functions. Additionally, we obtain several natural generating functions for the derived Hall algebra as well as their transition relations, which can be transferred to the ring of double symmetric functions via the established ring isomorphism."
  },
  {
    "date": "2026-01-20",
    "title": "LQ Mean Field Games with Common Noise in Hilbert Spaces: Small and Arbitrary Finite Time Horizons",
    "authors": "Hanchao Liu, Dena Firoozi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13493v1",
    "source": "arXiv",
    "abstract": "We extend the results of (Liu and Firoozi, 2025), which develops the theory of linear-quadratic (LQ) mean field games in Hilbert spaces, by incorporating a common noise. This common noise is an infinite-dimensional Wiener process affecting the dynamics of all agents. In the presence of common noise, the mean-field consistency condition is characterized by a system of coupled forward-backward stochastic evolution equations (FBSEEs) in Hilbert spaces, whereas in its absence, it is represented by forward-backward deterministic evolution equations. We establish the existence and uniqueness of solutions to the coupled linear FBSEEs associated with the LQ MFG setting for small time horizons and prove the $ε$-Nash property of the resulting equilibrium strategy. Furthermore, for the first time in the literature, we develop an analysis that establishes the well-posedness of these coupled linear FBSEEs in Hilbert spaces, for which only mild solutions exist, over arbitrary finite time horizons."
  },
  {
    "date": "2026-01-20",
    "title": "Bridging the Gap Between Estimated and True Regret Towards Reliable Regret Estimation in Deep Learning based Mechanism Design",
    "authors": "Shuyuan You, Zhiqiang Zhuang, Kewen Wang, Zhe Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13489v1",
    "source": "arXiv",
    "abstract": "Recent advances, such as RegretNet, ALGnet, RegretFormer and CITransNet, use deep learning to approximate optimal multi item auctions by relaxing incentive compatibility (IC) and measuring its violation via ex post regret. However, the true accuracy of these regret estimates remains unclear. Computing exact regret is computationally intractable, and current models rely on gradient based optimizers whose outcomes depend heavily on hyperparameter choices. Through extensive experiments, we reveal that existing methods systematically underestimate actual regret (In some models, the true regret is several hundred times larger than the reported regret), leading to overstated claims of IC and revenue. To address this issue, we derive a lower bound on regret and introduce an efficient item wise regret approximation. Building on this, we propose a guided refinement procedure that substantially improves regret estimation accuracy while reducing computational cost. Our method provides a more reliable foundation for evaluating incentive compatibility in deep learning based auction mechanisms and highlights the need to reassess prior performance claims in this area."
  },
  {
    "date": "2026-01-20",
    "title": "The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing",
    "authors": "Olivia Pal, Agam Goyal, Eshwar Chandrasekharan, Koustuv Saha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13487v1",
    "source": "arXiv",
    "abstract": "News consumption on social media has become ubiquitous, yet how different forms of engagement shape psychosocial outcomes remains unclear. To address this gap, we leveraged a large-scale dataset of ~26M posts and ~45M comments on the BlueSky platform, and conducted a quasi-experimental study, matching 81,345 Treated users exposed to News feeds with 83,711 Control users using stratified propensity score analysis. We examined psychosocial wellbeing, in terms of affective, behavioral, and cognitive outcomes. Our findings reveal that news engagement produces systematic trade-offs: increased depression, stress, and anxiety, yet decreased loneliness and increased social interaction on the platform. Regression models reveal that News feed bookmarking is associated with greater psychosocial deterioration compared to commenting or quoting, with magnitude differences exceeding tenfold. These per-engagement effects accumulate with repeated exposure, showing significant psychosocial impacts. Our work extends theories of news effects beyond crisis-centric frameworks by demonstrating that routine consumption creates distinct psychological dynamics depending on engagement type, and bears implications for tools and interventions for mitigating the psychosocial costs of news consumption on social media."
  },
  {
    "date": "2026-01-20",
    "title": "Inverse Reconstruction of Moving Contact Loads on an Elastic Half-Space Using Prescribed Surface Displacement",
    "authors": "Satoshi Takada, Yosuke Mori, Shintaro Hokada",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13478v1",
    "source": "arXiv",
    "abstract": "This study investigates the elastic response of a two-dimensional semi-infinite medium subjected to a moving surface load with a prescribed displacement profile. As a fundamental step, we derive analytical Green's functions for the displacement and stress fields generated by a point load traveling at a constant velocity along the surface, explicitly incorporating elastodynamic effects through Mach number dependence. These moving-load solutions serve as building blocks for constructing more general loading scenarios via linear superposition. Based on Green's functions, an inverse problem is formulated to reconstruct the unknown surface traction responsible for a given surface displacement. The inverse analysis is performed through a Fourier-domain inversion with regularization, which enables a direct and computationally efficient determination of the contact pressure without iterative forward simulations. This framework is applied to a rigid wheel-ground contact problem, where the imposed displacement is dictated by the wheel geometry. The reconstructed surface traction exhibits a smooth, symmetric distribution within the contact region, while the resulting subsurface stress fields are obtained in closed analytical form and involve dilogarithm functions. The principal stress difference reveals characteristic spatial patterns similar to photoelastic fringes, and their asymmetry increases with the Mach number, reflecting the dynamic nature of the moving contact."
  },
  {
    "date": "2026-01-20",
    "title": "Localizable Entanglement as an Order Parameter for Measurement-Induced Phase Transitions",
    "authors": "Sourav Manna, Arul Lakshminarayan, Vaibhav Madhok",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14185v1",
    "source": "arXiv",
    "abstract": "We identify localizable entanglement (LE) as an order parameter for measurement-induced phase transitions (MIPT). LE exhibits universal finite-size scaling with critical exponents that match previous MIPT results and gives a nice operational interpretation connecting MIPTs to classical percolation. Remarkably, we find that LE decays exponentially with distance in the area-law phase as opposed to being essentially constant for the volume-law phase thereby, discover an intrinsic length scale $ξ_E$ that diverges at the critical measurement probability $p_c$. While classical percolation transition captures successful transport across a network, MIPT as characterized by LE can be interpreted as quantifying the amount of quantum teleportation between two given nodes in a quantum circuit. Building on this insight, we propose a two-ancilla protocol that provides an experimentally accessible readout of entanglement redistribution across the transition."
  },
  {
    "date": "2026-01-20",
    "title": "Onset of thermalization of q-deformed SU(2) Yang-Mills theory on a trapped-ion quantum computer",
    "authors": "Tomoya Hayata, Yoshimasa Hidaka, Yuta Kikuchi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13530v1",
    "source": "arXiv",
    "abstract": "Nonequilibrium dynamics of quantum many-body systems is one of the main targets of quantum simulations. This focus - together with rapid advances in quantum-computing hardware - has driven increasing applications in high-energy physics, particularly in lattice gauge theories. However, most existing experimental demonstrations remain restricted to (1+1)-dimensional and/or abelian gauge theories, such as the Schwinger model and the toric code. It is essential to develop quantum simulations of nonabelian gauge theories in higher dimensions, addressing realistic problems in high-energy physics. To fill the gap, we demonstrate a quantum simulation of thermalization dynamics in a (2+1)-dimensional $q$-deformed $\\mathrm{SU}(2)_3$ Yang-Mills theory using a trapped-ion quantum computer. By restricting the irreducible representations of the gauge fields to the integer-spin sector of $\\mathrm{SU}(2)_3$, we obtain a simplified yet nontrivial model described by Fibonacci anyons, which preserves the essential nonabelian fusion structure of the gauge fields. We successfully simulate the real-time dynamics of this model using quantum circuits that explicitly implement $F$-moves. In our demonstrations, the quantum circuits execute up to 47 sequential $F$-moves. We identify idling errors as the dominant error source, which can be effectively mitigated using dynamical decoupling combined with a parallelized implementation of $F$-moves."
  },
  {
    "date": "2026-01-20",
    "title": "Preconditioning Benefits of Spectral Orthogonalization in Muon",
    "authors": "Jianhao Ma, Yu Huang, Yuejie Chi, Yuxin Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13474v1",
    "source": "arXiv",
    "abstract": "The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond."
  },
  {
    "date": "2026-01-20",
    "title": "A construction of smooth varieties admitting small contractions",
    "authors": "Yuto Masamura, Tomoki Yoshida",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13527v1",
    "source": "arXiv",
    "abstract": "We construct smooth varieties admitting small contractions from arbitrary smooth projective varieties. This construction generalizes Kawamata's four-dimensional example. We also give sufficient conditions for divisors on these varieties to be nef. As an application, we obtain weak Fano fourfolds from products of two del Pezzo surfaces."
  },
  {
    "date": "2026-01-20",
    "title": "Gradient-based optimization of exact stochastic kinetic models",
    "authors": "Francesco Mottes, Qian-Ze Zhu, Michael P. Brenner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14183v1",
    "source": "arXiv",
    "abstract": "Stochastic kinetic models describe systems across biology, chemistry, and physics where discrete events and small populations render deterministic approximations inadequate. Parameter inference and inverse design in these systems require optimizing over trajectories generated by the Stochastic Simulation Algorithm, but the discrete reaction events involved are inherently non-differentiable. We present an approach based on straight-through Gumbel-Softmax estimation that maintains exact stochastic simulations in the forward pass while approximating gradients through a continuous relaxation applied only in the backward pass. We demonstrate robust performance on parameter inference in stochastic gene expression, accurately recovering kinetic rates of telegraph promoter models from both moment statistics and full steady-state distributions across diverse and challenging parameter regimes. We further demonstrate the method's applicability to inverse design problems in stochastic thermodynamics, characterizing Pareto-optimal trade-offs between non-equilibrium currents and entropy production. The ability to efficiently differentiate through exact stochastic simulations provides a foundation for systematic inference and rational design across the many domains governed by continuous-time Markov dynamics."
  },
  {
    "date": "2026-01-20",
    "title": "closed $\\mathrm{G}_2$-structures with $\\mathbb{T}^3$-symmetry and hypersymplectic structures",
    "authors": "Chengjian Yao, Ziyi Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13747v1",
    "source": "arXiv",
    "abstract": "Closed $\\mathrm{G}_2$-structures $\\varphi$ with an effective $\\mathbb{T}^3$-symmetry on connected manifolds are roughly classified into three types according to the evaluation of $\\varphi$ on the principal orbits. Type 1: if there is neither associative nor isotropic orbit, then the action is free and $\\varphi$ reduces to a hypersymplectic structure on the quotient manifold admitting three linearly independent closed 1-forms; in particular, it is diffeomorphic to $\\mathbb{T}^4$ if the manifold is compact. Type 2: if some orbit is associative, then the action is almost-free and $\\varphi$ reduces to a good hypersymplectic orbifold with cyclic isotropic groups. Type 3: if some orbit is isotropic, then the action is locally multi-Hamiltonian for $\\varphi$. Moreover, the open and dense subset of principal orbits is foliated by $\\mathbb{T}^3$-invariant hypersymplectic manifolds. If $\\varphi$ is torsion-free and complete, then the hypersymplectic manifold is flat and $\\varphi$ is flat for Type 1; the good hypersymplectic orbifold is good hyperkähler orbifold for Type 2; $\\varphi$ is locally toric for Type 3. As shown, hypersymplectic structures have intimate link with closed $\\mathrm{G}_2$-structure with effective $\\mathbb{T}^3$-symmetry."
  },
  {
    "date": "2026-01-20",
    "title": "Local electrical impedance tomography via projections",
    "authors": "A. Jääskeläinen, A. Vavilov, J. Toivanen, A. Hänninen, V. Kolehmainen, N. Hyvönen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14198v1",
    "source": "arXiv",
    "abstract": "This paper introduces a method for approximately eliminating the effect that conductivity changes outside the region of interest have in electrical impedance tomography, allowing to form a local reconstruction in the region of interest only. The method considers the Jacobian matrix of the forward map, i.e., of the map that sends the discretized conductivity to the electrode measurements, at an initial guess for the conductivity. The Jacobian matrix is divided columnwise into two parts: one corresponding to the region of interest and a nuisance Jacobian corresponding to the rest of the domain. The leading idea is to project both the electrode measurements and the forward map onto the orthogonal complement of the span of a number of left-hand singular vectors for a suitably weighted nuisance Jacobian. The weighting can, e.g., account for the element sizes in a finite element discretization or to prior information on the conductivity outside the region of interest. The inverse problem is then solved by considering the projected relation between the measurements and the forward map, only reconstructing the conductivity in the region of interest. The functionality of the method is demonstrated by applying a reconstruction algorithm that combines lagged diffusivity iteration and total variation regularization to experimental data. In particular, data from a head-shaped water tank is considered, with the conductivity change in the region of interest mimicking growth of a hemorrhagic stroke and the changes outside the region of interest imitating physiological variations in the conductivity of the scalp."
  },
  {
    "date": "2026-01-20",
    "title": "On the $p$-adic deformation problem for the $K$-theory of semistable schemes",
    "authors": "Federico Binda, Tommy Lundemo, Alberto Merici, Doosung Park",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14146v1",
    "source": "arXiv",
    "abstract": "We establish a semistable generalization of the Beilinson-Bloch-Esnault-Kerz fiber square, relating the algebraic K-theory of a semistable scheme to its logarithmic topological cyclic homology. We prove that the obstruction to lifting K-theory classes is governed by the Hyodo-Kato Chern character. This answers the $p$-adic deformation problem for continuous K-theory in the semistable case, extending the work of Antieau-Mathew-Morrow-Nikolaus. As an application, we provide a purely K-theoretic proof of Yamashita's semistable $p$-adic Lefschetz $(1,1)$-theorem."
  },
  {
    "date": "2026-01-20",
    "title": "Partial Reductions for Kleene Algebra with Linear Hypotheses",
    "authors": "Liam Chung, Tobias Kappé",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14114v1",
    "source": "arXiv",
    "abstract": "Kleene algebra (KA) is an important tool for reasoning about general program equivalences, with a decidable and complete equational theory. However, KA cannot always prove equivalences between specific programs. For this purpose, one adds hypotheses to KA that encode program-specific knowledge. Traditionally, a map on regular expressions called a reduction then lets us lift decidability and completeness to these more expressive systems. Explicitly constructing such a reduction requires significant labour. Moreover, due to regularity constraints, a reduction may not exist for all combinations of expression and hypothesis. We describe an automaton-based construction to mechanically derive reductions for a wide class of hypotheses. These reductions can be partial, in which case they yield partial completeness: completeness for expressions in their domain. This allows us to automatically establish the provability of more equivalences than what is covered in existing work."
  },
  {
    "date": "2026-01-20",
    "title": "Nemesis, an Escape Game in Graphs",
    "authors": "Pierre Bergé, Antoine Dailly, Yan Gerard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13841v1",
    "source": "arXiv",
    "abstract": "We define a new escape game in graphs that we call Nemesis. The game is played on a graph having a subset of vertices labeled as exits and the goal of one of the two players, called the fugitive, is to reach one of these exit vertices. The second player, i.e. the fugitive adversary, is called the Nemesis. Her goal is to trap the fugitive in a connected component which does not contain any exit. At each round of the game, the fugitive moves from one vertex to an adjacent vertex. Then the Nemesis deletes one edge anywhere in the graph. The game ends when either the fugitive reached an exit or when he is in a connected component that does not contain any exit. In trees and graphs of maximum degree bounded by 3, Nemesis can be solved in linear time. We also show that a variant of the game called Blizzard where only edges adjacent to the position of the fugitive can be deleted also admits a linear time solution. For arbitrary graphs, we show that Nemesis is PSPACE-complete, and that it is NP-hard on planar multigraphs. We extend our results to the related Cat Herding problem, proving its PSPACE-completeness. We also prove that finding a strategy based on a full binary escape tree whose leaves are exists is NP-complete."
  },
  {
    "date": "2026-01-20",
    "title": "Principled Latent Diffusion for Graphs via Laplacian Autoencoders",
    "authors": "Antoine Siraudin, Christopher Morris",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13780v1",
    "source": "arXiv",
    "abstract": "Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\\times$ speed-up."
  },
  {
    "date": "2026-01-20",
    "title": "Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions",
    "authors": "Fan Huang, Haewoon Kwak, Jisun An",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13590v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs."
  },
  {
    "date": "2026-01-20",
    "title": "Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models",
    "authors": "Ahmad Al-Zuraiqi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13580v1",
    "source": "arXiv",
    "abstract": "We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets (\"donor organs\") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness."
  },
  {
    "date": "2026-01-20",
    "title": "GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds",
    "authors": "Tingting Dan, Jiaqi Ding, Guorong Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13570v1",
    "source": "arXiv",
    "abstract": "State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining the flexibility of deep learning with the principled dynamical structure of SSMs, recent studies have achieved powerful fits to functional neuroimaging data. However, most existing approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic and self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive definite (SPD) matrix, which resides on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth and geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer's disease, Parkinson's disease, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains."
  },
  {
    "date": "2026-01-20",
    "title": "LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI",
    "authors": "Jianan Wang, Siyang Zhang, Bin Li, Juan Chen, Jingtao Qi, Zhuo Zhang, Chen Qian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13556v1",
    "source": "arXiv",
    "abstract": "Simulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering. However, existing environment generation methods often emphasize visual realism (e.g., object diversity and layout coherence), overlooking a crucial aspect: logical diversity from the testing perspective. This limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments. To bridge this gap, we propose LogicEnvGen, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents. Given an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories. Subsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation. For each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment. Notably, it employs constraint solving for physical plausibility. Furthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation. Experimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%-68.00%."
  },
  {
    "date": "2026-01-20",
    "title": "Relic of quadrupole deformation produced in a hot neutron star era",
    "authors": "Yasufumi Kojima, Akira Dohi, Shota Kisaka, Kotaro Fujisawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13550v1",
    "source": "arXiv",
    "abstract": "A newly born neutron star is expected to exhibit significant deviations from spherical symmetry, which decay with time. Determining how much deformation remains at present is crucial for gravitational-wave astronomy. This study is the first investigation into the evolution of quadrupole deformation during the solid crust formation phase to obtain a plausible value at present. The equilibrium structure before solidification is modeled using a fluid description, and the deformation is introduced through an assumed driving force. As the star cools, this force weakens, leading to a gradual decay of the deformation. Eventually, the deformation vanishes in the fluid region but partially remains in the crust, sustained by elastic forces, after solidification. By comparing the equilibrium models before and after solidification, we estimate the residual ellipticity and demonstrate that the spatial profile of the elastic shear is imprinted in the crust. The relic ellipticity is only a few percent of the original value, with its absolute magnitude depending on the deformation mechanism during the hot era, which cannot be specified owing to the lack of elaborate models. This work provides a first step toward linking early neutron star deformation with future gravitational-wave observations."
  },
  {
    "date": "2026-01-20",
    "title": "Near-field Physical Layer Security: Robust Beamforming under Location Uncertainty",
    "authors": "Chao Zhou, Changsheng You, Cong Zhou, Chengwen Xing, Jianhua Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13549v1",
    "source": "arXiv",
    "abstract": "In this paper, we study robust beamforming design for near-field physical-layer-security (PLS) systems, where a base station (BS) equipped with an extremely large-scale array (XL-array) serves multiple near-field legitimate users (Bobs) in the presence of multiple near-field eavesdroppers (Eves). Unlike existing works that mostly assume perfect channel state information (CSI) or location information of Eves, we consider a more practical and challenging scenario, where the locations of Bobs are perfectly known, while only imperfect location information of Eves is available at the BS. We first formulate a robust optimization problem to maximize the sum-rate of Bobs while guaranteeing a worst-case limit on the eavesdropping rate under location uncertainty. By transforming Cartesian position errors into the polar domain, we reveal an important near-field angular-error amplification effect: for the same location error, the closer the Eve, the larger the angle error, severely degrading the performance of conventional robust beamforming methods based on imperfect channel state information. To address this issue, we first establish the conditions for which the first-order Taylor approximation of the near-field channel steering vector under location uncertainty is largely accurate. Then, we propose a two-stage robust beamforming method, which first partitions the uncertainty region into multiple fan-shaped sub-regions, followed by the second stage to formulate and solve a refined linear-matrix-inequality (LMI)-based robust beamforming optimization problem. In addition, the proposed method is further extended to scenarios with multiple Bobs and multiple Eves. Finally, numerical results validate that the proposed method achieves a superior trade-off between rate performance and secrecy robustness, hence significantly outperforming existing benchmarks under Eve location uncertainty."
  },
  {
    "date": "2026-01-20",
    "title": "Patterning: The Dual of Interpretability",
    "authors": "George Wang, Daniel Murfet",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13548v1",
    "source": "arXiv",
    "abstract": "Mechanistic interpretability aims to understand how neural networks generalize beyond their training data by reverse-engineering their internal structures. We introduce patterning as the dual problem: given a desired form of generalization, determine what training data produces it. Our approach is based on susceptibilities, which measure how posterior expectation values of observables respond to infinitesimal shifts in the data distribution. Inverting this linear response relationship yields the data intervention that steers the model toward a target internal configuration. We demonstrate patterning in a small language model, showing that re-weighting training data along principal susceptibility directions can accelerate or delay the formation of structure, such as the induction circuit. In a synthetic parentheses balancing task where multiple algorithms achieve perfect training accuracy, we show that patterning can select which algorithm the model learns by targeting the local learning coefficient of each solution. These results establish that the same mathematical framework used to read internal structure can be inverted to write it."
  },
  {
    "date": "2026-01-20",
    "title": "ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution",
    "authors": "Hui Sun, Chang Xu, Haonan Xie, Hao Li, Yuhao Huang, Chuheng Zhang, Ming Jin, Xiaoguang Liu, Gang Wang, Jiang Bian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13546v1",
    "source": "arXiv",
    "abstract": "LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation."
  },
  {
    "date": "2026-01-20",
    "title": "TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning",
    "authors": "Shirin Shahabi, Spencer Graham, Haruna Isah",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13545v1",
    "source": "arXiv",
    "abstract": "Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com"
  },
  {
    "date": "2026-01-20",
    "title": "The Collapse of Multilayer Predation and the Emergence of a Monolithic Leviathan",
    "authors": "Li Tuobang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13544v1",
    "source": "arXiv",
    "abstract": "This paper constructs a multilayer recursive game model to demonstrate that in a rule vacuum environment, hierarchical predatory structures inevitably collapse into a monolithic political strongman system due to the conflict between exponentially growing rent dissipation and the rigidity of bottom-level survival constraints. We propose that the rise of a monolithic political strongman is essentially an \"algorithmic entropy reduction\" achieved through forceful means by the system to counteract the \"informational entropy increase\" generated by multilayer agency. However, the order gained at the expense of social complexity results in the stagnation of social evolutionary functions."
  },
  {
    "date": "2026-01-20",
    "title": "Refined Gradient-Based Temperature Optimization for the Replica-Exchange Monte-Carlo Method",
    "authors": "Tatsuya Miyata, Shunta Arai, Satoshi Takabe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13542v1",
    "source": "arXiv",
    "abstract": "The replica-exchange Monte-Carlo (RXMC) method is a powerful Markov-chain Monte-Carlo algorithm for sampling from multi-modal distributions, which are challenging for conventional methods. The sampling efficiency of the RXMC method depends highly on the selection of the temperatures, and finding optimal temperatures remains a challenge. In this study, we propose a refined online temperature selection method by extending the gradient-based optimization framework proposed previously. Building upon the existing temperature update approach, we introduce a reparameterization technique to strictly enforce physical constraints, such as the monotonic ordering of inverse temperatures, which were not explicitly addressed in the original formulation. The proposed method defines the variance of acceptance rates between adjacent replicas as a loss function, estimates its gradient using differential information from the sampling process, and optimizes the temperatures via gradient descent. We demonstrate the effectiveness of our method through experiments on benchmark spin systems, including the two-dimensional ferromagnetic Ising model, the two-dimensional ferromagnetic XY model, and the three-dimensional Edwards-Anderson model. Our results show that the method successfully achieves uniform acceptance rates and reduces round-trip times across the temperature space. Furthermore, our proposed method offers a significant advantage over recently proposed policy gradient method that require careful hyperparameter tuning, while simultaneously preventing the constraint violations that destabilize optimization."
  },
  {
    "date": "2026-01-20",
    "title": "Confined non-Hermitian skin effect in a semi-infinite Fock-state lattice",
    "authors": "Zhi Jiao Deng, Xing Yao Mi, Ruo Kun Cai, Chun Wang Wu, Ping Xing Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13540v1",
    "source": "arXiv",
    "abstract": "In this paper, we investigate the non-Hermitian skin effect in a semi-infinite Fock-state lattice, where the inherent coupling scales as \\sqrt{n}. By analytically solving a non-uniform, non-reciprocal SSH model, we demonstrate that the intrinsic inhomogeneous coupling, in combination with nonreciprocity, fundamentally modifies the conventional skin effect. Instead of accumulating at the physical boundary, all eigenmodes become compressed and skewed within a finite spatial range determined by the inhomogeneous profile-a phenomenon we term the confined non-Hermitian skin effect. Consequently, the evolution of the probability distribution on the lattice starting from a single site is doubly confined: it is spatially bounded to a finite range by the inhomogeneous coupling, and further restricted to a one-sided trajectory at the edge of this range by the non-reciprocity. Moreover, a feasible experimental scheme based on a single trapped ion is also proposed. This work reveals how engineered coupling profiles in synthetic dimensions can reshape non-Hermitian properties and enable new protocols for quantum state manipulation."
  },
  {
    "date": "2026-01-20",
    "title": "MIU2Net: weak-lensing mass inversion using deep learning with nested U-structures",
    "authors": "Han W. G., An Zhao, Xinyue Chen, Ran Li, Rui Li, Xiangkun Liu, Zhao Chen, Yu Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13538v1",
    "source": "arXiv",
    "abstract": "One of the primary goals of next-generation gravitational lensing surveys is to measure the large-scale distribution of dark matter, which requires accurate mass inversion to convert weak-lensing shear maps into convergence (kappa) fields. This work develops a mass inversion method tailored for upcoming space missions such as CSST and Euclid, aiming to recover both the mass distribution and the convergence power spectrum with high fidelity. We introduce MIU2Net, a versatile deep-learning framework for kappa-map reconstruction based on the U2-Net architecture. A new loss function is constructed to jointly estimate the convergence field and its frequency-domain energy distribution, effectively balancing optimal mean squared error and optimal power-spectrum recovery. The method incorporates realistic observational effects into shear fields, including shape noise, reduced shear, and complex masks. Under noise levels anticipated for future space-based lensing surveys, MIU2Net recovers the convergence power spectrum with 4% uncertainties up to l approximately 500, significantly outperforming Wiener filtering and MCALens. Beyond two-point statistics, the method accurately reconstructs the convergence distribution, peak centroid, and peak amplitude. Compared to other learning-based approaches such as DeepMass, MIU2Net reduces the root-mean-square error by 5% without smoothing and by 38% with a 1-arcmin smoothing scale. MIU2Net represents a substantial advancement in mass inversion methodology, offering improved accuracy in both RMSE and power-spectrum reconstruction. It provides a promising tool for mapping dark matter environments and large-scale structures in the era of next-generation space lensing surveys."
  },
  {
    "date": "2026-01-20",
    "title": "MN-TSG:Continuous Time Series Generation with Irregular Observations",
    "authors": "Xu Zhang, Junwei Deng, Chang Xu, Hao Li, Jiang Bian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13534v1",
    "source": "arXiv",
    "abstract": "Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series. Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks. The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG. Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks."
  },
  {
    "date": "2026-01-20",
    "title": "The OncoReach Stylet for Brachytherapy: Design Evaluation and Pilot Study",
    "authors": "Pejman Kheradmand, Kent K. Yamamoto, Emma Webster, Keith Sowards, Gianna Hatheway, Katharine L. Jackson, Sabino Zani, Julie A. Raffi, Diandra N. Ayala-Peacock, Scott R. Silva, Joanna Deaton Bertram, Yash Chitalia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13529v1",
    "source": "arXiv",
    "abstract": "Cervical cancer accounts for a significant portion of the global cancer burden among women. Interstitial brachytherapy (ISBT) is a standard procedure for treating cervical cancer; it involves placing a radioactive source through a straight hollow needle within or in close proximity to the tumor and surrounding tissue. However, the use of straight needles limits surgical planning to a linear needle path. We present the OncoReach stylet, a handheld, tendon-driven steerable stylet designed for compatibility with standard ISBT 15- and 13-gauge needles. Building upon our prior work, we evaluated design parameters like needle gauge, spherical joint count and spherical joint placement, including an asymmetric disk design to identify a configuration that maximizes bending compliance while retaining axial stiffness. Free space experiments quantified tip deflection across configurations, and a two-tube Cosserat rod model accurately predicted the centerline shape of the needle for most trials. The best performing configuration was integrated into a reusable handheld prototype that enables manual actuation. A patient-derived, multi-composite phantom model of the uterus and pelvis was developed to conduct a pilot study of the OncoReach steerable stylet with one expert user. Results showed the ability to steer from less-invasive, medial entry points to reach the lateral-most targets, underscoring the significance of steerable stylets."
  },
  {
    "date": "2026-01-20",
    "title": "GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models",
    "authors": "Yang Yu, Yunze Deng, Yige Zhang, Yanjie Xiao, Youkun Ou, Wenhao Hu, Mingchao Li, Bin Feng, Wenyu Liu, Dandan Zheng, Jingdong Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13524v1",
    "source": "arXiv",
    "abstract": "Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/."
  },
  {
    "date": "2026-01-20",
    "title": "Polar perturbations of dilaton-Euler-Heisenberg black holes",
    "authors": "Sheng-Yuan Li, Yun Soo Myung, Ming Zhang, Xufen Zhang, De-Cheng Zou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13521v1",
    "source": "arXiv",
    "abstract": "We investigate the quasinormal modes of polar metric-dilaton perturbations around the dilaton-Euler-Heisenberg (dEH) black holes with dilaton hair obtained from the Einstein-Maxwell-dilaton theory with two dilaton coupling constants ($α,β$) to the nonlinear Euler-Heisenberg term. We compute the quasinormal mode spectra by making use of two numerical techniques: direct integration and matrix values continued fraction methods. An excellent agreement is found between two approaches, confirming the robustness of our computation. We present the fundamental quasinormal frequencies for both gravitational and dilaton modes and analyze their dependence on the magnetic charge ($Q_m$), angular momentum quantum number $(l)$, and coupling parameter ($ε=α-β$). All negative imaginary quasinormal frequencies imply that the dEH black hole with dilaton hair is stable against polar metric-dilaton perturbations. Also, our results reveal distinct qualitative behaviors between $ε=1$ and $ε=-1 $, particularly in the damping rates near the extremality."
  },
  {
    "date": "2026-01-20",
    "title": "Hidden convexity of quadratic systems and its application to quadratic programming",
    "authors": "Nguyen Quang Huy, Nguyen Huy Hung, Tran Van Nghi, Hoang Ngoc Tuan, Nguyen Van Tuyen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13511v1",
    "source": "arXiv",
    "abstract": "In this paper, we present sufficient conditions ensuring that the sum of the image of quadratic functions and the nonnegative orthant is convex. The hidden convexity of the trust-region problem with linear inequality constraints is established under a newly proposed assumption, which is compared with the previous one in [{\\it Math. Program. 147, 171--206, 2014}]. We also provide a complete proof of the hidden convexity of a system of two quadratic functions in [{\\it J. Glob. Optim. 56, 1045--1072, 2013}]. Furthermore, necessary and sufficient conditions for the S-lemma concerning systems of quadratic inequalities are investigated. Finally, we derive necessary and sufficient global optimality conditions and strong duality results for quadratic programming."
  },
  {
    "date": "2026-01-20",
    "title": "c-C3H2 deuteration towards prestellar and starless cores in the Perseus Molecular Cloud",
    "authors": "J. Ferrer Asensio, S. Scibelli, L. Steffes, B. Kulterer, A. Pokorny-Yadav, Y. Shirley, A. Megías, I. Jiménez-Serra, A. Taillard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13495v1",
    "source": "arXiv",
    "abstract": "Deuterium fractionation becomes highly efficient in cold, dense cores where CO is frozen out. Cyclopropenylidene (c-C3H2), an early-formed carbon ring, and its deuterated isotopologues trace gas-phase deuteration in these environments. We present a statistical study of c-C3H2 deuteration in starless and prestellar cores of the Perseus Molecular Cloud using observations of c-C3H2, c-C3HD and c-C3D2 obtained with the Yebes 40 m, ARO 12 m and IRAM 30 m telescopes towards 16 cores. Gaussian fits and RADEX modeling yield column densities for the detected species. c-C3H2 is detected in 14/15 covered cores, c-C3HD in 15/16, and c-C3D2 in 9/16. Derived column densities range from 0.5-8.1 x 10^{13} cm^{-2} for c-C3H2, 0.2-2.1 x 10^{12} cm^{-2} for c-C3HD, and 0.6-1.6 x 10^{11} cm^{-2} for c-C3D2. The ortho-to-para ratio of c-C3H2 is obtained for all but one core, with a median value of 3.5\\pm0.4. Statistically corrected D/H ratios span 0.5-9.2% (median 1.5\\pm0.2%), and D2/D ratios 9-55% (median 25.9\\pm4.3%). No trend is found between the c-C3H2 ortho-to-para ratio and core evolutionary stage traced by n(H2). The median D/H ratio in Perseus appears lower than values reported for Taurus and Chamaeleon, while the D2/D ratio agrees with Taurus within uncertainties. A positive correlation between D/H and n(H2) supports the use of D/H as an evolutionary tracer. D2/D does not correlate with n(H2), but shows a positive correlation with T_{kin}, suggesting that its formation is influenced by a mildly endothermic pathway."
  },
  {
    "date": "2026-01-20",
    "title": "Finite-resolution measurement induces topological curvature defects in spacetime",
    "authors": "Ewa Czuchry, Jean-Pierre Gazeau",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13491v1",
    "source": "arXiv",
    "abstract": "We show that regularizing $(2+1)$-dimensional Minkowski spacetime with a finite-resolution Gaussian probe, analogous to Weyl-Heisenberg (Gabor) signal analysis and related quantization, induces a curved geometry with a topological defect. The regularized metric replaces $r^2$ by $r^2+σ^2$ in the angular part, where $σ$ is the resolution scale from the width of the Gaussian probe. The resulting Gaussian curvature integrates to $-2π$, independently of $σ$, and including the boundary contribution, yields Euler characteristic $χ=0$, corresponding to a punctured plane. This curvature defines an effective stress-energy source with total energy $E_{\\text{eff}}=-1/(4G)$, universal and $σ$-independent. Spatial slices embed isometrically as helicoids, and geodesics exhibit a characteristic swirling motion. These results show that finite spatial resolution measurement does not merely smooth singularities but imprints topological defects with fixed physical consequences, suggesting that observational limitations fundamentally shape spacetime geometry. We show how our Gabor regularisation is extendable to $(3+1)$ Minkowski space-time."
  },
  {
    "date": "2026-01-20",
    "title": "Gorenstein Special Fiber Rings of Ladder Determinantal Modules",
    "authors": "Louiza Fouli, Kuei-Nuan Lin, Haydee Lindo, Maral Mostafazadehfard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13483v1",
    "source": "arXiv",
    "abstract": "A ladder determinantal module is an arbitrary direct sum of ideals of maximal minors of a generic ladder matrix. In this article, we give necessary and sufficient conditions for the special fiber ring of such modules to be Gorenstein. These conditions are expressed in terms of data obtained from the underlying matrix."
  },
  {
    "date": "2026-01-20",
    "title": "Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement",
    "authors": "Jian Zhang, Zhangqi Wang, Zhiyuan Wang, Weiping Fu, Yu He, Haiping Zhu, Qika Lin, Jun Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13481v1",
    "source": "arXiv",
    "abstract": "Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare."
  },
  {
    "date": "2026-01-20",
    "title": "Elias-type Bounds for Codes in the Symmetric Limited-Magnitude Error Channel",
    "authors": "Zhihao Guan, Hengjia Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13477v1",
    "source": "arXiv",
    "abstract": "We study perfect error-correcting codes in $\\mathbb{Z}^n$ for the symmetric limited-magnitude error channel, where at most $e$ coordinates of an integer vector may be altered by a value whose magnitude is at most $s$. Geometrically, such codes correspond to tilings of $\\mathbb{Z}^n$ by the symmetric limited-magnitude error ball $\\mathcal{B}(n,e,s,s)$. Given $n$ and $s$, we adapt the geometric ideas underlying the Elias bound for the Hamming metric to the distance $d_s$ tailed for this channel, and derive new necessary conditions on $e$ for the existence of perfect codes / tilings, without assuming any lattice structure. Our main results identify two distinct regimes depending on the error magnitude. For small error magnitudes ($s \\in \\{1, 2\\}$), we prove that if the number of correctable errors does not exceed a certain fraction of $n$, then it is asymptotically bounded by $e = \\mathcal{O}(\\sqrt{n \\log n})$. In contrast, for larger magnitudes ($s \\geq 3$), we establish a significantly sharper bound of $e < \\sqrt{12.36n}$, which holds without any restriction on $e$ being below a given fraction of $n$. Finally, by extending our method to non-perfect codes, we derive an upper bound on packing density, showing that for codes correcting a linear or $Ω(\\sqrt{n})$ number of errors, the density is bounded by a factor inversely proportional to the error magnitude $s$."
  },
  {
    "date": "2026-01-20",
    "title": "A turnpike property in an eigenvalue optimization problem",
    "authors": "Adam Kaminer, Thomas Kriecherbauer, Lars Grüne, Michael Margaliot",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13756v1",
    "source": "arXiv",
    "abstract": "We consider a constrained eigenvalue optimization problem that arises in an important nonlinear dynamical model for mRNA translation in the cell. We prove that the ordered list of optimal parameters admits a turnpike property, namely, it includes three parts with the first and third part relatively short, and the values in the middle part are all approximately equal. Turnpike properties have attracted considerable attention in econometrics and optimal control theory, but to the best of our knowledge this is the first rigorous proof of such a structure in an eigenvalue optimization problem."
  },
  {
    "date": "2026-01-20",
    "title": "HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection",
    "authors": "Daniel Kyselica, Jonáš Herec, Oliver Kutis, Rado Pitoňák",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13751v1",
    "source": "arXiv",
    "abstract": "Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection"
  },
  {
    "date": "2026-01-20",
    "title": "Hamiltonian hydrodynamic reductions of one-dimensional Vlasov equations",
    "authors": "Rayan Oufar, Cristel Chandre",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13746v1",
    "source": "arXiv",
    "abstract": "We investigate Hamiltonian fluid reductions of the one-dimensional Vlasov-Poisson equation. Our approach utilizes the hydrodynamic Poisson bracket framework, which allows us to systematically identify fundamental normal variables derived from the analysis of the Casimir invariants of the resulting Poisson bracket. This framework is then applied to analyze several well-established Hamiltonian closures of the onedimensional Vlasov equation, including the multi-delta distribution and the waterbag models. Our key finding is that all of these seemingly distinct closures consistently lead to the formulation of a unified form of parametric closures: When expressed in terms of the identified normal variables, the parameterization across all these closures is revealed to be polynomial and of the same degree. All these parametric closures are uniquely generated from one of the moments, called $μ$2, a cubic polynomial in the normal variables. This result establishes a structural connection between these different physical models, offering a path toward a more unified and simplified description of the one-dimensional Vlasov-Poisson dynamics through its reduced hydrodynamic forms with an arbitrary number of fluid variables."
  },
  {
    "date": "2026-01-20",
    "title": "Abstract maximal hypoellipticity and applications",
    "authors": "Omar Mohsen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13741v1",
    "source": "arXiv",
    "abstract": "We prove an abstract theorem of maximal hypoellipticy showing that in an abstract calculus under some natural assumptions, an operator is maximally hypoelliptic if and only if its principal symbol is left invertible. We then show that our theorem implies various known results in the literature like regularity theorem for elliptic operators, Helffer and Nourrigat's resolution of the Rockland conjecture, Rodino's theorem on regularity of operators on products of manifolds, and our resolution of the Helffer-Nourrigat conjecture. Other examples like our resolution of the microlocal Helffer-Nourrigat conjecture will be given in a sequel to this paper. Our arguments are based on the theory of $C^*$-algebras of Type I."
  },
  {
    "date": "2026-01-20",
    "title": "The Hamilton-Jacobi Equation and its Application to Nonlinear Beam Dynamics: Comparison of Approaches",
    "authors": "Stephan I. Tzenov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13739v1",
    "source": "arXiv",
    "abstract": "The rarely used Hamilton-Jacobi equation has been utilized as an elegant way to find the trajectories of mechanical systems and to derive symplectic maps. Further, the exact solution in kick approximation of Hamilton's equations of motion in interaction representation is written as a generalized one-turn twist map. One can imagine that the nonlinear kick comes first, followed by the one-period rotation along the machine circumference, or a second alternative in which the one-period rotation occurs before the kick. There is a difference in the result of solving Hamilton's equations between the two cases, which is expressed in obtaining a standard forward twist map in the first case, or alternatively a backward map in the second one. This nontrivial and intuitively unclear peculiarity is usually ignored/overlooked in practically all specialized references on the topic. Finally, the statistical properties and the behavior of the density distribution of a particle beam in configuration space under the influence of an isolated sextupole have been studied."
  },
  {
    "date": "2026-01-20",
    "title": "Structure of Bound States with Coulomb plus Short-range Interaction",
    "authors": "Chisato Uno, Tetsuo Hyodo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13733v1",
    "source": "arXiv",
    "abstract": "We study the structure of bound states appearing in systems governed by the Coulomb and short-range interactions. We analyze the binding energies and wave functions of the bound states generated by the Coulomb plus short-range potential. We demonstrate that Coulomb-induced shifts of the binding energy are closely correlated with the spatial distribution of the wave function. Furthermore, we show that the asymptotic behavior of wave functions of weakly bound states is qualitatively altered by Coulomb repulsion, leading to a modification of the near-threshold mass scaling that is otherwise universal for short-range interactions."
  },
  {
    "date": "2026-01-20",
    "title": "Outbreak dynamics and population vulnerability in stochastic epidemic models on networks",
    "authors": "Makoto Ueki, Robin N. Thompson, Murad Banaji",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13730v1",
    "source": "arXiv",
    "abstract": "During infectious disease epidemics, pathogen transmission occurs in host populations made up of interacting subpopulations. Using stochastic simulation and analytical approximations, we examine how outbreak sizes in networked populations depend on network architecture, subpopulation sizes and the strength of coupling between subpopulations. We find, as expected, that mean outbreak sizes are frequently lower in networked populations than in homogeneous populations with the same basic reproduction number. However, after an outbreak ends, a networked population is often vulnerable to further outbreaks, and the ending of an outbreak may not imply herd immunity in any sense. Another key finding is that a relatively small amount of randomly distributed prior immunity can be more protective in a networked population than a homogeneous population, a phenomenon which can be reproduced analytically in certain cases. We also find that in networked populations, randomly distributed prior immunity is often more protective than infection-acquired immunity; but this conclusion can be reversed in populations with highly variable susceptibility. All of these conclusions have implications for designing outbreak control strategies that aim to reduce pathogen transmission during epidemics."
  },
  {
    "date": "2026-01-20",
    "title": "On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation",
    "authors": "Weichuan Wang, Mingyang Liu, Linqi Song, Chen Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13729v1",
    "source": "arXiv",
    "abstract": "In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT."
  },
  {
    "date": "2026-01-20",
    "title": "A jet-gas interaction beyond the host galaxy: detection of a neutral hydrogen outflow at cosmic noon",
    "authors": "Renzhi Su, Stephen J. Curran, James R. Allison, Marcin Słowacki, Minfeng Gu, Vanessa Moss, Yongjun Chen, Zhongzu Wu, Zheng Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13728v1",
    "source": "arXiv",
    "abstract": "We present upgraded Giant Metrewave Radio Telescope (uGMRT) observations of 0731+438, an \\mbox{FR II} radio galaxy at a redshift of 2.429 with two lobes separated by 82 kpc. A blueshifted, faint and broad \\mbox{H{\\sc i}} 21 cm absorption line with velocity full width at half maximum (FWHM) $\\sim 600\\,\\rm km\\,s^{-1}$ is detected against the southern radio lobe that is 47 kpc from radio core, indicating a neutral hydrogen outflow associated with jet-gas interaction beyond the host galaxy. The outflow has a mass outflow rate of $\\sim\\,0.4T_{\\rm s}Ω\\rm\\, M_\\odot\\,{\\rm yr}^{-1}$, which could increase to $\\sim\\,4.0T_{\\rm s}Ω\\rm\\,M_\\odot\\,{\\rm yr}^{-1}$, corresponding to an energy outflow rate of $2.4T_{\\rm s}Ω\\times10^{40}$ -- $1.5T_{\\rm s}Ω\\times10^{41}\\,\\rm erg\\,s^{-1}$, where $T_{\\rm s}$ is the spin temperature and $Ω$ is the solid angle of the outflow. Previous optical observations identified an extended emission line region aligned with the radio axis, ionized by the central Active Galactic Nucleus (AGN). Within this region, a warm and ionized outflow with a mass outflow rate of $\\sim\\,50\\rm\\, M_\\odot\\,{\\rm yr}^{-1}$ and an energy outflow rate of $\\sim1.7\\times10^{43}\\,\\rm erg\\,s^{-1}$ was detected. We propose that both the extended emission line region and the optical outflow are results of synergistic effect between jet and AGN radiation. The AGN likely exerts negative feedback on the host galaxy, as evidenced by the gas expulsion by the jet and the high velocity dispersion of ionized gas observed optically. So far, detections of jet-driven neutral hydrogen outflows remain rare. The high redshift, large outflow radii, substantial mass outflow rate and energy outflow rate of the neutral hydrogen outflow in 0731+438 expand the known parameter space of such outflows."
  },
  {
    "date": "2026-01-20",
    "title": "Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement",
    "authors": "Sam Cantrill, David Ahmedt-Aristizabal, Lars Petersson, Hanna Suominen, Mohammad Ali Armin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13724v1",
    "source": "arXiv",
    "abstract": "Facial remote photoplethysmography (rPPG) methods estimate physiological signals by modeling subtle color changes on the 3D facial surface over time. However, existing methods fail to explicitly align their receptive fields with the 3D facial surface-the spatial support of the rPPG signal. To address this, we propose the Facial Spatiotemporal Graph (STGraph), a novel representation that encodes facial color and structure using 3D facial mesh sequences-enabling surface-aligned spatiotemporal processing. We introduce MeshPhys, a lightweight spatiotemporal graph convolutional network that operates on the STGraph to estimate physiological signals. Across four benchmark datasets, MeshPhys achieves state-of-the-art or competitive performance in both intra- and cross-dataset settings. Ablation studies show that constraining the model's receptive field to the facial surface acts as a strong structural prior, and that surface-aligned, 3D-aware node features are critical for robustly encoding facial surface color. Together, the STGraph and MeshPhys constitute a novel, principled modeling paradigm for facial rPPG, enabling robust, interpretable, and generalizable estimation. Code is available at https://samcantrill.github.io/facial-stgraph-rppg/ ."
  },
  {
    "date": "2026-01-20",
    "title": "MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network",
    "authors": "Yiwei Lu, Hao Huang, Tao Yan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13715v1",
    "source": "arXiv",
    "abstract": "Glass surface ubiquitous in both daily life and professional environments presents a potential threat to vision-based systems, such as robot and drone navigation. To solve this challenge, most recent studies have shown significant interest in Video Glass Surface Detection (VGSD). We observe that objects in the reflection (or transmission) layer appear farther from the glass surfaces. Consequently, in video motion scenarios, the notable reflected (or transmitted) objects on the glass surface move slower than objects in non-glass regions within the same spatial plane, and this motion inconsistency can effectively reveal the presence of glass surfaces. Based on this observation, we propose a novel network, named MVGD-Net, for detecting glass surfaces in videos by leveraging motion inconsistency cues. Our MVGD-Net features three novel modules: the Cross-scale Multimodal Fusion Module (CMFM) that integrates extracted spatial features and estimated optical flow maps, the History Guided Attention Module (HGAM) and Temporal Cross Attention Module (TCAM), both of which further enhances temporal features. A Temporal-Spatial Decoder (TSD) is also introduced to fuse the spatial and temporal features for generating the glass region mask. Furthermore, for learning our network, we also propose a large-scale dataset, which comprises 312 diverse glass scenarios with a total of 19,268 frames. Extensive experiments demonstrate that our MVGD-Net outperforms relevant state-of-the-art methods."
  },
  {
    "date": "2026-01-20",
    "title": "Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction",
    "authors": "Sayeed Shafayet Chowdhury, Snehasis Mukhopadhyay, Shiaofen Fang, Vijay R. Ramakrishnan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13710v1",
    "source": "arXiv",
    "abstract": "Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making."
  },
  {
    "date": "2026-01-20",
    "title": "XPE and VLT /FORS2 polarimetry challenge the Seyfert-1.9 classification of MCG-05-23-16",
    "authors": "Frédéric Marin, Daniele Tagliacozzo, Francesco Ursini, Damien Hutsemékers, Mitsuru Kokubo, Thibault Barnouin, Andrea Gnarini, Alessandro Leonardo Lai, Jirí Svoboda, Stefano Bianchi, Vittoria Elvezia Gianolli, Ephraim Gau, Kun Hu, Henric Krawczynski, W. Peter Maksym, Andrea Marinucci, Herman Marshall, Giorgio Matt, Riccardo Middei, Pierre-Olivier Petrucci, Simonetta Puccetti, Nicole Rodriguez, Roberto Serafinelli, Francesco Tombesi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13701v1",
    "source": "arXiv",
    "abstract": "We report the third observation of the Seyfert-1.9 active galactic nucleus (AGN) MCG-05-23-16 with the Imaging X-ray Polarimetry Explorer (\\textit{IXPE}), together with optical spectro-polarimetry obtained at the Very Large Telescope (VLT), and combined with archival near-ultraviolet, optical and near-infrared polarimetric data. No X-ray polarization was detected in the 2-8 keV band, with a 99\\% confidence upper limit of $\\leq$2.9\\%, further reduced to $\\leq$2.5\\% when combined with the two past IXPE observations of the same target. Monte Carlo simulations suggest that equatorial coronal models are disfavored if the AGN is indeed a type-1.9/2 AGN, but coronae coplanar to the accretion disk remain consistent if the source is less inclined than previously assumed. \\textit{VLT}/FORS2 data reveal a typical type-2 spectrum in total flux, a broad H$α$ line in polarized flux, and strongly wavelength dependent polarization degree and angle, rotating by nearly 70$^\\circ$ across the optical band. Comparison with historical measurements confirms long-term stability of the polarization spectrum and a $\\sim$90$^\\circ$ rotation in the near-ultraviolet. Interpreting the multi-wavelength polarization relative to the AGN ionization axis indicates that the main obscurer is not a compact circumnuclear torus, but a distant kpc-scale dust lane crossing the galaxy. This result implies that MCG-05-23-16 is in fact a type-1 AGN seen through foreground dust. The low X-ray column density becomes consistent with the absence of polarization, provided that the nuclear inclination is low."
  },
  {
    "date": "2026-01-20",
    "title": "Quantum Encoding Framework for Leptophilic Gauge Theories",
    "authors": "S. O. Kara",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13699v1",
    "source": "arXiv",
    "abstract": "We present a systematic quantum encoding framework for leptophilic extensions of the Standard Model, tailored to quantum simulation applications on near term and future quantum devices. Focusing on anomaly free $U(1)'_{\\ell}$ gauge theories, we show that the leptonic charge structure admits a natural and scalable representation on qubit registers, where gauge symmetries and anomaly cancellation conditions are enforced directly at the level of quantum states. Within this framework, gauge invariant operators are mapped to unitary quantum circuits, ensuring the preservation of gauge symmetry under quantum evolution. As a proof of principle, we construct explicit circuits that encode scattering processes mediated by a leptophilic gauge boson $Z'_{\\ell}$. Our results establish a reusable bridge between beyond the Standard Model gauge theories and quantum information science, providing a concrete pathway for simulating leptophilic gauge sectors within emerging quantum computing architectures."
  },
  {
    "date": "2026-01-20",
    "title": "Distributed Coverage Control on Poriferous Surface via Poly-Annulus Conformal Mapping",
    "authors": "Xun Feng, Chao Zhai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13688v1",
    "source": "arXiv",
    "abstract": "The inherent non-convexity of poriferous surfaces typically entraps agents in local minima and complicates workload distribution. To resolve this, we propose a distributed diffeomorphic coverage control framework for the multi-agent system (MAS) in such surfaces. First, we establish a distributed poly-annulus conformal mapping that transforms arbitrary poriferous surfaces into a multi-hole disk. Leveraging this topological equivalence, a collision-free sectorial partition mechanism is designed in the multi-hole disk, which rigorously induces strictly connected subregions and workload balance on the poriferous surfaces. This mechanism utilizes a buffer-based sequence mechanism to ensure strict topological safety when bypassing obstacles. Furthermore, a pull-back Riemannian metric is constructed to define the length metric that encodes safety constraints. Based on this metric, a distributed gradient-based control law is synthesized to drive agents toward optimal configurations, ensuring simultaneous obstacle avoidance and coverage optimization. Theoretical analyses guarantee the Input-to-State Stability (ISS) of the partition dynamics and the asymptotic convergence of the closed-loop system. Numerical simulations confirm the reachability and robustness of the proposed coverage algorithm, offering a scalable solution for distributed coverage in poriferous surfaces."
  },
  {
    "date": "2026-01-20",
    "title": "The spectral measures of random Jacobi matrices related to beta ensembles at high temperature and Dirichlet processes",
    "authors": "Fumihiko Nakano, Hoang Dung Trinh, Khanh Duy Trinh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13674v1",
    "source": "arXiv",
    "abstract": "In a high temperature regime where $βN \\to 2c$, the empirical distribution of the eigenvalues of Gaussian beta ensembles, beta Laguerre ensembles and beta Jacobi ensembles converges to a limiting measure which is related to associated Hermite polynomials, associated Laguerre polynomials and associated Jacobi polynomials, respectively. Here $β$ is the inverse temperature parameter, $N$ is the system size and $c>0$ is a given constant. This paper studies the spectral measure of the random tridiagonal matrix model of the three classical beta ensembles. We show that in the high temperature regime, the spectral measure converges in distribution to a Dirichlet process with base distribution being the limiting distribution, and scaling parameter $c$. Consequently, the spectral measure of a related semi-infinite Jacobi matrix coincides with that Dirichlet process, which provides examples of random Jacobi matrices with explicit spectral measures."
  },
  {
    "date": "2026-01-20",
    "title": "CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks",
    "authors": "Jiayu Lin, Zhongyu Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13669v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a \"middle ground\". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment."
  },
  {
    "date": "2026-01-20",
    "title": "The dynamically generated $N(1535)$ state in the $Λ_c^+ \\to p\\bar{K}^0 π^0$ decay",
    "authors": "Ying Li, En Wang, Li-Sheng Geng, Ju-Jun Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13668v1",
    "source": "arXiv",
    "abstract": "We present a theoretical analysis of the process $Λ_c^+ \\to p\\bar{K}^0 π^0$ within the chiral unitary approach, with particular emphasis on the dynamically generated $N(1535)$ resonance. In addition to $N(1535)$, our model incorporates contributions from other intermediate resonances including $N(1650)$, $K^*(892)$, $K_0^*(1430)$, $N(1440)$, and $Σ(1750)$. The calculated invariant mass distributions and Dalitz plot are in good agreement with the recent Belle measurements. Our analysis highlights the crucial role of $N(1535)$ state in this decay channel and supports its interpretation as a dynamically generated state arising from coupled-channel meson-baryon interactions."
  },
  {
    "date": "2026-01-20",
    "title": "Kenmotsu Contact Geometry Through the Lens of $\\ast-\\boldsymbolκ$-Ricci-Bourguignon Almost Solitons",
    "authors": "Lavanya Kumar, Soumendu Roy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13661v1",
    "source": "arXiv",
    "abstract": "This paper focuses on the study of the newly introduced $\\ast-\\boldsymbolκ$-Ricci-Bourguignon almost soliton pertaining to Kenmotsu structure manifolds. Our analysis concerns the characteristics of this soliton and derive the scalar curvature for a Kenmotsu manifold admitting such a structure. Further, we formulate the corresponding vector fields under the assumption that the manifold supports a $\\ast-\\boldsymbolκ-$Ricci-Bourguignon soliton. Additionally, we explore applications involving torse-forming vector fields within the framework of the $\\ast-\\boldsymbolκ-$Ricci-Bourguignon almost soliton on Kenmotsu structure manifolds. To support the theoretical findings, we provide a concrete illustration belonging to a $\\ast-\\boldsymbolκ-$Ricci-Bourguignon almost soliton in a 5D Kenmotsu structure manifold."
  },
  {
    "date": "2026-01-20",
    "title": "Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis",
    "authors": "Chunlei Meng, Ziyang Zhou, Lucas He, Xiaojing Du, Chun Ouyang, Zhongxue Gan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13659v1",
    "source": "arXiv",
    "abstract": "Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design."
  },
  {
    "date": "2026-01-20",
    "title": "Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation",
    "authors": "Arthur Amalvy, Hen-Hsen Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13658v1",
    "source": "arXiv",
    "abstract": "The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE."
  },
  {
    "date": "2026-01-20",
    "title": "GPUTB-2:An efficient E(3) network method for learning high-precision orthogonal Hamiltonian",
    "authors": "Yunlong Wang, Zhixin Liang, Chi Ding, Junjie Wang, Zheyong Fan, Hui-Tian Wang, Dingyu Xing, Jian Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13656v1",
    "source": "arXiv",
    "abstract": "Although equivariant neural networks have become a cornerstone for learning electronic Hamiltonians, the intrinsic non-orthogonality of linear combinations of atomic orbitals (LCAO) basis sets poses a fundamental challenge. The computational cost of Hamiltonian orthogonalization scales as O(N^3), which severely hinders electronic structure calculations for large-scale systems containing hundreds of thousands to millions of atoms. To address this issue, we develop GPUTB-2, a framework that learns implicitly orthogonality-preserving Hamiltonians by training directly on electronic band structures. Benefiting from an E(3)-equivariant network accelerated by Gaunt tensor product and SO(2) tensor product layers, GPUTB-2 achieves significantly higher accuracy than GPUTB across multiple benchmark systems. Moreover, GPUTB-2 accurately predicts large-scale electronic structures, including transport properties of temperature-perturbed SnSe and the band structures of magic-angle twisted bilayer graphene. By further integrating this framework with the linear-scaling quantum transport (LSQT) method, we investigate the electronic properties of million-atom amorphous graphene and uncover pressure-induced electronic structure transitions in more complex amorphous silicon. Together, these results establish GPUTB-2 as a high-accuracy and scalable approach for predicting orthogonal Hamiltonians."
  },
  {
    "date": "2026-01-20",
    "title": "When electrons meet ferroelastic domain walls in Strontium Titanate",
    "authors": "Shashank Kumar Ojha, Jyotirmay Maity, Srimanta Middey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13654v1",
    "source": "arXiv",
    "abstract": "Strontium titanate (SrTiO$_3$), famously described by Nobel laureate K. A. Müller as the \"drosophila of solid-state physics\", has been extensively investigated over the last seventy five years for its intricate coupling of structural, electronic, and dielectric properties and continues to serve as a foundational platform for advancing oxide electronics. In its pristine form, SrTiO$_3$ exhibits quantum paraelectric behavior below 35 K and undergoes an antiferrodistortive phase transition near 105 K. This transition generates ferroelastic twin domains separated by a dense network of domain walls, which function as nanoscale structural defects with far-reaching consequences. While the static influence of ferroelastic domain walls on carrier transport in electron-doped SrTiO$_3$ is well established, recent experimental results show that the emergence of polarity at these walls, combined with strain fields and inherent quantum fluctuations, induces correlated dynamical phenomena such as glass-like relaxations of electrons and memory effects. In this review, we highlight these recent advances, focusing on the subtle interplay between the emergence of nanoscale polar order, quantum fluctuations, and long-range strain fields. We propose that understanding charge carrier dynamics in the background of these complex ferroelastic domain wall landscapes offers a new paradigm for exploring electronic transport in the presence of local polar order and quantum fluctuations, with broad implications for correlated oxides."
  },
  {
    "date": "2026-01-20",
    "title": "Face-Voice Association with Inductive Bias for Maximum Class Separation",
    "authors": "Marta Moscati, Oleksandr Kats, Mubashir Noman, Muhammad Zaigham Zaheer, Yufang Hou, Markus Schedl, Shah Nawaz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13651v1",
    "source": "arXiv",
    "abstract": "Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm."
  },
  {
    "date": "2026-01-20",
    "title": "Gromov-Hausdorff stability of global attractors of damped wave equations under perturbations of the domain",
    "authors": "Ngoctu Bui, Jihoon Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13650v1",
    "source": "arXiv",
    "abstract": "In this paper, we will make use of the Gromov-Hausdorff distance between compact metric spaces to establish the continuous dependence and the Gromov-Hausdorff stability of global attractors for damped wave equations under perturbations of the domain."
  },
  {
    "date": "2026-01-20",
    "title": "Towards Token-Level Text Anomaly Detection",
    "authors": "Yang Cao, Bicheng Yu, Sikun Yang, Ming Liu, Yujiu Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13644v1",
    "source": "arXiv",
    "abstract": "Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore."
  },
  {
    "date": "2026-01-20",
    "title": "Superfluid Band Theory for the Rod Phase in the Magnetized Inner Crust Matter: Entrainment, Spin-orbit, Spin-triplet Pairing",
    "authors": "Kenta Yoshimura, Kazuyuki Sekizawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13636v1",
    "source": "arXiv",
    "abstract": "The inner crust of neutron stars hosts a rich variety of nuclear phenomena and provides a unique environment for exploring microscopic nuclear properties relevant to diverse astrophysical observations. Particularly magnetars, which possess extremely strong magnetic-fields, have attracted increasing attention in connection with nuclear spin dynamics and unconventional pairing correlations. This work is dedicated to develop a comprehensive theoretical framework to describe the structures and properties of two-dimensional (rod-phase) matter in the neutron star inner crust, incorporating band-structure effects, neutron spin-triplet pairing, and strong magnetic-fields on an equal footing. The main results of this study can be summarized as follows. In the first place, the magnetic-fields of the order of $10^{16}\\,$G are found to substantially enhance the neutron effective mass by a factor of approximately $1.5$, indicating a significant modification of entrainment properties in strongly magnetized crustal matter. In the second place, while the overall behavior of pairing phase transitions is qualitatively similar to that observed in one-dimensional systems studied previously, the present two-dimensional calculations reveal a nontrivial role of the spin-orbit interaction in inducing spin-polarization under magnetic fields. In the third place, concerning spin-triplet superfluidity, the rank-0 component is shown to emerge as a consequence of magnetic-field-induced spin-polarization, irrespective of the presence of spin-triplet pairing interactions, whereas the rank-2 component appears only when the corresponding interaction channel is included."
  },
  {
    "date": "2026-01-20",
    "title": "Deep Learning-Enabled Signal Detection for MIMO-OTFS-Based 6G and Future Wireless Networks",
    "authors": "Emin Akpinar, Emir Aslandogan, Burak Ahmet Ozden, Haci Ilhan, Erdogan Aydin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13635v1",
    "source": "arXiv",
    "abstract": "Orthogonal time frequency space (OTFS) modulation stands out as a promising waveform for sixth generation (6G) and beyond wireless communication systems, offering superior performance over conventional methods, particularly in high-mobility scenarios and dispersive channel conditions. Recent research has demonstrated that the reduced computational complexity of deep learning (DL)-based signal detection (SD) methods constitutes a compelling alternative to conventional techniques. In this study, low-complexity DL-based SD methods are proposed for a multiple-input multiple-output (MIMO)-OTFS system and examined under Nakagami-$m$ channel conditions. The symbols obtained from the receiver antennas are combined using maximum ratio combining (MRC) and detected with the help of a DL-based detector implemented with multi-layer perceptron (MLP), convolutional neural network (CNN), and residual network (ResNet). Complexity analysis reveals that the MLP architecture offers significantly lower computational complexity compared to CNN, ResNet, and classical methods such as maximum likelihood detection (MLD). Furthermore, numerical analyses have shown that the proposed DL-based detectors, despite their low complexity, achieve comparable bit error rate (BER) performance to that of a high-performance MLD under various system conditions."
  },
  {
    "date": "2026-01-20",
    "title": "ContiguousKV: Accelerating LLM Prefill with Granularity-Aligned KV Cache Management",
    "authors": "Jing Zou, Shangyu Wu, Hancong Duan, Qiao Li, Chun Jason Xue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13631v1",
    "source": "arXiv",
    "abstract": "Efficiently serving Large Language Models (LLMs) with persistent Prefix Key-Value (KV) Cache is critical for applications like conversational search and multi-turn dialogue. Serving a request requires loading the pre-computed prefix KV cache and generating the first token, defined as the Re-Prefill Phase. Offloading this shared prefix cache to secondary storage is essential for memory scalability. Re-Prefill with offloading suffers from severe I/O bottlenecks in two aspects. First, semantic-aware KV cache pruning algorithms select important tokens in fine granularity, while systems manage I/O in coarse, fixed-size blocks, causing severe read amplification. Second, the sequential dependency between identifying important tokens and loading KV cache creates idle I/O and compute bubbles, under-utilizing system resources. This paper proposes \\textit{ContiguousKV}, a high-performance prefix KV cache offloading system that bridges algorithmic semantics with I/O efficiency to accelerate the Re-Prefill phase. We first introduce \\textit{ContiguousChunk}, a unified data management granularity that aligns KV cache pruning with I/O operations. All the mechanisms critical for I/O performance are performed at the granularity of ContiguousChunk, thereby eliminating read amplification. By exploiting the high similarity in important ContiguousChunk indices across layers, we propose intra- and inter-period asynchronous prefetching to break the sequential dependency between I/O and compute, effectively eliminating idle bubbles. Finally, we propose attention-guided cache management to retain semantically critical prefix data in memory. Evaluations on Qwen2.5 series models show that ContiguousKV achieves a 3.85x speedup in the Re-Prefill phase over the state-of-the-art offloading system IMPRESS, while maintaining high output quality."
  },
  {
    "date": "2026-01-20",
    "title": "Cosmological Budget of Entropy from Merging Black Holes",
    "authors": "Siyuan Chen, Karan Jani, Thomas W. Kephart",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13621v1",
    "source": "arXiv",
    "abstract": "Black holes contain more entropy than any other component of the observable universe. Gravitational-wave observations from LIGO and Virgo have shown evidence of a previously unknown black hole mass range, which provides new information to update the entropy budget. Increases in entropy due to binary black hole mergers, as implied in the second law of thermodynamics, should also be added to the budget. In this study, we update the cosmological entropy budget for black holes in the stellar to lite-intermediate-mass range $(5-300~M_\\odot)$, originating from either supernovae or binary mergers, by utilizing a suite of population synthesis models and phenomenological fits derived from numerical relativity. We report three new insights: Firstly, the cumulative entropy from merging black holes surpasses the total entropy from cosmic microwave background photons around the onset of the Over-massive Black Hole Galaxy phase at $z\\sim 12$, suggesting that mergers played a more significant role in shaping the thermodynamic state of the early universe than relic radiation. Secondly, if primordial black holes constitute a nonzero fraction of dark matter, their early binary mergers establish an ``entropy floor\" in the Dark Ages and can dominate the cumulative merger-generated entropy history even for small abundances. Thirdly, by computing the cosmological density parameters, we highlight the thermodynamic asymmetry in black hole mergers, where the production of gravitational-wave energy is inefficient compared to the immense generation of Bekenstein-Hawking entropy."
  },
  {
    "date": "2026-01-20",
    "title": "A scalable near-visible integrated photon-pair source for satellite quantum science",
    "authors": "Yi-Han Luo, Yuan Chen, Ruiyang Chen, Zeying Zhong, Sicheng Zeng, Baoqi Shi, Sanli Huang, Chen Shen, Hui-Nan Wu, Yuan Cao, Junqiu Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13617v1",
    "source": "arXiv",
    "abstract": "Quantum state distribution over vast distances is essential for global-scale quantum networks and fundamental test of quantum physics at space scale. While satellite platforms have demonstrated thousand-kilometer entanglement distribution, quantum key distribution and quantum teleportation with ground, future constellations and deep-space missions demand photon sources that are robust, compact, and power-efficient. Integrated photonics offers a scalable solution, yet a critical spectral gap persists. Although telecom-band integrated photon-pair sources are well established, near-visible photons offer distinct advantages for satellite-to-ground links by mitigating diffraction loss and maximizing the collection efficiency of optical telescopes. Scalable integrated sources in this regime have remained elusive due to the fundamental challenge of achieving anomalous dispersion in materials transparent at visible wavelengths. Here we bridge this gap by demonstrating an integrated near-visible photon-pair source based on a wide-bandgap, ultralow-loss, silicon nitride (Si$_3$N$_4$) microresonator. By engineering the dispersion of higher-order waveguide modes, we overcome the intrinsic normal dispersion limit to achieve efficient phase matching. The device exhibits a spectral brightness of 4.87$\\times$10$^7$ pairs/s/mW$^2$/GHz and a narrow photon linewidth of 357 MHz. We report high-purity heralded single-photon generation with a heralding rate up to 2.3 MHz and a second-order correlation function as low as 0.0041. Furthermore, we observe energy-time entanglement with 98.4% interference visibility, violating the CHSH limit even at flux exceeding 40.6 million pairs/s. Combined with the proven radiation hardness of Si$_3$N$_4$, this source constitutes a flight-ready hardware foundation for daylight quantum communications and protocols requiring on-orbit multiphoton interference."
  },
  {
    "date": "2026-01-20",
    "title": "Resilient Hierarchical Power Control for Hybrid GFL/GFM Microgrids Under Mixed Cyber-Attacks and Physical Constraints",
    "authors": "Lifu Ding, Chunhui Hou, Yutong Li, Qinmin Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13615v1",
    "source": "arXiv",
    "abstract": "Hybrid microgrids integrating Grid-Following (GFL) and Grid-Forming (GFM) inverters present complex control challenges arising from the decoupling between long-term economic dispatch and real-time dynamic regulation, as well as the distinct physical limitations of heterogeneous inverters under cyber uncertainties. This paper proposes a Resilient Hierarchical Power Control (RHPC) strategy to unify these conflicting requirements within a cohesive framework. A standardized power increment mechanism is developed to bridge the tertiary and secondary layers, ensuring that real-time load fluctuations are compensated strictly according to the optimal economic ratios derived from the tertiary layer. To address the strict active power saturation constraints of GFL units, a dynamic activation scheme coupled with projection operators is introduced, which actively isolates saturated nodes from the consensus loop to prevent integrator wind-up and preserve the stability of the GFM backbone. Furthermore, the proposed framework incorporates a multi-scale attention mechanism and LSTM-based predictors into the secondary control protocol, endowing the system with robustness against unbounded False Data Injection (FDI) attacks and packet losses. Rigorous theoretical analysis confirms that the system achieves Uniformly Ultimately Bounded (UUB) convergence, and simulations on a modified IEEE 33-bus system demonstrate that the proposed strategy significantly improves power sharing accuracy and operational resilience in both grid-connected and islanded modes compared to conventional methods."
  },
  {
    "date": "2026-01-20",
    "title": "Balancing Fairness and High Match Rates in Reciprocal Recommender Systems: A Nash Social Welfare Approach",
    "authors": "Yoji Tomita, Tomohiko Yokoyama",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13609v1",
    "source": "arXiv",
    "abstract": "Matching platforms, such as online dating services and job recommendations, have become increasingly prevalent. For the success of these platforms, it is crucial to design reciprocal recommender systems (RRSs) that not only increase the total number of matches but also avoid creating unfairness among users. In this paper, we investigate the fairness of RRSs on matching platforms. From the perspective of fair division, we define the users' opportunities to be recommended and establish the fairness concept of envy-freeness in the allocation of these opportunities. We first introduce the Social Welfare (SW) method, which approximately maximizes the number of matches, and show that it leads to significant unfairness in recommendation opportunities, illustrating the trade-off between fairness and match rates. To address this challenge, we propose the Nash Social Welfare (NSW) method, which alternately optimizes two NSW functions and achieves nearly envy-free recommendations. We further generalize the SW and NSW method to the $α$-SW method, which balances the trade-off between fairness and high match rates. Additionally, we develop a computationally efficient approximation algorithm for the SW/NSW/$α$-SW methods based on the Sinkhorn algorithm. Through extensive experiments on both synthetic datasets and two real-world datasets, we demonstrate the practical effectiveness of our approach."
  },
  {
    "date": "2026-01-20",
    "title": "A Quenched and Relatively Isolated Dwarf Galaxy in the Local Volume",
    "authors": "Tehreem N. Hai, Kristen B. W. McQuinn, Yao-Yuan Mao, Roger E. Cohen, David Shih, Erik Tollerud, Joseph A. Breneman, Andrew E. Dolphin, Max J. B. Newman, Adam Smercina",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14248v1",
    "source": "arXiv",
    "abstract": "An increasing number of discoveries of isolated and quenched dwarf galaxies are challenging the idea that the present-day local environment of low-mass systems is the main determinant of their quenching. We present new Hubble Space Telescope (HST) data of one such system, the dwarf galaxy Canes Venatici C (CVn C). CVn C is a low-mass (3.4(+4.2-2.6)*10^6 M_sun) galaxy with a Tip of the Red Giant Branch distance of 8.43(+0.47-0.32) Mpc determined from the resolved stars in the HST imaging, which we also use to derive CVn C's structural parameters. CVn C's distance places CVn C in the Local Volume and in an isolated environment with the most tidally influential L* galaxy > 5Rvir away. Additional constraints from the HST color-magnitude diagram, archival Far-Ultraviolet (FUV), and neutral hydrogen (HI) data show that CVn C is quenched, with no evidence of star formation in the last 100 Myr and no detectable gas (MHI < 1.5*10^6 M_sun). Circumstantial evidence suggests that CVn C may have quenched via past interactions with the L* galaxy NGC 4631 (L_K = 10^10.4 L_sun), and was possibly sent on an extreme backsplash orbit by the tidal dissolution of a subhalo group. However, other quenching mechanisms-such as stripping via the cosmic web-cannot be ruled out. CVn C adds to the growing number of quenched dwarf galaxies in under-dense environments, a population that will be critical to defining the mass and environment regimes in which different quenching mechanisms operate."
  },
  {
    "date": "2026-01-20",
    "title": "APEX-Agents",
    "authors": "Bertie Vidgen, Austin Mann, Abby Fennelly, John Wright Stanly, Lucas Rothman, Marco Burstein, Julien Benchek, David Ostrofsky, Anirudh Ravichandran, Debnil Sur, Neel Venugopal, Alannah Hsia, Isaac Robinson, Calix Huang, Olivia Varones, Daniyal Khan, Michael Haines, Zach Richards, Chirag Mahapatra, Brendan Foody, Osvald Nitski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14242v1",
    "source": "arXiv",
    "abstract": "We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation."
  },
  {
    "date": "2026-01-20",
    "title": "Burst Aware Forecasting of User Traffic Demand in LEO Satellite Networks",
    "authors": "Yekta Demirci, Guillaume Mantelet, Stephane Martel, Jean-Francois Frigon, Gunes Karabulut Kurt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14233v1",
    "source": "arXiv",
    "abstract": "In Low Earth Orbit (LEO) satellite networks, Beam Hopping (BH) technology enables the efficient utilization of limited radio resources by adapting to varying user demands and link conditions. Effective BH planning requires prior knowledge of upcoming traffic at the time of scheduling, making forecasting an important sub-task. Forecasting becomes particularly critical under heavy load conditions where an unexpected demand burst combined with link degradation may cause buffer overflows and packet loss. To address this challenge, we propose a burst aware forecasting solution. This challenge may arise in a wide range of wireless networks; therefore, the proposed solution is broadly applicable to settings characterized by bursty traffic patterns where accurate demand forecasting is essential. Our approach introduces three key enhancements to a transformer architecture: (i) a distance from the last burst embedding to capture burst proximity, (ii) two additional linear layers in the decoder to forecast both upcoming bursts and their relative impact, and (iii) use of an asymmetric cost function during model training to better capture burst dynamics. Empirical evaluations in an Earth-fixed cell under high-traffic demand scenario demonstrate that the proposed model reduces prediction error by up to 94% at a one-step horizon and maintains the ability to accurately capture bursts even near the end of longer prediction horizons following Mean Square Error (MSE) metric."
  },
  {
    "date": "2026-01-20",
    "title": "Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment",
    "authors": "Punit Kumar, Vaibhav Saran, Divyesh Patel, Nitin Kulkarni, Alina Vereshchaka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14228v1",
    "source": "arXiv",
    "abstract": "Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations."
  },
  {
    "date": "2026-01-20",
    "title": "Group Fourier filtering of quantum resources in quantum phase space",
    "authors": "Luke Coffman, N. L. Diaz, Martin Larocca, Maria Schuld, M. Cerezo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14225v1",
    "source": "arXiv",
    "abstract": "Recently, it has been shown that group Fourier analysis of quantum states, i.e., decomposing them into the irreducible representations (irreps) of a symmetry group, enables new ways to characterize their resourcefulness. Given that quantum phase spaces (QPSs) provide an alternative description of quantum systems, and thus of the group's representation, one may wonder how such harmonic analysis changes. In this work we show that for general compact Lie-group quantum resource theories (QRTs), the entire family of Stratonovich-Weyl quantum phase space representations-characterized by the Cahill-Glauber parameter $s$-has a clear resource-theoretic and signal-processing meaning. Specifically, changing $s$ implements a group Fourier filter that can be continuously tuned to favor low-dimensional irreps where free states have most of their support ($s=-1$), leave the spectrum unchanged ($s=0$), or highlight resourceful, high-dimensional irreps ($s=1$). As such, distinct QPSs constitute veritable group Fourier filters for resources. Moreover, we show that the norms of the QRT's free state Fourier components completely characterize all QPSs. Finally, we uncover an $s$-duality relating the phase space spectra of free states and typical (Haar-random) highly resourceful states through a shift in $s$. Overall, our results provide a new interpretation of QPSs and promote them to a signal-processing framework for diagnosing, filtering, and visualizing quantum resources."
  },
  {
    "date": "2026-01-20",
    "title": "Many-body Euler topology",
    "authors": "Axel Fünfhaus, Titus Neupert, Thilo Kopp, Roser Valentí",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14217v1",
    "source": "arXiv",
    "abstract": "Integer and fractional Chern insulators exhibit a nonzero quantized anomalous Hall conductivity due to a spontaneous breaking of time reversal symmetry. To identify nontrivial topology in their time-reversal symmetric many-body spectra, we introduce many-body Euler numbers as a counterpart to many-body Chern numbers. Exemplarily, we perform calculations in a topological Hubbard model that can realize Chern and fractional Chern insulating phases. Furthermore, we lay out a classification scheme to realize different topological phases in interacting systems using symmetry indicators in analogy to topological band theory."
  },
  {
    "date": "2026-01-20",
    "title": "HALT: Hallucination Assessment via Latent Testing",
    "authors": "Rohan Bhatnagar, Youran Sun, Chi Andrew Zhang, Yixin Wen, Haizhao Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14210v1",
    "source": "arXiv",
    "abstract": "Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI."
  },
  {
    "date": "2026-01-20",
    "title": "Dynamical mass of a solar-like oscillator at the main-sequence turnoff from Gaia astrometry & ground-based spectroscopy",
    "authors": "P. G. Beck, T. Masseron, K. Pavlovski, D. Godoy-Rivera, S. Mathur, D. H. Grossmann, A. Hamy, D. B. Palakkatharappil, E. Panetier, R. A. García, J. Merc, Y. Lu, I. Amestoy, H. J. Deeg",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14197v1",
    "source": "arXiv",
    "abstract": "Asteroseismology is widely used for precise determining of masses of solar-like oscillating stars by performing individual-frequency modeling or applying homological scaling relations. However, these methods lack dynamical validation on the main sequence due to the absence of eclipsing double-lined binary system (SB2) as benchmark objects. By providing the orbital inclination, astrometric binary systems from ESA Gaia DR3 offer an abundant alternative for eclipsing systems. We present KIC693187 as the first SB2, hosting a solar-like oscillating post-main-sequence star with dynamical masses. By combining Gaia astrometry with spectroscopic obtained with the Las Cumbres Observatory network (LCO), we find $M_1^\\mathrm{dyn}$=0.99$\\pm$0.05$M_\\odot$ and $M_2^\\mathrm{dyn}$=0.89$\\pm$0.04$M_\\odot$ for the primary and secondary, respectively. Asteroseismic parameters were extracted from photometry of the NASA \\Kepler satellite. The mass from individual frequency modeling is $M_1^\\mathrm{IF}$=0.92$\\pm$0.01$M_\\odot$. Taking into account the systematic uncertainty of 0.04$M_\\odot$ for best fit models from individual frequency fitting, we find an agreement within 1.2$σ$. From scaling relations we obtain a mass range of 0.93 to 0.98$M_\\odot$ by using the observed large frequency separations (\\dnu) in the scaling relations for the primary. By using standard corrections for departures from the asymptotic regime of \\dnu, we obtained a mass range of 0.83 to 1.03$M_\\odot$. The upper ends of both ranges agree well with the dynamical mass of the primary. This approach provides the first empirical validation for main-sequence solar-like oscillators and opens a new window for validating asteroseismology. Through a dedicatded program targeting astrometric SB2 binary systems, ESA's PLATO space mission will provide will enlarge the benchmark sample substantially."
  },
  {
    "date": "2026-01-20",
    "title": "A Minimax Perspective on Almost-Stable Matchings",
    "authors": "Frederik Glitzner, David Manlove",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14195v1",
    "source": "arXiv",
    "abstract": "Stability is crucial in matching markets, yet in many real-world settings - from hospital residency allocations to roommate assignments - full stability is either impossible to achieve or can come at the cost of leaving many agents unmatched. When stability cannot be achieved, algorithmicists and market designers face a critical question: how should instability be measured and distributed among participants? Existing approaches to \"almost-stable\" matchings focus on aggregate measures, minimising either the total number of blocking pairs or the count of agents involved in blocking pairs. However, such aggregate objectives can result in concentrated instability on a few individual agents, raising concerns about fairness and incentives to deviate. We introduce a fairness-oriented approach to approximate stability based on the minimax principle: we seek matchings that minimise the maximum number of blocking pairs any agent is in. Equivalently, we minimise the maximum number of agents that anyone has justified envy towards. This distributional objective protects the worst-off agents from a disproportionate amount of instability. We characterise the computational complexity of this notion across fundamental matching settings. Surprisingly, even very modest guarantees prove computationally intractable: we show that it is NP-complete to decide whether a matching exists in which no agent is in more than one blocking pair, even when preference lists have constant-bounded length. This hardness applies to both Stable Roommates and maximum-cardinality Stable Marriage. On the positive side, we provide polynomial-time algorithms when agents rank at most two others, and present approximation algorithms and integer programs. Our results map the algorithmic landscape and reveal fundamental trade-offs between distributional guarantees and computational feasibility."
  },
  {
    "date": "2026-01-20",
    "title": "Influence of Finite-Nuclei Constraints on High-Density Transitions and Neutron Star Properties",
    "authors": "Anagh Venneti, Sarmistha Banik, Bijay K Agrawal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14194v1",
    "source": "arXiv",
    "abstract": "We construct posterior distributions of the equation of state (EoS) for matter beyond the inner crust of neutron stars by incorporating finite nuclei (FN) constraints within relativistic mean field models. These constraints are implemented in three complementary ways: (i) through theoretical bounds on the EoS, (ii) implicitly via nuclear matter parameters, and (iii) explicitly by enforcing consistency with experimental binding energies and charge radii of selected nuclei. The resulting low-density nucleonic EoSs are subsequently matched to a model-agnostic speed-of-sound parametrization, constrained by astrophysical observations, including NICER mass-radius measurements, tidal deformability limits from GW170817, and lower bounds on the maximum neutron-star mass inferred from radio pulsar observations. We find that the admissible range of the transition density is strongly sensitive to the choice of the low-density EoS. In particular, the inclusion of explicit FN constraints significantly reduces the allowed parameter space of the nucleonic EoS at low densities, narrowing the transition-density range by nearly a factor of two. Consequently, neutron-star properties inferred from EoSs with explicit FN constraints differ substantially, with especially pronounced effects for low-mass neutron stars and their correlations with nuclear matter parameters. A quantitative comparison, using metrics based on Mahalanobis distance, shows consistency of the explicit constraints with PSRs J0740+6620, J0030+0451, and J0437-4715, but suggest a possible tension with PSR J0614-3329. These findings underscore the critical importance of a consistent treatment of finite-nuclei properties for reliably inferring the behavior of high-density matter and the presence of possible phase transitions from astrophysical observations."
  },
  {
    "date": "2026-01-20",
    "title": "Translation invariant curvature measures of convex bodies",
    "authors": "Jakob Schuhmacher, Thomas Wannerer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14193v1",
    "source": "arXiv",
    "abstract": "In a series of papers, Weil initiated the investigation of translation invariant curvature measures of convex bodies, which include as prime examples Federer's curvature measures. In this paper, we continue this line of research by introducing new tools to study curvature measures. Our main results suggest that the space of curvature measures, which is graded by degree and parity, is highly structured: We conjecture that each graded component has length at most $2$ as a representation of the general linear group, and we prove this in degrees $0$ and $n-2$. Beyond this conjectural picture, our methods yield a characterization of Federer's curvature measures under weaker assumptions."
  },
  {
    "date": "2026-01-20",
    "title": "From big q-Jacobi and Chebyshev polynomials to exponential-reproducing subdivision: new identities",
    "authors": "Leonard Peter Bos, Lucia Romani, Alberto Viscardi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14189v1",
    "source": "arXiv",
    "abstract": "In this paper we derive new identities satisfied by Chebyshev polynomials of the first kind and big q-Jacobi polynomials. An immediate benefit of the derived identities is the achievement of closed-form expressions for the Laurent polynomials that identify minimum-support interpolating subdivision schemes reproducing finite sets of integer powers of exponentials."
  },
  {
    "date": "2026-01-20",
    "title": "Progressive self-supervised blind-spot denoising method for LDCT denoising",
    "authors": "Yichao Liu, Yueyang Teng, Junwen Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14180v1",
    "source": "arXiv",
    "abstract": "Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods."
  },
  {
    "date": "2026-01-20",
    "title": "Pre-computed aerosol extinction, scattering and asymmetry grids for scalable atmospheric retrievals",
    "authors": "Maël M. Voyer, Quentin Changeat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14177v1",
    "source": "arXiv",
    "abstract": "The unprecedented wavelength coverage and sensitivity of the James Webb Space Telescope (JWST) permits to measure the absorption features of a wide range of condensate species from Silicates to Titan tholins. Atmospheric retrievals are uniquely suited to analyse these datasets and characterize the aerosols present in exoplanet atmospheres. However, including the optical properties of condensed particles within retrieval frameworks remains computationally expensive, limiting our ability to fully exploit JWST observations. In this work, we improve the computational efficiency and scaling behavior of aerosol models in atmospheric retrievals, enabling in-depth studies including multiple condensate species within practical time scales. Rather than computing the aerosol Mie coefficients for each sampled model, we pre-compute extinction efficiency (Qext), scattering efficiency (Qscat) and asymmetry parameter (g) grids for seven condensate species relevant in exoplanet atmospheres (Mg2SiO4 amorph sol - gel, MgSiO3 amorph glass, MgSiO3 amorph sol - gel, SiO2 alpha, SiO2 amorph, SiO and Titan tholins). The pre-computed Qext grids significantly reduce computation time between 1.4 and 17 times with negligible differences on the retrieved parameters. They also scale effortlessly with the number of aerosol species while maintaining the accuracy of cloud models. Thereby enabling more complex retrievals as well as broader population studies without increasing the overall error budget. The Qext, Qscat and g grids are freely available on Zenodo as well as a public TauREx plugin -TauREx-PCQ- that utilize them."
  },
  {
    "date": "2026-01-20",
    "title": "ReSearch: A Multi-Stage Machine Learning Framework for Earth Science Data Discovery",
    "authors": "Youran Sun, Yixin Wen, Haizhao Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14176v1",
    "source": "arXiv",
    "abstract": "The rapid expansion of Earth Science data from satellite observations, reanalysis products, and numerical simulations has created a critical bottleneck in scientific discovery, namely identifying relevant datasets for a given research objective. Existing discovery systems are primarily retrieval-centric and struggle to bridge the gap between high-level scientific intent and heterogeneous metadata at scale. We introduce \\textbf{ReSearch}, a multi-stage, reasoning-enhanced search framework that formulates Earth Science data discovery as an iterative process of intent interpretation, high-recall retrieval, and context-aware ranking. ReSearch integrates lexical search, semantic embeddings, abbreviation expansion, and large language model reranking within a unified architecture that explicitly separates recall and precision objectives. To enable realistic evaluation, we construct a literature-grounded benchmark by aligning natural language intent with datasets cited in peer-reviewed Earth Science studies. Experiments demonstrate that ReSearch consistently improves recall and ranking performance over baseline methods, particularly for task-based queries expressing abstract scientific goals. These results underscore the importance of intent-aware, multi-stage search as a foundational capability for reproducible and scalable Earth Science research."
  },
  {
    "date": "2026-01-20",
    "title": "A model of errors in transformers",
    "authors": "Suvrat Raju, Praneeth Netrapalli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14175v1",
    "source": "arXiv",
    "abstract": "We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate."
  },
  {
    "date": "2026-01-20",
    "title": "Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum",
    "authors": "Víctor Yeste, Paolo Rosso",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14172v1",
    "source": "arXiv",
    "abstract": "We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task (\"does any value appear?\") and show that it is learnable from single sentences (positive-class F1 $\\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance."
  },
  {
    "date": "2026-01-20",
    "title": "Multi-Partner Project: Multi-GPU Performance Portability Analysis for CFD Simulations at Scale",
    "authors": "Panagiotis-Eleftherios Eleftherakis, George Anagnostopoulos, Anastassis Kapetanakis, Mohammad Umair, Jean-Yves Vet, Konstantinos Iliakis, Jonathan Vincent, Jing Gong, Akshay Patil, Clara García-Sánchez, Gerardo Zampino, Ricardo Vinuesa, Sotirios Xydis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14159v1",
    "source": "arXiv",
    "abstract": "As heterogeneous supercomputing architectures leveraging GPUs become increasingly central to high-performance computing (HPC), it is crucial for computational fluid dynamics (CFD) simulations, a de-facto HPC workload, to efficiently utilize such hardware. One of the key challenges of HPC codes is performance portability, i.e. the ability to maintain near-optimal performance across different accelerators. In the context of the \\textbf{REFMAP} project, which targets scalable, GPU-enabled multi-fidelity CFD for urban airflow prediction, this paper analyzes the performance portability of SOD2D, a state-of-the-art Spectral Elements simulation framework across AMD and NVIDIA GPU architectures. We first discuss the physical and numerical models underlying SOD2D, highlighting its computational hotspots. Then, we examine its performance and scalability in a multi-level manner, i.e. defining and characterizing an extensive full-stack design space spanning across application, software and hardware infrastructure related parameters. Single-GPU performance characterization across server-grade NVIDIA and AMD GPU architectures and vendor-specific compiler stacks, show the potential as well as the diverse effect of memory access optimizations, i.e. 0.69$\\times$ - 3.91$\\times$ deviations in acceleration speedup. Performance variability of SOD2D at scale is further examined on the LUMI multi-GPU cluster, where profiling reveals similar throughput variations, highlighting the limits of performance projections and the need for multi-level, informed tuning."
  },
  {
    "date": "2026-01-20",
    "title": "Resolving Overlapping EBSD Patterns by Experiment -- Simulation Residuals Analysis",
    "authors": "Grzegorz Cios, Aimo Winkelmann, Tomasz Tokarski, Wiktor Bednarczyk, Piotr Bała",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14155v1",
    "source": "arXiv",
    "abstract": "In the technique of Electron Backscatter Diffraction (EBSD), the accurate detection and identification of different phases existing in a sample is often limited by overlapping Kikuchi diffraction patterns originating from the extended probing volume of the individual EBSD map points measured in the scanning electron microscope (SEM). We present an iterative approach that uses simulated Kikuchi patterns to resolve several overlapping diffraction signals. For each measured EBSD pattern, our method first identifies the best-fit simulated Kikuchi pattern using dynamic template matching. This simulated, ideal reference pattern is then further processed to optimally match the experimental image, uncovering any underlying weaker signals after subtraction. Repeatedly utilizing dynamic template matching and pattern subtraction on residual signals of subsequent steps enables the identification of minor phases that might otherwise be missed from the probing volume of the EBSD map point. This method significantly improves phase detection in complex materials, addressing a key limitation of conventional EBSD analysis that conventionally assigns a single phase to each map point. The present method does not require a known orientation relationship between the phases of the overlapping patterns or close neighbor experimental patterns like previously published approaches."
  },
  {
    "date": "2026-01-20",
    "title": "Trade relationships during and after a crisis",
    "authors": "Alejandra Martinez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14150v1",
    "source": "arXiv",
    "abstract": "I study how firms adjust to temporary disruptions in international trade relationships organized through relational contracts. I exploit an extreme, plausibly exogenous weather shock during the 2010-11 La Niña season that restricted Colombian flower exporters' access to cargo terminals. Using transaction-level data from the Colombian-U.S. flower trade, I show that importers with less-exposed supplier portfolios are less likely to terminate disrupted relationships, instead tolerating shipment delays. In contrast, firms facing greater exposure experience higher partner turnover and are more likely to exit the market, with exit accounting for a substantial share of relationship separations. These findings demonstrate that idiosyncratic shocks to buyer-seller relationships can propagate into persistent changes in firms' trading portfolios."
  },
  {
    "date": "2026-01-20",
    "title": "Efficient charge transfer in solution-processed PbS Quantum Dot-reduced graphene oxide hybrid materials",
    "authors": "Beatriz Martín-García, Anatolii Polovitsyn, Mirko Prato, Iwan Moreels",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14144v1",
    "source": "arXiv",
    "abstract": "Quantum dot - graphene hybrid materials have raised significant interest due to the unique synergy of the optical properties of colloidal quantum dots (QDs) and the transport properties of graphene. This stimulated the development of low-cost and up-scalable solution-processed strategies for hybrid materials with potential application in light harvesting and opto-electronic devices. Here we report a versatile covalent-linking based approach for the functionalization of reduced graphene oxide (rGO), to prepare a variety of QD-rGO hybrid dispersions with QDs of different size and composition (PbS, PbS/CdS and CdSe QDs), and shape (CdSe/CdS dot-in-rods). We achieved a well-controlled QD coverage of the rGO sheets by functionalizing the rGO surface with mercapto-silane linkers. A further spectroscopic investigation of near-infrared PbS QD-rGO materials demonstrates efficient electronic coupling between both materials. The QD photoluminescence emission quenching and exciton lifetime shortening up to 95%, together with subtle graphene Raman G-band shifts upon QD linking, supports electron transfer as the dominant relaxation pathway from the QD to the rGO. The use of core/shell PbS/CdS QDs allows tuning of the transfer efficiency from 94% for a 0.2 nm thin CdS shell, down to 30% for a 1.1 nm thick shell."
  },
  {
    "date": "2026-01-20",
    "title": "Gilbert Damping Parameters of Epitaxially-Stabilized Iron Gallium Thin Films from Ferromagnetic Resonance",
    "authors": "Ruth Loh, Sujan Shrestha, Jiaxuan Wu, Jia-Mian Hu, Christoph Adelmann, Florin Ciubotaru, John T. Heron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14143v1",
    "source": "arXiv",
    "abstract": "Iron gallium (FeGa) alloys are excellent rare-earth-free magnetostrictors. Through epitaxial stabilization, the disordered A2 alloy can be extended from 19% to 30% gallium resulting in a magnetostrictive coefficient almost twice than that which is seen in rare earth magnetostrictors like SmFe2. In a composite magnetoelectric structure, this makes epitaxially-stabilized iron gallium a key material for energy-efficient beyond CMOS technologies. The energy dissipation and speed of magnetoelectric switching, however, is affected by the magnetic resonance frequency and damping. Here we report the evolution of the ferromagnetic resonance and key materials parameters (magnetic anisotropy, magnetic damping, and magnetostriction coefficient) for 70 nm thick epitaxially-stabilized single crystal A2 FeGa films beyond 19% Ga. Using flip chip ferromagnetic resonance (1-14 GHz), we find that the Gilbert damping parameter spans the range of 0.09-0.16 and decreases as the Ga concentration increases. This correlates an increasing magnetoelastic coupling with a reduction in the Gilbert damping. We find that the effective damping is a mix of contributions from the intrinsic magnon-phonon scattering and other scattering/dissipation mechanisms, with the latter being dominant especially at high Ga composition. Our results provide insight into the mechanism of magnetic relaxation in metastable high magnetostriction materials and potential switching behavior of composite magnetoelectrics."
  },
  {
    "date": "2026-01-20",
    "title": "The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning",
    "authors": "Renmiao Chen, Yida Lu, Shiyao Cui, Xuan Ouyang, Victor Shea-Jay Huang, Shumin Zhang, Chengwei Pan, Han Qiu, Minlie Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14127v1",
    "source": "arXiv",
    "abstract": "As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench."
  },
  {
    "date": "2026-01-20",
    "title": "Flexible curves and Hausdorff dimension",
    "authors": "Alex Rodriguez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14125v1",
    "source": "arXiv",
    "abstract": "We show that given a log-singular circle homeomorphism $h$ and given any $s\\in[1,2]$, there is a flexible curve of Hausdorff dimension $s$ with welding $h$. We also see that there is another curve with welding $h$ and positive area. In particular, this implies that given a flexible curve $Γ$, there is a homeomorphism of the plane $φ\\colon\\mathbb{C}\\to\\mathbb{C}$, conformal off $Γ$, so that $φ(Γ)$ has positive area. This answers a particular case of the corresponding conjecture for general non-conformally removable sets, for a class of curves that is residual in the space of all Jordan curves."
  },
  {
    "date": "2026-01-20",
    "title": "Universal Chord Theorem and a Topological Analysis",
    "authors": "Ion Ciudin, Eugen J. Ionascu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14120v1",
    "source": "arXiv",
    "abstract": "We study the set of chords of a real-valued continuous function on [0,1] with f(0)=f(1)=0. We describe which chords may appear as isolated points and provide examples illustrating our characterization. Maximal Hopf sets are introduced and analyzed."
  },
  {
    "date": "2026-01-20",
    "title": "Riemannian Liquid Spatio-Temporal Graph Network",
    "authors": "Liangsi Lu, Jingchao Wang, Zhaorong Dai, Hanqian Liu, Yang Shi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14115v1",
    "source": "arXiv",
    "abstract": "Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures. Project Page: https://rlstg.github.io"
  },
  {
    "date": "2026-01-20",
    "title": "Communication Technologies for Intelligent Transportation Systems: From Railways to UAVs and Beyond",
    "authors": "Shrief Rizkalla, Adrian Kliks, Nila Bagheri, Miguel A. Bellido-Manganell, Aniruddha Chandra, Anja Dakic, Laura Finarelli, Davy Gaillot, Matti Hamalainen, Ruisi He, Markus Hofer, Sandaruwan Jayaweera, Francesco Linsalata, Konstantin Mikhaylov, Jon M. Peha, Ibrahim Rashdan, Gianluca Rizzo, Abdul Saboor, Martin Schmidhammer, Michal Sybis, Fredrik Tufvesson, Paul Unterhuber, Fernando J. Velez, Evgenii Vinogradov, Michael Walter, Thomas Zemen, Haibin Zhang, Zhengyu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14106v1",
    "source": "arXiv",
    "abstract": "This white paper aims to comprehensively analyze and consolidate the state of the art in communication technologies supporting modern and future Information and Communication Technology (ICT). Its primary objective is to establish a common understanding of how communication solutions enable automation, safety, and efficiency across multiple transport domains, including railways, road vehicles, aircraft, and unmanned aerial vehicles. The document seeks to identify key communication requirements and technological enablers necessary for interoperable and reliable ITS operation. It also assesses the limitations of current systems and proposes pathways for integrating emerging technologies such as 5G, Sixth Generation (6G), and Artificial Intelligence (AI)-driven network control. The white paper also intends to support harmonization between different transport modes through a unified framework for communication modeling, testing, and standardization. It highlights the importance of accurate channel modeling and empirical validation to design efficient, robust, and scalable systems. Another objective is to explore the use of reconfigurable intelligent surfaces, integrated sensing and communication, and digital twin concepts within ITS. The document emphasizes the role of spectrum management and standardization efforts in ensuring interoperability among diverse communication systems. Finally, the paper seeks to stimulate collaboration among academia, industry, and standardization bodies to advance the design of resilient and adaptive communication infrastructures for future transportation systems."
  },
  {
    "date": "2026-01-20",
    "title": "Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning",
    "authors": "Tairan Huang, Qingqing Ye, Yulin Jin, Jiawei Lian, Yi Wang, Haibo Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14104v1",
    "source": "arXiv",
    "abstract": "Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material."
  },
  {
    "date": "2026-01-20",
    "title": "Measurement of the Z$γ$ production cross section and search for anomalous neutral triple gauge couplings in pp collisions at $\\sqrt{s}$ = 13 TeV",
    "authors": "CMS Collaboration",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14102v1",
    "source": "arXiv",
    "abstract": "A measurement of the fiducial cross section of the associated production of a Z boson and a high-$p_\\mathrm{T}$ photon, where the Z decays to two neutrinos, and a search for anomalous triple gauge couplings are reported. The results are based on data collected by the CMS experiment at the LHC in proton-proton collisions at $\\sqrt{s}$ = 13 TeV during 2016$-$2018, corresponding to an integrated luminosity of 138 fb$^{-1}$. The fiducial Z$γ$ cross section, where a photon with a $p_\\mathrm{T}$ greater than 225 GeV is produced in association with a Z, and the Z decays to a $ν\\barν$ pair (Z($ν\\barν$)$γ$), is measured to be 23.3$^{+1.4}_{-1.3}$ fb, in agreement, within uncertainties, with the standard model prediction. The differential cross section as a function of the photon $p_\\mathrm{T}$ has been measured and compared with standard model predictions computed at next-to-leading and at next-to-next-to-leading order in perturbative quantum chromodynamics. Constraints have been placed on the presence of anomalous couplings that affect the ZZ$γ$ and Z$γγ$ vertex using the $p_\\mathrm{T}$ spectrum of the photons. The observed 95% confidence level intervals for $CP$-conserving $h_3^γ$ and $h_4^γ$ are determined to be ($-$3.4, 3.5) $\\times$ 10$^{-4}$ and ($-$6.8, 6.8) $\\times$ 10$^{-7}$, and for $h_3^\\mathrm{Z}$ and $h_4^\\mathrm{Z}$ they are ($-$2.2, 2.2) $\\times$ 10$^{-4}$ and ($-$4.1, 4.2) $\\times$ 10$^{-7}$, respectively. These are the strictest limits to date on $h_3^γ$, $h_3^\\mathrm{Z}$ and $h_4^\\mathrm{Z}$."
  },
  {
    "date": "2026-01-20",
    "title": "A flexible language model-assisted electronic design automation framework",
    "authors": "Cristian Sestito, Panagiota Kontou, Pratibha Verma, Atish Dixit, Alexandros D. Keros, Michael O'Boyle, Christos-Savvas Bouganis, Themis Prodromakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14098v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are transforming electronic design automation (EDA) by enhancing design stages such as schematic design, simulation, netlist synthesis, and place-and-route. Existing methods primarily focus these optimisations within isolated open-source EDA tools and often lack the flexibility to handle multiple domains, such as analogue, digital, and radio-frequency design. In contrast, modern systems require to interface with commercial EDA environments, adhere to tool-specific operation rules, and incorporate feedback from design outcomes while supporting diverse design flows. We propose a versatile framework that uses LLMs to generate files compatible with commercial EDA tools and optimise designs using power-performance-area reports. This is accomplished by guiding the LLMs with tool constraints and feedback from design outputs to meet tool requirements and user specifications. Case studies on operational transconductance amplifiers, microstrip patch antennas, and FPGA circuits show that the framework is effective as an EDA-aware assistant, handling diverse design challenges reliably."
  },
  {
    "date": "2026-01-20",
    "title": "Simple subquotients of crossed products by abelian groups and twisted group algebras",
    "authors": "Siegfried Echterhoff",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14097v1",
    "source": "arXiv",
    "abstract": "Motivated by work of Poguntke we study the question under what conditions simple subquotients of crossed products $A\\rtimes_αG$ by (twisted) actions of abelian groups $G$ are isomorphic to simple twisted group algebras of abelian groups. As a consequence, we recover a theorem of Poguntke's saying that the simple subquotients of group $C^*$-algebras of connected groups are either stably isomorphic to $\\mathbb C$ or they are stably isomorphic to simple non-commutative tori."
  },
  {
    "date": "2026-01-20",
    "title": "Quantum Pontus-Mpemba Effect Enabled by the Liouvillian Skin Effect",
    "authors": "Stefano Longhi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14083v1",
    "source": "arXiv",
    "abstract": "We unveil a quantum Pontus-Mpemba effect enabled by the Liouvillian skin effect in a dissipative tight-binding chain with asymmetric incoherent hopping and coherent boundary coupling. The skin effect, induced by non-reciprocal dissipation, localizes relaxation modes near the system boundaries and gives rise to non-orthogonal spectral geometry. While such non-normality is often linked to slow relaxation, we show that it can instead accelerate relaxation through a two-step protocol - realizing a quantum Pontus-Mpemba effect. Specifically, we consider a one-dimensional open chain with coherent hopping $J$, asymmetric incoherent hoppings $J_{\\rm R} \\neq J_{\\rm L}$, and a controllable end-to-end coupling $ε$. For $ε=0$, the system exhibits the Liouvillian skin effect, with left and right eigenmodes localized at opposite edges. We compare two relaxation protocols toward the same stationary state: (i) a direct relaxation with $ε=0$, and (ii) a two-step (Pontus) protocol where a brief coherent evolution transfers the excitation across the lattice before relaxation. Although both share the same asymptotic decay rate, the two-step protocol relaxes significantly faster due to its reduced overlap with the slow boundary-localized Liouvillian mode. The effect disappears when $J_{\\rm R}=J_{\\rm L}$, i.e., when the skin effect vanishes. Our results reveal a clear connection between boundary-induced non-normality and protocol-dependent relaxation acceleration, suggesting new routes for controlling dissipation and transient dynamics in open quantum systems."
  },
  {
    "date": "2026-01-20",
    "title": "Background Subtraction with Drift Correction for Bistatic Radar Reflectivity Measurements",
    "authors": "Alexander Ihlow, Marius Schmidt, Carsten Andrich, Reiner S. Thomä",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14080v1",
    "source": "arXiv",
    "abstract": "Fundamental research on bistatic radar reflectivity is highly relevant, e.g., to the upcoming mobile communication standard 6G, which includes integrated sensing and communication (ISAC). We introduce a model for correcting instrumentation drift during bistatic radar measurements in anechoic chambers. Usually, background subtraction is applied with the goal to yield the target reflection signal as best as possible while coherently subtracting all signals which were present in both the foreground and background measurement. However, even slight incoherences between the foreground and background measurement process deteriorate the result. We analyze these effects in real measurements in the frequency range 2-18 GHz, taken with the Bistatic Radar (BIRA) measurement facility at TU Ilmenau. Applying our proposed drift correction model, we demonstrate up to 40 dB improvement for the removal of direct line-of-sight antenna crosstalk over the state of the art."
  },
  {
    "date": "2026-01-20",
    "title": "VENI: Variational Encoder for Natural Illumination",
    "authors": "Paul Walker, James A. D. Gardner, Andreea Ardelean, William A. P. Smith, Bernhard Egger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14079v1",
    "source": "arXiv",
    "abstract": "Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space."
  },
  {
    "date": "2026-01-20",
    "title": "How Disruptive is Financial Technology?",
    "authors": "Douglas Cumming, Hisham Farag, Santosh Koirala, Danny McGowan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14071v1",
    "source": "arXiv",
    "abstract": "We study whether Fintech disrupts the banking sector by intensifying competition for scarce deposits funds and raising deposit rates. Using difference-in-difference estimation around the exogenous removal of marketplace platform investing restrictions by US states, we show the cost of deposits increase by approximately 11.5% within small financial institutions. However, these price changes are effective in preventing a drain of liquidity. Size and geographical diversification through branch networks can mitigate the effects of Fintech competition by sourcing deposits from less competitive markets. The findings highlight the unintended consequences of the growing Fintech sector on banks and offer policy insights for regulators and managers into the ongoing development and impact of technology on the banking sector."
  },
  {
    "date": "2026-01-20",
    "title": "On the optimal shape parameter for kernel methods: Sharp direct and inverse statements",
    "authors": "Tizian Wenzel, Gabriele Santin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14070v1",
    "source": "arXiv",
    "abstract": "The search for the optimal shape parameter for Radial Basis Function (RBF) kernel approximation has been an outstanding research problem for decades. In this work, we establish a theoretical framework for this problem by leveraging a recently established theory on sharp direct, inverse and saturation statements for kernel based approximation. In particular, we link the search for the optimal shape parameter to superconvergence phenomena. Our analysis is carried out for finitely smooth Sobolev kernels, thereby covering large classes of radial kernels used in practice, including those emerging from current machine-learning methodologies. Our results elucidate how approximation regimes, kernel regularity, and parameter choices interact, thereby clarifying a question that has remained unresolved for decades."
  },
  {
    "date": "2026-01-20",
    "title": "Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management",
    "authors": "Nattapong Kurpukdee, Adrian G. Bors",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14069v1",
    "source": "arXiv",
    "abstract": "Unsupervised video class incremental learning (uVCIL) represents an important learning paradigm for learning video information without forgetting, and without considering any data labels. Prior approaches have focused on supervised class-incremental learning, relying on using the knowledge of labels and task boundaries, which is costly, requires human annotation, or is simply not a realistic option. In this paper, we propose a simple yet effective approach to address the uVCIL. We first consider a deep feature extractor network, providing a set of representative video features during each task without assuming any class or task information. We then progressively build a series of deep clusters from the extracted features. During the successive task learning, the model updated from the previous task is used as an initial state in order to transfer knowledge to the current learning task. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, by ignoring the labels from the supervised setting. Our approach significantly outperforms other baselines on all datasets."
  },
  {
    "date": "2026-01-20",
    "title": "Modular Attractor Acceleration in Infinite-State Games (Full Version)",
    "authors": "Philippe Heim, Rayna Dimitrova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14068v1",
    "source": "arXiv",
    "abstract": "Infinite-state games provide a framework for the synthesis of reactive systems with unbounded data domains. Solving such games typically relies on computing symbolic fixpoints, particularly symbolic attractors. However, these computations may not terminate, and while recent acceleration techniques have been proposed to address this issue, they often rely on acceleration arguments of limited expressiveness. In this work, we propose an approach for the modular computation of acceleration arguments. It enables the construction of complex acceleration arguments by composing simpler ones, thereby improving both scalability and flexibility. In addition, we introduce a summarization technique that generalizes discovered acceleration arguments, allowing them to be efficiently reused across multiple contexts. Together, these contributions improve the efficiency of solving infinite-state games in reactive synthesis, as demonstrated by our experimental evaluation."
  },
  {
    "date": "2026-01-20",
    "title": "XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs",
    "authors": "Mohsinul Kabir, Tasnim Ahmed, Md Mezbaur Rahman, Shaoxiong Ji, Hassan Alhuzali, Sophia Ananiadou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14063v1",
    "source": "arXiv",
    "abstract": "Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP."
  },
  {
    "date": "2026-01-20",
    "title": "Demystifying the trend of the healthcare index: Is historical price a key driver?",
    "authors": "Payel Sadhukhan, Samrat Gupta, Subhasis Ghosh, Tanujit Chakraborty",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14062v1",
    "source": "arXiv",
    "abstract": "Healthcare sector indices consolidate the economic health of pharmaceutical, biotechnology, and healthcare service firms. The short-term movements in these indices are closely intertwined with capital allocation decisions affecting research and development investment, drug availability, and long-term health outcomes. This research investigates whether historical open-high-low-close (OHLC) index data contain sufficient information for predicting the directional movement of the opening index on the subsequent trading day. The problem is formulated as a supervised classification task involving a one-step-ahead rolling window. A diverse feature set is constructed, comprising original prices, volatility-based technical indicators, and a novel class of nowcasting features derived from mutual OHLC ratios. The framework is evaluated on data from healthcare indices in the U.S. and Indian markets over a five-year period spanning multiple economic phases, including the COVID-19 pandemic. The results demonstrate robust predictive performance, with accuracy exceeding 0.8 and Matthews correlation coefficients above 0.6. Notably, the proposed nowcasting features have emerged as a key determinant of the market movement. We have employed the Shapley-based explainability paradigm to further elucidate the contribution of the features: outcomes reveal the dominant role of the nowcasting features, followed by a more moderate contribution of original prices. This research offers a societal utility: the proposed features and model for short-term forecasting of healthcare indices can reduce information asymmetry and support a more stable and equitable health economy."
  },
  {
    "date": "2026-01-20",
    "title": "POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion",
    "authors": "Andrea Rigo, Luca Stornaiuolo, Weijie Wang, Mauro Martino, Bruno Lepri, Nicu Sebe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14056v1",
    "source": "arXiv",
    "abstract": "We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts."
  },
  {
    "date": "2026-01-20",
    "title": "Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model",
    "authors": "Haoran Xu, Yanlin Liu, Zizhao Tong, Jiaze Li, Kexue Fu, Yuyang Zhang, Longxiang Gao, Shuaiguang Li, Xingyu Li, Yanran Xu, Changwei Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14052v1",
    "source": "arXiv",
    "abstract": "Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K."
  },
  {
    "date": "2026-01-20",
    "title": "Collective intelligence in science: direct elicitation of diverse information from experts with unknown information structure",
    "authors": "Alexey V. Osipov, Nikolay N. Osipov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14047v1",
    "source": "arXiv",
    "abstract": "Suppose we need a deep collective analysis of an open scientific problem: there is a complex scientific hypothesis and a large online group of mutually unrelated experts with relevant private information of a diverse and unpredictable nature. This information may be results of experts' individual experiments, original reasoning of some of them, results of AI systems they use, etc. We propose a simple mechanism based on a self-resolving play-money prediction market entangled with a chat. We show that such a system can easily be brought to an equilibrium where participants directly share their private information on the hypothesis through the chat and trade as if the market were resolved in accordance with the truth of the hypothesis. This approach will lead to efficient aggregation of relevant information in a completely interpretable form even if the ground truth cannot be established and experts initially know nothing about each other and cannot perform complex Bayesian calculations. Finally, by rewarding the experts with some real assets proportionally to the play money they end up with, we can get an innovative way to fund large-scale collaborative studies of any type."
  },
  {
    "date": "2026-01-20",
    "title": "Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology",
    "authors": "Kaiyu Wu, Pucheng Han, Hualong Zhang, Naigeng Wu, Keze Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14044v1",
    "source": "arXiv",
    "abstract": "While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1."
  },
  {
    "date": "2026-01-20",
    "title": "Federated Balanced Learning",
    "authors": "Jiaze Li, Haoran Xu, Wanyi Wu, Changwei Wang, Shuaiguang Li, Jianzhong Ju, Zhenbo Luo, Jian Luan, Youyang Qu, Longxiang Gao, Xudong Yang, Lumin Xing",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14042v1",
    "source": "arXiv",
    "abstract": "Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance."
  },
  {
    "date": "2026-01-20",
    "title": "PAC-Private Responses with Adversarial Composition",
    "authors": "Xiaochen Zhu, Mayuri Sridhar, Srinivas Devadas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14033v1",
    "source": "arXiv",
    "abstract": "Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs. We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying. Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP."
  },
  {
    "date": "2026-01-20",
    "title": "Intermittent time series forecasting: local vs global models",
    "authors": "Stefano Damato, Nicolò Rubattu, Dario Azzimonti, Giorgio Corani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14031v1",
    "source": "arXiv",
    "abstract": "Intermittent time series, characterised by the presence of a significant amount of zeros, constitute a large percentage of inventory items in supply chain. Probabilistic forecasts are needed to plan the inventory levels; the predictive distribution should cover non-negative values, have a mass in zero and a long upper tail. Intermittent time series are commonly forecast using local models, which are trained individually on each time series. In the last years global models, which are trained on a large collection of time series, have become popular for time series forecasting. Global models are often based on neural networks. However, they have not yet been exhaustively tested on intermittent time series. We carry out the first study comparing state-of-the-art local (iETS, TweedieGP) and global models (D-Linear, DeepAR, Transformers) on intermittent time series. For neural networks models we consider three different distribution heads suitable for intermittent time series: negative binomial, hurdle-shifted negative binomial and Tweedie. We use, for the first time, the last two distribution heads with neural networks. We perform experiments on five large datasets comprising more than 40'000 real-world time series. Among neural networks D-Linear provides best accuracy; it also consistently outperforms the local models. Moreover, it has also low computational requirements. Transformers-based architectures are instead much more computationally demanding and less accurate. Among the distribution heads, the Tweedie provides the best estimates of the highest quantiles, while the negative binomial offers overall the best performance."
  },
  {
    "date": "2026-01-20",
    "title": "Non-linear traces of Choquet type on AF algebras",
    "authors": "Ryota Ninomiya",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14016v1",
    "source": "arXiv",
    "abstract": "We study non-linear traces of Choquet type on AF algebras. Building on the characterization of Choquet traces on matrix algebras due to Nagisa--Watatani, we generalize the construction to arbitrary unital AF algebras. We show that there is a one-to-one correspondence between such traces and increasing functions on the dimension scale, and we obtain explicit Choquet formulas in terms of the spectrum and ranks of spectral projections along a fixed AF filtration."
  },
  {
    "date": "2026-01-20",
    "title": "BallotRank: A Condorcet Completion Method for Graphs",
    "authors": "Ismar Volic, Jason Douglas Todd",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14015v1",
    "source": "arXiv",
    "abstract": "We introduce BallotRank, a ranked preference aggregation method derived from a modified PageRank algorithm. It is a Condorcet-consistent method without damping, and empirical examination of nearly 2,000 ranked choice elections and over 20,000 internet polls confirms that BallotRank always identifies the Condorcet winner at conventional values of the damping parameter. We also prove that the method satisfies many of the same social choice criteria as other well-known Condorcet completion methods, but it has the advantage of being a natural social welfare function that provides a full ranking of the candidates."
  },
  {
    "date": "2026-01-20",
    "title": "MANATEE: A DevOps Platform for xApp Lifecycle Management and Testing in Open RAN",
    "authors": "Sofia Montebugnoli, Leonardo Bonati, Andrea Sabbioni, Luca Foschini, Paolo Bellavista, Salvatore D'Oro, Michele Polese, Tommaso Melodia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14009v1",
    "source": "arXiv",
    "abstract": "The shift to disaggregated 5G architectures introduces unprecedented flexibility but also significant complexity in Beyond 5G Radio Access Networks (RANs). Open RAN enables programmability through xApps, yet deploying and validating these applications is critical given the nature of the systems they aim to control. Current Open RAN ecosystems lack robust lifecycle management of xApps that enable automated testing, seamless migration, and production-grade observability, resulting in slow, error-prone xApp delivery. To address these issues, DevOps practices can streamline the xApp lifecycle by integrating Continuous Integration/Continuous Deployment (CI/CD) pipelines with advanced traffic management and monitoring, such as leveraging service mesh technologies to enable progressive deployment strategies (e.g., canary releases and A/B testing) to ensure fine-grained observability and resilience. The solution presented in this article, MANATEE (Mesh Architecture for Radio Access Network Automation and TEsting Ecosystems), is the first platform that combines these principles to simplify xApp delivery into production, accelerate innovation, and guarantee performance across heterogeneous O-RAN environments. We prototyped MANATEE on a Kubernetes cluster integrated with the O-RAN Software Community Near-Real Time RAN Intelligent Controller (RIC), as well as with service mesh technologies, to facilitate testing of xApps across simulated, emulated, and real testbed environments. Our experimental results demonstrate that service mesh integration introduces minimal overhead (below 1 ms latency), while enabling reliable canary deployments with fine-grained traffic control and conflict-free A/B testing through circuit-breaking mechanisms."
  },
  {
    "date": "2026-01-20",
    "title": "Bounds on Gravitational Wave Production from Unitarity in an Early NEC-Violating Model",
    "authors": "Pavel Petrov, Jianing Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14008v1",
    "source": "arXiv",
    "abstract": "We study a cosmological scenario featuring an early phase of null energy condition (NEC) violation. Within this framework, we show that perturbative unitarity bounds place strong constraints on both the amplitude and the spectral tilt of primordial gravitational waves. Our analysis is largely insensitive to the detailed realization of the transition between the NEC-violating phase and subsequent cosmological phases, allowing our results to be extended to a broader class of models. Finally, the perturbative unitarity approach employed here is applicable to a wide range of cosmological scenarios."
  },
  {
    "date": "2026-01-20",
    "title": "Modeling Zero-Inflated Longitudinal Circular Data Using Bayesian Methods: Application to Ophthalmology",
    "authors": "Prajamitra Bhuyan, Soutik Halder, Jayant Jha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13998v1",
    "source": "arXiv",
    "abstract": "This paper introduces the modeling of circular data with excess zeros under a longitudinal framework, where the response is a circular variable and the covariates can be both linear and circular in nature. In the literature, various circular-circular and circular-linear regression models have been studied and applied to different real-world problems. However, there are no models for addressing zero-inflated circular observations in the context of longitudinal studies. Motivated by a real case study, a mixed-effects two-stage model based on the projected normal distribution is proposed to handle such issues. The interpretation of the model parameters is discussed and identifiability conditions are derived. A Bayesian methodology based on Gibbs sampling technique is developed for estimating the associated model parameters. Simulation results show that the proposed method outperforms its competitors in various situations. A real dataset on post-operative astigmatism is analyzed to demonstrate the practical implementation of the proposed methodology. The use of the proposed method facilitates effective decision-making for treatment choices and in the follow-up phases."
  },
  {
    "date": "2026-01-20",
    "title": "From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning",
    "authors": "Zihan Niu, Wenping Hu, Junmin Chen, Xiyue Wang, Tong Xu, Ruiming Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13995v1",
    "source": "arXiv",
    "abstract": "Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \\textbf{+5.84\\%} using only \\textbf{5\\%} of the data, while our aligned sampling strategy further boosts average performance by \\textbf{+4.24\\%}."
  },
  {
    "date": "2026-01-20",
    "title": "Capacity and Energy Trade-Offs in FR3 6G Networks Using Real Deployment Data",
    "authors": "David López-Pérez, Nicola Piovesan, Matteo Bernabè",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13993v1",
    "source": "arXiv",
    "abstract": "This article presents a data-driven system-level analysis of multi-layer 6G networks operating in the upper mid-band (FR3: 7-24 GHz). Unlike most prior studies based on 3rd Generation Partnership Project (3GPP) templates, we leverage real-world deployment and traffic data from a commercial 4G/5G network in China to evaluate practical 6G strategies. Using Giulia-a deployment-informed system-level heterogeneous network model-we show that 6G can boost median throughput by up to 9.5x over heterogeneous 4G+5G deployments, but also increases power usage by up to 59%. Critically, co-locating 6G with existing sites delivers limited gains while incurring high energy cost. In contrast, non-co-located, traffic-aware deployments achieve superior throughput-to-watt efficiency, highlighting the need for strategic, user equipment (UE) hotspot-focused 6G planning."
  },
  {
    "date": "2026-01-20",
    "title": "A universal linearized subspace refinement framework for neural networks",
    "authors": "Wenbo Cao, Weiwei Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13989v1",
    "source": "arXiv",
    "abstract": "Neural networks are predominantly trained using gradient-based methods, yet in many applications their final predictions remain far from the accuracy attainable within the model's expressive capacity. We introduce Linearized Subspace Refinement (LSR), a general and architecture-agnostic framework that exploits the Jacobian-induced linear residual model at a fixed trained network state. By solving a reduced direct least-squares problem within this subspace, LSR computes a subspace-optimal solution of the linearized residual model, yielding a refined linear predictor with substantially improved accuracy over standard gradient-trained solutions, without modifying network architectures, loss formulations, or training procedures. Across supervised function approximation, data-driven operator learning, and physics-informed operator fine-tuning, we show that gradient-based training often fails to access this attainable accuracy, even when local linearization yields a convex problem. This observation indicates that loss-induced numerical ill-conditioning, rather than nonconvexity or model expressivity, can constitute a dominant practical bottleneck. In contrast, one-shot LSR systematically exposes accuracy levels not fully exploited by gradient-based training, frequently achieving order-of-magnitude error reductions. For operator-constrained problems with composite loss structures, we further introduce Iterative LSR, which alternates one-shot LSR with supervised nonlinear alignment, transforming ill-conditioned residual minimization into numerically benign fitting steps and yielding accelerated convergence and improved accuracy. By bridging nonlinear neural representations with reduced-order linear solvers at fixed linearization points, LSR provides a numerically grounded and broadly applicable refinement framework for supervised learning, operator learning, and scientific computing."
  },
  {
    "date": "2026-01-20",
    "title": "STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames",
    "authors": "Shih-Yao Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13974v1",
    "source": "arXiv",
    "abstract": "Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content. We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality. Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding. We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets."
  },
  {
    "date": "2026-01-20",
    "title": "Grain-Growth Stagnation from Vacancy-Diffusion-Limited Disconnection Climb",
    "authors": "Maik Punke, Abel H. G. Milor, Marco Salvalaglio",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13965v1",
    "source": "arXiv",
    "abstract": "Grain growth in polycrystals typically stagnates at long times. We identify disconnection climb, limited by vacancy diffusion, as a fundamental microscopic mechanism underlying this behavior. Using a phase-field crystal framework extended to model vacancy diffusion, we resolve grain-boundary migration on diffusive time scales and show that disconnection climb rates correlate with the characteristic grain size at which growth arrests. These results link vacancy transport, disconnection dynamics, and microstructural evolution, establishing vacancy diffusion as a key governing factor."
  },
  {
    "date": "2026-01-20",
    "title": "Optimising gravitational-wave sky maps for pulsar timing arrays",
    "authors": "Kathrin Grunthal, David J. Champion, Eric Thrane, Rowina S. Nathan, Michael Kramer, Matthew T. Miles",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13957v1",
    "source": "arXiv",
    "abstract": "Pulsar timing arrays (PTAs) have recently reported compelling evidence for the presence of a gravitational-wave background signal. Mapping the gravitational-wave background is key to understanding how it is formed, since anisotropy is a tracer for, for example, a supermassive black hole binary origin. In this work we refine the frequentist regularised gravitational-wave mapping analysis developed in our previous work (as part of the MeerKAT PTA 4.5-year data release). We derive a point-spread function describing the angular resolution of a PTA. We investigate how the point spread function changes for different PTA constellations and determine the best possible angular resolution achievable within our framework. Using simulated data, we demonstrate that previous methods do not capture the actual resolution - especially in regions of the sky with a high density of pulsars. We propose an improved scheme that accounts for a variable local resolution and test it using realistic simulations of the latest MeerKAT dataset. We demonstrate that we are able to identify a continuous gravitational wave signal in a region with good pulsar sky coverage with approximately a factor of two increase in significance compared to our previous method."
  },
  {
    "date": "2026-01-20",
    "title": "VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content",
    "authors": "Shengyi Wu, Yan Hong, Shengyao Chen, Zheng Wang, Xianbing Sun, Jiahui Zhan, Jun Lan, Jianfu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13951v1",
    "source": "arXiv",
    "abstract": "With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice."
  },
  {
    "date": "2026-01-20",
    "title": "Wold-type decomposition for doubly twisted left-invertible covariant representations",
    "authors": "Niraj Kumar, Azad Rohilla, Harsh Trivedi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13950v1",
    "source": "arXiv",
    "abstract": "We will introduce the notion of a near-isometric covariant representation of a $C^*$-correspondence and prove its Wold-type decomposition. Wold-type decomposition for doubly twisted left-invertible covariant representations of a product system is also obtained."
  },
  {
    "date": "2026-01-20",
    "title": "Stream-Voice-Anon: Enhancing Utility of Real-Time Speaker Anonymization via Neural Audio Codec and Language Models",
    "authors": "Nikita Kuzmin, Songting Liu, Kong Aik Lee, Eng Siong Chng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13948v1",
    "source": "arXiv",
    "abstract": "Protecting speaker identity is crucial for online voice applications, yet streaming speaker anonymization (SA) remains underexplored. Recent research has demonstrated that neural audio codec (NAC) provides superior speaker feature disentanglement and linguistic fidelity. NAC can also be used with causal language models (LM) to enhance linguistic fidelity and prompt control for streaming tasks. However, existing NAC-based online LM systems are designed for voice conversion (VC) rather than anonymization, lacking the techniques required for privacy protection. Building on these advances, we present Stream-Voice-Anon, which adapts modern causal LM-based NAC architectures specifically for streaming SA by integrating anonymization techniques. Our anonymization approach incorporates pseudo-speaker representation sampling, a speaker embedding mixing and diverse prompt selection strategies for LM conditioning that leverage the disentanglement properties of quantized content codes to prevent speaker information leakage. Additionally, we compare dynamic and fixed delay configurations to explore latency-privacy trade-offs in real-time scenarios. Under the VoicePrivacy 2024 Challenge protocol, Stream-Voice-Anon achieves substantial improvements in intelligibility (up to 46% relative WER reduction) and emotion preservation (up to 28% UAR relative) compared to the previous state-of-the-art streaming method DarkStream while maintaining comparable latency (180ms vs 200ms) and privacy protection against lazy-informed attackers, though showing 15% relative degradation against semi-informed attackers."
  },
  {
    "date": "2026-01-20",
    "title": "Topological Criteria for Hypothesis Testing with Finite-Precision Measurements",
    "authors": "Philip Boeken, Eduardo Skapinakis, Konstantin Genin, Joris M. Mooij",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13946v1",
    "source": "arXiv",
    "abstract": "We establish topological necessary and sufficient conditions under which a pair of statistical hypotheses can be consistently distinguished when i.i.d. observations are recorded only to finite precision. Requiring the test's decision regions to be open in the sample-space topology to accommodate finite-precision data, we show that a pair of null- and alternative hypotheses $H_0$ and $H_1$ admits a consistent test if and only if they are $F_σ$ in the weak topology on the space of probability measures $W := H_0\\cup H_1$. Additionally, the hypotheses admit uniform error control under $H_0$ and/or $H_1$ if and only if $H_0$ and/or $H_1$ are closed in $W$. Under compactness assumptions, uniform consistency is characterised by $H_0$ and $H_1$ having disjoint closures in the ambient space of probability measures. These criteria imply that - without regularity assumptions - conditional independence is not consistently testable. We introduce a Lipschitz-continuity assumption on the family of conditional distributions under which we recover testability of conditional independence with uniform error control under the null, with testable smoothness constraints."
  },
  {
    "date": "2026-01-20",
    "title": "RepoGenesis: Benchmarking End-to-End Microservice Generation from Readme to Repository",
    "authors": "Zhiyuan Peng, Xin Yin, Pu Zhao, Fangkai Yang, Lu Wang, Ran Jia, Xu Chen, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13943v1",
    "source": "arXiv",
    "abstract": "Large language models and agents have achieved remarkable progress in code generation. However, existing benchmarks focus on isolated function/class-level generation (e.g., ClassEval) or modifications to existing codebases (e.g., SWE-Bench), neglecting complete microservice repository generation that reflects real-world 0-to-1 development workflows. To bridge this gap, we introduce RepoGenesis, the first multilingual benchmark for repository-level end-to-end web microservice generation, comprising 106 repositories (60 Python, 46 Java) across 18 domains and 11 frameworks, with 1,258 API endpoints and 2,335 test cases verified through a \"review-rebuttal\" quality assurance process. We evaluate open-source agents (e.g., DeepCode) and commercial IDEs (e.g., Cursor) using Pass@1, API Coverage (AC), and Deployment Success Rate (DSR). Results reveal that despite high AC (up to 73.91%) and DSR (up to 100%), the best-performing system achieves only 23.67% Pass@1 on Python and 21.45% on Java, exposing deficiencies in architectural coherence, dependency management, and cross-file consistency. Notably, GenesisAgent-8B, fine-tuned on RepoGenesis (train), achieves performance comparable to GPT-5 mini, demonstrating the quality of RepoGenesis for advancing microservice generation. We release our benchmark at https://github.com/pzy2000/RepoGenesis."
  },
  {
    "date": "2026-01-20",
    "title": "Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning",
    "authors": "Hongbo Bai, Yujin Zhou, Yile Wu, Chi-Min Chan, Pengcheng Wen, Kunhao Pan, Sirui Han, Yike Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13942v1",
    "source": "arXiv",
    "abstract": "Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon."
  },
  {
    "date": "2026-01-20",
    "title": "Proactive Coded Caching Scheme for D2D Networks",
    "authors": "Qiaoling Zhang, Changlu Lin, Minquan Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13929v1",
    "source": "arXiv",
    "abstract": "Coded caching and device-to-device (D2D) communication are two effective techniques for alleviating network traffic. Secure transmission and file privacy have also become critical concerns in these domains. However, prevailing coded caching schemes typically assume that a user's cached content is inaccessible to others, overlooking the risk of file privacy leakage due to attacks targeting the cache itself. In this paper, we propose a secure coded caching scheme for D2D networks that guarantees both file privacy and secure delivery. We demonstrate that the proposed scheme achieves order-optimal performance when the file size is sufficiently large and the cache memory is ample."
  },
  {
    "date": "2026-01-20",
    "title": "Alternative $ν+ν$-picture of bosonic fractional Chern insulators at high filling factors in multiple flat-band systems",
    "authors": "Licheng Wang, Dong-Hao Guan, Ai-Lei He, Shun-Li Yu, Yuan Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13928v1",
    "source": "arXiv",
    "abstract": "Most fractional quantum Hall states have been traditionally identified within a single energy band, such as the lowest Landau level or topological flat band. As more particles are introduced, they inevitably populate higher energy bands. Whether the inclusion of multiple topological bands leads to new physics remains an open question. Here, we propose a universal picture applicable at higher filling factors $ν\\geq 1$ in bosonic systems: the occupied bands tend to coalesce into an effective single topological band characterized by a total Chern number $\\vert C\\vert$, the sum of the Chern number of all occupied lower topological flat bands. Using a Kekulé lattice model with two lower flat bands featuring a total Chern number $C=1$, regardless of their specific configurations, we identify the emergence of a $\\frac{1}{2}$ fractional Chern insulator (FCI) state at integer filling factor $ν=1$, followed by the Jain sequence states $\\frac{2}{3}$ and $\\frac{3}{4}$ at filling $ν=\\frac{4}{3}$ and $\\frac{6}{4}$. That is a $ν+ν$ picture, rather than the generally expected $1+ν^{\\prime}$ picture, where $ν^{\\prime}$ is the permitted FCI filling factor in the single second topological flat band. Our findings deepen the understanding of FCI states and open avenues for discovering exotic fractional topological phases in multiband systems."
  },
  {
    "date": "2026-01-20",
    "title": "Towards Modality-Agnostic Continual Domain-Incremental Brain Lesion Segmentation",
    "authors": "Yousef Sadegheih, Dorit Merhof, Pratibha Kumari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13927v1",
    "source": "arXiv",
    "abstract": "Brain lesion segmentation from multi-modal MRI often assumes fixed modality sets or predefined pathologies, making existing models difficult to adapt across cohorts and imaging protocols. Continual learning (CL) offers a natural solution but current approaches either impose a maximum modality configuration or suffer from severe forgetting in buffer-free settings. We introduce CLMU-Net, a replay-based CL framework for 3D brain lesion segmentation that supports arbitrary and variable modality combinations without requiring prior knowledge of the maximum set. A conceptually simple yet effective channel-inflation strategy maps any modality subset into a unified multi-channel representation, enabling a single model to operate across diverse datasets. To enrich inherently local 3D patch features, we incorporate lightweight domain-conditioned textual embeddings that provide global modality-disease context for each training case. Forgetting is further reduced through principled replay using a compact buffer composed of both prototypical and challenging samples. Experiments on five heterogeneous MRI brain datasets demonstrate that CLMU-Net consistently outperforms popular CL baselines. Notably, our method yields an average Dice score improvement of $\\geq$ 18\\% while remaining robust under heterogeneous-modality conditions. These findings underscore the value of flexible modality handling, targeted replay, and global contextual cues for continual medical image segmentation. Our implementation is available at https://github.com/xmindflow/CLMU-Net."
  },
  {
    "date": "2026-01-20",
    "title": "SCG With Your Phone: Diagnosis of Rhythmic Spectrum Disorders in Field Conditions",
    "authors": "Peter Golenderov, Yaroslav Matushenko, Anastasia Tushina, Michal Barodkin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13926v1",
    "source": "arXiv",
    "abstract": "Aortic valve opening (AO) events are crucial for detecting frequency and rhythm disorders, especially in real-world settings where seismocardiography (SCG) signals collected via consumer smartphones are subject to noise, motion artifacts, and variability caused by device heterogeneity. In this work, we present a robust deep-learning framework for SCG segmentation and rhythm analysis using accelerometer recordings obtained with consumer smartphones. We develop an enhanced U-Net v3 architecture that integrates multi-scale convolutions, residual connections, and attention gates, enabling reliable segmentation of noisy SCG signals. A dedicated post-processing pipeline converts probability masks into precise AO timestamps, whereas a novel adaptive 3D-to-1D projection method ensures robustness to arbitrary smartphone orientation. Experimental results demonstrate that the proposed method achieves consistently high accuracy and robustness across various device types and unsupervised data-collection conditions. Our approach enables practical, low-cost, and automated cardiac-rhythm monitoring using everyday mobile devices, paving the way for scalable, field-deployable cardiovascular assessment and future multimodal diagnostic systems."
  },
  {
    "date": "2026-01-20",
    "title": "A finiteness result on representations of Nori's fundamental group scheme",
    "authors": "Xiaodong Yi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13917v1",
    "source": "arXiv",
    "abstract": "Let $(X,x)$ be a pointed geometrically connected smooth projective variety over a sub-$p$-adic field $K$. For any given rank $n$, we prove that there are only finitely many isomorphism classes of representations $π_{1}^{EF}(X,x)\\rightarrow \\mathrm{GL}_{n}$, where $π_{1}^{EF}(X,x)$ is Nori's fundamental group of essentially finite bundles. Equivalently, there are only finitely many isomorphism classes of essentially finite bundles of rank $n$. This answers a question from C.Gasbarri."
  },
  {
    "date": "2026-01-20",
    "title": "Wiener Algebras Methods for Liouville Theorems on the Stationary Navier-Stokes System",
    "authors": "Nicolas Lerner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13916v1",
    "source": "arXiv",
    "abstract": "We prove some Liouville theorems for the stationary Navier-Stokes system for incompressible fluids. We provide some sufficient conditions on the low frequency part of the solution, using some properties of classical singular integrals with respect to Wiener algebras."
  },
  {
    "date": "2026-01-20",
    "title": "On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation",
    "authors": "Pavlo Melnyk, Cuong Le, Urs Waldmann, Per-Erik Forssén, Bastian Wandt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13913v1",
    "source": "arXiv",
    "abstract": "Estimating 3D from 2D is one of the central tasks in computer vision. In this work, we consider the monocular setting, i.e. single-view input, for 3D human pose estimation (HPE). Here, the task is to predict a 3D point set of human skeletal joints from a single 2D input image. While by definition this is an ill-posed problem, recent work has presented methods that solve it with up to several-centimetre error. Typically, these methods employ a two-step approach, where the first step is to detect the 2D skeletal joints in the input image, followed by the step of 2D-to-3D lifting. We find that common lifting models fail when encountering a rotated input. We argue that learning a single human pose along with its in-plane rotations is considerably easier and more geometrically grounded than directly learning a point-to-point mapping. Furthermore, our intuition is that endowing the model with the notion of rotation equivariance without explicitly constraining its parameter space should lead to a more straightforward learning process than one with equivariance by design. Utilising the common HPE benchmarks, we confirm that the 2D rotation equivariance per se improves the model performance on human poses akin to rotations in the image plane, and can be efficiently and straightforwardly learned by augmentation, outperforming state-of-the-art equivariant-by-design methods."
  },
  {
    "date": "2026-01-20",
    "title": "Frequency shift and viewing direction variations in gravitational lensing",
    "authors": "Mikołaj Korzyński, Mateusz Kulejewski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13912v1",
    "source": "arXiv",
    "abstract": "In a gravitational lensing system, the relative transverse velocities of the lens, source, and observer induce a frequency shift in the observed radiation. While this shift is typically negligible in most astrophysical contexts, strategies for its detection have been proposed for both electromagnetic and gravitational waves. This paper provides a rigorous theoretical treatment of the effect, deriving general expressions for the frequency shift within a lensing system embedded in a cosmological spacetime. Our formulation remains valid for arbitrary distances and velocities - including highly relativistic regimes - under any Friedmann-Lemaître-Robertson-Walker metric. Expanding upon previous papers on moving lenses, we provide a detailed analysis of frequency effects induced by lenses moving at relativistic speeds. Furthermore, we extend standard lensing theory by deriving an exact formula for the variation in the source's viewing direction. This result is of interest for strongly anisotropic emitters, such as compact binary systems emitting gravitational waves. Finally, we quantify the apparent misalignment between the lens and the source's two images produced by time-delay effects in lens systems moving with high velocity."
  },
  {
    "date": "2026-01-20",
    "title": "Synthetic Singers: A Review of Deep-Learning-based Singing Voice Synthesis Approaches",
    "authors": "Changhao Pan, Dongyu Yao, Yu Zhang, Wenxiang Guo, Jingyu Lu, Zhiyuan Zhu, Zhou Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13910v1",
    "source": "arXiv",
    "abstract": "Recent advances in singing voice synthesis (SVS) have attracted substantial attention from both academia and industry. With the advent of large language models and novel generative paradigms, producing controllable, high-fidelity singing voices has become an attainable goal. Yet the field still lacks a comprehensive survey that systematically analyzes deep-learning-based singing voice synthesis systems and their enabling technologies. To address the aforementioned issue, this survey first categorizes existing systems by task type and then organizes current architectures into two major paradigms: cascaded and end-to-end approaches. Moreover, we provide an in-depth analysis of core technologies, covering singing modeling and control techniques. Finally, we review relevant datasets, annotation tools, and evaluation benchmarks that support training and assessment. In appendix, we introduce training strategies and further discussion of SVS. This survey provides an up-to-date review of the literature on SVS models, which would be a useful reference for both researchers and engineers. Related materials are available at https://github.com/David-Pigeon/SyntheticSingers."
  },
  {
    "date": "2026-01-20",
    "title": "Improving the local solution of the DG predictor of the ADER-DG method for solving systems of ordinary differential equations and its applicability to systems of differential-algebraic equations",
    "authors": "I. S. Popov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13908v1",
    "source": "arXiv",
    "abstract": "Improved local numerical solution for the ADER-DG numerical method with a local DG predictor for solving the initial value problem for a first-order ODE system is proposed. The improved local numerical solution demonstrates convergence orders of one higher than the convergence order of the local numerical solution of the original ADER-DG numerical method and has the property of continuity at grid nodes. Rigorous proofs of the approximation orders of the local numerical solution and the improved local numerical solution are presented. Obtaining the proposed improved local numerical solution does not require significant changes to the structure of the ADER-DG numerical method. Therefore, all conclusions regarding the convergence orders of the numerical solution at grid nodes, the resulting superconvergence, and the high stability of the ADER-DG numerical method remain unchanged. A wide range of applications of the ADER-DG numerical method is presented for solving specific initial value problems for ODE systems for a wide range of polynomial degrees. The obtained results provide strong confirmation for the developed rigorous theory. The improved local numerical solution is shown to exhibit both higher accuracy and improved smoothness and point-wise comparability. Empirical convergence orders of all individual numerical solutions were calculated for a wide range of error norms, which well agree with the expected convergence orders. The rigorous proof, based on the $ε$-embedding method, of the applicability of the ADER-DG numerical method with a local DG predictor to solving DAE systems is presents."
  },
  {
    "date": "2026-01-20",
    "title": "PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation",
    "authors": "Jaeyoung Moon, Youjin Choi, Yucheon Park, David Melhart, Georgios N. Yannakakis, Kyung-Joong Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13904v1",
    "source": "arXiv",
    "abstract": "Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality."
  },
  {
    "date": "2026-01-20",
    "title": "Determinants of Self-Interstitial Energetics in Refractory High-Entropy Alloys",
    "authors": "Zichen Zhang, Zhiling Luo, Wang Gao, Qing Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13902v1",
    "source": "arXiv",
    "abstract": "Self-interstitials play a central role in governing the mechanical and anti-irradiation properties of refractory high-entropy alloys (RHEAs), however, the prediction of interstitial formation energies (Ef) is formidable due to the chemically complex environments in RHEAs. Herein, we develop a framework based on the tight-binding model to quantify the effects of complex alloying and lattice distortion on Ef. Our scheme reveals that Ef is jointly determined by the average d-band center of RHEAs and the d-band width of interstitial sites. Notably, the d-band width mainly depends on the interatomic hopping matrix and atomic size-determined coordination number, which together make the metallic bonding around interstitials in RHEAs resemble the distance-dependence law of van der Waals forces. By capturing d-band coupling character, our descriptor describes both interstitial configurations within a universal framework. Our model reveals a new physical picture of interstitial formation, providing a useful tool for the design of high-performance RHEAs."
  },
  {
    "date": "2026-01-20",
    "title": "TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography",
    "authors": "Ankita Joshi, Ashutosh Sharma, Anoushkrit Goel, Ranjeet Ranjan Jha, Chirag Ahuja, Arnav Bhavsar, Aditya Nigam",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13897v1",
    "source": "arXiv",
    "abstract": "Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, we propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability."
  },
  {
    "date": "2026-01-20",
    "title": "Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems",
    "authors": "Hong Su",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13887v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments."
  },
  {
    "date": "2026-01-20",
    "title": "LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health",
    "authors": "Ye Tian, Zihao Wang, Onat Gungor, Xiaoran Fan, Tajana Rosing",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13880v1",
    "source": "arXiv",
    "abstract": "Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B."
  },
  {
    "date": "2026-01-20",
    "title": "Chain-of-Thought Compression Should Not Be Blind: V-Skip for Efficient Multimodal Reasoning via Dual-Path Anchoring",
    "authors": "Dongxu Zhang, Yiding Sun, Cheng Tan, Wenbiao Yan, Ning Yang, Jihua Zhu, Hiajun Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13879v1",
    "source": "arXiv",
    "abstract": "While Chain-of-Thought (CoT) reasoning significantly enhances the performance of Multimodal Large Language Models (MLLMs), its autoregressive nature incurs prohibitive latency constraints. Current efforts to mitigate this via token compression often fail by blindly applying text-centric metrics to multimodal contexts. We identify a critical failure mode termed Visual Amnesia, where linguistically redundant tokens are erroneously pruned, leading to hallucinations. To address this, we introduce V-Skip that reformulates token pruning as a Visual-Anchored Information Bottleneck (VA-IB) optimization problem. V-Skip employs a dual-path gating mechanism that weighs token importance through both linguistic surprisal and cross-modal attention flow, effectively rescuing visually salient anchors. Extensive experiments on Qwen2-VL and Llama-3.2 families demonstrate that V-Skip achieves a $2.9\\times$ speedup with negligible accuracy loss. Specifically, it preserves fine-grained visual details, outperforming other baselines over 30\\% on the DocVQA."
  },
  {
    "date": "2026-01-20",
    "title": "Understanding Human-Multi-Agent Team Formation for Creative Work",
    "authors": "Hyunseung Lim, Dasom Choi, Sooyohn Nam, Bogoan Kim, Hwajung Hong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13865v1",
    "source": "arXiv",
    "abstract": "Team-based collaboration is a cornerstone of modern creative work. Recent advances in generative AI open possibilities for humans to collaborate with multiple AI agents in distinct roles to address complex creative workflows. Yet, how to form Human-Multi-Agent Teams (HMATs) is underexplored, especially given that inter-agent interactions increase complexity and the risk of unexpected behaviors. In this exploratory study, we aim to understand how to form HMATs for creative work using CrafTeam, a technology probe that allows users to form and collaborate with their teams. We conducted a study with 12 design practitioners, in which participants iterated through a three-step cycle: forming HMATs, ideating with their teams, and reflecting on their teams' ideation. Our findings reveal that while participants initially attempted autonomous team operations, they ultimately adopted team formations in which they directly orchestrated agents. We discuss design considerations for HMAT formation that humans can effectively orchestrate multiple agents."
  },
  {
    "date": "2026-01-20",
    "title": "Robust Reversible Watermarking in Encrypted Images Based on Dual-MSBs Spiral Embedding",
    "authors": "Haoyu Shen, Wen Yin, Zhaoxia Yin, Wan-Li Lyu, Xinpeng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13840v1",
    "source": "arXiv",
    "abstract": "Robust reversible watermarking in encrypted images (RRWEI) faces an inherent challenge in simultaneously achieving robustness, reversibility, and content privacy under severely constrained embedding capacity. Existing RRWEI schemes often exhibit limited robustness against noise, lossy compression, and cropping attacks due to insufficient redundancy in the encrypted domain. To address this challenge, this paper proposes a novel RRWEI framework that couples dual most significant bit-plane (dual-MSBs) embedding with spatial redundancy and error-correcting coding. By compressing prediction-error bit-planes, sufficient embedding space and auxiliary information for lossless reconstruction are reserved. The dual-MSBs are further reorganized using a spiral embedding strategy to distribute multiple redundant watermark copies across spatially dispersed regions, enhancing robustness against both noise and spatial loss.Experimental results on standard test images demonstrate that the proposed method consistently outperforms under evaluated settings robustness against Gaussian noise, JPEG compression, and diverse cropping attacks, while maintaining perfect reversibility and high embedding capacity. Compared with state-of-the-art RRWEI schemes, the proposed framework achieves substantially lower bit-error rates and more stable performance under a wide range of attack scenarios."
  },
  {
    "date": "2026-01-20",
    "title": "The Dead Cone Effect in Heavy-Quark Jets: A Unified Study from Charm and Bottom to Top",
    "authors": "Redamy Perez-Ramos, Stefan Kluth, Wolfgang Ochs",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13831v1",
    "source": "arXiv",
    "abstract": "We present a unified overview of recent progress in the study of QCD radiation in heavy-quark jets, focusing on the dead-cone effect. Using precision data from LEP at $\\sqrt{s}=91.2$~GeV, we demonstrate strong momentum-space suppression in charm and bottom quark jets, supported by Monte Carlo simulations with \\textsc{Pythia}8, and provide a quantitative interpretation within the Modified Leading Logarithmic Approximation (MLLA) of perturbative QCD. We then extend the analysis to top-quark jets at $\\sqrt{s}=1$~TeV, where finite lifetime effects and decay radiation introduce new conceptual challenges. A new method is presented to isolate the top-quark dead cone by separating production and decay radiation, and it is validated at both parton and hadron level using \\textsc{Pythia}8. Together, these results establish a coherent framework for testing QCD radiation dynamics across all three heavy quarks."
  },
  {
    "date": "2026-01-20",
    "title": "MirageNet:A Secure, Efficient, and Scalable On-Device Model Protection in Heterogeneous TEE and GPU System",
    "authors": "Huadi Zheng, Li Cheng, Yan Ding",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13826v1",
    "source": "arXiv",
    "abstract": "As edge devices gain stronger computing power, deploying high-performance DNN models on untrusted hardware has become a practical approach to cut inference latency and protect user data privacy. Given high model training costs and user experience requirements, balancing model privacy and low runtime overhead is critical. TEEs offer a viable defense, and prior work has proposed heterogeneous GPU-TEE inference frameworks via parameter obfuscation to balance efficiency and confidentiality. However, recent studies find partial obfuscation defenses ineffective, while robust schemes cause unacceptable latency. To resolve these issues, we propose ConvShatter, a novel obfuscation scheme that achieves low latency and high accuracy while preserving model confidentiality and integrity. It leverages convolution linearity to decompose kernels into critical and common ones, inject confounding decoys, and permute channel/kernel orders. Pre-deployment, it performs kernel decomposition, decoy injection and order obfuscation, storing minimal recovery parameters securely in the TEE. During inference, the TEE reconstructs outputs of obfuscated convolutional layers. Extensive experiments show ConvShatter substantially reduces latency overhead with strong security guarantees; versus comparable schemes, it cuts overhead by 16% relative to GroupCover while maintaining accuracy on par with the original model."
  },
  {
    "date": "2026-01-20",
    "title": "Comparative study of quartet superfluid state: Quartet Bardeen-Cooper-Schrieffer theory and generalized Nambu-Gor'kov formalism",
    "authors": "Yixin Guo, Hiroyuki Tajima, Haozhao Liang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13825v1",
    "source": "arXiv",
    "abstract": "We theoretically investigate a quartet superfluid state in fermionic matter by using the quartet Bardeen-Cooper-Schrieffer (BCS) variational theory and the Green's function method. We demonstrate that the quartet BCS theory with the multiple-infinite-product ansatz successfully reproduces an exact four-body result in a one-dimensional four-component Fermi gas at the dilute limit, in contrast to the single-infinite-product ansatz. To see the validity of the quartet BCS state, we derive the self-consistent equation for the quartet superfluid order parameter within the generalized imaginary-time Nambu-Gor'kov formalism, which is found to be consistent with the quartet BCS variational equation. Moreover, by numerically computing the momentum-resolved single-particle spectral function in a one-dimensional system, we discuss how the single-particle spectra evolve with increasing the strength of the four-body cluster formation. We show that a coherent BCS-like quasiparticle branch on the weak-coupling side evolves into a strongly damped, continuum-dominated spectrum in the strong-coupling side, while nonzero quartet superfluid order parameter persists throughout the crossover regime. Our results would be useful for understanding beyond-BCS pairing effects and four-body cluster formations in fermionic systems in an interdisciplinary way."
  },
  {
    "date": "2026-01-20",
    "title": "Multi-Trace Müller Boundary Integral Equation for Electromagnetic Scattering by Composite Objects",
    "authors": "Van Chien Le, Kristof Cools",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13823v1",
    "source": "arXiv",
    "abstract": "This paper introduces a boundary integral equation for time-harmonic electromagnetic scattering by composite dielectric objects. The formulation extends the classical Müller equation to composite structures through the global multi-trace method. The key ingredient enabling this extension is the use of the Stratton-Chu representation in complementary region, also known as the extinction property, which augments the off-diagonal blocks of the interior representation operator. The resulting block system is composed entirely of second-kind operators. A Petrov-Galerkin (mixed) discretization using Rao-Wilton-Glisson trial functions and Buffa-Christiansen test functions is employed, yielding linear systems that remain well conditioned on dense meshes and at low frequencies without the need for additional stabilization. This reduces computational costs associated with matrix-vector multiplications and iterative solving. Numerical experiments demonstrate the accuracy of the method in computing field traces and derived quantities."
  },
  {
    "date": "2026-01-20",
    "title": "Carrier-Envelope-Offset Frequency Stabilization of a High Peak and Average Power Thin-Disk Oscillator",
    "authors": "Yasmin Kopp, Gregor Hehl, Johann Gabriel Meyer, Simon Goncharov, Oleg Pronin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13821v1",
    "source": "arXiv",
    "abstract": "In this work, we demonstrate carrier-envelope-offset (CEO) frequency stabilization of a Kerr-lens mode-locked thin-disk oscillator delivering 180 W average power, 80 MW output peak power, and >500 MW intra-cavity peak power, the highest peak power achieved in any stabilized thin-disk oscillator system. The CEO frequency detection is performed with an f-2f interferometer based on supercontinuum generation in a YAG crystal. Intra-cavity loss modulation using an acousto-optic modulator, that simultaneously provides the Kerr lens, yields 50 mrad of residual phase noise with a 250 kHz control bandwidth. After pulse compression to 0.9 GW peak power in a dual-stage multipass cell, the system directly enables high harmonic generation in noble gases. These results represent a significant step in realizing a compact and robust high-repetition-rate driver system suitable for vacuum ultraviolet and extreme ultraviolet frequency comb generation."
  },
  {
    "date": "2026-01-20",
    "title": "Device Association and Resource Allocation for Hierarchical Split Federated Learning in Space-Air-Ground Integrated Network",
    "authors": "Haitao Zhao, Xiaoyu Tang, Bo Xu, Jinlong Sun, Linghao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13817v1",
    "source": "arXiv",
    "abstract": "6G facilitates deployment of Federated Learning (FL) in the Space-Air-Ground Integrated Network (SAGIN), yet FL confronts challenges such as resource constrained and unbalanced data distribution. To address these issues, this paper proposes a Hierarchical Split Federated Learning (HSFL) framework and derives its upper bound of loss function. To minimize the weighted sum of training loss and latency, we formulate a joint optimization problem that integrates device association, model split layer selection, and resource allocation. We decompose the original problem into several subproblems, where an iterative optimization algorithm for device association and resource allocation based on brute-force split point search is proposed. Simulation results demonstrate that the proposed algorithm can effectively balance training efficiency and model accuracy for FL in SAGIN."
  },
  {
    "date": "2026-01-20",
    "title": "Discriminant Learning-based Colorspace for Blade Segmentation",
    "authors": "Raül Pérez-Gonzalo, Andreas Espersen, Antonio Agudo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13816v1",
    "source": "arXiv",
    "abstract": "Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation."
  },
  {
    "date": "2026-01-20",
    "title": "From RTL to Prompt Coding: Empowering the Next Generation of Chip Designers through LLMs",
    "authors": "Lukas Krupp, Matthew Venn, Norbert Wehn",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13815v1",
    "source": "arXiv",
    "abstract": "This paper presents an LLM-based learning platform for chip design education, aiming to make chip design accessible to beginners without overwhelming them with technical complexity. It represents the first educational platform that assists learners holistically across both frontend and backend design. The proposed approach integrates an LLM-based chat agent into a browser-based workflow built upon the Tiny Tapeout ecosystem. The workflow guides users from an initial design idea through RTL code generation to a tapeout-ready chip. To evaluate the concept, a case study was conducted with 18 high-school students. Within a 90-minute session they developed eight functional VGA chip designs in a 130 nm technology. Despite having no prior experience in chip design, all groups successfully implemented tapeout-ready projects. The results demonstrate the feasibility and educational impact of LLM-assisted chip design, highlighting its potential to attract and inspire early learners and significantly broaden the target audience for the field."
  },
  {
    "date": "2026-01-20",
    "title": "Influence of Ru content on electrocatalytic activity and defect formation of Au-Pd-Pt-Ru compositionally complex solid solution thin films",
    "authors": "Miran Joo, Huixin Xiu, Sabrina Baha, Ridha Zerdoumi, Ningyan Cheng, Christoph Somsen, Yujiao Li, Aleksander Kostka, Wolfgang Schuhmann, Alfred Ludwig, Christina Scheu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13803v1",
    "source": "arXiv",
    "abstract": "Compositionally complex solid solutions (CCSSs) consist of a randomly mixed single phase with the potential to enhance electrocatalytic activity through their polyelemental surface atom arrangements. However, microstructural complexity originating from multiple principal elements influences local structure, chemistry, and lattice strain, which might also affect electrocatalytic activity. Here, we investigate the effect of Ru content on electrochemistry and defect formation in Au-Pd-Pt-Ru CCSS thin films. Such defects could provide active sites when terminating at the CCSS surface or modify surface composition through preferential segregation. A thin-film material library covering a wide composition range was fabricated by room-temperature combinatorial co-sputtering. High-throughput compositional, structural and functional characterization, including electron microscopy equipped with energy dispersive X-ray spectroscopy, X-ray diffraction, and electrochemical screening, were used to correlate composition and microstructural features with catalytic activity. Three representative compositions selected from the library - Au68Pd13Pt15Ru4, Au27Pd24Pt23Ru26, and Au9Pd21Pt18Ru52 - were examined in detail. The three samples exhibit face-centered cubic structures, with lattice contraction occurring with increasing Ru content. In addition, with increasing Ru content, a transition from a high density of nanotwins to high-density, atomic-layer stacking faults was observed. Moreover, the hydrogen evolution reaction activity improves with higher Ru content. Atom probe tomography reveals local compositional fluctuations, including element-specific enrichment and depletion at grain boundaries. The findings provide a new insight into surface atom arrangement design in the CCSS electrocatalysts with enhanced performance."
  },
  {
    "date": "2026-01-20",
    "title": "Asymptotic Properties of Filtrations of Ideals",
    "authors": "Mehrdad Nasernejad, Jonathan Toledo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13794v1",
    "source": "arXiv",
    "abstract": "We introduce a unified framework for studying persistence phenomena in commutative algebra via filtrations of ideals. For a filtration $\\mathcal{F} = \\{I_i\\}_{i \\in \\mathbb{N}}$, we define $\\mathcal{F}$-persistence and $\\mathcal{F}$-strong persistence, extending the classical notions for ordinary and symbolic powers of ideals. We show that if $\\mathcal{F}$ is strongly persistent, then $\\mathcal{F}_{\\mathrm{sym}}$ is strongly persistent, where $\\mathcal{F}_{\\mathrm{sym}}$ denotes the symbolic filtration associated with the filtration $\\mathcal{F}$. In addition, we prove that if $\\mathcal{F}$ is strongly persistent, then $\\mathcal{F}$ is persistent."
  },
  {
    "date": "2026-01-20",
    "title": "PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles",
    "authors": "ByeoungDo Kim, JunYeop Na, Kyungwook Tak, JunTae Kim, DongHyeon Kim, Duckky Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13793v1",
    "source": "arXiv",
    "abstract": "In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner."
  },
  {
    "date": "2026-01-20",
    "title": "Still Accelerating: Type Ia supernova cosmology is robust to host galaxy age evolution",
    "authors": "Phil Wiseman, Brodie Popovic, Mark Sullivan, Adam G. Riess, Dan Scolnic, Rebecca C. Chen, Tamara M. Davis, Lluís Galbany, Isobel M. Hook, Saurabh W. Jha, Lisa Kelsey, Yukei S. Murakami, Mickaël Rigault, Benjamin M. Rose, Brian Schmidt, Mat Smith, Maria Vincenzi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13785v1",
    "source": "arXiv",
    "abstract": "Type Ia supernovae are a cornerstone of modern cosmology, providing first evidence for cosmic acceleration and new tests of dark energy. Son et al. 2025 (S25) claim a strong redshift evolution in standardized supernova luminosities driven by supernova progenitor age, with dramatic cosmological implications: rapidly evolving dark energy, decelerating expansion, and a $9σ$ tension with $Λ$CDM. We show that the underpinning evidence required for this conclusion -- the supernova progenitor-age dependence, the redshift-dependent age difference, and their combined impact -- is either negligible or relies on effects already corrected for in modern supernova analyses. First, the S25 analysis omits the standard host-galaxy stellar mass correction that captures known environmental dependencies that also correlate with stellar age. Applying this correction to the S25 sample, we find no dependence of standardized supernova brightness on host age. Independent data also show no significant difference at low-redshift in standardized brightness between star-forming galaxies and several Gyr older quiescent galaxies of the same stellar mass. Second, the S25 scenario predicts strong redshift evolution of the host-mass effect. Data from the Dark Energy Survey supernova survey measure evolution of $-0.028 \\pm 0.034~\\mathrm{mag}\\,z^{-1}$, consistent with zero and altering the dark-energy equation-of-state measurement ($w$) by $<$0.01 if included. Third, we demonstrate that the claimed $\\sim5$~Gyr progenitor age difference between nearby and distant supernovae is overstated by factors of three to five largely due to a conflation of host galaxy age with supernova progenitor age. We conclude that type~Ia supernova cosmology remains robust for current measurements of dark energy."
  },
  {
    "date": "2026-01-20",
    "title": "Soliton dynamics in the ABS nonlinear spinor model with external fields",
    "authors": "Franz G. Mertens, Bernardo Sánchez-Rey, Niurka R. Quintero",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13783v1",
    "source": "arXiv",
    "abstract": "We consider the novel nonlinear model in (1 + 1)-dimensions for Dirac spinors recently introduced by Alexeeva, Barashenkov, and Saxena [1] (ABS model), which admits an exact explicit solitary-wave (soliton for short) solution. The charge, the momentum, and the energy of this solution are conserved. We investigate the dynamics of the soliton subjected to several potentials: a ramp, a harmonic, and a periodic potential. We develop a Collective Coordinates Theory by making an ansatz for a moving soliton where the position, rapidity, and momentum, are functions of time. We insert the ansatz into the Lagrangian density of the model, integrate over space and obtain a Lagrangian as a function of the collective coordinates. This Lagrangian differs only in the charge and mass with the Lagrangian of a collective coordinates theory for the Gross-Neveu equation. Thus the soliton dynamics in the ABS spinor model is qualitatively the same as in the Gross-Neveu equation, but quantitatively it differs. These results of the collective coordinates theory are confirmed by simulations, i.e., by numerical solutions for solitons of the ABS spinor model, subjected to the above potentials."
  },
  {
    "date": "2026-01-20",
    "title": "Sample Efficient Learning of Body-Environment Interaction of an Under-Actuated System",
    "authors": "Zvi Chapnik, Yizhar Or, Shai Revzen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13777v1",
    "source": "arXiv",
    "abstract": "Geometric mechanics provides valuable insights into how biological and robotic systems use changes in shape to move by mechanically interacting with their environment. In high-friction environments it provides that the entire interaction is captured by the ``motility map''. Here we compare methods for learning the motility map from motion tracking data of a physical robot created specifically to test these methods by having under-actuated degrees of freedom and a hard to model interaction with its substrate. We compared four modeling approaches in terms of their ability to predict body velocity from shape change within the same gait, across gaits, and across speeds. Our results show a trade-off between simpler methods which are superior on small training datasets, and more sophisticated methods, which are superior when more training data is available."
  },
  {
    "date": "2026-01-20",
    "title": "Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks",
    "authors": "Thibaut Boissin, Franck Mamalet, Valentin Lafargue, Mathieu Serrurier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13776v1",
    "source": "arXiv",
    "abstract": "Orthogonal and 1-Lipschitz neural network layers are essential building blocks in robust deep learning architectures, crucial for certified adversarial robustness, stable generative models, and reliable recurrent networks. Despite significant advancements, existing implementations remain fragmented, limited, and computationally demanding. To address these issues, we introduce Orthogonium , a unified, efficient, and comprehensive PyTorch library providing orthogonal and 1-Lipschitz layers. Orthogonium provides access to standard convolution features-including support for strides, dilation, grouping, and transposed-while maintaining strict mathematical guarantees. Its optimized implementations reduce overhead on large scale benchmarks such as ImageNet. Moreover, rigorous testing within the library has uncovered critical errors in existing implementations, emphasizing the importance of standardized and reliable tools. Orthogonium thus significantly lowers adoption barriers, enabling scalable experimentation and integration across diverse applications requiring orthogonality and robust Lipschitz constraints. Orthogonium is available at https://github.com/deel-ai/orthogonium."
  },
  {
    "date": "2026-01-20",
    "title": "The Harnack inequality without convexity for curve shortening flow",
    "authors": "Arjun Sobnack, Peter M. Topping",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13767v1",
    "source": "arXiv",
    "abstract": "In 1995, Hamilton introduced a Harnack inequality for convex solutions of the mean curvature flow. In this paper we prove an alternative Harnack inequality for curve shortening flow, i.e. one-dimensional mean curvature flow, that does not require any assumption of convexity. For an initial proper curve in the plane whose ends are radial lines but which is otherwise arbitrarily wild, we use the Harnack inequality to give an explicit time by which the curve shortening flow evolution must become graphical. This gives a new instance of delayed parabolic regularity. The Harnack inequality also gives estimates describing how a polar graphical flow with radial ends settles down to an expanding solution. Finally, we relate our Harnack inequality to Hamilton's by identifying a pointwise curvature estimate implied by both Harnack inequalities in the special case of convex flows."
  },
  {
    "date": "2026-01-20",
    "title": "DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes",
    "authors": "Aisha Al-Mohannadi, Ayisha Firoz, Yin Yang, Muhammad Imran, Ferda Ofli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13839v1",
    "source": "arXiv",
    "abstract": "Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770."
  },
  {
    "date": "2026-01-20",
    "title": "On the stability, complexity, and distribution of similarity classes of the longest edge bisection process for triangles",
    "authors": "Daniel Kalmanovich, Yaar Solomon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13663v1",
    "source": "arXiv",
    "abstract": "The Longest Edge Bisection (LEB) of a triangle is performed by joining the midpoint of its longest edge to the opposite vertex. Applying this procedure iteratively produces an infinite family of triangles. Surprisingly, a classical result of Adler (1983) shows that for any initial triangle, this infinite family falls into finitely many similarity classes. While the set of classes is finite, we show that a far smaller, stable subset of ``fat'' triangles, called {\\bf terminal quadruples}, effectively dominates the final mesh structure. We prove the following asymptotic area distribution result: for every initial triangle, the portion of area occupied by terminal quadruples tends to one, with the convergence occurring at an exponential rate. In fact, we provide the precise distribution of triangles in every step. We introduce the {\\bf bisection graph} and use spectral methods to establish this result. Given this dominance, we provide a complete characterization of triangles possessing a single terminal quadruple, while conversely exhibiting a sequence of triangles with an unbounded number of terminal quadruples. Furthermore, we reveal several fundamental geometric properties of the points of a terminal quadruple, laying the groundwork for studying the geometric distribution of the entire orbit. Our analysis leverages the hyperbolic geometry framework of Perdomo and Plaza (2014) and refines their techniques."
  },
  {
    "date": "2026-01-20",
    "title": "Moving Least Squares without Quasi-Uniformity: A Stochastic Approach",
    "authors": "Shir Tapiro-Moshe, Yariv Aizenbud, Barak Sober",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13782v1",
    "source": "arXiv",
    "abstract": "Local Polynomial Regression (LPR) and Moving Least Squares (MLS) are closely related nonparametric estimation methods, developed independently in statistics and approximation theory. While statistical LPR analysis focuses on overcoming sampling noise under probabilistic assumptions, the deterministic MLS theory studies smoothness properties and convergence rates with respect to the \\textit{fill-distance} (a resolution parameter). Despite this similarity, the deterministic assumptions underlying MLS fail to hold under random sampling. We begin by quantifying the probabilistic behavior of the fill-distance $h_n$ and \\textit{separation} $δ_n$ of an i.i.d. random sample. That is, for a distribution satisfying a mild regularity condition, $h_n\\propto n^{-1/d}\\log^{1/d} (n)$ and $δ_n \\propto n^{-1/d}$. We then prove that, for MLS of degree $k\\!-\\!1$, the approximation error associated with a differential operator $Q$ of order $|m|\\le k-1$ decays as $h_n^{\\,k-|m|}$ up to logarithmic factors, establishing stochastic analogues of the classical MLS estimates. Additionally, We show that the MLS approximant is smooth with high probability. Finally, we apply the stochastic MLS theory to manifold estimation. Assuming that the sampled Manifold is $k$-times smooth, we show that the Hausdorff distance between the true manifold and its MLS reconstruction decays as $h_n^k$, extending the deterministic Manifold-MLS guarantees to random samples. This work provides the first unified stochastic analysis of MLS, demonstrating that -- despite the failure of deterministic sampling assumptions -- the classical convergence and smoothness properties persist under natural probabilistic models"
  },
  {
    "date": "2026-01-20",
    "title": "The 2-categorical S-matrix of a braided fusion 1-category is a character table",
    "authors": "Alea Hofstetter, Christoph Schweigert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14168v1",
    "source": "arXiv",
    "abstract": "The semisimple module categories over a braided fusion category $\\mathcal{C}$ form a connected fusion 2-category $\\text{Mod}(\\mathcal{C})$. Its Drinfeld center $\\mathcal{Z}(\\text{Mod}(\\mathcal{C}))$ is a braided fusion 2-category. To any braided fusion 2-category, Johnson-Freyd and Reutter arXiv:2105.15167v3 [math.QA] have associated a matrix-valued invariant, the 2-categorical $S$-matrix. In this short note we investigate this matrix of $\\mathcal{Z}(\\text{Mod}(\\mathcal{C}))$ as an invariant for the braided fusion 1-category $\\mathcal{C}$ and show that it reduces to the character table of the Müger center of $\\mathcal{C}$."
  },
  {
    "date": "2026-01-20",
    "title": "Information transport and transport-induced entanglement in open fermion chains",
    "authors": "Andrea Nava, Claudia Artiaco, Yuval Gefen, Igor Gornyi, Mikheil Tsitsishvili, Alex Zazunov, Reinhold Egger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14153v1",
    "source": "arXiv",
    "abstract": "Understanding the entanglement dynamics in quantum many-body systems under steady-state transport conditions is an actively pursued challenging topic. Hydrodynamic equations, akin to transport equations for charge or heat, would be of great interest but face severe challenges because of the inherent nonlocality of entanglement and the difficulty of identifying conservation laws. We show that progress is facilitated by using information as key quantity related to - but distinct from - entanglement. Employing the recently developed \"information lattice\" framework, we characterize spatially and scale-resolved information currents in nonequilibrium open quantum systems. Specifically, using Lindblad master equations, we consider noninteracting fermion chains coupled to dissipative reservoirs. By relating the information lattice to a noise lattice constructed from particle-number fluctuations, we show that information is experimentally accessible via noise easurements. Similarly, local information currents can be obtained by measuring particle currents, onsite occupations, and covariances of particle numbers and/or particle currents. Using the fermionic negativity to quantify bipartite entanglement, we also study transport-induced entanglement and its relation to information currents. For a clean particle-hole symmetric chain, we find that information currents are shielded from entering the information lattice. Impurities or particle-hole asymmetry break this effect, causing information current flow and entanglement between end segments of the chain. Our work opens the door to systematic investigations of information transport and entanglement generation in driven open quantum systems far from equilibrium."
  },
  {
    "date": "2026-01-20",
    "title": "Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving",
    "authors": "Alexandre Justo Miro, Ludvig af Klinteberg, Bogdan Timus, Aron Asefaw, Ajinkya Khoche, Thomas Gustafsson, Sina Sharif Mansouri, Masoud Daneshtalab",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14038v1",
    "source": "arXiv",
    "abstract": "Accurate ground truth annotations are critical to supervised learning and evaluating the performance of autonomous vehicle systems. These vehicles are typically equipped with active sensors, such as LiDAR, which scan the environment in predefined patterns. 3D box annotation based on data from such sensors is challenging in dynamic scenarios, where objects are observed at different timestamps, hence different positions. Without proper handling of this phenomenon, systematic errors are prone to being introduced in the box annotations. Our work is the first to discover such annotation errors in widely used, publicly available datasets. Through our novel offline estimation method, we correct the annotations so that they follow physically feasible trajectories and achieve spatial and temporal consistency with the sensor data. For the first time, we define metrics for this problem; and we evaluate our method on the Argoverse 2, MAN TruckScenes, and our proprietary datasets. Our approach increases the quality of box annotations by more than 17% in these datasets. Furthermore, we quantify the annotation errors in them and find that the original annotations are misplaced by up to 2.5 m, with highly dynamic objects being the most affected. Finally, we test the impact of the errors in benchmarking and find that the impact is larger than the improvements that state-of-the-art methods typically achieve with respect to the previous state-of-the-art methods; showing that accurate annotations are essential for correct interpretation of performance. Our code is available at https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes."
  },
  {
    "date": "2026-01-20",
    "title": "Some Results on Causal Modalities in General Spacetimes",
    "authors": "Marco Lewis, Nesta van der Schaaf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14029v1",
    "source": "arXiv",
    "abstract": "Causality is one of the fundamental structures of spacetimes, it determines the possible behaviour and propagation of physical information through different relations. Causal structure can be analysed through the various modal logics it induces. The modal logics for the standard chronological and causal relations of the archetypal Minkowski spacetime have been classified. However only partial results have been achieved for the strict variant of the causal relation, also known as the after relation. The present work continues this analysis towards arbitrary spacetimes. By utilizing the definition of the causal relations through causal paths, we can lift known results about the modal logics of Minkowski spacetime to general spacetimes. In particular, for the after relation, we show that a previously studied formula within the logics of Minkowski spacetime holds in arbitrary spacetimes. We introduce a related modal formula that demonstrates that the logic of two-dimensional spacetimes are more expressive than higher dimensional ones. Lastly, we study the interrelation between the logical properties and physical properties along the causal ladder, a classification of causal structures according to a hierarchy of physically relevant properties."
  },
  {
    "date": "2026-01-20",
    "title": "Block-Fitness Modeling of the Global Air Mobility Network",
    "authors": "Giulia Fischetti, Anna Mancini, Giulio Cimini, Jessica T. Davis, Abby Leung, Alessandro Vespignani, Guido Caldarelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13867v1",
    "source": "arXiv",
    "abstract": "Accurate representations of the World Air Transportation Network (WAN) are fundamental inputs to models of global mobility, epidemic risk, and infrastructure planning. However, high-resolution, real-time data on the WAN are largely commercial and proprietary, therefore often inaccessible to the research community. Here we introduce a generative model of the WAN that treats air travel as a stochastic process within a maximum-entropy framework. The model uses airport-level passenger flows to probabilistically generate connections while preserving traffic volumes across geographic regions. The resulting reconstructed networks reproduce key structural properties of the WAN and enable simulations of dynamic spreading that closely match those obtained using the real network. Our approach provides a scalable, interpretable, and computationally efficient framework for forecasting and policy design in global mobility systems."
  },
  {
    "date": "2026-01-20",
    "title": "Non-perturbative flavor asymmetry in the nucleon and deuteron: The light-front Hamiltonian effective field theory approach",
    "authors": "Xianghui Cao, Shan Cheng, Yihan Duan, Yang Li, Siqi Xu, Xingbo Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13567v1",
    "source": "arXiv",
    "abstract": "We investigate non-perturbative multi-pion contributions to nucleon flavor asymmetry within the framework of Light-Front Hamiltonian Effective Field Theory (LFHEFT). Utilizing a Fock sector expansion, we systematically incorporate pionic degrees of freedom, with the nucleon-pion interactions governed by a scalar variant of chiral effective field theory. Our results demonstrate that the non-perturbatively calculated longitudinal momentum distributions exhibit significant deviations from leading-order perturbative predictions, emphasizing the importance of higher-order Fock components in describing the proton's sea quark structure. Furthermore, we demonstrate the feasibility of extending this framework to investigate nuclear effects in light nuclei, such as the deuteron. This unified approach provides a consistent basis for analyzing the interplay between intrinsic nucleon structure and nuclear modifications, potentially offering new insights into the flavor asymmetry observed in fixed-target and collider experiments."
  },
  {
    "date": "2026-1-20",
    "title": "“It’s Always in the Back of My Mind”: Navigating sensitive health data amid reduced abortion rights in the United States",
    "authors": "Georgia Kenderova, Eleanor Birrell, Sean A. Munson",
    "publish": "ACM Transactions on Computing for Healthcare",
    "url": "https://doi.org/10.1145/3788682",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "EffiPOI: A Product Quantization Framework Based on Knowledge Distillation for Efficient POI Recommendations",
    "authors": "Chengmei Peng, Yang Xu, Lei Zhu, Fengling Li, Huaxiang Zhang, Zhigang Ma",
    "publish": "ACM Transactions on Information Systems",
    "url": "https://doi.org/10.1145/3789267",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "Integer Hulls, Z-Polyhedra and Presburger Arithmetic in Action",
    "authors": "Rui-Juan Jing, Yuzhuo Lei, Christopher F. S. Maligec, Marc Moreno Maza, Chirantan Mukherjee",
    "publish": "ACM Communications in Computer Algebra",
    "url": "https://doi.org/10.1145/3787957.3787958",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "Koli Calling 2025 Conference Recap",
    "authors": "Juho Leinonen, Rodrigo Duran",
    "publish": "ACM SIGCSE Bulletin",
    "url": "https://doi.org/10.1145/3793257.3793261",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "Certified Algebraic Path Tracking with Algpath",
    "authors": "Alexandre Guillemot",
    "publish": "ACM Communications in Computer Algebra",
    "url": "https://doi.org/10.1145/3787957.3787960",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "Meditor, the Mathemagical Editor",
    "authors": "Raphaël Jolly",
    "publish": "ACM Communications in Computer Algebra",
    "url": "https://doi.org/10.1145/3787957.3787962",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "Member Spotlight: Paul Denny",
    "authors": "Paul Denny",
    "publish": "ACM SIGCSE Bulletin",
    "url": "https://doi.org/10.1145/3793257.3793263",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "SIGCSE News in Brief",
    "authors": "Julie M. Smith, Charles Wallace",
    "publish": "ACM SIGCSE Bulletin",
    "url": "https://doi.org/10.1145/3793257.3793258",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "Contiguous Zero-Copy for Encrypted Transport Protocols",
    "authors": "Florentin Rochet",
    "publish": "ACM SIGCOMM Computer Communication Review",
    "url": "https://doi.org/10.1145/3787927.3787929",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "The July 2025 Issue",
    "authors": "Steve Uhlig",
    "publish": "ACM SIGCOMM Computer Communication Review",
    "url": "https://doi.org/10.1145/3787927.3787928",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "The DenefLipshitz Algorithm: (Software Demonstration Support)",
    "authors": "François Boulier",
    "publish": "ACM Communications in Computer Algebra",
    "url": "https://doi.org/10.1145/3787957.3787959",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "Industry-Academia Open Research Collaboration: A Small Tech Company Perspective (SIDN)",
    "authors": "Giovane C. M. Moura, Ralph Koning, Moritz Müller, Cristian Hesselman",
    "publish": "ACM SIGCOMM Computer Communication Review",
    "url": "https://doi.org/10.1145/3787927.3787931",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "Symbolic-Numeric Pipeline for Reachability Analysis of Differential Equations with B-Series",
    "authors": "Julien Alexandre dit Sandretto",
    "publish": "ACM Communications in Computer Algebra",
    "url": "https://doi.org/10.1145/3787957.3787961",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-20",
    "title": "Campus5G: A Campus Scale Private 5G Open RAN Testbed",
    "authors": "Andrew E. Ferguson, Ujjwal Pawar, Tianxin Wang, Mahesh K. Marina",
    "publish": "ACM SIGCOMM Computer Communication Review",
    "url": "https://doi.org/10.1145/3787927.3787930",
    "source": "ACM",
    "abstract": "None"
  }
]