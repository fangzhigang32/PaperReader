[
  {
    "date": "2026-01-26",
    "title": "On-chip control of the coherence matrix of four-mode partially coherent light: rank, entropy, and modal Stokes parameters",
    "authors": "Amin Hashemi, Abbas Shiri, Bahaa E. A. Saleh, Andrea Blanco-Redondo, Ayman F. Abouraddy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18797v1",
    "source": "arXiv",
    "abstract": "Partially coherent light offers salutary capabilities in optical information processing that cannot be matched by coherent light. To date, this `coherence advantage' has been confirmed in proof-of-principle optical communications protocols using bulk optics. Taking full advantage of such opportunities necessitates processing multimode partially coherent light in integrated photonics platforms that alone provide the requisite stability for cascaded operations on a large scale. Here we demonstrate on-chip manipulation of four-mode partially coherent light described by a $4\\times4$ Hermitian coherence matrix. Starting with generic maximally incoherent light, we utilize an on-chip hexagonal mesh of Mach-Zehnder interferometers to perform all the unitary and non-unitary tasks that are critical for realizing structured coherence: controlling the coherence rank (the number of non-zero eigenvalues of the coherence matrix); tuning the field entropy; molding the structure of the coherence matrix via $4\\times4$ unitary transformations constructed out of sequences of $2\\times2$ unitaries acting on pairs of modes; and tomographic reconstruction of the coherence matrix by measuring the modal Stokes parameters associated with Kronecker Pauli matrices. These results confirm the scalability of utilizing $2\\times2$ on-chip building blocks for the synthesis and reconstruction of high-dimensional coherence matrices, and provide a decisive step towards large-scale on-chip manipulation of massively moded partially coherent light for applications in optical information processing."
  },
  {
    "date": "2026-01-26",
    "title": "ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models",
    "authors": "Brian Ondov, Chia-Hsuan Chang, Yujia Zhou, Mauro Giuffrè, Hua Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18796v1",
    "source": "arXiv",
    "abstract": "Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond."
  },
  {
    "date": "2026-01-26",
    "title": "Baryonification III: An accurate analytical model for the dispersion measure probability density function of fast radio bursts",
    "authors": "MohammadReza Torkamani, Robert Reischke, Michael Kovač, Andrina Nicola, Jozef Bucko, Alexandre Refregier, Sambit K. Giri, Aurel Schneider, Steffen Hagstotz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18784v1",
    "source": "arXiv",
    "abstract": "We develop a fully analytical framework for predicting the one-point probability distribution function (PDF) of dispersion measures (DM) for fast radio bursts (FRBs) using the baryonification (BFC) model. BFC provides a computationally efficient alternative to expensive hydrodynamical simulations for modelling baryonic effects on cosmological scales. By applying the halo mass function and halo bias, we convolve contributions from individual halos across a range of masses and redshifts to derive the large-scale structure contribution to the DM PDF. We validate our analytical predictions against consistency-check simulations and compare them with the IllustrisTNG hydrodynamical simulation across a range of redshifts up to $z = 5$, demonstrating excellent agreement. We demonstrate that our model produces consistent results when fitting gas profiles and predicting the PDF, and vice versa. We show that the BFC parameters controlling the gas profile, particularly the halo mass scale ($M_\\mathrm{c}$), mass-dependent slope ($μ$), and outer truncation ($δ$), are the primary drivers of the PDF shape. Additionally, we investigate the validity of the log-normal approximation commonly used for DM distributions, finding that it provides a sufficient description for a few hundred FRBs. Our work provides a self-consistent model that links gas density profiles to integrated DM statistics, enabling future constraints on baryonic feedback processes from FRB observations."
  },
  {
    "date": "2026-01-26",
    "title": "POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration",
    "authors": "Yuxiao Qu, Amrith Setlur, Virginia Smith, Ruslan Salakhutdinov, Aviral Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18779v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks."
  },
  {
    "date": "2026-01-26",
    "title": "Practical block encodings of matrix polynomials that can also be trivially controlled",
    "authors": "Martina Nibbi, Filippo Della Chiara, Yizhi Shen, Aaron Szasz, Roel Van Beeumen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18767v1",
    "source": "arXiv",
    "abstract": "Quantum circuits naturally implement unitary operations on input quantum states. However, non-unitary operations can also be implemented through block encodings, where additional ancilla qubits are introduced and later measured. While block encoding has a number of well-established theoretical applications, its practical implementation has been prohibitively expensive for current quantum hardware. In this paper, we present practical and explicit block encoding circuits implementing matrix polynomial transformations of a target matrix. With standard approaches, block-encoding a degree-$d$ matrix polynomial requires a circuit depth scaling as $d$ times the depth for block-encoding the original matrix alone. By leveraging the recently introduced Fast One-Qubit Controlled Select LCU (FOQCS-LCU) framework, we show that the additional circuit-depth overhead required for encoding matrix polynomials can be reduced to scale linearly in $d$ with no dependence on system size or the cost of block encoding the original matrix. Moreover, we demonstrate that the FOQCS-LCU circuits and their associated matrix polynomial transformations can be controlled with negligible overhead, enabling efficient applications such as Hadamard tests. Finally, we provide explicit circuits for representative spin models, together with detailed non-asymptotic gate counts and circuit depths."
  },
  {
    "date": "2026-01-26",
    "title": "Goal-oriented Communication for Fast and Robust Robotic Fault Detection and Recovery",
    "authors": "Shutong Chen, Adnan Aijaz, Yansha Deng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18765v1",
    "source": "arXiv",
    "abstract": "Autonomous robotic systems are widely deployed in smart factories and operate in dynamic, uncertain, and human-involved environments that require low-latency and robust fault detection and recovery (FDR). However, existing FDR frameworks exhibit various limitations, such as significant delays in communication and computation, and unreliability in robot motion/trajectory generation, mainly because the communication-computation-control (3C) loop is designed without considering the downstream FDR goal. To address this, we propose a novel Goal-oriented Communication (GoC) framework that jointly designs the 3C loop tailored for fast and robust robotic FDR, with the goal of minimising the FDR time while maximising the robotic task (e.g., workpiece sorting) success rate. For fault detection, our GoC framework innovatively defines and extracts the 3D scene graph (3D-SG) as the semantic representation via our designed representation extractor, and detects faults by monitoring spatial relationship changes in the 3D-SG. For fault recovery, we fine-tune a small language model (SLM) via Low-Rank Adaptation (LoRA) and enhance its reasoning and generalization capabilities via knowledge distillation to generate recovery motions for robots. We also design a lightweight goal-oriented digital twin reconstruction module to refine the recovery motions generated by the SLM when fine-grained robotic control is required, using only task-relevant object contours for digital twin reconstruction. Extensive simulations demonstrate that our GoC framework reduces the FDR time by up to 82.6% and improves the task success rate by up to 76%, compared to the state-of-the-art frameworks that rely on vision language models for fault detection and large language models for fault recovery."
  },
  {
    "date": "2026-01-26",
    "title": "Multi-Stage Structured Estimators for Information Freshness",
    "authors": "Sahan Liyanaarachchi, Sennur Ulukus, Nail Akar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18763v1",
    "source": "arXiv",
    "abstract": "Most of the contemporary literature on information freshness solely focuses on the analysis of freshness for martingale estimators, which simply use the most recently received update as the current estimate. While martingale estimators are easier to analyze, they are far from optimal, especially in pull-based update systems, where maximum aposteriori probability (MAP) estimators are known to be optimal, but are analytically challenging. In this work, we introduce a new class of estimators called $p$-MAP estimators, which enable us to model the MAP estimator as a piecewise constant function with finitely many stages, bringing us closer to a full characterization of the MAP estimators when modeling information freshness."
  },
  {
    "date": "2026-01-26",
    "title": "UI Remix: Supporting UI Design Through Interactive Example Retrieval and Remixing",
    "authors": "Junling Wang, Hongyi Lan, Xiaotian Su, Mustafa Doga Dogan, April Yi Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18759v1",
    "source": "arXiv",
    "abstract": "Designing user interfaces (UIs) is a critical step when launching products, building portfolios, or personalizing projects, yet end users without design expertise often struggle to articulate their intent and to trust design choices. Existing example-based tools either promote broad exploration, which can cause overwhelm and design drift, or require adapting a single example, risking design fixation. We present UI Remix, an interactive system that supports mobile UI design through an example-driven design workflow. Powered by a multimodal retrieval-augmented generation (MMRAG) model, UI Remix enables iterative search, selection, and adaptation of examples at both the global (whole interface) and local (component) level. To foster trust, it presents source transparency cues such as ratings, download counts, and developer information. In an empirical study with 24 end users, UI Remix significantly improved participants' ability to achieve their design goals, facilitated effective iteration, and encouraged exploration of alternative designs. Participants also reported that source transparency cues enhanced their confidence in adapting examples. Our findings suggest new directions for AI-assisted, example-driven systems that empower end users to design with greater control, trust, and openness to exploration."
  },
  {
    "date": "2026-01-26",
    "title": "Divergence-free and mass-conservative virtual element methods for the Navier-Stokes-Cahn-Hilliard system",
    "authors": "Alberth Silgado, Giuseppe Vacca",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18758v1",
    "source": "arXiv",
    "abstract": "In this work, we design and analyze semi/fully-discrete virtual element approximations for the time-dependent Navier--Stokes-Cahn--Hilliard equations, modeling the dynamics of two-phase incompressible fluid flows with diffuse interfaces. A new variational formulation is derived involving solely the velocity, pressure, and phase field, together with corresponding a priori energy estimates. The spatial discretization is based on the coupling divergence-free and $C^1$-conforming elements of high-order, while the time discretization employs a classical backward Euler scheme. By introducing a novel skew-symmetric trilinear form to discretize the convective term in the Cahn--Hilliard equation, we propose discrete schemes that satisfy mass conservation and energy bounds. Moreover, optimal error estimates are provided for both formulations. Finally, two numerical experiments are presented to support our theoretical findings and to illustrate the good performance of the proposed schemes for different polynomial degrees and polygonal meshes."
  },
  {
    "date": "2026-01-26",
    "title": "Role of the symmetry energy on hybrid stars",
    "authors": "H. Güven, K. Bozkurt, E. Khan, J. Margueron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18752v1",
    "source": "arXiv",
    "abstract": "The impact of the symmetry energy on the properties of compact stars is analyzed considering constraints from nuclear physics and astrophysics. A compact star can be a neutron star composed only of nuclear matter or a hybrid star with a quark core. Two typical models (soft and stiff) are considered for the nuclear equation of state, and for the hybrid one, a parameterized first-order phase transition approach, completed with a linear quark matter equation of state, is implemented. We show that the phase transition reduces the tension between GW170817 and NICER observations, and we illustrate the impact of the symmetry energy for the understanding of the nature of the binary system in GW170817. We also confirm our previous findings that the GW170817 waveform is best described as a binary HS with a low-density onset of stiff quark matter. This could also be interpreted as a quarkyonic cross-over."
  },
  {
    "date": "2026-01-26",
    "title": "SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification",
    "authors": "Ignacio Antequera-Sánchez, Juan Luis Suárez-Díaz, Rosana Montes, Francisco Herrera",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18739v1",
    "source": "arXiv",
    "abstract": "Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance."
  },
  {
    "date": "2026-01-26",
    "title": "Roth-type theorems in $K_{s,t}$-free sets",
    "authors": "Yifan Jing, Cosmin Pohoata, Max Wenqiang Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18738v1",
    "source": "arXiv",
    "abstract": "We show that for all integers $2\\le s\\le t$, any $K_{s,t}$-free subset of $[N]$ with size $Ω(n^{1-1/s})$ must contain a nontrivial solution to every fixed translation-invariant linear equation in at least five variables. This extends earlier results for Sidon sets due to Conlon-Fox-Sudakov-Zhao and Prendiville to the full family of $K_{s,t}$-free sets. We also study the corresponding problem in vector spaces over finite fields. In $\\mathbb F_q^n$ we obtain stronger quantitative bounds, including polylogarithmic savings, by combining Fourier-analytic transference with polynomial-method input from the arithmetic cycle-removal lemma of Fox-Lovász-Sauermann."
  },
  {
    "date": "2026-01-26",
    "title": "An ISAC-ready Full-Duplex Backscatter Architecture for the mmWave IoT",
    "authors": "Skanda Harisha, Jimmy G. D. Hester, Aline Eid",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18727v1",
    "source": "arXiv",
    "abstract": "Achieving long-range, high-rate, concurrent two-way mmWave communication with power-constrained IoT devices is fundamental to scaling future ubiquitous sensing systems, yet the substantial power demands and high cost of mmWave hardware have long stood in the way of practical deployment. This paper presents the first mmWave full-duplex backscatter tag architecture, charting a genuinely low-cost path toward high-performance mmWave connectivity and localization for ISAC systems. The proposed tag operates at ranges beyond 45m on the uplink and beyond 200m on the downlink, delivering 20x the reach of state-of-the-art systems while being over 100x cheaper than existing mmWave backscatter platforms. Enabling this leap is a novel low-power regenerative amplifier that provides 30 dB of gain while consuming only 30 mW, paired with a regenerative rectifier that achieves state-of-the-art sensitivity down to -60 dBm. We integrate our circuits on a compact PCB and evaluate it across diverse uplink and downlink scenarios, where it achieves an downlink BER of $10^{-1}$ at 200 meters and a uplink BER of $10^{-2}$ at 45 meters, demonstrating resilient, high-quality communication even at extended ranges."
  },
  {
    "date": "2026-01-26",
    "title": "HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences",
    "authors": "Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18724v1",
    "source": "arXiv",
    "abstract": "Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as \"HalluCitation\" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility."
  },
  {
    "date": "2026-01-26",
    "title": "Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods",
    "authors": "Mengyuan Liu, Juyi Sheng, Peiming Li, Ziyi Wang, Tianming Xu, Tiantian Xu, Hong Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18723v1",
    "source": "arXiv",
    "abstract": "Driven by the rapid evolution of Vision-Action and Vision-Language-Action models, imitation learning has significantly advanced robotic manipulation capabilities. However, evaluation methodologies have lagged behind, hindering the establishment of Trustworthy Evaluation for these behaviors. Current paradigms rely on binary success rates, failing to address the critical dimensions of trust: Source Authenticity (i.e., distinguishing genuine policy behaviors from human teleoperation) and Execution Quality (e.g., smoothness and safety). To bridge these gaps, we propose a solution that combines the Eval-Actions benchmark and the AutoEval architecture. First, we construct the Eval-Actions benchmark to support trustworthiness analysis. Distinct from existing datasets restricted to successful human demonstrations, Eval-Actions integrates VA and VLA policy execution trajectories alongside human teleoperation data, explicitly including failure scenarios. This dataset is structured around three core supervision signals: Expert Grading (EG), Rank-Guided preferences (RG), and Chain-of-Thought (CoT). Building on this, we propose the AutoEval architecture: AutoEval leverages Spatio-Temporal Aggregation for semantic assessment, augmented by an auxiliary Kinematic Calibration Signal to refine motion smoothness; AutoEval Plus (AutoEval-P) incorporates the Group Relative Policy Optimization (GRPO) paradigm to enhance logical reasoning capabilities. Experiments show AutoEval achieves Spearman's Rank Correlation Coefficients (SRCC) of 0.81 and 0.84 under the EG and RG protocols, respectively. Crucially, the framework possesses robust source discrimination capabilities, distinguishing between policy-generated and teleoperated videos with 99.6% accuracy, thereby establishing a rigorous standard for trustworthy robotic evaluation. Our project and code are available at https://term-bench.github.io/."
  },
  {
    "date": "2026-01-26",
    "title": "A mixed interpolation-regression method for numerical integration on the unit circle using zeros of para-orthogonal polynomials",
    "authors": "Ruymán Cruz-Barroso, Lidia Fernández, Francisco Marcellán",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18721v1",
    "source": "arXiv",
    "abstract": "A new alternative numerical procedure to the Szegő quadrature formulas for the estimation of integrals with respect to a positive Borel measure $μ$ supported on the unit circle is presented. As in many practical situations, we assume that the values of the integrand $F$ are only known at a finite number of points, which we will assume to be uniformly distributed on the unit circle (although this does not actually constitute a restriction). Our technique consists of obtaining an approximating Laurent polynomial $L$ to $F$ by interpolation in the Hermite sense in a collection of these points that mimic the zeros of a para-orthogonal polynomial with respect to $μ$, and to use the values of $F$ at the remaining nodes to improve the accuracy of the approximation by a process of simultaneous complex regression. Some numerical examples are carried out."
  },
  {
    "date": "2026-01-26",
    "title": "Nontrivial bounds on extractable energy in quantum energy teleportation for gapped manybody systems with a unique ground state",
    "authors": "Taisanul Haque",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18718v1",
    "source": "arXiv",
    "abstract": "We establish a universal, exponentially decaying upper bound on the average energy that can be extracted in quantum energy teleportation (QET) protocols executed on finite-range gapped lattice systems possessing a unique ground state. Under mild regularity assumptions on the Hamiltonian and uniform operator-norm bounds on the local measurement operators, there exist positive constants $C$ and $μ$ (determined by the spectral gap, interaction range and local operator norms) such that for any local measurement performed in a region $A$ and any outcome-dependent local unitaries implemented in a disjoint region $B$ separated by distance $d=\\operatorname{dist}(A,B)$ one has $|E_A-E_B|\\le C\\,e^{-μd}.$ The bound is nonperturbative, explicit up to model-dependent constants, and follows from the variational characterization of the ground state combined with exponential clustering implied by the spectral gap."
  },
  {
    "date": "2026-01-26",
    "title": "A New Layered Kagome Strip Structure Na2Co3(AsO4)2(OH)2: Static and Dynamic Magnetic Properties",
    "authors": "Duminda S. Liurukara, Emily D. Williams, Tianran Chen, Stuart Calder, V. Ovidiu Garlea, C. Charlotte Buchanan, Dustin A. Gilbert, Joseph W. Kolis, D. A. Tennant",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18717v1",
    "source": "arXiv",
    "abstract": "One-dimensional kagome strip chains share much of the same frustrated structural motif as two-dimensional kagome antiferromagnets, making them valuable for deepening our understanding of kagome lattice magnetism. In this paper, we report the hydrothermal synthesis and detailed structural and property characterization of Na2Co3(AsO4)2(OH)2, a striped kagome system. The crystal structure was characterized using single crystal X-ray diffraction, which reveals that Na2Co3(AsO4)2(OH)2 crystallizes in the monoclinic crystal system C2/m. The structure features a one-dimensional kagome strip lattice built from Co2+ ions and undergoes an antiferromagnetic transition at TN = 14 K. The magnetic ground state at zero field was characterized using neutron powder diffraction. Below the magnetic transition, Na2Co3(AsO4)2(OH)2 orders into an antiferromagnetic structure with a k-vector (0.5, 0.5, 0.5). In the proposed model, the Co1 moment is predominantly confined to the ac-plane while the Co2 moment is primarily aligned along the b-axis. Two flat bands were observed in the inelastic neutron spectra below the magnetic transition at 5 and 10 meV. Inelastic neutron spectra were modeled with a Heisenberg Hamiltonian including three nearest-neighbor exchange interactions (J1, J2, J3) and strong single-ion anisotropy to stabilize the observed magnetic structure. Our study highlights the complexity of the Co2+-based kagome strip magnetic lattice compound Na2Co3(AsO4)2(OH)2, which provides an excellent platform to broaden our understanding of the frustrated kagome magnetic lattice space."
  },
  {
    "date": "2026-01-26",
    "title": "Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning",
    "authors": "Judith Vilella-Cantos, Mauro Martini, Marcello Chiaberge, Mónica Ballesta, David Valiente",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18714v1",
    "source": "arXiv",
    "abstract": "Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction."
  },
  {
    "date": "2026-01-26",
    "title": "Analyzing Images of Blood Cells with Quantum Machine Learning Methods: Equilibrium Propagation and Variational Quantum Circuits to Detect Acute Myeloid Leukemia",
    "authors": "A. Bano, L. Liebovitch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18710v1",
    "source": "arXiv",
    "abstract": "This paper presents a feasibility study demonstrating that quantum machine learning (QML) algorithms achieve competitive performance on real-world medical imaging despite operating under severe constraints. We evaluate Equilibrium Propagation (EP), an energy-based learning method that does not use backpropagation (incompatible with quantum systems due to state-collapsing measurements) and Variational Quantum Circuits (VQCs) for automated detection of Acute Myeloid Leukemia (AML) from blood cell microscopy images using binary classification (2 classes: AML vs. Healthy). Key Result: Using limited subsets (50-250 samples per class) of the AML-Cytomorphology dataset (18,365 expert-annotated images), quantum methods achieve performance only 12-15% below classical CNNs despite reduced image resolution (64x64 pixels), engineered features (20D), and classical simulation via Qiskit. EP reaches 86.4% accuracy (only 12% below CNN) without backpropagation, while the 4-qubit VQC attains 83.0% accuracy with consistent data efficiency: VQC maintains stable 83% performance with only 50 samples per class, whereas CNN requires 250 samples (5x more data) to reach 98%. These results establish reproducible baselines for QML in healthcare, validating NISQ-era feasibility."
  },
  {
    "date": "2026-01-26",
    "title": "Efficient SN-like and PN-like Dynamic Low Rank methods for Thermal Radiative Transfer",
    "authors": "Terry Haut, John Loffeld, Lukas Einkemmer, Pierson Guthrey, Stefan Brunner, William Schill",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18705v1",
    "source": "arXiv",
    "abstract": "Dynamic Low Rank (DLR) methods are a promising way to reduce the computational cost and memory footprint of the high-dimensional thermal radiative transfer (TRT) equations. The TRT equations are a system of nonlinear PDEs that model the energy exhchange between the material temperature and the radiation energy density; due to their high dimensionality, solving the TRT equations is often bottleneck in multi-physics simulations. DLR methods represent the solution in terms of time-evolving SVD-like factors of angle and space. Although previous work has explored DLR methods for TRT, most of the methods have limitations that make them impractical for realistic scenarios and uncompetitive with current non-DLR production codes. Here we develop new PN-like and SN-like Dynamic Low Rank (DLR) methods for TRT. In the SN-like DLR method, we use the time-evolving angular basis functions to select time-evolving angles; this DLR formulation enables us to use the highly optimized SN transport sweep as our main computational kernel, and results in a practical way of leveraging low-rank methods in production TRT codes. In contrast, our PN-like DLR method uses an even-parity formulation and results in positive-definite linear systems to solve for each time step. We demonstrate the methods on several challenging, highly heterogenous problems in two spatial dimensions $(4$D) that these DLR schemes can give significant reduction in angular artifacts (``ray effects'') with the same cost as gold-standard SN methods."
  },
  {
    "date": "2026-01-26",
    "title": "Normal and Poisson approximation for Gibbs point processes with pair potentials",
    "authors": "Christian Hirsch, Moritz Otto, Anne Marie Svane",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18695v1",
    "source": "arXiv",
    "abstract": "We provide a Poisson approximation result for dependent thinnings of Gibbs point processes as well as qualitative and quantitative central limit theorems for geometric functionals of Gibbs point processes in increasing observation windows. The present paper extends prior work on finite-range Gibbs processes to processes with repulsive pairwise interaction of unbounded interaction range as well as processes on marked Euclidean space. The proofs rely on coupling different Gibbs processes using the disagreement coupling technique, which we generalize to infinite-volume domains under a suitable non-percolation condition. For the case of repulsive pairwise interactions, we introduce a version of disagreement coupling that constructs the Gibbs process by thinning a random connection model thus making previous approximation methods more flexible."
  },
  {
    "date": "2026-01-26",
    "title": "A Pragmatic VLA Foundation Model",
    "authors": "Wei Wu, Fan Lu, Yunnan Wang, Shuai Yang, Shi Liu, Fangjing Wang, Qian Zhu, He Sun, Yong Wang, Shuailei Ma, Yiyu Ren, Kejia Zhang, Hui Yu, Jingmei Zhao, Shuai Zhou, Zhenqi Qiu, Houlong Xiong, Ziyu Wang, Zechen Wang, Ran Cheng, Yong-Lu Li, Yongtao Huang, Xing Zhu, Yujun Shen, Kecheng Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18692v1",
    "source": "arXiv",
    "abstract": "Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards."
  },
  {
    "date": "2026-01-26",
    "title": "Function estimation in the empirical Bayes setting",
    "authors": "Benjamin Kang, Yury Polyanskiy, Anzo Teh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18689v1",
    "source": "arXiv",
    "abstract": "We study function estimation in the empirical Bayes setting for Poisson and normal means. Specifically, given observations $Y_i\\sim f(\\cdot; θ_i)$ with latent parameters $θ_i\\sim π$, the goal is to estimate $\\mathbb{E}_π[\\ell(θ)|X = x]$. This task lies between classical deconvolution (recovering the full prior $π$), and standard empirical Bayes mean estimation. While the minimax risk for estimating $π$ in the Wasserstein distance is known to decay only logarithmically, we show that estimating certain smooth functions admits dramatically faster rates. In particular, for polynomial functions of degree $k$ in the Poisson model, we establish a tight bound of $Θ(\\frac{1}{n}(\\frac{\\log n}{\\log \\log n})^{k+1})$ and $Θ(\\frac{1}{n}(\\log n)^{2k+1})$ for bounded and subexponential priors, respectively, attainable by estimators mimicking those that achieve optimal regret for the mean estimation problem (Robbins, mininum distance, ERM). Our analysis identifies the approximation-theoretic origin of this improvement: smooth functions can be well-approximated by low-degree polynomials, whereas Lipschitz functions require dense polynomial approximations, incurring a $\\frac{1}{k}$ loss for degree $k$ polynomial approximation. The results reveal a sharp hierarchy in the difficulty of empirical Bayes problems: ranging from slow, logarithmic deconvolution to near-parametric convergence for smooth posterior functionals, and establish new connections between nonparametric empirical Bayes theory, polynomial approximation, and statistical inverse problems. Finally, we complement our analysis with a lower bound of $Ω(\\frac 1n (\\frac{\\log n}{\\log \\log n})^{k+1})$ (bounded priors) and $Ω(\\frac 1n (\\log n)^{k + 1})$ (subgaussian priors) for the normal means model."
  },
  {
    "date": "2026-01-26",
    "title": "Optimal strategy and deep hedging for share repurchase programs",
    "authors": "Stefano Corti, Roberto Daluiso, Andrea Pallavicini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18686v1",
    "source": "arXiv",
    "abstract": "In recent decades, companies have frequently adopted share repurchase programs to return capital to shareholders or for other strategic purposes, instructing investment banks to rapidly buy back shares on their behalf. When the executing institution is allowed to hedge its exposure, it encounters several challenges due to the intrinsic features of the product. Moreover, contractual clauses or market regulations on trading activity may make it infeasible to rely on Greeks. In this work, we address the hedging of these products by developing a machine-learning framework that determines the optimal execution of the buyback while explicitly accounting for the bank's actual trading capabilities. This unified treatment of execution and hedging yields substantial performance improvements, resulting in an optimized policy that provides a feasible and realistic hedging approach. The pricing of these programs can be framed in terms of the discount that banks offer to the client on the price at which the shares are delivered. Since, in our framework, risk measures serve as objective functions, we exploit the concept of indifference pricing to compute this discount, thereby capturing the actual execution performance."
  },
  {
    "date": "2026-01-26",
    "title": "Out-of-Distribution Radar Detection with Complex VAEs: Theory, Whitening, and ANMF Fusion",
    "authors": "Yadang Alexis Rouzoumka, Jean Pinsolle, Eugénie Terreaux, Christèle Morisseau, Jean-Philippe Ovarlez, Chengfang Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18677v1",
    "source": "arXiv",
    "abstract": "We investigate the detection of weak complex-valued signals immersed in non-Gaussian, range-varying interference, with emphasis on maritime radar scenarios. The proposed methodology exploits a Complex-valued Variational AutoEncoder (CVAE) trained exclusively on clutter-plus-noise to perform Out-Of-Distribution detection. By operating directly on in-phase / quadrature samples, the CVAE preserves phase and Doppler structure and is assessed in two configurations: (i) using unprocessed range profiles and (ii) after local whitening, where per-range covariance estimates are obtained from neighboring profiles. Using extensive simulations together with real sea-clutter data from the CSIR maritime dataset, we benchmark performance against classical and adaptive detectors (MF, NMF, AMF-SCM, ANMF-SCM, ANMF-Tyler). In both configurations, the CVAE yields a higher detection probability Pd at matched false-alarm rate Pfa, with the most notable improvements observed under whitening. We further integrate the CVAE with the ANMF through a weighted log-p fusion rule at the decision level, attaining enhanced robustness in strongly non-Gaussian clutter and enabling empirically calibrated Pfa control under H0. Overall, the results demonstrate that statistical normalization combined with complex-valued generative modeling substantively improves detection in realistic sea-clutter conditions, and that the fused CVAE-ANMF scheme constitutes a competitive alternative to established model-based detectors."
  },
  {
    "date": "2026-01-26",
    "title": "Level structure of light neutron-rich La isotopes beyond the N=82 shell closure",
    "authors": "A. Navin, E. H. Wang, S. Bhattacharyya, Menglan Liu, Cenxi Yuan, M. Rejmund, A. Lemasson, S. Biswas, Y. H. Kim, C. Michelagnoli, J. H. Hamilton, A. V. Ramayya, I. Stefan, R. Banik, P. Bednarczyk, Soumik Bhattacharya, E. Clement, H. L. Crawford, G. de France, P. Fallon, G. Fremont J. Goupil, B. Jacquot, H. J. Li, J. Ljungvall, Y. X. Luo, A. Maj, L. Menager, V. Morel, G. Mukherjee, R. Palit, R. M. Perez-Vidal, J. O. Rasmussen, J. Ropert, C. Schmitt, S. J. Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18673v1",
    "source": "arXiv",
    "abstract": "The high spin excited states of Lanthanum isotopes $^{140-143}$La, above the $N=82$ closed shell, have been populated in fission reactions. The prompt $γ$-ray transitions were measured using two complementary methods; a) in coincidence with the isotopically identified fragments produced in the fission of the $^{238}$U+$^{9}$Be system using the VAMOS++ and the AGATA spectrometers and b) high statistics three-fold $γ-γ-γ$ and four-fold $γ-γ-γ-γ$ coincidence data from the spontaneous fission of $^{252}$Cf using the Gammasphere. This work reports the first identification of a pair of parity doublet structures in $^{143}$La and the new high spin level structure in $^{140-142}$La from prompt $γ$-ray spectroscopy. The level structures are interpreted in terms of the systematics of neighbouring odd-$Z$ nuclei above $Z=50$ shell closure and large-scale shell model calculations. The present results indicate the presence of stable octupole deformation, in $^{143}$La. The excitation energy pattern and their comparison with neighbouring isotones, moving away from the N=82 closed shell, point towards a transition from single particle structures to an alternating parity rotational band structure in the La isotopic chain."
  },
  {
    "date": "2026-01-26",
    "title": "A Dynamic Framework for Grid Adaptation in Kolmogorov-Arnold Networks",
    "authors": "Spyros Rigas, Thanasis Papaioannou, Panagiotis Trakadas, Georgios Alexandridis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18672v1",
    "source": "arXiv",
    "abstract": "Kolmogorov-Arnold Networks (KANs) have recently demonstrated promising potential in scientific machine learning, partly due to their capacity for grid adaptation during training. However, existing adaptation strategies rely solely on input data density, failing to account for the geometric complexity of the target function or metrics calculated during network training. In this work, we propose a generalized framework that treats knot allocation as a density estimation task governed by Importance Density Functions (IDFs), allowing training dynamics to determine grid resolution. We introduce a curvature-based adaptation strategy and evaluate it across synthetic function fitting, regression on a subset of the Feynman dataset and different instances of the Helmholtz PDE, demonstrating that it significantly outperforms the standard input-based baseline. Specifically, our method yields average relative error reductions of 25.3% on synthetic functions, 9.4% on the Feynman dataset, and 23.3% on the PDE benchmark. Statistical significance is confirmed via Wilcoxon signed-rank tests, establishing curvature-based adaptation as a robust and computationally efficient alternative for KAN training."
  },
  {
    "date": "2026-01-26",
    "title": "Adaptive dynamics of alternating Prisoner's Dilemma with memory N",
    "authors": "Nataliya A. Balabanova, Hong Duong, Christian Hilbe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18671v1",
    "source": "arXiv",
    "abstract": "The Prisoner's Dilemma is used as a model in processes involving reciprocity; however, its classical setup can be insufficient in settings where the symmetry of the simultaneous decision making is broken -- for example, in donor and recipient processes. In the alternating Prisoner's Dilemma model the two players take turns choosing their strategy. Assuming a finite memory setup, we establish the mathematical aspects of the adaptive dynamics of the alternating Prisoner's Dilemma, paying particular attention to the case of memory 1."
  },
  {
    "date": "2026-01-26",
    "title": "Novikov Coordinates and the Physical Description of Gravitational Collapse",
    "authors": "Jaume de Haro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18660v1",
    "source": "arXiv",
    "abstract": "We show that the Novikov coordinates can be obtained in a direct and physically transparent way from the radial geodesics of massive particles with negative energy in the Schwarzschild spacetime. These geodesics form a complete congruence that covers the entire spacetime. By rectifying this family of trajectories using the proper time as the time coordinate, the Novikov variables naturally emerge, providing a clear dynamical interpretation of the different regions usually identified as black-hole and white-hole sectors. In Novikov coordinates, observers at fixed spatial position follow free-fall trajectories. From their perspective, the gravitational collapse of a dust star is completed in a finite proper time, independently of their initial distance from the star. In contrast, observers described by Schwarzschild-Droste coordinates perceive the boundary of the collapsing star as taking an infinite coordinate time to reach the horizon. We emphasize that Schwarzschild-Droste observers are static with respect to the center of mass of the star and therefore cannot be in free fall. The use of these coordinates implicitly requires the presence of a force that compensates the gravitational attraction. From this viewpoint, the apparent infinite-time collapse is not a physical effect but a coordinate artifact associated with non-inertial observers."
  },
  {
    "date": "2026-01-26",
    "title": "Order Out of Noise and Disorder: Fate of the Frustrated Manifold",
    "authors": "Igor Halperin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18653v1",
    "source": "arXiv",
    "abstract": "We study Langevin dynamics of $N$ Brownian particles on compact two-dimensional Riemannian manifolds, interacting through pairwise potentials linear in geodesic distance with quenched random couplings. These \\emph{frustrated Brownian particles} experience the competing demands of random attractive and repulsive interactions while confined to curved surfaces. We consider three geometries: the sphere $S^2$, torus $T^2$ (closed manifolds), and bounded cylinder $S^1 \\times [0,H]$ (manifold with boundary). Our central finding is disorder-induced dimension reduction accompanied by spontaneous breaking of rotational symmetry: order emerges from the combination of two sources of randomness (thermal noise and quenched disorder), with the manifold topology determining the character of the emerging structures. Glassy relaxation drives particles from 2D distributions to quasi-1D structures, specifically bands on $S^2$, rings on $T^2$, and localized clusters on the cylinder. The symmetry breaking pattern depends on topology: SO(3)$\\to$SO(2) on the sphere, SO(2)$\\times$SO(2)$\\to$SO(2)$\\times\\mathbb{Z}_2$ on the torus, and SO(2)$\\to\\mathbb{Z}_2$ on the cylinder. Unlike conventional spontaneous symmetry breaking, the symmetry-breaking direction is not frozen but evolves slowly via thermal noise through type-A diffusive Nambu-Goldstone dynamics, while the reduced-dimensional structure persists. Unlike conventional self-organizing systems that require external driving or fine-tuned nonlinearities, our model demonstrates that geometry and topology alone can channel randomness into order. We discuss connections to spin glass theory, quantum field theory, astrophysical structure formation, and self-organizing systems, providing a geometric framework for understanding how disorder generates emergent spatial order on curved spaces."
  },
  {
    "date": "2026-01-26",
    "title": "D1-D5 CFT data from $AdS_3 \\times S^3$ Virasoro-Shapiro amplitude",
    "authors": "Hongliang Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18646v1",
    "source": "arXiv",
    "abstract": "The AdS Virasoro-Shapiro amplitude has recently been generalized to the AdS$_3$/CFT$_2$ correspondence between type IIB string theory on $ AdS_3 \\times S^3 \\times K3$ (or $T^4$), supported by Ramond-Ramond flux, and the D1-D5 CFT. In this paper, we use the $ AdS\\times S$ Virasoro-Shapiro machinery to extract strong-coupling CFT data of the D1-D5 CFT by extending and completing earlier analyses in several directions. First, starting from the superconformal/Mellin block expansion of four-point functions of half-BPS tensor operators with arbitrary external KK modes, we employ the full $ AdS\\times S$ Mellin formalism to bootstrap the $ AdS_3 \\times S^3$ Virasoro-Shapiro amplitude for general KK configurations. This establishes its consistency with superconformal symmetry and yields a wealth of additional CFT data naturally organized in internal Mellin space. Second, we push the computation to the next order in the strong-coupling expansion and extract additional higher-order CFT data. Third, we translate the resulting Mellin-space data into the internal spin basis. We derive the transformation kernel relating internal Mellin variables and $SU(2)_L \\times SU(2)_R$ R-symmetry spins. As applications, we obtain explicit formulae for the scaling dimensions of long multiplets on the first two leading Regge trajectories of arbitrary internal spins, and certain three-point functions with half-BPS tensor operators. These results provide a valuable set of analytic D1-D5 CFT data, enabling future applications and direct comparison with complementary approaches such as integrability."
  },
  {
    "date": "2026-01-26",
    "title": "Birational Weyl Group Action on the Symplectic Groupoid and Cluster Algebras",
    "authors": "Woojin Choi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18636v1",
    "source": "arXiv",
    "abstract": "A. Bondal introduced a symplectic groupoid of triangular bilinear forms. This induces the Poisson structure on $\\mathcal{A}_n$, the space of $n \\times n$ unipotent upper-triangular matrices. L. Chekhov and M. Shapiro described log-canonical coordinates on this symplectic groupoid via the $\\mathcal{A}_n$-quiver. In this paper, we introduce a birational Weyl group action on the symplectic groupoid. It is generated by cluster transformations associated with certain cycles of the quiver. We prove that every matrix entry of $\\mathcal{A}_n$ is invariant under this action. Conversely, we prove that matrix entries generate the Poisson subalgebra of Weyl group invariants in the ring of regular functions on the cluster variety $\\mathcal X_{|\\mathcal A_n|}$. V. Fock and L. Chekhov defined a Poisson map $φ_n$ from the Teichmüller space $\\mathcal{T}_{g,s}$ with genus $g$ and $s \\in \\{1,2\\}$ boundary components into $\\mathcal{A}_n$. We aim to describe the cluster structure of $\\text{Im}(φ_n)$ by applying a Hamiltonian reduction to $\\mathcal A_n$. Since every element in $\\text{Im}(φ_n)$ satisfies the rank condition $\\text{rank}(A+A^T) \\le 4$, it provides a natural criterion for our Hamiltonian reduction. The solution set of the rank condition has distinct irreducible components, so the reduction might be component-dependent. However, we show that the Weyl group acts transitively on these components. This implies that the Hamiltonian reductions are conjugate; thus, it suffices to determine the reduction on a single component. Furthermore, we prove that the longest element of the Weyl group corresponds to a cluster DT-transformation on the $\\mathcal{A}_{2k}$-quiver. In contrast, we show that no reddening sequence exists for odd $n$."
  },
  {
    "date": "2026-01-26",
    "title": "The ALMA-ATOMS survey: Methanol emission in a large sample of hot molecular cores",
    "authors": "Jiahang Zou, Tie Liu, Sheng-Li Qin, Yaping Peng, Fengwei Xu, Xunchuan Liu, Li Chen, Xindi Tang, Sami Dib, Zi-Yang Li, Hong-Li Liu, Mika Juvela, Patricio Sanhueza, Pablo Garcia, Chang Won Lee, Guido Garay, Swagat R. Das, Yan-Kun Zhang, Kee-Tae Kim, Jeong-Eun Lee, Meizhu Liu, Leonardo Bronfman, Zihping Kou, Dongting Yang, Gang Wu, Jihye Hwang, Dezhao Meng, Mengyao Tang, James O. Chibueze",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18628v1",
    "source": "arXiv",
    "abstract": "Methanol (CH$_{3}$OH) is a key complex organic molecule (COM) in the interstellar medium, widely used as a tracer of dense gas and hot molecular cores (HMCs). Using high-resolution ALMA observations from the ATOMS survey, we investigate the excitation and abundance of methanol nuclear spin isomers and their relationship to chemical complexity in massive star-forming cores. We identify 20 methanol transitions, including A- and E-type lines in the v=0 state and E-type lines in the v$_{t}$=1 state, and detect 94 HMC candidates. Rotational temperature analysis under the LTE assumption yields average values of 194 $\\pm$ 33 K for CH$_{3}$OH-E v$_{t}$=1, 178 $\\pm$ 33 K for CH$_{3}$OH-A v=0, and 75 $\\pm$ 33K for CH$_{3}$OH-E v=0. Emission from COMs other than methanol is detected in 87 of the 94 cores, with the CH$_{3}$OH-E v$_{t}$=1 line intensity showing a strong correlation with the channel detection ratio (CDR). These results demonstrate that CH$_{3}$OH-E v$_{t}$=1 lines are reliable tracers of HMCs and chemical complexity, and that the CDR provides a robust indicator of molecular richness. The temperature difference between A- and E-type methanol transitions is driven by anomalously strong J(2,J-2)$-$J(-1,J-1) lines, highlighting the importance of analyzing methanol symmetry types separately."
  },
  {
    "date": "2026-01-26",
    "title": "Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning",
    "authors": "Yingxiao Huo, Satya Prakash Dash, Radu Stoican, Samuel Kaski, Mingfei Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18626v1",
    "source": "arXiv",
    "abstract": "Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines."
  },
  {
    "date": "2026-01-26",
    "title": "CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling",
    "authors": "Panagiotis Lymperopoulos, Abhiramon Rajasekharan, Ian Berlot-Attwell, Stéphane Aroca-Ouellette, Kaheer Suleman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18620v1",
    "source": "arXiv",
    "abstract": "Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines."
  },
  {
    "date": "2026-01-26",
    "title": "Geometry-Free Conditional Diffusion Modeling for Solving the Inverse Electrocardiography Problem",
    "authors": "Ramiro Valdes Jara, Adam Meyers",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18615v1",
    "source": "arXiv",
    "abstract": "This paper proposes a data-driven model for solving the inverse problem of electrocardiography, the mathematical problem that forms the basis of electrocardiographic imaging (ECGI). We present a conditional diffusion framework that learns a probabilistic mapping from noisy body surface signals to heart surface electric potentials. The proposed approach leverages the generative nature of diffusion models to capture the non-unique and underdetermined nature of the ECGI inverse problem, enabling probabilistic sampling of multiple reconstructions rather than a single deterministic estimate. Unlike traditional methods, the proposed framework is geometry-free and purely data-driven, alleviating the need for patient-specific mesh construction. We evaluate the method on a real ECGI dataset and compare it against strong deterministic baselines, including a convolutional neural network, long short-term memory network, and transformer-based model. The results demonstrate that the proposed diffusion approach achieves improved reconstruction accuracy, highlighting the potential of diffusion models as a robust tool for noninvasive cardiac electrophysiology imaging."
  },
  {
    "date": "2026-01-26",
    "title": "Edge States Effects in Quantum Work Statistics",
    "authors": "Moallison F. Cavalcante",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18614v1",
    "source": "arXiv",
    "abstract": "Motivated by the objective of quantifying the energetic cost of accessing boundary phases through local control, we investigate here a simple, analytically tractable quantum impurity model. This model exhibits a rich boundary phase diagram, characterized by phases with different numbers of edge states. By considering a local quench protocol that drives the system out of equilibrium, we calculate exactly the resulting quantum work distribution across these phases. Our results show that the presence of edge states strongly alters this distribution. In particular, we analytically determine key fingerprints of these states both near the low-energy threshold and in the high-energy region."
  },
  {
    "date": "2026-01-26",
    "title": "Polynomials in molecules",
    "authors": "Yan Gao, Jinsong Zeng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18605v1",
    "source": "arXiv",
    "abstract": "This paper characterizes polynomials within molecules. We show that a geometrically finite polynomial of degree $d\\geq2$ lies in a molecule if and only if all its critical points belong to maximal Fatou chains, and show that distinct molecules are mutually disjoint. We also establish a necessary and sufficient condition for subhyperbolic polynomials to be on the closures of bounded hyperbolic components."
  },
  {
    "date": "2026-01-26",
    "title": "Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning",
    "authors": "Miguel Costa, Arthur Vandervoort, Carolin Schmidt, Morten W. Petersen, Martin Drews, Karyn Morrissey, Francisco C. Pereira",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18586v1",
    "source": "arXiv",
    "abstract": "Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities."
  },
  {
    "date": "2026-01-26",
    "title": "The Hasse principle for diagonal forms restricted to a hypersurface of adjacent degree",
    "authors": "Anna Theorin Johansson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18581v1",
    "source": "arXiv",
    "abstract": "We investigate the Hasse principle for Diophantine systems consisting of one diagonal form of degree $k$ and one general form of degree $k-1$. By refining the method of Brandes and Parsell (arXiv:2003.04350) in this specific setting, we improve the bound $n > 2^k k$ to $n > 2^{k-1}(2k-1)$; in particular, the requirement $n > 24$ in the case of degrees three and two is relaxed to $n > 20$."
  },
  {
    "date": "2026-01-26",
    "title": "One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization",
    "authors": "Franziska Weeber, Vera Neplenbroek, Jan Batzner, Sebastian Padó",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18572v1",
    "source": "arXiv",
    "abstract": "Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues."
  },
  {
    "date": "2026-01-26",
    "title": "Well-quasi-ordered classes of bounded clique-width",
    "authors": "Maël Dumas, Aliaume Lopez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18571v1",
    "source": "arXiv",
    "abstract": "We study classes of graphs with bounded clique-width that are well-quasi-ordered by the induced subgraph relation, in the presence of labels on the vertices. We prove that, given a finite presentation of a class of graphs, one can decide whether the class is labelled-well-quasi-ordered. This solves an open problem raised by Daligault, Rao and Thomassé in 2010, and answers positively to two conjectures of Pouzet in the restricted case of bounded clique-width classes. Namely, we prove that being labelled-well-quasi-ordered by a set of size 2 or by a well-quasi-ordered infinite set are equivalent conditions, and that in such cases, one can freely assume that the graphs are equipped with a total ordering on their vertices. Finally, we provide a structural characterization of those classes as those that are of bounded clique-width and do not existentially transduce the class of all finite paths."
  },
  {
    "date": "2026-01-26",
    "title": "Feature-Indexed Federated Recommendation with Residual-Quantized Codebooks",
    "authors": "Mingzhe Han, Jiahao Liu, Dongsheng Li, Hansu Gu, Peng Zhang, Ning Gu, Tun Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18570v1",
    "source": "arXiv",
    "abstract": "Federated recommendation provides a privacy-preserving solution for training recommender systems without centralizing user interactions. However, existing methods follow an ID-indexed communication paradigm that transmit whole item embeddings between clients and the server, which has three major limitations: 1) consumes uncontrollable communication resources, 2) the uploaded item information cannot generalize to related non-interacted items, and 3) is sensitive to client noisy feedback. To solve these problems, it is necessary to fundamentally change the existing ID-indexed communication paradigm. Therefore, we propose a feature-indexed communication paradigm that transmits feature code embeddings as codebooks rather than raw item embeddings. Building on this paradigm, we present RQFedRec, which assigns each item a list of discrete code IDs via Residual Quantization (RQ)-Kmeans. Each client generates and trains code embeddings as codebooks based on discrete code IDs provided by the server, and the server collects and aggregates these codebooks rather than item embeddings. This design makes communication controllable since the codebooks could cover all items, enabling updates to propagate across related items in same code ID. In addition, since code embedding represents many items, which is more robust to a single noisy item. To jointly capture semantic and collaborative information, RQFedRec further adopts a collaborative-semantic dual-channel aggregation with a curriculum strategy that emphasizes semantic codes early and gradually increases the contribution of collaborative codes over training. Extensive experiments on real-world datasets demonstrate that RQFedRec consistently outperforms state-of-the-art federated recommendation baselines while significantly reducing communication overhead."
  },
  {
    "date": "2026-01-26",
    "title": "An LLM-Agent-Based Framework for Age of Information Optimization in Heterogeneous Random Access Networks",
    "authors": "Fang Liu, Erchao Zhu, Jiedan Tan, Jingwen Tong, Taotao Wang, Shengli Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18563v1",
    "source": "arXiv",
    "abstract": "With the rapid expansion of the Internet of Things (IoT) and heterogeneous wireless networks, the Age of Information (AoI) has emerged as a critical metric for evaluating the performance of real-time and personalized systems. While AoI-based random access is essential for next-generation applications such as the low-altitude economy and indoor service robots, existing strategies, ranging from rule-based protocols to learning-based methods, face critical challenges, including idealized model assumptions, slow convergence, and poor generalization. In this article, we propose Reflex-Core, a novel Large Language Model (LLM) agent-based framework for AoI-driven random access in heterogeneous networks. By devising an \"Observe-Reflect-Decide-Execute\" closed-loop mechanism, this framework integrates Supervised Fine-Tuning (SFT) and Proximal Policy Optimization (PPO) to enable optimal, autonomous access control. Based on the Reflex-Core framework, we develop a Reflexive Multiple Access (RMA) protocol and a priority-based RMA variant for intelligent access control under different heterogeneous network settings. Experimental results demonstrate that in the investigated scenarios, the RMA protocol achieves up to a 14.9% reduction in average AoI compared with existing baselines, while the priority-based version improves the convergence rate by approximately 20%."
  },
  {
    "date": "2026-01-26",
    "title": "Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities",
    "authors": "Alberto Purpura, Li Wang, Sahil Badyal, Eugenio Beaufrand, Adam Faulkner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18554v1",
    "source": "arXiv",
    "abstract": "Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions."
  },
  {
    "date": "2026-01-26",
    "title": "Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection",
    "authors": "Devansh Srivastav, David Pape, Lea Schönherr",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18552v1",
    "source": "arXiv",
    "abstract": "LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance."
  },
  {
    "date": "2026-01-26",
    "title": "Resource-Efficient Noise Spectroscopy for Generic Quantum Dephasing Environments",
    "authors": "Yuan-De Jin, Zheng-Fei Ye, Wen-Long Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18290v1",
    "source": "arXiv",
    "abstract": "We present a resource-efficient method based on repetitive weak measurements to directly measure the noise spectrum of a generic quantum environment that causes qubit phase decoherence. The weak measurement is induced by a Ramsey interferometry measurement (RIM) on the qubit and periodically applied during the free evolution of the environment. We prove that the measurement correlation of such repetitive RIMs approximately corresponds to a direct sampling of the noise correlation function, thus enabling direct noise spectroscopy of the environment. Compared to dynamical-decoupling-based noise spectroscopy, this method can efficiently measure the full noise spectrum with the detected frequency range not limited by qubit coherence time. This method is also more resource-efficient than the correlation spectroscopy, as for the same detection accuracy with $N$ sampling times, it takes total detection time $O(N)$ while the latter one takes time $O(N^2)$. We numerically demonstrate this method for both bosonic and spin baths."
  },
  {
    "date": "2026-01-26",
    "title": "Validation of a Software-Defined 100-Gb/s RDMA Streaming Architecture for Ultrafast Optoacoustic and Ultrasound Imaging",
    "authors": "Federico Villani, Christian Vogt, Luca Specht, Jero Schmid, Xiang Liu, Andrea Cossettini, Daniel Razansky, Luca Benini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18280v1",
    "source": "arXiv",
    "abstract": "Optoacoustic (OA) imaging has emerged as a powerful investigation tool, with demonstrated applicability in oncology, neuroscience, and cardiovascular biology. However, its clinical translation is limited with the existing OA systems, which often rely on bulky and expensive acquisition hardware mainly optimized for pulse-echo ultrasound (US) imaging. Despite the fact that OA imaging has different requirements for receive bandwidths and timing synchronization with external laser sources, there is a strong need for unified OA-US imaging platforms, as pulse-echo US remains the standard tool for visualizing soft tissues. To address these challenges, we propose a new data acquisition architecture for ultrafast OA and US imaging that fully covers the requirements for large channel counts, wide bandwidth, and software-defined operation. LtL combines state-of-the-art wideband analog front-ends, a Zynq UltraScale+ MPSoC integrating FPGA fabric with an Application Processing Unit, and a 100 GbE Remote Direct Memory Access (RDMA) backend enabling raw-data streaming at up to 95.6 Gb/s. The architecture avoids local buffers followed by burst transfers, which commonly constrain sustainable frame rate and recording intervals, thus achieving true continuous and sustained streaming of raw data. We validate the core elements of the LtL architecture using a 16-channel demonstration system built from commercial evaluation boards. We further verify the signal chain for up to 256-channel scalability, confirming the wide bandwidth capabilities to support state-of-the-art data transmission speeds."
  },
  {
    "date": "2026-01-26",
    "title": "What Do Learned Models Measure?",
    "authors": "Indrė Žliobaitė",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18278v1",
    "source": "arXiv",
    "abstract": "In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension."
  },
  {
    "date": "2026-01-26",
    "title": "TEFormer: Structured Bidirectional Temporal Enhancement Modeling in Spiking Transformers",
    "authors": "Sicheng Shen, Mingyang Lv, Bing Han, Dongcheng Zhao, Guobin Shen, Feifei Zhao, Yi Zeng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18274v1",
    "source": "arXiv",
    "abstract": "In recent years, Spiking Neural Networks (SNNs) have achieved remarkable progress, with Spiking Transformers emerging as a promising architecture for energy-efficient sequence modeling. However, existing Spiking Transformers still lack a principled mechanism for effective temporal fusion, limiting their ability to fully exploit spatiotemporal dependencies. Inspired by feedforward-feedback modulation in the human visual pathway, we propose TEFormer, the first Spiking Transformer framework that achieves bidirectional temporal fusion by decoupling temporal modeling across its core components. Specifically, TEFormer employs a lightweight and hyperparameter-free forward temporal fusion mechanism in the attention module, enabling fully parallel computation, while incorporating a backward gated recurrent structure in the MLP to aggregate temporal information in reverse order and reinforce temporal consistency. Extensive experiments across a wide range of benchmarks demonstrate that TEFormer consistently and significantly outperforms strong SNN and Spiking Transformer baselines under diverse datasets. Moreover, through the first systematic evaluation of Spiking Transformers under different neural encoding schemes, we show that the performance gains of TEFormer remain stable across encoding choices, indicating that the improved temporal modeling directly translates into reliable accuracy improvements across varied spiking representations. These results collectively establish TEFormer as an effective and general framework for temporal modeling in Spiking Transformers."
  },
  {
    "date": "2026-01-26",
    "title": "Exact Controllability for Stochastic First-Order Multi-Dimensional Hyperbolic Systems",
    "authors": "Zengyu Li, Qi Lü, Yu Wang, Haitian Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18270v1",
    "source": "arXiv",
    "abstract": "This paper investigates the exact controllability problem for multi-dimensional stochastic first-order symmetric hyperbolic systems with control inputs acting in two distinct ways: an internal control applied to the diffusion term and a boundary control applied to the drift term. By means of a classical duality argument, the controllability problem is reduced to an observability estimate for the corresponding backward stochastic system. The main technical contribution is the establishment of a new global Carleman estimate for such backward systems, combined with a weighted energy identity. This enables us to prove the desired observability inequality under a geometric structural condition (Condition \\ref{cond1}), which ensures that all characteristic rays propagate toward the boundary within a finite time. As a result, we obtain exact controllability provided the control time $T$ exceeds a sharp threshold $T_0$ given explicitly in terms of the system geometry. Furthermore, we complement the positive result with several negative controllability theorems, which demonstrate that both controls are necessary and must act in a distributed manner. Our analysis not only extends controllability theory from deterministic to stochastic multi-dimensional hyperbolic systems but also provides, as a byproduct, new results for deterministic systems under a structural hypothesis. Applications to stochastic traffic flow, epidemiological models, and shallow-water equations are discussed."
  },
  {
    "date": "2026-01-26",
    "title": "Efficient Rehearsal for Continual Learning in ASR via Singular Value Tuning",
    "authors": "Steven Vander Eeckt, Hugo Van hamme",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18266v1",
    "source": "arXiv",
    "abstract": "Continual Learning (CL) in Automatic Speech Recognition (ASR) suffers from catastrophic forgetting when adapting to new tasks, domains, or speakers. A common strategy to mitigate this is to store a subset of past data in memory for rehearsal. However, rehearsal-based methods face key limitations: storing data is often costly, infeasible with pre-trained models, or restricted by privacy regulations. Running existing rehearsal-based methods with smaller memory sizes to alleviate these issues usually leads to degraded performance. We propose a rehearsal-based CL method that remains effective even with minimal memory. It operates in two stages: first, fine-tuning on the new task; second, applying Singular Value Decomposition (SVD) to the changes in linear layers and, in a parameter-efficient manner, retraining only gating vectors on the singular values, which control to extent to which updates from the first stage are accepted, using rehearsal. We extensively test and analyze our method on two monolingual and two multilingual benchmarks. Our method reduces forgetting and outperforms state-of-the-art CL approaches for ASR, even when limited to a single utterance per previous task."
  },
  {
    "date": "2026-01-26",
    "title": "Revisiting Aerial Scene Classification on the AID Benchmark",
    "authors": "Subhajeet Das, Susmita Ghosh, Abhiroop Chatterjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18263v1",
    "source": "arXiv",
    "abstract": "Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures."
  },
  {
    "date": "2026-01-26",
    "title": "Algebraic Phase Theory VI: Duality, Reconstruction, and Structural Toolkit Theorems",
    "authors": "Joe Gildea",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18258v1",
    "source": "arXiv",
    "abstract": "We prove that any functorial finite-depth reconstruction framework based on representation theory satisfies a strict dichotomy: it either collapses into a rigid regime or necessarily admits intrinsic structural boundaries. In the non-rigid case, reconstruction is uniquely determined up to canonical boundary collapse, and no boundary-free reconstruction theory with the same formal properties can exist. We establish that algebraic phases are \\emph{information-complete}. Any phase satisfying the axioms of Algebraic Phase Theory (APT) is uniquely determined, up to intrinsic phase equivalence, by its filtered representation category together with its boundary stratification. Reconstruction is exact on rigidity islands and fails globally only through canonical and unavoidable boundary phenomena. We further show that the axioms of APT force a minimal structural toolkit, including canonical finite generation, rigidity--obstruction equivalence, finite-depth boundary detectability, and the existence of universal obstruction objects. These results apply uniformly across all phase models developed in the APT series. Taken together, the results of this paper complete the foundational development of Algebraic Phase Theory and position it as a canonical and inevitable reconstruction framework extending classical duality theories beyond rigid and semisimple regimes."
  },
  {
    "date": "2026-01-26",
    "title": "Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs",
    "authors": "Fei Meng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18255v1",
    "source": "arXiv",
    "abstract": "Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \\textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief \"wake-up\" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded \"safety guarantee\" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning."
  },
  {
    "date": "2026-01-26",
    "title": "Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing",
    "authors": "Chao Wang, Xuanying Li, Cheng Dai, Jinglei Feng, Yuxiang Luo, Yuqi Ouyang, Hao Qin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18252v1",
    "source": "arXiv",
    "abstract": "Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception."
  },
  {
    "date": "2026-01-26",
    "title": "A model for a population of trees structured by phenological traits",
    "authors": "Sirine Boucenna, Vasilis Dakos, Gaël Raoul",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18214v1",
    "source": "arXiv",
    "abstract": "In the context of global warming, tree populations rely on two primary mechanisms of adaptation: phenotypic plasticity, which enables individuals to adjust their behavior in response to environmental stress, and genetic evolution, driven by natural selection and genetic diversity within the population. Understanding the interplay between these mechanisms is crucial for assessing the impacts of climate change on forest ecosystems and for informing sustainable management strategies. In this manuscript, we focus on a specific phenological adaptation: the ability of trees to enter summer dormancy once a critical temperature threshold is exceeded. Individuals are characterized by this threshold temperature and by their seed production capacity. We first establish a detailed mathematical model describing the population dynamics under these traits, and progressively reduce it to a system of two coupled ordinary differential equations. This simpler macroscopic model is then analyzed numerically, to investigate how the population reacts to a shift in its environment: an temperature increase, a drop in precipitation levels, or a combination of the two. Our results highlight contrasting effects of water stress and temperature stress on population dynamics, as well as the ambivalent effect of the plasticity."
  },
  {
    "date": "2026-01-26",
    "title": "Generative Chain of Behavior for User Trajectory Prediction",
    "authors": "Chengkai Huang, Xiaodi Chen, Hongtao Huang, Quan Z. Sheng, Lina Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18213v1",
    "source": "arXiv",
    "abstract": "Modeling long-term user behavior trajectories is essential for understanding evolving preferences and enabling proactive recommendations. However, most sequential recommenders focus on next-item prediction, overlooking dependencies across multiple future actions. We propose Generative Chain of Behavior (GCB), a generative framework that models user interactions as an autoregressive chain of semantic behaviors over multiple future steps. GCB first encodes items into semantic IDs via RQ-VAE with k-means refinement, forming a discrete latent space that preserves semantic proximity. On top of this space, a transformer-based autoregressive generator predicts multi-step future behaviors conditioned on user history, capturing long-horizon intent transitions and generating coherent trajectories. Experiments on benchmark datasets show that GCB consistently outperforms state-of-the-art sequential recommenders in multi-step accuracy and trajectory consistency. Beyond these gains, GCB offers a unified generative formulation for capturing user preference evolution."
  },
  {
    "date": "2026-01-26",
    "title": "Experimental investigation of wall-pressure fluctuations on a fully appended submarine model at high Reynolds numbers",
    "authors": "Peng Jiang, Haoyu Zhang, Yi Dai, Tao Peng, Bin Xie, Shijun Liao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18201v1",
    "source": "arXiv",
    "abstract": "This paper addresses a critical gap in hydroacoustics through a systematic wind tunnel investigation of wall-pressure fluctuations on the fully appended DARPA SUBOFF model at operationally relevant Reynolds numbers ranging from $5.6 \\times 10^{6}$ to $1.4 \\times 10^{7}$. The experimental campaign encompasses baseline straight-ahead flow, complex maneuvering (yaw and pitch) conditions, and a first-of-its-kind assessment of a novel vortex control baffle (VCB). To ensure benchmark-quality spectral data, rigorous signal processing techniques were applied, specifically Wiener filtering for background noise suppression and dynamic transfer function correction for pinhole sensors. Key findings indicate that while spectral self-similarity holds across Reynolds numbers, the primary finding is the critical role of appendages in noise amplification. Unstable horseshoe vortex dynamics at the sail-hull junction drive localized pressure fluctuations of up to 300%, establishing this feature as a major coherent noise source. To address this, the study provides the pioneering experimental validation of the VCB. By physically suppressing horseshoe vortex formation at the sail-hull junction, the VCB achieves a global stabilization of the downstream flow, resulting in a significant 35% reduction in root-mean-square wall-pressure fluctuations at the stern and an approximately 14% reduction along the parallel mid-body. Furthermore, maneuvering conditions are shown to fundamentally reshape the pressure field, introducing substantial crossflow effects and non-monotonic spectral behaviors. This comprehensive dataset and the demonstrated efficacy of the VCB provide essential physical insights and a critical validation benchmark for the design of next-generation quiet submarines."
  },
  {
    "date": "2026-01-26",
    "title": "HeterCSI: Channel-Adaptive Heterogeneous CSI Pretraining Framework for Generalized Wireless Foundation Models",
    "authors": "Chenyu Zhang, Xinchen Lyu, Chenshan Ren, Shuhan Liu, Qimei Cui, Xiaofeng Tao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18200v1",
    "source": "arXiv",
    "abstract": "Wireless foundation models promise transformative capabilities for channel state information (CSI) processing across diverse 6G network applications, yet face fundamental challenges due to the inherent dual heterogeneity of CSI across both scale and scenario dimensions. However, current pretraining approaches either constrain inputs to fixed dimensions or isolate training by scale, limiting the generalization and scalability of wireless foundation models. In this paper, we propose HeterCSI, a channel-adaptive pretraining framework that reconciles training efficiency with robust cross-scenario generalization via a new understanding of gradient dynamics in heterogeneous CSI pretraining. Our key insight reveals that CSI scale heterogeneity primarily causes destructive gradient interference, while scenario diversity actually promotes constructive gradient alignment when properly managed. Specifically, we formulate heterogeneous CSI batch construction as a partitioning optimization problem that minimizes zero-padding overhead while preserving scenario diversity. To solve this, we develop a scale-aware adaptive batching strategy that aligns CSI samples of similar scales, and design a double-masking mechanism to isolate valid signals from padding artifacts. Extensive experiments on 12 datasets demonstrate that HeterCSI establishes a generalized foundation model without scenario-specific finetuning, achieving superior average performance over full-shot baselines. Compared to the state-of-the-art zero-shot benchmark WiFo, it reduces NMSE by 7.19 dB, 4.08 dB, and 5.27 dB for CSI reconstruction, time-domain, and frequency-domain prediction, respectively. The proposed HeterCSI framework also reduces training latency by 53% compared to existing approaches while improving generalization performance by 1.53 dB on average."
  },
  {
    "date": "2026-01-26",
    "title": "UTune: Towards Uncertainty-Aware Online Index Tuning",
    "authors": "Chenning Wu, Sifan Chen, Wentao Wu, Yinan Jing, Zhenying He, Kai Zhang, X. Sean Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18199v1",
    "source": "arXiv",
    "abstract": "There have been a flurry of recent proposals on learned benefit estimators for index tuning. Although these learned estimators show promising improvement over what-if query optimizer calls in terms of the accuracy of estimated index benefit, they face significant limitations when applied to online index tuning, an arguably more common and more challenging scenario in real-world applications. There are two major challenges for learned index benefit estimators in online tuning: (1) limited amount of query execution feedback that can be used to train the models, and (2) constant coming of new unseen queries due to workload drifts. The combination of the two hinders the generalization capability of existing learned index benefit estimators. To overcome these challenges, we present UTune, an uncertainty-aware online index tuning framework that employs operator-level learned models with improved generalization over unseen queries. At the core of UTune is an uncertainty quantification mechanism that characterizes the inherent uncertainty of the operator-level learned models given limited online execution feedback. We further integrate uncertainty information into index selection and configuration enumeration, the key component of any index tuner, by developing a new variant of the classic $ε$-greedy search strategy with uncertainty-weighted index benefits. Experimental evaluation shows that UTune not only significantly improves the workload execution time compared to state-of-the-art online index tuners but also reduces the index exploration overhead, resulting in faster convergence when the workload is relatively stable."
  },
  {
    "date": "2026-01-26",
    "title": "Understanding Interface Stability in RENi2/Ni through First-Principles Calculations",
    "authors": "Yuta Yahagi, Yumi Katasho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18196v1",
    "source": "arXiv",
    "abstract": "Crystallographic orientation analysis revealed that DyNi2 grew epitaxially on Ni, whereas NdNi2 does not. To elucidate the microscopic origin of this contrasting behavior, we constructed atomistic models of Ni/Rare-earth (RE)Ni2 interfaces with well-defined crystallographic alignment and performed first-principles calculations based on density functional theory (DFT). The computed interfacial energies exhibit a clear correlation with lattice mismatch: larger mismatch leads to higher interfacial energy and reduced interface stability. Consequently, Ni/DyNi2 exhibits a significantly lower interfacial energy than Ni/NdNi2, consistent with experimental observations. A comparison between interfacial and strain energies for Ni/RENi2 (RE = Sc, Y, Nd, Gd, Dy, and Lu) reveals that the elemental dependence of interfacial stability is dominated by elastic strain rather than chemical bonding. Based on this insight, we developed a simple regression model using the absolute lattice mismatch as a descriptor, enabling qualitative predictions of stability for Ni/RENi2 interfaces with RE other than those examined in DFT."
  },
  {
    "date": "2026-01-26",
    "title": "Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval",
    "authors": "Yifan Li, Shiying Wang, Jianqiang Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18190v1",
    "source": "arXiv",
    "abstract": "Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP."
  },
  {
    "date": "2026-01-26",
    "title": "VIBEVOICE-ASR Technical Report",
    "authors": "Zhiliang Peng, Jianwei Yu, Yaoyao Chang, Zilong Wang, Li Dong, Yingbo Hao, Yujie Tu, Chenyu Yang, Wenhui Wang, Songchen Xu, Yutao Sun, Hangbo Bao, Weijiang Xu, Yi Zhu, Zehua Wang, Ting Song, Yan Xia, Zewen Chi, Shaohan Huang, Liang Wang, Chuang Ding, Shuai Wang, Xie Chen, Furu Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18184v1",
    "source": "arXiv",
    "abstract": "This report presents VibeVoice-ASR, a general-purpose speech understanding framework built upon VibeVoice, designed to address the persistent challenges of context fragmentation and multi-speaker complexity in long-form audio (e.g., meetings, podcasts) that remain despite recent advancements in short-form speech recognition. Unlike traditional pipelined approaches that rely on audio chunking, VibeVoice-ASRsupports single-pass processing for up to 60 minutes of audio. It unifies Automatic Speech Recognition, Speaker Diarization, and Timestamping into a single end-to-end generation task. In addition, VibeVoice-ASR supports over 50 languages, requires no explicit language setting, and natively handles code-switching within and across utterances. Furthermore, we introduce a prompt-based context injection mechanism that allows users to supply customized conetxt, significantly improving accuracy on domain-specific terminology and polyphonic character disambiguation."
  },
  {
    "date": "2026-01-26",
    "title": "Rotating black holes in the Hernquist galactic halo and its accretion disk luminosity",
    "authors": "Malihe Heydari-Fard, Mohaddese Heydari-Fard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18176v1",
    "source": "arXiv",
    "abstract": "Static, spherically symmetric black holes immersed in a dark matter halo with a Hernquist-type density profile have been derived by Cardoso et. al. in Ref. \\redcite{Cardoso:2021wlq}. Using the Newman-Janis algorithm, we construct the metric for a stationary and axially symmetric rotating black hole in this environment. Then, we obtain the electromagnetic properties of thin accretion disks around such rotating black holes by utilizing the steady-state Novikov-Thorne model, and study the effects of spin parameter and halo compactness parameter on the disk properties. Finally, by comparison the results of the rotating Cardoso black hole with that of Kerr black hole in the absence of dark matter, we find that the presence of dark matter can not significantly affect the disk properties and thus for astrophysical black holes with large spin parameter, the distinction of rotating Cardoso black holes becomes more difficult than the Kerr black hole."
  },
  {
    "date": "2026-01-26",
    "title": "Fine-Grained Emotion Detection on GoEmotions: Experimental Comparison of Classical Machine Learning, BiLSTM, and Transformer Models",
    "authors": "Ani Harutyunyan, Sachin Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18162v1",
    "source": "arXiv",
    "abstract": "Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples."
  },
  {
    "date": "2026-01-26",
    "title": "In-depth analysis of bar formation mechanisms of disk galaxies in halos of different concentrations",
    "authors": "T. Worrakitpoonpon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18161v1",
    "source": "arXiv",
    "abstract": "We use $N$-body simulations to investigate the distinct bar formation processes in disks residing in halos of various concentrations. In a highly concentrated halo, the bar development is limited by the dominant multi-arm modes as a result of the swing amplification in the early stage. Only after the multi-arm modes decay, the bar growth proceeds mechanically owing to the particle trapping in continuation of that bar seed. In this scheme, the corotation resonance of the bar modes does not come into play at all, justified by a low amount of disk-halo angular momentum transfer and a modestly decreasing bar pattern speed. On the other hand, although reducing the halo concentration suggests the reduction of the preferred swing-amplified modes to be bi-symmetric, the bar formation in a lowly concentrated halo does not involve the swing amplification at all. Rather, the fast-growing linearly unstable bar modes of a single uniform frequency is solely the governing factor, attributed to a mild shearing. The bar modes trigger the corotation resonance since the beginning and such resonance is maintained until the end, which leads to a high amount of angular momentum transfer and a fast slowdown. For the intermediate halo concentration, the kinematical analyses of multiple non-axisymmetric modes suggests that the linear modes, the swing amplification, and the particle trapping are all present in the evolution chronology. To specify bars formed in the different halo concentrations, full analyses of the isophotal shape, the radial Fourier amplitude, and the resonance diagram can be of use."
  },
  {
    "date": "2026-01-26",
    "title": "Agentic Very Long Video Understanding",
    "authors": "Aniket Rege, Arka Sadhu, Yuliang Li, Kejie Li, Ramya Korlakai Vinayak, Yuning Chai, Yong Jae Lee, Hyo Jin Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18157v1",
    "source": "arXiv",
    "abstract": "The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks."
  },
  {
    "date": "2026-01-26",
    "title": "EndoExtract: Co-Designing Structured Text Extraction from Endometriosis Ultrasound Reports",
    "authors": "Haiyi Li, Yiyang Zhao, Yutong Li, Alison Deslandes, Jodie Avery, Mary Louise Hull, Hsiang-Ting Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18154v1",
    "source": "arXiv",
    "abstract": "Endometriosis ultrasound reports are often unstructured free-text documents that require manual abstraction for downstream tasks such as analytics, machine learning model training, and clinical auditing. We present \\textbf{EndoExtract}, an on-premise LLM-powered system that extracts structured data from these reports and surfaces interpretive fields for human review. Through contextual inquiry with research assistants, we identified key workflow pain points: asymmetric trust between numerical and interpretive fields, repetitive manual highlighting, fatigue from sustained comparison, and terminology inconsistency across radiologists. These findings informed an interface that surfaces only interpretive fields for mandatory review, automatically highlights source evidence within PDFs, and separates batch extraction from human-paced verification. A formative workshop revealed that \\textbf{EndoExtract} supports a shift from field-by-field data entry to supervisory validation, though participants noted risks of over-skimming and challenges in managing missing data."
  },
  {
    "date": "2026-01-26",
    "title": "FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning",
    "authors": "Zhaopeng Qiu, Shuang Yu, Jingqi Zhang, Shuai Zhang, Xue Huang, Jingyi Yang, Junjie Lai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18150v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines."
  },
  {
    "date": "2026-01-26",
    "title": "Enhance the Safety in Reinforcement Learning by ADRC Lagrangian Methods",
    "authors": "Mingxu Zhang, Huicheng Zhang, Jiaming Ji, Yaodong Yang, Ying Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18142v1",
    "source": "arXiv",
    "abstract": "Safe reinforcement learning (Safe RL) seeks to maximize rewards while satisfying safety constraints, typically addressed through Lagrangian-based methods. However, existing approaches, including PID and classical Lagrangian methods, suffer from oscillations and frequent safety violations due to parameter sensitivity and inherent phase lag. To address these limitations, we propose ADRC-Lagrangian methods that leverage Active Disturbance Rejection Control (ADRC) for enhanced robustness and reduced oscillations. Our unified framework encompasses classical and PID Lagrangian methods as special cases while significantly improving safety performance. Extensive experiments demonstrate that our approach reduces safety violations by up to 74%, constraint violation magnitudes by 89%, and average costs by 67\\%, establishing superior effectiveness for Safe RL in complex environments."
  },
  {
    "date": "2026-01-26",
    "title": "Twisted scalar curvature as a moment map",
    "authors": "Ruadhaí Dervan, Thomas Murphy, Julius Ross, Lars Martin Sektnan, Xiaowei Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18141v1",
    "source": "arXiv",
    "abstract": "We develop the moment map theory of the twisted scalar curvature of a Kähler metric. Primarily, we introduce a coupled system of equations on a holomorphic submersion intertwining the twisted scalar curvature of a Kähler metric on the base and the fibrewise scalar curvature of a relatively Kähler metric on the total space. This resulting system can be viewed as producing the natural coupled metric geometry of holomorphic submersions, and we show that this system appears canonically as a moment map. The approach generalises to foliations, where we prove similar results."
  },
  {
    "date": "2026-01-26",
    "title": "RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening",
    "authors": "Xi Chen, Hongru Zhou, Huahui Yi, Shiyu Feng, Hanyu Zhou, Tiancheng He, Mingke You, Li Wang, Qiankun Li, Kun Wang, Weili Fu, Kang Li, Jian Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18132v1",
    "source": "arXiv",
    "abstract": "Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment."
  },
  {
    "date": "2026-01-26",
    "title": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models",
    "authors": "Kunat Pipatanakul, Pittawat Taveekitworachai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18129v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources."
  },
  {
    "date": "2026-01-26",
    "title": "LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment",
    "authors": "Daeyoung Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18118v1",
    "source": "arXiv",
    "abstract": "Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%."
  },
  {
    "date": "2026-01-26",
    "title": "Broadband asymmetric transmission with tunable bilayer silicon nanoarrays: from visible to near-infrared",
    "authors": "Ruihan Ma, Yuqing Cheng, Mengtao Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18104v1",
    "source": "arXiv",
    "abstract": "A kind of asymmetric transmission (AT) device based on bilayer silicon arrays (BSA) nanostructure is theoretically explored, which achieves high forward transmissivity and suppressed backward transmissivity for broadband by simply adjusting the parameters of the structure. The structure consists of two silicon cylinder arrays, one on the SiO2 substrate and the other embedded in the substrate. Particularly, three AT devices with different configurations are designed, which exhibit broadband AT with high isolation ratios in the wavelength ranges of 685-807 nm, 866-1029 nm, and 1285-1536 nm, respectively. A comprehensive analysis of the BSA structure's performance across different array periods highlights its potential for broadband optical applications, such as optical isolation and multi-channel optical sensors."
  },
  {
    "date": "2026-01-26",
    "title": "Enhancing LLM-based Recommendation with Preference Hint Discovery from Knowledge Graph",
    "authors": "Yuting Zhang, Ziliang Pei, Chao Wang, Ying Sun, Fuzhen Zhuang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18096v1",
    "source": "arXiv",
    "abstract": "LLMs have garnered substantial attention in recommendation systems. Yet they fall short of traditional recommenders when capturing complex preference patterns. Recent works have tried integrating traditional recommendation embeddings into LLMs to resolve this issue, yet a core gap persists between their continuous embedding and discrete semantic spaces. Intuitively, textual attributes derived from interactions can serve as critical preference rationales for LLMs' recommendation logic. However, directly inputting such attribute knowledge presents two core challenges: (1) Deficiency of sparse interactions in reflecting preference hints for unseen items; (2) Substantial noise introduction from treating all attributes as hints. To this end, we propose a preference hint discovery model based on the interaction-integrated knowledge graph, enhancing LLM-based recommendation. It utilizes traditional recommendation principles to selectively extract crucial attributes as hints. Specifically, we design a collaborative preference hint extraction schema, which utilizes semantic knowledge from similar users' explicit interactions as hints for unseen items. Furthermore, we develop an instance-wise dual-attention mechanism to quantify the preference credibility of candidate attributes, identifying hints specific to each unseen item. Using these item- and user-based hints, we adopt a flattened hint organization method to shorten input length and feed the textual hint information to the LLM for commonsense reasoning. Extensive experiments on both pair-wise and list-wise recommendation tasks verify the effectiveness of our proposed framework, indicating an average relative improvement of over 3.02% against baselines."
  },
  {
    "date": "2026-01-26",
    "title": "From Struggle to Success: Context-Aware Guidance for Screen Reader Users in Computer Use",
    "authors": "Nan Chen, Jing Lu, Zilong Wang, Luna K. Qiu, Siming Chen, Yuqing Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18092v1",
    "source": "arXiv",
    "abstract": "Equal access to digital technologies is critical for education, employment, and social participation. However, mainstream interfaces are visually oriented, creating steep learning curves and frequent obstacles for screen reader users, and limiting their independence and opportunities. Existing support is inadequate -- tutorials mainly target sighted users, while human assistance lacks real-time availability. We introduce AskEase, an on-demand AI assistant that provides step-by-step, screen reader user-friendly guidance for computer use. AskEase manages multiple sources of context to infer user intent and deliver precise, situation-specific guidance. Its seamless interaction design minimizes disruption and reduces the effort of seeking help. We demonstrated its effectiveness through representative usage scenarios and robustness tests. In a within-subjects study with 12 screen reader users, AskEase significantly improved task success while reducing perceived workload, including physical demand, effort, and frustration. These results demonstrate the potential of LLM-powered assistants to promote accessible computing and expand opportunities for users with visual impairments."
  },
  {
    "date": "2026-01-26",
    "title": "On Extending Type $B$ Parking Spaces",
    "authors": "Anthony Adams, Joshua Dorsam, Lily Levitsky, Megan Mann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18090v1",
    "source": "arXiv",
    "abstract": "Armstrong, Reiner, and Rhoades defined for all Weyl groups $W$ a natural representation of $W$ called the $W$-parking space. The type $B$ parking space is the representation $\\mathbb{C}[(\\mathbb{Z}/(2n+1)\\mathbb{Z})^n]$ of the $n$th signed symmetric group. We consider more general representations of the form $\\mathbb{C}[(\\mathbb{Z}/m\\mathbb{Z})^n]$; we conjecture that this representation extends to the $(n+1)$th signed symmetric group for all $n$ and $m$. We prove this conjecture when $m = 3$ or when $n \\leq 2$."
  },
  {
    "date": "2026-01-26",
    "title": "From Human Speech to Ocean Signals: Transferring Speech Large Models for Underwater Acoustic Target Recognition",
    "authors": "Mengcheng Huang, Xue Zhou, Chen Xu, Dapeng Man",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18086v1",
    "source": "arXiv",
    "abstract": "Underwater acoustic target recognition (UATR) plays a vital role in marine applications but remains challenging due to limited labeled data and the complexity of ocean environments. This paper explores a central question: can speech large models (SLMs), trained on massive human speech corpora, be effectively transferred to underwater acoustics? To investigate this, we propose UATR-SLM, a simple framework that reuses the speech feature pipeline, adapts the SLM as an acoustic encoder, and adds a lightweight classifier.Experiments on the DeepShip and ShipsEar benchmarks show that UATR-SLM achieves over 99% in-domain accuracy, maintains strong robustness across variable signal lengths, and reaches up to 96.67% accuracy in cross-domain evaluation. These results highlight the strong transferability of SLMs to UATR, establishing a promising paradigm for leveraging speech foundation models in underwater acoustics."
  },
  {
    "date": "2026-01-26",
    "title": "Two-Polariton Blockade via Ultrastrong Light-Matter Coupling",
    "authors": "Ting-Ting Ma, Jian Tang, Yun-Lan Zuo, Ran Huang. Adam Miranowicz, Franco Nori, Hui Jing",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18083v1",
    "source": "arXiv",
    "abstract": "We demonstrate that a two-polariton blockade (2PB) can occur under resonant single-polariton driving in an atom-cavity system operating in the ultrastrong coupling (USC) regime-a phenomenon qualitatively distinct from, and unattainable in, both the strong and weak coupling regimes. In the USC regime, where the ratio of the atom-cavity coupling strength to the cavity resonance frequency exceeds 0.1, hybrid light-matter quasiparticles known as polaritons emerge. By employing modified second- and third-order correlation functions appropriate for the USC regime, we predict the emergence of 2PB, characterized by pronounced two-polariton bunching accompanied by suppressed three-polariton coincidences. This Letter introduces a novel route to achieving 2PB, with promising implications for the realization of multiparticle quantum light sources in the USC regime."
  },
  {
    "date": "2026-01-26",
    "title": "DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal",
    "authors": "Peixuan Han, Yingjie Yu, Jingjun Xu, Jiaxuan You",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18081v1",
    "source": "arXiv",
    "abstract": "Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at https://github.com/ulab-uiuc/DRPG-RebuttalAgent."
  },
  {
    "date": "2026-01-26",
    "title": "Theoretical study of $f_0(980)$, $a_0(980)$ and $Ξ(1/2^-)$ in the process $Ξ_c^+ \\to Σ^+K^+K^-$",
    "authors": "Ruitian Li, Xuan Luo, Hao Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18078v1",
    "source": "arXiv",
    "abstract": "We employed the chiral unitarity approach to investigate the decay process $Ξ_c^+ \\to Σ^+K^+K^-$. by considering that the low lying nucleon resonance $Ξ(1/2^-)$ and the low lying scalar meson $f_0(980)$ and $a_0(980)$ that could be dynamically generated through $S$-wave pseudoscalar meson-octet baryon and the $S$-wave pseudoscalar meson-pseudoscalar meson interactions, respectively. In the invariant mass distributions of $Σ^+K^-$ and $K^+K^-$, we observe a distinct peak structure associated with the resonant state $Ξ(1/2^-)$ and a bit enhancement near the $K^+K^-$ threshold that is corresponding to the mesons $f_0(980)$ and $a_0(980)$, respectively. Consequently, we recommend more precise experimental measurements of this process in the future."
  },
  {
    "date": "2026-01-26",
    "title": "Maximum-Variance-Reduction Stratification for Improved Subsampling",
    "authors": "Dingyi Wang, Haiying Wang, Qingpei Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18075v1",
    "source": "arXiv",
    "abstract": "Subsampling is a widely used and effective approach for addressing the computational challenges posed by massive datasets. Substantial progress has been made in developing non-uniform, probability-based subsampling schemes that prioritize more informative observations. We propose a novel stratification mechanism that can be combined with existing subsampling designs to further improve estimation efficiency. We establish the estimator's asymptotic normality and quantify the resulting efficiency gains, which enables a principled procedure for selecting stratification variables and interval boundaries that target reductions in asymptotic variance. The resulting algorithm, Maximum-Variance-Reduction Stratification (MVRS), achieves significant improvements in estimation efficiency while incurring only linear additional computational cost. MVRS is applicable to both non-uniform and uniform subsampling methods. Experiments on simulated and real datasets confirm that MVRS markedly reduces estimator variance and improves accuracy compared with existing subsampling methods."
  },
  {
    "date": "2026-01-26",
    "title": "The effect of collinearity and sample size on linear regression results: a simulation study",
    "authors": "Stephanie CC van der Lubbe, Jose M Valderas, Evangelos Kontopantelis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18072v1",
    "source": "arXiv",
    "abstract": "Background: Multicollinearity inflates the variance of OLS coefficients, widening confidence intervals and reducing inferential reliability. Yet fixed variance inflation factor (VIF) cut-offs are often applied uniformly across studies with very different sample sizes, even though collinearity is a finite-sample problem. We quantify how collinearity and sample size jointly affect linear regression performance and provide practical guidance for interpreting VIFs. Methods: We simulated data across sample sizes N=100-100,000 and collinearity levels VIF=1-50. For each scenario we generated 1,000 datasets, fitted OLS models, and assessed coverage, mean absolute error (MAE), bias, traditional power (CI excludes 0), and precision assurance (probability the 95% CI lies within a prespecified margin around the true effect). We also evaluated a biased, misspecified setting by omitting a relevant predictor to study bias amplification. Results: Under correct specification, collinearity did not materially affect nominal coverage and did not introduce systematic bias, but it reduced precision in small samples: at N=100, even mild collinearity (VIF<2) inflated MAE and markedly reduced both power metrics, whereas at N>=50,000 estimates were robust even at VIF=50. Under misspecification, collinearity strongly amplified bias, increasing errors, reducing coverage, and sharply degrading both precision assurance and traditional power even at low VIF. Conclusion: VIF thresholds should not be applied mechanically. Collinearity must be interpreted in relation to sample size and potential sources of bias; removing predictors solely to reduce VIF can worsen inference via omitted-variable bias. The accompanying heatmaps provide a practical reference across study sizes and modelling assumptions."
  },
  {
    "date": "2026-01-26",
    "title": "EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization",
    "authors": "Wei-Po Hsin, Ren-Hao Deng, Yao-Ting Hsieh, En-Ming Huang, Shih-Hao Hung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18067v1",
    "source": "arXiv",
    "abstract": "Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL."
  },
  {
    "date": "2026-01-26",
    "title": "Differentiable Architecture Search for Adversarially Robust Quantum Computer Vision",
    "authors": "Mohamed Afane, Quanjiang Long, Haoting Shen, Ying Mao, Junaid Farooq, Ying Wang, Juntao Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18058v1",
    "source": "arXiv",
    "abstract": "Current quantum neural networks suffer from extreme sensitivity to both adversarial perturbations and hardware noise, creating a significant barrier to real-world deployment. Existing robustness techniques typically sacrifice clean accuracy or require prohibitive computational resources. We propose a hybrid quantum-classical Differentiable Quantum Architecture Search (DQAS) framework that addresses these limitations by jointly optimizing circuit structure and robustness through gradient-based methods. Our approach enhances traditional DQAS with a lightweight Classical Noise Layer applied before quantum processing, enabling simultaneous optimization of gate selection and noise parameters. This design preserves the quantum circuit's integrity while introducing trainable perturbations that enhance robustness without compromising standard performance. Experimental validation on MNIST, FashionMNIST, and CIFAR datasets shows consistent improvements in both clean and adversarial accuracy compared to existing quantum architecture search methods. Under various attack scenarios, including Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), Basic Iterative Method (BIM), and Momentum Iterative Method (MIM), and under realistic quantum noise conditions, our hybrid framework maintains superior performance. Testing on actual quantum hardware confirms the practical viability of discovered architectures. These results demonstrate that strategic classical preprocessing combined with differentiable quantum architecture optimization can significantly enhance quantum neural network robustness while maintaining computational efficiency."
  },
  {
    "date": "2026-01-26",
    "title": "Equivalent computational problems for superspecial abelian surfaces",
    "authors": "Mickaël Montessinos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18050v1",
    "source": "arXiv",
    "abstract": "We show reductions and equivalences between various problems related to the computation of the endomorphism ring of principally polarised superspecial abelian surfaces. Problems considered are the computation of the Ibukiyama-Katsura-Oort matrix and computation of unpolarised isomoprhisms between superspecial abelian surfaces."
  },
  {
    "date": "2026-01-26",
    "title": "Certifying optimal device-independent quantum randomness in quantum networks",
    "authors": "Shuai Zhao, Rong Wang, Qi Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18534v1",
    "source": "arXiv",
    "abstract": "Bell nonlocality provides a device-independent (DI) way to certify quantum randomness, based on which true random numbers can be extracted from the observed correlations without detail characterizations on devices for quantum state preparation and measurement. However, the efficiency of current strategies for DI randomness certification is still heavily constrained when it comes to non-maximal Bell values, especially for multiple parties. Here, we present a family of multipartite Bell inequalities that allows to certify optimal quantum randomness and self-test GHZ (Greenberger-Horne-Zeilinger) states, which are inspired from the stabilizer group of the GHZ state. Due to the simple representation of stabilizer group for GHZ states, this family of Bell inequalities is of simple structure and can be easily expanded to more parties. Compared with the Mermin-type inequalities, this family of Bell inequality is more efficient in certifying quantum randomness when non-maximal Bell values achieved. Meanwhile, the general analytical upper bound for the Holevo quantity is presented, and achieves better performance compared with the MABK (Mermin-Ardehali-Belinskii-Klyshko) inequality, Parity-CHSH (Clauser-Horne-Shimony-Holt) inequality and Holz inequality at $N=3$, which is of particular interests for experimental researches on DI quantum cryptography in quantum networks."
  },
  {
    "date": "2026-01-26",
    "title": "Closing the Modality Gap Aligns Group-Wise Semantics",
    "authors": "Eleonora Grassucci, Giordano Cicchetti, Emanuele Frasca, Aurelio Uncini, Danilo Comminiello",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18525v1",
    "source": "arXiv",
    "abstract": "In multimodal learning, CLIP has been recognized as the \\textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping."
  },
  {
    "date": "2026-01-26",
    "title": "Ribbons from Independence Structure: Hypercontractivity, $Φ$-Mutual Information, and Matrix $Φ$-Entropy",
    "authors": "Chenyu Wang, Amin Gohari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18516v1",
    "source": "arXiv",
    "abstract": "We study the hypercontractivity ribbon and the $Φ$-ribbon for joint distributions that obey a given independence structure, obtaining tight bounds in some basic regimes. For general independence structures, modeled as a hypergraph whose hyperedges specify mutually independent subcollections of random variables, we provide an explicit inner bound on the $Φ$-ribbon described by a simple convex hull of incidence vectors. We also provide a new multipartite generalization version and a $Φ$-mutual information analogue of the Zhang--Yeung inequality, which implies nontrivial points in the hypercontractivity ribbon and the $Φ$-ribbon respectively. Finally, we propose the matrix $Φ$-ribbon based on matrix $Φ$-entropy and establish the tensorization and data processing properties, together with the calculation of an exact matrix SDPI constant for the doubly symmetric binary source."
  },
  {
    "date": "2026-01-26",
    "title": "Simultaneous determination of multiple low-lying energy levels on a superconducting quantum processor",
    "authors": "Huili Zhang, Yibin Guo, Guanglei Xu, Yulong Feng, Jingning Zhang, Hai-feng Yu, S. P. Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18514v1",
    "source": "arXiv",
    "abstract": "Determining the ground and low-lying excited states is critical in numerous scenarios. Recent work has proposed the ancilla-entangled variational quantum eigensolver (AEVQE) that utilizes entanglement between ancilla and physical qubits to simultaneously tagert multiple low-lying energy levels. In this work, we report the experimental implementation of the AEVQE on a superconducting quantum cloud platform, demonstrating the full procedure of solving the low-lying energy levels of the H$_2$ molecule and the transverse-field Ising models (TFIMs). We obtain the potential energy curves of H$_2$ and show an indication of the ferromagnetic to paramagnetic phase transition in the TFIMs from the average absolute magnetization. Moreover, we investigate multiple factors that affect the algorithmic performance and provide a comparison with ancilla-free VQE algorithms. Our work demonstrates the experimental feasibility of the AEVQE algorithm and offers a guidance for the VQE approach in solving realistic problems on publicly-accessible quantum platforms."
  },
  {
    "date": "2026-01-26",
    "title": "Robust additive bases without minimal subbases",
    "authors": "Daniel Larsen, Michael Larsen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18507v1",
    "source": "arXiv",
    "abstract": "There exists a set $A$ of positive integers such that the number of representations of a large positive integer $m$ as a sum of two elements of $A$ grows with a lower bound of order $\\log m$, but for which there is no subset $D$ of $A$ minimal for the property that $D+D$ contains all sufficiently large positive integers."
  },
  {
    "date": "2026-01-26",
    "title": "On the Asymptotic Behavior of Guessing Sequences",
    "authors": "Tom Benhamou, Sean LeClair",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18502v1",
    "source": "arXiv",
    "abstract": "We continue the study of probabilistic and topological properties of the set of reals that are being guessed by a diamond sequence from \\cite{Benhamou_Wu}. We show that the existence of sequence of a asymptotic growth $π$ which infinitely guesses a probability one set is equivalent to the divergence of $\\sum_{n=0}^{\\infty}\\frac{π(n)}{2^n}$. We then provide concrete examples for guessing sequences of certain low asymptotic growth using random walks. Finally, we show that the ultrafilter construction from \\cite{Benhamou_Wu} always yield an ultrafilters and a sequence which guesses a meager set, while a simple construction using Cohen forcing gives a non-meager set of guessed reals. These results answer \\cite[Question 6.13]{Benhamou_Wu} and partially addresses \\cite[Question 6.8]{Benhamou_Wu}."
  },
  {
    "date": "2026-01-26",
    "title": "BAIT: Visual-illusion-inspired Privacy Preservation for Mobile Data Visualization",
    "authors": "Sizhe Cheng, Songheng Zhang, Dong Ma, Yong Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18497v1",
    "source": "arXiv",
    "abstract": "With the prevalence of mobile data visualizations, there have been growing concerns about their privacy risks, especially shoulder surfing attacks. Inspired by prior research on visual illusion, we propose BAIT, a novel approach to automatically generate privacy-preserving visualizations by stacking a decoy visualization over a given visualization. It allows visualization owners at proximity to clearly discern the original visualization and makes shoulder surfers at a distance be misled by the decoy visualization, by adjusting different visual channels of a decoy visualization (e.g., shape, position, tilt, size, color and spatial frequency). We explicitly model human perception effect at different viewing distances to optimize the decoy visualization design. Privacy-preserving examples and two in-depth user studies demonstrate the effectiveness of BAIT in both controlled lab study and real-world scenarios."
  },
  {
    "date": "2026-01-26",
    "title": "Fluctuation of fission observables investigated with a Monte Carlo method",
    "authors": "Alice Bernard, David Regnier, Junah Newsome, Paul Carpentier, Noël Dubray, Nathalie Pillet",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18488v1",
    "source": "arXiv",
    "abstract": "Nuclear fission dynamics described within nuclear energy density functional frameworks (EDF) have seen substantial advances in the last decade. Part of this success stems from projection techniques, which allow the computation f probability distribution functions (pdf) for selected observables such as particle number and angular momentum of the fragments. Predicting the pdf of other observables, such as the total kinetic energy of the fragments, remains undone. This work proposes a method to determine the complete pdf of a new category of observables from a Bogoliubov vacuum projected onto good particle number. It relies on sampling nucleonic configurations in coordinate and intrinsic-spin representation. We assess the feasibility and convergence properties of the method and apply it to states representative of the scission of an actinide. Fluctuations in fragment shapes, inter-fragment Coulomb and nuclear interaction as well as the corresponding torques are analyzed. We find that a significant fraction of the fluctuation of several measured fission observables is already present within the mean-field picture."
  },
  {
    "date": "2026-01-26",
    "title": "An Audit of Machine Learning Experiments on Software Defect Prediction",
    "authors": "Giuseppe Destefanis, Leila Yousefi, Martin Shepperd, Allan Tucker, Stephen Swift, Steve Counsell, Mahir Arzoky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18477v1",
    "source": "arXiv",
    "abstract": "Background: Machine learning algorithms are widely used to predict defect prone software components. In this literature, computational experiments are the main means of evaluation, and the credibility of results depends on experimental design and reporting. Objective: This paper audits recent software defect prediction (SDP) studies by assessing their experimental design, analysis, and reporting practices against accepted norms from statistics, machine learning, and empirical software engineering. The aim is to characterise current practice and assess the reproducibility of published results. Method: We audited SDP studies indexed in SCOPUS between 2019 and 2023, focusing on design and analysis choices such as outcome measures, out of sample validation strategies, and the use of statistical inference. Nine study issues were evaluated. Reproducibility was assessed using the instrument proposed by González Barahona and Robles. Results: The search identified approximately 1,585 SDP experiments published during the period. From these, we randomly sampled 101 papers, including 61 journal and 40 conference publications, with almost 50 percent behind paywalls. We observed substantial variation in research practice. The number of datasets ranged from 1 to 365, learners or learner variants from 1 to 34, and performance measures from 1 to 9. About 45 percent of studies applied formal statistical inference. Across the sample, we identified 427 issues, with a median of four per paper, and only one paper without issues. Reproducibility ranged from near complete to severely limited. We also identified two cases of tortured phrases and possible paper mill activity. Conclusions: Experimental design and reporting practices vary widely, and almost half of the studies provide insufficient detail to support reproduction. The audit indicates substantial scope for improvement."
  },
  {
    "date": "2026-01-26",
    "title": "Finite-Aperture Fluid Antenna Array Design: Analysis and Algorithm",
    "authors": "Zhentian Zhang, Kai-Kit Wong, Hao Jiang, Farshad Rostami Ghadi, Hyundong Shin, Yangyang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18471v1",
    "source": "arXiv",
    "abstract": "Finite-aperture constraints render array design nontrivial and can undermine the effectiveness of classical sparse geometries. This letter provides universal guidance for fluid antenna array (FAA) design under a fixed aperture. We derive a closed-form Cramér--Rao bound (CRB) that unifies conventional and reconfigurable arrays by explicitly linking the Fisher information to the geometric variance of port locations. We further obtain a closed-form probability density function of the minimum spacing under random FAA placement, which yields a principled lower bound for the minimum-spacing constraint. Building upon these analytical insights, we then propose a gradient-based algorithm to optimize continuous port locations. Utilizing a simple gradient update design, the optimized FAA can achieve about a $30\\%$ CRB reduction and a $42.5\\%$ reduction in mean-squared error."
  },
  {
    "date": "2026-01-26",
    "title": "Unstable Interface Dynamics for Gravity Stokes Flow",
    "authors": "Francisco Gancedo, Rafael Granero-Belinchón, Zhongtian Hu, Elena Salguero, Yao Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18460v1",
    "source": "arXiv",
    "abstract": "We investigate some unstable behavior of the interface given by two incompressible fluids of different densities evolving by the regular Stokes law with gravity force. In the unstable scenario, where the denser fluid lies above the lighter fluid, we prove infinite-in-time growth of the length or the curvature of the interface. We support these analytical results with numerical simulations that confirm the predicted growth phenomena. In the stable configuration, where the denser fluid lies below the lighter fluid, we show that certain initial configurations evolve into the unstable regime in finite time."
  },
  {
    "date": "2026-01-26",
    "title": "Token-level Collaborative Alignment for LLM-based Generative Recommendation",
    "authors": "Fake Lin, Binbin Hu, Zhi Zheng, Xi Zhu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Tong Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18457v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated strong potential for generative recommendation by leveraging rich semantic knowledge. However, existing LLM-based recommender systems struggle to effectively incorporate collaborative filtering (CF) signals, due to a fundamental mismatch between item-level preference modeling in CF and token-level next-token prediction (NTP) optimization in LLMs. Prior approaches typically treat CF as contextual hints or representation bias, and resort to multi-stage training to reduce behavioral semantic space discrepancies, leaving CF unable to explicitly regulate LLM generation. In this work, we propose Token-level Collaborative Alignment for Recommendation (TCA4Rec), a model-agnostic and plug-and-play framework that establishes an explicit optimization-level interface between CF supervision and LLM generation. TCA4Rec consists of (i) Collaborative Tokenizer, which projects raw item-level CF logits into token-level distributions aligned with the LLM token space, and (ii) Soft Label Alignment, which integrates these CF-informed distributions with one-hot supervision to optimize a soft NTP objective. This design preserves the generative nature of LLM training while enabling collaborative alignment with essential user preference of CF models. We highlight TCA4Rec is compatible with arbitrary traditional CF models and generalizes across a wide range of decoder-based LLM recommender architectures. Moreover, it provides an explicit mechanism to balance behavioral alignment and semantic fluency, yielding generative recommendations that are both accurate and controllable. Extensive experiments demonstrate that TCA4Rec consistently improves recommendation performance across a broad spectrum of CF models and LLM-based recommender systems."
  },
  {
    "date": "2026-01-26",
    "title": "Geneses: Unified Generative Speech Enhancement and Separation",
    "authors": "Kohei Asai, Wataru Nakata, Yuki Saito, Hiroshi Saruwatari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18456v1",
    "source": "arXiv",
    "abstract": "Real-world audio recordings often contain multiple speakers and various degradations, which limit both the quantity and quality of speech data available for building state-of-the-art speech processing models. Although end-to-end approaches that concatenate speech enhancement (SE) and speech separation (SS) to obtain a clean speech signal for each speaker are promising, conventional SE-SS methods suffer from complex degradations beyond additive noise. To this end, we propose \\textbf{Geneses}, a generative framework to achieve unified, high-quality SE--SS. Our Geneses leverages latent flow matching to estimate each speaker's clean speech features using multi-modal diffusion Transformer conditioned on self-supervised learning representation from noisy mixture. We conduct experimental evaluation using two-speaker mixtures from LibriTTS-R under two conditions: additive-noise-only and complex degradations. The results demonstrate that Geneses significantly outperforms a conventional mask-based SE--SS method across various objective metrics with high robustness against complex degradations. Audio samples are available in our demo page."
  },
  {
    "date": "2026-01-26",
    "title": "Hamiltonian formulation of the $1+1$-dimensional $φ^4$ theory in a momentum-space Daubechies wavelet basis",
    "authors": "Mrinmoy Basak, Debsubhra Chakraborty, Nilmani Mathur, Raghunath Ratabole",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18449v1",
    "source": "arXiv",
    "abstract": "We apply the wavelet formalism of quantum field theory to investigate nonperturbative dynamics within the Hamiltonian framework. In particular, we employ Daubechies wavelets in momentum space, whose basis functions are labeled by resolution and translation indices, providing a natural nonperturbative truncation of both infrared and ultraviolet truncation of quantum field theories. As an application, we compute the energy spectra of a free scalar field theory and the interacting $1+1$-dimensional $φ^4$ theory. This approach successfully reproduces the well-known strong-coupling phase transition in the $m^2 > 0$ regime. We find that the extracted critical coupling systematically converges toward its established value as the momentum resolution is increased, demonstrating the effectiveness of the wavelet-based Hamiltonian formulation for nonperturbative field-theoretic calculations."
  },
  {
    "date": "2026-01-26",
    "title": "GCFX: Generative Counterfactual Explanations for Deep Graph Models at the Model Level",
    "authors": "Jinlong Hu, Jiacheng Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18447v1",
    "source": "arXiv",
    "abstract": "Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations."
  },
  {
    "date": "2026-01-26",
    "title": "On the Optimal Message Size in PIR Under Arbitrary Collusion Patterns",
    "authors": "Guru S. Dornadula, Manikya Pant, Gowtham R. Kurri, Prasad Krishnan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18440v1",
    "source": "arXiv",
    "abstract": "A private information retrieval protocol (PIR) scheme under an arbitrary collusion pattern $\\mathcal{P}$ enables a client to retrieve one message from a library of $K$ equal-sized messages duplicated in $N$ servers, while keeping the index of the desired message private from any colluding set in $\\mathcal{P}$. Although achieving high rates typically requires sufficiently large message sizes, smaller message sizes also desirable due to reduced implementation complexity and fewer constraints. By characterizing the capacity-achieving schemes, Tian, Sun, and Chen (2019) showed that the optimal message size for uniformly decomposable PIR schemes under no-collusion setting is $N-1$. However, comparable results are not yet available for more general collusion settings. In this work, we present a complete characterization of the properties of capacity-achieving decomposable PIR schemes under arbitrary collusion patterns. Building on this characterization, we derive a general lower bound on the optimal message size for capacity-achieving uniformly decomposable PIR schemes under an arbitrary collusion pattern $\\mathcal{P}$, expressed in terms of the hitting number of a newly defined family of subsets of servers determined by the collusion pattern $\\mathcal{P}$. Finally, we specialize the lower bound to several important classes of collusion patterns, including $T$-collusion, disjoint collections of colluding sets, cyclically $T$-contiguous collusion, and disjoint collections of cyclically contiguous colluding sets. For the last two collusion patterns, we present matching achievable schemes that attain the corresponding bounds, thereby providing a complete characterization of the optimal message size."
  },
  {
    "date": "2026-01-26",
    "title": "On Extremal Volume Projections of the Simplex and the Cube",
    "authors": "Christos Pandis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18436v1",
    "source": "arXiv",
    "abstract": "Let $Δ_n$ and $Q_n$ denote the regular $n$-simplex of side length $\\sqrt{2}$ embedded in $\\mathbb{R}^{n+1}$ and the volume one cube in $\\mathbb{R}^n$, respectively. We derive a closed-form formula for the hyperplane volume projections of $Δ_n$, which also yields the directions achieving the extremal volume. Moreover, we revisit the problem of extremal planar projections of $Q_n$. In addition, we present generalizations within the framework of $L_p$-projection bodies."
  },
  {
    "date": "2026-01-26",
    "title": "Massless Representations in Conformal Space and Their de Sitter (dS) Restrictions",
    "authors": "Jean-Pierre Gazeau, Hamed Pejhan, Ivan Todorov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18433v1",
    "source": "arXiv",
    "abstract": "The monograph develops a self-contained, mathematically rigorous framework for massless representations of the conformal group U(2,2) and their restriction to the de Sitter group Sp(2,2). It systematically constructs ladder (massless) representations, computes invariant bilinear forms and Casimir operators, and provides explicit constructions of vertex operators and two-point functions for low-helicity fields. The monograph employs a novel Clifford-split-octonion approach, embedding 8-component Majorana spinors within an alternative composition algebra, which allows for fully explicit algebraic, spinorial, and geometric constructions. The text bridges foundational representation theory, explicit computational methods, and physical applications in quantum field theory and cosmology. While targeted at researchers in mathematical physics, quantum cosmology, and quantum field theory, the exposition is pedagogically structured to guide advanced graduate students through subtle algebraic and representation-theoretic ideas, making complex constructions accessible without sacrificing rigor."
  },
  {
    "date": "2026-01-26",
    "title": "Collaposer: Transforming Photo Collections into Visual Assets for Storytelling with Collages",
    "authors": "Jiayi Zhou, Liwenhan Xie, Jiaju Ma, Zheng Wei, Huamin Qu, Anyi Rao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18428v1",
    "source": "arXiv",
    "abstract": "Digital collage is an artistic practice that combines image cutouts to tell stories. However, preparing cutouts from a set of photos remains a tedious and time-consuming task. A formative study identified three main challenges: 1) inefficient search for relevant photos, 2) manual image cutout, and 3) difficulty in organizing large sets of cutouts. To meet these challenges and facilitate asset preparation for collage, we propose Collaposer, a tool that transforms a collection of photos into organized, ready-to-use visual cutouts based on user-provided story descriptions. Collaposer tags, detects, and segments photos, and then uses an LLM to select central and related labels based on the user-provided story description. Collaposer presents the resulting visuals in varying sizes, clustered according to semantic hierarchy. Our evaluation shows that Collaposer effectively automates the preparation process to produce diverse sets of visual cutouts adhering to the storyline, allowing users to focus on collaging these assets for storytelling. Project website: https://jiayzhou.github.io/collaposer-website/"
  },
  {
    "date": "2026-01-26",
    "title": "Superlinear Multi-Step Attention",
    "authors": "Yufeng Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18401v1",
    "source": "arXiv",
    "abstract": "In this paper, we propose \\textbf{Superlinear attention}, a fully trainable multi-step attention architecture that achieves subquadratic complexity for long sequences while preserving \\textbf{random context access} (a.k.a.\\ structural non-exclusion): no eligible token position is structurally excluded from being selected for attention. Superlinear attention reformulates standard causal self-attention as a multi-step search problem with $N$ steps, yielding an overall complexity of $O(L^{1+\\frac{1}{N}})$. To illustrate the architecture, we present a baseline $N=2$ implementation, which is algorithmically analogous to standard jump search. In this $O(L^{3/2})$ instantiation, the first step performs $O(L^{3/2})$ span-search to select relevant spans of the sequence, and the second step applies $O(L^{3/2})$ span-attention (standard attention restricted to the selected spans). In an upscaled $O(L^{1.54})$ configuration for robustness, we achieve an average decoding throughput of 114 tokens/sec at 1M context length and 80 tokens/sec at 10M context in our implementation on a modified 30B hybrid MoE model on a single B200 GPU. With limited training, we also obtain strong performance on the NIAH (Needle In A Haystack) task up to 256K context length, demonstrating that the routed span selection is learnable end-to-end. This paper emphasizes architectural formulation, scaling analysis, and systems feasibility, and presents initial validation; comprehensive quality evaluations across diverse long-context tasks are left to future work."
  },
  {
    "date": "2026-01-26",
    "title": "Do not be greedy, Think Twice: Sampling and Selection for Document-level Information Extraction",
    "authors": "Mikel Zubillaga, Oscar Sainz, Oier Lopez de Lacalle, Eneko Agirre",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18395v1",
    "source": "arXiv",
    "abstract": "Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art."
  },
  {
    "date": "2026-01-26",
    "title": "Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space",
    "authors": "Moritz Rempe, Lukas T. Rotkopf, Marco Schlimbach, Helmut Becker, Fabian Hörst, Johannes Haubold, Philipp Dammann, Kevin Kröninger, Jens Kleesiek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18392v1",
    "source": "arXiv",
    "abstract": "Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis."
  },
  {
    "date": "2026-01-26",
    "title": "AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito",
    "authors": "Yinghan Hou, Zongyou Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18381v1",
    "source": "arXiv",
    "abstract": "To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior."
  },
  {
    "date": "2026-01-26",
    "title": "Divisible design graphs from Higmanian association schemes",
    "authors": "Grigory Ryabov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18370v1",
    "source": "arXiv",
    "abstract": "An imprimitive symmetric indecomposable association scheme of rank 5 is said to be Higmanian. A divisible design graph is a graph whose adjacency matrix is an incidence matrix of a symmetric divisible design. We establish conditions which guarantee that a union of some basis relations of a Higmanian association scheme is an edge set of a divisible design graph. Further, we show that several known families of divisible design graphs can be obtained as fusions of Higmanian association schemes. Finally, using our approach we construct new infinite families of divisible design graphs."
  },
  {
    "date": "2026-01-26",
    "title": "Symplecticity-Preserving Prediction of Hamiltonian Dynamics by Generalized Kernel Interpolation",
    "authors": "Robin Herkert, Tobias Ehring, Bernard Haasdonk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18364v1",
    "source": "arXiv",
    "abstract": "In this work, a kernel-based surrogate for integrating Hamiltonian dynamics that is symplectic by construction and tailored to large prediction horizons is proposed. The method learns a scalar potential whose gradient enters a symplectic-Euler update, yielding a discrete flow map that exactly preserves the canonical symplectic structure. Training is formulated as a gradient Hermite--Birkhoff interpolation problem in a reproducing kernel Hilbert space, providing a systematic framework for existence, uniqueness, and error control. Algorithmically, the symplectic kernel predictor is combined with structure-preserving model order reduction, enabling efficient treatment of high-dimensional discretized PDEs. Numerical tests for a pendulum, a nonlinear spring--mass chain, and a semi-discrete wave equation show nearly algebraic greedy convergence and long-time trajectory errors reduce by two to three orders of magnitude compared to an implicit midpoint baseline at the same macro time step."
  },
  {
    "date": "2026-01-26",
    "title": "Graphical composition of mapping spaces between modules of configuration-space-type",
    "authors": "Semyon Abramyan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18363v1",
    "source": "arXiv",
    "abstract": "In embedding calculus, spaces of embeddings are identified with derived mapping spaces between framed Fulton-MacPherson-type modules (framed configuration spaces). Unfortunately, there are no sufficiently good algebraic models for framed Fulton-MacPherson modules that would allow us to explicitly describe the rational homotopy type of the embedding space. Recently there were several attempts to avoid dealing with the framed versions of Fulton-MacPherson modules by considering framed manifolds, e.g. embeddings modulo immersions $\\overline{\\mathrm{Emb}}$ in a recent paper by Fresse, Turchin and Willwacher, or embeddings with a deformation of the framing $\\widetilde{\\mathrm{Emb}}$ in a recent paper by the author. In both cases, the rational homotopy type of the corresponding embedding space has an explicit description in terms of graphs (hairy graph complexes). We construct a combinatorial graphical composition for the composition of embedding spaces $\\widetilde{\\mathrm{Emb}}$. As a step on our way, we describe the action of the coinduction functor on configuration-space-type $e_n^c$-comodules."
  },
  {
    "date": "2026-01-26",
    "title": "Integrating HAPS, LEO, and Terrestrial Networks: A Cost-Performance Study for IoT Connectivity",
    "authors": "Jean Michel de Souza Sant'Ana, Felipe Augusto Tondo, Nurul Huda Mahmood, Aamir Mahmood",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18361v1",
    "source": "arXiv",
    "abstract": "This work evaluates the potential of High-Altitude Platform Stations (HAPS) and Low Earth Orbit (LEO) satellites as alternative or complementary systems to enhance Internet of Things (IoT) connectivity. We first analyze the transmission erasure probability under different connectivity configurations, including only HAPS or LEO satellites, as well as hybrid architectures that integrate both aerial/spatial and terrestrial infrastructures. To make the analysis more realistic, we considered movement of LEO satellites regarding a fixed region, elevation angle between gateway and devices, and different fading models for terrestrial and non-terrestrial communication. We also analyze LR-FHSS (Long-Range Frequency Hopping Spread Spectrum) random access uplink technology as a potential use case for IoT connectivity, showing the scalability impact of the scenarios. The simulation results demonstrate that HAPS can effectively complement sparse terrestrial networks and improve the performance of satellite-based systems in specific scenarios. Furthermore, considering the deployment and operational costs, respectively, CAPEX and OPEX, the economic analysis reveals that although HAPS exhibits higher costs, these remain within a comparable order of magnitude to LEO and terrestrial deployments. In addition, specific use cases, such as natural disasters, transform HAPS into a competitive technology for conventional infrastructures."
  },
  {
    "date": "2026-01-26",
    "title": "On fractional semilinear wave equations in non-cylindrical domains",
    "authors": "Bonafini Mauro, Le Van Phu Cuong, Molinarolo Riccardo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18355v1",
    "source": "arXiv",
    "abstract": "In this paper, we investigate a class of semilinear wave equations in non-cylindrical time-dependent domains, subject to exterior homogeneous Dirichlet conditions. Under mild regularity and monotonicity assumptions on the evolving spatial domains, we establish existence of weak solutions by two different methods: a constructive time-discretization scheme and a penalty approach. The analysis applies to nonlocal fractional Laplacians and potentials with Lipschitz continuous gradient, and to vector-valued maps."
  },
  {
    "date": "2026-01-26",
    "title": "Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning",
    "authors": "Manjie Xu, Isabella Yin, Xinyi Tu, Chi Zhang, Yixin Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18352v1",
    "source": "arXiv",
    "abstract": "LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., \"Lava is Dangerous\") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting \"Lava is Safe\"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors."
  },
  {
    "date": "2026-01-26",
    "title": "On the Subspace Orbit Problem and the Simultaneous Skolem Problem",
    "authors": "Piotr Bacik, Anton Varonka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18349v1",
    "source": "arXiv",
    "abstract": "The Orbit Problem asks whether the orbit of a point under a matrix reaches a given target set. When the target is a single point, the problem was shown to be decidable in polynomial time by Kannan and Lipton. This decidability result was later extended by Chonev et al. to targets of dimension 3 (in arbitrary ambient dimension), but decidability remains open for subspaces of dimension 4. At the other extreme, the special case of the Orbit Problem in which the target set is a hyperplane of codimension 1 is equivalent to the Skolem Problem for linear recurrence sequences, whose decidability has been open for many decades. In this paper, we show that the Orbit Problem is decidable if the target subspace has dimension logarithmic in the dimension of the orbit. Over rationals, we moreover obtain a complexity bound NP^RP in this case. On the other hand, we show that the version of the Orbit Problem where the dimension of the target subspace is linear in the dimension of the orbit is as hard as the Skolem Problem."
  },
  {
    "date": "2026-01-26",
    "title": "Analytic Incremental Learning For Sound Source Localization With Imbalance Rectification",
    "authors": "Zexia Fan, Yu Chen, Qiquan Zhang, Kainan Chen, Xinyuan Qian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18335v1",
    "source": "arXiv",
    "abstract": "Sound source localization (SSL) demonstrates remarkable results in controlled settings but struggles in real-world deployment due to dual imbalance challenges: intra-task imbalance arising from long-tailed direction-of-arrival (DoA) distributions, and inter-task imbalance induced by cross-task skews and overlaps. These often lead to catastrophic forgetting, significantly degrading the localization accuracy. To mitigate these issues, we propose a unified framework with two key innovations. Specifically, we design a GCC-PHAT-based data augmentation (GDA) method that leverages peak characteristics to alleviate intra-task distribution skews. We also propose an Analytic dynamic imbalance rectifier (ADIR) with task-adaption regularization, which enables analytic updates that adapt to inter-task dynamics. On the SSLR benchmark, our proposal achieves state-of-the-art (SoTA) results of 89.0% accuracy, 5.3° mean absolute error, and 1.6 backward transfer, demonstrating robustness to evolving imbalances without exemplar storage."
  },
  {
    "date": "2026-01-26",
    "title": "Overalignment in Frontier LLMs: An Empirical Study of Sycophantic Behaviour in Healthcare",
    "authors": "Clément Christophe, Wadood Mohammed Abdul, Prateek Munjal, Tathagata Raha, Ronnie Rajan, Praveenkumar Kanithi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18334v1",
    "source": "arXiv",
    "abstract": "As LLMs are increasingly integrated into clinical workflows, their tendency for sycophancy, prioritizing user agreement over factual accuracy, poses significant risks to patient safety. While existing evaluations often rely on subjective datasets, we introduce a robust framework grounded in medical MCQA with verifiable ground truths. We propose the Adjusted Sycophancy Score, a novel metric that isolates alignment bias by accounting for stochastic model instability, or \"confusability\". Through an extensive scaling analysis of the Qwen-3 and Llama-3 families, we identify a clear scaling trajectory for resilience. Furthermore, we reveal a counter-intuitive vulnerability in reasoning-optimized \"Thinking\" models: while they demonstrate high vanilla accuracy, their internal reasoning traces frequently rationalize incorrect user suggestions under authoritative pressure. Our results across frontier models suggest that benchmark performance is not a proxy for clinical reliability, and that simplified reasoning structures may offer superior robustness against expert-driven sycophancy."
  },
  {
    "date": "2026-01-26",
    "title": "A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification",
    "authors": "Muhammad Ali Shah, Muhammad Mansoor Alam, Saddam Hussain Khan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18330v1",
    "source": "arXiv",
    "abstract": "This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset."
  },
  {
    "date": "2026-01-26",
    "title": "Unusual Dual Flat Bands and two-dimensional Dirac-node Arc State in Kagome Metal Ni3In2S2",
    "authors": "Bo Liang, Yichen Liu, Jie Pang, Hanbin Deng, Taimin Miao, Wenpei Zhu, Neng Cai, Tiantian Zhang, Jiayu Liu, Zhicheng Jiang, Zhanfeng Liu, Hongen Zhu, Yuliang Li, Tongrui Li, Mingkai Xu, Hao Chen, Xiaolin Ren, Chaohui Yin, Yingjie Shu, Yiwen Chen, Yu-Tian Zhang, Zhengtai Liu, Dawei Shen, Mao Ye, Fengfeng Zhang, Shenjin Zhang, Shengtao Cui, Zhe Sun, Koji Miyamoto, Taichi Okuda, Kenya Shimada, Lihong Yang, Jia-Xin Yin, Lin Zhao, Zuyan Xu, Haijun Zhang, Youguo Shi, X. J. Zhou, Guodong Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18317v1",
    "source": "arXiv",
    "abstract": "Kagome materials are at the frontier of condensed matter physics. An ideal kagome lattice features only one geometrically frustrated flat band spanning the entire momentum space and a single Dirac cone at the Brillouin-zone corners. However, for the first time, here we observe unusual flat-band and Dirac physics in the newly discovered \"322\" kagome material Ni3In2S2 by combining high-resolution synchrotron- and laser-based angle-resolved photoemission spectroscopy with a micro-focused beam, scanning tunneling microscopy, and first-principles calculations. We resolve two distinct electronic flat-band states located in close proximity to the Fermi level: a robust Topological Surface Flat Band at ~40 meV below the Fermi level on the Sulfur-terminated surface, originating from weak topological insulator states, and a kagome lattice-derived flat band at ~100 meV binding energy with an ultranarrow bandwidth (~5 meV). Instead of the single Dirac cone, the Indium-terminated surface hosts a rare two-dimensional Dirac-node arc state, where the gapless Dirac nodes extend along an open one-dimensional line crossing the Brillouin-zone boundary, exhibiting sharp linear dispersion, exceptionally high Fermi velocity, and pronounced circular dichroism. These findings establish Ni3In2S2 as a unique topological kagome metal in which multiple flat-band states of different physical origin coexist with an unusual Dirac-node arc, opening an avenue for discovering flat-band--driven and topology-enabled quantum phenomena."
  },
  {
    "date": "2026-01-26",
    "title": "Effect of ballistic re-solution on the nucleation kinetics of precipitates in diluted binary alloys under irradiation. Part 2: Cr-rich alpha' precipitates in Fe-Cr alloys",
    "authors": "M. S. Veshchunov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18316v1",
    "source": "arXiv",
    "abstract": "On the base of a critical analysis of existing models for nucleation of new phase precipitates in metastable binary alloys, a new kinetic model of homogeneous nucleation and growth of alpha'-phase precipitates in Fe-Cr alloys was developed within the framework of the Reiss kinetic theory of binary nucleation. The model was further modified to account for the influence of ballistic re-solution on the kinetics of nucleation and growth of alpha' precipitates, following the general approach proposed in Part 1. The model was used for qualitative interpretation of the results of recent tests, in which the stability of alpha' precipitates in Fe-15Cr alloys under irradiation was studied."
  },
  {
    "date": "2026-01-26",
    "title": "A Master Class on Reproducibility: A Student Hackathon on Advanced MRI Reconstruction Methods",
    "authors": "Lina Felsner, Sevgi G. Kafali, Hannah Eichhorn, Agnes A. J. Leth, Aidas Batvinskas, Andre Datchev, Fabian Klemm, Jan Aulich, Puntika Leepagorn, Ruben Klinger, Daniel Rueckert, Julia A. Schnabel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18314v1",
    "source": "arXiv",
    "abstract": "We report the design, protocol, and outcomes of a student reproducibility hackathon focused on replicating the results of three influential MRI reconstruction papers: (a) MoDL, an unrolled model-based network with learned denoising; (b) HUMUS-Net, a hybrid unrolled multiscale CNN+Transformer architecture; and (c) an untrained, physics-regularized dynamic MRI method that uses a quantitative MR model for early stopping. We describe the setup of the hackathon and present reproduction outcomes alongside additional experiments, and we detail fundamental practices for building reproducible codebases."
  },
  {
    "date": "2026-01-26",
    "title": "Effect of ballistic re-solution on the nucleation kinetics of precipitates in diluted binary alloys under irradiation. Part 1: Stoichiometric gamma' precipitates in Ni-Al alloys",
    "authors": "M. S. Veshchunov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18309v1",
    "source": "arXiv",
    "abstract": "A modification of classical nucleation theory is carried out as applied to solid solutions under irradiation, taking into account the influence of ballistic re-solution on the nucleation kinetics of pure unary (single-component) and stoichiometric binary precipitates. The effects of excessive point defects formed under steady irradiation conditions and operating alongside the ballistic re-solution mechanism are incorporated into the new model for a consistent description of the nucleation of incoherent and coherent particles. The developed model was applied to interpret the results of Nelson, Hudson and Mazey (NHM) tests, in which the stability of gamma' phase (Ni3Al) precipitates in diluted Ni-Al alloys under irradiation was studied."
  },
  {
    "date": "2026-01-26",
    "title": "A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience",
    "authors": "Geunsik Lim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18308v1",
    "source": "arXiv",
    "abstract": "As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures."
  },
  {
    "date": "2026-01-26",
    "title": "Laser interferometry as a robust neuromorphic platform for machine learning",
    "authors": "Amanuel Anteneh, Kyungeun Kim, J. M. Schwarz, Israel Klich, Olivier Pfister",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18047v1",
    "source": "arXiv",
    "abstract": "We present a method for implementing an optical neural network using only linear optical resources, namely field displacement and interferometry applied to coherent states of light. The nonlinearity required for learning in a neural network is realized via an encoding of the input into phase shifts allowing for far more straightforward experimental implementation compared to previous proposals for, and demonstrations of, $\\textit{in situ}$ inference. Beyond $\\textit{in situ}$ inference, the method enables $\\textit{in situ}$ training by utilizing established techniques like parameter shift rules or physical backpropagation to extract gradients directly from measurements of the linear optical circuit. We also investigate the effect of photon losses and find the model to be very resilient to these."
  },
  {
    "date": "2026-01-26",
    "title": "Heat flow of harmonic maps into CAT($0$)-spaces",
    "authors": "Fang-Hua Lin, Antonio Segatti, Yannick Sire, Changyou Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18046v1",
    "source": "arXiv",
    "abstract": "We introduce a new approach to prove the global existence and uniqueness of suitable weak solutions of the heat flow of harmonic mappings into CAT(0) metric spaces. Our method allows also to prove Lipschitz continuity in spatial variables for such solutions into a wide class of CAT$(0)$ spaces, answering a long-standing open problem in the field. Our approach is based on an elliptic regularization of the gradient flow of the Dirichlet energy and even in the case of smooth Riemannian targets provides a novel viewpoint, together with a new Dynamical Variational Principle and a new proof of the celebrated Eells-Sampson theorem. The spatial Lipschitz regularity for such weak solutions is achieved by fully exploiting the variational structure of the problem at the regularized level and introducing a parabolic frequency function of Almgren-Poon type. Our contribution is the first instance of the use of monotonicity methods for parabolic deformations of maps into singular targets."
  },
  {
    "date": "2026-01-26",
    "title": "SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction",
    "authors": "Linyong Gan, Zimo Li, Wenxin Xu, Xingjian Li, Jianhua Z. Huang, Enmei Tu, Shuhang Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18537v1",
    "source": "arXiv",
    "abstract": "Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction."
  },
  {
    "date": "2026-01-26",
    "title": "Non-equilibrium symmetry of cyclic first-passage times",
    "authors": "Daniel Maria Busiello, Shiling Liang, Simone Pigolotti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18136v1",
    "source": "arXiv",
    "abstract": "We study the sum of first passage times along an arbitrary cycle made up of N>2 states of a small physical system. We show that, if the system is at thermodynamic equilibrium, this sum follows the same probability distribution regardless of whether the cycle is explored clockwise or counterclockwise. Out of equilibrium, the distributions of clockwise and counterclockwise cyclic first passage times are related by a detailed fluctuation theorem. This result descends from a symmetry of clockwise and counterclockwise trajectories, which combines time reversal with swapping portions of the trajectories. We then relate the entropy produced along the cycle with the entropy production of the whole system using large deviation theory. Our results reveal a novel symmetry in stochastic systems, of potential broad applicability in non-equilibrium physics."
  },
  {
    "date": "2026-01-26",
    "title": "daVinci-Dev: Agent-native Mid-training for Software Engineering",
    "authors": "Ji Zeng, Dayuan Fu, Tiantian Mi, Yumin Zhuang, Yaxing Huang, Xuefeng Li, Lyumanshan Ye, Muhang Xie, Qishuo Hua, Zhen Huang, Mohan Jiang, Hanning Wang, Jifan Lin, Yang Xiao, Jie Sun, Yunze Wu, Pengfei Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18418v1",
    "source": "arXiv",
    "abstract": "Recently, the frontier of Large Language Model (LLM) capabilities has shifted from single-turn code generation to agentic software engineering-a paradigm where models autonomously navigate, edit, and test complex repositories. While post-training methods have become the de facto approach for code agents, **agentic mid-training**-mid-training (MT) on large-scale data that mirrors authentic agentic workflows-remains critically underexplored due to substantial resource requirements, despite offering a more scalable path to instilling foundational agentic behaviors than relying solely on expensive reinforcement learning. A central challenge in realizing effective agentic mid-training is the distribution mismatch between static training data and the dynamic, feedback-rich environment of real development. To address this, we present a systematic study of agentic mid-training, establishing both the data synthesis principles and training methodology for effective agent development at scale. Central to our approach is **agent-native data**-supervision comprising two complementary types of trajectories: **contextually-native trajectories** that preserve the complete information flow an agent experiences, offering broad coverage and diversity; and **environmentally-native trajectories** collected from executable repositories where observations stem from actual tool invocations and test executions, providing depth and interaction authenticity. We verify the model's agentic capabilities on `SWE-Bench Verified`. We demonstrate our superiority over the previous open software engineering mid-training recipe `Kimi-Dev` under two post-training settings with an aligned base model and agentic scaffold, while using less than half mid-training tokens (73.1B). Besides relative advantage, our best performing 32B and 72B models achieve **56.1%** and **58.5%** resolution rates, respectively, which are ..."
  },
  {
    "date": "2026-01-26",
    "title": "TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance",
    "authors": "Elena Bruches, Vadim Alperovich, Dari Baturova, Roman Derunets, Daniil Grebenkin, Georgy Mkrtchyan, Oleg Sedukhin, Mikhail Klementev, Ivan Bondarenko, Nikolay Bushkov, Stanislav Moiseev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18241v1",
    "source": "arXiv",
    "abstract": "While Large Language Models (LLMs) have shown promise in software engineering, their application to unit testing remains largely confined to isolated test generation or oracle prediction, neglecting the broader challenge of test suite maintenance. We introduce TAM-Eval (Test Automated Maintenance Evaluation), a framework and benchmark designed to evaluate model performance across three core test maintenance scenarios: creation, repair, and updating of test suites. Unlike prior work limited to function-level tasks, TAM-Eval operates at the test file level, while maintaining access to full repository context during isolated evaluation, better reflecting real-world maintenance workflows. Our benchmark comprises 1,539 automatically extracted and validated scenarios from Python, Java, and Go projects. TAM-Eval supports system-agnostic evaluation of both raw LLMs and agentic workflows, using a reference-free protocol based on test suite pass rate, code coverage, and mutation testing. Empirical results indicate that state-of-the-art LLMs have limited capabilities in realistic test maintenance processes and yield only marginal improvements in test effectiveness. We release TAM-Eval as an open-source framework to support future research in automated software testing. Our data and code are publicly available at https://github.com/trndcenter/TAM-Eval."
  },
  {
    "date": "2026-01-26",
    "title": "Handling Scope Checks (Extended Version)",
    "authors": "Michael Lee, Ningning Xie, Oleg Kiselyov, Jeremy Yallop",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18793v1",
    "source": "arXiv",
    "abstract": "Metaprogramming and effect handlers interact in unexpected, and sometimes undesirable, ways. One example is scope extrusion: the generation of ill-scoped code. Scope extrusion can either be preemptively prevented, via static type systems, or retroactively detected, via dynamic checks. Static type systems exist in theory, but struggle with a range of implementation and usability problems in practice. In contrast, dynamic checks exist in practice (e.g. in MetaOCaml), but are understudied in theory. Designers of metalanguages are thus given little guidance regarding the design and implementation of checks. We present the first formal study of dynamic scope extrusion checks, introducing a calculus ($λ_{\\langle\\langle\\text{op}\\rangle\\rangle}$) for describing and evaluating checks. Further, we introduce a novel dynamic check $\\unicode{x2014}$ the \"Cause-for-Concern\" check $\\unicode{x2014}$ which we prove correct, characterise without reference to its implementation, and argue combines the advantages of existing dynamic checks. Finally, we extend our framework with refined environment classifiers, which statically prevent scope extrusion, and compare their expressivity with the dynamic checks."
  },
  {
    "date": "2026-01-26",
    "title": "Scaling up Privacy-Preserving ML: A CKKS Implementation of Llama-2-7B",
    "authors": "Jaiyoung Park, Sejin Park, Jai Hyun Park, Jung Ho Ahn, Jung Hee Cheon, Guillaume Hanrot, Jung Woo Kim, Minje Park, Damien Stehlé",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18511v1",
    "source": "arXiv",
    "abstract": "As large language models (LLMs) become ubiquitous, privacy concerns pertaining to inference inputs keep growing. In this context, fully homomorphic encryption (FHE) has emerged as a primary cryptographic solution to provide non-interactive confidential LLM inference. Existing solutions scale poorly with the input token length, and hence focus either on small models or larger models with a small number of input tokens. They also suffer from the existence of large outlier values. These values have a strong impact on the evaluation of non-linear layers, leading to large-degree polynomial approximation and thus heavy evaluation costs. We propose an FHE-based private LLM inference solution that allows thousands of input tokens with only a part of them being encrypted: this fits with a scenario where the context is benign and only part of the input is sensitive. To do so, we suggest an unbalanced chunked prefill framework that processes the private and public parts of the input tokens differently. Our framework contains plaintext-plaintext, plaintext-ciphertext and ciphertext-ciphertext computational components. We adopt different strategies and ingredients for each component. We also devise new homomorphic algorithms for specific matrix multiplication and polynomial evaluation tasks encountered during LLM inference. Furthermore, without retraining, we tailor the LLM inference algorithm to reduce the ranges of outlier values: we leverage machine learning strategies (token prepending and rotations) to mitigate the impact of the outliers on non-linear layers. Based on these ingredients, we describe a CKKS-based end-to-end implementation of Llama-2-7B private inference for up to 4096 input tokens, of which the last 128 are encrypted. On a cluster of 8~NVIDIA RTX-4090 GPUs, inference takes 85s for summarization and 33s for generation per output token."
  },
  {
    "date": "2026-01-26",
    "title": "Gradient-Informed Machine Learning in Electromagnetics",
    "authors": "Matteo Zorzetto, Merle Backmeyer, Michael Wiesheu, Riccardo Torchio, Fabrizio Dughiero, Sebastian Schöps",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18300v1",
    "source": "arXiv",
    "abstract": "Simulation techniques such as the finite element method are essential for designing electrical devices, but their computational cost can be prohibitive for repeated or real-time computations. Projection-based model order reduction techniques mitigate this by reducing the model size and complexity, yet face challenges when extended to nonlinear or non-affine parametric models. In this work, Isogeometric Analysis (IGA) is combined with proper orthogonal decomposition and Gaussian process regression to construct a non-intrusive surrogate model of a parametric nonlinear model of a permanent magnet synchronous machine. The differentiable nature of IGA allows for computationally efficient extraction of parametric sensitivities, which are leveraged for gradient-enhanced surrogate modeling."
  },
  {
    "date": "2026-01-26",
    "title": "RG flows of minimal $\\mathcal W$-algebra CFTs via non-invertible symmetries",
    "authors": "Federico Ambrosino, Tomáš Procházka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18667v1",
    "source": "arXiv",
    "abstract": "In this letter we study renormalization group (RG) flows between 2d conformal field theories enjoying extended higher-spin $\\mathcal{W}$-symmetry. We propose a new class of RG flows between the diagonal minimal models of $\\mathcal{W}_N$-algebra that take the form $\\mathcal{W}_N(p,q)\\to\\mathcal{W}_N(p,kp-q)$. These are obtained by matching the anomalies of the non-invertible symmetry ${\\mathrm{Rep}}[SU(N)_{p-N}]$ (and its discrete quotients) that is preserved by special relevant primary fields. This large non-invertible symmetry includes the familiar $\\mathbb{Z}_N$ symmetry of the minimal models. Our new flows furnish a significant generalization of the ones recently found in the case of Virasoro algebra, and include all previously known RG flows of $\\mathcal{W}_N$. They have the remarkable property of being uniform in the rank $N$ of the $\\mathcal{W}$-algebra."
  },
  {
    "date": "2026-01-26",
    "title": "Non-Destructive Beam Monitoring via Secondary Radiation Detection with Ce-Doped Silica Fibers",
    "authors": "Alexander Gottstein, Pierluigi Casolaro, Gaia Dellepiane, Lars Eggimann, Eva Kasanda, Isidre Mateu, Samuel Usherovich, Paola Scampoli, Cornelia Hoehr, Saverio Braccini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18293v1",
    "source": "arXiv",
    "abstract": "Non-destructive beam diagnostics are essential for low-energy medical cyclotrons, where even thin interceptive devices can severely degrade beam quality. We investigate an external fiber monitor (EFM) based on Ce-doped silica scintillating fibers that detects secondary radiation generated at existing beamline components of the 18 MeV Bern Medical Cyclotron beam transfer line (BTL). Three use cases were studied: (i) beam intensity monitoring around an electrically isolated, water-cooled beam dump; (ii) beam-loss monitoring around a 10 mm collimator under varying the beam focusing; and (iii) by steering a 6.5 mm $\\times$ 6.5 mm beam spot on a beam dump. For case (i), the summed EFM signal exhibits a linear dependence on the current on target over nearly three orders of magnitude. In case (ii), a normalized EFM-based beam-loss proxy scales monotonically with an electrical loss proxy across several focusing settings. Furthermore, opposing-fiber signal ratios provide decoupled, monotonic sensitivity to horizontal and vertical beam displacements."
  },
  {
    "date": "2026-01-26",
    "title": "Probing electromagnetic moments of the tau lepton in PbPb collisions at the FCC-hh",
    "authors": "S. C. İnan, A. V. Kisselev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18288v1",
    "source": "arXiv",
    "abstract": "A production of a pair of tau leptons in PbPb collisions at the FCC-hh collider is examined. The 95\\% C.L. exclusion limits, as well as 3$σ$ and 5$σ$ sensitivity limits on the anomaly magnetic moment of the tau lepton $a_τ$ and its electric dipole moment $d_τ$ are obtained. A comparison with bounds on $a_τ$ and $d_τ$ for other future colliders are given."
  },
  {
    "date": "2026-01-26",
    "title": "U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents",
    "authors": "Jin Su, Runnan Fang, Yeqiu Li, Xiaobin Wang, Shihao Cai, Pengjun Xie, Ningyu Zhang, Fajie Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18285v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $τ$-bench, $τ^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications."
  },
  {
    "date": "2026-01-26",
    "title": "VissimRL: A Multi-Agent Reinforcement Learning Framework for Traffic Signal Control Based on Vissim",
    "authors": "Hsiao-Chuan Chang, Sheng-You Huang, Yen-Chi Chen, I-Chen Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18284v1",
    "source": "arXiv",
    "abstract": "Traffic congestion remains a major challenge for urban transportation, leading to significant economic and environmental impacts. Traffic Signal Control (TSC) is one of the key measures to mitigate congestion, and recent studies have increasingly applied Reinforcement Learning (RL) for its adaptive capabilities. With respect to SUMO and CityFlow, the simulator Vissim offers high-fidelity driver behavior modeling and wide industrial adoption but remains underutilized in RL research due to its complex interface and lack of standardized frameworks. To address this gap, this paper proposes VissimRL, a modular RL framework for TSC that encapsulates Vissim's COM interface through a high-level Python API, offering standardized environments for both single- and multi-agent training. Experiments show that VissimRL significantly reduces development effort while maintaining runtime efficiency, and supports consistent improvements in traffic performance during training, as well as emergent coordination in multi-agent control. Overall, VissimRL demonstrates the feasibility of applying RL in high-fidelity simulations and serves as a bridge between academic research and practical applications in intelligent traffic signal control."
  },
  {
    "date": "2026-01-26",
    "title": "Voltage-controlled topological spin textures in the monolayer limit",
    "authors": "Yangliu Wu, Bo Peng, Zhaozhuo Zeng, Chendi Yang, Haipeng Lu, Peiheng Zhou, Jianliang Xie, Difei Liang, Linbo Zhang, Peng Yan, Haizhong Guo, Renchao Che, Longjiang Deng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18277v1",
    "source": "arXiv",
    "abstract": "The physics of phase transitions in low-dimensional systems has long been a subject of significant research interest. Long-range magnetic order in the strict two-dimensional limit, whose discovery circumvented the Mermin-Wagner theorem, has rapidly emerged as a research focus. However, the demonstration of a non-trivial topological spin textures in two-dimensional limit has remained elusive. Here, we demonstrate the out-of-plane electric field breaks inversion symmetry while simultaneously modulating the electronic band structure, enabling electrically tunable spin-orbit interaction for creation and manipulation of topological spin textures in monolayer CrI3. The realization of ideal two-dimensional topological spin textures may offer not only an experimental testbed for probing the Berezinskii-Kosterlitz-Thouless mechanism, but also potential insights into unresolved quantum phenomena including superconductivity and superfluidity. Moreover, voltage-controlled spin-orbit interaction offers a novel pathway to engineer two-dimensional spin textures with tailored symmetries and topologies, while opening avenues for skyrmion-based next-generation information technologies."
  },
  {
    "date": "2026-01-26",
    "title": "The Most Luminous H$β$ Reverberation Mapping of E1821+643 Indicates the Lower Boundary of the Radius-Luminosity Relation",
    "authors": "Sha-Sha Li, Hai-Cheng Feng, Jiancheng Wu, J. M. Bai, H. T. Liu, Kai-Xing Lu, Mouyuan Sun, Jian-Guo Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18269v1",
    "source": "arXiv",
    "abstract": "The radius-luminosity ($R_{\\rm BLR}$-$L_{5100}$) relation is fundamental to active galactic nucleus (AGN) studies, enabling supermassive black hole (SMBH) mass estimates and AGN-based cosmology applications. However, its high-luminosity end remains poorly calibrated due to insufficient reliable reverberation mapping (RM) data. We present a four-year RM campaign of the luminous quasar E1821+643 using the Lijiang 2.4-m telescope, supplemented by archival multi-wavelength data. E1821+643 is the most luminous AGN with an \\hb\\ RM measurement to date. The measured time lag of $83.2_{-18.7}^{+17.5}$ days is a factor of 5.6 shorter than predicted by the canonical $R_{\\rm BLR}$-$L_{5100}$ relation. By compiling the full \\hb\\ RM sample, we find that such deviation defines a lower envelope ($0.2R_{\\rm BLR}$) of measured lags across the entire luminosity range, while the upper envelope lies near $2R_{\\rm BLR}$, implying that the scatter for individual AGNs can reach 1 dex. Spectral decomposition reveals two distinct \\hb\\ components: a core component with a lag of $267.0_{-17.6}^{+16.6}$ days closer to the $R_{\\rm BLR}$-$L_{5100}$ relation, and a redshifted tail with a much shorter lag of $-49.0_{-34.5}^{+50.5}$ days. The short-lag component not only accounts for the significantly shortened overall lag, but also leads to an opposite interpretation of the intrinsic BLR kinematics. These effects can introduce systematic uncertainties in black hole mass estimates by factors of up to tens. Our findings demonstrate that shortened lags in high-accretion-rate AGNs arise from multi-component BLR structures, posing substantial challenges to single-epoch mass estimates and impacting SMBH demographics and cosmological applications."
  },
  {
    "date": "2026-01-26",
    "title": "Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images",
    "authors": "Eytan Kats, Kai Geissler, Daniel Mensing, Jochen G. Hirsch, Stefan Heldman, Mattias P. Heinrich",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18260v1",
    "source": "arXiv",
    "abstract": "Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning."
  },
  {
    "date": "2026-01-26",
    "title": "Tensor-driven geometric phase in nonlinear AlGaAs metasurfaces",
    "authors": "Giorgio Guercio, Andrea Gerini, Kristina Frizyuk, Costantino De Angelis, Martina Morassi, Aristide Lemaître, Luca Carletti, Giuseppe Leo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18246v1",
    "source": "arXiv",
    "abstract": "Dielectric metasurfaces provide a unique platform for efficient harmonic generation and optical wavefront manipulation at the nanoscale. While several approaches are available for performing wavefront shaping, the one exploiting geometric phase streamlines significantly the design and fabrication process. It has been recently shown that, in III-V semiconductor alloys, the rotation of the crystal axes affects the phase and amplitude of second-harmonic generation (SHG) induced by circularly polarized light [1]. Based on this notion, we fabricated and characterized two aluminum gallium arsenide metasurfaces displaying the versatility of the geometric phase design approach through nonlinear beam steering and structured-light generation on the harmonic field."
  },
  {
    "date": "2026-01-26",
    "title": "Generative AI in Saudi Arabia: A National Survey of Adoption, Risks, and Public Perceptions",
    "authors": "Abdulaziz AlDakheel, Ali Alshehre, Esraa Alamoudi, Moslim AlKhabbaz, Ahmed Aljohani, Raed Alharbi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18234v1",
    "source": "arXiv",
    "abstract": "Generative Artificial Intelligence (GenAI) is rapidly becoming embedded in Saudi Arabia's digital transformation under Vision 2030, yet public awareness, adoption, and concerns surrounding these tools remain underexplored. This study provides an early snapshot of GenAI engagement among Saudi nationals. Using a nationwide survey of 330 participants across regions, age groups, and employment sectors, we examine seven dimensions of GenAI use: awareness and understanding, adoption patterns, perceived impacts, training needs, risks and barriers, data-sharing behaviors, and future expectations. Findings show that 93% of respondents actively use GenAI primarily for text-based tasks, while more advanced uses such as programming or multimodal generation are less common. Despite the prevalence of use, overall awareness and conceptual understanding remain uneven, with many reporting limited technical knowledge. Participants recognize GenAI's benefits for productivity, work quality, and understanding complex information, yet caution that sustained reliance may undermine critical thinking and key professional skills. Trust in AI-generated outputs remains cautious, with widespread concerns about privacy, misinformation, and ethical misuse, including potential job displacement. Respondents show strong interest in structured GenAI training that combines foundational skills, domain-specific applications, and clear guidance on privacy, ethics, and responsible use. These results establish a baseline for GenAI engagement in Saudi Arabia and highlight priorities for policymakers and developers: expanding AI literacy, ensuring culturally and linguistically aligned GenAI solutions, and strengthening frameworks for privacy and responsible deployment."
  },
  {
    "date": "2026-01-26",
    "title": "ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants",
    "authors": "Pei Wang, Yanan Wu, Xiaoshuai Song, Weixun Wang, Gengru Chen, Zhongwen Li, Kezhong Yan, Ken Deng, Qi Liu, Shuaibing Zhao, Shaopan Xiong, Xuepeng Liu, Xuefeng Chen, Wanxi Deng, Wenbo Su, Bo Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18225v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator."
  },
  {
    "date": "2026-01-26",
    "title": "On the Generalized Conditional Gradient Method for Mean Field Games with Local Coupling Terms",
    "authors": "Haruka Nakamura, Norikazu Saito",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18224v1",
    "source": "arXiv",
    "abstract": "We study the generalized conditional gradient (GCG) method for time-dependent second-order mean field games (MFG) with local coupling terms. While explicit convergence rates of the GCG method were previously established only for globally coupled interactions, the assumptions used there fail to cover typical local interactions such as congestion effects. To overcome this limitation, we introduce a refined analytical framework adapted to local couplings and derive explicit convergence estimates in terms of the exploitability and optimality gap. The key difficulty lies in establishing uniform bounds on the Hamilton--Jacobi--Bellman solutions; this is solved via the Cole--Hopf transformation under a standard quadratic Hamiltonian with a convection effect. We further provide numerical experiments demonstrating convergence behavior and confirming the theoretical rates. Additionally, the existence and uniqueness of smooth solutions to the MFG system with locally coupled interactions are established."
  },
  {
    "date": "2026-01-26",
    "title": "PaperTok: Exploring the Use of Generative AI for Creating Short-form Videos for Research Communication",
    "authors": "Meziah Ruby Cristobal, Hyeonjeong Byeon, Tze-Yu Chen, Ruoxi Shang, Donghoon Shin, Ruican Zhong, Tony Zhou, Gary Hsieh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18218v1",
    "source": "arXiv",
    "abstract": "The dissemination of scholarly research is critical, yet researchers often lack the time and skills to create engaging content for popular media such as short-form videos. To address this gap, we explore the use of generative AI to help researchers transform their academic papers into accessible video content. Informed by a formative study with science communicators and content creators (N=8), we designed PaperTok, an end-to-end system that automates the initial creative labor by generating script options and corresponding audiovisual content from a source paper. Researchers can then refine based on their preferences with further prompting. A mixed-methods user study (N=18) and crowdsourced evaluation (N=100) demonstrate that PaperTok's workflow can help researchers create engaging and informative short-form videos. We also identified the need for more fine-grained controls in the creation process. To this end, we offer implications for future generative tools that support science outreach."
  },
  {
    "date": "2026-01-26",
    "title": "Dynamical Mass Loss at the End of TP-AGB stars",
    "authors": "Yingzhen Cui, Song Wang, Xiangcun Meng, Jifeng Liu, Shuguo Ma, Weitao Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18194v1",
    "source": "arXiv",
    "abstract": "The thermally pulsating asymptotic giant branch (TP-AGB) phase plays a key role in the evolution of low- to intermediate-mass stars, driving mass loss that influences their final stages and contributes to galactic chemical enrichment. However, the mechanisms behind mass loss, particularly at the end of AGB, are still not well understood. We aim to investigate the relationship between stellar parameters and envelope dynamics during the TP-AGB phase, evaluating whether dynamical instabilities in the envelope can act as a possible mass-loss mechanism. We use hydrodynamics method in MESA to simulate the dynamical pulsations and resulting mass loss during the TP-AGB phase of a star evolved from a 1.5 Msun zero-age main sequence. Our simulations reproduce the dynamical pulsation behavior of stars during the TP-AGB phase, demonstrating that the envelope mass is a key factor governing pulsational properties. As the envelope mass decreases, both the pulsation period and radial amplitude increase, consistent with observational trends. For 1.5 Msun model, once the envelope mass declines to approximately 0.25 Msun, the model enters a regime of violent pulsations, potentially ejecting the remaining envelope within a few hundred years. We suggest that the instability can act as the dominant mass-loss mechanism in the end of the TP-AGB phase, marking a rapid transitional stage toward the post-AGB phase."
  },
  {
    "date": "2026-01-26",
    "title": "InkIdeator: Supporting Chinese-Style Visual Design Ideation via AI-Infused Exploration of Chinese Paintings",
    "authors": "Shiwei Wu, Ziyao Gao, Zhendong He, Zongtan He, Zhupeng Huang, Xia Chen, Wei Zeng, Xiaojuan Ma, Zhenhui Peng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18193v1",
    "source": "arXiv",
    "abstract": "Visual designers often seek inspiration from Chinese paintings when tasked with creating Chinese-style illustrations, posters, etc. Our formative study (N=10) reveals that during ideation, designers learn the cultural symbols, emotions, compositions, and styles in Chinese paintings but face challenges in searching, analyzing, and integrating these dimensions. This paper leverages multi-modal large models to annotate the value of each dimension in 16,315 Chinese paintings, built on which we propose InkIdeator, an ideation support system for Chinese-style visual designs. InkIdeator suggests cultural symbols associated with the task theme, provides dimensional keywords to help analyze Chinese paintings, and generates visual examples integrating user-selected keywords. Our within-subjects study (N=12) using a baseline system without extracted dimensional keywords, along with two extended use cases by Chinese painters, indicates InkIdeator's effectiveness in creative ideation support, helping users efficiently explore cultural dimensions in Chinese paintings and visualize their ideas. We discuss implications for supporting culture-related visual design ideation with generative AI."
  },
  {
    "date": "2026-01-26",
    "title": "Smooth, Sparse, and Stable: Finite-Time Exact Skeleton Recovery via Smoothed Proximal Gradients",
    "authors": "Rui Wu, Yongjun Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18189v1",
    "source": "arXiv",
    "abstract": "Continuous optimization has significantly advanced causal discovery, yet existing methods (e.g., NOTEARS) generally guarantee only asymptotic convergence to a stationary point. This often yields dense weighted matrices that require arbitrary post-hoc thresholding to recover a DAG. This gap between continuous optimization and discrete graph structures remains a fundamental challenge. In this paper, we bridge this gap by proposing the Hybrid-Order Acyclicity Constraint (AHOC) and optimizing it via the Smoothed Proximal Gradient (SPG-AHOC). Leveraging the Manifold Identification Property of proximal algorithms, we provide a rigorous theoretical guarantee: the Finite-Time Oracle Property. We prove that under standard identifiability assumptions, SPG-AHOC recovers the exact DAG support (structure) in finite iterations, even when optimizing a smoothed approximation. This result eliminates structural ambiguity, as our algorithm returns graphs with exact zero entries without heuristic truncation. Empirically, SPG-AHOC achieves state-of-the-art accuracy and strongly corroborates the finite-time identification theory."
  },
  {
    "date": "2026-01-26",
    "title": "A strictly geostrophic product of sea-surface velocities from the SWOT fast-sampling phase",
    "authors": "Takaya Uchida, Badarvada Yadidya, Vadim Bertrand, Jia-Xian Chang, Brian Arbic, Jay Shriver, Julien Le Sommer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18182v1",
    "source": "arXiv",
    "abstract": "While geostrophy remains the simplest and most practical balance to extract velocity information from sea-surface height anomaly (SSHa), confusions remain within the oceanographic community to what extent this balance can be applied to altimetric observations with the launch of the Surface Water and Ocean Topography (SWOT) satellite. Given the limited temporal resolution of SWOT, many studies have resorted to claiming that the spatially filtered SSHa fields correspond to the geostrophic component. This introduces the ambiguity of which spatial scale to choose. Here, we build upon the recent developments in internal tide (IT) corrections (Yadidya et al., 2025) and apply a dynamic mode decomposition (DMD)-based method introduced by Lapo et al. (2025) to robustly extract the geostrophic component associated with sub-inertial frequencies from the SWOT one-day-repeat orbit; we distribute the global dataset as a public good. We provide the joint probability density function (PDF) of vorticity and strain, and spectra of SSHa at a few cross-over regions."
  },
  {
    "date": "2026-01-26",
    "title": "General tropical convergence of harmonic amoebas",
    "authors": "Takashi Ichikawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18180v1",
    "source": "arXiv",
    "abstract": "By using Schottky uniformization theory of degenerating algebraic curves, we describe the tropical convergence of harmonic amoebas of pointed Riemann surfaces to tropical curves which are not necessarily simple. We extend Lang's results on the simple tropical convergence based on the Frenchel-Nielsen coordinates to the nonsimple case. Our results are hoped to give contributions in compactifying the moduli space of pointed Riemann surfaces with tropical curves, and in studying crystallization of general dimer models."
  },
  {
    "date": "2026-01-26",
    "title": "Lip-Siri: Contactless Open-Sentence Silent Speech with Wi-Fi Backscatter",
    "authors": "Ye Tian, Haohua Du, Chao Gu, Junyang Zhang, Shanyue Wang, Hao Zhou, Jiahui Hou, Xiang-Yang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18177v1",
    "source": "arXiv",
    "abstract": "Silent speech interfaces (SSIs) enable silent interaction in noise-sensitive or privacy-sensitive settings. However, existing SSIs face practical deployment trade-offs among privacy, user experience, and energy consumption, and most remain limited to closed-set recognition over small, pre-defined vocabularies of words or sentences, which restricts real-world expressiveness. In this paper, we present Lip-Siri, to the best of our knowledge, the first Wi-Fi backscatter--based SSI that supports open-vocabulary sentence recognition via lexicon-guided subword decoding. Lip-Siri designs a frequency-shifted backscatter tag to isolate tag-modulated reflections and suppress interference from non-target motions, enabling reliable extraction of lip-motion traces from ubiquitous Wi-Fi signals. We then segment continuous traces into lip-motion units, cluster them, learn robust unit representations via cluster-based self-supervision, and finally propose a lexicon-guided Transformer encoder--decoder with beam search to decode variable-length sentence sequences. We implement an end-to-end prototype and evaluate it with 15 participants on 340 sentences and 3,398 words across multiple scenarios. Lip-Siri achieves 85.61% accuracy on word prediction and a WER of 36.87% on continuous sentence recognition, approaching the performance of representative vision-based lip-reading systems."
  },
  {
    "date": "2026-01-26",
    "title": "A new fine-scale Berry-Esseen-type Gumbel-limit theorem for multivariate maxima",
    "authors": "James Allen Fill",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18170v1",
    "source": "arXiv",
    "abstract": "For $d \\geq 2$ and i.i.d. $d$-dimensional observations $\\mathbf{X}^{(1)}, \\mathbf{X}^{(2)}, \\ldots$ with independent Exponential$(1)$ coordinates, let $\\varphi_n$ denote the minimum $\\ell^1$-norm among the maxima of $\\{\\mathbf{X}^{(1)}, \\ldots, \\mathbf{X}^{(n)}\\}$. (A _maximum_ from this set is an observation $\\mathbf{X}^{(k)}$ with $1 \\leq k \\leq n$ such that $\\mathbf{X}^{(k)} \\not\\prec \\mathbf{X}^{(i)}$ for all $1 \\leq i \\leq n$, where $\\mathbf{x} \\prec \\mathbf{y}$ means that $x_j < y_j$ for $1 \\leq j \\leq d$.) Key roles in the study of multivariate Pareto records are played by $\\varphi_n$ and by the more easily handled maximum with the maximum $\\ell^1$-norm. Fill, Naiman, and Sun (2024) proved that \\[ \\varphi_n = \\ln n - \\ln \\ln \\ln n - \\ln(d - 1) + O_{\\mathrm{p}}\\!\\left( \\frac{1}{\\ln \\ln n} \\right), \\] where $Z_n = O_{\\mathrm{p}}(a_n)$ means that $Z_n / a_n$ is bounded in probability, and conjectured that \\[ (\\ln \\ln n) \\left(\\varphi_n - [\\ln n - \\ln \\ln \\ln n - \\ln(d - 1)] \\right) \\] has a nondegenerate limiting distribution, suggesting that the limiting distribution might be that of $ - G$, where $G$ has a Gumbel distribution with location $ - \\frac{\\ln[(d - 1)!]}{d - 1}$ and scale $\\frac{1}{d - 1}$. In the present paper we prove a Berry-Esseen-type theorem for this convergence in distribution, thereby establishing a very sharp result for $\\varphi_n$."
  },
  {
    "date": "2026-01-26",
    "title": "TempDiffReg: Temporal Diffusion Model for Non-Rigid 2D-3D Vascular Registration",
    "authors": "Zehua Liu, Shihao Zou, Jincai Huang, Yanfang Zhang, Chao Tong, Weixin Si",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18168v1",
    "source": "arXiv",
    "abstract": "Transarterial chemoembolization (TACE) is a preferred treatment option for hepatocellular carcinoma and other liver malignancies, yet it remains a highly challenging procedure due to complex intra-operative vascular navigation and anatomical variability. Accurate and robust 2D-3D vessel registration is essential to guide microcatheter and instruments during TACE, enabling precise localization of vascular structures and optimal therapeutic targeting. To tackle this issue, we develop a coarse-to-fine registration strategy. First, we introduce a global alignment module, structure-aware perspective n-point (SA-PnP), to establish correspondence between 2D and 3D vessel structures. Second, we propose TempDiffReg, a temporal diffusion model that performs vessel deformation iteratively by leveraging temporal context to capture complex anatomical variations and local structural changes. We collected data from 23 patients and constructed 626 paired multi-frame samples for comprehensive evaluation. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) methods in both accuracy and anatomical plausibility. Specifically, our method achieves a mean squared error (MSE) of 0.63 mm and a mean absolute error (MAE) of 0.51 mm in registration accuracy, representing 66.7\\% lower MSE and 17.7\\% lower MAE compared to the most competitive existing approaches. It has the potential to assist less-experienced clinicians in safely and efficiently performing complex TACE procedures, ultimately enhancing both surgical outcomes and patient care. Code and data are available at: \\textcolor{blue}{https://github.com/LZH970328/TempDiffReg.git}"
  },
  {
    "date": "2026-01-26",
    "title": "Functionalities of Au2O, Au2O3, Au2O3-x, and nanosheets, including spontaneous polarization, using DFT and hybrid functional",
    "authors": "Yukio Watanabe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18165v1",
    "source": "arXiv",
    "abstract": "We used density functional theories (DFT) to investigate the properties of Au2O and Au2O3-x (x = 00.08) to reveal their remarkable functionalities. Hybrid functional theories accurately estimate the band gap (Eg) of oxides, and the present hybrid functional calculations determined Eg values of 0.96 eV for Au2O and 2.86 eV for Au2O3, which is >300% of the commonly accepted Eg of Au2O3 (0.85 eV). Moreover, we discovered spontaneous polarization (PS) in Au2O3, which is unusually large and advantageous for catalysis. The PS was retained even in 2-nm-thick Au2O3 nanosheets, similar to hyperferroelectric, generating a potential of 0.6 eV despite screening caused by surface reconstruction, which is a novel screening mechanism. Below a thickness of 0.8 nm, the PS vanished, and inversion symmetry emerged at 0.4 nm, suggesting a new approach to finding a paraelectric phase. Au2O was supersoft under shear distortion."
  },
  {
    "date": "2026-01-26",
    "title": "Lifecycle Cost-Effectiveness Modeling for Redundancy-Enhanced Multi-Chiplet Architectures",
    "authors": "Zizhen Liu, Fangzhiyi Wang, Mengdi Wang, Jing Ye, Hayden Kwok-Hay So, Cheng Liu, Huawei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18159v1",
    "source": "arXiv",
    "abstract": "The growing demand for compute-intensive applications has made multi-chiplet architectures a promising alternative to monolithic designs, offering improved scalability and manufacturing flexibility. However, effectively managing the economic effectiveness remains challenging. Existing cost models either overlook the amortization of compute value over a chip's operational lifetime or fail to evaluate how redundancy strategies, which are widely adopted to enhance yield and fault tolerance, impact long-term cost efficiency. This paper presents a comprehensive cost-effectiveness framework for multi-chiplet architectures, introducing a novel Lifecycle Cost Effectiveness (LCE) metric that evaluates amortized compute costs by jointly optimizing manufacturing expenses and operational lifetime. Our approach uniquely integrates: (1) redundancy-aware cost modeling spanning both intra- and inter-chiplet levels, (2) reliability-driven lifetime estimation, and (3) quantitative analysis of how redundancy configurations on overall economic effectiveness. Extensive trade-off and multi-objective optimization studies demonstrate the effectiveness of the model and reveal essential co-optimization strategies between module and chiplet-level redundancy to achieve cost-efficient multi-chiplet architecture designs."
  },
  {
    "date": "2026-01-26",
    "title": "AttenMIA: LLM Membership Inference Attack through Attention Signals",
    "authors": "Pedram Zaree, Md Abdullah Al Mamun, Yue Dong, Ihsen Alouani, Nael Abu-Ghazaleh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18110v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly deployed to enable or improve a multitude of real-world applications. Given the large size of their training data sets, their tendency to memorize training data raises serious privacy and intellectual property concerns. A key threat is the membership inference attack (MIA), which aims to determine whether a given sample was included in the model's training set. Existing MIAs for LLMs rely primarily on output confidence scores or embedding-based features, but these signals are often brittle, leading to limited attack success. We introduce AttenMIA, a new MIA framework that exploits self-attention patterns inside the transformer model to infer membership. Attention controls the information flow within the transformer, exposing different patterns for memorization that can be used to identify members of the dataset. Our method uses information from attention heads across layers and combines them with perturbation-based divergence metrics to train an effective MIA classifier. Using extensive experiments on open-source models including LLaMA-2, Pythia, and Opt models, we show that attention-based features consistently outperform baselines, particularly under the important low-false-positive metric (e.g., achieving up to 0.996 ROC AUC & 87.9% TPR@1%FPR on the WikiMIA-32 benchmark with Llama2-13b). We show that attention signals generalize across datasets and architectures, and provide a layer- and head-level analysis of where membership leakage is most pronounced. We also show that using AttenMIA to replace other membership inference attacks in a data extraction framework results in training data extraction attacks that outperform the state of the art. Our findings reveal that attention mechanisms, originally introduced to enhance interpretability, can inadvertently amplify privacy risks in LLMs, underscoring the need for new defenses."
  },
  {
    "date": "2026-01-26",
    "title": "Text-Pass Filter: An Efficient Scene Text Detector",
    "authors": "Chuang Yang, Haozhao Ma, Xu Han, Yuan Yuan, Qi Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18098v1",
    "source": "arXiv",
    "abstract": "To pursue an efficient text assembling process, existing methods detect texts via the shrink-mask expansion strategy. However, the shrinking operation loses the visual features of text margins and confuses the foreground and background difference, which brings intrinsic limitations to recognize text features. We follow this issue and design Text-Pass Filter (TPF) for arbitrary-shaped text detection. It segments the whole text directly, which avoids the intrinsic limitations. It is noteworthy that different from previous whole text region-based methods, TPF can separate adhesive texts naturally without complex decoding or post-processing processes, which makes it possible for real-time text detection. Concretely, we find that the band-pass filter allows through components in a specified band of frequencies, called its passband but blocks components with frequencies above or below this band. It provides a natural idea for extracting whole texts separately. By simulating the band-pass filter, TPF constructs a unique feature-filter pair for each text. In the inference stage, every filter extracts the corresponding matched text by passing its pass-feature and blocking other features. Meanwhile, considering the large aspect ratio problem of ribbon-like texts makes it hard to recognize texts wholly, a Reinforcement Ensemble Unit (REU) is designed to enhance the feature consistency of the same text and to enlarge the filter's recognition field to help recognize whole texts. Furthermore, a Foreground Prior Unit (FPU) is introduced to encourage TPF to discriminate the difference between the foreground and background, which improves the feature-filter pair quality. Experiments demonstrate the effectiveness of REU and FPU while showing the TPF's superiority."
  },
  {
    "date": "2026-01-26",
    "title": "Sparks of Cooperative Reasoning: LLMs as Strategic Hanabi Agents",
    "authors": "Mahesh Ramesh, Kaousheik Jayakumar, Aswinkumar Ramkumar, Pavan Thodima, Aniket Rege",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18077v1",
    "source": "arXiv",
    "abstract": "Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication. We benchmark 17 state-of-the-art LLM agents in 2-5 player games and study the impact of context engineering across model scales (4B to 600B+) to understand persistent coordination failures and robustness to scaffolding: from a minimal prompt with only explicit card details (Watson setting), to scaffolding with programmatic, Bayesian-motivated deductions (Sherlock setting), to multi-turn state tracking via working memory (Mycroft setting). We show that (1) agents can maintain an internal working memory for state tracking and (2) cross-play performance between different LLMs smoothly interpolates with model strength. In the Sherlock setting, the strongest reasoning models exceed 15 points on average across player counts, yet still trail experienced humans and specialist Hanabi agents, both consistently scoring above 20. We release the first public Hanabi datasets with annotated trajectories and move utilities: (1) HanabiLogs, containing 1,520 full game logs for instruction tuning, and (2) HanabiRewards, containing 560 games with dense move-level value annotations for all candidate moves. Supervised and RL finetuning of a 4B open-weight model (Qwen3-Instruct) on our datasets improves cooperative Hanabi play by 21% and 156% respectively, bringing performance to within ~3 points of a strong proprietary reasoning model (o4-mini) and surpassing the best non-reasoning model (GPT-4.1) by 52%. The HanabiRewards RL-finetuned model further generalizes beyond Hanabi, improving performance on a cooperative group-guessing benchmark by 11%, temporal reasoning on EventQA by 6.4%, instruction-following on IFBench-800K by 1.7 Pass@10, and matching AIME 2025 mathematical reasoning Pass@10."
  },
  {
    "date": "2026-01-26",
    "title": "Secure Beamforming and Reflection Design for RIS-ISAC Systems under Collusion of Passive and Active Eavesdroppers",
    "authors": "Tian Zhang, Zhirong Su, Yueyi Dong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18063v1",
    "source": "arXiv",
    "abstract": "In the paper, the physical-layer security for reconfigurable intelligent surface (RIS) aided integrated sensing and communication (ISAC) system is studied. There is an active eavesdropper (AE) as well as a passive eavesdropper (PE), and they cooperate each other. By joint base station beamforming and RIS reflection design, we aim to achieve the best secure data communications with guaranteed sensing performance. Mathematically, taking the constraints on sensing performance and transmission power in consideration, the system secrecy rate maximization problem is formulated with respect to transmitting beamforming, RIS reflection, and receiving beamforming. The formulated problem is non-convex and is decomposed to three subproblem by applying the alternating optimization scheme. For the decomposed subproblem, we utilize the quadratic penalty method and successive convex approximation (SCA) for the solution derivation. Thereafter, an iterative numerical algorithm, referred to as the joint beamforming and reflection design (JBRD) algorithm, is proposed. Finally, numerical results demonstrate the effectiveness and superiority of the proposed algorithm."
  },
  {
    "date": "2026-01-26",
    "title": "Di-Graphs with tightly connected Clusters: Effective Graph Laplacians and Resolvent Convergence",
    "authors": "Christian Koke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18057v1",
    "source": "arXiv",
    "abstract": "In this note, we study Laplacians on graphs for which connectivity within certain sub-graphs tends to infinity. Our main focus are graphs sharing a common node set on which edge weights within certain clusters grow to infinity. As intra-cluster connectivity increases, we show that the corresponding graph Laplacians converge -- in the resolvent sense -- to an effective graph Laplacian. This effective limit Laplacian is defined on a coarsened graph, where each highly connected cluster is collapsed into a single node. In the undirected setting, the effective Laplacian arises naturally from agregating over tightly connected clusters. In the directed case, the limiting graph structure depends on the precise manner in which connectivity increases; with the corresponding effects mediated by the left and right kernel structure of the Laplacian restricted to high-connectivity clusters. Our results shed light on the emergence of coarse-grained dynamics in large-scale networks and contribute to spectral graph theory of directed graphs."
  },
  {
    "date": "2026-01-26",
    "title": "Neurocomputational Mechanisms of Syntactic Transfer in Bilingual Sentence Production",
    "authors": "Ahmet Yavuz Uluslu, Elliot Murphy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18056v1",
    "source": "arXiv",
    "abstract": "We discuss the benefits of incorporating into the study of bilingual production errors and their traditionally documented timing signatures (e.g., event-related potentials) certain types of oscillatory signatures, which can offer new implementational-level constraints for theories of bilingualism. We argue that a recent neural model of language, ROSE, can offer a neurocomputational account of syntactic transfer in bilingual production, capturing some of its formal properties and the scope of morphosyntactic sequencing failure modes. We take as a case study cross-linguistic influence (CLI) and attendant theories of functional inhibition/competition, and present these as being driven by specific oscillatory failure modes during L2 sentence planning. We argue that modeling CLI in this way not only offers the kind of linking hypothesis ROSE was built to encourage, but also licenses the exploration of more spatiotemporally complex biomarkers of language dysfunction than more commonly discussed neural signatures."
  },
  {
    "date": "2026-01-26",
    "title": "Large Coupling Limits Beyond Definiteness",
    "authors": "Christian Koke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18055v1",
    "source": "arXiv",
    "abstract": "We study convergence of operator families of the form $A_β= A + βB $ towards an effective operator defined on $\\ker(B)$, as the couling constant $β$ tends to infinity. Crucially, we focus on the setting where neither $A$ nor $B$ can be assumed to be positive- (or negative-) semi-definite. We are hence outside the classical form-theoretic framework, where results based on on Kato's monotone convergence theorem would be applicable. Thus, instead of form methods, our approach builds on classical resolvent identities to study convergence of the family $\\{A_β\\}_β$. Our findings are that: (i) Strong resolvent convergence holds (without further spectral assumptions) if $A + βB$ is self-adjoint and the compression of $A$ onto $\\ker(B)$ is well behaved. (ii) Under the more detailed assumption that $0 \\in σ(B)$ is isolated, norm resolvent convergence can be established even if $A+βB$ is merely closed, provided the quasi-nilpotent part of $B$ at zero vanishes and certain conditions on the interplay of $A$ and $B$ are met. Importantly, if $B$ is not self-adjoint we find that the limit operator not only depends on $\\ker(B)$ as a Hilbert space, but crucially also on the precise form of the Riesz projector at $0 \\in σ(B)$ onto $\\ker(B)$."
  },
  {
    "date": "2026-01-26",
    "title": "REMAC: Reference-Based Martian Asymmetrical Image Compression",
    "authors": "Qing Ding, Mai Xu, Shengxi Li, Xin Deng, Xin Zou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18547v1",
    "source": "arXiv",
    "abstract": "To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \\textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \\textit{intra-} and \\textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \\textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \\textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB."
  },
  {
    "date": "2026-01-26",
    "title": "GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning",
    "authors": "Kaixun Jiang, Yuzheng Wang, Junjie Zhou, Pandeng Li, Zhihang Liu, Chen-Wei Xie, Zhaoyu Chen, Yun Zheng, Wenqiang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18543v1",
    "source": "arXiv",
    "abstract": "We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\\%) and WISE (+14\\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \\href{https://github.com/deep-kaixun/GenAgent}{this url}."
  },
  {
    "date": "2026-01-26",
    "title": "XFit: Global Optimization and Degeneracy Mapping in X-ray Spectral Modeling",
    "authors": "Austin MacMaster, Adam Rogers, Jason Fiege, Rebecca Man, Samar Safi-Harb",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18542v1",
    "source": "arXiv",
    "abstract": "The standard approach to modeling X-ray spectral data relies on local optimization methods, such as the Levenberg-Marquardt algorithm. While effective for simple models and speedy spectral fitting, these local optimizers are prone to becoming trapped in local minima, particularly in high-dimensional or degenerate parameter spaces, and typically require extensive user intervention. In this work, we introduce XFit, a global optimization method for fitting X-ray data, which makes extensive use of the Ferret evolutionary algorithm. XFit enables automated exploration of complex parameter spaces, efficient mapping of confidence intervals, and identification of degenerate solutions that may be overlooked by local methods. We demonstrate the performance of XFit using two representative X-ray sources: the Central Compact Object in Cassiopeia A and the supernova remnant G41.1-0.3. These examples span both low- and high-dimensional models, allowing us to illustrate the advantages of global optimization. In both cases, XFit produces solutions that are consistent with or improve upon those found with traditional methods, while also revealing alternative fits or degenerate solutions within statistically acceptable confidence levels. The automated mapping of parameter space offered by XFit makes it a powerful complement to existing spectral fitting tools, particularly as models and data quality become increasingly complex. Future work will expand the application of XFit to broader datasets and more physically motivated models."
  },
  {
    "date": "2026-01-26",
    "title": "Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features",
    "authors": "Abishek Stephen, Jindřich Libovický",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18536v1",
    "source": "arXiv",
    "abstract": "We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems."
  },
  {
    "date": "2026-01-26",
    "title": "N.E.O.N.-Bridge Geometry Determination: Turbulence Modeling of Individual N.E.O.N.-Bridge Segment",
    "authors": "Arturo Rodriguez, Dominic Alexander, Nicolas J. Torres, Benay Ozcelik, Omar Escudero, Ty Reitzel, Pablo Rangel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18529v1",
    "source": "arXiv",
    "abstract": "The N.E.O.N.-Bridge is a capstone project being developed by students at TAMUCC, under the oversight of Los Alamos National Laboratory. The project requires the development of a hull geometry for an autonomous bridge segment optimized to support onboard electronics and camera systems while maintaining stability in a dynamic water environment. Traditional ribbon bridge systems typically do not experience intense hydrodynamic loading due to current transportation and assembly methods, whereas the N.E.O.N-Bridge must continuously withstand forces from dynamic flow patterns. The requirement for a hull geometry to have both hydrodynamic design and rigidity, as in current ribbon bridges, has posed unique challenges. The current hull designs were evaluated through turbulent water-flow simulations performed with ANSYS Discovery. Boundary conditions were determined based on the forward motion of the bridge segment, simulating inlet and outlet flows, and the resulting pressure distribution. A waterline-based geometric constraint derived from the camera system's elevation enabled the simulation to model flow characteristics in an operational scenario. Velocity fields, pressure contours, and turbulent flow patterns were analyzed to identify areas of high loading and hydrodynamic inefficiencies. The findings will provide essential performance metrics that could be used to make design adjustments to the overall hull geometry. The simulation results will support improvements in stability, structural rigidity, and overall effectiveness of the hull geometry, advancing the development of the N.E.O.N-Bridge segments."
  },
  {
    "date": "2026-01-26",
    "title": "Scalable Transit Delay Prediction at City Scale: A Systematic Approach with Multi-Resolution Feature Engineering and Deep Learning",
    "authors": "Emna Boudabbous, Mohamed Karaa, Lokman Sboui, Julio Montecinos, Omar Alam",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18521v1",
    "source": "arXiv",
    "abstract": "Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture. We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the \"giant cluster\" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training. We compare five model architectures on six months of bus operations from the Société de transport de Montréal (STM) network in Montréal. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation."
  },
  {
    "date": "2026-01-26",
    "title": "Fibers of phase tropicalizations",
    "authors": "Andrei Bengus-Lasnier, Mikhail Shkolnikov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18519v1",
    "source": "arXiv",
    "abstract": "The subject of the present paper is phase tropicalization, which was used crucially in the context of Mikhalkin's correspondence theorem for curve counting in the complex coefficient case. The subject can be traced back to Viro's patchworking for constructing topological types of real algebraic curves. These two instances correspond to complex and real phases. Both fall into the category of what can be called \"abelian\" or classical tropicalization, referring to degenerations of varieties within an algebraic torus (or its compactification). In contrast, in \"non-abelian\" tropicalizations the ambient torus is replaced by a non-commutative group such as the special linear group. This is the beginning of a general theory valid for a wide array of coefficient systems and dimensions. As an application, the paper settles the question of phase tropicalization for the special linear group $\\mathrm{SL}_2$. It also gives an algebraic explanation and phase extension of the case of curves, previously studied in the purely geometric framework. To accomplish these tasks we introduce valuative tools that allow us to prove an affine version of Kapranov's theorem on tropical hypersurfaces and its generalization to arbitrary tropical varieties. Most notably, we show the functorial properties of the graded ring of a valuation and exhibit the polynomial structure of the graded ring of monomial valuations."
  },
  {
    "date": "2026-01-26",
    "title": "Quantum Key Distribution with a Negatively Charged Quantum Dot Single-Photon Source",
    "authors": "Parvendra Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18518v1",
    "source": "arXiv",
    "abstract": "Various quantum key distribution protocols require bright single-photon sources with a very low probability of multiphoton emission. In this work, we investigate single-photon generation from a negatively charged quantum dot embedded in an elliptical pillar microcavity, driven using either resonant excitation or adiabatic rapid passage (ARP). Our results show that ARP excitation significantly suppresses multiphoton emission probability and improves photon indistinguishability compared to resonant excitation. We further evaluate the secure key rate of both BB84 and twin-field quantum key distribution (TF-QKD) using quantum-dot single-photon sources and compare their performance with that of Poisson-distributed photon sources (PDS) such as weak coherent pulses and down-conversion sources. The analysis reveals that adiabatic excitation offers a modest but consistent enhancement in secure key rate relative to resonant excitation. Moreover, quantum-dot single-photon sources outperform PDS sources over short and intermediate distances; however, at longer distances, PDS sources eventually surpass quantum-dot sources in both infinite decoy-state BB84 and TF-QKD."
  },
  {
    "date": "2026-01-26",
    "title": "LipNeXt: Scaling up Lipschitz-based Certified Robustness to Billion-parameter Models",
    "authors": "Kai Hu, Haoqi Hu, Matt Fredrikson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18513v1",
    "source": "arXiv",
    "abstract": "Lipschitz-based certification offers efficient, deterministic robustness guarantees but has struggled to scale in model size, training efficiency, and ImageNet performance. We introduce \\emph{LipNeXt}, the first \\emph{constraint-free} and \\emph{convolution-free} 1-Lipschitz architecture for certified robustness. LipNeXt is built using two techniques: (1) a manifold optimization procedure that updates parameters directly on the orthogonal manifold and (2) a \\emph{Spatial Shift Module} to model spatial pattern without convolutions. The full network uses orthogonal projections, spatial shifts, a simple 1-Lipschitz $β$-Abs nonlinearity, and $L_2$ spatial pooling to maintain tight Lipschitz control while enabling expressive feature mixing. Across CIFAR-10/100 and Tiny-ImageNet, LipNeXt achieves state-of-the-art clean and certified robust accuracy (CRA), and on ImageNet it scales to 1-2B large models, improving CRA over prior Lipschitz models (e.g., up to $+8\\%$ at $\\varepsilon{=}1$) while retaining efficient, stable low-precision training. These results demonstrate that Lipschitz-based certification can benefit from modern scaling trends without sacrificing determinism or efficiency."
  },
  {
    "date": "2026-01-26",
    "title": "Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research",
    "authors": "Antonio Garzon-Vico, Krithika Sharon Komalapati, Arsalan Shahid, Jan Rosier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18512v1",
    "source": "arXiv",
    "abstract": "This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings."
  },
  {
    "date": "2026-01-26",
    "title": "Imperfect blockade in Rydberg superatoms",
    "authors": "Valentin Magro, Sébastien Garcia, Alexei Ourjoumtsev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18506v1",
    "source": "arXiv",
    "abstract": "Ensembles of atoms interacting via their Rydberg levels, known as \"superatoms\" for their ability to encode qubits and to emit single photons, attract increasing attention as building blocks for quantum network nodes. Assessing their performance requires an accurate, physically informative and numerically scalable description of interactions in a large and disordered ensemble. We derive such a description from first principles and successfully test it against brute-force numerics and experimental data. This model proves essential to make quantitative predictions about gate fidelities or photon emission efficiencies, and to guide experiments towards large-scale superatom-based systems."
  },
  {
    "date": "2026-01-26",
    "title": "Pointwise-in-time convergence analysis of an Alikhanov scheme for a 2D nonlinear subdiffusion equation",
    "authors": "Chang Hou, Hu Chen, Jian Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18505v1",
    "source": "arXiv",
    "abstract": "In this paper, we discretize the Caputo time derivative of order α\\in (0,1) using the Alikhanov scheme on a quasi-graded temporal mesh, and employ the Newton linearization method to approximate the nonlinear term. This yields a linearized fully discrete scheme for the two-dimensional nonlinear time fractional subdiffusion equation with weakly singular solutions. For the purpose of conducting a pointwise convergence analysis using the comparison principle, we develop a new stability result. The global L^2-norm convergence order is min{αr, 2}, and the local L^2-norm convergence order is min{r, 2} under appropriate conditions and assumptions. Ultimately, the rates of convergence demonstrated by the numerical experiments serve to validate the analytical outcomes."
  },
  {
    "date": "2026-01-26",
    "title": "DV-VLN: Dual Verification for Reliable LLM-Based Vision-and-Language Navigation",
    "authors": "Zijun Li, Shijie Li, Zhenxi Zhang, Bin Li, Shoujun Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18492v1",
    "source": "arXiv",
    "abstract": "Vision-and-Language Navigation (VLN) requires an embodied agent to navigate in a complex 3D environment according to natural language instructions. Recent progress in large language models (LLMs) has enabled language-driven navigation with improved interpretability. However, most LLM-based agents still rely on single-shot action decisions, where the model must choose one option from noisy, textualized multi-perspective observations. Due to local mismatches and imperfect intermediate reasoning, such decisions can easily deviate from the correct path, leading to error accumulation and reduced reliability in unseen environments. In this paper, we propose DV-VLN, a new VLN framework that follows a generate-then-verify paradigm. DV-VLN first performs parameter-efficient in-domain adaptation of an open-source LLaMA-2 backbone to produce a structured navigational chain-of-thought, and then verifies candidate actions with two complementary channels: True-False Verification (TFV) and Masked-Entity Verification (MEV). DV-VLN selects actions by aggregating verification successes across multiple samples, yielding interpretable scores for reranking. Experiments on R2R, RxR (English subset), and REVERIE show that DV-VLN consistently improves over direct prediction and sampling-only baselines, achieving competitive performance among language-only VLN agents and promising results compared with several cross-modal systems.Code is available at https://github.com/PlumJun/DV-VLN."
  },
  {
    "date": "2026-01-26",
    "title": "An obstruction to fiberwise Anosov flows over 3-dimensional Anosov flows",
    "authors": "Neige Paulet, Danyu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18487v1",
    "source": "arXiv",
    "abstract": "We study obstructions preventing a three-dimensional Anosov flow from serving as the base of a fiberwise Anosov flow. We prove a non-existence result if the base flow admits infinitely many periodic orbits in the same free homotopy class. We get as a corollary that any R-covered Anosov flow serving as the base of a fiberwise Anosov flow is orbit equivalent to a suspension or a geodesic flow."
  },
  {
    "date": "2026-01-26",
    "title": "Physics-Informed Hybrid Quantum-Classical Dispatching for Large-Scale Renewable Power Systems:A Noise-Resilient Framework",
    "authors": "Fu Zhang, Yuming Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18482v1",
    "source": "arXiv",
    "abstract": "The integration of high-penetration renewable energy introduces significant stochasticity and non-convexity into power system dispatching, challenging the computational limits of classical optimization. While Variational Quantum Algorithms (VQAs) on Noisy Intermediate-Scale Quantum (NISQ) devices offer a promising path for combinatorial acceleration, existing approaches typically treat the power grid as a \"black box\", suffering from poor scalability (barren plateaus) and frequent violations of physical constraints. Bridging these gaps, this paper proposes a Physics-Informed Hybrid Quantum-Classical Dispatching (PI-HQCD) framework. We construct a topology-aware Hamiltonian that explicitly embeds linearized power flow equations, storage dynamics, and multi-timescale coupling directly into the quantum substrate, significantly reducing the search space dimensionality. We further derive a noise-adaptive regularization mechanism that theoretically bounds the effective Lipschitz constant of the objective function, guaranteeing convergence stability under realistic quantum measurement noise. Numerical experiments on the IEEE 39-bus benchmark and a 118-bus regional grid demonstrate that PI-HQCD achieves superior economic efficiency and higher renewable utilization compared to stochastic dual dynamic programming (SDDP). Theoretical analysis confirms that this topology-aware design leads to an O(1/N) gradient variance scaling, effectively mitigating barren plateaus and ensuring scalability for larger networks. This work establishes a rigorous paradigm for embedding engineering physics into quantum computing, paving the way for practical quantum advantage in next-generation grid operations."
  },
  {
    "date": "2026-01-26",
    "title": "Repellent properties of perfect powers on partition functions: a heuristic approach",
    "authors": "Summer Haag, Praneel Samanta, Swati, Holly Swisher, Stephanie Treneer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18138v1",
    "source": "arXiv",
    "abstract": "In 2013, Sun conjectured that the partition function $p(n)$ is never a perfect power for $n \\geq 2$. Building on this, Merca, Ono, and Tsai recently observed that for any fixed integers $d \\geq 0$ and $k \\geq 2$, there appear to be only finitely many integers $n$ such that $p(n)$ differs from a perfect $k$th power by at most $d$. Denoting by $M_k(d)$ the largest such $n$, they conjectured that $M_k(d) = o(d^ε)$ for every $ε> 0$. In this paper, we investigate the asymptotic growth of analogs of $M_k(d)$ for a wide class of partition functions. We establish sharp lower bounds and provide heuristics which suggest that $M_k(d)$ in fact grows polylogarithmically in $d$, i.e. of order $\\log^2(d)$. More generally, we prove that if $f(n)$ is a suitably random chosen function with asymptotic growth rate similar to that of $p(n)$, then the set of integers $n$ for which $f(n)$ is a perfect power is finite with probability 1."
  },
  {
    "date": "2026-01-26",
    "title": "Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing",
    "authors": "Kiana Jafari, Paul Ulrich Nikolaus Rust, Duncan Eddy, Robbie Fraser, Nina Vasan, Darja Djordjevic, Akanksha Dadlani, Max Lamparth, Eugenia Kim, Mykel Kochenderfer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18061v1",
    "source": "arXiv",
    "abstract": "Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $α= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement."
  },
  {
    "date": "2026-01-26",
    "title": "Vanishing Compactness Gap and Fermionic Compact Dark Matter in Hořava-Lifshitz Gravity",
    "authors": "Edwin J. Son, Kyungmin Kim, John J. Oh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18079v1",
    "source": "arXiv",
    "abstract": "We show that the gap in the compactness between black holes and neutron stars witnessed in general relativity may be vanishing in Hořava-Lifshitz (HL) gravity. Assuming a fermion equation-of-state for simplicity, and solving the Tolman-Oppenheimer-Volkoff equation within the HL gravity framework, we see that there exists a minimum fermion mass $m_f^\\text{(min)}(q,y)$, above which the gap of the compactness between black hole and fermionic compact object vanishes, for a given deformation parameter $q$ of HL and interaction strength $y$ between fermions. Thus, in HL gravity, the mass and radius of an object found in the lower mass gap by LIGO-Virgo-KAGRA observations might not be able to classify it as a black hole or a neutron star. It is interesting to note that a fermion of mass $\\sim 40\\ \\text{GeV}$ can form a highly compact object of mass $\\sim 10^{-4}\\ \\msun$ and radius $\\sim 1\\ \\text{m}$ that may play the role of the cold dark matter. In addition, we find the possible existence of another class of compact objects whose compactness is comparable to that of a black hole."
  },
  {
    "date": "2026-01-26",
    "title": "Holographic timelike entanglement and subregion complexity with scalar hair",
    "authors": "Hadyan Luthfan Prihadi, Muhammad Alifaldi Ramadhan Al-Faritsi, Rafi Rizqy Firdaus, Fitria Khairunnisa, Yanoar Pribadi Sarwono, Freddy Permana Zen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18310v1",
    "source": "arXiv",
    "abstract": "We investigate the holographic timelike entanglement entropy (HTEE) and timelike subregion complexity of a thermal CFT$_d$ deformed by a relevant scalar operator $φ_0$, dual to a hairy black hole in AdS$_{d+1}$. We employ the prescription of merging spacelike and timelike surfaces at the interior, constructing an extremal surface homologous to a boundary timelike subsystem with a time interval $Δt$. Consequently, this deformation breaks the invariance of the imaginary component of HTEE observed in pure AdS$_3$ and BTZ geometry, introducing a nontrivial dependence on $Δt$. At small $Δt$, we derive analytical expressions that are in agreement with numerical results, and observe partial consistency with analytic continuation to temporal or spacelike entanglement entropy at the level of the near-boundary expansion. However, analytic continuation of CFT temporal entanglement entropy fails to reproduce the HTEE calculations under boundary deformation, even in $d=2$. Furthermore, we extend the numerical calculations to higher dimensions ($d=3$). In addition, we study holographic timelike subregion complexity within the complexity=volume conjecture and find that it remains real-valued, providing a complementary geometric probe of the black hole interior. In particular, for the BTZ black hole, we analytically show that the UV-finite term of the subregion complexity receives its entire contribution from the interior region alone."
  },
  {
    "date": "2026-01-26",
    "title": "Data-Efficient Electromagnetic Surrogate Solver Through Dissipative Relaxation Transfer Learning",
    "authors": "Sunghyun Nam, Chan Y. Park, Min Seok Jang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18235v1",
    "source": "arXiv",
    "abstract": "In neural-network surrogate solvers for electromagnetic simulations, accurately modeling resonant phenomena remains a central challenge. High-amplitude resonances generate strongly localized field patterns that appear as outlier samples, deviating significantly from the general distribution of non-resonant cases, leading to instability and degraded predictive performance. To address this, we introduce dissipative relaxation transfer learning (DIRTL), a data-efficient training framework that integrates transfer learning with loss-regularized optimization principles from high-Q photonics. DIRTL first pretrains the model on data generated with a small fictitious material loss, which broadens sharp resonant modes and suppresses extreme field amplitudes. This smoothing of the response landscape enables the model to learn global modal features more effectively. The pretrained model is subsequently fine-tuned on the target lossless dataset containing the true high-amplitude resonances, allowing stable adaptation based on the pretrained information. Applied to both the Fourier Neural Operator (FNO) and UNet architectures, DIRTL yields substantial improvements in prediction accuracy, including up to a two-fold error reduction for the FNO variant. Furthermore, DIRTL exhibits robustness across diverse training conditions and supports strong multi-task performance, underscoring the generalizability and flexibility of the pretrained core. Altogether, these results establish DIRTL as a physically grounded and architecture-agnostic curriculum for enhancing the reliability of machine-learning-based electromagnetic surrogate solvers."
  },
  {
    "date": "2026-01-26",
    "title": "tilepy: A Flexible Open-Source Scheduling Engine for Time-Domain and Multi-Messenger Astronomy",
    "authors": "Fabian Schüssler, H. Ashkar, W. Kiendrébéogo, M. Seglar-Arroyo, M. de Bony, A. Berti, E. Ruiz-Velasco, R. Le Montagner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18668v1",
    "source": "arXiv",
    "abstract": "The era of multi-messenger astrophysics requires rapid and efficient follow-up of transient events, many of which, such as gravitational waves (GW), gamma-ray bursts (GRB), and high-energy neutrinos, suffer from poor sky localisation. We present tilepy, a Python-based software designed to optimize observation schedules for these events. We here detail the modular architecture of tilepy, which separates high-level scheduling logic from low-level tiling and pointing tools, enabling full adaptability for ground- and space-based observatories. Furthermore, we describe the integration of tilepy into the Astro-COLIBRI platform, providing the community with a user-friendly interface and API for triggering complex observation campaigns in real time."
  },
  {
    "date": "2026-01-26",
    "title": "Synchronization and Localization in Ad-Hoc ICAS Networks Using a Two-Stage Kuramoto Method",
    "authors": "Dominik Neudert-Schulz, Thomas Dallmann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18643v1",
    "source": "arXiv",
    "abstract": "To enable Integrated Communications and Sensing (ICAS) in a peer-to-peer vehicular network, precise synchronization in frequency and phase among the communicating entities is required. In addition, self-driving cars need accurate position estimates of the surrounding vehicles. In this work, we propose a joint, distributed synchronization and localization scheme for a network of communicating entities. Our proposed scheme is mostly signal-agnostic and therefore can be applied to a wide range of possible ICAS signals. We also mitigate the effect of finite sampling frequencies, which otherwise would degrade the synchronization and localization performance severely."
  },
  {
    "date": "2026-01-26",
    "title": "Information Hidden in Gradients of Regression with Target Noise",
    "authors": "Arash Jamshidi, Katsiaryna Haitsiukevich, Kai Puolamäki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18546v1",
    "source": "arXiv",
    "abstract": "Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $Σ$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $Ω(1)$ factor. The proposed method is practical (a \"set target-noise variance to $n$\" rule) and robust (variance $\\mathcal{O}(n)$ suffices to recover $Σ$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data."
  },
  {
    "date": "2026-01-26",
    "title": "Robust Learning of a Group DRO Neuron",
    "authors": "Guyang Cao, Shuyao Li, Sushrut Karmalkar, Jelena Diakonikolas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18115v1",
    "source": "arXiv",
    "abstract": "We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\\mathcal p_{[1]},\\dots,\\mathcal p_{[K]}$, we seek to approximate $\\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\\boldsymbolλ \\in Δ_K$, where the objective is $\\sum_{i \\in [K]}λ_{[i]}\\,\\mathbb E_{(\\mathbf x,y)\\sim\\mathcal p_{[i]}}(σ(\\mathbf w\\cdot\\mathbf x)-y)^2 - νd_f(\\boldsymbolλ,\\frac{1}{K}\\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $ν\\geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\\widehat{\\mathbf w}$ that is constant-factor competitive with $\\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks."
  },
  {
    "date": "2026-01-26",
    "title": "Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling",
    "authors": "Yunfei Qiu, Qiqiong Ma, Tianhua Lv, Li Fang, Shudong Zhou, Wei Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18049v1",
    "source": "arXiv",
    "abstract": "Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance."
  },
  {
    "date": "2026-01-26",
    "title": "Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes",
    "authors": "Amrith Setlur, Zijian Wang, Andrew Cohen, Paria Rashidinejad, Sang Michael Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18795v1",
    "source": "arXiv",
    "abstract": "Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings."
  },
  {
    "date": "2026-01-26",
    "title": "MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data",
    "authors": "Brian Liu, Oiwi Parker Jones",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18792v1",
    "source": "arXiv",
    "abstract": "Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain."
  },
  {
    "date": "2026-01-26",
    "title": "Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings",
    "authors": "Mumin Jia, Jairo Diaz-Rodriguez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18788v1",
    "source": "arXiv",
    "abstract": "Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation."
  },
  {
    "date": "2026-01-26",
    "title": "A Novel Lensed Point Source Modeling Pipeline using GIGA-Lens with Application to SN Zwicky and SN iPTF16geu",
    "authors": "Saul Baltasar, Nicolas Ratier-Werbin, Xiaosheng Huang, W. Sheu, C. J. Storfer, Y. -M. Hsu, Sean Xu, David J. Schlegel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18787v1",
    "source": "arXiv",
    "abstract": "We introduce a novel modeling pipeline for strongly lensed point sources, using the GIGA-Lens framework, running on four A100 GPUs via the JAX platform. Using simulations, we demonstrate accurate and precise recovery of image positions, fluxes, and time delays, together with inference of complex lens mass distributions -- including the mass density slope, $γ$ -- from images of lensed point sources alone. We further show that we can achieve statistical uncertainty of $\\sim 3.6\\%$ ($\\sim 2.5\\, \\mathrm{km\\, s^{-1}/Mpc}$) on $H_0$ from a single system, with full forward modeling, i.e., simultaneous inference of all lens model parameters together with $H_0$. We apply our pipeline to two well-studied lensed SNe Ia, Zwicky and iPTF16geu. For SN iPTF16geu, unlike previous modeling efforts, we model only the images of the lensed point source (the SN) and do not use the lensed images of the extended host-galaxy. Nevertheless, we are able to infer all of the mass parameters modeled in earlier studies, and our best-fit values, including $γ$, are fully consistent with published results. In the case of SN Zwicky, taking the same approach, however, we obtain an alternative best-fit model compared to published results, underscoring the importance of fully exploring the model parameter space."
  },
  {
    "date": "2026-01-26",
    "title": "OptiGAN for Crystal Arrays: Physics-Informed Generative Modeling of Optical Photon Transport in PET Detector Arrays",
    "authors": "Stephan Naunheim, Brandon Pardi, Guneet Mummaneni, Carlotta Trigila, Emilie Roncali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18780v1",
    "source": "arXiv",
    "abstract": "Monte Carlo simulations of optical photon transport are computationally prohibitive for large-scale optical systems including detector arrays and PET systems, restricting practical use to single-crystal studies. This work presents an enhanced conditional generative adversarial network (optiGAN) replacing optical simulations at the crystal array level, extending our single-crystal approach to a 3x3 BGO array. We enhance the Wasserstein-GAN framework with Fourier feature encoding, a learnable latent mapping network, and a physics-informed loss enforcing momentum conservation. Training data is reduced eight-fold by exploiting symmetry. Evaluation employs three studies: a full array evaluation testing generalization from the fundamental domain to the complete geometry, a high-resolution study probing out-of-distribution generalization to untrained positions, and a pencil beam $γ$-photon study assessing practical applicability for experimental detector characterization. Performance is benchmarked against GATE10/Geant4 ground truth, using intrinsic fluctuations between independent Monte Carlo runs as baseline. OptiGAN achieves sliced Wasserstein similarity within 3$σ$-agreement of the baseline across all conditions, demonstrating successful generalization to the full array. The model transitions from electron-emission training data to realistic $γ$-photon interactions, producing flood maps that reproduce characteristic patterns including photopeak clusters and inter-crystal scatter lines. This proof-of-concept demonstrates that physics-informed generative models can accurately simulate optical photon transport in segmented scintillator arrays. The reproduction of experimentally relevant flood map features validates optiGAN for PET detector development and establishes a foundation for models generalizing across diverse array configurations."
  },
  {
    "date": "2026-01-26",
    "title": "Col-OSSOS: Investigating the Origins of Different Surfaces in the Primordial Kuiper Belt",
    "authors": "Laura E. Buchanan, Megan E. Schwamb, Wesley C. Fraser, Michele T. Bannister, J. J. Kavelaars, Michaël Marsset, Rosemary E. Pike, David Nesvorný, Samantha M. Lawler, Susan D. Benecchi, Nuno Peixinho, Nicole J. Tan, Kathryn Volk, Mike Alexandersen, Jean-Marc Petit",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18776v1",
    "source": "arXiv",
    "abstract": "The Colours of the Outer Solar System Origins Survey (Col-OSSOS) measured the optical/NIR colours of a brightness-complete sample of Trans-Neptunian Objects (TNOs). Like previous surveys, this one found a bimodal colour distribution in TNOs, categorised as red and very red. Additionally, this survey proposed an alternative surface classification scheme: FaintIR and BrightIR. Cold classical TNOs mostly have very red or FaintIR surfaces, while dynamically excited TNOs show a mixture of surfaces. This likely indicates that formation locations and proximity to the Sun influenced surface characteristics and color changes. Our study combines the data from Col-OSSOS with two dynamical models describing the formation of the Kuiper belt during Neptune's migration. We investigate the proposed surface-colour changing line and explore the distribution of different surfaces within the primordial disk. By comparing radial colour transitions across various scenarios, we explore the origins of surface characteristics and their implications within the context of BrightIR and FaintIR classifications. Moreover, we extend our analysis to examine the distribution of these surface classes within the present-day Kuiper Belt, providing insights into the configuration of the early solar system's planetesimal disk prior to giant planet migration. We find that the most likely primordial disk compositions are inner neutral / outer red (with transition $30.0^{+1.1}_{-1.2}$ au), or inner BrightIR / outer FaintIR (with transition $31.5^{+1.1}_{-1.2}$ au)."
  },
  {
    "date": "2026-01-26",
    "title": "Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory",
    "authors": "Yanming Liu, Xinyue Peng, Zixuan Yan, Yanxin Shen, Wenjie Xu, Yuefeng Huang, Xinyi Wang, Jiannan Cao, Jianwei Yin, Xuhong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18771v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales."
  },
  {
    "date": "2026-01-26",
    "title": "Equality between two general ridge estimators and applications in several linear models",
    "authors": "Hirai Mukasa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18770v1",
    "source": "arXiv",
    "abstract": "General ridge estimators are widely used in the general linear model because they possess desirable properties such as linear sufficiency and linear admissibility. However, when the covariance matrix of the error term is partially unknown, estimation typically requires a two-step procedure. This paper derives conditions under which the general ridge estimator based on the covariance matrix coincides with the one that does not depend on it. In particular, we provide practically verifiable conditions for several linear models, including Rao's mixed-effects model, a seemingly unrelated regression model, first-order spatial autoregressive and spatial moving average models, and serial correlation models. These results enable the use of a covariance-free general ridge estimator, thereby simplifying the two-step estimation procedure."
  },
  {
    "date": "2026-01-26",
    "title": "Two Hornich-Hlawka-type and Buzano-type inequalities",
    "authors": "Nizar El Idrissi, Hicham Zoubeir",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18768v1",
    "source": "arXiv",
    "abstract": "This paper deals with Hornich-Hlawka-type and Buzano-type inequalities in inner product spaces (IPS). On the one hand, the Hornich-Hlawka inequality, or Hlawka's inequality, or quadrilateral inequality, is an inequality concerning three vectors in a quadrilateral. Namely, it states that for all $x,y,z$, $\\lVert x \\rVert + \\lVert y \\rVert + \\lVert z \\rVert + \\lVert x + y + z \\rVert \\geq \\lVert x+y \\rVert + \\lVert x + z \\rVert + \\lVert y + z \\rVert$. On the other hand, Buzano inequality, which states $|\\langle a,x\\rangle\\,\\langle x,b\\rangle|\\leq\\frac{1}{2}\\left[\\|a\\|\\cdot\\|b\\|+| \\langle a,b\\rangle|\\right]\\|x\\|^{2}$, is a refinement of the Cauchy-Schwarz inequality, since it is clear that for $a=b$, the above inequality becomes the standard inequality $|\\langle a,x\\rangle|^{2}\\leq\\|a\\|^{2}\\,\\|x\\|^{2}$. In the first part of our paper, we introduce a stronger version of Hornich-Hlawka inequality, namely: for all vectors $ x, y, z $, $ \\|x\\| \\|y\\| + \\|z\\| \\|x + y + z\\| \\geq \\|x + z\\| \\|y + z\\|$. In the second part of our paper, we establish a \"2-out-of-3\" Buzano-type principle."
  },
  {
    "date": "2026-01-26",
    "title": "Learning to Discover: A Generalized Framework for Raga Identification without Forgetting",
    "authors": "Parampreet Singh, Somya Kumar, Chaitanya Shailendra Nitawe, Vipul Arora",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18766v1",
    "source": "arXiv",
    "abstract": "Raga identification in Indian Art Music (IAM) remains challenging due to the presence of numerous rarely performed Ragas that are not represented in available training datasets. Traditional classification models struggle in this setting, as they assume a closed set of known categories and therefore fail to recognise or meaningfully group previously unseen Ragas. Recent works have tried categorizing unseen Ragas, but they run into a problem of catastrophic forgetting, where the knowledge of previously seen Ragas is diminished. To address this problem, we adopt a unified learning framework that leverages both labeled and unlabeled audio, enabling the model to discover coherent categories corresponding to the unseen Ragas, while retaining the knowledge of previously known ones. We test our model on benchmark Raga Identification datasets and demonstrate its performance in categorizing previously seen, unseen, and all Raga classes. The proposed approach surpasses the previous NCD-based pipeline even in discovering the unseen Raga categories, offering new insights into representation learning for IAM tasks."
  },
  {
    "date": "2026-01-26",
    "title": "From Access Control to Usage Control with User-Managed Access",
    "authors": "Wout Slabbinck, Wouter Termont, Ruben Dedecker, Beatriz Esteves",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18761v1",
    "source": "arXiv",
    "abstract": "Recent data protection and data governance regulations have intensified the demand for interoperable, decentralized data ecosystems that can support not only access control but also legally-aligned governance over data use. Existing Web-based data storage platforms increasingly struggle to meet these regulatory and practical requirements, as their authorization mechanisms rely on tightly coupled, document-centric access control models that lack expressiveness for legal constraints and fail to separate data management from authorization concerns. In parallel, widely adopted authorization standards remain poorly aligned with decentralized, semantically rich usage-control scenarios. To bridge this gap, this work introduces an architecture that replaces Solid's native access control mechanisms with a UMA authorization flow, enabling the enforcement of usage control policies expressed with the W3C ODRL standard. This article details the conceptual background motivating this approach, presents the proposed UMA-based architecture, and describes a prototype implementation that integrates an ODRL-enabled Authorization Server with a Solid-compatible Resource Server. The prototype demonstrates that decoupling authorization from storage enables more flexible, interoperable, and legally expressive control over data use, while remaining compatible with existing Solid infrastructure. It also highlights practical design choices required to evaluate ODRL policies in the absence of a fully standardized evaluation semantics. Moreover, this work shows how usage control can be operationalized using existing Web standards, offering a concrete path beyond permission-based access control toward policy-aware, legally informed data governance. Future research will focus on policy management interfaces, richer claim verification mechanisms, and techniques for communicating and enforcing obligations over time."
  },
  {
    "date": "2026-01-26",
    "title": "$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks",
    "authors": "Mohamed Amine Ferrag, Abderrahmane Lakas, Merouane Debbah",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18754v1",
    "source": "arXiv",
    "abstract": "Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings. We introduce $α^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $α^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $α^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage). We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $α^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench"
  },
  {
    "date": "2026-01-26",
    "title": "HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs",
    "authors": "Xinyue Zeng, Junhong Lin, Yujun Yan, Feng Guo, Liang Shi, Jun Wu, Dawei Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18753v1",
    "source": "arXiv",
    "abstract": "The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations."
  },
  {
    "date": "2026-01-26",
    "title": "A Scanning-Based Indoor Optical Wireless Positioning System with Single VCSEL",
    "authors": "Yicheng Dong, Rashid Iqbal, Julien Le Kernec, Hanaa Abumarshoud",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18740v1",
    "source": "arXiv",
    "abstract": "This paper presents a novel indoor visible light positioning (VLP) system utilising one vertical-cavity surface-emitting laser installed at the ceiling centre of a space. The system offers three-dimensional localisation by sweeping through space at one-degree resolution in two dimensions (azimuth and elevation), significantly simplifying hardware. Through incorporating the angle of arrival and received signal strength, this system demonstrates excellent precision in indoor positioning. Simulation results verify that the system attains sub-centimetre precision for most test points, outperforming conventional multi-transmitter VLP schemes in cost-efficiency and simplicity."
  },
  {
    "date": "2026-01-26",
    "title": "One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment",
    "authors": "Hongru Cai, Yongqi Li, Tiezheng Yu, Fengbin Zhu, Wenjie Wang, Fuli Feng, Wenjie Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18731v1",
    "source": "arXiv",
    "abstract": "Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines."
  },
  {
    "date": "2026-01-26",
    "title": "On the Stochastic-Quantum Correspondence",
    "authors": "Sami Calvo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18720v1",
    "source": "arXiv",
    "abstract": "This paper aims to first explain, somewhat more clearly, the Stochastic-Quantum correspondence put forward in by Barandes in 2023. Specifically, the quantum-mechanical bra-ket notation is used, illuminating some results of previous results. With this, we prove the six axioms of textbook quantum mechanics from a single axiom: every physical system evolves according to a, generally indivisible, stochastic law. Afterwards, we generalise the treatment to continuous bases, which showcases a problem with them, indicating that space (and other physical variables) may be discrete in nature. Some concrete examples are also given, including the generalisation to classical and quantum fields. Then, we treat some practical issues of this new stochastic approach, regarding the solving of problems in physics, which turns out to still be most tractable in the traditional way. Finally, we explain the classical limit, where a system of many particles is found to behave classically according to Newton's second law. Along with that, we present a way of solving the measurement problem, characterising what is an environment and a measuring device and explaining how the wavefunction collapse comes about. Specifically, it is found that what distinguishes an environment is its number of degrees of freedom, while a measuring device is a low-entropy type of environment."
  },
  {
    "date": "2026-01-26",
    "title": "Detection of high-frequency gravitational waves using SRF cavities",
    "authors": "M. Wenskat, B. Giaccone, J. Branlard, V. Chouhan, C. Dokuyucu, L. Fischer, I. Gonin, A. Grassellino, W. Hillert, T. Khabiboulline, T. Krokotsch, F. Ludwig, G. Marconato, A. Melnychuk, G. Moortgat-Pick, A. Muhs, A. Netepenko, Y. Orlov, M. Paulsen, K. Peters, L. Pfeiffer, S. Posen, O. Pronitchev, H. Schlarb",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18719v1",
    "source": "arXiv",
    "abstract": "Today, apart from some isolated R&D efforts, there are no gravitational wave (GW) experiments, yet which explore a large part of the vast frequency range above the LIGO/Virgo band. It is planned to establish an experiment at Deutsches Elektronen-Synchrotron (DESY) and at the Superconducting Quantum Materials and Systems (SQMS) Center at Fermi National Accelerator Laboratory (Fermilab) to search for high-frequency GWs in the frequency range of 10 kHz to 100 MHz. The basic idea is to use superconducting radiofrequency (SRF) cavities to detect tiny harmonic deformations induced by GWs which change the boundary conditions of the oscillating electromagnetic field. This paper summarizes the challenging environmental boundary requirements, and the R&D to operate a cavity using a low level RF (LLRF) system which pushes beyond state-of-the-art accuracy and resolutions and a seismic noise mitigated cryostat at 1.8 K. The focus of this paper is the warm and cold commissioning of a prototype cavity, built 20 years ago during the MAGO collaboration, and its first measurement in our collaborative research project."
  },
  {
    "date": "2026-01-26",
    "title": "Additive sink subtraction",
    "authors": "Anjali Bhagat, Urban Larsson, Hikaru Manabe, Takahiro Yamashita",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18715v1",
    "source": "arXiv",
    "abstract": "Subtraction games are a classical topic in Combinatorial Game Theory. A result of Golomb~(1966) shows that every subtraction game with a finite move set has an eventually periodic nim-sequence, but the known proof yields only an exponential upper bound on the period length. Flammenkamp (1997) conjectures a striking classification for three-move subtraction games: non-additive rulesets exhibit linear period lengths of the form ``the sum of two moves'', where the choice of which two moves displays fractal-like behavior, while additive sets $S=\\{a,b,a+b\\}$ have purely periodic outcomes with linear or quadratic period lengths. Despite early attention in \\emph{Winning Ways} (1982), the general additive case remains open. We introduce and analyze a dual winning convention, which we call {\\sc sink subtraction}. Unlike the standard wall convention, where moves to negative positions are forbidden, the sink convention declares a player the winner upon moving to a non-positive position. We show that {\\sc additive sink subtraction} admits a complete solution: the nim-sequence is purely periodic with an explicit linear or quadratic period formula, and we conjecture a duality between additive sink subtraction and classical wall subtraction. Keywords: Additive Subtraction Game, Nimber, Periodicity, Sink Convention."
  },
  {
    "date": "2026-01-26",
    "title": "Giant Resonant Enhancement of Photoinduced Dynamical Cooper Pairing, far above $T_c$",
    "authors": "Sambuddha Chattopadhyay, Marios Michael, Andrea Cavalleri, Eugene Demler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18712v1",
    "source": "arXiv",
    "abstract": "Pump-probe experiments performed on $\\mathrm{K}_3\\mathrm{C}_{60}$ have unveiled both optical and transport signatures of metastable light-induced superconductivity up to room temperature, far above $T_c$. Recent experiments have uncovered that excitation in the vicinity of $50 ~\\textrm{meV}$ enables the observation of high temperature light-induced superconductivity at significantly lower fluences. Inspired by these experiments we develop a mechanism which can explain such a giant resonant enhancement of light-induced superconductivity. Within a minimal non-linear Holstein model, we show that resonantly driving optical Raman modes leads to a time-dependent electron-phonon coupling. Such a coupling then modulates the effective electron-electron attraction, with the strongest modulations occurring when the drive is resonant with the phonon frequency. These dynamical modulations of the pairing interactions lead to Floquet-BCS instabilities at temperatures far exceeding equilibrium $T_c$, as observed in experiments. We conclude by discussing the implications of our general analysis on the $\\mathrm{K}_3\\mathrm{C}_{60}$ experiments specifically and suggesting experimental signatures of our mechanism."
  },
  {
    "date": "2026-01-26",
    "title": "SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model",
    "authors": "Jan Hagnberger, Mathias Niepert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18707v1",
    "source": "arXiv",
    "abstract": "Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations."
  },
  {
    "date": "2026-01-26",
    "title": "TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent",
    "authors": "Xingyu Sui, Yanyan Zhao, Yulin Hu, Jiahe Guo, Weixiang Zhao, Bing Qin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18700v1",
    "source": "arXiv",
    "abstract": "Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents."
  },
  {
    "date": "2026-01-26",
    "title": "Neural Multi-Speaker Voice Cloning for Nepali in Low-Resource Settings",
    "authors": "Aayush M. Shrestha, Aditya Bajracharya, Projan Shakya, Dinesh B. Kshatri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18694v1",
    "source": "arXiv",
    "abstract": "This research presents a few-shot voice cloning system for Nepali speakers, designed to synthesize speech in a specific speaker's voice from Devanagari text using minimal data. Voice cloning in Nepali remains largely unexplored due to its low-resource nature. To address this, we constructed separate datasets: untranscribed audio for training a speaker encoder and paired text-audio data for training a Tacotron2-based synthesizer. The speaker encoder, optimized with Generative End2End loss, generates embeddings that capture the speaker's vocal identity, validated through Uniform Manifold Approximation and Projection (UMAP) for dimension reduction visualizations. These embeddings are fused with Tacotron2's text embeddings to produce mel-spectrograms, which are then converted into audio using a WaveRNN vocoder. Audio data were collected from various sources, including self-recordings, and underwent thorough preprocessing for quality and alignment. Training was performed using mel and gate loss functions under multiple hyperparameter settings. The system effectively clones speaker characteristics even for unseen voices, demonstrating the feasibility of few-shot voice cloning for the Nepali language and establishing a foundation for personalized speech synthesis in low-resource scenarios."
  },
  {
    "date": "2026-01-26",
    "title": "LLAMA LIMA: A Living Meta-Analysis on the Effects of Generative AI on Learning Mathematics",
    "authors": "Anselm Strohmaier, Samira Bödefeld, Frank Reinhold",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18685v1",
    "source": "arXiv",
    "abstract": "The capabilities of generative AI in mathematics education are rapidly evolving, posing significant challenges for research to keep pace. Research syntheses remain scarce and risk being outdated by the time of publication. To address this issue, we present a Living Meta-Analysis (LIMA) on the effects of generative AI-based interventions for learning mathematics. Following PRISMA-LSR guidelines, we continuously update the literature base, apply a Bayesian multilevel meta-regression model to account for cumulative data, and publish updated versions on a preprint server at regular intervals. This paper reports results from the first version, including 15 studies. The analyses indicate a small positive effect (g = 0.31) with a wide credible interval [0.06, 0.58], reflecting the still limited evidence base."
  },
  {
    "date": "2026-01-26",
    "title": "Any Light Particle Searches with ALPS II: first science campaign",
    "authors": "Aaron D. Spector, Daniel C. Brotherton, Ayman Hallal, Henry Frädrich, Jacob Egge, Li-Wei Wei, Todd Kozlowski, Kanioar Karan, Katharina-Sophie Isleif, Hartmut Grote, Harold Hollis, Guido Mueller, David B. Tanner, Benno Willke, Axel Lindner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18684v1",
    "source": "arXiv",
    "abstract": "From February to May of 2024 the Any Light Particle Search II (ALPS II) conducted its first science campaign using the `light-shining-through-a-wall' technique to search for pseudo-Goldstone bosons that lie beyond the Standard Model of particle physics and which are inaccessible by accelerator-based experiments. The experimental setup consists of two strings of superconducting dipole magnets, each more than 100 m long, that are separated by a wall. Laser light is directed through the first magnet string and a heterodyne detection system is used to measure the electromagnetic power that traverses a wall via the conversion to and then from a bosonic field. After the wall, a high-finesse optical cavity resonantly enhances the signal power. Two searches were carried out, one with the laser polarized perpendicular to the magnetic field direction and another with its polarization state aligned parallel to the magnetic field. No evidence for the existence of new bosons was found. In its first science campaign, ALPS II reached photon-boson conversion probability sensitivities of a few $10^{-13}$. The ongoing upgrade of the optical system aims to increase this sensitivity by about four orders of magnitude."
  },
  {
    "date": "2026-01-26",
    "title": "A Unique Inverse Decomposition of Positive Definite Matrices under Linear Constraints",
    "authors": "Yan Dolinsky, Or Zuk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18662v1",
    "source": "arXiv",
    "abstract": "We study a nonlinear decomposition of a positive definite matrix into two components: the inverse of another positive definite matrix and a symmetric matrix constrained to lie in a prescribed linear subspace. Equivalently, the inverse component is required to belong to the orthogonal complement of that subspace with respect to the trace inner product. Under a sharp nondegeneracy condition on the subspace, we show that every positive definite matrix admits a \\emph{unique} decomposition of this form. This decomposition admits a variational characterization as the unique minimizer of a strictly convex log-determinant optimization problem, which in turn yields a natural dual formulation that can be efficiently exploited computationally. We derive several properties, including the stability of the decomposition. We further develop feasibility-preserving Newton-type algorithms with provable convergence guarantees and analyze their per-iteration complexity in terms of algebraic properties of the decomposed matrix and the underlying subspace. Finally, we show that the proposed decomposition arises naturally in exponential utility maximization, a central problem in mathematical finance."
  },
  {
    "date": "2026-01-26",
    "title": "McSAS3: improved Monte Carlo small-angle scattering analysis software for dilute and dense scatterers",
    "authors": "Brian Richard Pauw, Ingo Breßler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18659v1",
    "source": "arXiv",
    "abstract": "McSAS3 is the refactored successor to the original McSAS Monte Carlo small-angle scattering analysis software. It is intended to be integrated in automated data processing pipelines, but can also be used to process individual (batches of) scattering data. McSAS3 comes with a graphical user interface (McSAS3GUI), complete with guides, examples and videos. McSAS3GUI will help to generate and test the three configuration files that McSAS3 needs for data read-in, Monte Carlo optimization and histogramming. The user interface can also be used to process individual files or batches, and can be augmented with machine-specific use templates. The Monte Carlo (MC) approach is able to fit most practical scattering patterns extremely well, resulting in form-free model parameter distributions. Theoretically, these can be distributions on any model parameter, but in practice the MC-optimized parameter is usually a (volume-weighted) size distribution, in absolute volume fraction for absolute-scaled data."
  },
  {
    "date": "2026-01-26",
    "title": "Impact of Rastall gravity on hydrostatic mass of galaxy clusters",
    "authors": "M. Lawrence Pattersons, Feri Apryandi, Freddy P. Zen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18652v1",
    "source": "arXiv",
    "abstract": "Galaxy clusters are the largest virialized structures in the Universe and are predominantly dominated by dark matter. The hydrostatic mass and the mass obtained from gravitational lensing measurements generally differ, a discrepancy known as the hydrostatic mass bias. In this work, we derive the hydrostatic mass of galaxy clusters within the framework of Rastall gravity and investigate its implications under two scenarios: (i) the absence of dark matter and (ii) the existence of dark matter. In the first scenario, Rastall gravity effectively reduces the hydrostatic mass, bringing it closer to the observed baryonic mass. The best linear fit yields a slope $\\mathbf{M}=1.07\\pm0.11$, indicating a near one-to-one correspondence between the two masses. In the second scenario, Rastall gravity helps to alleviate the hydrostatic mass bias. The linear fit between the Rastall hydrostatic mass and the observed lensing mass results in a best-fit slope $\\mathbf{M}=1.01\\pm0.16$, which is very close to unity. These results suggest that Rastall gravity provides a statistically favorable framework for addressing mass discrepancies in galaxy clusters."
  },
  {
    "date": "2026-01-26",
    "title": "Learning Real-Life Approval Elections",
    "authors": "Piotr Faliszewski, Łukasz Janeczko, Andrzej Kaczmarczyk, Marcin Kurdziel, Grzegorz Pierczyński, Stanisław Szufa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18651v1",
    "source": "arXiv",
    "abstract": "We study the independent approval model (IAM) for approval elections, where each candidate has its own approval probability and is approved independently of the other ones. This model generalizes, e.g., the impartial culture, the Hamming noise model, and the resampling model. We propose algorithms for learning IAMs and their mixtures from data, using either maximum likelihood estimation or Bayesian learning. We then apply these algorithms to a large set of elections from the Pabulib database. In particular, we find that single-component models are rarely sufficient to capture the complexity of real-life data, whereas their mixtures perform well."
  },
  {
    "date": "2026-01-26",
    "title": "Closure models for the feedback of energetic particles on plasma turbulence",
    "authors": "J. Pratt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18649v1",
    "source": "arXiv",
    "abstract": "Energetic particles interact with the plasma surrounding them, resonating with certain plasma waves to stabilize them while destabilizing others, and changing the character of the background turbulence in ways that have not been fully quantified or understood. Interaction with the turbulent background plasma is key to the acceleration of many types of energetic particles including high-energy cosmic rays, solar energetic particles, and pick-up ions. This is a process that would ideally be described by a kinetic model, a type of model that follows a probability distribution function (PDF) for all particles in 7-dimensional space. Because of the high dimensionality of a kinetic model, such simulations use the largest computational resources available, and are yet unable to simulate a realistic number of particles, reach the large scales necessary for astrophysical problems, or use high-precision numerical methods. Two available alternatives to kinetic plasma models have been explored: a multi-fluid model, and a hybrid fluid/Fokker-Planck model. These methods are hampered by the physical modeling of the coupling. We develop a new model, which follows the PDF for all particles; this can be viewed as a step toward physical realism above a multi-fluid MHD model, while also being more computationally efficient than a kinetic model. The equations we develop model both the background plasma and the energetic particles self-consistently. Over the last decade, similar PDF methods have been developed to a high level of sophistication to model reactive flows and turbulent combustion for engineering applications. For treatment of the feedback of the energetic particles on a background plasma, a PDF closure approach should evaluate the mean characteristics, including the density, with better statistical quality than will particle-sampling procedures."
  },
  {
    "date": "2026-01-26",
    "title": "FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory",
    "authors": "Lei Wei, Xu Dong, Xiao Peng, Niantao Xie, Bin Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18642v1",
    "source": "arXiv",
    "abstract": "Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems."
  },
  {
    "date": "2026-01-26",
    "title": "Unheard in the Digital Age: Rethinking AI Bias and Speech Diversity",
    "authors": "Onyedikachi Hope Amaechi-Okorie, Branislav Radeljic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18641v1",
    "source": "arXiv",
    "abstract": "Speech remains one of the most visible yet overlooked vectors of inclusion and exclusion in contemporary society. While fluency is often equated with credibility and competence, individuals with atypical speech patterns are routinely marginalized. Given the current state of the debate, this article focuses on the structural biases that shape perceptions of atypical speech and are now being encoded into artificial intelligence. Automated speech recognition (ASR) systems and voice interfaces, trained predominantly on standardized speech, routinely fail to recognize or respond to diverse voices, compounding digital exclusion. As AI technologies increasingly mediate access to opportunity, the study calls for inclusive technological design, anti-bias training to minimize the impact of discriminatory algorithmic decisions, and enforceable policy reform that explicitly recognize speech diversity as a matter of equity, not merely accessibility. Drawing on interdisciplinary research, the article advocates for a cultural and institutional shift in how we value voice, urging co-created solutions that elevate the rights, representation, and realities of atypical speakers in the digital age. Ultimately, the article reframes speech inclusion as a matter of equity (not accommodation) and advocates for co-created AI systems that reflect the full spectrum of human voices."
  },
  {
    "date": "2026-01-26",
    "title": "TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning",
    "authors": "Zhiwei Zheng, Kevin Bryson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18640v1",
    "source": "arXiv",
    "abstract": "Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation. Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as \"background\" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference. Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery."
  },
  {
    "date": "2026-01-26",
    "title": "The Compounded BSDE method: A fully-forward method for option pricing and optimal stopping problems in finance",
    "authors": "Zhipeng Huang, Cornelis W. Oosterlee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18634v1",
    "source": "arXiv",
    "abstract": "We propose the Compound BSDE method, a fully forward, deep-learning-based approach for solving a broad class of problems in financial mathematics, including optimal stopping. The method is based on a reformulation of option pricing problems in terms of a system of backward stochastic differential equations (BSDEs), which offers a new perspective on the numerical treatment of compound options and optimal stopping problems such as Bermudan option pricing. Building on the classical deep BSDE method for a single BSDE, we develop an algorithm for compound BSDEs and establish its convergence properties. In particular, we derive an \\emph{a posteriori} error estimate for the proposed method. Numerical experiments demonstrate the accuracy and computational efficiency of the approach, and illustrate its effectiveness for high-dimensional option pricing and optimal stopping problems."
  },
  {
    "date": "2026-01-26",
    "title": "Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting",
    "authors": "Tong Shi, Melonie de Almeida, Daniela Ivanova, Nicolas Pugeault, Paul Henderson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18633v1",
    "source": "arXiv",
    "abstract": "Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait."
  },
  {
    "date": "2026-01-26",
    "title": "AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning",
    "authors": "Mingyang Song, Haoyu Sun, Jiawei Gu, Linjie Li, Luxin Xu, Ranjay Krishna, Yu Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18631v1",
    "source": "arXiv",
    "abstract": "When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \\textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw."
  },
  {
    "date": "2026-01-26",
    "title": "ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection",
    "authors": "Yiming Wang, Ruogu Zhang, Minyang Li, Hao Shi, Junbo Wang, Deyi Li, Jieji Ren, Wenhai Liu, Weiming Wang, Hao-Shu Fang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18629v1",
    "source": "arXiv",
    "abstract": "Real-to-Sim-to-Real technique is gaining increasing interest for robotic manipulation, as it can generate scalable data in simulation while having narrower sim-to-real gap. However, previous methods mainly focused on environment-level visual real-to-sim transfer, ignoring the transfer of interactions, which could be challenging and inefficient to obtain purely in simulation especially for contact-rich tasks. We propose ExoGS, a robot-free 4D Real-to-Sim-to-Real framework that captures both static environments and dynamic interactions in the real world and transfers them seamlessly to a simulated environment. It provides a new solution for scalable manipulation data collection and policy learning. ExoGS employs a self-designed robot-isomorphic passive exoskeleton AirExo-3 to capture kinematically consistent trajectories with millimeter-level accuracy and synchronized RGB observations during direct human demonstrations. The robot, objects, and environment are reconstructed as editable 3D Gaussian Splatting assets, enabling geometry-consistent replay and large-scale data augmentation. Additionally, a lightweight Mask Adapter injects instance-level semantics into the policy to enhance robustness under visual domain shifts. Real-world experiments demonstrate that ExoGS significantly improves data efficiency and policy generalization compared to teleoperation-based baselines. Code and hardware files have been released on https://github.com/zaixiabalala/ExoGS."
  },
  {
    "date": "2026-01-26",
    "title": "Spin-redirection Berry phase with planar rays",
    "authors": "Aymeric Braud, Renaud Gueroult",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18624v1",
    "source": "arXiv",
    "abstract": "Geometric or Berry phases are fundamental manifestations that appear in many areas of physics. They arise from the geometry of the space describing the properties of multi-component wave fields. An important example for electromagnetic waves is the spin-redirection Berry phase associated with the evolution of the spin direction. Because this effect has traditionally been studied in isotropic media where the spin is aligned with the ray trajectory, it has become commonly assumed that this spin-redirection Berry phase requires nonplanar rays. Here we show that a spin-redirection phase can in fact arise along a planar ray if the spin evolves along the ray. We expose this effect through the singular example of a moving unmagnetized plasma, and demonstrate how this behavior can more generally arise from a finite transverse spin. In identifying this new spin-redirection mechanism our work not only provides the tools to discover additional manifestations of SOIs in nature, but also uncovers supplemental degrees of freedom to harness SOIs to control light."
  },
  {
    "date": "2026-01-26",
    "title": "Duality in $SIM(2)$ topologically massive models with $B\\wedge F$ term",
    "authors": "Fernando M. Belchior, Roberto V. Maluf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18621v1",
    "source": "arXiv",
    "abstract": "This paper aims to investigate the classical duality between the $SIM(2)$-Maxwell-Kalb-Ramond (MKR) theory and a self-dual non-gauge-invariant model. First, we establish the equivalence in the free-field case using two complementary methods: a direct comparison of the equations of motion and the master Lagrangian approach. In both methodologies, we verify that the classical correspondence between the MKR model and self-dual fields exhibits modifications induced by very special relativity (VSR). Moreover, we employ the master Lagrangian approach to examine the duality when the self-dual model is minimally coupled to fermionic matter. We show that the resulting MKR model contains Thirring-like interactions modified by nonlocal contributions arising from VSR."
  },
  {
    "date": "2026-01-26",
    "title": "Broadband tunable narrow-linewidth laser based on scattering-enhanced fiber covering E-S-C-L bands",
    "authors": "Minzhi Xu, Zechun Geng, Da Wei, Yujia Li, Juntao He, Chaoze Zhang, Wei Du, Lei Gao, Leilei Shi, Ligang Huang, Jindong Wang, Tao Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18611v1",
    "source": "arXiv",
    "abstract": "This work demonstrates a broadband tunable narrow-linewidth laser based on scattering-enhanced fiber, covering the E-S-C-L wavelength bands from 1337.47 nm to 1631.39 nm, with a total tuning span of 293.92 nm. The laser employs two semiconductor optical amplifiers (SOAs) centered at 1420 nm and 1550 nm, which are connected into a single ring resonator via polarization multiplexing. Wavelength selection and tunability is realized using an ultra-broadband tunable filter based on a blazed grating. To suppress side longitude modes, an 18-meter-long femtosecond-laser-empowered random scattering fiber is utilized inside the cavity as a feedback medium, yielding an output linewidths between 1.54 kHz and 2.61 kHz. Benefited from the fast response of the galvanometer mirror and short relaxation time of SOAs, wavelength switching time is less than 1 ms under different tuning channels among the wavelength range of near 300 nm. The stable single-longitude-mode operation is maintained across the entire tuning range. The exceptionally broad tuning range and high spectral purity of the laser endow it with significant application potentials across a wide range of fields."
  },
  {
    "date": "2026-01-26",
    "title": "Hybrid integrated narrow linewidth laser with external distributed optical feedback from a silicon strip waveguide",
    "authors": "Da Wei, Leilei Shi, Yujia Li, Minzhi Xu, Chaoze Zhang, Xianming Huang, Jianxian Yu, Lei Zhai, Wenxuan Huang, Huan Tian, Tao Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18609v1",
    "source": "arXiv",
    "abstract": "External optical feedback via Rayleigh scattering from an integrated microresonator or an optical fiber has been demonstrated to significantly narrow the intrinsic linewidth of semiconductor lasers. Wavelength matching between the lasing cavity and the external high-Q microresonator is required to accumulate Rayleigh scattering based optical feedback. Optical fiber can provide Rayleigh scattering based optical feedback for any lasing wavelength. However, optical fibers hundreds of meters or even kilometers long are required for the accumulation of Rayleigh scattering based optical feedback, hindering the integration of narrow linewidth lasers. Here, we present an integrated scheme that collects distributed feedback signal with weak wavelength dependence by exploiting surface radiation in a silicon waveguide. The effects of waveguide width on the intensities of the surface radiation and distributed optical feedback signal are first numerically analyzed by introducing a collection coefficient. Numerical calculations show that a 1 μm-wide strip waveguide yields optimal performance for excitation and collection of distributed optical feedback, which is also experimentally verified by measuring the feedback signal with an optical frequency-domain reflectometry. Benefitting from the enhanced distributed optical feedback that is 34.72 dB higher than that in a single-mode fiber, the hybrid integrated laser demonstrates an intrinsic linewidth of 1.52 kHz, a side-mode suppression ratio (SMSR) of 74.71 dB, and a frequency noise of 24.44 Hz2/Hz. Furthermore, within a maximum allowable wavelength tuning range of 2.342 nm, the linewidth narrowing ratio depends little on the wavelength for all the waveguides with different widths."
  },
  {
    "date": "2026-01-26",
    "title": "Atmospheric Circulation of High-Obliquity Mini-Neptunes",
    "authors": "Yanhong Lai, Xianyu Tan, Yubo Su",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18606v1",
    "source": "arXiv",
    "abstract": "With the operation of JWST, atmospheric characterization has now extended to low-mass exoplanets. In compact multiplanetary systems, secular spin-orbital resonance may preserve high obliquities and asynchronous rotation even for tidally-despinning, low-mass planets, potentially leading to unique atmospheric circulation patterns. To understand the impact on the atmospheric circulation and to identify the potential atmospheric observational signatures of such high-obliquity planets, we simulate the three dimensional circulation of a representative mini-Neptune K2-290 b, whose obliquity may reach about 67 degrees. Whether synchronously rotating or not, the planet's slow rotation, moderate temperature and radius result in a global Weak-Temperature-Gradient (WTG) behavior with moderate horizontal temperature contrasts. Under synchronous rotation, broad eastward superrotating jets efficiently redistribute heat. Circulation in an asynchronous rotation exhibits a seasonal cycle driven by high obliquity, along with quasi-periodic oscillations in winds and temperatures with a period of about 70 orbital periods. These oscillations, driven by wave-mean flow interactions, extend from low to mid-latitudes due to the slow planetary rotation. Higher atmospheric metallicity strengthens radiative forcing, increasing temperature contrasts and jet speeds. Clouds have minimal impact under synchronous rotation but weaken jets under nonsynchronous rotation by reducing temperature contrasts. In all cases, both thermal emission and transmission spectra exhibit moderate observational signals at a level of 100 ppm, and high-obliquity effects contribute differences at the 10 ppm level. Our results are also applicable to a range of potential high-obliquity exoplanets, which reside in the WTG regime and likely exhibit nearly homogeneous horizontal temperature patterns."
  },
  {
    "date": "2026-01-26",
    "title": "Asymptotics of the d'Arcais Numbers at Small $k$",
    "authors": "Shannon Starr",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18599v1",
    "source": "arXiv",
    "abstract": "The d'Arcais numbers are the triangular array $\\{A(2,n,k)\\, :\\, n=0,1,\\dots,\\, k=0,\\dots,n\\}$, such that $\\sum_{n=0}^{\\infty} \\sum_{k=0}^{n} A(2,n,k) x^k z^n/n! = ((z;z)_{\\infty})^{-x}$. The infinite $q$-Pochhammer symbol is $(q;q)_{\\infty} = \\prod_{n=1}^{\\infty} (1-q^n)$. Holding $k$ fixed and considering large $n$, we note that the ratio $k! A(2,n,k)/n!$ is asymptotic to $C(k) σ_{2k-1}(n)/n^k$ where the divisor sum function is $σ_p(n) = \\sum_{d|n} d^p$ and $C(k) = (ζ(2))^k/(Γ(k) ζ(2k))$. This is a slightly generalized version of one of Ramanujan's formulas from his paper, ``On Certain Arithmetical Functions,\" and it is an immediate consequence of the more recent article of Oliver, Shreshta and Thorne. Heim and Neuhauser made a conjecture, that $A(2,n,k)/A(2,n,k-1)$ is greater than or equal to $A(2,n,k+1)/A(2,n,k)$, for $k=2,3,\\dots$ and all $n$. The conjecture is false for $k=2$, and it is true for $k=3,4,\\dots$ when $n$ is sufficiently large. We consider the Hardy-Ramanujan circle method as a heuristic step."
  },
  {
    "date": "2026-01-26",
    "title": "Radio streaks in the Lighthouse Nebula discovered with MeerKAT -- Particles escaping from the tail and illuminating the ambient magnetic field",
    "authors": "Pierrick Martin, Mickael Coriat, Barbara Olmi, Elena Amato, Niccolò Bucciantini, Alexandre Marcowith, Sarah Recchia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18596v1",
    "source": "arXiv",
    "abstract": "Bow-shock pulsar wind nebulae are valuable sources to investigate the dynamics of relativistic pulsar winds and the mechanisms by which they are converted into cosmic-ray leptons at the highest energies. The Lighthouse Nebula is one such object, famous for the high velocity of its pulsar and a long misaligned X-ray jet that is understood as a specific escape channel for the most energetic particles. We aim to get a better understanding of how the bulk of non-thermal particles are released into the interstellar medium. We focus on GHz radio observations, which probe lower-energy particles that are dominant in number and long-lived, thus offering a picture of how escape proceeds in the long run. We analyze 10.5h of MeerKAT observations in the 0.9-1.7GHz band. MeerKAT observations reveal a highly structured synchrotron nebula downstream of pulsar PSR J1101-6101. A cometary tail is detected up to beyond 5pc from the pulsar, while a system of multiple transverse two-sided emission streaks is observed for the first time. No radio counterpart of the misaligned X-ray jet is seen. The radio streaks are interpreted as the occasional charge-independent release of energetic leptons from the tail into the surrounding medium, as a result of dynamical instabilities and reconfiguration in the downstream flow. The intensity layout suggests that most of the particle content of the nebula is discharged into the ambient medium within several parsec. Once escaped, particles light up the ambient magnetic field, which appears to have a coherence length of at least a few parsec. The length and persistence of the streaks indicate a low level of magnetic turbulence, possibly slightly enhanced with respect to average cosmic-ray transport conditions in the Galaxy. Such a confinement may result from self-generated turbulence by resonant streaming instability, or be due to past activity of the progenitor star."
  },
  {
    "date": "2026-01-26",
    "title": "K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents",
    "authors": "Vincenzo De Paola, Mirco Mutti, Riccardo Zamboni, Marcello Restelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18580v1",
    "source": "arXiv",
    "abstract": "Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies."
  },
  {
    "date": "2026-01-26",
    "title": "Self-Refining Video Sampling",
    "authors": "Sangwon Jang, Taekyung Ki, Jaehyeong Jo, Saining Xie, Jaehong Yoon, Sung Ju Hwang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18577v1",
    "source": "arXiv",
    "abstract": "Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\\% human preference compared to the default sampler and guidance-based sampler."
  },
  {
    "date": "2026-01-26",
    "title": "Stable Matching with Deviators and Conformists",
    "authors": "Frederik Glitzner, David Manlove",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18573v1",
    "source": "arXiv",
    "abstract": "In the fundamental Stable Marriage and Stable Roommates problems, there are inherent trade-offs between the size and stability of solutions. While in the former problem, a stable matching always exists and can be found efficiently using the celebrated Gale-Shapley algorithm, the existence of a stable matching is not guaranteed in the latter problem, but can be determined efficiently using Irving's algorithm. However, the computation of matchings that minimise the instability, either due to the presence of additional constraints on the size of the matching or due to restrictive preference cycles, gives rise to a collection of infamously intractable almost-stable matching problems. In practice, however, not every agent is able or likely to initiate deviations caused by blocking pairs. Suppose we knew, for example, due to a set of requirements or estimates based on historical data, which agents are likely to initiate deviations - the deviators - and which are likely to comply with whatever matching they are presented with - the conformists. Can we decide efficiently whether a matching exists in which no deviator is blocking, i.e., in which no deviator has an incentive to initiate a deviation? Furthermore, can we find matchings in which only a few deviators are blocking? We characterise the computational complexity of this question in bipartite and non-bipartite preference settings. Surprisingly, these problems prove computationally intractable in strong ways: for example, unlike in the classical setting, where every agent is considered a deviator, in this extension, we prove that it is NP-complete to decide whether a matching exists where no deviator is blocking. On the positive side, we identify polynomial-time and fixed-parameter tractable cases, providing novel algorithmics for multi-agent systems where stability cannot be fully guaranteed."
  },
  {
    "date": "2026-01-26",
    "title": "Semilinear Diffusion Equations on Infinite Graphs: The Dissipative and Lipschitz Cases",
    "authors": "Elvise Berchio, Davide Bianchi, Alberto G. Setti, Maria Vallarino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18549v1",
    "source": "arXiv",
    "abstract": "We study a class of semilinear diffusion equations on infinite, connected, weighted graphs, focusing on two types of nonlinearities: monotone decreasing and Lipschitz continuous. Under minimal structural assumptions on the graph, we establish existence, uniqueness, and regularity of mild solutions for initial data in $\\ell^p$ spaces, with $1\\leq p<\\infty$. Our approach relies on time discretization via an implicit Euler scheme and an exhaustion technique using Dirichlet subgraphs. As a by-product, we obtain existence and uniqueness results for a related time-independent equation. Finite-time extinction and positivity for solutions under a specific forcing term are also proved."
  },
  {
    "date": "2026-01-26",
    "title": "Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States",
    "authors": "Kyoleen Kwak, Hyoseok Hwang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18479v1",
    "source": "arXiv",
    "abstract": "Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods."
  },
  {
    "date": "2026-01-26",
    "title": "Dualband OFDM Delay Estimation for Multi-Target Localization",
    "authors": "Jialun Kou, Achiel Colpaert, Zhuangzhuang Cui, Sofie Pollin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18478v1",
    "source": "arXiv",
    "abstract": "Integrated localization and communication systems aim to reuse communication waveforms for simultaneous data transmission and localization, but delay resolution is fundamentally limited by the available bandwidth. In practice, large contiguous bandwidths are difficult to obtain due to hardware constraints and spectrum fragmentation. Aggregating non-contiguous narrow bands can increase the effective frequency span, but a non-contiguous frequency layout introduces challenges such as elevated sidelobes and ambiguity in delay estimation. This paper introduces a point-spread-function (PSF)-centric framework for dual-band OFDM delay estimation. We model the observed delay profile as the convolution of the true target response with a PSF determined by the dual-band subcarrier selection pattern, explicitly linking band configuration to resolution and ambiguity. To suppress PSF-induced artifacts, we adapt the RELAX algorithm for dual-band multi-target delay estimation. Simulations demonstrate improved robustness and accuracy in dual-band scenarios, supporting ILC under fragmented spectrum."
  },
  {
    "date": "2026-01-26",
    "title": "Latent Knowledge as a Predictor of Fact Acquisition in Fine-Tuned Large Language Models",
    "authors": "Daniel B. Hier, Tayo Obafemi-Ajayi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18468v1",
    "source": "arXiv",
    "abstract": "Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced."
  },
  {
    "date": "2026-01-26",
    "title": "Rethinking AI in the age of climate collapse: Ethics, power, and responsibility",
    "authors": "Julio Vega",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18462v1",
    "source": "arXiv",
    "abstract": "The climate crisis requires responses that integrate scientific, ethical, social, and technological perspectives. Artificial intelligence (AI) has emerged as a powerful tool in climate modelling, environmental monitoring, and energy optimisation, yet its growing use also raises critical environmental, ethical, legal, and social questions. This contribution examines the ambivalent role of AI in the ecological crisis, addressing both its promises and its risks. On the one hand, AI supports improvements in climate forecasting, renewable energy management, and real-time detection of environmental degradation. On the other hand, the energy demands of data centres, resource-intensive hardware production, algorithmic bias, corporate concentration of power, and technocratic decision-making reveal contradictions that challenge its sustainability. The discussion explores these issues through interdisciplinary lenses, including environmental ethics, philosophy of technology, and legal governance, and concludes with recommendations for socially just, ecologically responsible, and democratically accountable uses of AI. Rather than assuming AI as an inherently sustainable solution, this analysis argues that its contribution to climate action depends fundamentally on the values, institutions, and power structures that shape its development."
  },
  {
    "date": "2026-01-26",
    "title": "Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off?",
    "authors": "Xinmeng Yu, Tao Jiang, Ran Cheng, Yaochu Jin, Kay Chen Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18446v1",
    "source": "arXiv",
    "abstract": "Evolutionary algorithms (EAs) are increasingly implemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evaluation uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large populations enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms."
  },
  {
    "date": "2026-01-26",
    "title": "A coarse Gallai theorem",
    "authors": "Marc Distel, Ugo Giocanti, Jędrzej Hodor, Clément Legrand-Duchesne, Piotr Micek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18439v1",
    "source": "arXiv",
    "abstract": "We prove that there exist functions $f$ and $g$ such that for all positive integers $k$ and $d$, for every graph $G$ and every subset $A$ of the vertices of $G$, either $G$ contains $k$ $A$-paths such that vertices of different $A$-paths are at distance at least $d$ in $G$, or there exists a set $X$ of the vertices of $G$ with $|X|\\leq f(k)$ such that every $A$-path in $G$ contains a vertex of $B_G(X,g(k,d))$."
  },
  {
    "date": "2026-01-26",
    "title": "Properties of calculus in r-Complexity 2025",
    "authors": "Rares Folea, Emil Slusanschi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18437v1",
    "source": "arXiv",
    "abstract": "This paper presents a series of general properties of the r-Complexity calculus, a complexity measurement for assessing the performance and asymptotic behaviour of real-world algorithms. This research describes characteristics such as reflexivity, transitivity, or symmetry and discusses several conversion rules between different classes of r-Complexity, as well as establishing fundamental arithmetic principles. The work also examines the behaviour of the addition property within this system and compares its characteristics with those frequently used in the traditional Bachmann-Landau notation. Through utilizing these properties, this research seeks to promote the exploration and development of novel applications for r-Complexity, as well as accelerating the adoption rate of calculus in this refined complexity model."
  },
  {
    "date": "2026-01-26",
    "title": "The Quantum Cliff: A Critical Proton Tunneling Threshold Determines Clinical Severity in RPE65-Mediated Retinal Disease",
    "authors": "Biraja Ghoshal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18435v1",
    "source": "arXiv",
    "abstract": "Predicting clinical severity from genotype remains a fundamental challenge in molecular medicine, particularly for enzymes whose function depends on sub-atomic-scale geometry. Mutations in the \\textit{RPE65} isomerohydrolase cause Leber Congenital Amaurosis (LCA) and related retinal diseases; however, the kinetic mechanisms connecting sub-atomic-scale perturbations to blindness remain unclear. In this study, we demonstrate that mutations in the human visual isomerase RPE65 are governed by a quantum-mechanical threshold effect arising from proton tunneling in the active site. We established a hybrid quantum-classical structure-to-phenotype pipeline combining AlphaFold structure prediction with \\textit{ab initio} quantum simulation using the Variational Quantum Eigensolver (VQE) to analyze minimal proton-coupled electron transfer in the visual cycle. Our analysis reveals that many pathogenic mutations do not merely occlude the active site, but rather strongly reduce the quantum probability of proton tunneling. We observed a sharp non-linear effect, termed the \"Quantum Cliff,\" where minute structural changes (below 0.1 Å) reduce the reaction rate by multiple orders of magnitude. Based on these findings, we introduce a dimensionless Relative Quantum Activity Score (RQAS) that isolates the geometry-controlled exponential sensitivity of the reaction rate and successfully distinguishes between mild and severe patient phenotypes. These results suggest that RPE65 operates near a quantum-critical point, where sub-Angstrom structural perturbations induce a catastrophic loss of function. Furthermore, our findings establish quantum tunneling as a predictive mechanistic link between atomic structure and clinical phenotype, proposing a general framework for quantum-structural disease modeling."
  },
  {
    "date": "2026-01-26",
    "title": "Nuclear effects on longitudinal-transverse structure function ratio in the deuteron",
    "authors": "S. Kumano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18431v1",
    "source": "arXiv",
    "abstract": "Nuclear modifications of the nucleon's structure function $F_2^N$ have been investigated mainly since the discovery of the EMC nuclear effect in 1983, and there were many experimental measurements from the deuteron to a heavy nucleus. Now, the details of the modifications of $F_2^N$ are known from small $x$ to large $x$. On the other hand, it is taken as granted that a nuclear modification does not exist for the longitudinal-transverse structure function ratio $R_N=F_L^N/(2xF_1^N)$. However, such a nuclear modification does exist theoretically. A nucleon in a nucleus moves in any space direction, which is not necessary the longitudinal direction along the virtual-photon momentum in charged-lepton scattering. Because of this transverse Fermi motion, the longitudinal and transverse structure functions mix with the mixture probability proportional to the nucleon's transverse-momentum squared $\\vec p_T^{\\,\\, 2}/Q^2$. In this paper, the nuclear modifications are shown numerically for the deuteron by using a standard convolution description. The magnitude of the modifications is of the order of a few percent in the deuteron; however, they should be large in large nuclei. In handling high-energy nuclear data, such nuclear modifications need to be taken into account for a precise determination of physical quantities. Now, the longitudinal-transverse structure-function ratio and tensor-polarized experiments are under preparation for the deuteron at JLab. We hope that such effects will be confirmed experimentally for not only for the deuteron but also for larger nuclei."
  },
  {
    "date": "2026-01-26",
    "title": "A brush problem. Homogenization involving thin domains and PDEs in graphs",
    "authors": "José M. Arrieta, Joaquín Domínguez-de-Tena",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18430v1",
    "source": "arXiv",
    "abstract": "This work analyses the homogenization of a linear elliptic equation with Neumann boundary conditions in a comb/brush domain, composed of a fixed base and a family of thin teeth. The teeth are defined as rescalings of order less than or equal to $\\varepsilon$ of a model tooth of arbitrary shape. Periodicity in their distribution is not assumed; instead, the existence of an asymptotic limit density $θ$, which may vanish in certain regions, is assumed. The convergence analysis is performed using an adaptation of the unfolding operator method to a non-periodic framework. Finally, it is shown that, under certain conditions on the geometry of the teeth, the resulting limit problem can be interpreted as a differential equation on a graph."
  },
  {
    "date": "2026-01-26",
    "title": "Biorthogonal ensembles of derivative type",
    "authors": "Tom Claeys, Jiyuan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18427v1",
    "source": "arXiv",
    "abstract": "In this paper, we prove that biorthogonal ensembles on the real line with a specific derivative structure admit an explicit correlation kernel of double contour integral form. We will demonstrate that this expression is a valuable starting point for asymptotic analysis and that our class of biorthogonal ensembles admits a large variety of limit kernels, by proving that two new classes of limit kernels can occur. The first type is a deformation of the hard edge Bessel kernel which arises in polynomial ensembles describing the eigenvalues of the sum of two random matrices, while the second type arises for Muttalib-Borodin type deformations of polynomial ensembles."
  },
  {
    "date": "2026-01-26",
    "title": "Time-reversed Shannon entropy as a chaos indicator for non-integrable systems",
    "authors": "Wenfu Cao, Siyan Chen, Hongsheng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18422v1",
    "source": "arXiv",
    "abstract": "We propose a novel chaos indicator -- time-reversed Shannon entropy (TRSE) -- that leverages the interplay between time-reversal symmetry breaking and information entropy in curved spacetimes. By quantifying statistical discrepancies between forward and backward temporal evolution of particle orbits, TRSE robustly distinguishes chaotic from regular dynamics in non-integrable systems. In contrast, integrable systems exhibit stable, symmetric probability distributions preserved by conserved quantities such as the Carter constant. We validate the method through high-precision numerical simulations in both Kerr and Schwarzschild-Melvin black hole geometries, evolving trajectories forward and backward in time. Furthermore, we refine our previously introduced particle-pair mutual information (MIPP) and perform comprehensive parameter-space scans, revealing a strong quantitative agreement between MIPP and TRSE. The two indicators emerge as complementary probes of chaos: TRSE captures symmetry breaking in orbital evolution, while MIPP measures statistical correlations. Together, they establish a unified framework for diagnosing chaos in general relativistic systems, paving a new path to understand the fundamental nature of chaos in non-integrable systems."
  },
  {
    "date": "2026-01-26",
    "title": "Refinement and Performance Benchmark for Range-Separated Water Force Field",
    "authors": "Qian Gao, Junmin Chen, Kuang Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18416v1",
    "source": "arXiv",
    "abstract": "In our previous work, we developed a CCSD(T)-level range-separated water force field that combines the power of physics-driven and machine learning models. However, it was found that expensive CCSD(T)/CBS calculations lead to limited number of QM data as well as the missing of force labels, both of which lead to training instability issues. Bulk properties show large variations that cannot be resolved by simply reducing the fitting error in small cluster QM dataset. Such instability in bulk phase simulation is a universal problem in the training of machine learning potentials (MLPs), and is particularly severe at CCSD(T) level of theory.In this work, using our range-separated water model as an example, we aim to overcome these limitations by developing a new training workflow. It is composed by several techniques including: 1. an active learning protocol that ensures more thorough sampling in different temperatures and densities; 2. an intermediate force label technique employing machine learning density functional; and 3. an ensemble knowledge distillation (EKD) method. These techniques significantly stabilize the resulting water model, consistently achieving sub-chemical accuracies in both cluster energies and experimental properties. Benchmarks are carried out for various properties including densities, radial distribution functions (RDFs), dielectric constants, diffusivity, and infrared spectra, all showing state-of-the-art (SOTA) performances and proving the effectiveness of the training protocol."
  },
  {
    "date": "2026-01-26",
    "title": "Exploring the role of accretion shocks in galaxy clusters as sources of ultrahigh-energy cosmic rays",
    "authors": "A. D. Supanitsky, S. E. Nuza",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18411v1",
    "source": "arXiv",
    "abstract": "Recently, the Pierre Auger Observatory has found strong evidence supporting the extragalactic origin of the most energetic cosmic rays. Despite several observed excesses in the distribution of arrival directions for the highest energy cosmic rays, the sources remain unidentified. Accretion shocks in galaxy clusters have been proposed as potential sources in the past. These immense shock waves, which can have radii on the order of megaparsecs, are generated by the infall of material from the intergalactic medium into the gravitational potential wells of galaxy clusters. In this work, we investigate the possibility that ultrahigh-energy cosmic rays are accelerated in these regions. Nearby massive galaxy clusters, including Virgo, are treated as a discrete component of the cluster mass distribution. Less massive galaxy clusters, as well as distant massive ones, are assumed to follow a continuous distribution in agreement with cluster mass statistics. We fit the flux at Earth and the composition profile measured by the Pierre Auger Observatory, assuming the injection of different nuclear species by these sources, to determine the values of the model parameters. Our results indicate that cosmic ray acceleration in cluster accretion shocks may account for at least a fraction of the observed UHECR flux at energies below the suppression scale. At higher energies, direct acceleration from the thermal pool would be feasible only if local fluctuations create favorable conditions, such as magnetic fields about an order of magnitude stronger than those typically expected in cluster accretion shocks, or for particular shock normal-magnetic field configurations."
  },
  {
    "date": "2026-01-26",
    "title": "Linear Response for Intermittent Circle Maps",
    "authors": "Odaudu Etubi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18394v1",
    "source": "arXiv",
    "abstract": "Using the Cone technique of Baladi and Todd, we show some form of weak differentiability of the SRB measure for the intermittent circle maps, demonstrating linear response in the process. Subsequently, as an application, we lift the regularity from the base dynamics of the solenoid map with intermittency, showing that this family is statistically stable."
  },
  {
    "date": "2026-01-26",
    "title": "Cohomologically or numerically trivial automorphisms of surfaces of general type",
    "authors": "Fabrizio Catanese, Davide Frapporti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18389v1",
    "source": "arXiv",
    "abstract": "Our main result is the determination of the respective groups $ Aut_\\mathbb{Z}(S) $ of cohomologically trivial automorphisms and $ Aut_\\mathbb{Q}(S) $ of numerically trivial automorphisms for the reducible fake quadrics, that is, the surfaces $S$ isogenous to a product with $q=p_g=0$. In this way we produce new record winning examples: a surface $S$ with $|Aut_\\mathbb{Q}(S)| =192$, and a surface whose cohomology has torsion with nontrivial $ Aut_\\mathbb{Z}(S) \\cong \\mathbb{Z}/2.$"
  },
  {
    "date": "2026-01-26",
    "title": "Estimation of geometric transformation matrices using grid-shaped pilot signals",
    "authors": "Rinka Kawano, Masaki Kawamura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18385v1",
    "source": "arXiv",
    "abstract": "Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks."
  },
  {
    "date": "2026-01-26",
    "title": "Quantum Error Correction on Error-mitigated Physical Qubits",
    "authors": "Minjun Jeon, Zhenyu Cai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18384v1",
    "source": "arXiv",
    "abstract": "We present a general framework for applying linear quantum error mitigation (QEM) techniques directly to physical qubits within a logical qubit to suppress logical errors. By exploiting the linearity of quantum error correction (QEC), we demonstrate that any linear QEM method$\\unicode{x2014}$including probabilistic error cancellation (PEC), zero-noise extrapolation (ZNE), and symmetry verification$\\unicode{x2014}$can be integrated into the physical layer without requiring modifications to the subsequent QEC decoder. Applying this framework to memory experiments using PEC, we analytically prove and numerically verify that the leading-order contribution to the logical error can be removed, increasing the effective code distance by 2. Our simulations on repetition and rotated surface codes show that a distance-3 code with physical-level PEC achieves logical error rates lower than or similar to a distance-5 unmitigated code while using 40% and 64% fewer qubits, respectively. These results establish physical-level QEM as a widely compatible and resource-efficient strategy for enhancing logical performance in early fault-tolerant architectures."
  },
  {
    "date": "2026-01-26",
    "title": "Analysis of freeze-in scenario with a scalar Leptoquark and a scalar Dark Matter",
    "authors": "Joydeep Roy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18379v1",
    "source": "arXiv",
    "abstract": "Dark Matter relic density generation through \\textit{freeze-in} mechanism where dark matter particles interact feebly with visible sector particles, is an alternative approach to well-studied and most popular \\textit{freeze-out} paradigm. We study this \\textit{freeze-in} scenario in the presence of a scalar leptoquark interacting with both dark matter and Standard Model particles with renormalizable interactions. We discuss the effect of the presence of such heavy particle, a scalar leptoquark with mass $\\geq 1.5 \\TeV$, in the thermal bath and subsequent relic density generation. We explore the parameter space of such framework, consisting of two masses and three dimensionless couplings. We numerically study the interaction rates and relic density as a function of these parameters and determine their values consistent with the dark matter constraints."
  },
  {
    "date": "2026-01-26",
    "title": "Socioeconomic Determinants of the COVID-19 Infodemic",
    "authors": "Anna Bertani, Alessandro Cortese, Federico Pilati, Pierluigi Sacco, Riccardo Gallotti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18377v1",
    "source": "arXiv",
    "abstract": "The COVID-19 pandemic has been accompanied by an infodemic of misinformation that impedes effective public health responses. This study examines relationships between socioeconomic factors and infodemic risk patterns across 37 OECD countries using Twitter data from 2020-2022. Employing dimensionality reduction techniques on 20 socioeconomic indicators, we identify complex correlations with infodemic measures that evolve throughout the pandemic. Countries exhibit distinct clustering in their infodemic profiles that transcend conventional socioeconomic categorizations. We find that dynamic information behaviors dominate initial crisis responses, while stable socioeconomic conditions become more influential as the pandemic progresses. News media diet diversity emerges as a significant protective factor, with pluralistic information ecosystems demonstrating greater resilience against misinformation. Additionally, institutional stability correlates strongly with reduced infodemic volatility over time. These findings highlight how infodemics are embedded within broader socioeconomic contexts, providing foundations for targeted interventions to build societal resilience against misinformation during future health emergencies."
  },
  {
    "date": "2026-01-26",
    "title": "Hierarchical Text Classification with LLM-Refined Taxonomies",
    "authors": "Jonas Golde, Nicolaas Jedema, Ravi Krishnan, Phong Le",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18375v1",
    "source": "arXiv",
    "abstract": "Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance."
  },
  {
    "date": "2026-01-26",
    "title": "Potential of Graphene/AlGaN/GaN heterostructures to study the drag and two-stream instability effects",
    "authors": "A. Rehman, D. B. But, P. Sai, M. Dub, P. Prystawko, A. Krajewska, G. Cywinski, W. Knap, S. Rumyantsev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18369v1",
    "source": "arXiv",
    "abstract": "Graphene/AlGaN/GaN heterostructures are proposed to investigate the drag and two-stream instability effects. In this study, graphene grown by chemical vapor deposition was transferred from copper onto the top of the standard AlGaN/GaN wafer, forming a heterostructure with two conducting layers separated by an AlGaN barrier layer. Contacts fabricated to the two-dimensional electron gas and graphene allowed us to study the drag current induced in graphene by passing the drive current through the two-dimensional electron gas. At low temperatures, the graphene drag current exhibited quantum oscillations as a function of the drive voltage. As temperature increases, quantum oscillations disappear, and the magnitude of the drag current increases. Graphene/AlGaN/GaN heterostructures are a promising platform for studying drag and two-stream instability effects, especially if the AlGaN barrier layer thickness can be reduced to a few nanometers."
  },
  {
    "date": "2026-01-26",
    "title": "A short note on $A_α$-eigenvalues for simple graphs",
    "authors": "Giovanni Barbarino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18365v1",
    "source": "arXiv",
    "abstract": "Given a simple graph $G$, its $A_α$ matrix is a convex combination with parameter $α\\in [0,1]$ of its adjacency matrix and its degree diagonal matrices. Here we compare two lower bounds presented in [J. D. G. Silva Jr., C. S. Oliveira and L. M. G. C. Costa. \"Some results involving the $A_α$-eigenvalues for graphs and line graphs\"] for the spectral radius of $A_α$, and prove that one is better than the other when there are no isolated nodes in $G$."
  },
  {
    "date": "2026-01-26",
    "title": "Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning",
    "authors": "Weiqin Yang, Haowen Xue, Qingyi Peng, Hexuan Hu, Qian Huang, Tingbo Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18356v1",
    "source": "arXiv",
    "abstract": "Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings."
  },
  {
    "date": "2026-01-26",
    "title": "When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs",
    "authors": "Junyi Zou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18350v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons."
  },
  {
    "date": "2026-01-26",
    "title": "Maps of Tournaments: Distances, Experiments, and Data",
    "authors": "Filip Nikolow, Piotr Faliszewski, Stanisław Szufa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18348v1",
    "source": "arXiv",
    "abstract": "We form a \"map of tournaments\" by adapting the map framework from the world of elections. By a tournament we mean a complete directed graph where the nodes are the players and an edge points from a winner of a game to the loser (with no ties allowed). A map is a set of tournaments represented as points on a 2D plane, so that their Euclidean distances resemble the distances computed according to a given measure. We identify useful distance measures, discuss ways of generating random tournaments (and compare them to several real-life ones), and show how the maps are helpful in visualizing experimental results (also for knockout tournaments)."
  },
  {
    "date": "2026-01-26",
    "title": "Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception",
    "authors": "Sijing Wu, Yunhao Li, Zicheng Zhang, Qi Jia, Xinyue Li, Huiyu Duan, Xiongkuo Min, Guangtao Zhai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18346v1",
    "source": "arXiv",
    "abstract": "Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs."
  },
  {
    "date": "2026-01-26",
    "title": "Structural Gender Bias in Credit Scoring: Proxy Leakage",
    "authors": "Navya SD, Sreekanth D, SS Uma Sankari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18342v1",
    "source": "arXiv",
    "abstract": "As financial institutions increasingly adopt machine learning for credit risk assessment, the persistence of algorithmic bias remains a critical barrier to equitable financial inclusion. This study provides a comprehensive audit of structural gender bias within the Taiwan Credit Default dataset, specifically challenging the prevailing doctrine of \"fairness through blindness.\" Despite the removal of explicit protected attributes and the application of industry standard fairness interventions, our results demonstrate that gendered predictive signals remain deeply embedded within non-sensitive features. Utilizing SHAP (SHapley Additive exPlanations), we identify that variables such as Marital Status, Age, and Credit Limit function as potent proxies for gender, allowing models to maintain discriminatory pathways while appearing statistically fair. To mathematically quantify this leakage, we employ an adversarial inverse modeling framework. Our findings reveal that the protected gender attribute can be reconstructed from purely non-sensitive financial features with an ROC AUC score of 0.65, demonstrating that traditional fairness audits are insufficient for detecting implicit structural bias. These results advocate for a shift from surface-level statistical parity toward causal-aware modeling and structural accountability in financial AI."
  },
  {
    "date": "2026-01-26",
    "title": "Agentic Much? Adoption of Coding Agents on GitHub",
    "authors": "Romain Robbes, Théo Matricon, Thomas Degueule, Andre Hora, Stefano Zacchiroli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18341v1",
    "source": "arXiv",
    "abstract": "In the first half of 2025, coding agents have emerged as a category of development tools that have very quickly transitioned to the practice. Unlike ''traditional'' code completion LLMs such as Copilot, agents like Cursor, Claude Code, or Codex operate with high degrees of autonomy, up to generating complete pull requests starting from a developer-provided task description. This new mode of operation is poised to change the landscape in an even larger way than code completion LLMs did, making the need to study their impact critical. Also, unlike traditional LLMs, coding agents tend to leave more explicit traces in software engineering artifacts, such as co-authoring commits or pull requests. We leverage these traces to present the first large-scale study (129,134 projects) of the adoption of coding agents on GitHub, finding an estimated adoption rate of 15.85%--22.60%, which is very high for a technology only a few months old--and increasing. We carry out an in-depth study of the adopters we identified, finding that adoption is broad: it spans the entire spectrum of project maturity; it includes established organizations; and it concerns diverse programming languages or project topics. At the commit level, we find that commits assisted by coding agents are larger than commits only authored by human developers, and have a large proportion of features and bug fixes. These findings highlight the need for further investigation into the practical use of coding agents."
  },
  {
    "date": "2026-01-26",
    "title": "PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction",
    "authors": "Isaac Deutsch, Nicolas Moënne-Loccoz, Gavriel State, Zan Gojcic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18336v1",
    "source": "arXiv",
    "abstract": "Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp"
  },
  {
    "date": "2026-01-26",
    "title": "Scalable Repeater Architecture for Long-Range Quantum Energy Teleportation in Gapped Systems",
    "authors": "M. Y. Abd-Rabbou, Irfan Siddique, Saeed Haddadi, Cong-Feng Qiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18327v1",
    "source": "arXiv",
    "abstract": "Quantum Energy Teleportation (QET) constitutes a paradigm-shifting protocol that permits the activation of local vacuum energy through the consumption of pre-existing entanglement and classical communication. Nevertheless, the implementation of QET is severely impeded by the fundamental locality of gapped many-body systems, where the exponential clustering of ground-state correlations restricts energy extraction to microscopic scales. In this work, we address this scalability crisis within the framework of the one-dimensional anisotropic XY model. We initially provide a rigorous characterization of a monolithic measurement-induced strategy, demonstrating that while bulk projective measurements can theoretically induce long-range couplings, the approach is rendered physically untenable by exponentially diverging thermodynamic costs and vanishing success probabilities. To circumvent this impasse, we propose and analyze a hierarchical quantum repeater architecture adapted for energy teleportation. By orchestrating heralded entanglement generation, iterative entanglement purification, and nested entanglement swapping, our protocol effectively counteracts the fidelity degradation inherent in noisy quantum channels. We establish that this architecture fundamentally alters the operational resource scaling from exponential to polynomial. This proves, for the first time, the physical permissibility and computational tractability of activating vacuum energy at arbitrary distances. The significance lies not in net energy gain, but in establishing long-range QET as a viable protocol for remote quantum control and resource distribution."
  },
  {
    "date": "2026-01-26",
    "title": "TC-IDM: Grounding Video Generation for Executable Zero-shot Robot Motion",
    "authors": "Weishi Mi, Yong Bao, Xiaowei Chi, Xiaozhu Ju, Zhiyuan Qin, Kuangzhi Ge, Kai Tang, Peidong Jia, Shanghang Zhang, Jian Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18323v1",
    "source": "arXiv",
    "abstract": "The vision-language-action (VLA) paradigm has enabled powerful robotic control by leveraging vision-language models, but its reliance on large-scale, high-quality robot data limits its generalization. Generative world models offer a promising alternative for general-purpose embodied AI, yet a critical gap remains between their pixel-level plans and physically executable actions. To this end, we propose the Tool-Centric Inverse Dynamics Model (TC-IDM). By focusing on the tool's imagined trajectory as synthesized by the world model, TC-IDM establishes a robust intermediate representation that bridges the gap between visual planning and physical control. TC-IDM extracts the tool's point cloud trajectories via segmentation and 3D motion estimation from generated videos. Considering diverse tool attributes, our architecture employs decoupled action heads to project these planned trajectories into 6-DoF end-effector motions and corresponding control signals. This plan-and-translate paradigm not only supports a wide range of end-effectors but also significantly improves viewpoint invariance. Furthermore, it exhibits strong generalization capabilities across long-horizon and out-of-distribution tasks, including interacting with deformable objects. In real-world evaluations, the world model with TC-IDM achieves an average success rate of 61.11 percent, with 77.7 percent on simple tasks and 38.46 percent on zero-shot deformable object tasks. It substantially outperforms end-to-end VLA-style baselines and other inverse dynamics models."
  },
  {
    "date": "2026-01-26",
    "title": "Residual Learning for Neural Ambisonics Encoders",
    "authors": "Thomas Deppisch, Yang Gao, Manan Mittal, Benjamin Stahl, Christoph Hold, David Alon, Zamir Ben-Hur",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18322v1",
    "source": "arXiv",
    "abstract": "Emerging wearable devices such as smartglasses and extended reality headsets demand high-quality spatial audio capture from compact, head-worn microphone arrays. Ambisonics provides a device-agnostic spatial audio representation by mapping array signals to spherical harmonic (SH) coefficients. In practice, however, accurate encoding remains challenging. While traditional linear encoders are signal-independent and robust, they amplify low-frequency noise and suffer from high-frequency spatial aliasing. On the other hand, neural network approaches can outperform linear encoders but they often assume idealized microphones and may perform inconsistently in real-world scenarios. To leverage their complementary strengths, we introduce a residual-learning framework that refines a linear encoder with corrections from a neural network. Using measured array transfer functions from smartglasses, we compare a UNet-based encoder from the literature with a new recurrent attention model. Our analysis reveals that both neural encoders only consistently outperform the linear baseline when integrated within the residual learning framework. In the residual configuration, both neural models achieve consistent and significant improvements across all tested metrics for in-domain data and moderate gains for out-of-domain data. Yet, coherence analysis indicates that all neural encoder configurations continue to struggle with directionally accurate high-frequency encoding."
  },
  {
    "date": "2026-01-26",
    "title": "Black Hole Interior and Time-like Entanglement Entropy",
    "authors": "Zi-Hao Li, Run-Qiu Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18319v1",
    "source": "arXiv",
    "abstract": "We establish time-like entanglement entropy (TEE) as a novel tool to characterize the black hole interior from a single-boundary perspective. In the Schwarzschild-AdS black hole, we show that TEE of time-like boundary strips exhibits linear growth as a function of temporal width in the limit of large temporal width, and that its imaginary part carries physical significance rather than being a constant. By analyzing charged, scalar-hairy black holes, we present evidence that TEE detects a hidden \"causal phase transition\" separating Type-I and Type-II interiors -- distinguished by singularity structure. We identify a critical temporal width $τ_c$ that acts as the order parameter for this transition: for strips narrower than $τ_c$, the system enters a distinct \"time-like entanglement phase\" dominated purely by time-like contributions, up to a regulator effect; conversely, for strips wider than $τ_c$, space-like entanglement re-emerges. Notably, the existence of a Cauchy horizon drives the $τ_c$ to infinity, leading to pure time-like entanglement. These results suggest that the TEE may supply a novel boundary quantum-information measure to detect structure hidden inside the black hole and suggests a deep connection between TEE and cosmic censorship."
  },
  {
    "date": "2026-01-26",
    "title": "CovertComBench: The First Domain-Specific Testbed for LLMs in Wireless Covert Communication",
    "authors": "Zhaozhi Liu, Jiaxin Chen, Yuanai Xie, Yuna Jiang, Minrui Xu, Xiao Zhang, Pan Lai, Zan Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18315v1",
    "source": "arXiv",
    "abstract": "The integration of Large Language Models (LLMs) into wireless networks presents significant potential for automating system design. However, unlike conventional throughput maximization, Covert Communication (CC) requires optimizing transmission utility under strict detection-theoretic constraints, such as Kullback-Leibler divergence limits. Existing benchmarks primarily focus on general reasoning or standard communication tasks and do not adequately evaluate the ability of LLMs to satisfy these rigorous security constraints. To address this limitation, we introduce CovertComBench, a unified benchmark designed to assess LLM capabilities across the CC pipeline, encompassing conceptual understanding (MCQs), optimization derivation (ODQs), and code generation (CGQs). Furthermore, we analyze the reliability of automated scoring within a detection-theoretic ``LLM-as-Judge'' framework. Extensive evaluations across state-of-the-art models reveal a significant performance discrepancy. While LLMs achieve high accuracy in conceptual identification (81%) and code implementation (83%), their performance in the higher-order mathematical derivations necessary for security guarantees ranges between 18% and 55%. This limitation indicates that current LLMs serve better as implementation assistants rather than autonomous solvers for security-constrained optimization. These findings suggest that future research should focus on external tool augmentation to build trustworthy wireless AI systems."
  },
  {
    "date": "2026-01-26",
    "title": "Photoexcitation spectroscopy of highly charged ions for application to astronomy using a compact electron beam ion trap (EBIT) at the synchrotron radiation facility SPring-8",
    "authors": "Leo Hirata, Yuki Amano, Moto Togawa, Hiroyuki A. Sakaue, Nobuyuki Nakamura, Makoto Sawada, Hiromasa Suzuki, Masaki Oura, Hiroya Yamaguchi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18311v1",
    "source": "arXiv",
    "abstract": "In the past few decades, X-ray astronomy satellites equipped with grating spectrometers and microcalorimeters have enabled high-resolution spectroscopic observations of astrophysical objects. The need for accurate atomic data has arose as we attempt detailed analysis of the high-resolution spectra they provide. This is because current spectral models, which heavily rely on theoretical calculations, entail non-negligible uncertainties. We employ a plasma spectroscopy device called electron beam ion trap (EBIT) to experimentally obtain precise atomic data. An EBIT with a design that allows combined operation with synchrotron radiation facilities was developed based on the Heidelberg Compact EBIT and installed at ISAS/JAXA for this purpose. We conducted a spectroscopic experiment using the JAXA-EBIT at the synchrotron radiation facility SPring-8, and successfully obtained high-resolution spectra of the L$α$ resonance transition of Ne-like Fe$^{16+}$ ions, 3C, as well as the K$α$ resonance transition of He-like O$^{6+}$ ions. We also measured another Ne-like Fe$^{16+}$ L$α$ resonance transition, 3G, and constrained an upper limit of the oscillator strength ratio of 3G to 3C, using our experimental results. The experimental values obtained in this study will be applied to observational studies of astrophysical objects as a part of the plasma spectral modeling."
  },
  {
    "date": "2026-01-26",
    "title": "Dicey Games: Shared Sources of Randomness in Distributed Systems",
    "authors": "Léonard Brice, Thomas A. Henzinger, K. S. Thejaswini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18303v1",
    "source": "arXiv",
    "abstract": "Consider a 4-player version of Matching Pennies where a team of three players competes against the Devil. Each player simultaneously says \"Heads\" or \"Tails\". The team wins if all four choices match; otherwise the Devil wins. If all team players randomise independently, they win with probability 1/8; if all players share a common source of randomness, they win with probability 1/2. What happens when each pair of team players shares a source of randomness? Can the team do better than win with probability 1/4? The surprising (and nontrivial) answer is yes! We introduce Dicey Games, a formal framework motivated by the study of distributed systems with shared sources of randomness (of which the above example is a specific instance). We characterise the existence, representation and computational complexity of optimal strategies in Dicey Games, and we study the problem of allocating limited sources of randomness optimally within a team."
  },
  {
    "date": "2026-01-26",
    "title": "Contextual Range-View Projection for 3D LiDAR Point Clouds",
    "authors": "Seyedali Mousavi, Seyedhamidreza Mousavi, Masoud Daneshtalab",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18301v1",
    "source": "arXiv",
    "abstract": "Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \\textit{Centerness-Aware Projection (CAP)} and \\textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes"
  },
  {
    "date": "2026-01-26",
    "title": "Acceleration of Modelling with Physics Informed Learning: Frameworks and Perspectives for Real-Time Control of Electrochemical Devices",
    "authors": "Remus Teodorescu, Yusheng Zheng, Yi Zhuang, Dominic Karnehm, Javid Beyrami",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18297v1",
    "source": "arXiv",
    "abstract": "Electrochemical devices (batteries, fuel cells, and electrolyzers) are in full development, driven by the green energy transition. Their real-time control requires ms predictions in order to take critical decisions during fast transients or faults. The physics behind include coupled multi-physics phenomena that conventional finite element methods cannot solve so fast with the current CPU technology. This paper evaluates the potential of physics-informed machine learning represented by three frameworks: \\ac{pinn}, \\ac{pideeponet}, and \\ac{pino} by evaluating their training effort, inference speed, and extrapolation capacity. Our analysis reveals valuable performance trade-offs. \\acp{pinn} offer simplicity for fixed problem instances but require retraining for parameter changes. \\ac{pideeponet} enables operator learning across varying conditions with mesh-free geometric flexibility. \\ac{pino} delivers superior performance on regular grids, with the strongest extrapolation capabilities due to spectral derivative computation and resolution invariance. \\ac{pideeponet} is particularly suited for irregular, unstructured geometries (e.g., porous electrodes or complex flow fields), while \\ac{pino} works best for layered, structured-grid problems (e.g., transport across stacked electrochemical layers) requiring fast inference. Possible future applications include real-time lithium concentration prediction for safe fast-charging and micro short circuit detection, water management in fuel cells, and optimal power management in electrolyzers under intermittent renewable inputs. These findings establish physics-informed operator learning as a transformative approach for next-generation electrochemical device controller technology."
  },
  {
    "date": "2026-01-26",
    "title": "Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning",
    "authors": "Zhaoyan Gong, Zhiqiang Liu, Songze Li, Xiaoke Guo, Yuanxiang Liu, Xinle Deng, Zhizhen Liu, Lei Liang, Huajun Chen, Wen Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18296v1",
    "source": "arXiv",
    "abstract": "Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1."
  },
  {
    "date": "2026-01-26",
    "title": "Noise-Robust Contrastive Learning with an MFCC-Conformer For Coronary Artery Disease Detection",
    "authors": "Milan Marocchi, Matthew Fynn, Yue Rong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18295v1",
    "source": "arXiv",
    "abstract": "Cardiovascular diseases (CVD) are the leading cause of death worldwide, with coronary artery disease (CAD) comprising the largest subcategory of CVDs. Recently, there has been increased focus on detecting CAD using phonocardiogram (PCG) signals, with high success in clinical environments with low noise and optimal sensor placement. Multichannel techniques have been found to be more robust to noise; however, achieving robust performance on real-world data remains a challenge. This work utilises a novel multichannel energy-based noisy-segment rejection algorithm, using heart and noise-reference microphones, to discard audio segments with large amounts of nonstationary noise before training a deep learning classifier. This conformer-based classifier takes mel-frequency cepstral coefficients (MFCCs) from multiple channels, further helping improve the model's noise robustness. The proposed method achieved 78.4% accuracy and 78.2% balanced accuracy on 297 subjects, representing improvements of 4.1% and 4.3%, respectively, compared to training without noisy-segment rejection."
  },
  {
    "date": "2026-01-26",
    "title": "Closed Eyes and Coil Size -- Effects on Motor Threshold and Intracortical Inhibition, measured with TMS",
    "authors": "Meher Sabharwal, Narin Suleyman, Gabriel R. Palma, Roisin McMackin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18286v1",
    "source": "arXiv",
    "abstract": "Rationale: Transcranial magnetic stimulation (TMS)-based measures such as resting motor threshold (RMT) and short interval intracortical inhibition (SICI) are widely employed to study motor cortical and corticospinal tract function, and effects of diseases and drug therapies thereon. However, the effect of key experimental factors, including as eye state (open or closed) or stimulating coil size, remain unclear. As such, it is unknown whether these factors must be kept consistent across multi-center studies, and whether differences in such factors may underpin contradictory findings in existing literature. Materials and Methods: Threshold tracking TMS was employed to measure RMT and SICI (3ms interstimulus interval, conditioning at 70% of RMT) in 21 alert and awake, healthy controls. Motor evoked potentials were recorded from abductor pollicis brevis. Both RMT and SICI were measured under 6 conditions, while eyes were open or closed, using 3 figure-of-eight coils of differing winding diameter. Mixed effects modelling was employed to investigate effects of eye state and coil size on each measure. Results: RMT was found to be significantly higher for the smallest (30BFT) coil compared to both larger (50BFT and 70BF) coils. No difference in SICI was identified across coil sizes. Eye state was not found to affect either RMT or SICI measurements. Conclusions: Measurements of RMT and SICI can be considered comparable if recorded with eyes open or closed, provided the individual is awake and alert. Measurements of SICI recorded with figure-of-eight coils of different size can be considered comparable."
  },
  {
    "date": "2026-01-26",
    "title": "Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning",
    "authors": "Lei Wei, Jinpeng Ou, Xiao Peng, Bin Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18282v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal \"think\" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors."
  },
  {
    "date": "2026-01-26",
    "title": "When Nobody Around Is Real: Exploring Public Opinions and User Experiences On the Multi-Agent AI Social Platform",
    "authors": "Qiufang Yu, Mengmeng Wu, Xingyu Lan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18275v1",
    "source": "arXiv",
    "abstract": "Powered by large language models, a new genre of multi-agent social platforms has emerged. Apps such as Social.AI deploy numerous AI agents that emulate human behavior, creating unprecedented bot-centric social networks. Yet, existing research has predominantly focused on one-on-one chatbots, leaving multi-agent AI platforms underexplored. To bridge this gap, we took Social.AI as a case study and performed a two-stage investigation: (i) content analysis of 883 user comments; (ii) a 7-day diary study with 20 participants to document their firsthand platform experiences. While public discourse expressed greater skepticism, the diary study found that users did project a range of social expectations onto the AI agents. While some user expectations were met, the AI-dominant social environment introduces distinct problems, such as attention overload and homogenized interaction. These tensions signal a future where AI functions not merely as a tool or an anthropomorphized actor, but as the dominant medium of sociality itself-a paradigm shift that foregrounds new forms of architected social life."
  },
  {
    "date": "2026-01-26",
    "title": "Designing large language model prompts to extract scores from messy text: A shared dataset and challenge",
    "authors": "Mike Thelwall",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18271v1",
    "source": "arXiv",
    "abstract": "In some areas of computing, natural language processing and information science, progress is made by sharing datasets and challenging the community to design the best algorithm for an associated task. This article introduces a shared dataset of 1446 short texts, each of which describes a research quality score on the UK scale of 1* to 4*. This is a messy collection, with some texts not containing scores and others including invalid scores or strange formats. With this dataset there is also a description of what constitutes a valid score and a \"gold standard\" of the correct scores for these texts (including missing values). The challenge is to design a prompt for Large Language Models (LLMs) to extract the scores from these texts as accurately as possible. The format for the response should be a number and no other text so there are two aspects to the challenge: ensuring that the LLM returns only a number, and instructing it to deduce the correct number for the text. As part of this, the LLM prompt needs to explain when to return the missing value code, -1, instead of a number when the text does not clearly contain one. The article also provides an example of a simple prompt. The purpose of the challenge is twofold: to get an effective solution to this problem, and to increase understanding of prompt design and LLM capabilities for complex numerical tasks. The initial solution suggested has an accuracy of 72.6%, so the challenge is to beat this."
  },
  {
    "date": "2026-01-26",
    "title": "Neural Network Approximation: A View from Polytope Decomposition",
    "authors": "ZeYu Li, ShiJun Zhang, TieYong Zeng, FengLei Fan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18264v1",
    "source": "arXiv",
    "abstract": "Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate."
  },
  {
    "date": "2026-01-26",
    "title": "FGGM: Fisher-Guided Gradient Masking for Continual Learning",
    "authors": "Chao-Hong Tan, Qian Chen, Wen Wang, Yukun Ma, Chong Zhang, Chong Deng, Qinglin Zhang, Xiangang Li, Jieping Ye",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18261v1",
    "source": "arXiv",
    "abstract": "Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution."
  },
  {
    "date": "2026-01-26",
    "title": "BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation",
    "authors": "Peng Sun, Xiangyu Zhang, Duan Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18253v1",
    "source": "arXiv",
    "abstract": "Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED."
  },
  {
    "date": "2026-01-26",
    "title": "GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction",
    "authors": "Kesha Ou, Zhen Tian, Wayne Xin Zhao, Hongyu Lu, Ji-Rong Wen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18251v1",
    "source": "arXiv",
    "abstract": "Click-through rate (CTR) prediction plays a pivotal role in online advertising and recommender systems. Despite notable progress in modeling user preferences from historical behaviors, two key challenges persist. First, exsiting discriminative paradigms focus on matching candidates to user history, often overfitting to historically dominant features and failing to adapt to rapid interest shifts. Second, a critical information chasm emerges from the point-wise ranking paradigm. By scoring each candidate in isolation, CTR models discard the rich contextual signal implied by the recalled set as a whole, leading to a misalignment where long-term preferences often override the user's immediate, evolving intent. To address these issues, we propose GenCI, a generative user intent framework that leverages semantic interest cohorts to model dynamic user preferences for CTR prediction. The framework first employs a generative model, trained with a next-item prediction (NTP) objective, to proactively produce candidate interest cohorts. These cohorts serve as explicit, candidate-agnostic representations of a user's immediate intent. A hierarchical candidate-aware network then injects this rich contextual signal into the ranking stage, refining them with cross-attention to align with both user history and the target item. The entire model is trained end-to-end, creating a more aligned and effective CTR prediction pipeline. Extensive experiments on three widely used datasets demonstrate the effectiveness of our approach."
  },
  {
    "date": "2026-01-26",
    "title": "A particle on a ring or: how I learned to stop worrying and love $θ$-vacua",
    "authors": "Mohammad Aghaie, Ryosuke Sato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18248v1",
    "source": "arXiv",
    "abstract": "Recently, Ai, Cruz, Garbrecht, and Tamarit (ACGT)~\\cite{Ai:2020ptm, Ai:2024vfa, Ai:2024cnp, Ai:2025quf} claimed that there is no strong CP problem by adopting a new order of limits in the volume and topological sector. We critically examine this proposal by focusing on simple one-dimensional quantum mechanics on a ring. We demonstrate that consistent results are obtained only when one sums over all topological sectors \\textit{before} taking the large $T$ limit. This observation justifies the conventional path integral formulation of gauge theories and implies that the strong CP problem does exist in QCD."
  },
  {
    "date": "2026-01-26",
    "title": "Nonanalytic Structure of Effective Potential at Finite Temperature on Compactified Space",
    "authors": "Makoto Sakamoto, Kazunori Takenaga",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18244v1",
    "source": "arXiv",
    "abstract": "We thoroughly investigate nonanalytic terms in the finite-temperature effective potential in one-loop approximation on a $D$-dimensional spacetime, $S_τ\\times R^{D-(p+1)}\\times \\prod_{i=1}^p S_i^1$, using a mode recombination formula. Such nonanalytic terms cannot be expressed as positive powers of field-dependent mass squared. The formula provides a clear separation of the effective potential into a part that contains the nonanalytic terms and a part that is purely analytic, and clarifies the origin of the nonanalytic terms. We obtain all the nonanalytic terms and show that only two types of nonanalytic terms arise: power-type and logarithmic-one. For a real scalar field with periodic boundary conditions, the manner of the emergence of these terms is highly characteristic; the two types never appear simultaneously. By contrast, for fermions with general boundary conditions, we find that neither of the two types appears. These results clarify the nonanalytic structure of the finite-temperature effective potential on the spacetime with compactified spatial dimensions."
  },
  {
    "date": "2026-01-26",
    "title": "TechING: Towards Real World Technical Image Understanding via VLMs",
    "authors": "Tafazzul Nadeem, Bhavik Shangari, Manish Rai, Gagan Raj Gupta, Ashutosh Modi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18238v1",
    "source": "arXiv",
    "abstract": "Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x."
  },
  {
    "date": "2026-01-26",
    "title": "Breakdown of bosonic Thouless pump due to interaction in a quasiperiodic lattice",
    "authors": "Suman Mondal, Emmanuel Gottlob, Fabian Heidrich-Meisner, Ulrich Schneider",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18229v1",
    "source": "arXiv",
    "abstract": "We investigate the effect of inter-particle interaction on the quantized Thouless pump in the bosonic quasiperiodic Aubry-Andr{é} model and find that the quantization of the pumped charge breaks down already for weak interactions. Furthermore, the pumped charge undergoes sharp changes as a function of interaction strength that we can attribute to the closing of specific doublon channels. As expected, the quantization revives in the hard-core limit at very large interaction strengths where the bosons are subject to a hardcore constraint. Interestingly, the stability of isolated doublons under the pump depends on the band they are in. For repulsive interactions and a suitably fixed pump period, doublons in the lowest band are pumped stably while doublons in higher bands dissociate during the pump with one particle decaying into a lower band. This asymmetry leads to the decay of the total energy over time, in stark contrast to the typical Floquet heating expected for a driven many-body system."
  },
  {
    "date": "2026-01-26",
    "title": "HomoFM: Deep Homography Estimation with Flow Matching",
    "authors": "Mengfan He, Liangzheng Sun, Chunyu Li, Ziyang Meng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18222v1",
    "source": "arXiv",
    "abstract": "Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM."
  },
  {
    "date": "2026-01-26",
    "title": "Automated HER2 scoring with uncertainty quantification using lensfree holography and deep learning",
    "authors": "Che-Yung Shen, Xilin Yang, Yuzhu Li, Leon Lenk, Aydogan Ozcan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18219v1",
    "source": "arXiv",
    "abstract": "Accurate assessment of human epidermal growth factor receptor 2 (HER2) expression is critical for breast cancer diagnosis, prognosis, and therapy selection; yet, most existing digital HER2 scoring methods rely on bulky and expensive optical systems. Here, we present a compact and cost-effective lensfree holography platform integrated with deep learning for automated HER2 scoring of immunohistochemically stained breast tissue sections. The system captures lensfree diffraction patterns of stained HER2 tissue sections under RGB laser illumination and acquires complex field information over a sample area of ~1,250 mm^2 at an effective throughput of ~84 mm^2 per minute. To enhance diagnostic reliability, we incorporated an uncertainty quantification strategy based on Bayesian Monte Carlo dropout, which provides autonomous uncertainty estimates for each prediction and supports reliable, robust HER2 scoring, with an overall correction rate of 30.4%. Using a blinded test set of 412 unique tissue samples, our approach achieved a testing accuracy of 84.9% for 4-class (0, 1+, 2+, 3+) HER2 classification and 94.8% for binary (0/1+ vs. 2+/3+) HER2 scoring with uncertainty quantification. Overall, this lensfree holography approach provides a practical pathway toward portable, high-throughput, and cost-effective HER2 scoring, particularly suited for resource-limited settings, where traditional digital pathology infrastructure is unavailable."
  },
  {
    "date": "2026-01-26",
    "title": "Rhea: Detecting Privilege-Escalated Evasive Ransomware Attacks Using Format-Aware Validation in the Cloud",
    "authors": "Beom Heyn Kim, Seok Min Hong, Mohammad Mannan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18216v1",
    "source": "arXiv",
    "abstract": "Ransomware variants increasingly combine privilege escalation with sophisticated evasion strategies such as intermittent encryption, low-entropy encryption, and imitation attacks. Such powerful ransomware variants, privilege-escalated evasive ransomware (PEER), can defeat existing solutions relying on I/O-pattern analysis by tampering with or obfuscating I/O traces. Meanwhile, conventional statistical content-based detection becomes unreliable as the encryption size decreases due to sampling noises. We present Rhea, a cloud-offloaded ransomware defense system that analyzes replicated data snapshots, so-called mutation snapshots. Rhea introduces Format-Aware Validation that validates the syntactic and semantic correctness of file formats, instead of relying on statistical or entropy-based indicators. By leveraging file-format specifications as detection invariants, Rhea can reliably identify fine-grained and evasive encryption even under elevated attacker privileges. Our evaluation demonstrates that Rhea significantly outperforms existing approaches, establishing its practical effectiveness against modern ransomware threats."
  },
  {
    "date": "2026-01-26",
    "title": "Controllability of wave-heat and heat-wave cascades",
    "authors": "Hugo Lhachemi, Christophe Prieur, Emmanuel Trélat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18212v1",
    "source": "arXiv",
    "abstract": "We study boundary controllability of one-dimensional coupled hyperbolic-parabolic cascades, focusing on the fine structure of reachable sets. The main model is a wave-heat cascade in which a boundary control acts on the wave equation and drives the heat equation through an internal coupling. We provide a sharp minimal time for the hyperbolic part (T > 2L) and a complete spectral characterization of exact controllability in weighted Hilbert spaces, whose definition depends explicitly on the coupling profile through a sequence of modal coefficients. In particular, internal couplings may generate nonstandard highly irregular controllability spaces and yield a generic (full measure) but non-robust controllability property. The analysis relies on Riesz basis decompositions and on an Ingham-M{ü}ntz inequality. We also prove that the exact controllability space is not invariant along Hilbert Uniqueness Method trajectories: even if both endpoints belong to the controllability space, the associated minimal-energy trajectory may leave it at intermediate times. Finally, we compare with the reversed (heat-wave) cascade and discuss how reversing the direction of the coupling transfers the loss of regularity between the parabolic and hyperbolic components."
  },
  {
    "date": "2026-01-26",
    "title": "Wave functions and k-point functions for the AKNS hierarchy",
    "authors": "Ang Fu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18211v1",
    "source": "arXiv",
    "abstract": "For an arbitrary solution to the AKNS hierarchy, the logarithmic derivatives of the tau-function of the solution can be computed by the matrix-resolvent method [14,21]. In this paper, we introduce a pair of wave functions of the solution and we use them to express the corresponding matrix resolvent. Based on this, we derive a new formula for the k-point correlation function of the AKNS hierarchy expressed in terms of wave functions. As an application, we show that the tau-function of an arbitrary solution to the AKNS hierarchy is a KP tau-function."
  },
  {
    "date": "2026-01-26",
    "title": "Tunneling signatures of interband coherence in dilute exciton condensates",
    "authors": "Kryštof Kolář, Felix von Oppen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18210v1",
    "source": "arXiv",
    "abstract": "We theoretically investigate signatures of exciton condensation and the underlying interband coherence in scanning tunneling microscopy. We consider both monolayer and bilayer condensates in the regime of a dilute condensate of tightly bound excitons. For monolayer condensates, interband coherence is directly encoded in spatially oscillating contributions to the tunneling conductance, which break the underlying lattice symmetry. We show how scanning tunneling microscopy allows one to extract the exciton wavefunction. For bilayer condensates, we show that the formation of the exciton insulator is signaled by the emergence of a characteristic peak in the tunneling conductance, which can be used to extract the (local) exciton density. Our results are based on analytical considerations using a systematic solution of the mean-field equations in powers of the exciton density as well as numerical calculations."
  },
  {
    "date": "2026-01-26",
    "title": "Lattice determination of the neutrino background for $J/ψ\\rightarrow γ+ \\textrm{invisible}$",
    "authors": "Yu Meng, Ning Li, Chuan Liu, Haobo Yan, Ke-Long Zhang, Xue-Ze Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18209v1",
    "source": "arXiv",
    "abstract": "Searching for dark matter is a primary goal of modern astronomy and particle physics. Invisible decays of heavy quarkonia are particularly promising for probing light dark matter, attracting broad interest due to their unique sensitivity. Experiments searching for radiative invisible decays of the $J/ψ$ have steadily improved upper limits, and upcoming facilities will push sensitivity further -- making the precise determination and subtraction of the neutrino background indispensable. Here, we present the first lattice QCD calculation of the Standard Model decay $J/ψ\\to γν\\barν$, an irreducible background to $J/ψ\\to γ+ \\textrm{invisible}$. Our result for the branching fraction is $\\operatorname{Br}(J/ψ\\to γν\\barν)=1.00(9)(7)\\times 10^{-10}$, where the first uncertainty is statistical and the second is our systematic estimate. This work advances lattice-based determinations of neutrino backgrounds to quarkonium invisible decays, delivering an ab initio benchmark for $J/ψ\\to γ+ \\textrm{invisible}$. Our approach generalizes to other quarkonium channels (e.g., $Υ/φ\\to γ+\\textrm{invisible}$) and provides critical theoretical support for dark matter searches at colliders."
  },
  {
    "date": "2026-01-26",
    "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR",
    "authors": "James Burgess, Jan N. Hansen, Duo Peng, Yuhui Zhang, Alejandro Lozano, Min Woo Sun, Emma Lundberg, Serena Yeung-Levy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18207v1",
    "source": "arXiv",
    "abstract": "Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains."
  },
  {
    "date": "2026-01-26",
    "title": "Gluing different gravitational models: $f(R)$ case",
    "authors": "Amin Aalipour, Nima Khosravi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18205v1",
    "source": "arXiv",
    "abstract": "This paper presents a comprehensive analysis of junction conditions for gluing different $f(R)$ gravitational theories across a non-null hypersurface. Using the variational approach, we systematically derive the junction conditions for both general $f(R)$ theories and the special case of Einstein gravity, for comparison. We demonstrate that when joining two distinct $f(R)$ theories, the junction conditions require continuity of $\\partial f(R)/\\partial R$, the extrinsic curvature $K_{μν}$, while allowing for discontinuities in the Ricci Scalar $R$. Furthermore, we establish the equivalence between Jordan and Einstein frame formulations through careful treatment of conformal transformations; Our results reveal that different $f(R)$ theories can be consistently matched provided specific relations between their functional forms and geometric quantities are satisfied at the interface."
  },
  {
    "date": "2026-01-26",
    "title": "MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning",
    "authors": "Juexiang Ye, Xue Li, Xinyu Yang, Chengkai Huang, Lanshun Nie, Lina Yao, Dechen Zhan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18204v1",
    "source": "arXiv",
    "abstract": "Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\\% compared to long-context baselines."
  },
  {
    "date": "2026-01-26",
    "title": "DMAP: Human-Aligned Structural Document Map for Multimodal Document Understanding",
    "authors": "ShunLiang Fu, Yanxin Zhang, Yixin Xiang, Xiaoyu Du, Jinhui Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18203v1",
    "source": "arXiv",
    "abstract": "Existing multimodal document question-answering (QA) systems predominantly rely on flat semantic retrieval, representing documents as a set of disconnected text chunks and largely neglecting their intrinsic hierarchical and relational structures. Such flattening disrupts logical and spatial dependencies - such as section organization, figure-text correspondence, and cross-reference relations, that humans naturally exploit for comprehension. To address this limitation, we introduce a document-level structural Document MAP (DMAP), which explicitly encodes both hierarchical organization and inter-element relationships within multimodal documents. Specifically, we design a Structured-Semantic Understanding Agent to construct DMAP by organizing textual content together with figures, tables, charts, etc. into a human-aligned hierarchical schema that captures both semantic and layout dependencies. Building upon this representation, a Reflective Reasoning Agent performs structure-aware and evidence-driven reasoning, dynamically assessing the sufficiency of retrieved context and iteratively refining answers through targeted interactions with DMAP. Extensive experiments on MMDocQA benchmarks demonstrate that DMAP yields document-specific structural representations aligned with human interpretive patterns, substantially enhancing retrieval precision, reasoning consistency, and multimodal comprehension over conventional RAG-based approaches. Code is available at https://github.com/Forlorin/DMAP"
  },
  {
    "date": "2026-01-26",
    "title": "SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback",
    "authors": "Fangyuan Xu, Rujun Han, Yanfei Chen, Zifeng Wang, I-Hung Hsu, Jun Yan, Vishy Tirumalashetty, Eunsol Choi, Tomas Pfister, Chen-Yu Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18202v1",
    "source": "arXiv",
    "abstract": "Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training."
  },
  {
    "date": "2026-01-26",
    "title": "Trajectory-Based RBF Collocation Method for Surface Advection-Diffusion Equations",
    "authors": "Xiaobin Li, Leevan Ling, Yizhong Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18186v1",
    "source": "arXiv",
    "abstract": "We introduce a Trajectory-Based RBF Collocation (TBRBF) method for solving surface advection-diffusion equations on smooth, compact manifolds. TBRBF decouples advection and diffusion by applying a characteristic treatment with a Kansa-type RBF collocation method for diffusion PDE, which yields an operator-split characteristic (OSC) system comprising a characteristic ODE and a diffusion PDE. We rigorously prove the equivalence between the OSC system and the original surface PDE on manifolds by embedding the latter into a narrow band domain. Using an intrinsic approach, we construct a time-continuous embedded PDE with push-forward operators in each chart of the atlas and establish its equivalence with the OSC system in the narrow band. Restricting the solution back to the manifold recovers the OSC system on manifolds, ensuring that the method introduces no operator splitting error. Extensive numerical experiments confirm the robust stability and accuracy of the proposed method."
  },
  {
    "date": "2026-01-26",
    "title": "Vertex degrees in grid graphs associated with 213-avoiding permutations",
    "authors": "N. B. Huamaní",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18173v1",
    "source": "arXiv",
    "abstract": "Given a permutation of size $n$, we consider its associated grid graph whose $i$th column has height equal to the $i$th entry, with vertical edges between consecutive levels and horizontal edges between equal levels in adjacent columns. We study global degree statistics of these graphs when the permutation is chosen from the Catalan avoidance class $\\mathrm{Av}_n(213)$ (and, by reversal, also from $\\mathrm{Av}_n(312)$). We first obtain an explicit closed form for the total number of horizontal edges summed over all permutations in $\\mathrm{Av}_n(213)$. We then determine, for each degree $r\\in\\{1,2,3,4\\}$, the total number of degree-$r$ vertices accumulated over the same class, yielding closed expressions in terms of central binomial coefficients and powers of four. The proofs rely on the Catalan decomposition induced by the position of the minimum entry, which leads to gluing identities and algebraic functional equations for ordinary generating functions, completed using global vertex and degree-sum identities. As a consequence, we derive asymptotic degree proportions for a uniform random permutation in $\\mathrm{Av}_n(213)$: the distribution concentrates and the proportion of degree-$4$ vertices tends to $1$, with a deficit of order $n^{-1/2}$."
  },
  {
    "date": "2026-01-26",
    "title": "YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection",
    "authors": "Lin Huang, Yujuan Tan, Weisheng Li, Shitai Shan, Liu Liu, Bo Liu, Linlin Shen, Jing Yu, Yue Niu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18172v1",
    "source": "arXiv",
    "abstract": "One-stage object detection, particularly the YOLO series, strikes a favorable balance between accuracy and efficiency. However, existing YOLO detectors lack explicit modeling of heterogeneous object responses within shared feature channels, which limits further performance gains. To address this, we propose YOLO-DS, a framework built around a novel Dual-Statistic Synergy Operator (DSO). The DSO decouples object features by jointly modeling the channel-wise mean and the peak-to-mean difference. Building upon the DSO, we design two lightweight gating modules: the Dual-Statistic Synergy Gating (DSG) module for adaptive channel-wise feature selection, and the Multi-Path Segmented Gating (MSG) module for depth-wise feature weighting. On the MS-COCO benchmark, YOLO-DS consistently outperforms YOLOv8 across five model scales (N, S, M, L, X), achieving AP gains of 1.1% to 1.7% with only a minimal increase in inference latency. Extensive visualization, ablation, and comparative studies validate the effectiveness of our approach, demonstrating its superior capability in discriminating heterogeneous objects with high efficiency."
  },
  {
    "date": "2026-01-26",
    "title": "Lie algebroid connection and Harder-Narasimhan reduction",
    "authors": "Ashima Bansal, Indranil Biswas, Pradip Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18169v1",
    "source": "arXiv",
    "abstract": "Take a holomorphic Lie algebroid $(V,\\, φ)$ on a compact connected Riemann surface $X$ such that the anchor map $φ$ is not surjective. Let $P$ be a parabolic subgroup of a complex reductive affine algebraic group $G$ and $E_P\\, \\subset\\, E_G$ a holomorphic reduction of structure group, to $P$, of a holomorphic principal $G$--bundle $E_G$ on $X$. We prove that $E_P$ admits a holomorphic Lie algebroid connection for $(V,\\,φ)$ if the reduction $E_P$ is infinitesimally rigid. If $E_P$ is the Harder--Narasimhan reduction of $E_G$, then it is shown that $E_P$ admits a holomorphic Lie algebroid connection for $(V,\\,φ)$. In particular, for any point $x_0\\,\\in\\, X$, the Harder--Narasimhan reduction $E_P$ admits a logarithmic connection that is nonsingular on the complement $X\\setminus\\{x_0\\}$."
  },
  {
    "date": "2026-01-26",
    "title": "A necessary condition for the logarithmic Minkowksi problem in higher dimension",
    "authors": "Mijia Lai, Zixiao Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18167v1",
    "source": "arXiv",
    "abstract": "In this paper, we establish a necessary condition for the logarithmic Minkowski problem in higher dimensions. This result generalizes a necessary condition proposed by Liu, Lu, Sun, and Xiong in their investigation of the two-dimensional case, and also refines the so-called subspace concentration condition."
  },
  {
    "date": "2026-01-26",
    "title": "Pullback and Direct Image of Parabolic Ample and Parabolic Nef Vector Bundles",
    "authors": "Ashima Bansal, Indranil Biswas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18166v1",
    "source": "arXiv",
    "abstract": "We prove that under a finite surjective map of irreducible smooth complex projective curves, the pullback and direct image of a parabolic ample (respectively, parabolic nef) vector bundle is again parabolic ample (respectively, parabolic nef) if and only if the original parabolic vector bundle is parabolic ample (respectively, parabolic nef)."
  },
  {
    "date": "2026-01-26",
    "title": "Magnetic field-induced non-trivial Lifshitz transition in TaCo2Te2",
    "authors": "Suman Kalyan Pradhan, Xiaoming Ma, Jicheng Wang, Weiqi Liu, Yue Dai, Wenxing Chen, Xiaobai Ma, Wenyun Yang, Yu Wu, Zhaochu Luo, Raktim Datta, Arnab Bera, Samik DuttaGupta, Jinbo Yang, Yanglong Hou, Chang Liu, Rui Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18160v1",
    "source": "arXiv",
    "abstract": "Magnetic-field-driven Lifshitz transitions are typically considered zero-temperature phenomena involving Fermi-surface reconstruction without symmetry breaking. Here, we report an unconventional Lifshitz transition in TaCo2Te2 that emerges exclusively within a narrow finite-temperature window under cooperative tuning by both temperature and magnetic field. Bulk-sensitive transport and thermoelectric measurements demonstrate continuous Fermi-surface renormalization at low temperatures, where the transition is sharply triggered by a critical magnetic field. Crucially, neutron diffraction reveals the absence of structural or magnetic phase transitions, while angle-resolved photoemission spectroscopy shows no spectral anomalies in electronic structure without magnetic field. These observations constrain the mechanism to a Zeeman-driven process invisible to equilibrium probes, establishing a paradigm where Fermi-surface topology is jointly controlled by temperature and magnetic field."
  },
  {
    "date": "2026-01-26",
    "title": "JWST Spectroscopic Census of ALMA Faint Submillimeter Galaxies in the Hubble Ultra Deep Field",
    "authors": "Tomokazu Kiyota, Masami Ouchi, Daisuke Iono, Seiji Fujimoto, Kotaro Kohno, Yoshihiro Ueda, Kimihiko Nakajima, Moka Nishigaki, Hidenobu Yajima",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18149v1",
    "source": "arXiv",
    "abstract": "We present a JWST/NIRSpec rest-frame optical spectroscopic census of ALMA 1-mm continuum sources in the Hubble Ultra Deep Field (UDF) identified by the deep ALMA UDF and ASPECS programs. Our sample is composed of the ALMA flux-limited ($S_{1\\,\\mathrm{mm}}\\gtrsim 0.1\\,\\mathrm{mJy}$) sources observed with medium-resolution NIRSpec spectroscopy from JADES and SMILES, 16 faint submillimeter galaxies (SMGs) at spectroscopic redshifts of $z\\sim 1$-$4$. These SMGs show bright longer-wavelength optical lines (H$α$, [N II]$λ\\lambda6548,6583$, and [S II]$λ\\lambda6717,6731$) and faint shorter-wavelength optical lines (H$β$ and [O III]$λ\\lambda4959,5007$) with a large nebular attenuation, $E(B-V)\\sim0.3$-$1.8$. We test the SMGs using BPT diagnostics and Chandra X-ray fluxes, and find that most SMGs are classified as AGNs; the AGN fraction is $\\sim80\\%$ for the SMGs at $M_*>10^{10.5} M_\\odot$. We find only one SMG ($<10\\%$) with a broad Balmer line, indicating that the SMGs are predominantly obscured AGNs. With the optical lines, we estimate the metallicities of the SMGs to be moderately high, $\\sim0.4$-$2 Z_\\odot$, exceeding the model-predicted dust-growth critical metallicity ($\\sim0.1$-$0.2Z_\\odot$), which naturally explains the dusty nature of the SMGs. Interestingly, the SMGs fall in the mass-metallicity relation and the star-formation main sequence, showing no significant differences from other high-$z$ galaxies. Similarly, we find electron densities of $n_e\\sim10^2$-$10^3\\,\\mathrm{cm}^{-3}$ for the SMGs that are comparable with other high-$z$ galaxies. Together with the high SMG fraction ($\\sim 100\\%$) at the massive end ($M_*>10^{10.5} M_\\odot$), these results indicate that the SMGs are mostly not special, but typical massive star-forming galaxies at high redshift."
  },
  {
    "date": "2026-01-26",
    "title": "Systematic classification of one-loop models addressing the $b \\to s ν\\barν$ anomaly",
    "authors": "Xin-Shuai Yan, Wen-Feng Liu, Qin Chang, Ya-Dong Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18147v1",
    "source": "arXiv",
    "abstract": "The recent evidence for the decay $B^+ \\to K^+ ν\\barν$ reported by the Belle II collaboration, combined with the existing constraints on the neutral mode $B^0 \\to K^{*0} ν\\barν$, implies a deviation from the Standard Model prediction that necessitates New Physics contributions to both left- and right-handed vector currents. We perform a systematic topological classification of renormalizable one-loop completions capable of generating the required dimension-six operators while forbidding tree-level mediation. Based on this classification, we identify and construct two minimal benchmark scenarios -- a scalar-rich model and a fermion-rich model -- and perform a comprehensive phenomenological analysis. Our study demonstrates that while these one-loop models can yield enhancements in the $b \\to s ν\\barν$ branching fractions, the attainable magnitudes are significantly restricted by the combined effects of loop suppression and complementary flavor constraints, limiting their ability to fully accommodate the current anomaly."
  },
  {
    "date": "2026-01-26",
    "title": "Neuro-Parametric Spectral Classification of Black Hole and Neutron Star X-ray Binary Systems",
    "authors": "Akash Garg, Aman Kumar, Ajit Kembhavi, Ranjeev Misra, Aniruddha Kembhavi, N. S. Philip, Rohan Pattnaik, Shreya Watwe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18139v1",
    "source": "arXiv",
    "abstract": "We perform the classification of black hole and neutron star X-ray binary systems using deep neural networks applied to archival RXTE X-ray spectral data. We first construct two neural network models: one trained using only spectral flux values and another trained using both fluxes and their associated errors. Both models achieve high classification accuracies of ~90-94 %. To gain physical interpretability of these networks, we fit all spectra with a simple phenomenological model consisting of a thermal disk component and a power-law. From this analysis, we identify the blackbody temperature, power-law index, the ratio of blackbody to power-law flux, the reduced $χ^2$, and the variance of the data as key parameters that likely contribute to the classification. We validate this inference by designing an additional neural network trained exclusively on this reduced parameter set, without using the spectral data directly. This parameter-based model achieves a classification accuracy comparable to that of the spectral models. Our results show that deep neural networks can not only classify compact objects in X-ray binaries with high accuracy but can also be interpreted in terms of physically meaningful spectral parameters derived from conventional X-ray spectral analysis. This framework offers a promising, mission-agnostic approach for compact object classification in current and future X-ray surveys."
  },
  {
    "date": "2026-01-26",
    "title": "Accelerating Update Broadcasts Over LoRaWAN Downlink via D2D Cooperation",
    "authors": "Anshika Singh, Siddhartha S. Borkotoky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18134v1",
    "source": "arXiv",
    "abstract": "Broadcast distribution of updates (e.g., security patches, machine learning models) from a server to end devices (EDs) is a critical requirement in the Internet of Things (IoT). In this paper, we consider the problem of reliable over-the-air broadcast of updates in Long Range Wide Area Networks (LoRaWANs). Existing broadcast techniques for LoRaWANs suffer from long delivery delays due to low data rates and duty-cycle constraints. We address this problem by proposing a device-level cooperative mechanism, in which updated EDs broadcast a few update fragments to accelerate delivery to their neighbors. We demonstrate large reductions in the delivery time compared to conventional methods. For instance, in a 400-node network spanning 1 km radius and operating at 1% duty-cycle, the proposed scheme reduces the time required to deliver a 10 kilobyte update to an ED at the network's edge from 42 hours to 45 minutes. The proposed solution thus provides a pathway toward improved security and efficient realization of edge intelligence in LoRaWAN IoT."
  },
  {
    "date": "2026-01-26",
    "title": "Heavy Quarkonium Spectrum and Decay Constants from a Neural-Network-Based Holographic Model",
    "authors": "Yu Zhang, Xun Chen, Miguel Angel Martin Contreras",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18133v1",
    "source": "arXiv",
    "abstract": "We present a data-driven inverse construction of the dilaton field in a bottom-up AdS/QCD description of heavy vector quarkonia. Instead of adopting an \\emph{ad hoc} analytic ansatz, we use a multilayer perceptron to learn \\(Φ'(z)\\) as a smooth function of the holographic coordinate, with \\(Φ(0)=0\\) imposed to ensure ultraviolet consistency. The dilaton and its derivatives obtained by automatic differentiation generate the holographic potential \\(U(z)\\), and the associated Schrödinger-like equation is discretized and diagonalized to extract the low-lying eigenmodes. Masses and decay constants are then evaluated from the eigenvalues and the near-boundary behavior of the bulk-to-boundary modes. Training on PDG data for charmonium and bottomonium yields a non-quadratic dilaton profile that resolves the longstanding difficulty of simultaneously reproducing both the heavy-quarkonium spectrum and the monotonic suppression of leptonic decay constants with radial excitation. The combined fit achieves RMS deviations of \\(1.26\\%\\) (charmonium) and \\(3.32\\%\\) (bottomonium). This work establishes neural-network reconstruction as a flexible tool for holographic modeling and provides a basis for future extensions incorporating additional channels, lattice constraints, or finite-temperature backgrounds."
  },
  {
    "date": "2026-01-26",
    "title": "Static stable timelike circular orbits and Aschenbach effect in horizonless solutions of Einstein cubic gravity",
    "authors": "Zhen-Hua Zhao, Yong-Qiang Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18122v1",
    "source": "arXiv",
    "abstract": "In the spacetime of horizonless compact objects described by Einsteinian cubic gravity (ECG), we demonstrate the existence of static stable timelike circular orbits on which massive particles remain at rest relative to distant observers. These static orbits are further identified as the innermost stable circular orbits (ISCOs) in this spacetime. If such static orbits form part of an accretion disk, they would give rise to a ring-like structure that is unaffected by Doppler shifts. Moreover, the Aschenbach effect is shown to be present: the orbital velocity of particles on timelike circular orbits, as measured by a zero angular momentum observer (ZAMO), displays a non-monotonic dependence on the radial coordinate. Additionally, the regions supporting stable circular orbits can be discontinuous, and particles on stable orbits near the center can possess specific energies greater than one ($E > 1$)."
  },
  {
    "date": "2026-01-26",
    "title": "Decentralized Multi-product Pricing: Diagonal Dominance, Nash Equilibrium, and Price of Anarchy",
    "authors": "Boxiao Chen, Jiashuo Jiang, Stefanus Jasin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18117v1",
    "source": "arXiv",
    "abstract": "Decentralized decision making in multi--product firms can lead to efficiency losses when autonomous decision makers fail to internalize cross--product demand interactions. This paper quantifies the magnitude of such losses by analyzing the Price of Anarchy in a pricing game in which each decision maker independently sets prices to maximize its own product--level revenue. We model demand using a linear system that captures both substitution and complementarity effects across products. We first establish existence and uniqueness of a pure--strategy Nash equilibrium under economically standard diagonal dominance conditions. Our main contribution is the derivation of a tight worst--case lower bound on the ratio between decentralized revenue and the optimal centralized revenue. We show that this efficiency loss is governed by a single scalar parameter, denoted by $μ$, which measures the aggregate strength of cross--price effects relative to own--price sensitivities. In particular, we prove that the revenue ratio is bounded below by $4(1-μ)/(2-μ)^2$, and we demonstrate the tightness of this bound by constructing a symmetric market topology in which the bound is exactly attained. We further refine the analysis by providing an instance--exact characterization of efficiency loss based on the spectral properties of the demand interaction matrix. Together, these results offer a quantitative framework for assessing the trade--off between centralized pricing and decentralized autonomy in multi--product firms."
  },
  {
    "date": "2026-01-26",
    "title": "MalURLBench: A Benchmark Evaluating Agents' Vulnerabilities When Processing Web URLs",
    "authors": "Dezhang Kong, Zhuxi Wu, Shiqi Liu, Zhicheng Tan, Kuichen Lu, Minghao Li, Qichen Liu, Shengyu Chu, Zhenhua Xu, Xuan Liu, Meng Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18113v1",
    "source": "arXiv",
    "abstract": "LLM-based web agents have become increasingly popular for their utility in daily life and work. However, they exhibit critical vulnerabilities when processing malicious URLs: accepting a disguised malicious URL enables subsequent access to unsafe webpages, which can cause severe damage to service providers and users. Despite this risk, no benchmark currently targets this emerging threat. To address this gap, we propose MalURLBench, the first benchmark for evaluating LLMs' vulnerabilities to malicious URLs. MalURLBench contains 61,845 attack instances spanning 10 real-world scenarios and 7 categories of real malicious websites. Experiments with 12 popular LLMs reveal that existing models struggle to detect elaborately disguised malicious URLs. We further identify and analyze key factors that impact attack success rates and propose URLGuard, a lightweight defense module. We believe this work will provide a foundational resource for advancing the security of web agents. Our code is available at https://github.com/JiangYingEr/MalURLBench."
  },
  {
    "date": "2026-01-26",
    "title": "Quasiregular maps of Sierpinski carpet Julia sets",
    "authors": "Sergei Merenkov, Letian Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18109v1",
    "source": "arXiv",
    "abstract": "We prove that if $f$ and $g$ are postcritically finite rational maps whose Julia sets $\\mathcal{J}(f), \\mathcal{J}(g)$, respectively, are Sierpiński carpets, and if $ξ$ is a quasiregular map of the Riemann sphere $\\widehat{\\mathbb{C}}$ with $ξ^{-1}(\\mathcal{J}(g))=\\mathcal{J}(f)$, then $ξ$ is the restriction of a rational map to the Julia set $\\mathcal{J}(f)$. Moreover, when $g=f$ we prove that, for some positive integers $k$ and $l$, $f^k\\circ ξ^l=f^{2k}$. These conclusions extend the main results of M. Bonk, M. Lyubich, S. Merenkov, Quasisymmetries of Sierpiński carpet Julia sets, Adv. Math, 301 (2016), 383-422. Finally, we demonstrate that when Julia sets of postcritically finite rational maps are not Sierpiński carpets, say they are tree-like or gaskets, the above conclusions no longer hold."
  },
  {
    "date": "2026-01-26",
    "title": "Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions",
    "authors": "Pedram Agand, Mo Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18107v1",
    "source": "arXiv",
    "abstract": "Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets."
  },
  {
    "date": "2026-01-26",
    "title": "Mitigating the OWASP Top 10 For Large Language Models Applications using Intelligent Agents",
    "authors": "Mohammad Fasha, Faisal Abul Rub, Nasim Matar, Bilal Sowan, Mohammad Al Khaldy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18105v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have emerged as a transformative and disruptive technology, enabling a wide range of applications in natural language processing, machine translation, and beyond. However, this widespread integration of LLMs also raised several security concerns highlighted by the Open Web Application Security Project (OWASP), which has identified the top 10 security vulnerabilities inherent in LLM applications. Addressing these vulnerabilities is crucial, given the increasing reliance on LLMs and the potential threats to data integrity, confidentiality, and service availability. This paper presents a framework designed to mitigate the security risks outlined in the OWASP Top 10. Our proposed model leverages LLM-enabled intelligent agents, offering a new approach to proactively identify, assess, and counteract security threats in real-time. The proposed framework serves as an initial blueprint for future research and development, aiming to enhance the security measures of LLMs and protect against emerging threats in this rapidly evolving landscape."
  },
  {
    "date": "2026-01-26",
    "title": "Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs",
    "authors": "Akbar Saadat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18099v1",
    "source": "arXiv",
    "abstract": "Following the earlier verification for Gaussian model in \\cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\\%$, obtained by applying the extracted defocus filters to less blurred images."
  },
  {
    "date": "2026-01-26",
    "title": "LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts",
    "authors": "Venmugil Elango, Nidhi Bhatia, Roger Waleffe, Rasoul Shafipour, Tomer Asida, Abhinav Khattar, Nave Assaf, Maximilian Golub, Joey Guman, Tiyasa Mitra, Ritchie Zhao, Ritika Borkar, Ran Zilberstein, Mostofa Patwary, Mohammad Shoeybi, Bita Rouhani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18089v1",
    "source": "arXiv",
    "abstract": "Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856)."
  },
  {
    "date": "2026-01-26",
    "title": "\"Crash Test Dummies\" for AI-Enabled Clinical Assessment: Validating Virtual Patient Scenarios with Virtual Learners",
    "authors": "Brian Gin, Ahreum Lim, Flávia Silva e Oliveira, Kuan Xing, Xiaomei Song, Gayana Amiyangoda, Thilanka Seneviratne, Alison F. Doubleday, Ananya Gangopadhyaya, Bob Kiser, Lukas Shum-Tim, Dhruva Patel, Kosala Marambe, Lauren Maggio, Ara Tekian, Yoon Soo Park",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18085v1",
    "source": "arXiv",
    "abstract": "Background: In medical and health professions education (HPE), AI is increasingly used to assess clinical competencies, including via virtual standardized patients. However, most evaluations rely on AI-human interrater reliability and lack a measurement framework for how cases, learners, and raters jointly shape scores. This leaves robustness uncertain and can expose learners to misguidance from unvalidated systems. We address this by using AI \"simulated learners\" to stress-test and psychometrically characterize assessment pipelines before human use. Objective: Develop an open-source AI virtual patient platform and measurement model for robust competency evaluation across cases and rating conditions. Methods: We built a platform with virtual patients, virtual learners with tunable ACGME-aligned competency profiles, and multiple independent AI raters scoring encounters with structured Key-Features items. Transcripts were analyzed with a Bayesian HRM-SDT model that treats ratings as decisions under uncertainty and separates learner ability, case performance, and rater behavior; parameters were estimated with MCMC. Results: The model recovered simulated learners' competencies, with significant correlations to the generating competencies across all ACGME domains despite a non-deterministic pipeline. It estimated case difficulty by competency and showed stable rater detection (sensitivity) and criteria (severity/leniency thresholds) across AI raters using identical models/prompts but different seeds. We also propose a staged \"safety blueprint\" for deploying AI tools with learners, tied to entrustment-based validation milestones. Conclusions: Combining a purpose-built virtual patient platform with a principled psychometric model enables robust, interpretable, generalizable competency estimates and supports validation of AI-assisted assessment prior to use with human learners."
  },
  {
    "date": "2026-01-26",
    "title": "Physics-Integrated Inference for Signal Recovery in Non-Gaussian Regimes",
    "authors": "Mohamed A. Mousa, Leif Bauer, Ziyi Yang, Utkarsh Singh, Angshuman Deka, Zubin Jacob",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18074v1",
    "source": "arXiv",
    "abstract": "High-performance room-temperature sensing is often limited by non-stationary $1/f$ fluctuations and non-Gaussian stochasticity. In spintronic devices, thermally activated Néel switching creates heavy-tailed noise that masks weak signals, defeating linear filters optimized for Gaussian statistics. Here, we introduce a physics-integrated inference framework that decouples signal morphology from stochastic transients using a hierarchical 1D CNN-GRU topology. By learning the temporal signatures of Néel relaxation, this architecture reduces the Noise Equivalent Differential Temperature (NEDT) of spintronic Poisson bolometers by a factor of six (233.78 mK to 40.44 mK), effectively elevating room-temperature sensitivity toward cryogenic limits. We demonstrate the framework's universality across the electromagnetic and biological spectrum, achieving a 9-fold error suppression in Radar tracking, a 40\\% uncertainty reduction in LiDAR, and a 15.56 dB SNR enhancement in ECG. This hardware-inference coupling recovers deterministic signals from fluctuation-dominated regimes, enabling near-ideal detection limits in noisy edge environments."
  },
  {
    "date": "2026-01-26",
    "title": "Remarks about Connection and Dirac matrices",
    "authors": "Oliver Knill",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18071v1",
    "source": "arXiv",
    "abstract": "The connection Laplacian L and the Dirac matrix D are both n x n matrices defined from a given finite simplicial complex G with n sets. In both cases, there is interlacing of the eigenvalues for subcomplexes. This gives general upper bounds of the eigenvalues both for L and D in terms of inclusion or intersection degrees. We conjecture that L always dominates both D and the inverse of L in a weak Loewner sense. In a second part we look at dynamical systems (G,T), where T is a simplicial map on G. Both L and D generalize to dynamical versions of L and D. The modified L is still unimodular with an explicit Green function inverse and modified Dirac part still comes from an exterior derivative d. We also review the Lefschetz fixed point theorem for a simplicial map T on a simplicial complex G which implies the Brouwer fixed point theorem: any simplicial map on a contractible finite abstract simplicial complex G has a fixed simplex."
  },
  {
    "date": "2026-01-26",
    "title": "CIM-Tuner: Balancing the Compute and Storage Capacity of SRAM-CIM Accelerator via Hardware-mapping Co-exploration",
    "authors": "Jinwu Chen, Yuhui Shi, He Wang, Zhe Jiang, Jun Yang, Xin Si, Zhenhua Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18070v1",
    "source": "arXiv",
    "abstract": "As an emerging type of AI computing accelerator, SRAM Computing-In-Memory (CIM) accelerators feature high energy efficiency and throughput. However, various CIM designs and under-explored mapping strategies impede the full exploration of compute and storage balancing in SRAM-CIM accelerator, potentially leading to significant performance degradation. To address this issue, we propose CIM-Tuner, an automatic tool for hardware balancing and optimal mapping strategy under area constraint via hardware-mapping co-exploration. It ensures universality across various CIM designs through a matrix abstraction of CIM macros and a generalized accelerator template. For efficient mapping with different hardware configurations, it employs fine-grained two-level strategies comprising accelerator-level scheduling and macro-level tiling. Compared to prior CIM mapping, CIM-Tuner's extended strategy space achieves 1.58$\\times$ higher energy efficiency and 2.11$\\times$ higher throughput. Applied to SOTA CIM accelerators with identical area budget, CIM-Tuner also delivers comparable improvements. The simulation accuracy is silicon-verified and CIM-Tuner tool is open-sourced at https://github.com/champloo2878/CIM-Tuner.git."
  },
  {
    "date": "2026-01-26",
    "title": "Design of a Miniature Kibble Balance for Kilogram-Scale Mass Calibration -- KBmini",
    "authors": "Shisong Li, Nanjia Li, Weibo Liu, Elsayed E. E. Qupasie, Wei Zhao, Songling Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18054v1",
    "source": "arXiv",
    "abstract": "Tabletop version Kibble balances are a significant developing trend for mass realizations following the revised International System of Units. A key innovation through the miniaturization of the Kibble balance from a large-scale instrument into a tabletop device is making the quantum-based realization of mass accessible to a wider range of calibration laboratories and industries. This paper presents a tabletop Kibble balance design at Tsinghua University targeting E2-accuracy class mass calibrations from 1 g to 1 kg. For calibrating a mass of 1 kg, for instance, the required relative standard measurement uncertainty must be below 0.27 ppm to meet E2-accuracy class. Major components and features of the proposed system are discussed. A novel method of multi-harmonic excitation is proposed to improve the coil-motion linearity during velocity measurement. We show that injecting odd-order harmonics into the motion-driving current can significantly improve the uniformity of the coil's moving velocity, while the second-order component can address the asymmetry between upward and downward movements. This achieves a flat velocity $Δv/v< 5\\%$ over 60% of the motion cycle."
  },
  {
    "date": "2026-01-26",
    "title": "BASTION: A Bayesian Framework for Trend and Seasonality Decomposition",
    "authors": "Jason B. Cho, David S. Matteson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18052v1",
    "source": "arXiv",
    "abstract": "We introduce BASTION (Bayesian Adaptive Seasonality and Trend DecompositION), a flexible Bayesian framework for decomposing time series into trend and multiple seasonality components. We cast the decomposition as a penalized nonparametric regression and establish formal conditions under which the trend and seasonal components are uniquely identifiable, an issue only treated informally in the existing literature. BASTION offers three key advantages over existing decomposition methods: (1) accurate estimation of trend and seasonality amidst abrupt changes, (2) enhanced robustness against outliers and time-varying volatility, and (3) robust uncertainty quantification. We evaluate BASTION against established methods, including TBATS, STR, and MSTL, using both simulated and real-world datasets. By effectively capturing complex dynamics while accounting for irregular components such as outliers and heteroskedasticity, BASTION delivers a more nuanced and interpretable decomposition. To support further research and practical applications, BASTION is available as an R package at https://github.com/Jasoncho0914/BASTION"
  },
  {
    "date": "2026-01-26",
    "title": "MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts",
    "authors": "Etienne Lanzeray, Stephane Meilliez, Malo Ruelle, Damien Sileo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18790v1",
    "source": "arXiv",
    "abstract": "Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a \"tunnel vision\" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment."
  },
  {
    "date": "2026-01-26",
    "title": "PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation",
    "authors": "Abhishek Divekar, Anirban Majumder",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18777v1",
    "source": "arXiv",
    "abstract": "Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings."
  },
  {
    "date": "2026-01-26",
    "title": "The Blown Lead Paradox: Conditional Laws for the Running Maximum of Binary Doob Martingales",
    "authors": "Jonathan Pipping-Gamón, Abraham J. Wyner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18774v1",
    "source": "arXiv",
    "abstract": "Live win-probability forecasts are now ubiquitous in sports broadcasts, and retrospective commentary often cites the largest win probability attained by a team that ultimately loses as evidence of a \"collapse.\" Interpreting such extrema requires a reference distribution under correct specification. Modeling the forecast sequence as the Doob martingale of conditional win probabilities for a binary terminal outcome, we derive sharp distributional laws for its path maximum, including the conditional law given an eventual loss. In discrete time, we quantify explicit correction terms (last-step crossings and overshoots); under continuous-path regularity these corrections disappear, yielding exact identities. We further obtain closed-form distributions for two extensions: the maximal win probability attained by the eventual loser in a two-player game and the minimal win probability attained by the eventual winner in an n-player game. The resulting formulas furnish practical benchmarks for diagnosing sequential forecast calibration."
  },
  {
    "date": "2026-01-26",
    "title": "Hamiltonian Decoded Quantum Interferometry for General Pauli Hamiltonians",
    "authors": "Kaifeng Bu, Weichen Gu, Xiang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18773v1",
    "source": "arXiv",
    "abstract": "In this work, we study the Hamiltonian Decoded Quantum Interferometry (HDQI) for the general Hamiltonians $H=\\sum_ic_iP_i$ on an $n$-qubit system, where the coefficients $c_i\\in \\mathbb{R}$ and $P_i$ are Pauli operators. We show that, given access to an appropriate decoding oracle, there exist efficient quantum algorithms for preparing the state $ρ_{\\mathcal P}(H) = \\frac{\\mathcal P^2(H)}{\\text{Tr}[\\mathcal P^2(H)]}$, where $\\mathcal P(H)$ denotes the matrix function induced by a univariate polynomial $\\mathcal P(x)$. Such states can be used to approximate the Gibbs states of $H$ for suitable choices of polynomials. We further demonstrate that the proposed algorithms are robust to imperfections in the decoding procedure. Our results substantially extend the scope of HDQI beyond stabilizer-like Hamiltonians, providing a method for Gibbs-state preparation and Hamiltonian optimization in a broad class of physically and computationally relevant quantum systems."
  },
  {
    "date": "2026-01-26",
    "title": "The Role of Intrinsic Temperature and Vertical Mixing in Characterizing Sub-Neptune Atmospheres",
    "authors": "Neha Dushyantha Kumar, Jessica E. Libby-Roberts, Caleb I. Canas, Nicholas F. Wogan, Suvrath Mahadevan, Sagnick Mukherjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18769v1",
    "source": "arXiv",
    "abstract": "Sub-Neptune planets are often modeled with a dense rocky or metal-rich interior beneath a thick hydrogen/helium (H/He) atmosphere; though their bulk densities could also be explained by a water-rich interior with a thin H/He atmosphere. Atmospheric composition provides a key mechanism to break this degeneracy between competing interior models. However, the overall composition of sub-Neptunes inferred from spectra obtained with the James Webb Space Telescope, remains debated in part due to differences in modeling assumptions. While previous studies explored parameter spaces such as stellar spectra, atmospheric metallicities, and carbon-to-oxygen ratios, they often assumed fixed intrinsic temperatures (Tint) and vertical eddy diffusion coefficients (Kzz) - two critical, yet poorly constrained, drivers of atmospheric chemistry. To address this, we present a self-consistent grid of models that covers the full plausible range of Tint (60 - 450 K) and Kzz (10^{5} - 10^{12} cm^2/s) using the open-source PICASO and VULCAN packages to better characterize sub-Neptune atmospheres. Focusing on K2-18b analogs, we demonstrate that Tint and Kzz significantly impact CH4, CO2, CO, NH3 and HCN abundances, with H2O being largely unaffected. Our work demonstrates that comprehensive parameter space exploration of thermal and mixing parameters is essential for accurate interpretation of sub-Neptune spectra, and that single-parameter assumptions can lead to misclassification of planetary interiors. We provide a diagnostic framework using multi-molecule observations to distinguish between competing atmospheric models and advance robust characterization of sub-Neptunes."
  },
  {
    "date": "2026-01-26",
    "title": "Anticipation in Action: Evaluating Stimulus-Preceding Negativity as an Implicit Trigger for Adaptive Mixed Reality",
    "authors": "Francesco Chiossi, Elnur Imamaliyev, Martin Bleichner, Sven Mayer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18750v1",
    "source": "arXiv",
    "abstract": "Mixed Reality (MR) interfaces increasingly rely on gaze for interaction , yet distinguishing visual attention from intentional action remains difficult, leading to the Midas Touch problem. Existing solutions require explicit confirmations, while brain-computer interfaces may provide an implicit marker of intention using Stimulus-Preceding Negativity (SPN). We investigated how Intention (Select vs. Observe) and Feedback (With vs. Without) modulate SPN during gaze-based MR interactions. During realistic selection tasks, we acquired EEG and eye-tracking data from 28 participants. SPN was robustly elicited and sensitive to both factors: observation without feedback produced the strongest amplitudes, while intention to select and expectation of feedback reduced activity, suggesting SPN reflects anticipatory uncertainty rather than motor preparation. Complementary decoding with deep learning models achieved reliable person-dependent classification of user intention, with accuracies ranging from 75% to 97% across participants. These findings identify SPN as an implicit marker for building intention-aware MR interfaces that mitigate the Midas Touch."
  },
  {
    "date": "2026-01-26",
    "title": "Let's Make Every Pull Request Meaningful: An Empirical Analysis of Developer and Agentic Pull Requests",
    "authors": "Haruhiko Yoshioka, Takahiro Monno, Haruka Tokumasu, Taiki Wakamatsu, Yuki Ota, Nimmi Weeraddana, Kenichi Matsumoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18749v1",
    "source": "arXiv",
    "abstract": "The automatic generation of pull requests (PRs) using AI agents has become increasingly common. Although AI-generated PRs are fast and easy to create, their merge rates have been reported to be lower than those created by humans. In this study, we conduct a large-scale empirical analysis of 40,214 PRs collected from the AIDev dataset. We extract 64 features across six families and fit statistical regression models to compare PR merge outcomes for human and agentic PRs, as well as across three AI agents. Our results show that submitter attributes dominate merge outcomes for both groups, while review-related features exhibit contrasting effects between human and agentic PRs. The findings of this study provide insights into improving PR quality through human-AI collaboration."
  },
  {
    "date": "2026-01-26",
    "title": "Symmetric Proofs of Parameterized Programs",
    "authors": "Ruotong Cheng, Azadeh Farzan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18745v1",
    "source": "arXiv",
    "abstract": "We investigate the problem of safety verification of infinite-state parameterized programs that are formed based on a rich class of topologies. We introduce a new proof system, called parametric proof spaces, which exploits the underlying symmetry in such programs. This is a local notion of symmetry which enables the proof system to reuse proof arguments for isomorphic neighbourhoods in program topologies. We prove a sophisticated relative completeness result for the proof system with respect to a class of universally quantified invariants. We also investigate the problem of algorithmic construction of these proofs. We present a construction, inspired by classic results in model theory, where an infinitary limit program can be soundly and completely verified in place of the parameterized family, under some conditions. Furthermore, we demonstrate how these proofs can be constructed and checked against these programs without the need for axiomatization of the underlying topology for proofs or the programs. Finally, we present conditions under which our algorithm becomes a decision procedure."
  },
  {
    "date": "2026-01-26",
    "title": "SNC Kähler-Einstein metrics and RCD spaces",
    "authors": "Martin de Borbon, Cristiano Spotti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18741v1",
    "source": "arXiv",
    "abstract": "We show that Kähler-Einstein metrics with cone singularities along simple normal crossing (SNC) divisors define RCD spaces, both in the compact setting and in certain non-compact cases, thereby producing many examples of Einstein RCD spaces. In particular, we show the existence of smooth non-compact $4$-manifolds carrying ALE Ricci-flat RCD$(0,4)$ metrics with any space form $S^3/Γ$ as the link of the tangent cone at infinity, answering a question raised by D. Semola. Our proofs rely on the characterization of RCD spaces in the almost-smooth setting due to S. Honda and Honda-Sun."
  },
  {
    "date": "2026-01-26",
    "title": "Benchmarking Machine Learning Models for IoT Malware Detection under Data Scarcity and Drift",
    "authors": "Jake Lyon, Ehsan Saeedizade, Shamik Sengupta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18736v1",
    "source": "arXiv",
    "abstract": "The rapid expansion of the Internet of Things (IoT) in domains such as smart cities, transportation, and industrial systems has heightened the urgency of addressing their security vulnerabilities. IoT devices often operate under limited computational resources, lack robust physical safeguards, and are deployed in heterogeneous and dynamic networks, making them prime targets for cyberattacks and malware applications. Machine learning (ML) offers a promising approach to automated malware detection and classification, but practical deployment requires models that are both effective and lightweight. The goal of this study is to investigate the effectiveness of four supervised learning models (Random Forest, LightGBM, Logistic Regression, and a Multi-Layer Perceptron) for malware detection and classification using the IoT-23 dataset. We evaluate model performance in both binary and multiclass classification tasks, assess sensitivity to training data volume, and analyze temporal robustness to simulate deployment in evolving threat landscapes. Our results show that tree-based models achieve high accuracy and generalization, even with limited training data, while performance deteriorates over time as malware diversity increases. These findings underscore the importance of adaptive, resource-efficient ML models for securing IoT systems in real-world environments."
  },
  {
    "date": "2026-01-26",
    "title": "Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models",
    "authors": "Siyan Zhao, Zhihui Xie, Mengchen Liu, Jing Huang, Guan Pang, Feiyu Chen, Aditya Grover",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18734v1",
    "source": "arXiv",
    "abstract": "Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods."
  },
  {
    "date": "2026-01-26",
    "title": "Optimal Use of Preferences in Artificial Intelligence Algorithms",
    "authors": "Joshua S. Gans",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18732v1",
    "source": "arXiv",
    "abstract": "Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectives, the welfare results here apply uniformly across decision problems. The key primitive is a diminishing-value-of-information condition: relative to a fixed (normalised) preference-free loss, preference embedding makes informativeness less valuable at the margin, inducing a mean-preserving contraction of learned posteriors. Because the value of information is convex in beliefs, preference-free training weakly dominates for any expected utility decision problem. This provides theoretical foundations for modular AI pipelines that learn calibrated probabilities and implement asymmetric costs through downstream decision rules. However, separation requires users to implement optimal decision rules. When cognitive constraints bind, as documented in human AI decision-making, preference embedding can dominate by automating threshold computation. These results provide design guidance: preserve optionality through post-processing when objectives may shift; embed preferences when decision-stage frictions dominate."
  },
  {
    "date": "2026-01-26",
    "title": "Liquid crystals and topological vorticity: smoothness of mild solutions",
    "authors": "Fanghua Lin, Yannick Sire, Yantao Wu, Yifu Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18726v1",
    "source": "arXiv",
    "abstract": "We introduce several new models whose common feature is to take into account effects from topological vorticity. The macroscopic unknown is driven by a dissipative anomalous diffusion (of SQG-type) and is coupled with the orientation of the crystal, moving by the gradient flow of the energy of maps. The main idea of such models is to have a better insight on the vorticity formulation of the Liquid Crystal Flow and to tackle some regularity issues in the associated conserved geometric motions. One of the advantage of the present PDEs is to capture features of the Navier-Stokes equations (or Euler) through a {\\sl scalar} unknown, keeping the advection-diffusion structure of the orientation field. We obtain regularity for mild solutions under natural assumptions for the initial data, which are actually near-optimal. Along the way, we also draw some links with natural models of (anti-)ferromagnets previously investigated."
  },
  {
    "date": "2026-01-26",
    "title": "Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules",
    "authors": "Naeyma N. Islam, Thomas R. Caulfield",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18716v1",
    "source": "arXiv",
    "abstract": "Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases."
  },
  {
    "date": "2026-01-26",
    "title": "Point transformer for protein structural heterogeneity analysis using CryoEM",
    "authors": "Muyuan Chen, Muchen Li, Renjie Liao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18713v1",
    "source": "arXiv",
    "abstract": "Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics. Here, by implementing Point Transformer, a self-attention network designed for point cloud analysis, we are able to improve the performance of heterogeneity analysis on CryoEM data, and characterize the dynamics of highly complex protein systems in a more human-interpretable way."
  },
  {
    "date": "2026-01-26",
    "title": "Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs",
    "authors": "Zhichao Yang, Sepehr Janghorbani, Dongxu Zhang, Jun Han, Qian Qian, Andrew Ressler, Gregory D. Lyng, Sanjit Singh Batra, Robert E. Tillman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18706v1",
    "source": "arXiv",
    "abstract": "Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable."
  },
  {
    "date": "2026-01-26",
    "title": "From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic",
    "authors": "Hansheng Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18702v1",
    "source": "arXiv",
    "abstract": "Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the \"hallucinations\" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI."
  },
  {
    "date": "2026-01-26",
    "title": "On the Distance Distribution of Reed-Muller Codes",
    "authors": "Neil Kolekar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18691v1",
    "source": "arXiv",
    "abstract": "In this paper, we give error bounds for the distance distribution of Reed-Muller codes, extending prior work on the distance distribution of Reed-Solomon codes. This is equivalent to the problem of counting multivariate polynomials over a finite field with prescribed degree, coefficients, and number of zeroes. We provide a solution to this problem using the character sum method, which offers a new unified framework applicable to a broad class of polynomial enumeration problems over finite fields that involve prescribed evaluation vectors. This work effectively makes the first systematic attempt to study the coset weight distribution problem for Reed-Muller codes of fixed degree over large finite fields, which was proposed in MacWilliams and Sloane's 1977 textbook \\emph{The Theory of Error Correcting Codes}."
  },
  {
    "date": "2026-01-26",
    "title": "ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule",
    "authors": "Yilie Huang, Wenpin Tang, Xunyu Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18681v1",
    "source": "arXiv",
    "abstract": "We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fréchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining."
  },
  {
    "date": "2026-01-26",
    "title": "New parameters for star cluster dynamics: observational results",
    "authors": "Barbara Lanzoni, Francesco R. Ferraro, Enrico Vesperini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18679v1",
    "source": "arXiv",
    "abstract": "We recently used a large set of Monte Carlo simulations of globular clusters (GCs) to define new fully empirical parameters (named A5, P5, and S2.5) able to trace the internal dynamical evolution of dense stellar systems. These parameters are specifically designed to quantify the steepness of the cumulative radial distribution of stars in the innermost region of the host system, which tends to progressively increase with dynamical aging due to core contraction. Following the original definitions, here we measure A5 and P5 in a sample of 40 Galactic GCs homogeneously surveyed through HST photometric observations. In agreement with the predictions of our simulations, the largest values of A5 and P5 are found for the most dynamically evolved GCs, i.e., those previously classified as post-core collapse systems based on the shape of their density profile, and those characterized by the shortest central relaxation times. Moreover, the new dynamical parameters here measured strongly correlate with A+rh, another fully empirical, independent parameter that traces the dynamical age of star clusters through the level of central segregation of blue straggler stars."
  },
  {
    "date": "2026-01-26",
    "title": "Counterfactual Explanations on Robust Perceptual Geodesics",
    "authors": "Eslam Zaher, Maciej Trzaskowski, Quan Nguyen, Fred Roosta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18678v1",
    "source": "arXiv",
    "abstract": "Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics."
  },
  {
    "date": "2026-01-26",
    "title": "Quasi Monte Carlo methods enable extremely low-dimensional deep generative models",
    "authors": "Miles Martinez, Alex H. Williams",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18676v1",
    "source": "arXiv",
    "abstract": "This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis."
  },
  {
    "date": "2026-01-26",
    "title": "Non-Markovian non-equilibrium modeling of experimental cell-motion trajectories reveals dependence of propulsion-force correlations on solvent viscosity",
    "authors": "Anton Klimek, Prince V. Baruah, Prerna Sharma, Roland R. Netz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18669v1",
    "source": "arXiv",
    "abstract": "Cell motility underlies many biological processes, including cancer metastasis, bacterial infection, and evolutionary adaptation. We introduce a non-equilibrium single-cell motility model inspired by the generalized Langevin equation, which accounts for hydrodynamic friction and correlated propulsion force. From video microscopy of Chlamydomonas reinhardtii algae and Salmonella typhimurium bacteria we extract the propulsion-force dynamics on the single-cell level, which we find to exhibit multi-exponential correlations, not captured by literature non-equilibrium cell-motility models. Based on our data-driven model, we predict the effective cell diffusivities beyond experimentally resolved timescales and demonstrate a diffusivity maximum at intermediate solvent viscosity for both cell types. This means that cells adapt their propulsion-force characteristics according to the solvent viscosity. In addition, our model predicts the power output of single cells, which is on the order of aW for the salmonella and fW for the algae."
  },
  {
    "date": "2026-01-26",
    "title": "The phase structure of QCD: Fluctuations and Correlations",
    "authors": "Peter Braun-Munzinger, Anar Rustamov, Nu Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18666v1",
    "source": "arXiv",
    "abstract": "The strong interaction - governed by Quantum Chromodynamics (QCD) - shapes the structure of the visible universe. At about 10 $μ$s after the big bang, the primordial matter made up of quarks and gluons plus leptons, photons and neutrinos, the quark-gluon plasma (QGP), became cool enough to create, in a phase transition, the protons and neutrons of ordinary matter, along with other strongly interacting unstable hadrons. This phase transition was predicted within the framework of QCD and has been studied in accelerator laboratories world-wide since about 40 years. This review will explore recent breakthroughs in the study of the QCD phase diagram. We will highlight measurements of particle production and fluctuations, and compare them to theoretical predictions. We summarize our current understanding of the QCD structure and outline future experimental opportunities with high energy nuclear collisions at fixed-target and collider facilities world-wide."
  },
  {
    "date": "2026-01-26",
    "title": "S$^2$GR: Stepwise Semantic-Guided Reasoning in Latent Space for Generative Recommendation",
    "authors": "Zihao Guo, Jian Wang, Ruxin Zhou, Youhua Liu, Jiawei Guo, Jun Zhao, Xiaoxiao Xu, Yongqi Liu, Kaiqiao Zhan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18664v1",
    "source": "arXiv",
    "abstract": "Generative Recommendation (GR) has emerged as a transformative paradigm with its end-to-end generation advantages. However, existing GR methods primarily focus on direct Semantic ID (SID) generation from interaction sequences, failing to activate deeper reasoning capabilities analogous to those in large language models and thus limiting performance potential. We identify two critical limitations in current reasoning-enhanced GR approaches: (1) Strict sequential separation between reasoning and generation steps creates imbalanced computational focus across hierarchical SID codes, degrading quality for SID codes; (2) Generated reasoning vectors lack interpretable semantics, while reasoning paths suffer from unverifiable supervision. In this paper, we propose stepwise semantic-guided reasoning in latent space (S$^2$GR), a novel reasoning enhanced GR framework. First, we establish a robust semantic foundation via codebook optimization, integrating item co-occurrence relationship to capture behavioral patterns, and load balancing and uniformity objectives that maximize codebook utilization while reinforcing coarse-to-fine semantic hierarchies. Our core innovation introduces the stepwise reasoning mechanism inserting thinking tokens before each SID generation step, where each token explicitly represents coarse-grained semantics supervised via contrastive learning against ground-truth codebook cluster distributions ensuring physically grounded reasoning paths and balanced computational focus across all SID codes. Extensive experiments demonstrate the superiority of S$^2$GR, and online A/B test confirms efficacy on large-scale industrial short video platform."
  },
  {
    "date": "2026-01-26",
    "title": "Balancing Privacy and Robustness in Coded Computing Under Profiled Workers",
    "authors": "Rimpi Borah, J. Harshan, Aaditya Sharma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18661v1",
    "source": "arXiv",
    "abstract": "In distributed computing with untrusted workers, the assignment of evaluation indices plays a critical role in determining both privacy and robustness. In this work, we study how the placement of unreliable workers within the Numerically Stable Lagrange Coded Computing (NS-LCC) framework influences privacy and the ability to localize Byzantine errors. We derive analytical bounds that quantify how different evaluation-index assignments affect privacy against colluding curious workers and robustness against Byzantine corruption under finite-precision arithmetic. Using these bounds, we formulate optimization problems that identify privacy-optimal and robustness-optimal index placements and show that the resulting assignments are fundamentally different. This exposes that index choices that maximizes privacy degrade error-localization, and vice versa. To jointly navigate this trade-off, we propose a low-complexity greedy assignment strategy that closely approximates the optimal balance between privacy and robustness."
  },
  {
    "date": "2026-01-26",
    "title": "When Is Self-Disclosure Optimal? Incentives and Governance of AI-Generated Content",
    "authors": "Juan Wu, Zhe, Zhang, Amit Mehra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18654v1",
    "source": "arXiv",
    "abstract": "Generative artificial intelligence (Gen-AI) is reshaping content creation on digital platforms by reducing production costs and enabling scalable output of varying quality. In response, platforms have begun adopting disclosure policies that require creators to label AI-generated content, often supported by imperfect detection and penalties for non-compliance. This paper develops a formal model to study the economic implications of such disclosure regimes. We compare a non-disclosure benchmark, in which the platform alone detects AI usage, with a mandatory self-disclosure regime in which creators strategically choose whether to disclose or conceal AI use under imperfect enforcement. The model incorporates heterogeneous creators, viewer discounting of AI-labeled content, trust penalties following detected non-disclosure, and endogenous enforcement. The analysis shows that disclosure is optimal only when both the value of AI-generated content and its cost-saving advantage are intermediate. As AI capability improves, the platform's optimal enforcement strategy evolves from strict deterrence to partial screening and eventual deregulation. While disclosure reliably increases transparency, it reduces aggregate creator surplus and can suppress high-quality AI content when AI is technologically advanced. Overall, the results characterize disclosure as a strategic governance instrument whose effectiveness depends on technological maturity and trust frictions."
  },
  {
    "date": "2026-01-26",
    "title": "Hamiltonian Analysis of Doubled 4d Chern-Simons",
    "authors": "Jake Stedman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18647v1",
    "source": "arXiv",
    "abstract": "Motivated by a conjecture that doubled four-dimensional Chern-Simons produces new integrable models, we perform its Hamiltonian analysis and find the theory's Poisson algebra. This requires carefully accounting for a set of boundary conditions that identify two gauge fields. Two methods for doing so are given, one of which is based on edge-modes and the other on a recharacterisation of the boundary conditions as constraints. We find that the Poisson algebra is that of an affine Gaudin model subject to a constraint, generalising the Goddard-Kent-Olive construction (from conformal field theory) to the world of integrable models. We also conjecture the existence of extended quantum groups and a generalisation of the affine Harish-Chandra Isomorphism."
  },
  {
    "date": "2026-01-26",
    "title": "Physics-Informed Uncertainty Enables Reliable AI-driven Design",
    "authors": "Tingkai Xue, Chin Chun Ooi, Yang Jiang, Luu Trung Pham Duong, Pao-Hsiung Chiu, Weijiang Zhao, Nagarajan Raghavan, My Ha Dao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18638v1",
    "source": "arXiv",
    "abstract": "Inverse design is a central goal in much of science and engineering, including frequency-selective surfaces (FSS) that are critical to microelectronics for telecommunications and optical metamaterials. Traditional surrogate-assisted optimization methods using deep learning can accelerate the design process but do not usually incorporate uncertainty quantification, leading to poorer optimization performance due to erroneous predictions in data-sparse regions. Here, we introduce and validate a fundamentally different paradigm of Physics-Informed Uncertainty, where the degree to which a model's prediction violates fundamental physical laws serves as a computationally-cheap and effective proxy for predictive uncertainty. By integrating physics-informed uncertainty into a multi-fidelity uncertainty-aware optimization workflow to design complex frequency-selective surfaces within the 20 - 30 GHz range, we increase the success rate of finding performant solutions from less than 10% to over 50%, while simultaneously reducing computational cost by an order of magnitude compared to the sole use of a high-fidelity solver. These results highlight the necessity of incorporating uncertainty quantification in machine-learning-driven inverse design for high-dimensional problems, and establish physics-informed uncertainty as a viable alternative to quantifying uncertainty in surrogate models for physical systems, thereby setting the stage for autonomous scientific discovery systems that can efficiently and robustly explore and evaluate candidate designs."
  },
  {
    "date": "2026-01-26",
    "title": "Brazilian Social Media Anti-vaccine Information Disorder Dataset -- Telegram (2020-2025)",
    "authors": "João Phillipe Cardenuto, Ana Carolina Monari, Michelle Diniz Lopes, Leopoldo Lusquino Filho, Anderson Rocha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18622v1",
    "source": "arXiv",
    "abstract": "Over the past decade, Brazil has experienced a decline in vaccination coverage, reversing decades of public health progress achieved through the National Immunization Program (PNI). Growing evidence points to the widespread circulation of vaccine-related misinformation -- particularly on social media platforms -- as a key factor driving this decline. Among these platforms, Telegram remains the only major platform permitting accessible and ethical data collection, offering insight into public channels where vaccine misinformation circulates extensively. This data paper introduces a curated dataset of about four million Telegram posts collected from 119 prominent Brazilian anti-vaccine channels between 2020 and 2025. The dataset includes message content, metadata, associated media, and classification related to vaccine posts, enabling researchers to examine how false or misleading information spreads, evolves, and influences public sentiment. By providing this resource, our aim is to support the scientific and public health community in developing evidence-based strategies to counter misinformation, promote trust in vaccination, and engage compassionately with individuals and communities affected by false narratives. The dataset and documentation are openly available for non-commercial research, under strict ethical and privacy guidelines at https://doi.org/10.25824/redu/5JIVDT"
  },
  {
    "date": "2026-01-26",
    "title": "Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures",
    "authors": "Jorge Quesada, Ghassan AlRegib",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18619v1",
    "source": "arXiv",
    "abstract": "Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains."
  },
  {
    "date": "2026-01-26",
    "title": "Fractal functions defined in terms of number representations in systems with a redundant alphabet",
    "authors": "M. V. Pratsiovytyi, S. P. Ratushniak, Yu. Yu. Vovk, Ya. V. Goncharenko",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18610v1",
    "source": "arXiv",
    "abstract": "For fixed natural numbers $r$ and $s$, where $2\\leq s \\leq r$, we consider a representation of numbers from the interval $[0;\\frac{r}{s-1}]$ obtained by encoding numbers by means of the alphabet $A=\\{0,1,...,r\\}$ via the expansion $x=\\sum\\limits_{n=1}^{\\infty}s^{-n}α_n=Δ^{r_s}_{α_1α_2...α_n...}.$ The algorithm for expanding a number into such a series is justified in the paper. The geometry of this representation is studied, including the geometric meaning of digits, properties of cylinder sets -- particularly the specificity of their overlaps -- and metric relations, as well as the connection between the representation and partial sums of the corresponding series. The paper also presents results on the study of a function $f$ defined by $f(x=\\sum\\limits_{n=1}^{\\infty}\\frac{α_n}{(r+1)^n})=Δ^{r_s}_{α_1α_2...α_n...}, α_n\\in A.$ It is proved that the function $f$ is continuous at every point that has a unique representation in the classical numeration system with base $r+1$, and discontinuous at points having two representations. The function has unbounded variation and a self-affine graph. For $r<2s-1$, the function possesses singleton, finite, countable, and continuum level sets, including fractal ones; for $r>2s-2$, every level set is a continuum, and moreover it is fractal or anomalously fractal."
  },
  {
    "date": "2026-01-26",
    "title": "Disk-jet-wind coupling from stellar mass to supermassive black holes",
    "authors": "Chris Done",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18607v1",
    "source": "arXiv",
    "abstract": "Black holes are the simplest possible objects, characterised by only mass and spin. We see them via accretion, so there is one more fundamental parameter which is the mass accretion rate. Here I will review how the data from both stellar and supermassive black holes can be fit into a framework where there is a major spectral transition at $\\dot{m}=L/L_{\\rm Edd}\\sim 0.01$ where the optically thick disc is replaced by a hot flow. This dramatic spectral change also affects the expected properties of thermal and radiatively powered winds, matching the overall properties of winds seen in new XRISM data from the stellar mass binaries, though there can also be additional UV and dust driven winds in supermassive black holes. The radio data in stellar and supermassive black holes are clear that the hot flow (not the disc) connects to the radio jet, and the radio-X-ray 'fundamental plane' can be qualitatively understood if the radio quiet AGN and stellar mass black holes have low to moderate spins, with the jet power set as a constant fraction of the accretion power. A small fraction of AGN (radio loud) instead have much higher (factor $100-1000\\times$) radio-to-X-ray ratio at the same black hole mass and mass accretion rates. I speculate that these have higher jet power due to high black hole spin. I review the multiple issues still remaining in this picture, most of which are connected to the geometry and nature of the X-ray corona, and the conflicting constraints on this which come from reflection spectroscopy and polarimetry."
  },
  {
    "date": "2026-01-26",
    "title": "Role of transfer films and interfacial cracking in metallic sliding wear",
    "authors": "R. Xu, B. N. J. Persson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18603v1",
    "source": "arXiv",
    "abstract": "The origin of wear particles in metallic sliding contacts remains debated. Classical views based on cold-welded junctions suggest that plastic yielding of the real contact area should lead to large wear coefficients, in apparent contradiction with the small values typically measured for metals. Here we argue that this discrepancy can be resolved if most junctions do not directly produce wear particles, but instead cause metal transfer and the formation of a weakly bound transfer film. Wear then occurs intermittently when fragments of this film detach due to crack propagation at the interface between the transfer film and the underlying bulk metal. We perform unlubricated reciprocating sliding experiments on nominally smooth stainless steel, brass, and aluminum. For steel on steel, the wear mass loss shows an initial stage with negligible mass change up to a sliding distance of $\\sim 2.4 \\ {\\rm m}$, followed by a linear regime. Transfer-film formation in dissimilar-metal contacts is evidenced by optical imaging, net mass gain of the steel slider, and energy-dispersive X-ray spectroscopy, and the collected debris is flake-like. These observations support a transfer-film-controlled wear mechanism associated with cold-welded junctions."
  },
  {
    "date": "2026-01-26",
    "title": "Distinguishing Graphs by Counting Homomorphisms from Sparse Graphs",
    "authors": "Daniel Neuen, Tim Seppelt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18602v1",
    "source": "arXiv",
    "abstract": "Lovász (1967) showed that two graphs $G$ and $H$ are isomorphic if, and only if, they are homomorphism indistinguishable over all graphs, i.e., $G$ and $H$ admit the same number of number of homomorphisms from every graph $F$. Subsequently, a substantial line of work studied homomorphism indistinguishability over restricted graph classes. For example, homomorphism indistinguishability over minor-closed graph classes $\\mathcal{F}$ such as the class of planar graphs, the class of graphs of treewidth $\\leq k$, pathwidth $\\leq k$, or treedepth $\\leq k$, was shown to be equivalent to quantum isomorphism and equivalences with respect to counting logic fragments, respectively. Via such characterisations, the distinguishing power of e.g. logical or quantum graph isomorphism relaxations can be studied with graph-theoretic means. In this vein, Roberson (2022) conjectured that homomorphism indistinguishability over every graph class excluding some minor is not the same as isomorphism. We prove this conjecture for all vortex-free graph classes. In particular, homomorphism indistinguishability over graphs of bounded Euler genus is not the same as isomorphism. As a negative result, we show that Roberson's conjecture fails when generalised to graph classes excluding a topological minor. Furthermore, we show homomorphism distinguishing closedness for several graph classes including all topological-minor-closed and union-closed classes of forests, and show that homomorphism indistinguishability over graphs of genus $\\leq g$ (and other parameters) forms a strict hierarchy."
  },
  {
    "date": "2026-01-26",
    "title": "A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic",
    "authors": "Joseph Cotnareanu, Didier Chetelat, Yingxue Zhang, Mark Coates",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18595v1",
    "source": "arXiv",
    "abstract": "Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts."
  },
  {
    "date": "2026-01-26",
    "title": "The generalised balanced power diagram: flat sections, affine transformations and an improved rendering algorithm",
    "authors": "Felix Ballani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18593v1",
    "source": "arXiv",
    "abstract": "The generalised balanced power diagram (GBPD) is regarded in the literature as a suitable geometric model for describing polycrystalline microstructures with curved grain boundaries. This article compiles properties of GBPDs with regard to affine transformations and flat sections. Furthermore, it extends an algorithm known for power diagrams for generating digital images, which is more efficient than the usual brute force approach, on GBPDs."
  },
  {
    "date": "2026-01-26",
    "title": "Uncooled Poisson Bolometer for High-Speed Event-Based Long-wave Thermal Imaging",
    "authors": "Mohamed A. Mousa, Leif Bauer, Utkarsh Singh, Ziyi Yang, Angshuman Deka, Zubin Jacob",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18583v1",
    "source": "arXiv",
    "abstract": "Event-based vision provides high-speed, energy-efficient sensing for applications such as autonomous navigation and motion tracking. However, implementing this technology in the long-wave infrared remains a significant challenge. Traditional infrared sensors are hindered by slow thermal response times or the heavy power requirements of cryogenic cooling. Here, we introduce the first event-based infrared detector operating in a Poisson-counting regime. This is realized with a spintronic Poisson bolometer capable of broadband detection from 0.8-14$μ\\text{m}$. In this regime, infrared signals are detected through statistically resolvable changes in stochastic switching events. This approach enables room-temperature operation with high timing resolution. Our device achieves a maximum event rate of 1,250 Hz, surpassing the temporal resolution of conventional uncooled microbolometers by a factor of 4. Power consumption is kept low at 0.2$μ$W per pixel. This work establishes an operating principle for infrared sensing and demonstrates a pathway toward high-speed, energy-efficient, event-driven thermal imaging."
  },
  {
    "date": "2026-01-26",
    "title": "From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection",
    "authors": "Yuan Cao, Feixiang Liu, Xinyue Wang, Yihan Zhu, Hui Xu, Zheng Wang, Qiang Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18582v1",
    "source": "arXiv",
    "abstract": "Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks."
  },
  {
    "date": "2026-01-26",
    "title": "Formal Naive Dirac Operators and Graph Topology",
    "authors": "G. M. von Hippel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18576v1",
    "source": "arXiv",
    "abstract": "Motivated by a recent conjecture of Misumi and Yumoto relating the number of zero modes of lattice Dirac operators to the sum of the Betti numbers of the underlying spacetime manifold, we study formal Dirac operators on a class of graphs admitting such in terms of their zero modes. Our main result is that for graphs on which translations commute, the conjecture of Misumi and Yumoto can be shown and indeed can be strengthened to obtain bounds on the individual Betti numbers rather than merely on their sum. Interpretations of the zero modes in terms of graph quotients and of the representation theory of abelian groups are given, and connections with a homology theory for such graphs are highlighted."
  },
  {
    "date": "2026-01-26",
    "title": "Hierarchical self-organization of highly-ordered granular ensemble of optical solitons through collective motions",
    "authors": "Xiaocong Wang, Benhai Wang, Haochen Lin, Wenbin He, Yu Jiang, Qi Huang, Xintong Zhang, Long Zhang, Meng Pang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18574v1",
    "source": "arXiv",
    "abstract": "Self-organizations of ordered patterns in far-from-equilibrium many-body systems host fundamental importance in many disciplines. Meanwhile, complex systems often feature hierarchical structures with distinct scales for different layers, enabling high-level effective dynamics without exhaustive tracking of all possible degrees of freedoms. In this work, we report a study of the self-organization dynamics of highly-ordered soliton ensembles in a high-harmonic mode-locked fiber lasers through collective motions driven by nonlocal optomechanical interactions and local collisions, which exhibit a series of universal characteristics reminiscent of phase transitions. Moreover, the multi-soliton laser-field can be coarsely grained as a granular ensemble of limit-cycle oscillators with simple interaction rules derived from fine-scale physics. The self-organization of the multitude of solitons in the mode-locked laser cavity can then be mapped into a low-dimensional dynamic model that essentially reproduced the emergent process. Our work affords a conceptual framework for understanding the complex structure formation in nonlinear laser systems, and may help to design ultrafast lasers by exploiting universal principles of collective motions."
  },
  {
    "date": "2026-01-26",
    "title": "On the Abolition of the \"ICSE Paper\" and the Adoption of the \"Registered Proposal\" and the \"Results Report\"",
    "authors": "Fabio Massacci, Winnie Mbaka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18566v1",
    "source": "arXiv",
    "abstract": "To address the 'novelty-vicious cycle' and the 'replicability crisis' of the field (both discussed in the survey) we propose abolishing the \"ICSE paper\" as we know it and replacing it with a two-tier system that also evolves the existing notion of 'Registered Report'. Authors proposing a new idea, experiment, or analysis would submit a \"Registered Proposal\" of their idea and the proposed experimental methodology to undergo peer review. The following year, anyone can submit (shorter) \"Results Reports\" on the realization of the empirical work based on the registered proposals of the previous ICSE (or FSE or ISSTA or ASE etc.). Both works should be first class citizens of the mainstream events. We argue that such a disruptive (heretical?) idea is supported and based on the responses of the community of the Future of Software Engineering pre-survey"
  },
  {
    "date": "2026-01-26",
    "title": "An Unsupervised Tensor-Based Domain Alignment",
    "authors": "Chong Hyun Lee, Kibae Lee, Hyun Hee Yim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18564v1",
    "source": "arXiv",
    "abstract": "We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks."
  },
  {
    "date": "2026-01-26",
    "title": "Finite-Time Transition to Intermittency for a Stochastic Heat Equation Driven by the Square of a Gaussian Field",
    "authors": "Philippe Mounaix",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18561v1",
    "source": "arXiv",
    "abstract": "In this paper, we study the spatial behavior of the solution $ψ(x,t)$ to the stochastic heat equation $\\partial_tψ(x,t)-\\frac{1}{2}\\partial^2_{x^2} ψ(x,t)=g\\, S(x,t)^2\\, ψ(x,t)$, with $0\\le t\\le T$, $x\\in\\mathbb{R}$, and $ψ(x,0)=1$. Here, $g>0$ is a coupling constant and $S(x,t)$ is a stationary, homogeneous, and ergodic Gaussian field. Focusing on $\\mathcal{E}(x,g)\\equiv ψ(x,T)$ at a finite time $T>0$, we identify the critical coupling $g_c(T)$ above which the average of $\\mathcal{E}(0,g)$ diverges. We show that in the subcritical regime $g<g_c(T)$, $\\mathcal{E}(x,g)$ is spatially ergodic, with no intermittency, while in the supercritical regime $g>g_c(T)$ it becomes spatially intermittent and loses ergodicity. Our results differ from the extensively studied case where $S(x,t)^2$ is replaced by $S(x,t)$, in which intermittency appears only asymptotically as $T\\to +\\infty$, with no finite-time intermittency."
  },
  {
    "date": "2026-01-26",
    "title": "AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging",
    "authors": "Li Fang, Tianyu Li, Yanghong Lin, Shudong Zhou, Wei Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18560v1",
    "source": "arXiv",
    "abstract": "As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels."
  },
  {
    "date": "2026-01-26",
    "title": "Arithmetic volumes of moduli stacks of Shtukas",
    "authors": "Tony Feng, Zhiwei Yun, Wei Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18557v1",
    "source": "arXiv",
    "abstract": "We define and study \"tautological classes\" in the cohomology of moduli stacks of shtukas, pursuing two directions of applications. First, we prove a formula relating the \"arithmetic volume\" of tautological classes to higher derivatives of Artin $L$-functions, which can be viewed as an arithmetic analog of Hirzebruch's Proportionality principle. Second, we define and analyze the structure of the \"phantom tautological ring\", using a general relation between Hecke correspondences and Vinberg's degeneration, and give applications to a function field analog of Colmez's Conjecture."
  },
  {
    "date": "2026-01-26",
    "title": "Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis",
    "authors": "Jingsong Xia, Siqi Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18556v1",
    "source": "arXiv",
    "abstract": "In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios."
  },
  {
    "date": "2026-01-26",
    "title": "Different Transient Phenomena at the Edges of Traveling Foreshocks",
    "authors": "Primoz Kajdic, Xóchitl Blanco-Cano, Diana Rojas-Castllo, Nojan Omidi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18553v1",
    "source": "arXiv",
    "abstract": "Past kinetic simulations and spacecraft observations have shown that traveling foreshocks (TFs) are bounded by either foreshock compressional boundaries (FCBs) or foreshock bubbles (FBs). Here we present four TFs with a different kind of structure appearing at one of their edges. Two of them, observed by the Cluster mission, are bounded by a hot flow anomaly (HFA). In one case, the HFA was observed only by the spacecraft closest to the bow shock, while the other three probes observed an FCB. In addition, two other TFs were observed by the MMS spacecraft to be delimited by a structure that we call HFA-like FCB. In the spacecraft data, these structures present signatures similar to those of HFAs: dips in magnetic field magnitude and solar wind density, decelerated and deflected plasma flow and increased temperature. However, a detailed inspection of these events reveals the absence of heating of the SW beam. Instead, the beam almost disappears inside these events and the plasma moments are strongly influenced by the suprathermal particles. We suggest that HFA-like FCBs are related to the evolution and structure of the directional discontinuities of the interplanetary magnetic field whose thickness is larger than the gyroradious of suprathermal ions. We also show that individual TFs may appear together with several different types of transient upstream mesoscale structures, which brings up a question about their combined effect on regions downstream of the bow shock."
  },
  {
    "date": "2026-01-26",
    "title": "An exploration of lateral optical forces from a triangular periodic motif",
    "authors": "Bo Gao, Henkjan Gersen, Simon Hanna",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18550v1",
    "source": "arXiv",
    "abstract": "This computational study investigates lateral optical forces in asymmetric dielectric nanostructures, focusing on their connection to resonant light-matter interactions. We examine isosceles triangular motifs that exhibit two distinct types of optical force response under plane wave illumination. Through parameter-space analysis, we identify stable zones where optical forces remain consistent and switching bands where forces change abruptly as parameters are altered. The observed force spectra show characteristic asymmetric lineshapes, suggesting Fano-resonance behavior. Eigenfrequency analysis confirms these effects arise from interference between discrete eigenmodes and continuum propagation states, with the eigenmode Q-factors correlating with transition sharpness. These findings provide insights into how structural geometry influences optical forces through resonant effects, offering guidance for designing optically-driven systems where controlled optical force responses are desired."
  },
  {
    "date": "2026-01-26",
    "title": "Fast and Safe Trajectory Optimization for Mobile Manipulators With Neural Configuration Space Distance Field",
    "authors": "Yulin Li, Zhiyuan Song, Yiming Li, Zhicheng Song, Kai Chen, Chunxin Zheng, Zhihai Bi, Jiahang Cao, Sylvain Calinon, Fan Shi, Jun Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18548v1",
    "source": "arXiv",
    "abstract": "Mobile manipulators promise agile, long-horizon behavior by coordinating base and arm motion, yet whole-body trajectory optimization in cluttered, confined spaces remains difficult due to high-dimensional nonconvexity and the need for fast, accurate collision reasoning. Configuration Space Distance Fields (CDF) enable fixed-base manipulators to model collisions directly in configuration space via smooth, implicit distances. This representation holds strong potential to bypass the nonlinear configuration-to-workspace mapping while preserving accurate whole-body geometry and providing optimization-friendly collision costs. Yet, extending this capability to mobile manipulators is hindered by unbounded workspaces and tighter base-arm coupling. We lift this promise to mobile manipulation with Generalized Configuration Space Distance Fields (GCDF), extending CDF to robots with both translational and rotational joints in unbounded workspaces with tighter base-arm coupling. We prove that GCDF preserves Euclidean-like local distance structure and accurately encodes whole-body geometry in configuration space, and develop a data generation and training pipeline that yields continuous neural GCDFs with accurate values and gradients, supporting efficient GPU-batched queries. Building on this representation, we develop a high-performance sequential convex optimization framework centered on GCDF-based collision reasoning. The solver scales to large numbers of implicit constraints through (i) online specification of neural constraints, (ii) sparsity-aware active-set detection with parallel batched evaluation across thousands of constraints, and (iii) incremental constraint management for rapid replanning under scene changes."
  },
  {
    "date": "2026-01-26",
    "title": "Tight semidefinite programming relaxations for sparse box-constrained quadratic programs",
    "authors": "Aida Khajavirad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18545v1",
    "source": "arXiv",
    "abstract": "We introduce a new class of semidefinite programming (SDP) relaxations for sparse box-constrained quadratic programs, obtained by a novel integration of the Reformulation Linearization Technique into standard SDP relaxations while explicitly exploiting the sparsity of the problem. The resulting relaxations are not implied by the existing LP and SDP relaxations for this class of optimization problems. We establish a sufficient condition under which the convex hull of the feasible region of the lifted quadratic program is SDP-representable; the proof is constructive and yields an explicit extended formulation. Although the resulting SDP may be of exponential size in general, we further identify additional structural conditions on the sparsity of the optimization problem that guarantee the existence of a polynomial-size SDP-representable formulation, which can be constructed in polynomial time."
  },
  {
    "date": "2026-01-26",
    "title": "Audio Inpainting in Time-Frequency Domain with Phase-Aware Prior",
    "authors": "Peter Balušík, Pavel Rajmic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18535v1",
    "source": "arXiv",
    "abstract": "The so-called audio inpainting problem in the time domain refers to estimating missing segments of samples within a signal. Over the years, several methods have been developed for such type of audio inpainting. In contrast to this case, a time-frequency variant of inpainting appeared in the literature, where the challenge is to reconstruct missing spectrogram columns with reliable information. We propose a method to address this time-frequency audio inpainting problem. Our approach is based on the recently introduced phase-aware signal prior that exploits an estimate of the instantaneous frequency. An optimization problem is formulated and solved using the generalized Chambolle-Pock algorithm. The proposed method is evaluated both objectively and subjectively against other time-frequency inpainting methods, specifically a deep-prior neural network and the autoregression-based approach known as Janssen-TF. Our proposed approach surpassed these methods in the objective evaluation as well as in the conducted listening test. Moreover, this outcome is achieved with a substantially reduced computational requirement compared to alternative methods."
  },
  {
    "date": "2026-01-26",
    "title": "From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation",
    "authors": "Yuxin Jiang, Yufei Wang, Qiyuan Zhang, Xingshan Zeng, Liangyou Li, Jierun Chen, Chaofan Tao, Haoli Bai, Lifeng Shang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18533v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR."
  },
  {
    "date": "2026-01-26",
    "title": "From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation",
    "authors": "Devon Levy, Bar Assayag, Laura Gaspar, Ilan Shimshoni, Bella Specktor-Fadida",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18532v1",
    "source": "arXiv",
    "abstract": "Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy."
  },
  {
    "date": "2026-01-26",
    "title": "The Universal Post-Lie-Rinehart Algebra of Planar Aromatic Trees",
    "authors": "Ludwig Rahm",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18528v1",
    "source": "arXiv",
    "abstract": "This paper defines the algebraic structure of tracial post-Lie-Rinehart algebras and describes the free object in this category. Post-Lie-Rinehart algebras is a generalisation of pre-Lie-Rinehart algebras, and of post-Lie algebroids."
  },
  {
    "date": "2026-01-26",
    "title": "From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale",
    "authors": "Yongqi Jin, Yecheng Wang, Jun-jie Wang, Rong Zhu, Guolin Ke, Weinan E",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18524v1",
    "source": "arXiv",
    "abstract": "Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science."
  },
  {
    "date": "2026-01-26",
    "title": "A BFBt preconditioner for Double Saddle-Point Systems",
    "authors": "Chen Greif",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18520v1",
    "source": "arXiv",
    "abstract": "We consider block preconditioners for double saddle-point systems, and investigate the effect of approximating the nested Schur complement associated with the trailing diagonal block on the eigenvalue distribution of the preconditioned matrix. We develop a variant of Elman's BFBt method and adapt it to this family of linear systems. Our findings are illustrated on a Marker-and-Cell discretization of the Stokes-Darcy equations."
  },
  {
    "date": "2026-01-26",
    "title": "Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates",
    "authors": "Yibo Li, Zijie Lin, Ailin Deng, Xuan Zhang, Yufei He, Shuo Ji, Tri Cao, Bryan Hooi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18510v1",
    "source": "arXiv",
    "abstract": "While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL."
  },
  {
    "date": "2026-01-26",
    "title": "Interference-induced entanglement in an effectively zero-lifetime particle pair",
    "authors": "Xin Wu, Xinbai Li, Zebo Tang, Yusong Wang, Wangmei Zha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18503v1",
    "source": "arXiv",
    "abstract": "Quantum entanglement in high-energy collisions is often obscured by finite lifetimes, dynamical evolution, and final-state interactions, complicating the identification of genuinely quantum correlations. Ultra-peripheral heavy-ion collisions provide a clean benchmark via the Drell-S${\\rm\\ddot{o}ding}$ production of nonresonant pion pair, realizing an effectively zero-lifetime particle pair whose quantum correlations are fixed at production and remain robust against subsequent elastic scattering. The coherent superposition of photoproduction amplitudes from two indistinguishable nuclei encodes the linear polarization of quasi-real photons in the orbital motion of the pair, generating a nonfactorizable two-particle quantum state. This entanglement leaves a direct experimental imprint: a characteristic second-harmonic azimuthal modulation in momentum space arising from spin-dependent interference between the two sources. In this paper, we establish a quantitative framework for Drell-S${\\rm\\ddot{o}ding}$ pion-pair production in relativistic heavy-ion collisions and predict the magnitude and transverse-momentum dependence of the entanglement-induced azimuthal asymmetry. Our results provide experimentally accessible signatures of interference-induced entanglement and a controlled test of quantum coherence in relativistic environments."
  },
  {
    "date": "2026-01-26",
    "title": "DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference",
    "authors": "Zihan wang, Hao Wang, Shi Feng, Xiaocui Yang, Daling Wang, Yiqun Zhang, Jinghao Lin, Haihua Yang, Xiaozhong Ji",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18496v1",
    "source": "arXiv",
    "abstract": "Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus \"find it but fail to use it,\" leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\\% on average and outperforms larger medical reasoning and DR models."
  },
  {
    "date": "2026-01-26",
    "title": "Evidence of Langmuir/$\\mathcal{Z}$-mode Wave Decay into $\\mathcal{Z}$-mode Electromagnetic Radiation in the Solar Wind",
    "authors": "F. J. Polanco-Rodríguez, C. Krafft, P. Savoini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18495v1",
    "source": "arXiv",
    "abstract": "The nonlinear decay of Langmuir/$\\mathcal{Z}$-mode waves into electromagnetic $\\mathcal{Z}$-mode wave radiation at the plasma frequency is observed for the first time in the solar wind. This finding was enabled by the unprecedented high-resolution electric and magnetic field measurements provided by the Radio Plasma Waves (RPW) instrument aboard the Solar Orbiter spacecraft, which encountered an electron beam associated with a Type III radio burst. The decay process is definitively identified through multiple lines of evidence: satisfaction of frequency and wavevector resonance conditions, strong phase coherence and temporal coincidence between the interacting waves, exclusion of competing mechanisms, and full agreement with theoretical predictions. Particle-in-cell simulations, conducted under close beam-plasma conditions, successfully reproduce the key features of the observations. Notably, they suggest that the wave packet observed by Solar Orbiter may be trapped within an extended, nearly flat-bottomed density well, where the decay process is not overcome by wave scattering on random density fluctuations and subsequent mode conversion effects."
  },
  {
    "date": "2026-01-26",
    "title": "Demographic Probing of Large Language Models Lacks Construct Validity",
    "authors": "Manuel Tonneau, Neil K. R. Seghal, Niyati Malhotra, Victor Orozco-Olvera, Ana María Muñoz Boudet, Lakshmi Subramanian, Sharath Chandra Guntuku, Valentin Hofmann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18486v1",
    "source": "arXiv",
    "abstract": "Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs."
  },
  {
    "date": "2026-01-26",
    "title": "Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs",
    "authors": "Arya Labroo, Ivaxi Sheth, Vyas Raina, Amaani Ahmed, Mario Fritz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18483v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \\textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control."
  },
  {
    "date": "2026-01-26",
    "title": "On decay of solutions to the anisotropic Boussinesq equations near the hydrostatic balance in half space $\\mathbb{R}_+^3$",
    "authors": "Wangrong Yang, Aibin Zang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18481v1",
    "source": "arXiv",
    "abstract": "The system of the Boussinesq equations is one of the most important models for geophysical fluids. This paper focuses on the initial-boundary problem of the 3D incompressible anisotropic Boussinesq system with horizontal dissipation. The goal here is to assess the stability property and large-time behavior of perturbations near the hydrostatic balance. By utilizing the structure of the system, the energy methods and the means of bootstrapping argument, we prove the global stability property in the Sobolev space $H^3(\\mathbb{R}^3_+)$. After taking a Fourier transform in $x_h = (x_1, x_2)$ and Fourier cosine and sine transforms in $x_3$ for the system, we obtain the decay rates for the global solution itself as well as its derivatives."
  },
  {
    "date": "2026-01-26",
    "title": "Dynamic Channel Charting: An LSTM-AE-based Approach",
    "authors": "Yuan Gao, Xinyu Guo, Wenjing Xie, Zifan Wang, Hongwen Yu, Gongyang Li, Shugong Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18473v1",
    "source": "arXiv",
    "abstract": "With the development of the sixth-generation (6G) communication system, Channel State Information (CSI) plays a crucial role in improving network performance. Traditional Channel Charting (CC) methods map high-dimensional CSI data to low-dimensional spaces to help reveal the geometric structure of wireless channels. However, most existing CC methods focus on learning static geometric structures and ignore the dynamic nature of the channel over time, leading to instability and poor topological consistency of the channel charting in complex environments. To address this issue, this paper proposes a novel time-series channel charting approach based on the integration of Long Short-Term Memory (LSTM) networks and Auto encoders (AE) (LSTM-AE-CC). This method incorporates a temporal modeling mechanism into the traditional CC framework, capturing temporal dependencies in CSI using LSTM and learning continuous latent representations with AE. The proposed method ensures both geometric consistency of the channel and explicit modeling of the time-varying properties. Experimental results demonstrate that the proposed method outperforms traditional CC methods in various real-world communication scenarios, particularly in terms of channel charting stability, trajectory continuity, and long-term predictability."
  },
  {
    "date": "2026-01-26",
    "title": "Design and modeling of a liquid-lead dump concept for beamstrahlung radiation absorption in the CERN Future Circular e$^+$e$^-$ Collider",
    "authors": "Silvio Candido, Rui Franqueira Ximenes, Anton Lechner, Alessandro Frasca, Giuseppe Lerner, Antonio Perillo Marcone, Regis Seidenbinder, Markus Widorski, Louise Jorat, Giacomo Lavezzari, Davide Bozzato, Gabriel Banks, Marco Calviani, Luca Tricarico, Carlo Carrelli, Mariano Tarantino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18470v1",
    "source": "arXiv",
    "abstract": "The electron-positron Future Circular Collider (FCC-ee) being developed at CERN will generate intense beamstrahlung radiation, thus requiring photon absorbers downstream of the interaction points. This work presents the conceptual design of flowing-liquid-lead absorbers capable of dissipating around 370 kW of photon power, with a mean photon energy of 62 MeV. Two configurations are investigated: an inclined-flow geometry, developed to increase the photon interaction length to maximize absorption, and a compact upstream slope with an additional pool, in which a free-surface lead flow intercepts the power peak before a downstream pool dissipates the remaining load. Photon-matter interactions are modeled using Monte Carlo simulations in fluka, while conjugate heat-transfer and free-surface dynamics are analyzed through computational-fluid-dynamics simulations using ansys fluent. Design refinements are introduced based on the simulated thermal and hydraulic performance and to mitigate secondary effects such as photon backscattering. Both configurations demonstrate stable operation within the 300 kg/s flow limit and maintain liquid-lead and structural temperatures within the operational range of 450--500 $^{\\circ}$C. The results establish circulating liquid lead as a feasible and thermally robust baseline technology for beamstrahlung absorption in FCC-ee."
  },
  {
    "date": "2026-01-26",
    "title": "Constraining bulk-to-boundary correlators in the theories with Poincaré symmetry",
    "authors": "Jiang Long, Jing-Long Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18461v1",
    "source": "arXiv",
    "abstract": "It is well known that a general two-point function cannot be uniquely determined in a theory with Poincaré symmetry. In this paper, we show that bulk-to-boundary correlators are highly constrained after imposing suitable fall-off conditions near future/past null infinity. More precisely, scalar bulk-to-boundary correlators are fixed to a unique form up to a normalization constant, whereas fermionic bulk-to-boundary correlators are fixed to a linear superposition of scalar and fermionic branches. This is established by asymptotically expanding the Ward identities, where upon the leading terms decouple from the subleading ones. In the fermionic branch, the power-law exponent of the bulk-to-boundary correlator is greater by one than the fall-off index. Consequently, we revisit the relation between Carrollian correlators and momentum space scattering amplitudes for fermionic operators. In this context, we find that the Fourier transform bridging the two acquires an extra factor of $\\sqrtω$ for each fermionic operator. Furthermore, we reduce the bulk-to-boundary correlator to the boundary-to-boundary correlator and identify a critical fall-off index $Δ=1$. For $0 \\le Δ< 1$, only a magnetic branch exists for scalars. For $Δ> 1$, the electric branch is always divergent for both scalar and fermionic branches and thus requires regularization."
  },
  {
    "date": "2026-01-26",
    "title": "3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control",
    "authors": "Xuanmeng Sha, Liyun Zhang, Tomohiro Mashita, Naoya Chiba, Yuki Uranishi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18451v1",
    "source": "arXiv",
    "abstract": "Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures."
  },
  {
    "date": "2026-01-26",
    "title": "KeyMemRT Compiler and Runtime: Unlocking Memory-Scalable FHE",
    "authors": "Eymen Ünay, Björn Franke, Jackson Woodruff",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18445v1",
    "source": "arXiv",
    "abstract": "Fully Homomorphic Encryption (FHE) enables privacy preserving computation but it suffers from high latency and memory consumption. The computations are secured with special keys called rotation keys which often take up the majority of memory. In complex FHE applications, these rotation keys can cause a large memory bottleneck limiting program throughput. Existing compilers make little effort to solve this problem, instead relying on systems with massive memory availability. This resource requirement is a barrier to FHE uptake because optimizing FHE programs by hand is challenging due to their scale, complexity and expertise required. In this work, we present KeyMemRT; an MLIR based compiler and runtime framework that individually manages rotation key lifetimes to lower memory utilization and to allow arbitrary number of rotation indices to be supported without memory bloating. KeyMemRT relies on dataflow analysis to determine key lifetimes and is the first FHE compiler to provide automatic key management, handle fine-grained key-mangement and manage boostrap keys. We implement frontends for Orion and HEIR and show improvements over state-of-the-art FHE compilers. KeyMemRT achieves memory reduction of 1.74x and a speedup of 1.20x over ANT-ACE, and memory reduction of 1.16x and a speedup of 1.73x over memory-optimized compiler Fhelipe. We provide KeyMemRT as a post-optimizing compiler that can be targeted by any FHE compiler."
  },
  {
    "date": "2026-01-26",
    "title": "SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation",
    "authors": "Hongyi Zhao, Shuo Wang, Qijie He, Ziyuan Pu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18442v1",
    "source": "arXiv",
    "abstract": "Autonomous vehicle safety validation requires testing on safety-critical scenarios, but these events are rare in real-world driving and costly to test due to collision risks. Crash reports provide authentic specifications of safety-critical events, offering a vital alternative to scarce real-world collision trajectory data. This makes them valuable sources for generating realistic high-risk scenarios through simulation. Existing approaches face significant limitations because data-driven methods lack diversity due to their reliance on existing latent distributions, whereas adversarial methods often produce unrealistic scenarios lacking physical fidelity. Large Language Model (LLM) and Vision Language Model (VLM)-based methods show significant promise. However, they suffer from context suppression issues where internal parametric knowledge overrides crash specifications, producing scenarios that deviate from actual accident characteristics. This paper presents SG-CADVLM (A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation), a framework that integrates Context-Aware Decoding with multi-modal input processing to generate safety-critical scenarios from crash reports and road network diagrams. The framework mitigates VLM hallucination issues while enabling the simultaneous generation of road geometry and vehicle trajectories. The experimental results demonstrate that SG-CADVLM generates critical risk scenarios at a rate of 84.4% compared to 12.5% for the baseline methods, representing an improvement of 469%, while producing executable simulations for autonomous vehicle testing."
  },
  {
    "date": "2026-01-26",
    "title": "First Observational Evidence for Split Infall Flow of Cosmic Filaments into Clusters",
    "authors": "Ji Yao, Huanyuan Shan, Pengjie Zhang, Xiaohu Yang, Jiale Zhou, Jiaxin Han, Peng Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18434v1",
    "source": "arXiv",
    "abstract": "Velocity fields in the cosmic web are fundamental to structure formation but remain difficult to observe directly beyond the linear regime. Here we present observational evidence that galaxy filaments connecting pairs of galaxy clusters undergo a split infall, with opposite velocity flows toward the two clusters. Using spectroscopic galaxies from the Sloan Digital Sky Survey, we isolate the internal filament velocity field by subtracting its rigid-body background motion and Hubble flow, and detect this effect at greater than $5σ$ significance across a wide range of cluster and filament selections. The measured velocity profile exhibits a sign reversal near the filament midpoint and a maximum infall amplitude of $\\sim30$ km/s ($\\sim20$ km/s projected onto the line-of-sight) for clusters of mass $\\sim10^{14.3}M_\\odot$, substantially lower than expected for infall from an average cosmic environment. Multiple results on density-velocity correlation, mass-dependency, and validation with simulation indicate that filaments dynamically respond to competing gravitational potentials rather than acting as passive mass transport channels. Our results establish a new observational window on quasi-linear velocity fields in the cosmic web and provide a promising probe of mass measurement, testing gravity and velocity reconstruction with upcoming wide-field spectroscopic surveys."
  },
  {
    "date": "2026-01-26",
    "title": "Fusion of Spatio-Temporal and Multi-Scale Frequency Features for Dry Electrodes MI-EEG Decoding",
    "authors": "Tianyi Gong, Can Han, Junxi Wu, Dahong Qian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18424v1",
    "source": "arXiv",
    "abstract": "Dry-electrode Motor Imagery Electroencephalography (MI-EEG) enables fast, comfortable, real-world Brain Computer Interface by eliminating gels and shortening setup for at-home and wearable use.However, dry recordings pose three main issues: lower Signal-to-Noise Ratio with more baseline drift and sudden transients; weaker and noisier data with poor phase alignment across trials; and bigger variances between sessions. These drawbacks lead to larger data distribution shift, making features less stable for MI-EEG tasks.To address these problems, we introduce STGMFM, a tri-branch framework tailored for dry-electrode MI-EEG, which models complementary spatio-temporal dependencies via dual graph orders, and captures robust envelope dynamics with a multi-scale frequency mixing branch, motivated by the observation that amplitude envelopes are less sensitive to contact variability than instantaneous waveforms. Physiologically meaningful connectivity priors guide learning, and decision-level fusion consolidates a noise-tolerant consensus. On our collected dry-electrode MI-EEG, STGMFM consistently surpasses competitive CNN/Transformer/graph baselines. Codes are available at https://github.com/Tianyi-325/STGMFM."
  },
  {
    "date": "2026-01-26",
    "title": "Meson-exchange currents and nuclear correlations in neutrino and electron scattering with nuclei",
    "authors": "Paloma Rodríguez Casalé",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18421v1",
    "source": "arXiv",
    "abstract": "This thesis is dedicated to the study of electron and neutrino scattering on nuclei, with special emphasis on meson-exchange currents (MEC) and short-range correlations (SRC) between nucleon pairs in one-particle emission processes. In chapter 2, the SuSAM* model is improved by redefining the single nucleon hadronic tensor, averaging it over a Fermi distribution instead of using the previous extrapolation from the relativistic Fermi gas. This formulation removes the inconsistency associated with negative contributions in kinematics far from the QE peak. The new definition allows extending the SuSAM* formalism to include MEC, which is the focus of chapter 3. In chapter 3, a scaling analysis of 12C data is performed incorporating MEC explicitly at the single nucleon level, leading to a new phenomenological scaling function. Using this model, the effect of MEC on EM responses is studied and compared with the relativistic Fermi gas (RFG) and the relativistic mean field (RMF) models. Chapter 4 presents a detailed analysis of the interference between 1b2b in the RT. It is shown that this interference is always negative within the independent-particle approximation. Chapter 5 extends the study of MEC to the CCQE neutrino scattering within the RFG, RMF, and SuSAM* frameworks. It is found that OB-MEC interference reduces both the RT and the neutrino cross section. Chapter 6 addresses SRC in the wave function of a nucleon pair in nuclear matter. The BG equation is solved using the NN potential developed by the Granada group, allowing for the calculation of high-momentum components. Finally, chapter 7 combined the effect of MEC and SRC, which extends the FG by including the high-momentum components of nucleon pairs affected by MEC. It is found that SRC enhance the RT, in contrast with what is observed in uncorrelated models."
  },
  {
    "date": "2026-01-26",
    "title": "Fundamentals, Recent Advances, and Challenges Regarding Cryptographic Algorithms for the Quantum Computing Era",
    "authors": "Darlan Noetzold, Valderi Reis Quietinho Leithardt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18413v1",
    "source": "arXiv",
    "abstract": "This book arises from the need to provide a clear and up-to-date overview of the impacts of quantum computing on cryptography. The goal is to provide a reference in Portuguese for undergraduate, master's, and doctoral students in the field of data security and cryptography. Throughout the chapters, we present fundamentals, we discuss classical and post-quantum algorithms, evaluate emerging patterns, and point out real-world implementation challenges. The initial objective is to serve as a guide for students, researchers, and professionals who need to understand not only the mathematics involved, but also its practical implications in security systems and policies. For more advanced professionals, the main objective is to present content and ideas so that they can assess the changes and perspectives in the era of quantum cryptographic algorithms. To that end, the text's structure was designed to be progressive: we begin with essential concepts, move on to quantum algorithms and their consequences (with emphasis on Shor's algorithm), present issues focusing on \"families\" of post-quantum schemes (based on lattices, codes, hash functions, multivariate, isogenies), analyze the state of the art in standardization (highlighting the NIST process), and finally, discuss migration, interoperability, performance, and cryptographic governance. We hope that this work will assist in the formation of critical thinking and informed technical decision-making, fostering secure transition strategies for the post-quantum era."
  },
  {
    "date": "2026-01-26",
    "title": "Frequency-Based Hyperparameter Selection in Games",
    "authors": "Aniket Sanyal, Baraah A. M. Sidahmed, Rebekka Burkholz, Tatjana Chavdarova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18409v1",
    "source": "arXiv",
    "abstract": "Learning in smooth games fundamentally differs from standard minimization due to rotational dynamics, which invalidate classical hyperparameter tuning strategies. Despite their practical importance, effective methods for tuning in games remain underexplored. A notable example is LookAhead (LA), which achieves strong empirical performance but introduces additional parameters that critically influence performance. We propose a principled approach to hyperparameter selection in games by leveraging frequency estimation of oscillatory dynamics. Specifically, we analyze oscillations both in continuous-time trajectories and through the spectrum of the discrete dynamics in the associated frequency-based space. Building on this analysis, we introduce \\emph{Modal LookAhead (MoLA)}, an extension of LA that selects the hyperparameters adaptively to a given problem. We provide convergence guarantees and demonstrate in experiments that MoLA accelerates training in both purely rotational games and mixed regimes, all with minimal computational overhead."
  },
  {
    "date": "2026-01-26",
    "title": "Brauer-Siegel theorem for families of number fields over almost Sn fields",
    "authors": "Anup B Dixit",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18408v1",
    "source": "arXiv",
    "abstract": "The classical Brauer-Siegel conjecture describes the asymptotic behaviour of the product of the class number and the regulator in families of number fields. All known cases of the conjecture rely on reducing the problem, via group theoretic methods, to Siegel's theorem for quadratic fields over Q or over a fixed base field. In this paper, we establish a new form of descent for the Brauer-Siegel conjecture. We show that if the conjecture holds for a family of almost Sn-fields, it necessarily holds for all quadratic extensions over that family, under mild conditions. This result may be viewed as an analogue of Siegel's theorem in which the base field is allowed to vary. In addition, we also establish the generalized Brauer-Siegel conjecture as formulated by Tsfasman-Vladut for asymptotically good towers of number fields over a family of almost Sn-fields."
  },
  {
    "date": "2026-01-26",
    "title": "On the average hitting times of the directed wheel",
    "authors": "Shunya Tamura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18402v1",
    "source": "arXiv",
    "abstract": "In this paper, following the paper ``On the average hitting times of the squares of cycles,'' we provide an explicit formula for the average hitting times of a simple random walk on a directed graph with $N$ vertices, where the graph consists of a cycle with a single absorbing vertex at its center, using elementary methods. Also, we show that the average hitting times can be expressed in terms of the Fibonacci and Lucas numbers in general."
  },
  {
    "date": "2026-01-26",
    "title": "Trace ideals of canonical modules over Schubert cycles and determinantal rings",
    "authors": "Kaito Kimura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18387v1",
    "source": "arXiv",
    "abstract": "In this paper, we study the canonical trace of Schubert cycles and determinantal rings. As an application, we give an explicit description of the non-Gorenstein locus and show that its structure is compatible with the known representations of the singular locus and the canonical module. Furthermore, for the CTR property recently introduced by Miyazaki, we establish its stability under base change and provide a characterization in the case of determinantal rings."
  },
  {
    "date": "2026-01-26",
    "title": "CitiLink: Enhancing Municipal Transparency and Citizen Engagement through Searchable Meeting Minutes",
    "authors": "Rodrigo Silva, José Evans, José Isidro, Miguel Marques, Afonso Fonseca, Ricardo Morais, João Canavilhas, Arian Pasquali, Purificação Silvano, Alípio Jorge, Nuno Guimarães, Sérgio Nunes, Ricardo Campos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18374v1",
    "source": "arXiv",
    "abstract": "City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction."
  },
  {
    "date": "2026-01-26",
    "title": "Atom-light hybrid interferometer for atomic sensing with quantum memory",
    "authors": "Xingchang Wang, Xinyun Liang, Liang Dong, Ying Zuo, Jianmin Wang, Dasen Yang, Linyu Chen, Georgios A. Siviloglou, Z. Y. Ou, J. F. Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18373v1",
    "source": "arXiv",
    "abstract": "Quantum memories feature a reversible conversion of optical fields into long-lived atomic spin waves, and are therefore ideal for operating as sensitive atomic sensors. However, up to now, atom-light interferometers have lacked an efficient approach to exploit their ultimate atomic sensing performance, since an extra optical delay line is required to compensate for the memory time. Here, we report a new protocol that records the photocurrent via heterodyne mixing with a stable local oscillator. The obtained complex quadrature amplitude that carries information imprinted on its phase by an external magnetic field, is successfully recovered from the interference patterns between the light and the atomic spin wave, without the stringent requirement of having them overlap in time. Our results reveal that the sensitivity scales favorably with the lifetime of the quantum memory. Our work may have important applications in building distributed quantum networks through quantum memory-assisted atom-light interferometers."
  },
  {
    "date": "2026-01-26",
    "title": "Scaling of multicopy constructive interference of Gaussian states",
    "authors": "Matthieu Arnhem, Radim Filip",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18347v1",
    "source": "arXiv",
    "abstract": "Quantum technology advances crucially depend on the scaling up of essential quantum resources. Their ideal multiplexing offers more significant gains in applications; however, the scaling of the nonidentical, fragile and varying resources is neither theoretically nor experimentally known. For bosonic systems, multimode interference is an essential tool already widely exploited to develop quantum technology. Here, we analyze, predict and compare essential scaling laws for a constructive interference of multiplexed nonclassical Gaussian states carrying information by displacement with weakly fluctuating squeezing in different multimode interference architectures. The signal-to-noise ratio quantifies the increase in displacement relative to the noise. We introduce the gain-to-instability ratio to numerically estimate the effect of unexplored resource instabilities in a large scale interference scheme. The use of the gain-to-instability ratio to quantify the scaling laws opens steps for extensive theoretical investigation of other bosonic resources and follow-up feasible experimental verification necessary for further development of these platforms."
  },
  {
    "date": "2026-01-26",
    "title": "Quantum Hyperuniformity and Quantum Weight",
    "authors": "Junmo Jeon, Shiro Sakai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18331v1",
    "source": "arXiv",
    "abstract": "Extending hyperuniformity from classical to quantum fluctuations in electron systems yields a framework that identifies quantum phase transitions and reveals underlying gap structures through the quantum weight. We study long-wavelength fluctuations of many-body ground states through the charge-density structure factor by incorporating intrinsic quantum fluctuations into hyperuniformity. Although charge fluctuations at zero temperature are generally suppressed by particle-number conservation, their long-wavelength scaling reveals distinct universal behaviors that define quantum hyperuniformity classes. By exemplifying the Aubry-Andre model, we find that gapped, gapless, and localized-critical-extended phases are sharply distinguished by the quantum hyperuniformity classes. Notably, at the critical point, multifractal wave functions generate anomalous scaling behavior. We further show that, in quantum-hyperuniform gapped phases, the quantum weight provides a quantitative measure of the gap size through a universal power-law scaling. Along with classical hyperuniformity, quantum hyperuniformity serves a direct fingerprint of quantum criticality and a practical probe of quantum phase transitions in aperiodic electron systems."
  },
  {
    "date": "2026-01-26",
    "title": "Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection",
    "authors": "Chuhan Feng, Jing Li, Jie Li, Lu Lv, Fengkui Gong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18329v1",
    "source": "arXiv",
    "abstract": "We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types."
  },
  {
    "date": "2026-01-26",
    "title": "Integrating Fine-Grained Audio-Visual Evidence for Robust Multimodal Emotion Reasoning",
    "authors": "Zhixian Zhao, Wenjie Tian, Xiaohai Tian, Jun Zhang, Lei Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18321v1",
    "source": "arXiv",
    "abstract": "Multimodal emotion analysis is shifting from static classification to generative reasoning. Beyond simple label prediction, robust affective reasoning must synthesize fine-grained signals such as facial micro-expressions and prosodic which shifts to decode the latent causality within complex social contexts. However, current Multimodal Large Language Models (MLLMs) face significant limitations in fine-grained perception, primarily due to data scarcity and insufficient cross-modal fusion. As a result, these models often exhibit unimodal dominance which leads to hallucinations in complex multimodal interactions, particularly when visual and acoustic cues are subtle, ambiguous, or even contradictory (e.g., in sarcastic scenery). To address this, we introduce SABER-LLM, a framework designed for robust multimodal reasoning. First, we construct SABER, a large-scale emotion reasoning dataset comprising 600K video clips, annotated with a novel six-dimensional schema that jointly captures audiovisual cues and causal logic. Second, we propose the structured evidence decomposition paradigm, which enforces a \"perceive-then-reason\" separation between evidence extraction and reasoning to alleviate unimodal dominance. The ability to perceive complex scenes is further reinforced by consistency-aware direct preference optimization, which explicitly encourages alignment among modalities under ambiguous or conflicting perceptual conditions. Experiments on EMER, EmoBench-M, and SABER-Test demonstrate that SABER-LLM significantly outperforms open-source baselines and achieves robustness competitive with closed-source models in decoding complex emotional dynamics. The dataset and model are available at https://github.com/zxzhao0/SABER-LLM."
  },
  {
    "date": "2026-01-26",
    "title": "MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization",
    "authors": "Jinwei Lu, Yuanfeng Song, Chen Zhang, Raymond Chi-Wing Wong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18320v1",
    "source": "arXiv",
    "abstract": "Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation."
  },
  {
    "date": "2026-01-26",
    "title": "Convex Chance-Constrained Stochastic Control under Uncertain Specifications with Application to Learning-Based Hybrid Powertrain Control",
    "authors": "Teruki Kato, Ryotaro Shima, Kenji Kashima",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18313v1",
    "source": "arXiv",
    "abstract": "This paper presents a strictly convex chance-constrained stochastic control framework that accounts for uncertainty in control specifications such as reference trajectories and operational constraints. By jointly optimizing control inputs and risk allocation under general (possibly non-Gaussian) uncertainties, the proposed method guarantees probabilistic constraint satisfaction while ensuring strict convexity, leading to uniqueness and continuity of the optimal solution. The formulation is further extended to nonlinear model-based control using exactly linearizable models identified through machine learning. The effectiveness of the proposed approach is demonstrated through model predictive control applied to a hybrid powertrain system."
  },
  {
    "date": "2026-01-26",
    "title": "Understanding Heat Transport Mechanisms in Optically Transparent Thermal Loss Mitigators",
    "authors": "Domala Sai Suhas, Vikrant Khullar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18299v1",
    "source": "arXiv",
    "abstract": "Optically transparent thermal loss mitigators have recently seen renewed research interests owing to their increasing relevance in the realms ranging from smart windows, efficient greenhouse designs and high-performance-low-cost solar thermal systems. In depth understanding of the heat transport mechanisms and their quantification is crucial for building efficient opto-thermal management strategies for optimization of the aforementioned systems. The present work serves to identify and quantify the key heat transfer mechanisms operative in a host of optically transparent thermal loss mitigators. In particular, comprehensive experimental modelling frameworks have been developed to investigate the efficacy of carbon dioxide gas (CO2), air, vacuum (0.07mbar), transparent heat mirrors (Indium tin oxide coated glass) and aerogels (silica-based) in mitigating thermal losses. Detailed and careful experimental modelling reveals that it is imperative to employ more than one thermal loss mitigator and choose correct absorber surface orientation (relative to the irradiation direction) to maximize thermal loss mitigation. Magnitude of absorber surface stagnation temperature has been employed as the figure of merit to quantitatively compare various optically transparent thermal loss mitigators. Under un-evacuated conditions, CO2 has emerged as potent alternative to more sophisticated optically transparent thermal loss mitigators like aerogels and transparent heat mirrors. Enhancements (relative to air) on the order of 2%-7%, 46%-84%, 57%-84% and 66%-86% are observed in case of CO2, vacuum, transparent heat mirrors (vacuum) and aerogel (vacuum) respectively."
  },
  {
    "date": "2026-01-26",
    "title": "A Heterogeneous Massive MIMO Technique for Uniform Service in Cellular Networks",
    "authors": "Wei Jiang, Hans D. Schotten",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18298v1",
    "source": "arXiv",
    "abstract": "Traditional cellular networks struggle with poor quality of service (QoS) for cell-edge users, while cell-free (CF) systems offer uniform QoS but incur high roll-out costs due to acquiring numerous access point (AP) sites and deploying a large-scale optical fiber network to connect them. This paper proposes a cost-effective heterogeneous massive MIMO architecture that integrates centralized co-located antennas at a cell-center base station with distributed edge APs. By strategically splitting massive antennas between centralized and distributed nodes, the system maintains high user fairness comparable to CF systems but reduces infrastructure costs substantially, by minimizing the required number of AP sites and fronthaul connections. Numerical results demonstrate its superiority in balancing performance and costs compared to cellular and CF systems."
  },
  {
    "date": "2026-01-26",
    "title": "A necessary and sufficient condition for convergence in distribution of the P-P process in $L^1[0,1]$",
    "authors": "Brendan K. Beare, Tetsuya Kaji",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18390v1",
    "source": "arXiv",
    "abstract": "We establish that the procentile-procentile (P-P) process constructed from a random sample of pairs converges in distribution in $L^1[0,1]$ if and only if the P-P curve is absolutely continuous. If the P-P process converges in distribution then it may be approximated using the bootstrap."
  },
  {
    "date": "2026-01-26",
    "title": "Chiral Properties of $(2\\!+\\!1)$-Flavor QCD in Magnetic Fields at Zero Temperature",
    "authors": "Heng-Tong Ding, Dan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18354v1",
    "source": "arXiv",
    "abstract": "We present a lattice QCD study of the chiral properties of $(2\\!+\\!1)$-flavor QCD in background magnetic fields at zero temperature with physical pion masses. Simulations are performed using the highly improved staggered quark (HISQ) action across four different lattice spacings to enable a controlled continuum extrapolation. We compute the renormalized chiral condensates together with pseudoscalar meson masses and decay constants for pions, kaons, and the fictitious $η^0_{s\\bar{s}}$ pseudoscalar as functions of the magnetic field strength $eB$ up to $eB\\simeq1.2$ $\\mathrm{GeV}^2$. The chiral condensates exhibit clear magnetic catalysis, increasing monotonically with the field strength. In the meson sector, neutral pseudoscalar masses decrease steadily with $eB$, whereas charged pseudoscalar masses display a non-monotonic response: they rise at small fields, consistent with the lowest-Landau-level expectation, but then saturate and slightly decrease at larger fields, signaling sizable internal-structure effects. At the same time, neutral pseudoscalar decay constants are strongly enhanced by the magnetic field. To quantify deviations from chiral symmetry relations, we isolate the magnetic-field-induced shift in the Gell-Mann--Oakes--Renner corrections, and find it to remain small for the neutral pion but to become sizable for the neutral kaon. To elucidate the origin of the magnetic response, we separately analyze the sea and valence quark contributions to both neutral and charged meson masses, finding that valence effects dominate at zero temperature. These results provide new insights into the interplay between QCD chiral symmetry breaking and strong magnetic fields."
  },
  {
    "date": "2026-01-26",
    "title": "RTeAAL Sim: Using Tensor Algebra to Represent and Accelerate RTL Simulation (Extended Version)",
    "authors": "Yan Zhu, Boru Chen, Christopher W. Fletcher, Nandeeka Nayak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18140v1",
    "source": "arXiv",
    "abstract": "RTL simulation on CPUs remains a persistent bottleneck in hardware design. State-of-the-art simulators embed the circuit directly into the simulation binary, resulting in long compilation times and execution that is fundamentally CPU frontend-bound, with severe instruction-cache pressure. This work proposes RTeAAL Sim, which reformulates RTL simulation as a sparse tensor algebra problem. By representing RTL circuits as tensors and simulation as a sparse tensor algebra kernel, RTeAAL Sim decouples simulation behavior from binary size and makes RTL simulation amenable to well-studied tensor algebra optimizations. We demonstrate that a prototype of our tensor-based simulator, even with a subset of these optimizations, already mitigates the compilation overhead and frontend pressure and achieves performance competitive with the highly optimized Verilator simulator across multiple CPUs and ISAs."
  },
  {
    "date": "2026-01-26",
    "title": "Constraining Reionization Morphology and Source Properties with 21cm-Galaxy Cross-Correlation Surveys",
    "authors": "Yannic Pietschke, Anne Hutter, Caroline Heneka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18627v1",
    "source": "arXiv",
    "abstract": "Cross-correlations between 21cm observations and galaxy surveys provide a powerful probe of reionization by reducing foreground sensitivity while linking ionization morphology to galaxies. We quantify the constraining power of 21cm-Galaxy cross-power spectra for inferring neutral hydrogen fraction $x_\\mathrm{HI}(z)$ and mean overdensity $\\langle 1+δ_\\mathrm{HI} \\rangle(z)$, exploring dependence on field of view, redshift precision $σ_z$, and minimum halo mass $M_\\mathrm{h,min}$. We employ our simulation-based inference framework EoRFlow for likelihood-free parameter estimation. Mock observations include thermal noise for 100h SKA-Low with foreground avoidance and realistic galaxy survey effects. For a fiducial survey ($\\mathrm{FOV}=100\\,\\mathrm{deg}^2$, $σ_z=0.001$, $M_\\mathrm{h,min}=10^{11}\\mathrm{M}_\\odot$), cross-power spectra yield unbiased constraints with posterior volumes (PV) of $\\sim$10% relative to priors. Cross-power measurements reduce PV by 20-30% versus 21cm auto-power alone. With foreground avoidance, spectroscopic redshift precision is essential; photometric redshifts render cross-correlations uninformative. Notably, cross-power spectra constrain ionizing source properties, the escape fraction $f_\\mathrm{esc}$ and star formation efficiency $f_*$, which remain degenerate in auto-power (PV $>$60%). Tight constraints require either deep surveys detecting faint galaxies ($M_\\mathrm{h,min} \\sim 10^{10}\\mathrm{M}_\\odot$) with moderate foregrounds, or conservative mass limits with optimistic foreground removal (PV $<$15%). 21cm-Galaxy cross-correlations enhance morphology constraints beyond auto-power while enabling previously inaccessible source property constraints. Realizing full potential requires precise redshifts and either faint galaxy detection limits or improved 21cm foreground cleaning."
  },
  {
    "date": "2026-01-26",
    "title": "Complex-Valued-Matrix Permanents: SPA-based Approximations and Double-Cover Analysis",
    "authors": "Junda Zhou, Pascal O. Vontobel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18232v1",
    "source": "arXiv",
    "abstract": "Approximating the permanent of a complex-valued matrix is a fundamental problem with applications in Boson sampling and probabilistic inference. In this paper, we extend factor-graph-based methods for approximating the permanent of non-negative-real-valued matrices that are based on running the sum-product algorithm (SPA) on standard normal factor graphs, to factor-graph-based methods for approximating the permanent of complex-valued matrices that are based on running the SPA on double-edge normal factor graphs. On the algorithmic side, we investigate the behavior of the SPA, in particular how the SPA fixed points change when transitioning from real-valued to complex-valued matrix ensembles. On the analytical side, we use graph covers to analyze the Bethe approximation of the permanent, i.e., the approximation of the permanent that is obtained with the help of the SPA. This combined algorithmic and analytical perspective provides new insight into the structure of Bethe approximations in complex-valued problems and clarifies when such approximations remain meaningful beyond the non-negative-real-valued settings."
  },
  {
    "date": "2026-01-26",
    "title": "Error-mitigation aware benchmarking strategy for quantum optimization problems",
    "authors": "Marine Demarty, Bo Yang, Kenza Hammam, Pauline Besserve",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18680v1",
    "source": "arXiv",
    "abstract": "Assessing whether a noisy quantum device can potentially exhibit quantum advantage is essential for selecting practical quantum utility tasks that are not efficiently verifiable by classical means. For optimization, a prominent candidate for quantum advantage, entropy benchmarking provides insights based concomitantly on the specifics of the application and its implementation, as well as hardware noise. However, such an approach still does not account for finite-shot effects or for quantum error mitigation (QEM), a key near-term error suppression strategy that reduces estimation bias at the cost of increased sampling overhead. We address this limitation by developing a benchmarking framework that explicitly incorporates finite-shot statistics and the resource overhead induced by QEM. Our framework quantifies quantum advantage through the confidence that an estimated energy lies within an interval defined by the best-known classical upper and lower bounds. Using a proof-of-principle numerical study of the two-dimensional Fermi-Hubbard model at size $8\\times8$, we demonstrate that the framework effectively identifies noise and shot-budget regimes in which the probabilistic error cancellation (PEC), a representative QEM method, is operationally advantageous, and potential quantum advantage is not hindered by finite-shot effects. Overall, our approach equips end-users with a framework based on lightweight numerics for assessing potential practical quantum advantage in optimization on near-future quantum hardware, in light of the allocated shot budget."
  },
  {
    "date": "2026-01-26",
    "title": "An Adaptive Purification Controller for Quantum Networks: Dynamic Protocol Selection and Multipartite Distillation",
    "authors": "Pranav Kulkarni, Leo Sünkel, Michael Kölle",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18351v1",
    "source": "arXiv",
    "abstract": "Efficient entanglement distribution is the cornerstone of the Quantum Internet. However, physical link parameters such as photon loss, memory coherence time, and gate error rates fluctuate dynamically, rendering static purification strategies suboptimal. In this paper, we propose an Adaptive Purification Controller (APC) that autonomously optimizes the entanglement distillation sequence to maximize the \"goodput,\" the rate of delivered pairs meeting a strict fidelity threshold. By treating protocol selection as a resource allocation problem, the APC dynamically switches between purification depths and protocol families (e.g., BBPSSW vs. DEJMPS) to navigate the trade-off between generation rate and state quality. Using a dynamic programming planner with Pareto pruning, simulation results demonstrate that our approach eliminates the \"fidelity cliffs\" inherent in static protocols and prevents resource wastage in high-noise regimes. Furthermore, we extend the controller to heterogeneous scenarios, demonstrating robustness for both multipartite GHZ state generation and continuous variable systems using effective noiseless linear amplification models. We benchmark its computational overhead, confirming real-time feasibility with decision latencies in the millisecond range per link."
  },
  {
    "date": "2026-01-26",
    "title": "Pisets: A Robust Speech Recognition System for Lectures and Interviews",
    "authors": "Ivan Bondarenko, Daniil Grebenkin, Oleg Sedukhin, Mikhail Klementev, Roman Derunets, Lyudmila Budneva",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18415v1",
    "source": "arXiv",
    "abstract": "This work presents a speech-to-text system \"Pisets\" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of \"Pisets\" system is publicly available at GitHub: https://github.com/bond005/pisets."
  },
  {
    "date": "2026-01-26",
    "title": "The Cost of Inflation",
    "authors": "Vipin P Veetil",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18544v1",
    "source": "arXiv",
    "abstract": "Empirical evidence suggests that there is little to no correlation between the rate of inflation and the size of price change. Economists have hitherto taken this to mean that monetary shocks do not generate much deviation in relative prices and therefore inflation does not hurt the economy by impeding the workings of the price system. This paper presents a production network model of inflationary dynamics in which it is well possible for inflation to have near-zero correlation with the size of price change yet cause significant distortion of relative prices. The relative price distortion caused by inflation critically depends on the spectral gap, degree distribution, and assortativity of the production network."
  },
  {
    "date": "2026-01-26",
    "title": "Formation Dynamics of Quantum Droplets for Homonuclear and Heteronuclear Mixtures",
    "authors": "Enrique Calderoli, Gerardo Martinez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18541v1",
    "source": "arXiv",
    "abstract": "Great effort has been invested over the past decade in studying the properties of quantum droplets, a phase of bosonic quantum matter that arises as a consequence of the fluctuating Lee-Huang-Yang correction. However, the dynamics of droplet formation for heteronuclear Bose mixtures is partially understood. Here, we numerically analyze the formation process for homonuclear and heteronuclear boson mixtures in one dimension using a tight-binding model and real-time evolution. A systematic sweep of interaction strengths, mass ratios, and initial conditions allows us to characterize quantitative criteria for droplet formation and equilibration. We find that the energy contribution of the LHY correction dominates the energetic profile of the droplets formed, with the deepest binding occurring for mass ratios $m_2/m_1 \\in [1.2,2.0]$. Breathing oscillations are observed, and the low equilibration rate is consistent with the restricted nature of the phase space for one-dimensional systems; the oscillation frequency is found to have a very weak correlation to the interaction strengths. For the simulation, Gaussian over discrete initial conditions are clearly favorable to the formation of droplets. The results contained herein provide rich insight into the dynamical nature of quantum droplet physics."
  },
  {
    "date": "2026-01-26",
    "title": "Sufficient conditions for additivity of the zero-error classical capacity of quantum channels",
    "authors": "Jeonghoon Park, Jeong San Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18538v1",
    "source": "arXiv",
    "abstract": "The one-shot zero-error classical capacity of a quantum channel is the amount of classical information that can be transmitted with zero probability of error by a single use. Then the one-shot zero-error classical capacity equals to the logarithmic value of the independence number of the noncommutative graph induced by the channel. Thus the additivity of the one-shot zero-error classical capacity of a quantum channel is equivalent to the multiplicativity of the independence number of the noncommutative graph. The independence number is not multiplicative in general, and it is not clearly understood when the multiplicativity occurs. In this work, we present sufficient conditions for multiplicativity of the independence number, and we give explicit examples of quantum channels. Furthermore, we consider a block form of noncommutative graphs, and provide conditions when the independence number is multiplicative."
  },
  {
    "date": "2026-01-26",
    "title": "Exotic vortex states at high magnetic fields in a quasi-two-dimensional FeSe-based superconductor",
    "authors": "Xuyang Li, Jian Li, Kai Liu, Jiaqiang Cai, Shunjiao Li, Baolei Kang, Mengzhu Shi, Dan Zhao, Chuanying Xi, Jinglei Zhang, Tao Wu, Xianhui Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18531v1",
    "source": "arXiv",
    "abstract": "Owing to strong electronic correlations, high-temperature superconductivity always exhibits intricate intertwinement with various competing electronic orders in phase diagrams, such as spin/charge density waves (S/CDWs). In cuprate superconductors,the intertwinement of superconductivity and CDW order could strongly affect the fundamental properties of superconductivity, such as the critical temperature(Tc) and critical magnetic field(Hc). Recent high-field transport measurements indicate that when quantum fluctuations become important at low temperatures and high magnetic fields, the CDW order also reshapes the vortex states, which leads to fragile superconductivity with extremely low critical current(Jc). Here, by performing comprehensive high-field transport measurements, the H-T phase diagram of vortex states is mapped to H = 33 T in a quasi-two-dimensional FeSe-based superconductor (TBA+)xFeSe with a zero-resistivity transition temperature above 40 K. Our results indicate that (TBA+)xFeSe is an extremely type II superconductor with significant thermal fluctuations.At low temperatures, high magnetic fields cause the vortex solid state to exhibit similar current-dependent zero-resistance behavior as the fragile superconductivity in cuprate superconductors with CDW order. When the vortex solid state is melted with increasing temperature, a superconducting regime with vortex-like phase fluctuations emerges as an intermediate state, which features finite longitudinal resistance and vanishing Hall resistance. At higher temperatures, a vortex liquid state with finite Hall resistance eventually appears due to thermal fluctuations. All these observations suggest exotic vortex states beyond the classical paradigm of vortex matter."
  },
  {
    "date": "2026-01-26",
    "title": "Equicontinuity of the Hutchinson operator $F$ and sensitivity of $F_-$",
    "authors": "Aliasghar Sarizadeh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18530v1",
    "source": "arXiv",
    "abstract": "For an iterated function system $ \\mathcal{F} = \\{ f_1, \\dots, f_k \\} $ of homeomorphisms on a compact metric space $(X, d)$, write $ \\mathcal{F}_-= \\{ f_1^{-1}, \\dots, f_k^{-1} \\} $. The objective of this paper is to illustrate an iterated function system $\\mathcal{F}$ of homeomorphisms on the circle that the Hutchinson operator of $\\mathcal{F}$ is equicontinuous, but the Hutchinson operator of $\\mathcal{F}_-$ is sensitive."
  },
  {
    "date": "2026-01-26",
    "title": "Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmark",
    "authors": "Andro Sabashvili",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18509v1",
    "source": "arXiv",
    "abstract": "Reliable uncertainty quantification is of critical importance in time series forecasting, yet traditional methods often rely on restrictive distributional assumptions. Conformal prediction (CP) has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees. However, applying CP to sequential data presents a primary challenge: the temporal dependencies inherent in time series fundamentally violate the core assumption of data exchangeability, upon which standard CP guarantees are built. This review critically examines the main categories of algorithmic solutions designed to address this conflict. We survey and benchmark methods that relax the exchangeability assumption, those that redefine the data unit to be a collection of independent time series, approaches that explicitly model the dynamics of the prediction residuals, and online learning algorithms that adapt to distribution shifts to maintain long-run coverage. By synthesizing these approaches, we highlight computational efficiency and practical performance on real-world data."
  },
  {
    "date": "2026-01-26",
    "title": "Gravitational wave detectors from an experimental perspective",
    "authors": "Marina Trad-Nery, Margherita Turconi, Walid Chaibi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18501v1",
    "source": "arXiv",
    "abstract": "This chapter introduces the fundamental principles of gravitational wave detectors in a simple and comprehensive manner. Because these instruments aim for extremely high sensitivity, it is essential to understand their various noise sources, how such noise couples to the detector output, and the strategies used to mitigate them. These noises contributions are computed in the frame of the Virgo detector and a sensitivity curve is calculated. Although a simplified layout of a gravitational wave detector is considered, it takes into account the most dominant effects and yields in a sensitivity estimate close to the what is observed in real detectors."
  },
  {
    "date": "2026-01-26",
    "title": "Nearly Optimal Bayesian Inference for Structural Missingness",
    "authors": "Chen Liang, Donghua Yang, Yutong Wang, Tianle Zhang, Shenghe Zhou, Zhiyu Liang, Hengtong Zhang, Hongzhi Wang, Ziqi Li, Xiyang Zhang, Zheng Liang, Yifei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18500v1",
    "source": "arXiv",
    "abstract": "Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior."
  },
  {
    "date": "2026-01-26",
    "title": "Qubit-parity interference despite unknown interaction phases",
    "authors": "Kratveer Singh, Kimin Park, Vojtěch Švarc, Artem Kovalenko, Tuan Pham, Ondřej Číp, Lukáš Slodička, Radim Filip",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18499v1",
    "source": "arXiv",
    "abstract": "Quantum interference between interacting systems is fundamental to basic science and quantum technology, but it typically requires precise control of the interaction phases of lasers or microwave generators. Can interference be observed if those interaction phases are stable but unknown, usually prohibitive for complex state without active control? Here, we answer this question by experimentally preparing a Schrödinger-cat-like state of an internal qubit and a motional oscillator of a trapped $^{40}$Ca$^{+}$ ion, and its robustness to such uncontrolled phase. By applying alternating red and blue sideband pulses, we enforce a strict qubit-parity correlation and interference inherently insensitive to stable but unknown phases of the driving laser. For this qubit-parity interference, we use a minimal two-pulse interferometric sequence to demonstrate characteristic visibilities of $20\\%$ and $40\\%$, which approach the theoretical visibility limit, providing a scalable coherence witness without full state tomography for high-dimensional states."
  },
  {
    "date": "2026-01-26",
    "title": "AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security",
    "authors": "Dongrui Liu, Qihan Ren, Chen Qian, Shuai Shao, Yuejin Xie, Yu Li, Zhonghao Yang, Haoyu Luo, Peng Wang, Qingyu Liu, Binxin Hu, Ling Tang, Jilin Mei, Dadi Guo, Leitao Yuan, Junyao Yang, Guanxu Chen, Qihao Lin, Yi Yu, Bo Zhang, Jiaxuan Guo, Jie Zhang, Wenqi Shao, Huiqi Deng, Zhiheng Xi, Wenjie Wang, Wenxuan Wang, Wen Shen, Zhikai Chen, Haoyu Xie, Jialing Tao, Juntao Dai, Jiaming Ji, Zhongjie Ba, Linfeng Zhang, Yong Liu, Quanshi Zhang, Lei Zhu, Zhihua Wei, Hui Xue, Chaochao Lu, Jing Shao, Xia Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18491v1",
    "source": "arXiv",
    "abstract": "The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released."
  },
  {
    "date": "2026-01-26",
    "title": "Intertwiners for D=3 Gauge Theories",
    "authors": "P. A. Grassi, E. M. G. Landrò",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18490v1",
    "source": "arXiv",
    "abstract": "We apply the intertwiner operator method of arXiv:2411.08865 to topological field theories, including BF theories, Chern-Simons theory, and three-dimensional gravity. We construct the operator on foliated manifolds while preserving covariance on the Cauchy surface, and compare canonical and holomorphic quantization, providing the intertwiner in both frameworks. For three-dimensional gravity, we present both covariant and time-gauge formulations, analyze the constraints, and construct the corresponding intertwiner. As an application, we derive the path ordering of Wilson loops in Chern-Simons theory. The study of observables is left for future work."
  },
  {
    "date": "2026-01-26",
    "title": "Galactic Large-scale Filaments Resident in Asymmetric Environments: Clues from Cross-filament Profiles of Density and Temperature",
    "authors": "Keyun Su, Ke Wang, Fengwei Xu, N. K. Bhadari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18485v1",
    "source": "arXiv",
    "abstract": "Large-scale filaments ubiquitously exist in the Galactic interstellar medium, and their radial profiles offer insights into their formation mechanisms. We present a statistical analysis of molecular hydrogen column density ($\\rm N(H_2)$) and dust temperature ($\\rm T_d$) radial profiles for 35 Galactic large-scale filaments. We divided their spines into 315 segments, extracted the radial profiles of each segment using $\\rm N(H_2)$ and $\\rm T_d$ maps derived from $Herschel$ Hi-GAL data, and estimated the asymmetry degree within the radial profiles ($α_{\\rm asy}$), as well as the length proportion of segments with asymmetric profiles across the entire filament ($f_{\\rm asy}$). We found that Galactic large-scale filaments reside in surroundings distinctly asymmetric and varied in $\\rm N(H_2)$, and mild asymmetric yet stable in $\\rm T_d$. Different filament morphology types do not show significant differences in $α_{\\rm asy}$ or $f_{\\rm asy}$. A bent filament shape does not necessarily correspond to an asymmetric radial profile, whereas a straight filament shape may be associated with a symmetric profile. Segments with asymmetric surroundings in $\\rm N(H_2)$ may not simultaneously appear asymmetric in $\\rm T_d$, and vice versa. We found three filaments with 4-44% of their spine show asymmetric $\\rm N(H_2)$ and $\\rm T_d$ radial profiles in inverse trends, likely caused by nearby HII region. HII regions of similar scale to large filaments can induce asymmetric radial profiles within them, indicating their influence on filament evolution. However, they are unlikely to independently trigger the formation of an entire Galactic large-scale filament, in contrast to their role in small-scale filament formation."
  },
  {
    "date": "2026-01-26",
    "title": "Tensor decomposition of Demazure crystals for symmetrizable Kac-Moody Lie algebras",
    "authors": "Divya Setia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18484v1",
    "source": "arXiv",
    "abstract": "We study the tensor product of Demazure crystals for symmetrizable Kac-Moody Lie algebras. It is not necessary that the tensor product of Demazure crystals is isomorphic to a disjoint union of Demazure crystals. In this paper, we provide necessary and sufficient conditions for the decomposition of the tensor product of Demazure crystals as a disjoint union of Demazure crystals. Our results are the generalization of the results proved by Anthony Joseph and Takafumi Kouno. As an application, we obtain a sufficient condition when the product of Demazure characters is a linear combination of Demazure characters with nonnegative integer coefficients. In particular, we obtain a partial solution for the key positivity problem."
  },
  {
    "date": "2026-01-26",
    "title": "Uncertainty Quantification in Coupled Multiphysics Systems via Gaussian Process Surrogates: Application to Fuel Assembly Bow",
    "authors": "Ali Abboud, Josselin Garnier, Bertrand Leturcq, Stanislas de Lambert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18480v1",
    "source": "arXiv",
    "abstract": "Predicting fuel assembly bow in pressurized water reactors requires solving tightly coupled fluid-structure interaction problems, whose direct simulations can be computationally prohibitive, making large-scale uncertainty quantification (UQ) very challenging. This work introduces a general mathematical framework for coupling Gaussian process (GP) surrogate models representing distinct physical solvers, aimed at enabling rigorous UQ in coupled multiphysics systems. A theoretical analysis establishes that the predictive variance of the coupled GP system remains bounded under mild regularity and stability assumptions, ensuring that uncertainty does not grow uncontrollably through the iterative coupling process. The methodology is then applied to the coupled hydraulic-structural simulation of fuel assembly bow, enabling global sensitivity analysis and full UQ at a fraction of the computational cost of direct code coupling. The results demonstrate accurate uncertainty propagation and stable predictions, establishing a solid mathematical basis for surrogate-based coupling in large-scale multiphysics simulations."
  },
  {
    "date": "2026-01-26",
    "title": "LoD-Structured 3D Gaussian Splatting for Streaming Video Reconstruction",
    "authors": "Xinhui Liu, Can Wang, Lei Liu, Zhenghao Chen, Wei Jiang, Wei Wang, Dong Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18475v1",
    "source": "arXiv",
    "abstract": "Free-Viewpoint Video (FVV) reconstruction enables photorealistic and interactive 3D scene visualization; however, real-time streaming is often bottlenecked by sparse-view inputs, prohibitive training costs, and bandwidth constraints. While recent 3D Gaussian Splatting (3DGS) has advanced FVV due to its superior rendering speed, Streaming Free-Viewpoint Video (SFVV) introduces additional demands for rapid optimization, high-fidelity reconstruction under sparse constraints, and minimal storage footprints. To bridge this gap, we propose StreamLoD-GS, an LoD-based Gaussian Splatting framework designed specifically for SFVV. Our approach integrates three core innovations: 1) an Anchor- and Octree-based LoD-structured 3DGS with a hierarchical Gaussian dropout technique to ensure efficient and stable optimization while maintaining high-quality rendering; 2) a GMM-based motion partitioning mechanism that separates dynamic and static content, refining dynamic regions while preserving background stability; and 3) a quantized residual refinement framework that significantly reduces storage requirements without compromising visual fidelity. Extensive experiments demonstrate that StreamLoD-GS achieves competitive or state-of-the-art performance in terms of quality, efficiency, and storage."
  },
  {
    "date": "2026-01-26",
    "title": "\"Infinitely Often\" Transcendence of Gamma-Function Derivatives",
    "authors": "Michael R. Powers",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18474v1",
    "source": "arXiv",
    "abstract": "Relatively little is known about the arithmetic properties of Gamma-function derivatives evaluated at arbitrary points $q\\in\\mathbb{Q}\\setminus\\mathbb{Z}_{\\leq0}$. In recent work, we showed that elements of the sequence $\\left\\{ Γ^{\\left(n\\right)}\\left(1\\right)\\right\\} _{n\\geq1}$ are transcendental infinitely often. This result is now generalized to all sequences $\\left\\{ Γ^{\\left(n\\right)}\\left(q\\right)\\right\\} _{n\\geq1}$ for $q\\in\\tfrac{1}{2}\\mathbb{Z}\\setminus\\mathbb{Z}_{\\leq0}$. Furthermore, for $q\\in\\mathbb{Q}\\setminus\\tfrac{1}{2}\\mathbb{Z}$ we show that at least one of the sequences $\\left\\{ Γ^{\\left(n\\right)}\\left(q\\right)\\right\\} _{n\\geq1}$, $\\left\\{ Γ^{\\left(n\\right)}\\left(1-q\\right)\\right\\} _{n\\geq1}$ contains infinitely many transcendental elements."
  },
  {
    "date": "2026-01-26",
    "title": "Spontaneous epicuticular charging affects droplet dynamics on living leaves",
    "authors": "Mihir Durve, Serena Armiento, Benham Kamare, Sauro Succi, Barbara Mazzolai, Fabian Meder",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18465v1",
    "source": "arXiv",
    "abstract": "How water droplets move and slide on leaves influences plant ecophysiological and abiotic interactions, as well as the design of advanced bio-inspired wetting materials. Despite cross-disciplinary relevance, current descriptions of the in situ dynamics of droplets on living leaves focus almost exclusively on surface structure and chemistry, treating the leaf as a static, electrically neutral substrate. Here, three decades after the mechanistic discovery of the Lotus effect, we show that a yet 'hidden' force due to instantaneous electrical phenomena affect the dynamic droplet motion on living leaves. Using high-speed motion tracking and precision charge measurements, we show that droplets sliding on the pristine epicuticular wax layer on superhydrophobic Colocasia esculenta leaves strongly charge affecting its dynamics, previously observed only on synthetic (highly electronegative fluorinated) surfaces. Droplets accumulate charges of Qp,D1 = -0.02 to -0.15 nC per 30 uL droplet on pristine leaves. However, we specifically demonstrate the crucial role of the epicuticular wax layer plasticity: by a structural modification that decreases its roughness amplitude, the same leaves gain an impressive 30-40 fold enhancement in charge transfer (reaching Qt,D1 = -2.8 to -5.2 nC) slowing the droplet by half due to an estimated electrostatic force of 11 uN dominating the resistive forces. The charge accumulation is surface-history-dependent and charge quantities per droplet are surprisingly similar or even exceeding those recently reported from artificial surfaces. Our findings prove that electrostatic charging is a fundamental component of droplet-leaf interactions, opening new research directions from charge-affected leaf ecology to sustainable materials for droplet-based energy harvesting by tuning surface treatments and, moreover,..."
  },
  {
    "date": "2026-01-26",
    "title": "Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System",
    "authors": "Wenbin Wei, Suyuan Yao, Cheng Huang, Xiangyu Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18464v1",
    "source": "arXiv",
    "abstract": "Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity."
  },
  {
    "date": "2026-01-26",
    "title": "Measurement induced faster symmetry restoration in quantum trajectories",
    "authors": "Katha Ganguly, Bijay Kumar Agarwalla",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18458v1",
    "source": "arXiv",
    "abstract": "Continuous measurement of quantum systems provides a standard route to quantum trajectories through the successive acquisition of information which further results in measurement back-action. In this work, we harness this back-action as a resource for global $U(1)$ symmetry restoration where continuous measurement is combined with a $U(1)$-preserving unitary evolution. Starting from a $U(1)$ symmetry-broken initial state, we simulate quantum trajectories generated by continuous measurements of both global and local observables. We show that under global monitoring, states containing superpositions of distant charge sectors restore symmetry faster than those involving nearby sectors. We establish the universality of this behavior across different measurement protocols. Finally, we demonstrate that local monitoring can further accelerate symmetry restoration for certain states that relax slowly under global monitoring."
  },
  {
    "date": "2026-01-26",
    "title": "A stabilized finite element method for a flow problem arising from 4D flow magnetic resonance imaging",
    "authors": "Gabriel Barrenechea, Cristian Cárcamo, Abner Poza",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18454v1",
    "source": "arXiv",
    "abstract": "In this work we propose, {analyze}, and validate a stabilized finite element method for a flow problem arising from the assessment of {4D Flow Magnetic Resonance Imaging quality}. Starting from the Navier-Stokes equation and splitting its velocity as the MRI-observed one (considered a datum) plus an ``observation error'', a modified Navier-Stokes problem is derived. This procedure allows us to estimate the quality of the measured velocity fields, while also providing an alternative approach to pressure reconstruction, thereby avoiding invasive procedures. Since equal-order approximations have become a popular choice for problems linked to pressure recovery from MRI images, we design a stabilized finite element method allowing equal-order interpolations for velocity and pressure. In the linearized version of the resulting model, we prove stability and (optimal order) error estimates and test the method with a variety of numerical experiments testing both the linearized case and the more realistic nonlinear one."
  },
  {
    "date": "2026-01-26",
    "title": "On Higher Representation Theory via Categories of type Charge-Conserving--with--Glue",
    "authors": "Paul P Martin, Sarah Almateari, Eric C Rowell",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18452v1",
    "source": "arXiv",
    "abstract": "In this paper we introduce a strict monoidal subcategory of the category of matrices, suitable to address a higher representation theoretic analogue of radicals (non-semisimplicity) in ordinary representation theory. We show the extent to which this analogue has analogous representation theoretic properties. To illustrate, we apply to two key problems in the study of braid representations (strict monoidal functors from the braid category $\\mathsf{B}$ to the matrix category): the classification problem; and the problem of analysing the ordinary braid group representations that braid representations generate in towers."
  },
  {
    "date": "2026-01-26",
    "title": "Enhanced Wall Boundary Modeling for Turbulent Flows Using the Lattice Boltzmann Method with Adaptive Cartesian Grids",
    "authors": "Jorge Ponsin, Carlos Lozano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18443v1",
    "source": "arXiv",
    "abstract": "We propose an enhanced wall-boundary treatment for the lattice Boltzmann method (LBM), designed for high-Reynolds-number turbulent flows on adaptively refined Cartesian grids. The method improves the slip-velocity bounce-back scheme by coupling it with a near-wall turbulence model based on an analytical wall function. The Spalart-Allmaras (negative) turbulence model is solved using a second-order finite-difference scheme and integrated within the LBM framework to statistically represent the Reynolds-Averaged Navier-Stokes (RANS) equations (LBM-RANS). The approach is validated on two benchmark configurations: the National Advisory Committee for Aeronautics (NACA) 0012 airfoil and the McDonnell Douglas (MD)-30P30N multi-element high-lift configuration. LBM-RANS results show good agreement with conventional finite-volume RANS solutions and experimental data for key aerodynamic quantities, including pressure and skin-friction distributions, as well as turbulent boundary layer velocity profiles and eddy-viscosity fields. The method delivers smooth and accurate predictions of skin friction, which are often challenging for immersed-boundary approaches on Cartesian grids. The auxiliary geometric data required for enforcing the turbulent boundary condition are minimal, making the method potentially well-suited for graphics processing unit (GPU)-based implementations. Moreover, no ad-hoc near-wall treatments are needed, as the boundary condition is applied naturally via the link-wise bounce-back scheme. These results illustrate that the proposed LBM-RANS framework can robustly and accurately simulate high-Reynolds-number turbulent two-dimensional (2D) flows over complex aerodynamic geometries under equilibrium or near-equilibrium conditions."
  },
  {
    "date": "2026-01-26",
    "title": "Algebraic Characterizations of Classes of Regular Languages in DynFO",
    "authors": "Corentin Barloy, Felix Tschirbs, Nils Vortmeier, Thomas Zeume",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18429v1",
    "source": "arXiv",
    "abstract": "This paper explores the fine-grained structure of classes of regular languages maintainable in fragments of first-order logic within the dynamic descriptive complexity framework of Patnaik and Immerman. A result by Hesse states that the class of regular languages is maintainable by first-order formulas even if only unary auxiliary relations can be used. Another result by Gelade, Marquardt,and Schwentick states that the class of regular languages coincides with the class of languages maintainable by quantifier-free formulas with binary auxiliary relations. We refine Hesse's result and show that with unary auxiliary data formulas with one quantifier alternation can maintain all regular languages. We then obtain precise algebraic characterizations of the classes of languages maintainable with quantifier-free formulas and positive existential formulas in the presence of unary auxiliary relations."
  },
  {
    "date": "2026-01-26",
    "title": "A Theory of Single-Antenna Atomic Beamforming",
    "authors": "Mingyao Cui, Qunsong Zeng, Kaibin Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18426v1",
    "source": "arXiv",
    "abstract": "Leveraging the quantum advantages of highly excited atoms, Rydberg atomic receivers (RAREs) represent a paradigm shift in radio wave detection, offering high sensitivity and broadband reception. However, existing studies largely model RAREs as isotropic point receivers and overlook the spatial variations of atomic quantum states within vapor cells, thus inaccurately characterizing their reception patterns. To address this issue, we present a theoretical analysis of the aforementioned spatial responses of a standard local-oscillator (LO)- dressed RARE. Our results reveal that increasing the vapor-cell length produces a receive beam aligned with the LO field, with a beamwidth inversely proportional to the cell length. This finding enables atomic beamforming to enhance received signal-to-noise ratio using only a single-antenna RARE. Furthermore, we derive the achievable beamforming gain by characterizing and balancing the fundamental tradeoff between the effects of increasing the vapor cell length and the exponential power decay of laser propagating through the cell. To overcome the limitation imposed by exponential decay, we propose a novel RARE architecture termed segmental vapor cell. This architecture consists of vapor-cell segments separated by clear-air gaps, allowing the total cell length (and hence propagation loss) to remain fixed while the effective cell length increases. As a result, this segmented design expands the effective atom-field interaction area without increasing the total vapor cell length, yielding a narrower beamwidth and thus higher beamforming gain as compared with a traditional continuous vapor cell."
  },
  {
    "date": "2026-01-26",
    "title": "Gradient Regularized Natural Gradients",
    "authors": "Satya Prakash Dash, Hossein Abdi, Wei Pan, Samuel Kaski, Mingfei Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18420v1",
    "source": "arXiv",
    "abstract": "Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning."
  },
  {
    "date": "2026-01-26",
    "title": "Larger than memory image processing",
    "authors": "Jon Sporring, David Stansby",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18407v1",
    "source": "arXiv",
    "abstract": "This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory."
  },
  {
    "date": "2026-01-26",
    "title": "Validity of the stochastic Ginzburg-Landau approximation in higher space dimensions -A Wiener algebra approach-",
    "authors": "Anna Logioti, Guido Schneider",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18406v1",
    "source": "arXiv",
    "abstract": "We consider an anisotropic $d$-dimensional Swift-Hohenberg model $ \\mathcal{O}(\\varepsilon^2) $-close to the first instability, where $ 0 < \\varepsilon \\ll 1 $ is a small perturbation parameter. This model for pattern formation is perturbed with additive noise in time and space. By a multiple scaling ansatz we derive a stochastic $ d $-dimensional Ginzburg-Landau equation for the approximate description of the bifurcating solutions. We prove the validity of the approximation by this amplitude equation on its natural time scale in case of $ d $-dimensional periodic domains of length $ \\mathcal{O}(1/\\varepsilon) $ for the Swift-Hohenberg model under suitable conditions on the additive noise. In detail, we prove the validity of this approximation for noise whose set of Fourier coefficients with respect to $ x $ is in $ \\ell^1 $ for fixed $ t \\geq 0 $. Moreover, we improve existing approximation results in the sense that the stable part of the noise can be larger."
  },
  {
    "date": "2026-01-26",
    "title": "Flash evaporation Riemann Problem: Formulation and its Exact Solution",
    "authors": "Haotong Bai, Ping Yi, Yixin Yang, Guoyan Zhao, Wenjia Xie, Mingbo Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18404v1",
    "source": "arXiv",
    "abstract": "Flash evaporation, a liquid-to-gas phase transition phenomenon in real fluids, is prevalent in aerospace propulsion systems. To elucidate the physical mechanisms of such complex flows and provide theoretical benchmarks for Computational Fluid Dynamics simulations, this paper formalizes the Flash evaporation Riemann problem (FeRP) characterized by the expansion branch crossing the saturation line, within the framework of Homogeneous Equilibrium and Vapor-Liquid Equilibrium assumptions. An exact solution framework that analytically resolves all thermodynamic derivatives of equilibrium two-phase fluids is established for arbitrary two-parameter equations of state. By evaluating the Landau fundamental derivative, the non-classical wave structures arising in the FeRP are analyzed, for which a stable iterative solution strategy incorporating the Chapman-Jouguet condition as an outer constraint is proposed. Furthermore, an exact solution for the FeRP based on Wood's mechanical equilibrium speed of sound is developed, enabling a comprehensive evaluation of its thermodynamic implications. Results indicate that Wood's model alters the definition of the two-phase mixture entropy in the Euler equations, introducing an isentropic path characterized by a \"density lag\" effect and non-physical entropy decrease. Comparative analysis of the FeRP under typical scramjet fuel injection conditions reveals that, although Wood's model captures the general trend of the Riemann solution curve, it significantly underestimates intermediate pressure, velocity, and the extent of vaporization relative to the complete equilibrium model."
  },
  {
    "date": "2026-01-26",
    "title": "On the Bandwidth Consumption of Blockchains",
    "authors": "Andrei Lebedev, Vincent Gramoli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18400v1",
    "source": "arXiv",
    "abstract": "With the advent of blockchain technology, the number of proposals has boomed. The network traffic imposed by these blockchain proposals increases the cost of hosting nodes. Unfortunately, as of today, we are not aware of any comparative study of the bandwidth consumption of blockchains. In this paper, we propose the first empirical comparison of blockchain bandwidth consumption. To this end, we measure the network traffic of blockchain network nodes of five blockchain protocols: Algorand, Aptos, Avalanche, Redbelly and Solana. We study the variation over time, differentiate the receiving and sending traffic and analyze how this traffic varies with the number of nodes and validators. We conclude that the transport protocol is the main factor impacting the network traffic, segregating node roles helps reduce traffic and different blockchains are differently impacted by the network size."
  },
  {
    "date": "2026-01-26",
    "title": "Testing residual-symmetry-fixed columns of $U_{\\rm PMNS}$ at DUNE and T2HK with initial JUNO constraints",
    "authors": "Debajyoti Dutta, Srubabati Goswami, Monal Kashav, Ketan M. Patel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18397v1",
    "source": "arXiv",
    "abstract": "We study fixed-column predictions of the lepton mixing matrix that arise from residual symmetries originating in a class of discrete flavour and modular symmetries. While the recent high-precision determination of $\\sin^{2}θ_{12}$ by JUNO already constrains part of these predictions, the remaining ones are primarily characterized by non-trivial correlations between $\\sin^{2}θ_{23}$ and the Dirac CP phase $δ_{\\rm CP}$, which are currently only weakly constrained. This motivates a detailed investigation using next-generation long-baseline neutrino experiments. For the viable scenarios, we derive precise $\\sin^{2}θ_{23}$-$δ_{\\rm CP}$ correlations and use them to generate test-event samples, marginalising over the remaining oscillation parameters. We perform detailed simulations for DUNE and T2HK, presenting allowed regions in the $\\sin^{2}θ_{23}$-$δ_{\\rm CP}$ plane and evaluating the CP-violation fraction as a function of exposure. Our results show that the combined sensitivity of DUNE and T2HK provides a robust test of fixed-column lepton-mixing predictions."
  },
  {
    "date": "2026-01-26",
    "title": "Noise-Robust AV-ASR Using Visual Features Both in the Whisper Encoder and Decoder",
    "authors": "Zhengyang Li, Thomas Graave, Björn Möller, Zehang Wu, Matthias Franz, Tim Fingscheidt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18396v1",
    "source": "arXiv",
    "abstract": "In audiovisual automatic speech recognition (AV-ASR) systems, information fusion of visual features in a pre-trained ASR has been proven as a promising method to improve noise robustness. In this work, based on the prominent Whisper ASR, first, we propose a simple and effective visual fusion method -- use of visual features both in encoder and decoder (dual-use) -- to learn the audiovisual interactions in the encoder and to weigh modalities in the decoder. Second, we compare visual fusion methods in Whisper models of various sizes. Our proposed dual-use method shows consistent noise robustness improvement, e.g., a 35% relative improvement (WER: 4.41% vs. 6.83%) based on Whisper small, and a 57% relative improvement (WER: 4.07% vs. 9.53%) based on Whisper medium, compared to typical reference middle fusion in babble noise with a signal-to-noise ratio (SNR) of 0dB. Third, we conduct ablation studies examining the impact of various module designs and fusion options. Fine-tuned on 1929 hours of audiovisual data, our dual-use method using Whisper medium achieves 4.08% (MUSAN babble noise) and 4.43% (NoiseX babble noise) average WER across various SNRs, thereby establishing a new state-of-the-art in noisy conditions on the LRS3 AV-ASR benchmark. Our code is at https://github.com/ifnspaml/Dual-Use-AVASR"
  },
  {
    "date": "2026-01-26",
    "title": "Tensor-polarized parton distribution functions for spin-1 hadrons",
    "authors": "S. Kumano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18391v1",
    "source": "arXiv",
    "abstract": "Spin-1 hadrons contain different aspects of spin physics from the ones of the spin-1/2 nucleon because of the existence of tensor-polarized structure functions. In the charged-lepton deep inelastic scattering from a spin-1 hadron or nucleus, such as the deuteron, there are leading-twist structure functions $b_1$ and $b_2$. In addition, there exists a gluon transversity which does not exist in the spin-1/2 nucleon. In the deuteron, these observables could probe interesting dynamical aspects beyond a simple bound system of a proton and a neutron. In addition, there are recent theoretical studies on higher-twist distributions. Tensor-polarized deuteron experiments are now under preparation at the Thomas Jefferson National Accelerator Facility, so that the topic of polarized deuteron is expected to become one of exciting fields in hadron physics. This paper is a brief overview on the tensor-polarized parton distribution functions, including transverse-momentum-dependent parton distributions and fragmentation functions up to twist 4."
  },
  {
    "date": "2026-01-26",
    "title": "ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks",
    "authors": "Gabriel Lee Jun Rong, Christos Korgialas, Dion Jia Xu Ho, Pai Chet Ng, Xiaoxiao Miao, Konstantinos N. Plataniotis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18386v1",
    "source": "arXiv",
    "abstract": "Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk\". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score."
  },
  {
    "date": "2026-01-26",
    "title": "Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models",
    "authors": "Zhenyuan Guo, Tong Chen, Wenlong Meng, Chen Gong, Xin Yu, Chengkun Wei, Wenzhi Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18383v1",
    "source": "arXiv",
    "abstract": "Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency."
  },
  {
    "date": "2026-01-26",
    "title": "On the relation between time-reversed acoustics and Green's function retrieval in space-variant and in time-variant materials",
    "authors": "Kees Wapenaar, Johannes Aichele, Dirk-Jan van Manen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18382v1",
    "source": "arXiv",
    "abstract": "The methods of time-reversed acoustics and Green's function retrieval are traditionally deployed for classical inhomogeneous, time-invariant materials. The mutual relation between these methods is well-established. Recently, similar methods have been proposed for homogeneous, time-variant materials. Here we investigate their mutual relation and their relation with the corresponding methods in classical materials. For this analysis we make use of the fact that the wave equations for both types of material are similar, with the roles of time and space interchanged. However, the principle of causality holds for both types of material, hence, here the roles of time and space are not interchanged. We find that: (1) whereas classical time-reversed acoustics involves emission of a time-reversed single-component wave field from a (ideally closed) boundary into the inhomogeneous material, its idealized counterpart involves emission of a sign-reversed two-component wave field, recorded in a time-reversed material, from a single time instant into the actual time-variant material; (2) whereas classical Green's function retrieval involves temporal crosscorrelation of wave fields at two space locations in response to single-component sources on a (ideally closed) boundary, its counterpart involves spatial crosscorrelation of wave fields at two time instants in response to two-component sources at a single time instant."
  },
  {
    "date": "2026-01-26",
    "title": "Corpus-Based Approaches to Igbo Diacritic Restoration",
    "authors": "Ignatius Ezeani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18380v1",
    "source": "arXiv",
    "abstract": "With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work. In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors."
  },
  {
    "date": "2026-01-26",
    "title": "OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI",
    "authors": "Caterina Fuster-Barceló, Claudia Castrillón, Laura Rodrigo-Muñoz, Victor Manuel Vega-Suárez, Nicolás Pérez-Fernández, Gorka Bastarrika, Arrate Muñoz-Barrutia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18368v1",
    "source": "arXiv",
    "abstract": "We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention. Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic. These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear."
  },
  {
    "date": "2026-01-26",
    "title": "Physical Features of Geometrically Deformed Anisotropic Charged Three-dimensional BTZ Black Holes",
    "authors": "Z. Yousaf, Kazuharu Bamba, Mansoor Alshehri, S. Khan, M. Z. Bhatti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18367v1",
    "source": "arXiv",
    "abstract": "This work employs the minimal geometric deformation decoupling scheme to derive interior stellar solutions in the background of an electrically charged BTZ ansatz as a seed metric in three dimensions. In this respect, we impose two different equations of state to determine the deformation function and the new material contributions emerging from the additional field source. Furthermore, we describe the finiteness of all thermodynamic quantities of the presented stellar solutions, including the effective thermodynamical quantities, for varying values of the deformation parameter and total electric charge. We explore the new interior astrophysical solutions in three-dimensional gravity by analyzing the charged BTZ metric, admitting circular symmetry through the principles of geometric deformation. This study examines the impact of radial-metric deformation on the charged BTZ geometry and underscores the importance of stellar decoupling within the context of electrically charged dense distributions. It is shown that new physically acceptable solutions by incorporating any known three-dimensional spacetime as the isotropic basis are possible, which in turn enable one to analyze the quantum effects due to low degrees of freedom at lower dimensions."
  },
  {
    "date": "2026-01-26",
    "title": "Bohr's complementarity principle tested on a real quantum computer via interferometer experiments",
    "authors": "Celia Álvarez Álvarez, Mariamo Mussa Juane",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18366v1",
    "source": "arXiv",
    "abstract": "Bohr's Complementarity Principle is a core concept of quantum mechanics. In this article, an updated complementarity relation for the wave and ondulatory aspects of a quantum system is presented and discussed. Two interferometric experiments are implemented in one and two qubit circuits and executed on real hardware. The final state density matrices are reconstructed using quantum state tomography and the complementarity relation is tested via direct computation. Results of the executions are presented both graphically and with a mean squared error analysis for a better comprehension."
  },
  {
    "date": "2026-01-26",
    "title": "Polyhedral results for two classes of submodular sets with GUB constraints",
    "authors": "Weikang Qian, Keyan Li, Wei-Kun Chen, Yu-Hong Dai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18360v1",
    "source": "arXiv",
    "abstract": "In this paper, we investigate the polyhedral structure of two submodular sets with generalized upper bound (GUB) constraints, which arise as important substructures in various real-world applications. We derive a class of strong valid inequalities for the two sets using sequential lifting techniques. The proposed lifted inequalities are facet-defining for the convex hulls of two sets and are stronger than the well-known extended polymatroid inequalities (EPIs). We provide a more compact characterization of these inequalities and show that each of them can be computed in linear time. Moreover, the proposed lifted inequalities, together with bound and GUB constraints, can completely characterize the convex hulls of the two sets, and can be separated using a combinatorial polynomial-time algorithm. Finally, computational results on probabilistic covering location and multiple probabilistic knapsack problems demonstrate the superiority of the proposed lifted inequalities over the EPIs within a branch-and-cut framework."
  },
  {
    "date": "2026-01-26",
    "title": "Resolution Dependence in Magnetohydrodynamic Simulations of Neutrino-Driven Core-Collapse Supernovae",
    "authors": "Vishnu Varma, Bernhard Müller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18357v1",
    "source": "arXiv",
    "abstract": "We investigate the role of resolution and initial magnetic field strength on core-collapse supernovae in simulations of a non-rotating $13 \\mathrm{M_\\odot}$ progenitor. Specifically, we study the effect on shock revival, explosion dynamics, and the properties of the compact remnant. We run four models with different numerical grid resolutions with an initial central dipole field strength of $\\mathord{\\approx}10^{12}\\, \\mathrm{G}$. Two of those resolutions are also run with a weaker central magnetic field of $\\mathord{\\approx}10^{10}\\, \\mathrm{G}$ . The shock revival time for all models is largely independent of resolution and initial magnetic field strength, but we find higher explosion energies when the initial magnetism is stronger and at higher resolutions. We find that models with strong magnetic fields have lower neutrino luminosity and energies, due to a proto-neutron star (PNS) that is deformed by the strong magnetic fields. At higher resolutions, magnetic fields are amplified more efficiently in the gain region and in the PNS via the small-scale dynamo. Although the strong magnetic fields do not directly drive the explosion, they have a subsidiary impact on the explosion mechanism and compensate for the reduced neutrino heating. Stronger magnetic energies in the PNS also affect energy and angular momentum redistribution, leading to more extended and vigorous PNS convection zones at higher resolutions."
  },
  {
    "date": "2026-01-26",
    "title": "Promises, Perils, and (Timely) Heuristics for Mining Coding Agent Activity",
    "authors": "Romain Robes Théo Matricon, Thomas Degueule, Andre Hora, Stefano Zacchiroli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18345v1",
    "source": "arXiv",
    "abstract": "In 2025, coding agents have seen a very rapid adoption. Coding agents leverage Large Language Models (LLMs) in ways that are markedly different from LLM-based code completion, making their study critical. Moreover, unlike LLM-based completion, coding agents leave visible traces in software repositories, enabling the use of MSR techniques to study their impact on SE practices. This paper documents the promises, perils, and heuristics that we have gathered from studying coding agent activity on GitHub."
  },
  {
    "date": "2026-01-26",
    "title": "Stratified Morse Theory for Cell Complexes",
    "authors": "Vidit Nanda, Francesca Tombari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18343v1",
    "source": "arXiv",
    "abstract": "We develop a version of discrete Morse theory for finite regular CW complexes equipped with an auxiliary stratification. The key construction is the halo of a cell, which contains all those faces in the boundary that enter closed sublevelsets precisely when the threshold reaches that cell's value. The complement of this halo in the boundary, called the shadow, is always a subcomplex. A stratified discrete Morse function requires Forman's conditions on each stratum together with the requirement that closures of paired cells admit filtered collapses onto their shadows. We establish fundamental Morse lemmas: filtered collapses across regular intervals, and controlled attachments at critical values. For functions satisfying only the stratum-wise Forman condition, we construct an upper envelope on the barycentric subdivision whose local Morse data decomposes into horizontal and vertical components. This yields a simplicial analogue of the standard tangential-normal splitting of local Morse data in the sense of Goresky and MacPherson."
  },
  {
    "date": "2026-01-26",
    "title": "Precision Light Yield and Crosstalk Characterization for the SuperFGD scintillator cubes",
    "authors": "I. Alekseev, A. Chvirova, M. Danilov, S. Fedotov, A. Khotjantsev, M. Kolupanova, N. Kozlenko, A. Krapiva, Y. Kudenko, A. Mefodiev, O. Mineev, D. Novinsky, E. Samigullin, N. Skrobova, D. Svirida",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18338v1",
    "source": "arXiv",
    "abstract": "A detailed study of a $5\\times5\\times5$ cube prototype of the SuperFGD detector was performed using a 730 MeV/$c$ pion beam at the SC-1000 synchrocyclotron (PNPI, Gatchina, Russia). The detector, based on plastic scintillation cubes with orthogonal wavelength-shifting (WLS) fiber readout and silicon photomultipliers (SiPMs), was tested to evaluate its performance in terms of light yield, spatial uniformity, and optical crosstalk. Using high-resolution tracking, the spatial distribution of light yield was mapped with a granularity of 0.5 mm. An average light response map was obtained by combining data from 27 cubes. Optical crosstalk between adjacent cubes was also measured and characterized in four directions (left, right, up, down). Position-dependent crosstalk values ranged from 2% to 6%, with the highest levels observed near cube interfaces. These results confirm the excellent performance and scalability of the SuperFGD design, and provide valuable input for simulation tuning and reconstruction algorithms in the ND280 upgrade of the T2K experiment. The obtained result on the response uniformity and crosstalk are reasonably well described by simple MC model of the setup."
  },
  {
    "date": "2026-01-26",
    "title": "Quantum-vortex-driven Kelvin wave in the thermal background of superfluid helium",
    "authors": "Simone Scollo, Luca Galantucci, Giorgio Krstulovic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18337v1",
    "source": "arXiv",
    "abstract": "We present numerical evidence that Kelvin waves (KWs) on quantized vortices in superfluid helium can be directly observed in the normal fluid component at finite temperatures. Using the Fully cOUpled loCAl model of sUperfLuid Turbulence (FOUCAULT) model, we analyze the propagation and temperature dependence of KWs by simultaneously measuring the dispersion of waves on the vortex displacement and the normal fluid velocity. The results demonstrate that the normal fluid supports a coherent KW-like response, with a dispersion relation matching that of the vortex filament (VF). Unlike the Schwarz model where there is almost no temperature dependence, in FOUCAULT KWs frequency and damping both depend on temperature, highlighting the role of mutual friction in mediating the coupling between the two fluids. These findings open a pathway for experimental observation of KWs in the normal phase using tracer based visualization."
  },
  {
    "date": "2026-01-26",
    "title": "Recurrence Relations for the Maclaurin Coefficients of Products of Elementary Functions and the Bessel Functions",
    "authors": "Zhong-Xuan Mao, Jing-Feng Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18332v1",
    "source": "arXiv",
    "abstract": "In this paper, we investigate recurrence relations for the Maclaurin coefficients of the products of a elementary function and the Bessel function of the first kind $\\mathcal{J}(z) = h(z) J_ν(z)$ and the modified Bessel function of the first kind $\\mathcal{I}(z) = h(z) I_ν(z)$ in the complex plane corresponding to several specific choices of $h(z)$. In particular, we specialize $h(z)$ as $e^{pz}$, $(1-θz)^p$, $e^{-p \\arctan z}$, $\\sin(pz)$, $\\cos(pz)$, $\\sinh(pz)$, $\\cosh(pz)$, $\\arcsin(pz)$ and $\\arccos(pz)$."
  },
  {
    "date": "2026-01-26",
    "title": "MarioChart: Autonomous Tangibles as Active Proxy Interfaces for Embodied Casual Data Exploration",
    "authors": "Shaozhang Dai, Kadek Ananta Satriadi, Jim Smiley, Barrett Ens, Lonni Besançon, Tim Dwyer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18328v1",
    "source": "arXiv",
    "abstract": "We introduce the notion of an Active Proxy interface, i.e. tangible models as proxies for physical data referents, supporting interactive exploration of data through active manipulation. We realise an active proxy data visualisation system, \"MarioChart\", using robot carts relocating themselves on a tabletop, e.g., to align with their data referents in a map or other visual layout. We consider a casual-data exploration scenario involving a multivariate campus sustainability dataset, using scale models as proxies for their physical building data referents. Our empirical study (n=12) compares active proxy use with conventional tablet interaction, finding that our active proxy system enhances short-term spatial memory of data and enables faster completion of certain data analytic tasks. It shows no significant differences compared to traditional touch-screens in long-term memory, physical fatigue, mental workload, or user engagement. Our study offers an initial baseline for active proxy techniques and advances understanding of tangible interfaces in situated data visualisation."
  },
  {
    "date": "2026-01-26",
    "title": "Discrete spectrum from local perturbations of leaky curves",
    "authors": "Pavel Exner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18325v1",
    "source": "arXiv",
    "abstract": "We discuss spectrum of a class of singular Schrödinger operator models known as leaky curves and show that if the interaction support has a periodic shape, its local perturbations can give rise to a discrete spectrum below the continuum threshold even if they are of `zero mean'."
  },
  {
    "date": "2026-01-26",
    "title": "Representations with the same degree",
    "authors": "Frank Lübeck",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18786v1",
    "source": "arXiv",
    "abstract": "In this short note we show that every connected reductive simply-connected algebraic group of rank $>1$ over the complex numbers has infinitely many pairs of irreducible representations which are not related by an automorphism of the algebraic group and which have the same degree. This answers a question I was asked by J.~P.~Serre."
  },
  {
    "date": "2026-01-26",
    "title": "Are Conversational AI Agents the Way Out? Co-Designing Reader-Oriented News Experiences with Immigrants and Journalists",
    "authors": "Yongle Zhang, Ge Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18772v1",
    "source": "arXiv",
    "abstract": "Recent discussions at the intersection of journalism, HCI, and human-centered computing ask how technologies can help create reader-oriented news experiences. The current paper takes up this initiative by focusing on immigrant readers, a group who reports significant difficulties engaging with mainstream news yet has received limited attention in prior research. We report findings from our co-design research with eleven immigrant readers living in the United States and seven journalists working in the same region, aiming to enhance the news experience of the former. Data collected from all participants revealed an \"unaddressed-or-unaccountable\" paradox that challenges value alignment across immigrant readers and journalists. This paradox points to four metaphors regarding how conversational AI agents can be designed to assist news reading. Each metaphor requires conversational AI, journalists, and immigrant readers to coordinate their shared responsibilities in a distinct manner. These findings provide insights into reader-oriented news experiences with AI in the loop."
  },
  {
    "date": "2026-01-26",
    "title": "A general variational approach for equilibrium phase boundaries of trapped spin-1 Bose-Einstein condensates",
    "authors": "Sahil Satapathy, Projjwal K. Kanjilal, A. Bhattacharyay",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18764v1",
    "source": "arXiv",
    "abstract": "We develop a simple and general variational method to estimate the solutions of the Gross-Pitaevskii equations and obtain the corresponding density profiles for all spin states of a trapped spin-1 Bose-Einstein condensate. We further employ this approach to obtain the complete phase diagram of the system under quasi-one-dimensional harmonic confinement, with ferromagnetic or antiferromagnetic spin interactions. We identify a suitable scaling that collapses all phase diagrams for different system sizes (i.e., total particle number) into a universal (system size-independent) phase diagram. The complete phase diagram for a confined system shows some significant qualitative differences compared to that of a condensate with homogeneous density distribution. The phase diagrams reported here could help identify the important parameter regimes in which phase transitions in the confined system, in general, occur. This knowledge of the region of phase boundaries can enable a reliable investigation of the instabilities near the boundaries that drive phase transitions."
  },
  {
    "date": "2026-01-26",
    "title": "Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values",
    "authors": "Henry Bell, Lara Neubauer da Costa Schertel, Bochu Ding, Brandon Fain",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18760v1",
    "source": "arXiv",
    "abstract": "A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \\textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \\textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic."
  },
  {
    "date": "2026-01-26",
    "title": "Subdividing simplicial virtual resolutions with homology",
    "authors": "Eric Nathan Stucky, Jay Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18755v1",
    "source": "arXiv",
    "abstract": "While sporadic examples of virtual resolutions with homology have been constructed, their occurrence is not well understood or controlled. Our results build a new set of tools for studying virtual resolutions of monomial ideals as arising from simplicial complexes, including characterizing them by the acyclicity of certain induced subcomplexes. Using this characterization, we give a description of minimal simplicial complexes supporting virtual resolutions as well as a technique for removing homology from simplicial virtual resolutions."
  },
  {
    "date": "2026-01-26",
    "title": "Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback",
    "authors": "Seyed Amir Hosseini, Maryam Abdolali, Amirhosein Tavakkoli, Fardin Ayar, Ehsan Javanmardi, Manabu Tsukada, Mahdi Javanmardi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18751v1",
    "source": "arXiv",
    "abstract": "Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines."
  },
  {
    "date": "2026-01-26",
    "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models",
    "authors": "Fangxu Yu, Xingang Guo, Lingzhi Yuan, Haoqiang Kang, Hongyu Zhao, Lianhui Qin, Furong Huang, Bin Hu, Tianyi Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18744v1",
    "source": "arXiv",
    "abstract": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/."
  },
  {
    "date": "2026-01-26",
    "title": "Quantum skyrmions in the antiferromagnetic triangular lattice",
    "authors": "Inés Corte, Federico Holik, Lorena Rebón, Flavia A. Gómez Albarracín",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18737v1",
    "source": "arXiv",
    "abstract": "Magnetic skyrmions are topological quasiparticles potentially useful for memory and computing devices. Antiferromagnetic (AF) skyrmions present no transverse deflection, making them suitable candidates for data storage applications. After the discovery of skyrmions with length scales comparable to the lattice constant, several works presented quantum analogues of classical ferromagnetic skyrmions in spin systems. However, studies about quantum analogues of AF skyrmions are still lacking. Here, we explore the phases of the AF quantum spin-1/2 Heisenberg model with Dzyaloshinskii-Moriya interactions on the triangular lattice using the density matrix renormalization group (DMRG) algorithm. We study the magnetization profile, spin structure factor and quantum entanglement of the resulting ground states to characterize the corresponding phases and signal the emergence of quantum AF skyrmions. Our results support that three-sublattice quantum antiferromagnetic skyrmion textures are stabilized in a wide range of magnetic fields."
  },
  {
    "date": "2026-01-26",
    "title": "Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems",
    "authors": "Jusheng Zhang, Yijia Fan, Kaitong Cai, Jing Yang, Jiawei Yao, Jian Wang, Guanlong Qu, Ziliang Chen, Keze Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18735v1",
    "source": "arXiv",
    "abstract": "Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems."
  },
  {
    "date": "2026-01-26",
    "title": "Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale",
    "authors": "Henry Bell, Caroline Zhang, Mohammed Mobasserul Haque, Dhaval Potdar, Samia Zaman, Brandon Fain",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18730v1",
    "source": "arXiv",
    "abstract": "The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \\textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \\textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \\textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \\textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \\textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \\textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios."
  },
  {
    "date": "2026-01-26",
    "title": "Restoring Wasserstein Rigidity with a single point",
    "authors": "Zoltán M. Balogh, Eric Ströher, Dániel Virosztek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18729v1",
    "source": "arXiv",
    "abstract": "We consider isometrically flexible Wasserstein spaces and demonstrate that adding a single point to the underlying metric space makes these Wasserstein spaces rigid."
  },
  {
    "date": "2026-01-26",
    "title": "Explaining the thermal emission of old neutron stars with rotochemical heating and magnetized superconducting protons",
    "authors": "Luis E. Rodríguez, Andreas Reisenegger, Denis González-Caniulef, Cristóbal Petrovich",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18725v1",
    "source": "arXiv",
    "abstract": "The detection of likely thermal ultraviolet emission from a few old neutron stars suggests that at least one internal heating mechanism is present in these stars. One proposed mechanism is rotochemical heating, in which the continuous contraction of the neutron star due to its spin-down produces chemical imbalances that induce Urca reactions, and the latter deposit heat in the neutron star core. If the protons in the star are superconducting, their energy gap suppresses the reactions, except in microscopic magnetized regions (such as quantized flux tubes) in which the protons act as if they were normal. Therefore, the strength of the internal magnetic field controls the rate at which reactions proceed and thus affects the thermal evolution of the neutron star. Here, we present the first comprehensive study of the effect of an internal magnetic field in the superconducting interior on rotochemical heating. We simulate the evolution of neutron stars for different internal magnetic field strengths and neutron energy gaps, comparing the results to Hubble Space Telescope observations of old neutron stars. All the observational data can be accounted for if the proton energy gap is large ($\\sim 1.5\\,\\mathrm{MeV}$) and the neutron energy gap is small ($\\lesssim 0.1\\,\\mathrm{MeV}$) or vanishing, while the millisecond pulsar PSR~J0437$-$4715 needs to have a very weak internal magnetic field. Our results suggest that neutron-star cores are characterized by a large proton pairing gap and a small or vanishing neutron gap, and that millisecond pulsars have very weak internal magnetic fields. Under these conditions, rotochemical heating alone can account for the observed thermal emission of old neutron stars."
  },
  {
    "date": "2026-01-26",
    "title": "Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning",
    "authors": "Lintang Sutawika, Gokul Swamy, Zhiwei Steven Wu, Graham Neubig",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18722v1",
    "source": "arXiv",
    "abstract": "When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \\texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \\textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \\textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \\texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than of the training data across the single-language, multilingual, and generalization to unseen language settings."
  },
  {
    "date": "2026-01-26",
    "title": "Ultra-fast growth of primordial black holes through radiative absorption",
    "authors": "Dimitris S. Kallifatides, Theodoros Papanikolaou, Emmanuel N. Saridakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18708v1",
    "source": "arXiv",
    "abstract": "We show that Schwarzschild primordial black holes (PBHs) formed in the radiation-dominated era can grow extremely rapidly through $\\textit{radiative absorption}$ governed by the full Stefan-Boltzmann law. By introducing a principle of isonomy - ensuring identical particle species dependence for Hawking emission and absorption - we find that, whenever the temperature of the PBH environment is larger than the PBH horizon temperature, PBHs generically gain mass. In particular, for PBH masses following the critical collapse mass-scaling law with critical exponent $γ_\\mathrm{crit}$, with $γ_\\mathrm{crit} \\in (0.33, 0.49)$, the aforementioned radiative absorption mass growth mechanism produces a striking effect: PBHs forming with a mass $10^6M_\\odot$ during BBN can reach $\\mathcal{O}(10^{10} M_\\odot)$ within $\\mathcal{O}(10^{6} \\mathrm{s})$ ($\\sim $ 58 days). Interestingly enough, small deviations from $γ_\\mathrm{crit}$, depending itself on the number of relativistic species present in the primordial plasma, yield a continuous PBH mass spectrum providing us ultimately with a single, Standard-Model-based explanation for the origin of stellar-mass, intermediate-mass, and supermassive black holes (SMBHs), and naturally accounting for the early appearance of SMBHs. The Schwarzschild treatment presented here can be extended to spherically symmetric cosmological black holes, indicating that radiative absorption is a dominant and previously overlooked PBH growth channel in the early Universe."
  },
  {
    "date": "2026-01-26",
    "title": "Chemotaxis-inspired PDE models of airborne infectious disease transmission: epidemiologically-motivated mathematical and numerical analyses",
    "authors": "Alex Viguerie, Malú Grave, Alvaro L. G. A. Coutinho, Alessandro Veneziani, Thomas J. R. Hughes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18703v1",
    "source": "arXiv",
    "abstract": "Partial differential equation (PDE) models for infectious diseases, while less common than their ordinary differential equation (ODE) counterparts, have found successful applications for many years. Such models are typically of reaction-diffusion type, and model spatial propagation as a diffusive process. However, given the complex nature of human mobility, such models are limited in their ability to describe airborne infectious diseases in human populations. Recent work has advocated for the inclusion of an additional chemotaxis-type term as an alternative; spatial propagation of infection fronts is assumed additionally to flow from low-to-high concentrations of susceptible populations. The present work extends the study of such models by providing an epidemiologically interpretable analysis, directly connecting model behavior to information readily available to policymakers. In particular, we derive a spatially-aware basic reproduction number, which accounts for spatial heterogeneity in population density. Furthermore, we discuss several important aspects concerning the numerical solution of the model, including the introduction of a stabilization scheme. Finally, we perform a series of simulation studies in the Italian region of Lombardy (severely affected by the COVID-19 outbreak in 2020) and in the US state of Georgia, in which we demonstrate the model's potential to better capture important spatiotemporal dynamics observed in real-world data compared to pure reaction-diffusion models."
  },
  {
    "date": "2026-01-26",
    "title": "Hyperkähler bases for six rational bordism theories",
    "authors": "Jonathan Buchanan, Arun Debray, Cameron Krulewski, Stephen McKean",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18701v1",
    "source": "arXiv",
    "abstract": "We use tori and Hilbert schemes of K3 surfaces to construct explicit bases for the real, complex, and quaternionic versions of rational symplectic and rational Spin bordism. The key input to our work is a theorem of Oberdieck, Song, and Voisin on the Milnor genus of Hilbert schemes of K3s."
  },
  {
    "date": "2026-01-26",
    "title": "Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning",
    "authors": "Olaf Yunus Laitinen Imanov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18699v1",
    "source": "arXiv",
    "abstract": "Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems."
  },
  {
    "date": "2026-01-26",
    "title": "Competitive Social Mobilization in Threshold Models of Collective Action",
    "authors": "Bianca Y. S. Ishikawa, José F. Fontanari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18682v1",
    "source": "arXiv",
    "abstract": "Social mobilization often fails not for a lack of collective interest, but because of fierce competition between rival movements for the same limited pool of participants. We generalize the classic threshold model of collective behavior to analyze this competitive aggregation, exploring how populations with diverse participation thresholds navigate multiple, mutually exclusive causes. Focusing on the conditions necessary for a single consensus movement to encompass an entire population, our analysis reveals that the outcome of social competition depends critically on the stability of individual dispositions. In quenched environments where participation thresholds are fixed, increasing resistance initially allows a dominant movement to suppress its competitors; however, further resistance triggers a sudden collapse into total fragmentation as low-threshold instigators become too rare to sustain growth. Conversely, in annealed environments where opinions are fluid, higher resistance paradoxically drives a winner-takes-all consensus. In this fluid scenario, massive movements can only be avoided through a deliberate divide-and-conquer strategy. In both cases, the transitions between pulverized and massive movements are discontinuous. These findings demonstrate that the effectiveness of social control depends entirely on environmental stability: raising the cost of participation can either forge unity or shatter collective action into insignificance."
  },
  {
    "date": "2026-01-26",
    "title": "COMETS: Coordinated Multi-Destination Video Transmission with In-Network Rate Adaptation",
    "authors": "Yulong Zhang, Ying Cui, Zili Meng, Abhishek Kumar, Dirk Kutscher",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18670v1",
    "source": "arXiv",
    "abstract": "Large-scale video streaming events attract millions of simultaneous viewers, stressing existing delivery infrastructures. Client-driven adaptation reacts slowly to shared congestion, while server-based coordination introduces scalability bottlenecks and single points of failure. We present COMETS, a coordinated multi-destination video transmission framework that leverages information-centric networking principles such as request aggregation and in-network state awareness to enable scalable, fair, and adaptive rate control. COMETS introduces a novel range-interest protocol and distributed in-network decision process that aligns video quality across receiver groups while minimizing redundant transmissions. To achieve this, we develop a lightweight distributed optimization framework that guides per-hop quality adaptation without centralized control. Extensive emulation shows that COMETS consistently improves bandwidth utilization, fairness, and user-perceived quality of experience over DASH, MoQ, and ICN baselines, particularly under high concurrency. The results highlight COMETS as a practical, deployable approach for next-generation scalable video delivery."
  },
  {
    "date": "2026-01-26",
    "title": "A probabilistic journey through the Newton-Girard identities",
    "authors": "Jean-Christophe Pain",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18665v1",
    "source": "arXiv",
    "abstract": "This article presents a pedagogical probabilistic exploration of the Newton-Girard identities. We show that the coefficients in these classical relations between power sums and elementary symmetric polynomials can be interpreted as the stable limits of integrals over the unit cube, and as ratios of moments of simple probability distributions. Several classes of integrals are studied, including trigonometric and multiplicative forms. In addition, we discuss the spectral implications via the Le Verrier-Souriau-Faddeev algorithm and Random Matrix Theory, providing a unified framework for the asymptotic algebraic behavior of these identities. While the identities are classical, the probabilistic interpretation of the limits of their normalized forms is the specific focus of the present work."
  },
  {
    "date": "2026-01-26",
    "title": "On Partition Classes Arising from Parity, Differences, and Repeated Smallest Parts",
    "authors": "Rahul Kumar, Nargish Punia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18657v1",
    "source": "arXiv",
    "abstract": "In this paper, we study various classes of partition functions such as those related to the parity of the number of parts, to differences of partition numbers, and to partitions with a repeated smallest part. We establish identities connecting these various classes of partitions. Moreover, our identities help us to extend the Euler's partition theorem. An analogue of Legendre's theorem of the partition-theoretic interpretation of Euler's pentagonal number theorem is also derived. Both combinatorial and $q$-series proofs are given for our results."
  },
  {
    "date": "2026-01-26",
    "title": "On series identities involving $\\binom{4k}k$ and harmonic numbers",
    "authors": "Bo Jiang, Zhi-Wei Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18645v1",
    "source": "arXiv",
    "abstract": "The harmonic numbers are those $H_n=\\sum_{0<k\\le n}\\frac1k\\ (n=0,1,2,\\ldots)$. In this paper we confirm over ten conjectural series identities with summands involving the binomial coefficient $\\binom{4k}k$ and harmonic numbers. For example, we prove the identities $$\\sum_{k=1}^\\infty \\frac{\\binom{4k}{k}}{16^k}\\left((22k^2-92k+11)H_{4k}-\\frac{449k-275}{2}-\\frac{85}{12k}\\right)=-151-\\frac{80}{3}\\log{2}$$ and $$ \\sum_{k=0}^\\infty\\frac{\\binom{4k}{k}((11k^2+8k+1)(10H_{4k}-17H_{2k})+2k+18)}{(3k+1)(3k+2)16^k}=8\\log2,$$ which were previously conjectured by Z.-W. Sun."
  },
  {
    "date": "2026-01-26",
    "title": "The growing family of gamma-ray narrow-line Seyfert 1 galaxies",
    "authors": "Luigi Foschini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18635v1",
    "source": "arXiv",
    "abstract": "The revision of the fourth Fermi Large Area Telescope (LAT) catalog of gamma-ray point sources (rev4FGL) revealed that the gamma-ray sky is populated by emerging populations of jetted active galactic nuclei (AGN) other than blazars and radio galaxies. Narrow-Line Seyfert 1, Seyfert 1, intermediate, and Seyfert 2 galaxies, changing-look AGN, plus a number of ambiguous or unclassified sources. After a short historical introduction on the gamma-ray observations of Seyfert-type AGN, I explore the main statistical properties of 1477 jetted AGN from the rev4FGL with spectroscopic redshift, and also the cross-match with Very Large Baseline Array (VLBA) radio observations at 15~GHz from the Monitoring Of Jets in Active galactic nuclei with VLBA Experiments (MOJAVE) program. I then discuss the difference between gamma and non-gamma jetted AGN, and the implications on the classification."
  },
  {
    "date": "2026-01-26",
    "title": "Conductance switching and nonequilibrium phase coexistence in superconductors with intermediate bias",
    "authors": "Shamashis Sengupta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18632v1",
    "source": "arXiv",
    "abstract": "Superconducting systems may display different types of nonequilibrium states depending on the specific constraints imposed for measurement. We probe current-voltage relations of three-dimensional superconducting films by allowing finite voltages to develop across their length. Our experiments reveal sharp features of negative differential conductance which highlight the validity of the principle of minimum entropy production at the critical current transition. We have observed dissipative states with resistances intermediate between those of superconducting and normal phases at zero applied magnetic field, indicating a phenomenon of phase coexistence under nonequilibrium conditions. The features of steady states reported here are not accessible in conventional transport experiments with current-biasing methods."
  },
  {
    "date": "2026-01-26",
    "title": "Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation",
    "authors": "Zihao Wang, Yuzhou Chen, Shaogang Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18623v1",
    "source": "arXiv",
    "abstract": "Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps."
  },
  {
    "date": "2026-01-26",
    "title": "Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks",
    "authors": "Pierre Orhan, Pablo Diego-Simón, Emmnanuel Chemla, Yair Lakretz, Yves Boubenec, Jean-Rémi King",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18617v1",
    "source": "arXiv",
    "abstract": "During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition."
  },
  {
    "date": "2026-01-26",
    "title": "Issues regarding the Indexing of Publication Types and Study Designs",
    "authors": "Neil R. Smalheiser, Joe D. Menke, Arthur W. Holt, Halil Kilicoglu, Jodi Schneider",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18616v1",
    "source": "arXiv",
    "abstract": "Objectives. Major research and implementation efforts have been devoted to indexing articles according to the major topics discussed, but much less effort to indexing their publication types and study designs (collectively, PTs). In this Perspective, we discuss how indexing PTs differs from topical MeSH indexing and requires a different approach. Materials and Methods. Rather than focus on the technical aspects of machine learning-based indexing models, we emphasize the goals and purposes for which biomedical articles are indexed, and the surprisingly thorny question of how indexing systems should be evaluated. Results. Topical Medical Subject Heading (MeSH) terms are assigned to articles that cover the major topics discussed; when more than one term is applicable, only the most specific term is assigned. In contrast, PTs are assigned to articles that have a given structure or use a particular design. To meet the needs of end users, particularly groups involved in evidence syntheses, PT indexing needs to be comprehensive and employ probabilistic prediction scores. Whereas existing NLM hierarchies place publication types and study design-related terms on separate trees from each other, a unified rubric permits more appropriate retrieval via automatic expansion. Discussion. Automated PT indexing systems should allow users to input article records or full text pdfs and receive scores in real time. This will offer consistent indexing across bibliographic databases, as well as preprints and unpublished manuscripts. Conclusions. Automated PT indexing systems, properly designed and implemented, hold the promise of greatly improving the retrieval of biomedical articles, saving substantial effort when writing evidence syntheses and benefiting other users as well."
  },
  {
    "date": "2026-01-26",
    "title": "LaCoGSEA: Unsupervised deep learning for pathway analysis via latent correlation",
    "authors": "Zhiwei Zheng, Kevin Bryson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18604v1",
    "source": "arXiv",
    "abstract": "Motivation: Pathway enrichment analysis is widely used to interpret gene expression data. Standard approaches, such as GSEA, rely on predefined phenotypic labels and pairwise comparisons, which limits their applicability in unsupervised settings. Existing unsupervised extensions, including single-sample methods, provide pathway-level summaries but primarily capture linear relationships and do not explicitly model gene-pathway associations. More recently, deep learning models have been explored to capture non-linear transcriptomic structure. However, their interpretation has typically relied on generic explainable AI (XAI) techniques designed for feature-level attribution. As these methods are not designed for pathway-level interpretation in unsupervised transcriptomic analyses, their effectiveness in this setting remains limited. Results: To bridge this gap, we introduce LaCoGSEA (Latent Correlation GSEA), an unsupervised framework that integrates deep representation learning with robust pathway statistics. LaCoGSEA employs an autoencoder to capture non-linear manifolds and proposes a global gene-latent correlation metric as a proxy for differential expression, generating dense gene rankings without prior labels. We demonstrate that LaCoGSEA offers three key advantages: (i) it achieves improved clustering performance in distinguishing cancer subtypes compared to existing unsupervised baselines; (ii) it recovers a broader range of biologically meaningful pathways at higher ranks compared with linear dimensionality reduction and gradient-based XAI methods; and (iii) it maintains high robustness and consistency across varying experimental protocols and dataset sizes. Overall, LaCoGSEA provides state-of-the-art performance in unsupervised pathway enrichment analysis. Availability and implementation: https://github.com/willyzzz/LaCoGSEA"
  },
  {
    "date": "2026-01-26",
    "title": "On-surface dehydrogenative lateral homo-coupling and aromatization of n-octane on Pt(111)",
    "authors": "D. Arribas, E. Tosi, V. Villalobos-Vilda, B. Cirera, I. Palacio, A. Sáez-Coronado, P. Lacovig, A. Baraldi, L. Bignardi, S. Lizzit, A. Gutiérrez, J. A. Martín-Gago, J. I. Martínez, P. L. de Andres, P. Merino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18600v1",
    "source": "arXiv",
    "abstract": "Aliphatic hydrocarbons, such as normal alkanes, constitute a naturally abundant source of carbon atoms. Of special interest is the formation of cyclic and aromatic products from aliphatic reactants. Combining scanning tunneling microscopy and ab initio calculations, we investigate the thermal induced aromatization of linear n octane molecules on the catalytic Pt(111) surface and the reactions of intermolecular homocoupling between them at temperatures above 600 K. The cycloaromatization of individual n octane molecules requires bending the linear adsorbates prior to their dehydrogenation and the formation of an intramolecular C-C bond, yielding adsorbed benzene rings. In addition, the Pt(111) surface catalyzes a homocoupling reaction by initiating the formation of a C-C bond between the dehydrogenated methyl ends of the chemisorbed n octane molecules and then propagating along the carbon backbone in a zipper like fashion. Our findings provide molecular level insight into the heterogeneous catalytic processes underlying the generation of aromatic products and stable on surface polycyclic species."
  },
  {
    "date": "2026-01-26",
    "title": "EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery",
    "authors": "Yu Xia, Chang Liu, Tianqi Xiang, Zhigang Tu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18597v1",
    "source": "arXiv",
    "abstract": "Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \\textbf{1.6}\\% and \\textbf{5.8}\\% in AP and AP$_{s}$ on VisDrone, while obtaining \\textbf{188} FPS inference speed on a single RTX 4090 GPU."
  },
  {
    "date": "2026-01-26",
    "title": "How are MLOps Frameworks Used in Open Source Projects? An Empirical Characterization",
    "authors": "Fiorella Zampetti, Federico Stocchetti, Federica Razzano, Damian Andrew Tamburri, Massimiliano Di Penta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18591v1",
    "source": "arXiv",
    "abstract": "Machine Learning (ML) Operations (MLOps) frameworks have been conceived to support developers and AI engineers in managing the lifecycle of their ML models. While such frameworks provide a wide range of features, developers may leverage only a subset of them, while missing some highly desired features. This paper investigates the practical use and desired feature enhancements of eight popular open-source MLOps frameworks. Specifically, we analyze their usage by dependent projects on GitHub, examining how they invoke the frameworks' APIs and commands. Then, we qualitatively analyze feature requests and enhancements mined from the frameworks' issue trackers, relating these desired improvements to the previously identified usage features. Results indicate that MLOps frameworks are rarely used out-of-the-box and are infrequently integrated into GitHub Workflows, but rather, developers use their APIs to implement custom functionality in their projects. Used features concern core ML phases and whole infrastructure governance, sometimes leveraging multiple frameworks with complementary features. The mapping with feature requests highlights that users mainly ask for enhancements to core features of the frameworks, but also better API exposure and CI/CD integration."
  },
  {
    "date": "2026-01-26",
    "title": "AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment",
    "authors": "KV Karthikeya, Ashok Kumar Das, Shantanu Pal, Vivekananda Bhat K, Arun Sekar Rajasekaran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18589v1",
    "source": "arXiv",
    "abstract": "In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification."
  },
  {
    "date": "2026-01-26",
    "title": "FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG",
    "authors": "Seonho An, Chaejeong Hyun, Min-Soo Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18579v1",
    "source": "arXiv",
    "abstract": "Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency."
  },
  {
    "date": "2026-01-26",
    "title": "The AIDA-TNG project: gas distributions inside and around haloes",
    "authors": "Chi Zhang, Enrico Garaldi, Giulia Despali, Matteo Viel, Lauro Moscardini, Mark Vogelsberger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18578v1",
    "source": "arXiv",
    "abstract": "The nature of Dark Matter (DM) is one of the most outstanding mysteries of modern astrophysics. While the standard Cold DM (CDM) model successfully explains observations on most astrophysical scales, DM particles have not yet been detected, leaving room for a plethora of different models. In order to identify their observable signatures, we use the AIDA-TNG cosmological simulation suite to predict the distributions of gas and neutral hydrogen (HI) in the CDM, Self-Interacting DM (SIDM), velocity-dependent SIDM (vSIDM), and Warm DM (WDM) models. We find that the DM models investigated have very limited impact on the median gas and HI profile of haloes. In particular, for the most massive haloes ($M_{\\rm vir}\\sim10^{14}\\,\\mathrm{M}_\\odot$), we find that DM self-interactions can shallow the central potential and thereby enhance gas cooling. We find that, in all models, the halo-to-halo variation in the HI profiles is explained by AGN feedback, and that the specific characteristics of DM model is largely subdominant. Nevertheless, we detect some systematic difference in the case of SIDM, with more HI surviving close to the centre with respect to other models. We provide fitting functions for the gas and HI profiles. We investigate the galaxy-Ly$α$ cross-correlation function (\\galacc) for different halo masses, redshift and observation strategies. We find that at $z=0$ vSIDM can be distinguished from CDM in haloes with $10^{12}\\lesssim M_{\\rm vir}\\lesssim10^{13}\\,{\\rm M}_\\odot$, while SIDM1 can be distinguished from CDM in haloes with $M_{\\rm vir}\\gtrsim10^{13}\\,{\\rm M}_\\odot$. We estimate that statistically-robust detection requires sampling $\\sim160$ haloes with $\\sim20$ sightlines each, a task that can be achieved with current and future facilities like WEAVE, 4MOST, PFS, ELT and WST."
  },
  {
    "date": "2026-01-26",
    "title": "Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation",
    "authors": "Seokju Lee, Kyung-Soo Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18569v1",
    "source": "arXiv",
    "abstract": "In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions."
  },
  {
    "date": "2026-01-26",
    "title": "Supersolid phases and collective excitations in two-dimensional Rashba spin-orbit coupled spin-1 condensates",
    "authors": "Sanu Kumar Gangwar, Sayan Chatterjee, Rajamanickam Ravisankar, Henrique Fabrelli, Paulsamy Muruganandam, Pankaj Kumar Mishra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18568v1",
    "source": "arXiv",
    "abstract": "We investigate the collective excitation spectrum and dynamics of a quasi two-dimensional spin-1 Bose-Einstein condensate with Rashba type spin-orbit (SO) coupling. Employing Bogoliubov-de-Gennes analysis, we analytically compute the excitation spectra across a wide range of interaction strengths and coupling parameters. By systematically varying the SO and Rabi couplings, we uncover distinct dynamical signatures of quantum phase transitions, including mode softening, the appearance of roton-like minima, and miscibility-driven instabilities in both ferromagnetic and antiferromagnetic interaction regimes. In the antiferromagnetic case, these instabilities lead to a dynamically unstable supersolid phase characterized by the coexistence of density modulation and global phase coherence. To corroborate the analytical predictions, we numerically solve the coupled Gross-Pitaevskii equations and analyze the dynamical stability of the condensate. Our results provide experimentally accessible signatures for spinor condensates with tunable spin-orbit coupling and demonstrate the rich interplay between spin-dependent interactions and synthetic couplings in nonequilibrium quantum fluids."
  },
  {
    "date": "2026-01-26",
    "title": "Ancient relic moderately metal-rich bulge cluster Tonantzintla 2",
    "authors": "Sergio Ortolani, Stefano O. Souza, Domenico Nardiello, Beatriz Barbuy, Eduardo Bica, Bernardo P. L. Ferreira, Cristina Chiappini, José Fernandez-Trincado, Heitor Ernandes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18567v1",
    "source": "arXiv",
    "abstract": "The assembly history of the Galactic bulge is intimately tied to the formation of the proto-Milky Way, yet reconstructing this early phase is difficult because mergers and secular evolution have erased most of its original structure. Among present-day stellar systems, only globular clusters retain the ancient signatures needed to trace these primordial building blocks. Here we present the most detailed characterization to date of Tonantzintla 2, a prime candidate for a relic of the Milky Way's primordial bulge. It is a moderately metal-rich globular cluster projected onto the bulge that has remained largely unexplored despite its potential to constrain the early formation of the inner Milky Way. We derive its fundamental parameters using proper motion-corrected Hubble Space Telescope WFC3 and ACS photometry. By applying an isochrone fitting to very clean data, we obtain an age of 13.58 Gyr, a reddening E(B-V) = 1.44, a metallicity [M/H]=-0.68, and a heliocentric distance of d = 7.38 kpc. A complementary chemical-abundance analysis of seven member stars from APOGEE high-resolution spectroscopy reveals an enrichment pattern consistent with an in-situ origin. Tonantzintla 2 is among the oldest globular clusters studied in the literature, and the oldest so far analyzed in the Galactic bulge. Its age places a stringent constraint on the onset of the bulge formation, implying that star formation in the inner Galaxy began within ~0.2 Gyr of the Big Bang and that Tonantzintla 2 represents an exceptional relic of the Milky Way's earliest chemical enrichment."
  },
  {
    "date": "2026-01-26",
    "title": "Monochromatic triangle-tilings in dense graphs without large independent sets",
    "authors": "Xinmin Hou, Xiangyang Wang, Zhi Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18565v1",
    "source": "arXiv",
    "abstract": "Given two graphs $H$ and $G$, an $H$-tiling is a family of vertex-disjoint copies of $H$ in $G$. A perfect $H$-tiling covers all vertices of $G$. The Corradi-Hajnal theorem (1963) states that an $n$-vertex graph $G$ with minimum degree $δ(G)\\ge 2n/3$ contains a perfect triangle-tiling. For an $n$-vertex graph $G$ with independence number $α(G)=o(n)$, Balogh, Molla and Sharifzadeh (Random Structures & Algorithms, 2016) showed that a minimum degree of $(\\frac12+o(1))n$ forces a perfect triangle-tiling. In a 2-edge-colored graph, Balogh, Freschi, Treglown (European J. Combin. 2026) determined the (asymptotic) minimum degree threshold for forcing a strong or weak monochromatic triangle-tiling covering a prescribed proportion of the vertices: a strong tiling requires all triangles to be in the same color class, while a weak tiling only requires each triangle to be monochromatic. In this paper, we combine the conditions from these two lines of work and prove that every $2$-edge-colored $n$-vertex graph $G$ with $α(G)=o(n)$ contains a weak monochromatic triangle-tiling $Γ$ of size \\[ |Γ|\\ge \\begin{cases} 2δ(G)-n-o(n), & \\text{if }\\frac12 n\\le δ(G)\\le \\frac35 n,\\\\[2mm] δ(G)/3-o(n), & \\text{if }δ(G)>\\frac35 n. \\end{cases} \\] Both bounds are asymptotically optimal. We use the degree form regularity lemma in our proof."
  },
  {
    "date": "2026-01-26",
    "title": "Bayesian Optimization for Quantum Error-Correcting Code Discovery",
    "authors": "Yihua Chengyu, Richard Meister, Conor Carty, Sheng-Ku Lin, Roberto Bondesan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18562v1",
    "source": "arXiv",
    "abstract": "Quantum error-correcting codes protect fragile quantum information by encoding it redundantly, but identifying codes that perform well in practice with minimal overhead remains difficult due to the combinatorial search space and the high cost of logical error rate evaluation. We propose a Bayesian optimization framework to discover quantum error-correcting codes that improves data efficiency and scalability with respect to previous machine learning approaches to this task. Our main contribution is a multi-view chain-complex neural embedding that allows us to predict the logical error rate of quantum LDPC codes without performing expensive simulations. Using bivariate bicycle codes and code capacity noise as a testbed, our algorithm discovers a high-rate code [[144,36]] that achieves competitive per-qubit error rate compared to the gross code, as well as a low-error code [[144,16]] that outperforms the gross code in terms of error rate per qubit. These results highlight the ability of our pipeline to automatically discover codes balancing rate and noise suppression, while the generality of the framework enables application across diverse code families, decoders, and noise models."
  },
  {
    "date": "2026-01-26",
    "title": "Brownian motion on reflection quantum groups. Construction and cutoff",
    "authors": "Jean Delhaye",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18559v1",
    "source": "arXiv",
    "abstract": "T. In this study, we construct an analog of the Brownian motion on free reflection quantum groups and compute its cutoff profile."
  },
  {
    "date": "2026-01-26",
    "title": "Experimental Characterization of ISAC Channel Mapping and Environment Awareness",
    "authors": "Zhuangzhuang Cui, Rizqi Hersyandika, Haoqiu Xiong, Sofie Pollin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18558v1",
    "source": "arXiv",
    "abstract": "In the context of integrated sensing and communications (ISAC), this paper presents an experimental investigation of the relationship between monostatic sensing and naturally bistatic communication channels in an indoor millimeter-wave environment. We characterize the propagation channel in the joint delay--angle domain, extract dominant multipath components (MPCs) and associate them with physical scatterers in the environment, and demonstrate how communication MPCs can be explicitly recovered from sensing channels. Finally, the radar cross-sections (RCSs) of two key scatterers, namely the wall and metal plate, are obtained based on calibrated channel power and reconstructed propagation distances."
  },
  {
    "date": "2026-01-26",
    "title": "Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray",
    "authors": "Roberto Di Via, Vito Paolo Pastore, Francesca Odone, Siôn Glyn-Jones, Irina Voiculescu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18555v1",
    "source": "arXiv",
    "abstract": "Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions"
  },
  {
    "date": "2026-01-26",
    "title": "Reinforcement Learning with Distributed MPC for Fuel-Efficient Platoon Control with Discrete Gear Transitions",
    "authors": "Samuel Mallick, Gianpietro Battocletti, Dimitris Boskos, Azita Dabiri, Bart De Schutter",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18294v1",
    "source": "arXiv",
    "abstract": "Cooperative control of groups of autonomous vehicles (AVs), i.e., platoons, is a promising direction to improving the efficiency of autonomous transportation systems. In this context, distributed co-optimization of both vehicle speed and gear position can offer benefits for fuel-efficient driving. To this end, model predictive control (MPC) is a popular approach, optimizing the speed and gear-shift schedule while explicitly considering the vehicles' dynamics over a prediction window. However, optimization over both the vehicles' continuous dynamics and discrete gear positions is computationally intensive, and may require overly long sample times or high-end hardware for real-time implementation. This work proposes a reinforcement learning (RL)-based distributed MPC approach to address this issue. For each vehicle in the platoon, a policy is trained to select and fix the gear positions across the prediction window of a local MPC controller, leaving a significantly simpler continuous optimization problem to be solved as part of a distributed MPC scheme. In order to reduce the computational cost of training and facilitate the scalability of the proposed approach to large platoons, the policies are parameterized such that the emergent multi-agent RL problem can be decoupled into single-agent learning tasks. In addition, a recurrent neural-network (RNN) architecture is proposed for the gear selection policy, such that the learning is scalable even as the number of possible gear-shift schedules grows exponentially with the MPC prediction horizon. In highway-driving simulations, the proposed approach is shown to have a significantly lower computation burden and a comparable performance in terms of fuel-efficient platoon control, with respect to pure MPC-based co-optimization."
  },
  {
    "date": "2026-01-26",
    "title": "Quest2ROS2: A ROS 2 Framework for Bi-manual VR Teleoperation",
    "authors": "Jialong Li, Zhenguo Wang, Tianci Wang, Maj Stenmark, Volker Krueger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18289v1",
    "source": "arXiv",
    "abstract": "Quest2ROS2 is an open-source ROS2 framework for bi-manual teleoperation designed to scale robot data collection. Extending Quest2ROS, it overcomes workspace limitations via relative motion-based control, calculating robot movement from VR controller pose changes to enable intuitive, pose-independent operation. The framework integrates essential usability and safety features, including real-time RViz visualization, streamlined gripper control, and a pause-and-reset function for smooth transitions. We detail a modular architecture that supports \"Side-by-Side\" and \"Mirror\" control modes to optimize operator experience across diverse platforms. Code is available at: https://github.com/Taokt/Quest2ROS2."
  },
  {
    "date": "2026-01-26",
    "title": "Line Spectral Estimation Using a G-Filter: Atomic Norm Minimization with Multiple Output Vectors",
    "authors": "Jiale Tang, Bin Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18279v1",
    "source": "arXiv",
    "abstract": "We propose an atomic norm minimization (ANM) estimator of frequencies in a noisy complex sinusoidal signal that integrates Georgiou's filter bank (G-filter) with multiple output vectors (MOV). Unlike our previous work on the G-filter version of ANM which is restricted to a single filtered output vector, the proposed method in this paper uses MOV to improve data utilization and robustness of the estimate. The ANM problem with MOV can be reformulated as a semidefinite program thanks to a Carathéodory--Fejér-type decomposition for output covariance matrices of the G-filter. Numerical simulations demonstrate that the proposed approach significantly outperforms the standard ANM and the G-filter version of ANM with a single output vector in recovering the correct number of frequency components when the frequencies fall within the band(s) selected by the G-filter, particularly in the low SNR regime."
  },
  {
    "date": "2026-01-26",
    "title": "Functional Large Deviations for Wide Deep Neural Networks with Gaussian Initialization and Lipschitz Activations",
    "authors": "Claudio Macci, Barbara Pacchiarotti, Katerina Papagiannouli, Giovanni Luca Torrisi, Dario Trevisan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18276v1",
    "source": "arXiv",
    "abstract": "We establish a functional large deviation principle for fully connected multi-layer perceptrons with i.i.d. Gaussian weights (LeCun initialization) and general Lipschitz activation functions, including therefore the popular case of ReLU. The large deviation principle holds for the entire network output process on any compact input set. The proof combines exponential tightness for recursively defined processes, finite-dimensional large deviations, and the Dawson-Gärtner theorem, extending existing results beyond finite input sets and less general activations."
  },
  {
    "date": "2026-01-26",
    "title": "Improved stability estimates at elliptic equilibria of Hamiltonian systems",
    "authors": "Massimiliano Guzzo, Chiara Caracciolo, Gabriella Pinzari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18268v1",
    "source": "arXiv",
    "abstract": "This paper deals with an improvement of the \"a-priori stability bounds\" on the variation of the action variables and on the stability time obtained from a given Birkhoff normal form around the elliptic equilibrium point of an Hamiltonian system satisfying a non-resonance condition of finite order N. In particular, we improve the standard a-priori lower bound on the stability time from a purely linear dependence on the inverse of the polynomial norm of the remainder of the normal form to the sum of a linear term (which is still present but with a different constant coefficient) and a quadratic one. The prevalence between the linear and the quadratic term depends on the resonance properties of all the monomials in the remainder of the normal form with degree from N to a finite order M. We also provide a comparative example of the new estimates and the traditional a priori ones in the framework of computer-assisted proofs."
  },
  {
    "date": "2026-01-26",
    "title": "Orchestrating Specialized Agents for Trustworthy Enterprise RAG",
    "authors": "Xincheng You, Qi Sun, Neha Bora, Huayi Li, Shubham Goel, Kang Li, Sean Culatana",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18267v1",
    "source": "arXiv",
    "abstract": "Retrieval-Augmented Generation (RAG) shows promise for enterprise knowledge work, yet it often underperforms in high-stakes decision settings that require deep synthesis, strict traceability, and recovery from underspecified prompts. One-pass retrieval-and-write pipelines frequently yield shallow summaries, inconsistent grounding, and weak mechanisms for completeness verification. We introduce ADORE (Adaptive Deep Orchestration for Research in Enterprise), an agentic framework that replaces linear retrieval with iterative, user-steered investigation coordinated by a central orchestrator and a set of specialized agents. ADORE's key insight is that a structured Memory Bank (a curated evidence store with explicit claim-evidence linkage and section-level admissible evidence) enables traceable report generation and systematic checks for evidence completeness. Our contributions are threefold: (1) Memory-locked synthesis - report generation is constrained to a structured Memory Bank (Claim-Evidence Graph) with section-level admissible evidence, enabling traceable claims and grounded citations; (2) Evidence-coverage-guided execution - a retrieval-reflection loop audits section-level evidence coverage to trigger targeted follow-up retrieval and terminates via an evidence-driven stopping criterion; (3) Section-packed long-context grounding - section-level packing, pruning, and citation-preserving compression make long-form synthesis feasible under context limits. Across our evaluation suite, ADORE ranks first on DeepResearch Bench (52.65) and achieves the highest head-to-head preference win rate on DeepConsult (77.2%) against commercial systems."
  },
  {
    "date": "2026-01-26",
    "title": "A Field-Weighted model for Surface Layer Characterization using Single Channel Intensity Interrogation SPR",
    "authors": "Zhiying Chen, Zihao Luo, Changsen Sun, Dmitry Kiesewetter, Sergey Krivosheev, Sergey Magazinov, Victor Malyugin, Xue Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18265v1",
    "source": "arXiv",
    "abstract": "To address the difficulty of characterizing the surface layer rigorously, especially the thickness and refractive index (RI) in surface plasmon resonance (SPR) technology, we propose a field-weighted analysis method. This approach enables simultaneous quantitative determination of RI for the bulk solution and the surface layer. This study utilizes the aluminum-based Kretschmann structure with the intensity interrogation technique. We construct the field-weighted model governed by the evanescent field penetration depth to decompose the SPR reflected intensity into the bulk and surface responses. Experiments are conducted using bovine serum albumin (BSA) solution to form a surface adsorbed protein layer, and different concentrations of BSA are tested. Results show that the separated surface response fits well with the Langmuir formula, representing a significant improvement over the untreated SPR signal. The bulk and surface responses are then incorporated into the field-weighted model to determine the RI values of the bulk BSA solution and the surface adsorbed BSA layer at various concentrations. The experimental results of BSA solution match the Abbe refractometer measurements with a maximum error 0.0004 in RI, while the results of the adsorbed BSA layer, both the RI and thickness, aligned well with reported parameters for a single BSA layer. This method eliminates the stage rotation in the common angular interrogation SPR technique and complicated optical design and nano-fabrication in the nano-optics sensing schemes, making it suitable for compact, low-cost SPR platforms for practical applications needing surface layer characterization."
  },
  {
    "date": "2026-01-26",
    "title": "Revisiting a Quasar Microlensing Event Towards AGN~J1249+3449",
    "authors": "Mario Cazzolla, Francesco De Paolis, Antonio Franco, Achille Nucita",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18262v1",
    "source": "arXiv",
    "abstract": "The gravitational wave event GW190521 seems to be the only BH merger event possibly correlated with an electromagnetic counterpart, which appeared about 34 days after the GW event. This work aims to confirm that the electromagnetic bump towards the Active Galactic Nucleus (AGN) J1249+3449 can be explained within the framework of the gravitational microlensing phenomenon. In particular, considering the data of the Zwicky Transient Facility (ZTF), what emerges from a detailed analysis of the observed light curve using three fitting models (Point Source Point Lens, Finite Source Point Lens, Uniform Source Binary Lens) is that the optical bump can be explained as a microlensing event caused by a lens with mass {$\\sim\\,$0.1 $M_{\\odot}$}, lying in the host galaxy of the AGN in question.} %MDPI: Please confirm if the bold formatting is necessary; if not, please remove it."
  },
  {
    "date": "2026-01-26",
    "title": "Algebraic Phase Theory V: Boundary Calculus, Rigidity Islands, and Deformation Theory",
    "authors": "Joe Gildea",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18257v1",
    "source": "arXiv",
    "abstract": "We develop a general boundary calculus for algebraic phases and use it to formulate an intrinsic and purely structural deformation theory. Structural boundaries are shown to be inevitable, finitely detectable, and canonically stratified by failure type and depth. For each boundary we construct a canonical boundary exact sequence and identify a unique maximal rigid subphase, called a \\emph{rigidity island}, that persists beyond global boundary failure. Rigidity islands are classified by intrinsic invariants and serve as universal base points for deformation theory. All deformations are boundary-controlled, restrict trivially to rigidity islands, and are governed by boundary quotients, which act as universal obstruction objects. Infinitesimal and higher-order obstructions are finite, stratified by boundary depth, and terminate intrinsically. As a consequence, deformation directions are discrete, formal smoothness is equivalent to the vanishing of boundary data, and the moduli of algebraic phases form a stratified discrete groupoid indexed by rigidity islands. No analytic or continuous moduli parameters arise intrinsically."
  },
  {
    "date": "2026-01-26",
    "title": "A Mechanical Wi-Fi Antenna Device for Automatic Orientation Tuning with Bayesian Optimization",
    "authors": "Akihito Taya, Yuuki Nishiyama, Kaoru Sezaki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18256v1",
    "source": "arXiv",
    "abstract": "Wi-Fi access points have been widely deployed in homes, offices, and public spaces. Some APs allow users to adjust the antenna orientation to improve communication performance by optimizing antenna polarization. However, it is difficult for non-expert users to determine the optimal orientation, and users often leave the antenna orientation in ineffective positions. To address this issue, we developed a mechanical Wi-Fi antenna device capable of automatically tuning its orientation. Experimental results show that antenna orientation could cause a throughput variation of approximately 70 Mbps under line-of-sight conditions. Furthermore, Bayesian optimization identified better configurations than random search, demonstrating its effectiveness for orientation tuning."
  },
  {
    "date": "2026-01-26",
    "title": "Algebraic Phase Theory IV: Morphisms, Equivalences, and Categorical Rigidity",
    "authors": "Joe Gildea",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18254v1",
    "source": "arXiv",
    "abstract": "We complete the foundational architecture of Algebraic Phase Theory by developing a categorical and $2$-categorical framework for algebraic phases. Building on the structural notions introduced in Papers~I-III, we define phase morphisms, equivalence relations, and intrinsic invariants compatible with the canonical filtration and defect stratification. For finite, strongly admissible phases we establish strong rigidity theorems: phase morphisms are uniquely determined by their action on rigid cores, and under bounded defect, weak, strong, and Morita-type equivalence all coincide. In particular, finite strongly admissible phases admit no distinct models with the same filtered representation theory. We further show that structural boundaries are invariant under Morita-type equivalence and therefore constitute genuine categorical invariants. Algebraic phases, phase morphisms, and filtration-compatible natural transformations form a strict $2$-category in the strongly admissible regime. We also prove that completion defines a reflective localization of this category, with complete phases characterized as universal forced rigidifications. Together, these results elevate Algebraic Phase Theory from a collection of algebraic constructions to a categorical framework in which rigidity, equivalence collapse, boundary invariance, and completion arise as intrinsic consequences of phase interaction, finiteness, and admissibility."
  },
  {
    "date": "2026-01-26",
    "title": "Tractable Gaussian Phase Retrieval with Heavy Tails and Adversarial Corruption with Near-Linear Sample Complexity",
    "authors": "Santanu Das, Jatin Batra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18245v1",
    "source": "arXiv",
    "abstract": "Phase retrieval is the classical problem of recovering a signal $x^* \\in \\mathbb{R}^n$ from its noisy phaseless measurements $y_i = \\langle a_i, x^* \\rangle^2 + ζ_i$ (where $ζ_i$ denotes noise, and $a_i$ is the sensing vector) for $i \\in [m]$. The problem of phase retrieval has a rich history, with a variety of applications such as optics, crystallography, heteroscedastic regression, astrophysics, etc. A major consideration in algorithms for phase retrieval is robustness against measurement errors. In recent breakthroughs in algorithmic robust statistics, efficient algorithms have been developed for several parameter estimation tasks such as mean estimation, covariance estimation, robust principal component analysis (PCA), etc. in the presence of heavy-tailed noise and adversarial corruptions. In this paper, we study efficient algorithms for robust phase retrieval with heavy-tailed noise when a constant fraction of both the measurements $y_i$ and the sensing vectors $a_i$ may be arbitrarily adversarially corrupted. For this problem, Buna and Rebeschini (AISTATS 2025) very recently gave an exponential time algorithm with sample complexity $O(n \\log n)$. Their algorithm needs a robust spectral initialization, specifically, a robust estimate of the top eigenvector of a covariance matrix, which they deemed to be beyond known efficient algorithmic techniques (similar spectral initializations are a key ingredient of a large family of phase retrieval algorithms). In this work, we make a connection between robust spectral initialization and recent algorithmic advances in robust PCA, yielding the first polynomial-time algorithms for robust phase retrieval with both heavy-tailed noise and adversarial corruptions, in fact with near-linear (in $n$) sample complexity."
  },
  {
    "date": "2026-01-26",
    "title": "Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation",
    "authors": "Zerui Kang, Yishen Lim, Zhouyou Gu, Seung-Woo Ko, Tony Q. S. Quek, Jihong Park",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18242v1",
    "source": "arXiv",
    "abstract": "Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\\times$ faster convergence and 10-100$\\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation."
  },
  {
    "date": "2026-01-26",
    "title": "V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering",
    "authors": "Mengyuan Jin, Zehui Liao, Yong Xia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18240v1",
    "source": "arXiv",
    "abstract": "Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination."
  },
  {
    "date": "2026-01-26",
    "title": "Probing the Future of Meta-Analysis: Eliciting Design Principles via an Agentic Research IDE",
    "authors": "Sizhe Cheng, Feng Liang, Yuhan Wen, Xipei Yu, Yong Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18239v1",
    "source": "arXiv",
    "abstract": "Meta-analyses and systematic reviews demand rigorous abductive reasoning to build, test, and refine hypotheses across vast, heterogeneous literature. While NLP advancements have automated parts of this pipeline, existing tools often detach researchers from the cognitive loop or function merely as retrieval engines, leading to loss of intellectual ownership and frequent context switching. We present Research IDE, a prototype reimagining authoring environments through the \"Research as Code\" metaphor. Research IDE embeds a multi-agent backend into the writing flow, enabling in-situ verification via \"hypothesis breakpoints.\" A one-week field deployment with 8 domain experts, followed by a reflective workshop, as a Research through Design (RtD) probe, reveals that users strongly preferred this verification workflow, actively leveraged prior knowledge for confirmation, and reported that breakpoints sparked insights. Drawing from participant feedback and suggestions, we derive design implications for future AI-assisted research tools that fully preserve researcher autonomy and intellectual ownership while harnessing computational scale."
  },
  {
    "date": "2026-01-26",
    "title": "Revisiting $μ$-$e$ conversion in $R$-parity violating SUSY",
    "authors": "Yu-Qi Xiao, Xiao-Gang He, Hong-Yi Niu, Rong-Rong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18237v1",
    "source": "arXiv",
    "abstract": "The $μ$-$e$ conversion process is one of the most powerful ways to test lepton-flavor-violating (LFV) interactions involving charged leptons. The standard model with massive neutrinos predicts an extremely low rate for $μ$-$e$ conversion, making this process an excellent probe for testing LFV arising from new physics. Among many theoretical models that can induce LFV, the Supersymmetric model with R-parity violating interactions is one of the most studied for $μ$-$e$ conversion. In this work, we revisit trilinear R-parity violating interactions for $μ$-$e$ conversion, considering renormalization group (RG) running effects from high to low energy scales. The $μ$-$e$ conversion, $μ\\to e γ$, and $μ\\to eee$ experimental data are compared to give upper limits on the relevant 15 combinations of the trilinear $λ^{\\prime}$ couplings and 6 combinations of the $λ$ couplings, certain of which are underexplored in previous studies. We find that RG running effects influence the limits by no more than 30\\% in most cases, but can improve constraints by $\\sim$80\\% in certain combinations, which cannot be neglected. In the near future, COMET and Mu2e are expected to begin data-taking and aim to provide the most stringent constraints on $μ$-$e$ conversion. These next-generation $μ$-$e$ experiments have the ability to give much more comprehensive examinations on most trilinear coupling combinations than the $μ\\to eγ$ and $μ\\to 3e$ decay experiments. The $μ$-$e$ experiments will not only deepen our understanding of LFV but also provide a crucial way to examine the underlying new physics contributions."
  },
  {
    "date": "2026-01-26",
    "title": "Limit theorems for non linear (compound marked) Hawkes processes",
    "authors": "Benjamin Massat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18236v1",
    "source": "arXiv",
    "abstract": "In this article, we fill a gap in the literature on Hawkes processes. In particular, we derive a CLT for a non linear compound marked Hawkes process. We also provide an upper bound on the convergence rate using the functional 1-Wasserstein distance. This result is obtained by discretizing the time line and reducing the problem to the quantification of the distance between finite marginal vectors, as well as between the discretized process and the original one."
  },
  {
    "date": "2026-01-26",
    "title": "The global attractor of the Toner-Tu-Swift-Hohenberg equations of active turbulence and its properties",
    "authors": "Daniel W. Boutros, Kolluru Venkata Kiran, John D. Gibbon, Rahul Pandit",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18233v1",
    "source": "arXiv",
    "abstract": "The Toner-Tu-Swift-Hohenberg (TTSH) equations are one of the basic equations that are used to model turbulent behaviour in active matter, specifically the swarming of bacteria in suspension. They combine features of the incompressible Navier-Stokes, the Toner-Tu and Swift-Hohenberg equations, together with the important properties that they are linearly driven, and that the Laplacian diffusion is taken to be negative in combination with hyper-dissipation. We prove that the TTSH equations possess a finite-dimensional compact global attractor on the periodic domain $\\mathbb{T}^d$ ($d=2,3$) and we establish explicit estimates for its Lyapunov dimension which agree with the heuristic prediction based on the Swift-Hohenberg length scale. The predominance of this length scale (as a vortex length scale) has been observed in both numerical and experimental studies of bacterial turbulence, so our methods and results provide a rigorous theoretical foundation for this phenomenon. We also carry out pseudospectral direct numerical simulations of these PDEs in dimension $d=2$ through which we obtain Lyapunov spectra for representative parameter values. We show that our numerical results are consistent with the analytically derived rigorous bounds."
  },
  {
    "date": "2026-01-26",
    "title": "Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting",
    "authors": "Trong Khiem Tran, Manh Cuong Dao, Phi Le Nguyen, Thao Nguyen Truong, Trong Nghia Hoang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18231v1",
    "source": "arXiv",
    "abstract": "Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets."
  },
  {
    "date": "2026-01-26",
    "title": "Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach",
    "authors": "Sahil Naik, Soham Bagayatkar, Pavankumar Singh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18228v1",
    "source": "arXiv",
    "abstract": "Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications."
  },
  {
    "date": "2026-01-26",
    "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks",
    "authors": "Haotian Li, Shijun Yang, Weizhen Qi, Silei Zhao, Rui Hua, Mingzhu Song, Xiaojian Yang, Chao Peng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18226v1",
    "source": "arXiv",
    "abstract": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence."
  },
  {
    "date": "2026-01-26",
    "title": "Minimal spectral radius of graphs with given matching number",
    "authors": "Jiaqi Liu, Zhenzhen Lou, Vilmar Trevisan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18223v1",
    "source": "arXiv",
    "abstract": "The Brualdi-Solheid problem asks which graph achieves the extremal (maximum or minimum) spectral radius for a given class of graphs. This paper addresses the Brualdi-Solheid problem for \\( \\mathcal{G}_{n,β} \\), the family of graphs with order \\( n \\) and matching number \\( β\\), aiming to identify its spectrally minimal graphs i.e., those that minimize the spectral radius \\(ρ(G)\\). We introduce the novel concept of ``quasi-adjacency'' relation, developing a unified structural classification framework for trees in \\(\\mathcal{G}_{n,β}\\), which clarifies structural properties and provides a constructive method to generate trees with fixed \\(β\\). By showing that all spectrally minimal graphs in \\( \\mathcal{G}_{n,β} \\) are trees, we further narrow the search for extremal graphs. Additionally, we apply this framework to the representative cases \\(β=2,3,4\\), obtaining the minimizers by explicit structural formulas involving parameters related to \\(n\\)."
  },
  {
    "date": "2026-01-26",
    "title": "LLM-ForcedAligner: A Non-Autoregressive and Accurate LLM-Based Forced Aligner for Multilingual and Long-Form Speech",
    "authors": "Bingshen Mu, Xian Shi, Xiong Wang, Hexin Liu, Jin Xu, Lei Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18220v1",
    "source": "arXiv",
    "abstract": "Forced alignment (FA) predicts start and end timestamps for words or characters in speech, but existing methods are language-specific and prone to cumulative temporal shifts. The multilingual speech understanding and long-sequence processing abilities of speech large language models (SLLMs) make them promising for FA in multilingual, crosslingual, and long-form speech settings. However, directly applying the next-token prediction paradigm of SLLMs to FA results in hallucinations and slow inference. To bridge the gap, we propose LLM-ForcedAligner, reformulating FA as a slot-filling paradigm: timestamps are treated as discrete indices, and special timestamp tokens are inserted as slots into the transcript. Conditioned on the speech embeddings and the transcript with slots, the SLLM directly predicts the time indices at slots. During training, causal attention masking with non-shifted input and label sequences allows each slot to predict its own timestamp index based on itself and preceding context, with loss computed only at slot positions. Dynamic slot insertion enables FA at arbitrary positions. Moreover, non-autoregressive inference is supported, avoiding hallucinations and improving speed. Experiments across multilingual, crosslingual, and long-form speech scenarios show that LLM-ForcedAligner achieves a 69%~78% relative reduction in accumulated averaging shift compared with prior methods. The checkpoint and inference code will be released later."
  },
  {
    "date": "2026-01-26",
    "title": "Separating Energy and Entropy Contributions to the Hexatic-Liquid Transitions in Two-Dimensional Repulsive Systems",
    "authors": "Yan-Wei Li, Rui Ding, Wen-Hao Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18215v1",
    "source": "arXiv",
    "abstract": "Over the past decades, research on two-dimensional melting has established that both first-order and continuous hexatic-liquid transitions can occur, influenced by various factors in the potential energy and system details. The fundamental thermodynamic origins of this sensitivity remains elusive. Here, by decomposing the Helmholtz free energy across three representative repulsive systems, we reveal a universal competition between energy and entropy that dictates the melting pathway. The energetic contribution consistently imparts convexity to the free energy, whereas entropy imparts concavity. A first-order transition occurs when concave entropy dominates; otherwise, the transition is continuous. Further decomposition shows that vibrational entropy drives the concave total entropic curvature, while the configurational entropy's curvature switches from convex (first-order) to concave (continuous), mirroring defect proliferation measured by Shannon entropy. The convexity of the energy is dominated by the inherent potential, with minimal vibrational influence. Finally, we predict and verify that the first-order transition becomes continuous at zero temperature, where entropic effects vanish. Our work establishes the curvature of different thermodynamic quantities as a fundamental principle for understanding the nature of two-dimensional melting."
  },
  {
    "date": "2026-01-26",
    "title": "The Regge-Gribov model with odderons",
    "authors": "M. A. Braun, E. M. Kuzminskii, M. I. Vyazovsky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18206v1",
    "source": "arXiv",
    "abstract": "The Regge-Gribov model describing interacting pomerons and odderons is proposed with triple reggeon vertices taking into account the negative signature of the odderon. Its simplified version with zero transverse dimensions is first considered. No phase transition occurs in this case at the intercept crossing unity. This simplified model is studied without more approximations by numerical techniques. The physically relevant model in the two-dimensional transverse space is then studied by the renormalization group method in the single loop approximation. The pomeron and odderon are taken to have different bare intercepts and slopes. The behaviour when the intercepts move from below to their critical values compatible with the Froissart limitation is studied. Five real fixed points are found with singularities in the form of non-trivial branch points indicating a phase transition as the intercepts cross unity. The new phases, however, are not physical, since they violate the projectile-target symmetry. In the vicinity of fixed points the asymptotical behaviour of Green functions and elastic scattering amplitude is found under Glauber approximation for couplings to participants."
  },
  {
    "date": "2026-01-26",
    "title": "Scalable Quantum Message Passing Graph Neural Networks for Next-Generation Wireless Communications: Architectures, Use Cases, and Future Directions",
    "authors": "Le Tung Giang, Nguyen Xuan Tung, Trinh Van Chien, Lajos Hanzo, Won-Joo Hwang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18198v1",
    "source": "arXiv",
    "abstract": "Graph Neural Networks (GNNs) are eminently suitable for wireless resource management, thanks to their scalability, but they still face computational challenges in large-scale, dense networks in classical computers. The integration of quantum computing with GNNs offers a promising pathway for enhancing computational efficiency because they reduce the model complexity. This is achieved by leveraging the quantum advantages of parameterized quantum circuits (PQCs), while retaining the expressive power of GNNs. However, existing pure quantum message passing models remain constrained by the limited number of qubits, hence limiting the scalability of their application to the wireless systems. As a remedy, we conceive a Scalable Quantum Message Passing Graph Neural Network (SQM-GNN) relying on a quantum message passing architecture. To address the aforementioned scalability issue, we decompose the graph into subgraphs and apply a shared PQC to each local subgraph. Importantly, the model incorporates both node and edge features, facilitating the full representation of the underlying wireless graph structure. We demonstrate the efficiency of SQM GNN on a device-to-device (D2D) power control task, where it outperforms both classical GNNs and heuristic baselines. These results highlight SQM-GNN as a promising direction for future wireless network optimization."
  },
  {
    "date": "2026-01-26",
    "title": "QualiRAG: Retrieval-Augmented Generation for Visual Quality Understanding",
    "authors": "Linhan Cao, Wei Sun, Weixia Zhang, Xiangyang Zhu, Kaiwei Zhang, Jun Jia, Dandan Zhu, Guangtao Zhai, Xiongkuo Min",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18195v1",
    "source": "arXiv",
    "abstract": "Visual quality assessment (VQA) is increasingly shifting from scalar score prediction toward interpretable quality understanding -- a paradigm that demands \\textit{fine-grained spatiotemporal perception} and \\textit{auxiliary contextual information}. Current approaches rely on supervised fine-tuning or reinforcement learning on curated instruction datasets, which involve labor-intensive annotation and are prone to dataset-specific biases. To address these challenges, we propose \\textbf{QualiRAG}, a \\textit{training-free} \\textbf{R}etrieval-\\textbf{A}ugmented \\textbf{G}eneration \\textbf{(RAG)} framework that systematically leverages the latent perceptual knowledge of large multimodal models (LMMs) for visual quality perception. Unlike conventional RAG that retrieves from static corpora, QualiRAG dynamically generates auxiliary knowledge by decomposing questions into structured requests and constructing four complementary knowledge sources: \\textit{visual metadata}, \\textit{subject localization}, \\textit{global quality summaries}, and \\textit{local quality descriptions}, followed by relevance-aware retrieval for evidence-grounded reasoning. Extensive experiments show that QualiRAG achieves substantial improvements over open-source general-purpose LMMs and VQA-finetuned LMMs on visual quality understanding tasks, and delivers competitive performance on visual quality comparison tasks, demonstrating robust quality assessment capabilities without any task-specific training. The code will be publicly available at https://github.com/clh124/QualiRAG."
  },
  {
    "date": "2026-01-26",
    "title": "Relative bi-exactness and structural results for graph-wreath product von Neumann algebras",
    "authors": "Taisuke Hoshino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18185v1",
    "source": "arXiv",
    "abstract": "We study relative bi-exactness of graph product and graph-wreath product group von Neumann algebras. In particular, we obtain the relative bi-exactness for graph product von Neumann algebras $LH_Γ=\\ast_{v,Γ} LH_v$ and graph-wreath product von Neumann algebras $L(H_Γ\\rtimes G)=(\\ast_{v,Γ} LH)\\rtimes G$, assuming that the component groups are exact. We adopt the $C^{\\ast}$-algebraic method of Ozawa for the proof. As an application, for a certain class of graph-wreath products, we establish the rigidity result for the quotient graph $G\\backslashΓ$ under stable isomorphism. Furthermore, we obtain a new family of prime $\\mathrm{II}_1$ factors."
  },
  {
    "date": "2026-01-26",
    "title": "Inferring photospheric horizontal flows from multiple observations with SUVEL models",
    "authors": "Quan Xie, Jiajia Liu, Robert Erdélyi, Yuming Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18183v1",
    "source": "arXiv",
    "abstract": "Photospheric horizontal velocity fields play essential roles in the formation and evolution of numerous solar activities. Various methods for estimating the horizontal velocity field have been proposed in the past. Aiming at the highest available (and future) spatial resolution (10 km/pixel) observations, a new method the Shallow U-net models (SUVEL) based on realistic numerical simulation and machine learning techniques was recently developed to track the photospheric horizontal velocity fields. Although SUVEL has been tested on numerical simulation data, its performance on solar observational data remained unclear. In this work, we apply SUVEL to the photospheric intensity observations from four ground-based solar telescopes (DKIST, GST, NVST, and SST) with the largest available apertures, and compare the results obtained from SUVEL with the Fourier local correlation tracking method (FLCT). Average correlation indices between granular regions and velocity fields inferred by SUVEL (FLCT) are 0.63, 0.81, 0.80, and 0.87 (0.00, 0.11, 0.16, and 0.10) for DKIST, GST, NVST, and SST observations. Higher correlation indices between the velocity fields tracked by SUVEL and granular patterns than FLCT reveal the superior performance of SUVEL, validating its reliability with respect to solar observational data."
  },
  {
    "date": "2026-01-26",
    "title": "Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success",
    "authors": "Daniel Russo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18175v1",
    "source": "arXiv",
    "abstract": "A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective."
  },
  {
    "date": "2026-01-26",
    "title": "An Initial Evaluation of Distributed Graph Algorithms using NWGraph and HPX",
    "authors": "Karame Mohammadiporshokooh, Panagiotis Syskakis, Hartmut Kaiser",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18158v1",
    "source": "arXiv",
    "abstract": "Graphs are central to modeling relationships in scientific computing, data analysis, and AI/ML, but their growing scale can exceed the memory and compute capacity of single nodes, requiring distributed solutions. Existing distributed graph framework, however, face fundamental challenges: graph algorithms are latency-bound, suffer from irregular memory access, and often impose synchronization costs that limit scalability and efficiency. In this work, we present a distributed implementation of the NWGraph library integrated with the HPX runtime system. By leveraging HPX's asynchronous many-task model, our approach aims to reduce synchronization overhead, improve load balance, and provide a foundation for distributed graph analytics. We evaluate this approach using two representative algorithms: Breadth-First-Search (BFS) and (PageRank). Our initial results show that BFS achieves better performance than the distributed Boost Graph Library (BGL), while PageRank remains more challenging, with current implementation not yet outperforming BGL. These findings highlight both the promise and the open challenges of applying asynchronous task-based runtimes to graph processing, and point to opportunities for future optimizations and extensions."
  },
  {
    "date": "2026-01-26",
    "title": "Reconstructing Toponium using Recursive Jigsaw Reconstruction",
    "authors": "Aman Desai, Amelia Lovison, Paul Jackson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18155v1",
    "source": "arXiv",
    "abstract": "The results from the ATLAS and CMS experiment at the Large Hadron Collider indicate the existence of a top-quark pair bound state near the $\\ttbar$ threshold region. We present a method relying on Recursive Jigsaw Reconstruction to reconstruct the toponium bound state at the $\\ttbar$ threshold region. We propose incorporating two variables in the analysis that can improve sensitivity to the toponium signal. Our results indicate that this method may be useful to gain additional insights into the physics phenomenology of the $\\ttbar$ threshold region."
  },
  {
    "date": "2026-01-26",
    "title": "The Stability Limit of Prepotentials for Hurwitz-Frobenius Manifolds: An Infinite-Dimensional Approach",
    "authors": "Shilin Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18152v1",
    "source": "arXiv",
    "abstract": "The stability of prepotential derivatives for Frobenius manifolds associated with A_N and D_N singularities has been utilized to construct (2+1)-dimensional dispersionless integrable hierarchies. Although the generalization of this construction to genus-zero Hurwitz-Frobenius manifolds was shown to yield the genus-zero Whitham hierarchy, a direct geometric explanation of this correspondence has been lacking. In this note, we provide a direct proof of this identification within the framework of infinite-dimensional Frobenius manifolds. We demonstrate that the stability of prepotentials is an intrinsic property of the tau-structure of the Whitham hierarchy. Furthermore, we extend this identification to the hierarchies arising from the stability of solutions to the open WDVV equations with the extensions of the Whitham hierarchy."
  },
  {
    "date": "2026-01-26",
    "title": "Contact Plan Design For Optical Interplanetary Communications",
    "authors": "Jason Gerard, Juan A. Fraire, Sandra Cespedes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18148v1",
    "source": "arXiv",
    "abstract": "Space exploration missions generate rapidly increasing volumes of scientific telemetry that far exceed the capacity of today's manually scheduled, RF-based deep-space infrastructure. Free-space optical (FSO) communications promise orders of magnitude higher throughput, but their narrow beams require precise pointing, acquisition, and tracking (PAT) for link establishment and tightly synchronized contact schedules. Critically, no existing contact plan design (CPD) framework accounts for optical head retargeting delay, the time spent during coarse pointing and link acquisition before data transmission begins, which directly reduces usable contact time. Retargeting delay is the dominant impairment unique to optical networks, which induces a seconds-to-minutes-long mechanical pointing process for an optical terminal's laser from its current partner to the next receiver. This paper introduces the first PAT-aware CPD framework for optical interplanetary backhaul networks. The model captures directional temporal flows across both direct-to-Earth optical links and two-hop relay paths using delay/disruption-tolerant networking (DTN) satellites. We also introduce an optical network duty-cycle metric that quantifies the proportion of time spent transmitting to the contact window duration, exposing capacity lost to retargeting delay. Our results show that our MILP scheduler delivers over 30 percent higher network capacity than a greedy algorithm. More importantly, the results uncover a fundamental behavioral shift: when retargeting delays are modeled accurately, optimal schedules favor fewer but longer optical links that maximize throughput while minimizing retargeting overhead. These findings demonstrate that zero-delay assumptions substantially overestimate achievable performance and yield unrealistic contact plans."
  },
  {
    "date": "2026-01-26",
    "title": "Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking",
    "authors": "Huizhong Guo, Tianjun Wei, Dongxia Wang, Yingpeng Du, Ziyan Wang, Jie Zhang, Zhu Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18146v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly applied to ranking tasks in retrieval and recommendation. Although reasoning prompting can enhance ranking utility, our preliminary exploration reveals that its benefits are inconsistent and come at a substantial computational cost, suggesting that when to reason is as crucial as how to reason. To address this issue, we propose a reasoning routing framework that employs a lightweight, plug-and-play router head to decide whether to use direct inference (Non-Think) or reasoning (Think) for each instance before generation. The router head relies solely on pre-generation signals: i) compact ranking-aware features (e.g., candidate dispersion) and ii) model-aware difficulty signals derived from a diagnostic checklist reflecting the model's estimated need for reasoning. By leveraging these features before generation, the router outputs a controllable token that determines whether to apply the Think mode. Furthermore, the router can adaptively select its operating policy along the validation Pareto frontier during deployment, enabling dynamic allocation of computational resources toward instances most likely to benefit from Think under varying system constraints. Experiments on three public ranking datasets with different scales of open-source LLMs show consistent improvements in ranking utility with reduced token consumption (e.g., +6.3\\% NDCG@10 with -49.5\\% tokens on MovieLens with Qwen3-4B), demonstrating reasoning routing as a practical solution to the accuracy-efficiency trade-off."
  },
  {
    "date": "2026-01-26",
    "title": "Exact Minimum-Volume Confidence Set Intersection for Multinomial Outcomes",
    "authors": "Heguang Lin, Binhao Chen, Mengze Li, Daniel Pimentel-Alarcón, Matthew L. Malloy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18145v1",
    "source": "arXiv",
    "abstract": "Computation of confidence sets is central to data science and machine learning, serving as the workhorse of A/B testing and underpinning the operation and analysis of reinforcement learning algorithms. Among all valid confidence sets for the multinomial parameter, minimum-volume confidence sets (MVCs) are optimal in that they minimize average volume, but they are defined as level sets of an exact p-value that is discontinuous and difficult to compute. Rather than attempting to characterize the geometry of MVCs directly, this paper studies a practically motivated decision problem: given two observed multinomial outcomes, can one certify whether their MVCs intersect? We present a certified, tolerance-aware algorithm for this intersection problem. The method exploits the fact that likelihood ordering induces halfspace constraints in log-odds coordinates, enabling adaptive geometric partitioning of parameter space and computable lower and upper bounds on p-values over each cell. For three categories, this yields an efficient and provably sound algorithm that either certifies intersection, certifies disjointness, or returns an indeterminate result when the decision lies within a prescribed margin. We further show how the approach extends to higher dimensions. The results demonstrate that, despite their irregular geometry, MVCs admit reliable certified decision procedures for core tasks in A/B testing."
  },
  {
    "date": "2026-01-26",
    "title": "An Extension of the $sl(n)$ Polynomial to Knotted 4-Valent Graphs",
    "authors": "Carmen Caprau, Victoria Wiest",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18144v1",
    "source": "arXiv",
    "abstract": "We use planar 4-valent graphs and a graphical calculus involving such graphs to construct an invariant for balanced-oriented, knotted 4-valent graphs. Our invariant is an extension of the $sl(n)$ polynomial for classical knots and links. We also provide a minimal generating set of Reidemeister-type moves for diagrams of balanced-oriented, knotted 4-valent graphs."
  },
  {
    "date": "2026-01-26",
    "title": "DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints",
    "authors": "Yinger Zhang, Shutong Jiang, Renhao Li, Jianhong Tu, Yang Su, Lianghao Deng, Xudong Guo, Chenxu Lv, Junyang Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18137v1",
    "source": "arXiv",
    "abstract": "While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research."
  },
  {
    "date": "2026-01-26",
    "title": "RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents",
    "authors": "Jize Wang, Han Wu, Zhiyuan You, Yiming Song, Yijun Wang, Zifei Shan, Yining Li, Songyang Zhang, Xinyi Le, Cailian Chen, Xinping Guan, Dacheng Tao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18130v1",
    "source": "arXiv",
    "abstract": "Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool."
  },
  {
    "date": "2026-01-26",
    "title": "Understanding Users' Privacy Reasoning and Behaviors During Chatbot Use to Support Meaningful Agency in Privacy",
    "authors": "Mohammad Hadi Nezhad, Francisco Enrique Vicente Castro, Ivon Arroyo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18125v1",
    "source": "arXiv",
    "abstract": "Conversational agents (CAs) (e.g., chatbots) are increasingly used in settings where users disclose sensitive information, raising significant privacy concerns. Because privacy judgments are highly contextual, supporting users to engage in privacy-protective actions during chatbot interactions is essential. However, enabling meaningful engagement requires a deeper understanding of how users currently reason about and manage sensitive information during realistic chatbot use scenarios. To investigate this, we qualitatively examined computer science (undergraduate and masters) students' in-the-moment disclosure and protection behaviors, as well as the reasoning underlying these behaviors, across a range of realistic chatbot tasks. Participants used a simulated ChatGPT interface with and without a privacy notice panel that intercepts message submissions, highlights potentially sensitive information, and offers privacy protective actions. The panel supports anonymization through retracting, faking, and generalizing, and surfaces two of ChatGPT's built-in privacy controls to improve their discoverability. Drawing on interaction logs, think-alouds, and survey responses, we analyzed how the panel fostered privacy awareness, encouraged protective actions, and supported context-specific reasoning about what information to protect and how. We further discuss design opportunities for tools that provide users greater and more meaningful agency in protecting sensitive information during CA interactions."
  },
  {
    "date": "2026-01-26",
    "title": "Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters",
    "authors": "Muhammad Ibrahim Khan, Bivin Pradeep, James Brusey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18123v1",
    "source": "arXiv",
    "abstract": "Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained."
  },
  {
    "date": "2026-01-26",
    "title": "A Generalized Weak Galerkin Method for Linear Elasticity with Nonpolynomial Approximations",
    "authors": "Junping Wang, Yue Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18120v1",
    "source": "arXiv",
    "abstract": "This paper presents a generalized weak Galerkin (gWG) finite element method for linear elasticity problems on general polygonal and polyhedral meshes. The proposed framework is flexible and efficient, allowing for the use of nonpolynomial approximating functions. The generalized weak differential operators are defined as an element-level correction of the classical differential operators accounting for boundary discontinuities. This construction reduces computational cost and provides greater flexibility than standard weak Galerkin formulations. The gWG framework naturally accommodates arbitrary finite-dimensional approximation spaces, including nonpolynomial activation-based spaces with randomly selected parameters. Error equations and error estimates are established for the proposed method. Numerical experiments demonstrate that the method is locking-free, robust with respect to mesh geometry, and effective on general polygonal and polyhedral partitions. In particular, activation-based interior approximation spaces exhibit convergence behavior comparable to that of classical polynomial spaces."
  },
  {
    "date": "2026-01-26",
    "title": "FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning",
    "authors": "Lin Sun, Linglin Zhang, Jingang Huang, Change Jia, Zhengwei Cheng, Xiangzheng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18116v1",
    "source": "arXiv",
    "abstract": "The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis. We present \\textbf{FABLE}, a \\textbf{F}orest-based \\textbf{A}daptive \\textbf{B}i-path \\textbf{L}LM-\\textbf{E}nhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs. Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval."
  },
  {
    "date": "2026-01-26",
    "title": "Mitigating Deadtime in Distributed Optical Arrays: A Liveness-Aware Trigger Approach for High-Energy Neutrino Detection",
    "authors": "Thammarat Yawisit, Pittaya Pannil",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18114v1",
    "source": "arXiv",
    "abstract": "Large-scale neutrino observatories operate under unavoidable detector deadtime arising from photomultiplier saturation, digitizer limits, and front-end readout constraints. Conventional coincidence-based trigger logic implicitly assumes continuous sensor availability and therefore suffers systematic efficiency loss when channels become temporarily non-live. This work presents the design of a liveness-aware trigger architecture targeting low-latency FPGA deployment in distributed optical arrays. We introduce a recursive Infinite Impulse Response (IIR) update law implemented as a fully synthesizable pipeline that constructs a continuity-preserving effective observable at each sensor node. Rather than collapsing during non-liveness intervals, the observable decays smoothly while retaining phase and amplitude information relevant for network-level coherence estimation. By explicitly separating continuous measurement construction from discrete trigger decision logic, the proposed architecture enables graceful degradation under partial channel non-liveness. Performance is evaluated using a hybrid validation framework that combines representative event topologies derived from IceCube Open Data with a hardware-accurate signal and noise model spanning a wide dynamic range. Simulation results demonstrate that the proposed trigger sustains high event recovery efficiency in regimes of elevated deadtime probability, where conventional coincidence logic degrades substantially. Furthermore, the continuity-preserving observable yields up to a two-order-of-magnitude improvement in effective signal-to-noise ratio, enabling robust detection under strong saturation and non-ideal operating conditions. This method provides a robust foundation for next-generation firmware-level trigger strategies in large-scale, noise-dominated detector systems."
  },
  {
    "date": "2026-01-26",
    "title": "Effects of Stellar X-ray Photoevaporation on Planetesimal Formation via the Streaming Instability",
    "authors": "Xuchu Ying, Beibei Liu, Haifeng Yang, Joanna Drazkowska, Sebastian M. Stammler, Zhaohuan Zhu, Linn E. J. Eriksson, Hongping Deng, Bin Liu, Ping Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18112v1",
    "source": "arXiv",
    "abstract": "The formation of planetesimals via the streaming instability (SI) is a crucial step in planet formation, yet its triggering conditions and efficiency are highly sensitive to both disk properties and specific evolutionary processes. We aim to study the planetesimal formation via the SI, driven by the stellar X-ray photoevaporation during the late stages of disk dispersal, and quantify its dependence on key disk and stellar parameters. We use the DustPy code to simulate the dust dynamics including coagulation, fragmentation, and radial drift in a viscously accreting disk undergoing stellar X-ray photoevaporation. Stellar X-rays drive the disk dispersal, opening a cavity at a few au orbital distance and inducing the formation of an associated local pressure maximum. This pressure maximum acts as a trap for radially drifting dust, therefore enhancing the dust density to the critical level required to initiate the streaming instability and the subsequent collapse into planetesimals. The fiducial model produces 31.4 M_\\oplus of planetesimals with an initial dust to final planetesimal conversion efficiency of 20.4%. This pathway is most efficient in larger disks with higher metallicities, lower viscosities, higher dust fragmentation threshold velocities, and/or around stars with higher X-ray luminosities. This work demonstrates that stellar X-ray photoevaporation is a robust and feasible mechanism for triggering planetesimal formation via the SI during the final clearing phase of protoplanetary disk evolution."
  },
  {
    "date": "2026-01-26",
    "title": "GLEN-Bench: A Graph-Language based Benchmark for Nutritional Health",
    "authors": "Jiatan Huang, Zheyuan Zhang, Tianyi Ma, Mingchen Li, Yaning Zheng, Yanfang Ye, Chuxu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18106v1",
    "source": "arXiv",
    "abstract": "Nutritional interventions are important for managing chronic health conditions, but current computational methods provide limited support for personalized dietary guidance. We identify three key gaps: (1) dietary pattern studies often ignore real-world constraints such as socioeconomic status, comorbidities, and limited food access; (2) recommendation systems rarely explain why a particular food helps a given patient; and (3) no unified benchmark evaluates methods across the connected tasks needed for nutritional interventions. We introduce GLEN-Bench, the first comprehensive graph-language based benchmark for nutritional health assessment. We combine NHANES health records, FNDDS food composition data, and USDA food-access metrics to build a knowledge graph that links demographics, health conditions, dietary behaviors, poverty-related constraints, and nutrient needs. We test the benchmark using opioid use disorder, where models must detect subtle nutritional differences across disease stages. GLEN-Bench includes three linked tasks: risk detection identifies at-risk individuals from dietary and socioeconomic patterns; recommendation suggests personalized foods that meet clinical needs within resource constraints; and question answering provides graph-grounded, natural-language explanations to facilitate comprehension. We evaluate these graph-language approaches, including graph neural networks, large language models, and hybrid architectures, to establish solid baselines and identify practical design choices. Our analysis identifies clear dietary patterns linked to health risks, providing insights that can guide practical interventions."
  },
  {
    "date": "2026-01-26",
    "title": "Scattering lengths of the $J/ψπ$ and $J/ψK$ systems",
    "authors": "Jiang Yan, Xiong-Hui Cao, Meng-Lin Du, Feng-Kun Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18103v1",
    "source": "arXiv",
    "abstract": "We investigate the low-energy interactions between the charmonium state $J/ψ$ and the light pseudoscalar mesons ($π$ and $K$) within the framework of dispersion relations.We demonstrate that the symmetry-breaking terms in the chiral Lagrangian induce mixing between the bare charmonium fields, necessitating a diagonalization procedure to correctly identify the physical $J/ψ$ and $ψ'$ states. Following this diagonalization, we relate the threshold scattering amplitudes of $J/ψ{\\cal P}~({\\cal P}=π,K)$, which determine the scattering lengths, to the $J/ψJ/ψ\\to {\\cal P}\\bar{\\cal P}$ amplitudes via crossing symmetry. The ${\\cal P}\\bar{\\cal P}$ rescattering effects are incorporated using dispersion relations. We obtain the $S$-wave scattering lengths $a_{J/ψπ} \\lesssim -0.0021$~fm and $a_{J/ψK} \\lesssim -0.028$~fm, where the negative sign indicates an attractive interaction. Our results show that the $J/ψK$ interaction is moderately enhanced relative to the pion channel, driven by explicit chiral symmetry breaking. Furthermore, a quantitative comparison of the coupled-channel mechanism, where $J/ψπ$ couples to $D\\bar{D}^*$ and $J/ψK$ couples to $D^*\\bar{D}_s/D\\bar{D}_s^*$, reveals that both $J/ψπ$ and $J/ψK$ scatterings are predominantly governed by the soft-gluon exchange mechanism."
  },
  {
    "date": "2026-01-26",
    "title": "Spatial-Conditioned Reasoning in Long-Egocentric Videos",
    "authors": "James Tribble, Hao Wang, Si-En Hong, Chaoyi Zhou, Ashish Bastola, Siyu Huang, Abolfazl Razi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18100v1",
    "source": "arXiv",
    "abstract": "Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection."
  },
  {
    "date": "2026-01-26",
    "title": "Chain-Length-Dependent Partitioning of 1-Alkanols in Raft-Like Lipid Membranes",
    "authors": "Anirban Polley",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18095v1",
    "source": "arXiv",
    "abstract": "Although 1-alkanols are widely used as anesthetics and membrane-active agents, the molecular basis of their chain-length-dependent cutoff behavior remains unclear. Here, we perform extensive atomistic molecular dynamics simulations to investigate the partitioning of 1-alkanols with varying chain lengths in a raft-like lipid bilayer composed of dipalmitoylphosphatidylcholine (DPPC), dioleoylphosphatidylcholine (DOPC), and cholesterol (Chol), which exhibits coexistence of liquid-ordered ($l_o$) and liquid-disordered ($l_d$) domains. We observe pronounced lateral heterogeneity in alkanol distribution, membrane thickness, number density, and lateral pressure profiles across coexisting phases. A distinct cutoff chain length, $n_{cutoff}=12$, is identified: alkanols with $n<n_{cutoff}$ preferentially partition into DOPC-rich $l_d$ domains, whereas alkanols with $n \\ge n_{cutoff}$ preferentially localize within DPPC- and cholesterol-rich $l_o$ domains. This chain-length-dependent redistribution is accompanied by systematic reductions in the lateral pressure profile, membrane compressibility, and bending rigidity of the bilayer. The results provide a detailed molecular characterization of how alkanol chain length modulates membrane structure and mechanical response in laterally heterogeneous lipid membranes."
  },
  {
    "date": "2026-01-26",
    "title": "OneVoice: One Model, Triple Scenarios-Towards Unified Zero-shot Voice Conversion",
    "authors": "Zhichao Wang, Tao Li, Wenshuo Ge, Zihao Cui, Shilei Zhang, Junlan Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18094v1",
    "source": "arXiv",
    "abstract": "Recent progress of voice conversion~(VC) has achieved a new milestone in speaker cloning and linguistic preservation. But the field remains fragmented, relying on specialized models for linguistic-preserving, expressive, and singing scenarios. We propose OneVoice, a unified zero-shot framework capable of handling all three scenarios within a single model. OneVoice is built upon a continuous language model trained with VAE-free next-patch diffusion, ensuring high fidelity and efficient sequence modeling. Its core design for unification lies in a Mixture-of-Experts (MoE) designed to explicitly model shared conversion knowledge and scenario-specific expressivity. Expert selection is coordinated by a dual-path routing mechanism, including shared expert isolation and scenario-aware domain expert assignment with global-local cues. For precise conditioning, scenario-specific prosodic features are fused into each layer via a gated mechanism, allowing adaptive usage of prosody information. Furthermore, to enable the core idea and alleviate the imbalanced issue (abundant speech vs. scarce singing), we adopt a two-stage progressive training that includes foundational pre-training and scenario enhancement with LoRA-based domain experts. Experiments show that OneVoice matches or surpasses specialized models across all three scenarios, while verifying flexible control over scenarios and offering a fast decoding version as few as 2 steps. Code and model will be released soon."
  },
  {
    "date": "2026-01-26",
    "title": "Pulse-driven photonic transitions and nonreciprocity in space-time modulated metasurfaces",
    "authors": "Zeki Hayran, John B. Pendry, Prasad P. Iyer, Francesco Monticone",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18084v1",
    "source": "arXiv",
    "abstract": "Time-varying photonic systems open new possibilities for controlling light, enabling photonic time crystals, time reflection and refraction, frequency conversion, synthetic gauge fields, optical nonreciprocity, among others. These effects emerge from the dynamic modulation of optical properties, which can mediate photonic transitions between eigenstates of different frequencies and/or wavevectors. To achieve such transitions, conventional approaches rely on periodic modulation schemes that demand ultrafast modulation rates and continuous energy input, posing significant practical challenges at optical frequencies. Here, we demonstrate that periodic-modulation-driven photonic transitions within the radiation continuum can be effectively mimicked using a single-period ultrafast pulse modulation, eliminating the need for sustained continuous modulation. By leveraging dispersion engineering in metasurfaces to tailor the density of states in the radiation continuum, we achieve controlled frequency transitions and theoretically demonstrate strong nonreciprocity for free-space waves as a key application. Our findings may guide future experimental research on time-varying photonics using materials such as transparent conductive oxides and semiconductors, expanding the possibilities for ultrafast and reconfigurable optical technologies. More broadly, our work may establish a practical and energy-efficient framework for dynamic photonic systems, with potential applications ranging from spatio-temporal wavefront manipulation to photonic computing and ultrafast signal processing."
  },
  {
    "date": "2026-01-26",
    "title": "Effects of stimulation frequencies on energy efficiency of a muscle fiber during contraction",
    "authors": "Jiaxiang Xu, Bin Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18073v1",
    "source": "arXiv",
    "abstract": "Contradictory experimental reports on the relationship between efficiency and stimulation frequency have hindered mechanistic understanding in converting neural activity into mechanical work during muscle contraction. To resolve this issue, we develop a biophysical model integrating calcium-mediated excitation with a detailed cross-bridge cycle to enable single-fiber simulations. Our model demonstrates that shortening velocity is the primary determinant of cross-bridge efficiency: efficiency peaks at an optimal velocity and declines at higher or lower velocities, while frequency exerts secondary influence. Critically, the velocity yielding peak efficiency remains consistent across frequencies, with a slight upward shift at higher frequencies. Elevated inorganic phosphate ([Pi]) appears to amplify the efficiency disparity between high- and low-frequency regimes in our analysis. Our work suggests that stimulation frequency modulates efficiency predominantly through its regulation of shortening velocity, which primarily governs the kinetics of the myosin power stroke. This work may help clarify neural control of muscle energetics, and provide a quantitative foundation for studying muscle function in physiological and pathological contexts."
  },
  {
    "date": "2026-01-26",
    "title": "XGuardian: Towards Explainable and Generalized AI Anti-Cheat on FPS Games",
    "authors": "Jiayi Zhang, Chenxin Sun, Chenxiong Qian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18068v1",
    "source": "arXiv",
    "abstract": "Aim-assist cheats are the most prevalent and infamous form of cheating in First-Person Shooter (FPS) games, which help cheaters illegally reveal the opponent's location and auto-aim and shoot, and thereby pose significant threats to the game industry. Although a considerable research effort has been made to automatically detect aim-assist cheats, existing works suffer from unreliable frameworks, limited generalizability, high overhead, low detection performance, and a lack of explainability of detection results. In this paper, we propose XGuardian, a server-side generalized and explainable system for detecting aim-assist cheats to overcome these limitations. It requires only two raw data inputs, pitch and yaw, which are all FPS games' must-haves, to construct novel temporal features and describe aim trajectories, which are essential for distinguishing cheaters and normal players. XGuardian is evaluated with the latest mainstream FPS game CS2, and validates its generalizability with another two different games. It achieves high detection performance and low overhead compared to prior works across different games with real-world and large-scale datasets, demonstrating wide generalizability and high effectiveness. It is able to justify its predictions and thereby shorten the ban cycle. We make XGuardian as well as our datasets publicly available."
  },
  {
    "date": "2026-01-26",
    "title": "Overcoming Barren Plateaus in Variational Quantum Circuits using a Two-Step Least Squares Approach",
    "authors": "Francis Boabang, Samuel Asante Gyamerah",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18060v1",
    "source": "arXiv",
    "abstract": "Variational Quantum Algorithms are a vital part of quantum computing. It is a blend of quantum and classical methods for tackling tough problems in machine learning, chemistry, and combinatorial optimization. Yet as these algorithms scale up, they cannot escape the barren-plateau phenomenon. As systems grow, gradients can vanish so quickly that training deep or randomly initialized circuits becomes nearly impossible. To overcome the barren plateau problem, we introduce a two-stage optimization framework. First comes the convex initialization stage. Here, we shape the quantum energy landscape, the Hilmaton landscape, into a smooth, low-energy basin. This step makes gradients easier to spot and keeps noise from derailing the process. Once we have gotten a stable gradient flow, we move to the second stage: nonconvex refinement. In this phase, we allow the algorithm to explore different energy minima, thereby making the model more expressive. Finally, we used our two-stage solution to perform quantum cryptanalysis of the quantum key distribution protocol (i.e., BB84) to determine the optimal cloning strategies. The simulation results showed that our proposed two-stage solution outperforms its random initialization counterpart."
  },
  {
    "date": "2026-01-26",
    "title": "Addressing LLM Diversity by Infusing Random Concepts",
    "authors": "Pulin Agrawal, Prasoon Goyal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18053v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form \"Name 10 Hollywood actors\", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically."
  },
  {
    "date": "2026-01-26",
    "title": "Neutrino opacities in magnetic fields for binary neutron star merger simulations",
    "authors": "Mia Kumamoto, Catherine Welch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18051v1",
    "source": "arXiv",
    "abstract": "Neutrino interactions play a central role in transport and flavor evolution in the ejecta of binary neutron star mergers. Simulations suggest that neutron star mergers may produce magnetic fields as strong as $10^{17}$ G, but computational difficulties have hampered the inclusion of magnetic field effects in neutrino interaction rates. In this paper we give approximate interaction rates for neutrinos in the presence of strong magnetic fields, including the effects of Landau quantization and anomalous magnetic moments with errors of order $\\sqrt{T/M}$. We also comment on a neutrino production channel from individual neutrons that can produce low-energy $ν\\barν$ pairs even at low density."
  },
  {
    "date": "2026-01-26",
    "title": "Multi-target density matrix renormalization group for 3D CFTs on the fuzzy sphere",
    "authors": "Jin-Xiang Hao, Zheng Zhu, Yang Qi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18648v1",
    "source": "arXiv",
    "abstract": "The fuzzy sphere regularization provides a powerful framework for studying three-dimensional (3D) conformal field theories (CFTs) by mapping them onto numerically tractable lattice models on the spherical lowest Landau level. However, the system sizes accessible to this method have been limited by the exact diagonalization (ED). In this work, we transcend this limitation by combining the fuzzy sphere regularization with a sophisticated multi-target density matrix renormalization group (DMRG) algorithm. Focusing on the 3D Ising-type model on the spherical lowest Landau level, we calculate the 24 low-lying energies at a larger system size than previously feasible with ED. At criticality, we extract the scaling dimensions of six primary operators, and the results show significantly improved agreement with bootstrap benchmarks compared to previous ED results at smaller sizes. Our approach allows us to efficiently target multiple excited states in larger systems beyond the reach of exact diagonalization. This study establishes the fuzzy sphere regularization combined with advanced DMRG techniques as a powerful and general framework for precision physics in 3D CFTs."
  },
  {
    "date": "2026-01-26",
    "title": "On slope unstable Fano varieties",
    "authors": "Yen-An Chen, Ching-Jui Lai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18526v1",
    "source": "arXiv",
    "abstract": "For Fano varieties, significant progress has been made recently in the study of $K$-stability, while the understanding of the weaker but more algebraic concept of $(-K)$-slope stability remains intricate. For instance, a conjecture attributed to Iskovskikh states that the tangent bundle of a Picard rank one Fano manifold is slope stable. Peternell-Wiśniewski and Hwang proved this conjecture up to dimension five in 1998, but Kanemitsu later disproved it in 2021. To address this gap in understanding, we present a method that aims to characterize the geometry associated with the maximal destabilizing sheaf of the tangent sheaf of a Fano variety. This approach utilizes modern advancements in the foliated minimal model program. In dimension two, our approach leads to a complete classification of $(-K)$-slope unstable weak del Pezzo surfaces with canonical singularities. As by-products, we provide the first conceptual proof that $\\mathbb{P}^1 \\times \\mathbb{P}^1$ and $\\mathbb{F}_1$ are the only $(-K)$-slope unstable nonsingular del Pezzo surfaces, recovering a classical result of Fahlaoui in 1989. We also uncover a phenomenon that does not occur for Fano manifolds: there exists a del Pezzo surface with type A singularities admitting a weak Kähler-Einstein metric, yet whose tangent sheaf is slope unstable."
  },
  {
    "date": "2026-01-26",
    "title": "Preference-based Centrality and Ranking in General Metric Spaces",
    "authors": "Lingfeng Lyu, Doudou Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18412v1",
    "source": "arXiv",
    "abstract": "Assessing centrality or ranking observations in multivariate or non-Euclidean spaces is challenging because such data lack an intrinsic order and many classical depth notions lose resolution in high-dimensional or structured settings. We propose a preference-based framework that defines centrality through population pairwise proximity comparisons: a point is central if a typical draw from the underlying distribution tends to lie closer to it than to another. This perspective yields a well-defined statistical functional that generalizes data depth to arbitrary metric spaces. To obtain a coherent one-dimensional representation, we study a Bradley-Terry-Luce projection of the induced preferences and develop two finite-sample estimators based on convex M-estimation and spectral aggregation. The resulting procedures are consistent, scalable, and applicable to high-dimensional and non-Euclidean data, and across a range of examples they exhibit stable ranking behavior and improved resolution relative to classical depth-based methods."
  },
  {
    "date": "2026-01-26",
    "title": "Learning Fair Domain Adaptation with Virtual Label Distribution",
    "authors": "Yuguang Zhang, Lijun Sheng, Jian Liang, Ran He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18171v1",
    "source": "arXiv",
    "abstract": "Unsupervised Domain Adaptation (UDA) aims to mitigate performance degradation when training and testing data are sampled from different distributions. While significant progress has been made in enhancing overall accuracy, most existing methods overlook performance disparities across categories-an issue we refer to as category fairness. Our empirical analysis reveals that UDA classifiers tend to favor certain easy categories while neglecting difficult ones. To address this, we propose Virtual Label-distribution-aware Learning (VILL), a simple yet effective framework designed to improve worst-case performance while preserving high overall accuracy. The core of VILL is an adaptive re-weighting strategy that amplifies the influence of hard-to-classify categories. Furthermore, we introduce a KL-divergence-based re-balancing strategy, which explicitly adjusts decision boundaries to enhance category fairness. Experiments on commonly used datasets demonstrate that VILL can be seamlessly integrated as a plug-and-play module into existing UDA methods, significantly improving category fairness."
  },
  {
    "date": "2026-01-26",
    "title": "Sub-ion scale current sheets in kinetic Alfvén wave turbulence",
    "authors": "Johan Sharma, Ch Akshath Kumar, Kirit D. Makwana, Tulasi N Parashar, Sruti Satyasmita",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18131v1",
    "source": "arXiv",
    "abstract": "3D kinetic particle-in-cell (PIC) simulations are performed using the kinetic Alfvén wave (KAW) eigenvector relations from a two-fluid model as initial conditions, in order to study turbulent fluctuations and intermittent structures at sub-ion and electron scales. Simulations with different ion-to-electron mass ratios are set up to investigate the role of electron scales in the formation of intermittent structures. We analyze the current sheet structures that develop in these simulations. Two algorithms, namely Breadth-First Search (BFS) and Density-Based Spatial Clustering of Applications with Noise (DBSCAN), are employed to determine the thickness, length, and width of the current sheets, and both methods are found to yield consistent results. The average current sheet thickness scales inversely with the square root of the ion-to-electron mass ratio, with values close to the electron skin depth ($d_e$), indicating the presence of electron-scale current sheets in the simulations. The widths and lengths of the current sheets show a weaker scaling with the mass ratio. The scale-dependent kurtosis reveals enhanced intermittency at electron scales, consistent with magnetosheath observations. Distributions of scale-dependent properties of the current sheets also align with the electron skin depth of the different simulations and they lie within ranges observed in kinetic scale solar wind turbulence. This study reveals the nature of sub-ion-scale current sheets in KAW turbulence and their role in dissipation."
  },
  {
    "date": "2026-01-26",
    "title": "GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback",
    "authors": "James Sungarda, Hongkai Liu, Zilong Zhou, Tien-Hsuan Wu, Johnson Chun-Sing Cheung, Ben Kao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18517v1",
    "source": "arXiv",
    "abstract": "Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship."
  },
  {
    "date": "2026-01-26",
    "title": "Coding Schemes for Document Exchange under Multiple Substring Edits",
    "authors": "Hrishi Narayanan, Vinayak Ramkumar, Rawad Bitar, Antonia Wachter-Zeh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18441v1",
    "source": "arXiv",
    "abstract": "We study the document exchange problem under multiple substring edits. A substring edit in a string $\\mathbf{x}$ occurs when a substring $\\mathbf{u}$ of $\\mathbf{x}$ is replaced by an arbitrary string $\\mathbf{v}$. The lengths of $\\mathbf{u}$ and $\\mathbf{v}$ are bounded from above by a fixed constant. Let $\\mathbf{x}$ and $\\mathbf{y}$ be two binary strings that differ by multiple substring edits. The aim of document exchange schemes is to construct an encoding of $\\mathbf{x}$ with small length such that $\\mathbf{x}$ can be recovered using $\\mathbf{y}$ and the encoding. We construct a low-complexity document exchange scheme with encoding length of $4t\\log n+o(\\log n)$ bits, where $n$ is the length of the string $\\mathbf{x}$. The best known scheme achieves an encoding length of $4t \\log n+O(\\log\\log n)$ bits, but at a much higher computational complexity. Then, we investigate the average length of valid encodings for document exchange schemes with uniform strings $\\mathbf{x}$ and develop a scheme with an expected encoding length of $(4t-1) \\log n+o(\\log n)$ bits. In this setting, prior works have only constructed schemes for a single substring edit."
  },
  {
    "date": "2026-01-26",
    "title": "Geometrical Constraints On Leptonic Unitarity Triangles",
    "authors": "Mathieu Guigue, Lorenzo Restrepo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18601v1",
    "source": "arXiv",
    "abstract": "The precision of the neutrino oscillation parameters measurements has improved and will continue to improve as the next-generation experiments become online. Beyond the more precise measurements of the mixing angles and phases used to parametrize the lepton mixing matrix, tests of its unitarity are of great interest. This paper studies how the amplitudes of the oscillation patterns can be used and combined to construct leptonic unitarity triangles."
  },
  {
    "date": "2026-01-26",
    "title": "Multi-epoch VLBI observations of the blazar 3C 66A: Spatial twisting and temporal oscillation of the parsec-scale jet",
    "authors": "Paloma Thevenet, Jeonguk Kim, Guang-Yao Zhao, Bong Won Sohn, Suk-Jin Yoon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18551v1",
    "source": "arXiv",
    "abstract": "Previous VLBI kinematic studies of the blazar 3C 66A have unveiled complex jet kinematic behaviors. Using follow-up high-resolution VLBI observations and archival data, we investigate the morphology and the variations in orientation and core flux density of the 3C 66A jet to gain a deeper insights into its kinematic behavior and physical origins. We performed KVN and VERA array (KaVA) observations at 22/43 GHz over three epochs in 2014 and collected 109 sets of Very Long Baseline Array (VLBA) archival data at 43 GHz between 1996 - 2025. We imaged the parsec-scale jet and parameterized it using circular Gaussian fittings to the UV visibilities. Finally, we derived the inner jet PA and the core flux densities for the VLBA data. The jet presents a twisted morphology in the KaVA maps. The PA of the fitted Gaussian components is in the range between 170 deg and 195 deg. Our kinematic analysis using the VLBA data indicates that the PA oscillates with an amplitude of 7.77 pm 0.79 deg and a period of 10.94 pm 0.22 years, presented for the first time in this work. This oscillation is topped by a continuous clockwise shift of the PA by -0.83 pm 0.07 deg/year. We also identified a strong core flux variability with possible periodicity and a 2 sigma correlation between the core flux density and the inner jet PA change. We discuss possible physical models that could explain the observed features for this object; in particular, a supermassive black hole binary (SMBHB) system, Lense Thirring (LT) effect, and jet or disk instabilities. The oscillation and continuous shift of the PA and the possible radio flux periodicity, together with the optical flux periodicity of approximately 2 years that had previously been confirmed in several independent studies, favor a jet precession scenario driven by orbital motion and disk-orbit misalignment in a SMBHB system."
  },
  {
    "date": "2026-01-26",
    "title": "A note on nested conditions for finite categories of subgraphs",
    "authors": "Jens Kosiol, Steffen Zschaler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18376v1",
    "source": "arXiv",
    "abstract": "In this note, we present a nesting-free normal form for the formalism of nested conditions and constraints in the context of finite categories of subgraphs."
  },
  {
    "date": "2026-01-26",
    "title": "Gap Labelling for Almost Periodic Sturm-Liouville Operators",
    "authors": "Gerald Teschl, Yifei Wang, Bing Xie, Zhe Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18312v1",
    "source": "arXiv",
    "abstract": "In this paper, we introduce a rotation number for almost periodic Sturm-Liouville operators in the spirit of Johnson and Moser. We then prove the gap labelling theorem in terms of rotation numbers for the operator in question. To do this, we rigorously prove the almost periodicity of Green's functions."
  },
  {
    "date": "2026-01-26",
    "title": "Toward Scalable Normalizing Flows for the Hubbard Model",
    "authors": "Janik Kreit, Andrea Bulgarelli, Lena Funcke, Thomas Luu, Dominic Schuh, Simran Singh, Lorenzo Verzichelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18273v1",
    "source": "arXiv",
    "abstract": "Normalizing flows have recently demonstrated the ability to learn the Boltzmann distribution of the Hubbard model, opening new avenues for generative modeling in condensed matter physics. In this work, we investigate the steps required to extend such simulations to larger lattice sizes and lower temperatures, with a focus on enhancing stability and efficiency. Additionally, we present the scaling behavior of stochastic normalizing flows and non-equilibrium Markov chain Monte Carlo methods for this fermionic system."
  },
  {
    "date": "2026-01-26",
    "title": "TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment",
    "authors": "Zhewen Tan, Wenhan Yu, Jianfeng Si, Tongxin Liu, Kaiqi Guan, Huiyan Jin, Jiawen Tao, Xiaokun Yuan, Duohe Ma, Xiangzheng Zhang, Tong Yang, Lin Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18292v1",
    "source": "arXiv",
    "abstract": "In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop."
  },
  {
    "date": "2026-01-26",
    "title": "Higher-order topological bound states in the continuum in a topoelectrical lattice with long-range coupling",
    "authors": "Araceli Gutiérrez-Llorente",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18291v1",
    "source": "arXiv",
    "abstract": "Linear electric circuits composed of inductors and capacitors can serve as analogues of tight-binding models that describe the electronic band structure of materials. This mapping provides a versatile approach for exploring topological phenomena within engineered electrical lattices. In this work, the two-dimensional Su-Schrieffer-Heeger model is examined through electric circuit analogues to study the interplay between higher-order topology, bound states in the continuum, and disorder. Building upon this model, the effect of introducing next-nearest-neighbour interactions that preserve chiral and spatial symmetries of the system is analyzed. The results reveal that even without Hamiltonian separability, corner-localized bound states in the continuum remain protected by symmetry in the long-range coupled lattice. This robustness highlights the potential of circuit-based platforms for probing advanced topological phenomena in a highly controllable setting."
  },
  {
    "date": "2026-01-26",
    "title": "A Quantum-safe Key Exchange Scheme using Mihailova Subgroups in Braid groups",
    "authors": "Hanling Lin, Yu Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18287v1",
    "source": "arXiv",
    "abstract": "In this paper,we propose a modified Anshel-Anshel-Goldfeld(AAG) key exchange scheme. The hardness assumption underlying this modified construction is based on the membership problem for Mihailova subgroups of the braid group, a problem that is algorithmically unsolvable. According to the security analysis, we show that the proposed scheme is resistant to all known attacks, including quantum computational attacks."
  },
  {
    "date": "2026-01-26",
    "title": "Complexity and structure scalars of Type II matter fields",
    "authors": "Samarjit Chakraborty, Rituparno Goswami, Sunil D. Maharaj",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18283v1",
    "source": "arXiv",
    "abstract": "A general semi-tetrad covariant approach is adopted to analyse the structure scalars of a Type II fluid in generalized Vaidya spacetime. The relationship between the $1+1+2$ covariant quantities and the structure scalars are obtained. We calculate the complexity factor in terms of the Misner-Sharp mass and the matter variables to obtain a non-trivial class of spacetimes with vanishing complexity. Also the Vaidya spacetime with pure Type II matter field has negative complexity. The differences between the complexity of Type I and Type II matter fields are highlighted. We compute the propagation and evolution equations of the structure scalars, showcasing their interdependency through the kinematical variables. The causal wave equation of the Gaussian curvature of the 2-shell and its dependence on the structure scalars are also studied."
  },
  {
    "date": "2026-01-26",
    "title": "Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue",
    "authors": "Yuhang Jia, Pei Liu, Haoqin Sun, Jiaming Zhou, Xuxin Cheng, Cao Liu, Ke Zeng, Xunliang Cai, Yong Qin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18281v1",
    "source": "arXiv",
    "abstract": "End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single \"correct\" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions."
  },
  {
    "date": "2026-01-26",
    "title": "Topology optimization of passively moving rigid bodies in unsteady flows",
    "authors": "Yuta Tanabe, Kentaro Yaji, Kuniharu Ushijima",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18272v1",
    "source": "arXiv",
    "abstract": "This study proposes the topology optimization method for moving rigid bodies subjected to forces from fluid flow, such as sails and turbines, with an unsteady time-dependent formulation. Unlike existing topology optimization frameworks in which rigid-body motion drives the flow, which is referred to as $\\textit{active}$, the present study considers rigid-body motion induced by fluid forces, i.e., $\\textit{passive}$. The equations of motion governing the rigid-body dynamics are solved in a coupled manner with the continuity equation and the momentum conservation equations. The rigid body is represented on a design grid that is separated from the analysis grid on which the state and adjoint fields are defined. After updating the rigid body motion, the body is mapped onto the analysis grid. The fluid equations are solved using the lattice kinetic scheme, an extended version of the lattice Boltzmann method, owing to its suitability for unsteady flows. Design sensitivities based on the adjoint variable method are presented and applied to two- and three-dimensional problems involving translational and rotational motions. The optimized shapes for each problem are discussed from a physical perspective and compared with a reference shape or their binarized counterparts, providing insights into the effectiveness of the proposed method as well as its limitations."
  },
  {
    "date": "2026-01-26",
    "title": "Chemical study of two starless cores in the B213/L1495 filament",
    "authors": "L. Moral-Almansa, A. Fuente, M. Rodríguez-Baras, T. Alonso-Albi, G. Esplugues, D. Navarro-Almaida, P. Riviére-Marichalar, B. Tercero, A. Asensio Ramos, C. Westendorp Plaza",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18259v1",
    "source": "arXiv",
    "abstract": "The chemical evolution of pre-stellar cores during their transition to a protostellar stage is not yet fully understood. Detailed chemical characterizations of these sources are needed to better define their chemistry during star formation. Our goal is to characterize the chemistry of the starless cores C2 and C16 in the B213/L1495 filament of the Taurus Molecular Cloud, and to understand how it relates to the environmental conditions and the evolutionary state of the cores. We made use of two complete spectral surveys at 7 mm of these sources, carried out using the Yebes 40-m telescope. Derived molecular abundances were compared with those of other sources in different evolutionary stages and with values computed by chemical models. Including isotopologs, 22 molecules were detected in B213-C2, and 25 in B213-C16. The derived rotational temperatures have values of between $\\sim$ 5 K and $\\sim$ 9 K. A comparison of the two sources shows lower abundances in C2, except for l-C$_{3}$H and HOCO$^{+}$, which have similar values in both cores. Model results indicate that both cores are best fit assuming early-time chemistry, and point to C2 being in a more advanced evolutionary stage, as it presents a higher molecular hydrogen density and sulfur depletion, and a lower cosmic-ray ionization rate. Our chemical modeling successfully accounts for the abundances of most molecules, including complex organic molecules and long cyanopolynes (HC$_{5}$N, HC$_{7}$N), but fails to reproduce those of the carbon chains CCS and C$_{3}$O. Chemical differences between C2 and C16 could stem from the evolutionary stage of the cores, with C2 being closer to the pre-stellar phase. Both cores are better fit assuming early-time chemistry of t $\\sim$ 0.1 Myr. The more intense UV radiation in the northern region of B213 could account for the high abundances of l-C$_{3}$H and HOCO$^{+}$ in C2."
  },
  {
    "date": "2026-01-26",
    "title": "A multimodal vision foundation model for generalizable knee pathology",
    "authors": "Kang Yu, Dingyu Wang, Zimu Yuan, Nan Zhou, Jiajun Liu, Jiaxin Liu, Shanggui Liu, Yaoyan Zheng, Huishu Yuan, Di Huang, Dong Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18250v1",
    "source": "arXiv",
    "abstract": "Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice."
  },
  {
    "date": "2026-01-26",
    "title": "Relative Dixmier property for Poisson algebras",
    "authors": "Hongdi Huang, Zahra Nazemian, Xin Tang, Xingting Wang, Yanhua Wang, James J. Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18249v1",
    "source": "arXiv",
    "abstract": "Dixmier property concerns the bijectivity of endomorphisms for algebras. We introduce a relative Dixmier property, which is a generalization of the Dixmier property. This new concept has applications in proving that several classes of Poisson algebras possess the Dixmier property, as well as in other topics such as the cancellation problem and the non-existence of Hopf coactions."
  },
  {
    "date": "2026-01-26",
    "title": "Direct observation of vortex liquid droplets in the iron pnictide superconductor CaKAs$_4$Fe$_4$ at $0.5T$_c$",
    "authors": "Oscar Bou Marqués, Jose A. Moreno, Pablo García Talavera, Mingyu Xu, Juan Schmidt, Sergey L. Bud'ko, Paul C. Canfield, Isabel Guillamón, Edwin Herrera, Hermann Suderow",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18247v1",
    "source": "arXiv",
    "abstract": "Type-II superconductors under magnetic fields are in a quantum coherent non-dissipative state as long as vortices remain pinned. Dissipation appears when vortices depin, eventually driven by thermal fluctuations. This can be associated to a melting transition between a vortex solid and a vortex liquid. This transition is almost always observed very close to T$_c$ when probed by macroscopic experiments. However, it remains unclear how the vortex solid responds to thermal fluctuations at the scale of individual vortices far from the melting transition. Here we use scanning tunneling microscopy (STM) to visualize vortices in CaKAs$_4$Fe$_4$ (T$_c \\approx$ 35 K). We find vortex liquid droplets-localized regions in space where vortices strongly fluctuate due to thermal exctiation-at temperatures as low as 0.5\\,T$_c$. Our results show that the onset of dissipation at the local scale occurs at temperatures considerably below T$_c$ in type-II superconductors."
  },
  {
    "date": "2026-01-26",
    "title": "Double-bosonization and Majid's conjecture (V): grafting of quantum groups",
    "authors": "Hongmei Hu, Naihong Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18243v1",
    "source": "arXiv",
    "abstract": "The goal of this paper is to propose and carry out a program which allows us to yield a larger target quantum group of Drinfeld-Jimbo type via grafting two given smaller ones. To this effect, we first set up some basics of a multi-tensor product theory of the generalized double-bosonization construction (see [HH2] for the latter). Such a grafting method, depending on the choice of grafting node in the Dynkin diagram, including rank-induction and type-crossing constructions as special cases, provides a one-stop resolving strategy of the generation question of Majid's quantum tree, which grows up from the root part $U_q(\\mathfrak{sl}_2)$ and decorates with the quantum groups of various Dynkin diagrams (of finite types) as the branches."
  },
  {
    "date": "2026-01-26",
    "title": "Using LibCal Seats to Better Serve Students",
    "authors": "François Renaville, Fabienne Prosmans",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18230v1",
    "source": "arXiv",
    "abstract": "This chapter examines the evolution of library services at the University of Liège (ULiège), with a focus on the implementation and assessment of the LibCal Seats booking module. Introduced in September 2020 in response to the COVID-19 pandemic, this system was designed to manage occupancy and maintain social distancing. While initially a temporary measure, the seat booking service remains in use during peak periods. Drawing on survey data from 2022 and 2023, the chapter analyses user perceptions of the system. Results indicate strong student appreciation, particularly regarding stress reduction and equitable access to study spaces. Despite overall satisfaction, issues such as unoccupied reserved seats and an unnecessarily complex booking process emerged, leading to targeted improvements. This chapter highlights the importance of responsive, user-centred services in academic libraries. The adoption of the booking system helped address challenges such as overcrowding and \"seat hogging,\" ultimately contributing to a more organised and accessible environment. The case study illustrates how technology can enhance library service delivery, offering insights for institutions seeking to optimise space management. The continued evaluation of the system reflects a broader commitment to adapting services in alignment with user needs and institutional priorities."
  },
  {
    "date": "2026-01-26",
    "title": "150 years of ground-based solar instrumentation at Meudon observatory (1876-2026)",
    "authors": "Jean-Marie Malherbe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18227v1",
    "source": "arXiv",
    "abstract": "The Sun has been observed through a telescope for four centuries. However, its study made a prodigious leap at the end of the nineteenth century with the appearance of photography and spectroscopy, then at the beginning of the following century with the invention of the coronagraph and monochromatic filters, and finally in the second half of the twentieth century with the advent of large ground-based telescopes and space exploration. This article retraces the main stages of solar instrumental developments in Meudon, from its foundation by Jules Janssen in 1876 to the present day, limited to ground-based or balloon instrumentation, designed in Meudon and installed there or in other places (Nan{\\c c}ay, Pic du Midi, Canary Islands). The Meudon astronomers played a pioneering role in the history of solar physics through the experimentation of innovative techniques. After the golden age of inventions, came the time of large instruments, studied in Meudon but often installed in more favourable sites, and that of space, in a framework of international collaboration, but this is not discussed here."
  },
  {
    "date": "2026-01-26",
    "title": "Elliptic genera and E8 Bundles in odd dimensions",
    "authors": "Siyao Liu, Yong Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18221v1",
    "source": "arXiv",
    "abstract": "This paper aims to derive new anomaly cancellation formulas by combining modular forms with E8 and E8*E8 bundles. To this end, we systematically twist and generalize known SL(2,Z) modular forms to define new modular forms associated with these bundles on odd-dimensional spin and spin^c manifolds, leading to a new series of anomaly cancellation formulas."
  },
  {
    "date": "2026-01-26",
    "title": "On positivity of CM line bundles on the moduli space of klt good minimal models with $κ=1$",
    "authors": "Masafumi Hattori",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18208v1",
    "source": "arXiv",
    "abstract": "We study the positivity of CM line bundles on the coarse moduli space of Kawamata log terminal (klt) good minimal models with Kodaira dimension one. We prove that the seminormalization of the moduli space is quasi-projective under a mild assumption on the general fibers of good minimal models. Moreover, we show that the CM line bundle becomes ample after normalization. A key new ingredient is the construction of a moduli space of numerical equivalence classes, which is an extension of the work of Viehweg and allows us to bypass the failure of quasi-finiteness in the approach of the previous work by Hashizume and the author. We also establish the projectivity of the moduli space of $ε$-stable quotients, which is introduced by Toda, to a projective space, which plays a central role in our method. This particular situation is encompassed by our general framework of K-moduli of quasimaps."
  },
  {
    "date": "2026-01-26",
    "title": "GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models",
    "authors": "Shaokang Wang, Pei Fu, Ruoceng Zhang, Shaojie Zhang, Xiuwen Xi, Jiahui Yang, Bin Qin, Ying Huang, Zhenbo Luo, Jian Luan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18197v1",
    "source": "arXiv",
    "abstract": "While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released."
  },
  {
    "date": "2026-01-26",
    "title": "MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models",
    "authors": "Tian-Yi Zhou, Xuan-Hao Liu, Bao-Liang Lu, Wei-Long Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18192v1",
    "source": "arXiv",
    "abstract": "Reconstructing human dynamic visual perception from electroencephalography (EEG) signals is of great research significance since EEG's non-invasiveness and high temporal resolution. However, EEG-to-video reconstruction remains challenging due to: 1) Single Modality: existing studies solely align EEG signals with the text modality, which ignores other modalities and are prone to suffer from overfitting problems; 2) Data Scarcity: current methods often have difficulty training to converge with limited EEG-video data. To solve the above problems, we propose a novel framework MindCine to achieve high-fidelity video reconstructions on limited data. We employ a multimodal joint learning strategy to incorporate beyond-text modalities in the training stage and leverage a pre-trained large EEG model to relieve the data scarcity issue for decoding semantic information, while a Seq2Seq model with causal attention is specifically designed for decoding perceptual information. Extensive experiments demonstrate that our model outperforms state-of-the-art methods both qualitatively and quantitatively. Additionally, the results underscore the effectiveness of the complementary strengths of different modalities and demonstrate that leveraging a large-scale EEG model can further enhance reconstruction performance by alleviating the challenges associated with limited data."
  },
  {
    "date": "2026-01-26",
    "title": "Critical collapse of a massive scalar field in semi-classical loop quantum gravity",
    "authors": "Li-Jie Xin, Xiangdong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18191v1",
    "source": "arXiv",
    "abstract": "We investigate critical phenomena during the gravitational collapse of a massive scalar field under two distinct semi-classical loop quantum gravity (LQG) approaches within spherical symmetry. Numerical simulations reveal that the massive scalar field in both semi-classical frameworks exhibits two distinct types of critical behavior, consistent with the classical scenario. When the scalar field's mass parameter is small, type II critical phenomena emerge, with the resulting echoing periods and critical exponents precisely matching those obtained in general relativity. In contrast, a large mass parameter triggers type I critical phenomena, where the resulting black holes possess a finite minimum mass. These findings suggest that semi-classical corrections from LQG have a negligible impact on the dynamics of critical collapse."
  },
  {
    "date": "2026-01-26",
    "title": "\\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation",
    "authors": "Weiye Zhu, Zekai Zhang, Xiangchen Wang, Hewei Pan, Teng Wang, Tiantian Geng, Rongtao Xu, Feng Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18188v1",
    "source": "arXiv",
    "abstract": "Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \\textsc{NaVIDA} (\\textbf{Nav}igation with \\textbf{I}nverse \\textbf{D}ynamics \\textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \\textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \\textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \\textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance."
  },
  {
    "date": "2026-01-26",
    "title": "On the Image of the $p$-adic Logarithm on Annuli of Principal Units",
    "authors": "Mabud Ali Sarkar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18187v1",
    "source": "arXiv",
    "abstract": "Let $K$ be a finite extension of $\\mathbb{Q}_p$, and let $\\mathfrak{m}_K$ be its maximal ideal. The image of the group of principal units $1+\\mathfrak{m}_K$ under $p$-adic logarithm plays important role in several areas of number theory. In general, when the ramification index of $K/\\mathbb{Q}_p$ is greater or equal to $p-1$, the precise description of this image is not known. For the cyclotomic extension $K=\\mathbb{Q}_p(ζ_p)$ of degree $p-1$, it was previously proved in \\cite{MAS} that the image of the annulus region $(1+\\mathfrak{m}_K) \\setminus (1+\\mathfrak{m}_K^2)$ by $p$-adic logarithm is exactly $\\mathfrak{m}_K^2$. In this paper, we give a self-contained analytic proof of this result based on explicit $p$-adic logarithmic expansions."
  },
  {
    "date": "2026-01-26",
    "title": "Accurate semiempirical analytical formulas for spontaneous polarization by crystallographic parameters of SrTiO3-BaTiO3 system by ab initio calculations",
    "authors": "Yukio Watanabe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18181v1",
    "source": "arXiv",
    "abstract": "Spontaneous polarizations (PSs) of BaTiO3 and SrTiO3 under various conditions are calculated ab initio using different exchange-correlation functionals. The extensive theoretical sets of PS vs. ion positions are found to lie on a single curve, despite the chemical differences and the wide variations of PS and lattice parameters. This uncovers accurate simple analytical formulas of PS of SrTiO3-BaTiO3 system expressed by ion positions; a single formula predicts both macroscopic and atomic-scale PS of SrTiO3, BaTiO3 and SrTiO3-BaTiO alloys. The accuracy of the formula is demonstrated by the application to experiments, BaTiO3-SrTiO3 (-CaTiO3) alloys, Sr4Ti4O12 with PS // a-axis, a parallel domain, and a headon domain. In addition, the present results verify empirically that oxygen displacement is the primary identifier and the origin of PS of SrTiO3 and BaTiO3 and indicate that BaTiO3 and SrTiO3 may transforms into new state by an extremely large strain, e.g., -3%. Furthermore, the earlier prediction of headon domain without aid of defects was confirmed. The present procedures for finding formulas can be applied to other materials."
  },
  {
    "date": "2026-01-26",
    "title": "Exploring Customizable Interactive Tools for Therapeutic Homework Support in Mental Health Counseling",
    "authors": "Yimeng Wang, Liabette Escamilla, Yinzhou Wang, Bianca R. Augustine, Yixuan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18179v1",
    "source": "arXiv",
    "abstract": "Therapeutic homework (i.e., tasks assigned by therapists for clients to complete between sessions) is essential for effective psychotherapy, yet therapists often interpret fragmented client logs, assessments, and reflections within limited preparation time. Our formative study with licensed therapists revealed three critical design requirements: support for interpreting unstructured client self-reports, customization aligned with clinical objectives, and seamless integration across multiple data sources. We then designed and developed TheraTrack, a customizable, therapist-facing tool that integrates multi-dimensional data and leverages large language models to generate traceable summaries and support natural-language queries, to streamline between-session homework tracking. Our pilot study with 14 therapists showed that TheraTrack reduced their cognitive load, enabled verification through direct navigation from AI summaries to original data entries, and was adapted differently for private analysis compared to in-session use, with dependence varying based on therapist experience and usage duration. We also discuss design implications for clinician-centered AI for mental health."
  },
  {
    "date": "2026-01-26",
    "title": "Asymptotic properties of multivariate Szász-Mirakyan distribution estimators on the nonnegative orthant",
    "authors": "Guanjie Lyu, Frédéric Ouimet, Cindy Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18178v1",
    "source": "arXiv",
    "abstract": "The asymptotic properties of multivariate Szász-Mirakyan estimators for distribution functions supported on the nonnegative orthant are investigated. Explicit bias and variance expansions are derived on compact subsets of the interior, yielding sharp mean squared error characterizations and optimal smoothing rates. The analysis shows that the proposed Poisson smoothing yields a non-negligible variance reduction relative to the empirical distribution function, leading to asymptotic efficiency gains that can be quantified through local and global deficiency measures. The behavior of the estimator near the boundary of its support is examined separately. Under a boundary-layer scaling that preserves nondegenerate Poisson smoothing as the evaluation point approaches the boundary of $[0,\\infty)^d$, bias and variance expansions are obtained that differ fundamentally from those in the interior region. In particular, the variance reduction mechanism disappears at leading order, implying that no asymptotically optimal smoothing parameter exists in the boundary regime. Central limit theorems and almost sure uniform consistency are also established. Together, these results provide a unified asymptotic theory for multivariate Szász-Mirakyan distribution estimation and clarify the distinct roles of smoothing in the interior and boundary regions."
  },
  {
    "date": "2026-01-26",
    "title": "Programming Nonlinear Interfacial Mechanics of Synthetic Cells: Lipid Geometry and DNA Nanostructures",
    "authors": "Kazutoshi Masuda, Miho Yanagisawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18174v1",
    "source": "arXiv",
    "abstract": "Soft interfaces formed by lipid membranes are fundamental to living cells, synthetic cells, and membrane-based soft materials. However, a quantitative framework linking molecular organization with nonlinear interfacial mechanics remains elusive. Here, we establish an analytical framework that captures the nonlinear elastic response of lipid-membrane-coated synthetic cells under micropipette aspiration. Incorporating both area stretching and curvature bending enables the model to quantitatively reproduce the complete pressure-displacement response within the small-deformation regime. This approach reduces interfacial mechanics to two parameters: the in-plane area-stretching modulus and an out-of-plane bending-related term. Using this unified framework, we experimentally demonstrate that nonlinear interfacial mechanics can be programmed by altering the molecular geometry and effective dimensionality of adsorbed elements. The lipid molecular shape and curvature-dependent packing regulate in-plane stiffness, while DNA nanostructures, the other adsorbed element, introduce an orthogonal control axis via dimensionality: isolated motifs primarily enhance area stretching, whereas three-dimensional network architectures markedly reinforce bending resistance. Together, these results establish a general molecular design principle for programming interfacial mechanics and provide a quantitative foundation for engineering mechanically tunable synthetic cells and soft interfaces."
  },
  {
    "date": "2026-01-26",
    "title": "Quantum Recurrent Unit: A Parameter-Efficient Quantum Neural Network Component",
    "authors": "Tzong-Daw Wu, Hsi-Sheng Goan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18164v1",
    "source": "arXiv",
    "abstract": "The rapid growth of modern machine learning (ML) models presents fundamental challenges in parameter efficiency and computational resource requirements. This study introduces the Quantum Recurrent Unit (QRU), a novel quantum neural network (NN) architecture specifically designed to address these challenges while remaining compatible with Noisy Intermediate-Scale Quantum (NISQ) devices. QRU leverages quantum controlled-SWAP (C-SWAP; Fredkin) gates to implement an information selection mechanism inspired by classical Gated Recurrent Units (GRUs), enabling selective processing of temporal information via quantum operations. Through its innovative recurrent architecture featuring measurement results feedforward state propagation and shared parameters across time steps, QRU achieves constant circuit depth and constant parameter count regardless of input sequence length, effectively circumventing stringent NISQ hardware constraints. We systematically validate QRU through three progressive experiments: (1) oscillatory behavior prediction, where 72-parameter QRU matches 197-parameter classical GRU performance; (2) Wisconsin Diagnostic Breast Cancer classification, where 35 parameters achieve 96.13% accuracy comparable to 167-parameter artificial NNs; and (3) MNIST handwritten digit recognition, where 132 parameters reach 98.05% accuracy, outperforming a 27,265-parameter convolutional NN. These results demonstrate that QRU consistently achieves comparable or superior performance with significantly fewer parameters than classical NNs while maintaining constant quantum circuit depth. The architecture's quantum-native design, combining C-SWAP-based information selection with novel recurrent processing, suggests QRU's potential as a fundamental building block for next-generation ML systems, offering a promising pathway toward more efficient and scalable quantum ML architectures."
  },
  {
    "date": "2026-01-26",
    "title": "AI-based separation of turbulence from coherent background flows in decaying hydrodynamic turbulence",
    "authors": "Ji-Hoon Ha, Elena S. Volnova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18163v1",
    "source": "arXiv",
    "abstract": "Separating turbulent fluctuations from coherent large-scale background flows is a fundamental challenge in the analysis of numerical simulations and astronomical observations. Traditional approaches to this problem commonly rely on decomposition-based techniques, including scale-based filtering methods such as Fourier or wavelet transforms, as well as adaptive methods like the Hilbert-Huang transformation. In realistic flows, however, coherent motions and turbulent fluctuations often overlap across a broad range of scales and interact nonlinearly, rendering any clear and unique separation inherently ambiguous, particularly in astrophysical settings where data are projected or sparsely sampled. In this work, we assess the robustness of AI-based turbulence-background separation using two-dimensional incompressible Navier-Stokes simulations of decaying hydrodynamic turbulence. The simulations are initialized with a coherent background flow and divergence-free turbulent perturbations with a Kolmogorov-like power spectrum, and evolve without external forcing, providing a conservative physical testbed. A neural network trained exclusively on static synthetic images is applied to simulation snapshots at different evolutionary stages. We find that the model successfully recovers turbulent fluctuations during early and intermediate stages, when partial scale separation is preserved. At later stages, despite the substantial decay of turbulent energy and the resulting reduction in fluctuation strength, the model continues to recover visually and spectrally plausible turbulent structures and preserves inertial-range spectral scaling, demonstrating robust separation under increasingly challenging conditions. These results demonstrate the potential of applying AI models trained on static data to time-evolving turbulent flows, with direct implications for astrophysical and cosmological applications."
  },
  {
    "date": "2026-01-26",
    "title": "Beyond Pairwise Comparisons: A Distributional Test of Distinctiveness for Machine-Generated Works in Intellectual Property Law",
    "authors": "Anirban Mukherjee, Hannah Hanwen Chang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18156v1",
    "source": "arXiv",
    "abstract": "Key doctrines, including novelty (patent), originality (copyright), and distinctiveness (trademark), turn on a shared empirical question: whether a body of work is meaningfully distinct from a relevant reference class. Yet analyses typically operationalize this set-level inquiry using item-level evidence: pairwise comparisons among exemplars. That unit-of-analysis mismatch may be manageable for finite corpora of human-created works, where it can be bridged by ad hoc aggregations. But it becomes acute for machine-generated works, where the object of evaluation is not a fixed set of works but a generative process with an effectively unbounded output space. We propose a distributional alternative: a two-sample test based on maximum mean discrepancy computed on semantic embeddings to determine if two creative processes-whether human or machine-produce statistically distinguishable output distributions. The test requires no task-specific training-obviating the need for discovery of proprietary training data to characterize the generative process-and is sample-efficient, often detecting differences with as few as 5-10 images and 7-20 texts. We validate the framework across three domains: handwritten digits (controlled images), patent abstracts (text), and AI-generated art (real-world images). We reveal a perceptual paradox: even when human evaluators distinguish AI outputs from human-created art with only about 58% accuracy, our method detects distributional distinctiveness. Our results present evidence contrary to the view that generative models act as mere regurgitators of training data. Rather than producing outputs statistically indistinguishable from a human baseline-as simple regurgitation would predict-they produce outputs that are semantically human-like yet stochastically distinct, suggesting their dominant function is as a semantic interpolator within a learned latent space."
  },
  {
    "date": "2026-01-26",
    "title": "On Golod Subdeterminantal Ideals",
    "authors": "Omkar Javadekar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18153v1",
    "source": "arXiv",
    "abstract": "Let $X=(x_{ij})_{m\\times n}$ be a matrix of indeterminates and let $S=\\mathbb{k}[x_{ij} \\mid 1\\leq i\\leq m,\\ 1\\leq j\\leq n]$ be a polynomial ring over an infinite field $\\mathbb{k}$. Let $I$ be an ideal generated by a subset of the set of all $2\\times2$ minors of $X$. We show that the quotient ring $S/I$ is Golod if and only if $I=I_2(Y)$ for some $2\\times \\ell$ or $\\ell\\times2$ submatrix $Y$ of $X$. In fact, we prove that Golodness of $S/I$ is equivalent to the triviality of the product on the Koszul homology of $S/I$ and to $I$ having a linear resolution. Along the way, we also prove a result on the non-Golodness of tensor products of rings under certain conditions."
  },
  {
    "date": "2026-01-26",
    "title": "Explaining Synergistic Effects in Social Recommendations",
    "authors": "Yicong Li, Shan Jin, Qi Liu, Shuo Wang, Jiaying Liu, Shuo Yu, Qiang Zhang, Kuanjiu Zhou, Feng Xia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18151v1",
    "source": "arXiv",
    "abstract": "In social recommenders, the inherent nonlinearity and opacity of synergistic effects across multiple social networks hinders users from understanding how diverse information is leveraged for recommendations, consequently diminishing explainability. However, existing explainers can only identify the topological information in social networks that significantly influences recommendations, failing to further explain the synergistic effects among this information. Inspired by existing findings that synergistic effects enhance mutual information between inputs and predictions to generate information gain, we extend this discovery to graph data. We quantify graph information gain to identify subgraphs embodying synergistic effects. Based on the theoretical insights, we propose SemExplainer, which explains synergistic effects by identifying subgraphs that embody them. SemExplainer first extracts explanatory subgraphs from multi-view social networks to generate preliminary importance explanations for recommendations. A conditional entropy optimization strategy to maximize information gain is developed, thereby further identifying subgraphs that embody synergistic effects from explanatory subgraphs. Finally, SemExplainer searches for paths from users to recommended items within the synergistic subgraphs to generate explanations for the recommendations. Extensive experiments on three datasets demonstrate the superiority of SemExplainer over baseline methods, providing superior explanations of synergistic effects."
  },
  {
    "date": "2026-01-26",
    "title": "On 2-dimensional invariant subspaces of matrices",
    "authors": "Omar Al-Raisi, Mohammad Shahryari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18143v1",
    "source": "arXiv",
    "abstract": "We introduce a unified method for study of 2-dimensional invariant subspaces of matrices and their corresponding super-eigenvalues. As a novel application to non-commutative algebra, we present a connection between the eigenvalues of matrices with entries in the ring Mat_2(F) and 2-dimensional invariant subspaces of matrices with entries in the field F."
  },
  {
    "date": "2026-01-26",
    "title": "Forward Consistency Learning with Gated Context Aggregation for Video Anomaly Detection",
    "authors": "Jiahao Lyu, Minghua Zhao, Xuewen Huang, Yifei Chen, Shuangli Du, Jing Hu, Cheng Shi, Zhiyong Lv",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18135v1",
    "source": "arXiv",
    "abstract": "As a crucial element of public security, video anomaly detection (VAD) aims to measure deviations from normal patterns for various events in real-time surveillance systems. However, most existing VAD methods rely on large-scale models to pursue extreme accuracy, limiting their feasibility on resource-limited edge devices. Moreover, mainstream prediction-based VAD detects anomalies using only single-frame future prediction errors, overlooking the richer constraints from longer-term temporal forward information. In this paper, we introduce FoGA, a lightweight VAD model that performs Forward consistency learning with Gated context Aggregation, containing about 2M parameters and tailored for potential edge devices. Specifically, we propose a Unet-based method that performs feature extraction on consecutive frames to generate both immediate and forward predictions. Then, we introduce a gated context aggregation module into the skip connections to dynamically fuse encoder and decoder features at the same spatial scale. Finally, the model is jointly optimized with a novel forward consistency loss, and a hybrid anomaly measurement strategy is adopted to integrate errors from both immediate and forward frames for more accurate detection. Extensive experiments demonstrate the effectiveness of the proposed method, which substantially outperforms state-of-the-art competing methods, running up to 155 FPS. Hence, our FoGA achieves an excellent trade-off between performance and the efficiency metric."
  },
  {
    "date": "2026-01-26",
    "title": "Nonlinear multi-study factor analysis",
    "authors": "Gemma E. Moran, Anandi Krishnan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18128v1",
    "source": "arXiv",
    "abstract": "High-dimensional data often exhibit variation that can be captured by lower dimensional factors. For high-dimensional data from multiple studies or environments, one goal is to understand which underlying factors are common to all studies, and which factors are study or environment-specific. As a particular example, we consider platelet gene expression data from patients in different disease groups. In this data, factors correspond to clusters of genes which are co-expressed; we may expect some clusters (or biological pathways) to be active for all diseases, while some clusters are only active for a specific disease. To learn these factors, we consider a nonlinear multi-study factor model, which allows for both shared and specific factors. To fit this model, we propose a multi-study sparse variational autoencoder. The underlying model is sparse in that each observed feature (i.e. each dimension of the data) depends on a small subset of the latent factors. In the genomics example, this means each gene is active in only a few biological processes. Further, the model implicitly induces a penalty on the number of latent factors, which helps separate the shared factors from the group-specific factors. We prove that the latent factors are identified, and demonstrate our method recovers meaningful factors in the platelet gene expression data."
  },
  {
    "date": "2026-01-26",
    "title": "The Limits of AI Data Transparency Policy: Three Disclosure Fallacies",
    "authors": "Judy Hanwen Shen, Ken Liu, Angelina Wang, Sarah H. Cen, Andy K. Zhang, Caroline Meinhardt, Daniel Zhang, Kevin Klyman, Rishi Bommasani, Daniel E. Ho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18127v1",
    "source": "arXiv",
    "abstract": "Data transparency has emerged as a rallying cry for addressing concerns about AI: data quality, privacy, and copyright chief among them. Yet while these calls are crucial for accountability, current transparency policies often fall short of their intended aims. Similar to nutrition facts for food, policies aimed at nutrition facts for AI currently suffer from a limited consideration of research on effective disclosures. We offer an institutional perspective and identify three common fallacies in policy implementations of data disclosures for AI. First, many data transparency proposals exhibit a specification gap between the stated goals of data transparency and the actual disclosures necessary to achieve such goals. Second, reform attempts exhibit an enforcement gap between required disclosures on paper and enforcement to ensure compliance in fact. Third, policy proposals manifest an impact gap between disclosed information and meaningful changes in developer practices and public understanding. Informed by the social science on transparency, our analysis identifies affirmative paths for transparency that are effective rather than merely symbolic."
  },
  {
    "date": "2026-01-26",
    "title": "Elliptic Chern Characters and Elliptic Atiyah--Witten Formula",
    "authors": "Geyang Dai, Fei Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18126v1",
    "source": "arXiv",
    "abstract": "Let $G$ be a compact, connected, and simply connected Lie group. A principal $G$-bundle over a manifold $X$, equipped with a connection, together with a positive-energy representation of the loop group $LG$, gives rise to a circle-equivariant gerbe module on the free loop space $LX$. From this data we construct the elliptic Chern character on $LX$, and a refinement, the elliptic Bismut--Chern character, on the double loop space $L^2X$. Generalizing the classical Atiyah--Witten formula from the free loop space $LX$ to the double loop space $L^2X$, we establish an elliptic Atiyah--Witten formula. The elliptic holonomy on $L^2X$ is defined by $τ$-deformed equivariant twisted parallel transport on $LX$. We show that the four Pfaffian sections, corresponding to the four spin structures on an elliptic curve, are identified with the four elliptic holonomies arising from the four virtual level-one positive-energy representations when $G=\\mathrm{Spin}(2n)$. These constructions are intimately connected to the moduli of $G_{\\mathbb{C}}$-bundles over elliptic curves and conformal blocks in the context of Chern--Simons gauge theory."
  },
  {
    "date": "2026-01-26",
    "title": "The Sherman-Morrison-Markowitz Portfolio",
    "authors": "Steven E. Pav",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18124v1",
    "source": "arXiv",
    "abstract": "We show that the Markowitz portfolio is a scalar multiple of another portfolio which replaces the covariance with the second moment matrix, via simple application of the Sherman-Morrison identity. Moreover it is shown that when using conditional estimates of the first two moments, this \"Sherman-Morrison-Markowitz\" portfolio solves the standard unconditional portfolio optimization problems. We argue that in multi-period portfolio optimization problems it is more natural to replace variance and covariance with their uncentered counterparts. We extend the theory to deal with constraints in expectation, where we find a decomposition of squared effects into spanned and orthogonal components. Compared to the Markowitz portfolio, the Sherman-Morrison-Markowitz portfolio downlevers by a small amount that depends on the conditional squared maximal Sharpe ratio; the practical impact will be fairly small, however. We present some example use cases for the theory."
  },
  {
    "date": "2026-01-26",
    "title": "Grasp-and-Lift: Executable 3D Hand-Object Interaction Reconstruction via Physics-in-the-Loop Optimization",
    "authors": "Byeonggyeol Choi, Woojin Oh, Jongwoo Lim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18121v1",
    "source": "arXiv",
    "abstract": "Dexterous hand manipulation increasingly relies on large-scale motion datasets with precise hand-object trajectory data. However, existing resources such as DexYCB and HO3D are primarily optimized for visual alignment but often yield physically implausible interactions when replayed in physics simulators, including penetration, missed contact, and unstable grasps. We propose a simulation-in-the-loop refinement framework that converts these visually aligned trajectories into physically executable ones. Our core contribution is to formulate this as a tractable black-box optimization problem. We parameterize the hand's motion using a low-dimensional, spline-based representation built on sparse temporal keyframes. This allows us to use a powerful gradient-free optimizer, CMA-ES, to treat the high-fidelity physics engine as a black-box objective function. Our method finds motions that simultaneously maximize physical success (e.g., stable grasp and lift) while minimizing deviation from the original human demonstration. Compared to MANIPTRANS-recent transfer pipelines, our approach achieves lower hand and object pose errors during replay and more accurately recovers hand-object physical interactions. Our approach provides a general and scalable method for converting visual demonstrations into physically valid trajectories, enabling the generation of high-fidelity data crucial for robust policy learning."
  },
  {
    "date": "2026-01-26",
    "title": "Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?",
    "authors": "Jing Ye, Yiwen Duan, Yonghong Yu, Victor Ma, Yang Gao, Xing Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18119v1",
    "source": "arXiv",
    "abstract": "SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment. OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees. Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs."
  },
  {
    "date": "2026-01-26",
    "title": "Demystifying Data-Driven Probabilistic Medium-Range Weather Forecasting",
    "authors": "Jean Kossaifi, Nikola Kovachki, Morteza Mardani, Daniel Leibovici, Suman Ravuri, Ira Shokar, Edoardo Calvello, Mohammad Shoaib Abbas, Peter Harrington, Ashay Subramaniam, Noah Brenowitz, Boris Bonev, Wonmin Byeon, Karsten Kreis, Dale Durran, Arash Vahdat, Mike Pritchard, Jan Kautz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18111v1",
    "source": "arXiv",
    "abstract": "The recent revolution in data-driven methods for weather forecasting has lead to a fragmented landscape of complex, bespoke architectures and training strategies, obscuring the fundamental drivers of forecast accuracy. Here, we demonstrate that state-of-the-art probabilistic skill requires neither intricate architectural constraints nor specialized training heuristics. We introduce a scalable framework for learning multi-scale atmospheric dynamics by combining a directly downsampled latent space with a history-conditioned local projector that resolves high-resolution physics. We find that our framework design is robust to the choice of probabilistic estimator, seamlessly supporting stochastic interpolants, diffusion models, and CRPS-based ensemble training. Validated against the Integrated Forecasting System and the deep learning probabilistic model GenCast, our framework achieves statistically significant improvements on most of the variables. These results suggest scaling a general-purpose model is sufficient for state-of-the-art medium-range prediction, eliminating the need for tailored training recipes and proving effective across the full spectrum of probabilistic frameworks."
  },
  {
    "date": "2026-01-26",
    "title": "CHiRPE: A Step Towards Real-World Clinical NLP with Clinician-Oriented Model Explanations",
    "authors": "Stephanie Fong, Zimu Wang, Guilherme C. Oliveira, Xiangyu Zhao, Yiwen Jiang, Jiahe Liu, Beau-Luke Colton, Scott Woods, Martha E. Shenton, Barnaby Nelson, Zongyuan Ge, Dominic Dwyer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18102v1",
    "source": "arXiv",
    "abstract": "The medical adoption of NLP tools requires interpretability by end users, yet traditional explainable AI (XAI) methods are misaligned with clinical reasoning and lack clinician input. We introduce CHiRPE (Clinical High-Risk Prediction with Explainability), an NLP pipeline that takes transcribed semi-structured clinical interviews to: (i) predict psychosis risk; and (ii) generate novel SHAP explanation formats co-developed with clinicians. Trained on 944 semi-structured interview transcripts across 24 international clinics of the AMP-SCZ study, the CHiRPE pipeline integrates symptom-domain mapping, LLM summarisation, and BERT classification. CHiRPE achieved over 90% accuracy across three BERT variants and outperformed baseline models. Explanation formats were evaluated by 28 clinical experts who indicated a strong preference for our novel concept-guided explanations, especially hybrid graph-and-text summary formats. CHiRPE demonstrates that clinically-guided model development produces both accurate and interpretable results. Our next step is focused on real-world testing across our 24 international sites."
  },
  {
    "date": "2026-01-26",
    "title": "EFT Perspective On de-Sitter S-Matrix",
    "authors": "Sayantan Choudhury",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18101v1",
    "source": "arXiv",
    "abstract": "Non-perturbative limitations on low-energy effective field theories (EFTs) based on the characteristics of high-energy theory are provided by the analyticity of the flat-space version of the S-matrix. Although the analyticity of the flat-space S-matrix is widely established, it is difficult to apply this framework to de Sitter space because the growing backdrop breaks time-translation symmetry and makes it more difficult to define asymptotic states. The flat-space analyticity imprint on the de Sitter S-matrix is examined in this study. On a certain limit, we derive a comprehensive relationship between the flat-space amplitude and the de Sitter S-matrix. In particular, we demonstrate that the relationship is valid for tree-level amplitude exchanging with arbitrary local derivative interactions with a large scalar field. Next, we contend that this specific limit is more consistent with the definition of EFT since, similar to flat space, the Mandelstam variable may be identified as the unique energy scale because the total energy dependence of the de Sitter S-matrix becomes negligible. Finally, we also find an unexpected connection between the idea of generalized energy conservation of an S-matrix of four-dimensional de Sitter and exceptional EFTs in de Sitter space. We restrict the coupling constants in theories of self-interacting scalars dwelling in the exceptional series of de Sitter representations by requiring that such an S-matrix only has support when the total energies of in and out states are equal. We rediscover the Dirac-Born-Infeld (DBI) and Special Galileon theories, in which a single coupling constant uniquely fixes the four-point scalar self-interactions."
  },
  {
    "date": "2026-01-26",
    "title": "Tail-Latency-Aware Federated Learning with Pinching Antenna: Latency, Participation, and Placement",
    "authors": "Yushen Lin, Zhiguo Ding",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18097v1",
    "source": "arXiv",
    "abstract": "Straggler synchronization is a dominant wall-clock bottleneck in synchronous wireless federated learning (FL). Under non-IID data, however, aggressively sampling only fast clients may significantly slow convergence due to statistical heterogeneity. This paper studies PASS-enabled FL, where a radiating pinching antenna (PA) can be activated at an arbitrary position along a dielectric waveguide to reshape uplink latencies. We consider a joint optimization of PA placement and client participation to minimize the expected time-to-accuracy, coupling the exact expected maximum round latency via order statistics with a heterogeneity-aware convergence factor. We derive first-order optimality conditions that reveal an explicit tail-latency premium in the KKT recursion, quantifying how latency gaps are amplified by maximum-order-statistic synchronization. Under a latency-class structure, we obtain a within-class square-root sampling law and establish a two-class phase transition where slow-class participation collapses under an explicit heterogeneity-threshold condition as the per-round sample size grows. For PA placement, we prove a piecewise envelope-derivative characterization and provide an exact breakpoint-and-root candidate-enumeration procedure. Simulation results verify the theoretical findings and show that PASS enables more eligible participation, yielding higher wall-clock accuracy."
  },
  {
    "date": "2026-01-26",
    "title": "Dimers for degenerating families of M-curves",
    "authors": "Takashi Ichikawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18093v1",
    "source": "arXiv",
    "abstract": "We study dimer models on infinite minimal graphs with Fock's weights for degenerating families of M-curves of any genus based on works of Boutillier-Cimasoni-de Tilière and Bobenko A.I.- Bobenko N.-Suris for a fixed M-curve. We show that these dimer models for families of M-curves behave consistently under their degeneration shrinking real circles to points, and that they can be calculated as power series in the associated deformation parameters which are regarded as the perturbation of Kenyon's critical dimer models."
  },
  {
    "date": "2026-01-26",
    "title": "From LLMs to LRMs: Rethinking Pruning for Reasoning-Centric Models",
    "authors": "Longwei Ding, Anhao Zhao, Fanghua Ye, Ziyang Chen, Xiaoyu Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18091v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly costly to deploy, motivating extensive research on model pruning. However, most existing studies focus on instruction-following LLMs, leaving it unclear whether established pruning strategies transfer to reasoning-augmented models that explicitly generate long intermediate reasoning traces. In this work, we conduct a controlled study of pruning for both instruction-following ($\\textbf{LLM-instruct}$) and reasoning-augmented ($\\textbf{LLM-think}$) models. To isolate the effects of pruning, we align pruning calibration and post-pruning recovery data with each model's original training distribution, which we show yields more stable and reliable pruning behavior. We evaluate static depth pruning, static width pruning, and dynamic pruning across 17 tasks spanning classification, generation, and reasoning. Our results reveal clear paradigm-dependent differences: depth pruning outperforms width pruning on classification tasks, while width pruning is more robust for generation and reasoning. Moreover, static pruning better preserves reasoning performance, whereas dynamic pruning excels on classification and generation but remains challenging for long-chain reasoning. These findings underscore the need for pruning strategies that explicitly account for the distinct characteristics of reasoning-augmented LLMs. Our code is publicly available at https://github.com/EIT-NLP/LRM-Pruning."
  },
  {
    "date": "2026-01-26",
    "title": "Log-linear law of the mean streamwise velocity in turbulent boundary layers with moderate adverse pressure gradients",
    "authors": "Fuzhou Lyu, Lihao Zhao, Weixi Huang, Chunxiao Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18087v1",
    "source": "arXiv",
    "abstract": "An essential feature of canonical zero-pressure-gradient (ZPG) turbulent boundary layers (TBLs) is that the mean streamwise velocity exhibits a logarithmic dependence on the wall-normal distance, known as the log law. In this study, we demonstrate that this conventional log law is not suitable for turbulent boundary layers subjected to pressure gradients (PGs). Instead, a log--linear law is theoretically derived for TBLs under moderate adverse pressure gradients (APGs), based on the total shear-stress balance and a rescaled eddy-viscosity model. The validity of the proposed log--linear law is assessed using available datasets of incompressible APG TBLs with the Clauser pressure-gradient parameter $β$ ranging from 0.73 to 9.0. Compared with the conventional log law, the present log--linear formulation shows significantly improved agreement with the measured mean velocity profiles. In the limiting case of $β\\to 0$, the proposed law naturally recovers the classical log law."
  },
  {
    "date": "2026-01-26",
    "title": "Feedback-Based Quantum Control for Safe and Synergistic Drug Combination Design",
    "authors": "Mai Nguyen Phuong Nhi, Lan Nguyen Tran, Le Bin Ho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18082v1",
    "source": "arXiv",
    "abstract": "Drug-drug interactions (DDIs) strongly affect the safety and efficacy of combination therapies. Despite the availability of large DDI databases, selecting optimal multi-drug combinations that balance safety, therapeutic benefit, and regimen size remains a challenging combinatorial optimization problem. Here, we present a quantum-control-based framework for DDI-aware drug combination optimization, in which known harmful and synergistic interactions are encoded into Ising Hamiltonians as penalties and rewards, respectively. The optimization is performed using the feedback-based quantum algorithm FALQON, a gradient-free variational approach. We study two clinically motivated tasks: the Maximum Safe Subset problem and the Synergy-Constrained Optimization problem. Numerical simulations using interaction data from Drugs.com and SYNERGxDB demonstrate efficient convergence and high-quality solutions for clinically relevant drug sets, including COVID-19 case studies."
  },
  {
    "date": "2026-01-26",
    "title": "Use of operator defect identities in multi-channel signal plus residual-analysis via iterated products and telescoping energy-residuals: Applications to kernels in machine learning",
    "authors": "Palle E. T. Jorgensen, Myung-Sin Song, James F. Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18080v1",
    "source": "arXiv",
    "abstract": "We present a new operator theoretic framework for analysis of complex systems with intrinsic subdivisions into components, taking the form of \"residuals\" in general, and \"telescoping energy residuals\" in particular. We prove new results which yield admissibility/effectiveness, and new a priori bounds on energy residuals. Applications include infinite-dimensional Kaczmarz theory for $λ_{n}$-relaxed variants, and $λ_{n}$-effectiveness. And we give applications of our framework to generalized machine learning algorithms, greedy Kernel Principal Component Analysis (KPCA), proving explicit convergence results, residual energy decomposition, and criteria for stability under noise."
  },
  {
    "date": "2026-01-26",
    "title": "Comparison requires valid measurement: Rethinking attack success rate comparisons in AI red teaming",
    "authors": "Alexandra Chouldechova, A. Feder Cooper, Solon Barocas, Abhinav Palia, Dan Vann, Hanna Wallach",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18076v1",
    "source": "arXiv",
    "abstract": "We argue that conclusions drawn about relative system safety or attack method efficacy via AI red teaming are often not supported by evidence provided by attack success rate (ASR) comparisons. We show, through conceptual, theoretical, and empirical contributions, that many conclusions are founded on apples-to-oranges comparisons or low-validity measurements. Our arguments are grounded in asking a simple question: When can attack success rates be meaningfully compared? To answer this question, we draw on ideas from social science measurement theory and inferential statistics, which, taken together, provide a conceptual grounding for understanding when numerical values obtained through the quantification of system attributes can be meaningfully compared. Through this lens, we articulate conditions under which ASRs can and cannot be meaningfully compared. Using jailbreaking as a running example, we provide examples and extensive discussion of apples-to-oranges ASR comparisons and measurement validity challenges."
  },
  {
    "date": "2026-01-26",
    "title": "Diffusion Model-based Reinforcement Learning for Version Age of Information Scheduling: Average and Tail-Risk-Sensitive Control",
    "authors": "Haoyuan Pan, Sizhao Chen, Zhaorui Wang, Tse-Tin Chan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18069v1",
    "source": "arXiv",
    "abstract": "Ensuring timely and semantically accurate information delivery is critical in real-time wireless systems. While Age of Information (AoI) quantifies temporal freshness, Version Age of Information (VAoI) captures semantic staleness by accounting for version evolution between transmitters and receivers. Existing VAoI scheduling approaches primarily focus on minimizing average VAoI, overlooking rare but severe staleness events that can compromise reliability under stochastic packet arrivals and unreliable channels. This paper investigates both average-oriented and tail-risk-sensitive VAoI scheduling in a multi-user status update system with long-term transmission cost constraints. We first formulate the average VAoI minimization problem as a constrained Markov decision process and introduce a deep diffusion-based Soft Actor-Critic (D2SAC) algorithm. By generating actions through a diffusion-based denoising process, D2SAC enhances policy expressiveness and establishes a strong baseline for mean performance. Building on this foundation, we put forth RS-D3SAC, a risk-sensitive deep distributional diffusion-based Soft Actor-Critic algorithm. RS-D3SAC integrates a diffusion-based actor with a quantile-based distributional critic, explicitly modeling the full VAoI return distribution. This enables principled tail-risk optimization via Conditional Value-at-Risk (CVaR) while satisfying long-term transmission cost constraints. Extensive simulations show that, while D2SAC reduces average VAoI, RS-D3SAC consistently achieves substantial reductions in CVaR without sacrificing mean performance. The dominant gain in tail-risk reduction stems from the distributional critic, with the diffusion-based actor providing complementary refinement to stabilize and enrich policy decisions, highlighting their effectiveness for robust and risk-aware VAoI scheduling in multi-user wireless systems."
  },
  {
    "date": "2026-01-26",
    "title": "Mesoamerican proportional design and astronomical dualities: rational approximations consistent with $φ$ and $π$ in calendrics and architecture",
    "authors": "Gabriel K. Kruell, Oliver López-Corona, Sergio Mendoza, Pablo Padilla, Elvia Ramírez-Carrillo, Sarahí Silva",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18066v1",
    "source": "arXiv",
    "abstract": "Understanding how ancient Mesoamerican societies integrated mathematical ideas into calendrical design and monumental architecture requires approaches that acknowledge their distinct epistemological frameworks. While explicit textual evidence for concepts such as $π$ or the golden ratio $φ$ is absent, numerical patterns embedded in Mesoamerican calendars, iconography, and ritual architecture reveal a coherent system of proportional reasoning grounded in simple integer ratios. Here we show that the numbers 5 and 8, central to Venus and solar calendrical relations and widely represented in Mesoamerican cosmology, generate rational approximations that reproduce, within known construction tolerances, the geometric relations associated with decagonal layouts. Using high-resolution measurements of the Iguana structure at Guachimontones, we demonstrate that its proportions align with integer ratios consistent with those found in the calendrical system and with the practical geometry of the regular decagon, without requiring knowledge of irrational constants. These findings suggest that Mesoamerican builders employed stable proportional modules that harmonized astronomical cycles, cosmological symbolism, and architectural design. This should not be interpreted as a lack of mathematical sophistication; rather, the material record reveals a distinct mathematical tradition in which number, measure, and cosmology were mutually reinforcing elements of cultural knowledge."
  },
  {
    "date": "2026-01-26",
    "title": "Grounded Concreteness: Human-Like Concreteness Sensitivity in Vision-Language Models",
    "authors": "Aryan Roy, Zekun Wang, Christopher J. MacLellan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18065v1",
    "source": "arXiv",
    "abstract": "Do vision--language models (VLMs) develop more human-like sensitivity to linguistic concreteness than text-only large language models (LLMs) when both are evaluated with text-only prompts? We study this question with a controlled comparison between matched Llama text backbones and their Llama Vision counterparts across multiple model scales, treating multimodal pretraining as an ablation on perceptual grounding rather than access to images at inference. We measure concreteness effects at three complementary levels: (i) output behavior, by relating question-level concreteness to QA accuracy; (ii) embedding geometry, by testing whether representations organize along a concreteness axis; and (iii) attention dynamics, by quantifying context reliance via attention-entropy measures. In addition, we elicit token-level concreteness ratings from models and evaluate alignment to human norm distributions, testing whether multimodal training yields more human-consistent judgments. Across benchmarks and scales, VLMs show larger gains on more concrete inputs, exhibit clearer concreteness-structured representations, produce ratings that better match human norms, and display systematically different attention patterns consistent with increased grounding."
  },
  {
    "date": "2026-01-26",
    "title": "Resonant Sparse Geometry Networks",
    "authors": "Hasi Hays",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18064v1",
    "source": "arXiv",
    "abstract": "We introduce Resonant Sparse Geometry Networks (RSGN), a brain-inspired architecture with self-organizing sparse hierarchical input-dependent connectivity. Unlike Transformer architectures that employ dense attention mechanisms with O(n^2) computational complexity, RSGN embeds computational nodes in learned hyperbolic space where connection strength decays with geodesic distance, achieving dynamic sparsity that adapts to each input. The architecture operates on two distinct timescales: fast differentiable activation propagation optimized through gradient descent, and slow Hebbian-inspired structural learning for connectivity adaptation through local correlation rules. We provide rigorous mathematical analysis demonstrating that RSGN achieves O(n*k) computational complexity, where k << n represents the average active neighborhood size. Experimental evaluation on hierarchical classification and long-range dependency tasks demonstrates that RSGN achieves 96.5% accuracy on long-range dependency tasks while using approximately 15x fewer parameters than standard Transformers. On challenging hierarchical classification with 20 classes, RSGN achieves 23.8% accuracy (compared to 5% random baseline) with only 41,672 parameters, nearly 10x fewer than the Transformer baselines which require 403,348 parameters to achieve 30.1% accuracy. Our ablation studies confirm the contribution of each architectural component, with Hebbian learning providing consistent improvements. These results suggest that brain-inspired principles of sparse, geometrically-organized computation offer a promising direction toward more efficient and biologically plausible neural architectures."
  },
  {
    "date": "2026-01-26",
    "title": "Invariance of domain in locally o-minimal structures",
    "authors": "Masato Fujita",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18062v1",
    "source": "arXiv",
    "abstract": "Definable continuous injective maps defined on definable open sets into the Euclidean spaces of the same dimension are open maps in definably complete locally o-minimal expansions of ordered groups."
  },
  {
    "date": "2026-01-26",
    "title": "Thicker amorphous grain boundary complexions reduce plastic strain localization in nanocrystalline Cu-Zr",
    "authors": "Esther C. Hessong, Nicolo Maria della Ventura, Tongjun Niu, Daniel S. Gianola, Hyosim Kim, Nan Li, Saryu Fensin, Brad L. Boyce, Timothy J. Rupert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18059v1",
    "source": "arXiv",
    "abstract": "Amorphous grain boundary complexions have been shown to increase the plasticity of nanocrystalline alloys as compared to ordered grain boundaries. Here, the effect of an important structural descriptor, amorphous complexion thickness, on the plasticity and failure modes of nanocrystalline Cu-Zr is studied with in-situ compression testing, with over 50 micropillars tested. Two model materials were created that differ only in their complexion thickness, with one having a thicker complexion population than the other. The sample with thinner complexions was more likely to experience non-uniform plastic deformation in the form of localized plastic flow or shear banding. In contrast, the sample with thicker complexions displayed more homogeneous plasticity and higher damage tolerance; thicker amorphous complexions suppress localization by absorbing defects. This work demonstrates that increasing complexion thickness can be beneficial for stable plastic flow in nanocrystalline alloys, by improving resistance to strain localization and premature failure."
  },
  {
    "date": "2026-01-26",
    "title": "Nucleophilic substitution at silicon under vibrational strong coupling: Refined insights from a high-level ab initio perspective",
    "authors": "Niels-Ole Frerick, Michael Roemelt, Eric W. Fischer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18540v1",
    "source": "arXiv",
    "abstract": "We study the bimolecular nucleophilic substitution (S$_\\mathrm{N}$2) reaction of 1-phenyl-2-trimethylsilylacetylene (PTA) under vibrational strong coupling (VSC) from the perspective of high-level ab initio quantum and polaritonic chemistry. Specifically, we address conflicting mechanistic proposals, cavity-induced electronic corrections under VSC and the relevance of a previously debated Si-C-stretching motion of PTA for vibrational polariton formation. We first provide computational evidence for a two-step mechanism based on density functional theory and high-level coupled cluster results, identify new encounter and products complexes and illustrate the relevance of diffuse basis functions for a qualitatively correct description of anionic reactive systems. We subsequently show that cavity-induced dipole fluctuation corrections of electronic energies can be significant on the level of cavity Born-Oppenheimer coupled cluster theory and discuss their qualitative impact on the proposed two-step mechanism taking into account cavity-induced molecular reorientation. We finally show that the Si-C-stretching contribution to the experimentally relevant double-peak feature of PTA exhibits a dominant dipole character, which renders it central for linear IR response and vibrational polariton formation despite the presence of CH$_3$-rocking contributions. The dipole character along the cleaving Si-C-bond is eventually shown to rationalize Rabi splittings throughout the proposed two-step mechanism. Our work refines the microscopic perspective on the S$_\\mathrm{N}$2 reaction of PTA under VSC and highlights recent developments in ab initio polaritonic chemistry for the VSC regime."
  },
  {
    "date": "2026-01-26",
    "title": "Hybrid Radar Fusion with Quantization: CRB-Rate Trade-offs and ADC Dynamic Range",
    "authors": "Akhileswar Chowdary, Ahmad Bazzi, Marwa Chafii",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18539v1",
    "source": "arXiv",
    "abstract": "Recent advancements have underscored the relevance of low-resolution analog-to-digital converters (ADCs) in integrated sensing and communication (ISAC) systems. Nevertheless, their specific impact on hybrid radar fusion (HRF) remains largely unexplored. In HRF systems, where uplink (UL) paths carry direct and reflected signals in the same frequency band, the reflected signal is often significantly weaker, making HRF performance particularly sensitive to ADC resolution. To study this effect, we use the quantized Cramér-Rao bound (CRB) to measure sensing accuracy. This work derives an upper bound on the quantized CRB for angle of arrival (AoA) estimation and explores CRB-rate trade-offs through two formulated optimization problems. Simulation results indicate that HRF becomes infeasible when the dynamic range of the received signal exceeds the dynamic range supported by the ADC, which is inherently limited by its resolution. Furthermore, the UL communication rate does not increase significantly when the ADC resolution is raised beyond a certain threshold. These observations highlight a fundamental trade-off between sensing and communication performance: while HRF performance benefits from higher ADC resolutions, the corresponding gains in communication rate plateau. This trade-off is effectively characterized using CRB-rate boundaries derived through simulation."
  },
  {
    "date": "2026-01-26",
    "title": "Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models",
    "authors": "Francesco Maria Molfese, Momchil Hardalov, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18527v1",
    "source": "arXiv",
    "abstract": "With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks."
  },
  {
    "date": "2026-01-26",
    "title": "Gravitational Lorentz-violating $e^-+e^+\\to\\ell^-+\\ell^+$ scattering",
    "authors": "L. A. S. Evangelista, A. F. Santos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18523v1",
    "source": "arXiv",
    "abstract": "We investigate the gravitational $e^-+e^+\\to\\ell^-+\\ell^+$ scattering process within the framework of gravitoelectromagnetism, a weak-field approximation of gravity analogous to Maxwell's theory of electromagnetism. This process involves the interaction between a fermion and an antifermion mediated by graviton exchange. We consider the nonminimal gravitational sector of the standard model extension and calculate the corrections to the scattering cross section arising from Lorentz violation. The analysis is carried out in two scenarios: (i) at zero temperature and (ii) at finite temperature. To incorporate thermal effects, we employ the thermo field dynamics formalism, which allows for a consistent treatment of quantum fields at finite temperature. The results provide insights into how Lorentz-violating and thermal corrections influence gravitational interactions, particularly relevant in high-energy or astrophysical environments."
  },
  {
    "date": "2026-01-26",
    "title": "Livestock, Methane and Climate",
    "authors": "D. Alexander, J. D. Ferguson, A. Glatzle, W. Happer, W. A. van Wijngaarden",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18522v1",
    "source": "arXiv",
    "abstract": "Methane emissions by livestock have a negligible effect on Earth's temperature. For example, killing all of the approximately 1.6 billion cattle on Earth in the year 2025, when this paper was written, would only reduce atmospheric methane concentrations enough to change the temperature by -0.04 C. Killing all 1.3 billion sheep would lead to a temperature change of -0.004 C. New Zealand's pledge to reduce methane emissions of their livestock by 14% to 24% from those in the year 2017 would change the temperature by -0.000005 to -0.000008 C, far too small to measure. These are maximum temperature savings where methane emissions from domestic livestock are not replaced by other sources (such as wild ruminants and termites) during the inevitable rewilding of managed grasslands and rangelands."
  },
  {
    "date": "2026-01-26",
    "title": "Magnetic Signatures of a Putative Fractional Topological Insulator in Twisted MoTe2",
    "authors": "Yiping Wang, Gillian E. Minarik, Weijie Li, Yves Kwan, Shuai Yuan, Eric Anderson, Chaowei Hu, Julian Ingham, Jeongheon Choe, Takashi Taniguchi, Kenji Watanabe, Xavier Roy, Jiun-Haw Chu, Raquel Queiroz, James C. Hone, N. Regnault, Xiaodong Xu, Xiaoyang Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18508v1",
    "source": "arXiv",
    "abstract": "The interplay among electronic correlation, topology, and time-reversal-symmetry (TRS) often leads to exotic quantum states of matter. Primary examples include the recently realized fractional Chern insulators (FCIs) in twisted MoTe2 bilayers (tMoTe2) and multilayer graphene aligned with hBN, where TRS is broken in partially filled flat moire Chern bands. Among the FCIs in tMoTe2, the most robust is at a hole filling of v = -2/3 per moire unit cell. Interestingly, transient optical sensing and more recent transport measurements revealed a correlated state at v = -4/3, twice the filling factor for the v = -2/3 FCI. Here, employing pump-probe circular dichroism (CD) measurements on tMoTe2 with twist angles = 3.9 degree and 3.7 degree, we find that the v = -4/3 state exhibits vanishing magnetization (m = 0) in finite windows of out-of-plane magnetic field less than ~2-4 mT, and a first order phase transition to + - m states at higher fields. This out-of-plane antiferromagnetic (AFM) like behavior is notably absent for all other correlated states and disappears for the v = -4/3 state at higher or lower twist angles = 4.0 degree and 3.3 degree. The observed magnetic signature at v = -4/3 is consistent with a predicted fractional topological insulator (FTI) with TRS, consisting of two copies of -2/3 FCIs with opposite chiralities. We support these findings with calculations in the interacting continuum model of tMoTe2. Our work presents a candidate for fractional topological insulators with TRS."
  },
  {
    "date": "2026-01-26",
    "title": "Curvature and Lagrangian submanifolds of nearly Kähler $\\mathbb{C}P^3$",
    "authors": "Michaël Liefsoens, Joeri Van der Veken",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18504v1",
    "source": "arXiv",
    "abstract": "A tractable definition of the homogeneous nearly Kähler structure on $\\mathbb{C}P^3$ is given via the Hopf fibration, facilitating explicit computations and analysis. The description extends to all homogeneous metrics on $\\mathbb{C}P^3$, providing expressions for their Riemann curvature tensors and full isometry groups. Rigid immersions are presented for all extrinsically homogeneous Lagrangian submanifolds in the nearly Kähler $\\mathbb{C}P^3$, and the nonexistence of Lagrangians with constant sectional curvature is established."
  },
  {
    "date": "2026-01-26",
    "title": "Regulatory Hub Discovery in MDD Methylome: Hypotheses for Molecular Subtypes via Computational Analysis",
    "authors": "Mingyan Liu, Min Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18498v1",
    "source": "arXiv",
    "abstract": "Major Depressive Disorder (MDD) is a clinically heterogeneous syndrome with diverse etiological pathways. Traditional Epigenome-Wide Association Studies (EWAS) have successfully identified risk loci based on differential methylation magnitude. As a complementary perspective, effect-size-based ranking alone may not fully capture regulatory nodes that exhibit modest methylation changes but occupy critical upstream positions in biological networks. Here, we report findings and hypotheses from a two-tier computational analysis of DNA methylation data (GSE198904; \\(n=206\\) ), combining conventional statistical approaches with machine learning-assisted regulatory inference."
  },
  {
    "date": "2026-01-26",
    "title": "Real-Time Prediction of Lower Limb Joint Kinematics, Kinetics, and Ground Reaction Force using Wearable Sensors and Machine Learning",
    "authors": "Josée Mallah, Yu Zhu, Kailang Xu, Gurvinder S. Virk, Shaoping Bai, Luigi G. Occhipinti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18494v1",
    "source": "arXiv",
    "abstract": "Walking is a key movement of interest in biomechanics, yet gold-standard data collection methods are time- and cost-expensive. This paper presents a real-time, multimodal, high sample rate lower-limb motion capture framework, based on wireless wearable sensors and machine learning algorithms. Random Forests are used to estimate joint angles from IMU data, and ground reaction force (GRF) is predicted from instrumented insoles, while joint moments are predicted from angles and GRF using deep learning based on the ResNet-16 architecture. All three models achieve good accuracy compared to literature, and the predictions are logged at 1 kHz with a minimal delay of 23 ms for 20s worth of input data. The present work fully relies on wearable sensors, covers all five major lower limb joints, and provides multimodal comprehensive estimations of GRF, joint angles, and moments with minimal delay suitable for biofeedback applications."
  },
  {
    "date": "2026-01-26",
    "title": "DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment",
    "authors": "Sara Tehrani, Yonghao Xu, Leif Haglund, Amanda Berg, Michael Felsberg",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18493v1",
    "source": "arXiv",
    "abstract": "Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines. To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery."
  },
  {
    "date": "2026-01-26",
    "title": "Electrostatic Screening Modulation of Graphene's Electronic Structure and the Helical Wavefunction-Dominated Topological Properties",
    "authors": "Yaorui Tan, Xiang Chen, Yunhu Zhu, Xiaowu Yang, Zhongkai Huang, Chuang Yao, Maolin Bo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18489v1",
    "source": "arXiv",
    "abstract": "This study examines electrostatic screening effects in graphene using tight binding calculations under the BBC and modified BBC models, with sigmav ranging from 0.00 to 3.00. Our results demonstrate that the modified BBC potential decays, which effectively suppresses electron-electron interactions. Hopping integrals decrease by 65% over distance and shift 7% with sigmav, while on site energy rises linearly by 0.045 eV. A band gap opens for sigmav greater than or equal to 1.00. The density of states peaks near the Fermi level, with the low energy region largely unaffected. Graphene's low energy helical wave functions yield topological features like pseudospin momentum locking and a pi Berry phase, leading to distinct transport behavior. The model avoids the Coulomb singularity, offering insights for 2D screening engineering and topological device design."
  },
  {
    "date": "2026-01-26",
    "title": "Superconductivity under pressure in the two-dimensional van der Waals heavy-fermion metal CeSiI",
    "authors": "Tong Shi, Wenhao Li, Qingxin Dong, Pengtao Yang, Hanming Ma, Zhaoming Tian, Ningning Wang, Jianping Sun, Yoshiya Uwatoko, Yi-feng Yang, Bosen Wang, Hechang Lei, Jinguang Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18476v1",
    "source": "arXiv",
    "abstract": "CeSiI is a newly discovered exfoliable van der Waals (vdW) heavy-fermion metal featured by a long-range antiferromagnetic (AF) order (TN =7.5 K) inside the Kondo coherent state below T* = 50 K. To gain a more profound understanding of the intriguing physics of this material and to uncover novel phenomena driven by quantum criticality, it is imperative to construct the phase diagram of CeSiI detailing the evolutions of T* and TN as a function of external tuning parameters such as pressure (P).In this study, we employ high pressure as an effective tuning knob to investigate this system, thereby generating a comprehensive T-P phase diagram of CeSiI. This diagram is characterized by an unusual V-shaped nonmonotonic evolution of T*(P) and the emergence of a superconducting dome with Tcmax = 240 mK upon suppression of AF order at Pc = 6 GPa, coinciding with the minimum of T*(P).The close proximity of the superconductivity (SC) to the AF instability and an unusually large upper critical field Bc2(0) exceeding 4-7 times the Pauli paramagnetic limit, suggests an unconventional pairing mechanism in CeSiI. Further analyses of normal-state transport properties provide evidence of quantum criticality, i.e., non-Fermi-liquid behavior and divergence of quasiparticle effective mass near Pc = 7 GPa. Our findings not only establish CeSiI as the first vdW heavy-fermion superconductor but also highlight an unconventional nature for the Kondo coherent state at T* at ambient pressure, hence opening a new avenue to study the interplay of strong electron correlation, Kondo hybridization, magnetism, and unconventional SC in the vdW heavy-fermion systems."
  },
  {
    "date": "2026-01-26",
    "title": "Plasmon assisted superconductivity in LiTi$_2$O$_4$",
    "authors": "Francesco Petocchi, Viktor Christiansson, Ryotaro Arita, Philipp Werner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18472v1",
    "source": "arXiv",
    "abstract": "We combine $GW$ plus extended dynamical mean field theory ($GW$+EDMFT) with the density functional theory for superconductors (SCDFT) framework to study the electronic properties of LiTi$_2$O$_4$. Excellent agreement with experiment is obtained for the density of states, mass enhancement, Sommerfeld coefficient and superconducting $T_c$, if the dynamical nature of the screened Coulomb interaction is taken into account. Our results show that the coupling to collective charge fluctuations (plasmons) plays an important role in the pairing mechanism and explains the remarkably high $T_c$ of this moderately correlated spinel compound."
  },
  {
    "date": "2026-01-26",
    "title": "First-principles study of bulk stacking, $J_{\\rm eff}$ picture, magnetic Hamiltonian, $g$ factors, and structural distortions of $α$-RuCl$_3$",
    "authors": "Seung-Ju Hong, Tae Yun Kim, Cheol-Hwan Park",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18469v1",
    "source": "arXiv",
    "abstract": "$α$-RuCl$_3$ is a candidate Kitaev material that exhibits zigzag antiferromagnetic ordering below 7 K. One contentious issue regarding this material is its bulk structure in the low-temperature phase. Recently, it has become generally accepted from experiments that the low- and high-temperature structures belong to the $R\\bar{3}$ and $C2/m$ space groups, respectively. However, there was no theoretical study supporting the $R\\bar{3}$-type structure as the low-temperature structure. In this study, we use constrained density functional theory to show that the $R\\bar{3}$ structure is lower in energy than the $C2/m$ structure, in agreement with experimental observations. Then, we show that the conduction band minimum states are almost of the $J_\\textrm{eff}=1/2$ and $m_\\textrm{eff}=-1/2$ character, if we set the angular momentum quantization axis to be parallel to the Néel vector; this is the first analysis of the $J_\\textrm{eff}$ picture for $α$-RuCl$_3$ from this perspective. In addition, we compute the anisotropic magnetic exchange parameters and $g$ factors of monolayer $α$-RuCl$_3$, thereby providing a comprehensive understanding of its magnetism. Our results demonstrate that both second-nearest-neighbor exchange interactions and magnetic moments not captured by the conventional atomic orbital projection method are necessary for accurate description of the magnetism in $α$-RuCl$_3$. Moreover, the calculated $g$ factors are in fairly good agreement with experimental measurements, especially the small anisotropy between their in-plane and out-of-plane components. Finally, we examine the effects of structural distortions from a perfect RuCl$_6$ octahedron, already present in bulk $α$-RuCl$_3$ without any external perturbation, on the magnetic properties. (The abstract is cut here due to the word limit; see the pdf file for the full abstract.)"
  },
  {
    "date": "2026-01-26",
    "title": "OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents",
    "authors": "Yuhang Zhou, Kai Zheng, Qiguang Chen, Mengkang Hu, Qingfeng Sun, Can Xu, Jingjing Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18467v1",
    "source": "arXiv",
    "abstract": "Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL."
  },
  {
    "date": "2026-01-26",
    "title": "Study of dynamical systems and large-scale structure",
    "authors": "Dumiso Mithi, Saikat Charkraborty, Shambel Sahlu, Amare Abebe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18466v1",
    "source": "arXiv",
    "abstract": "In this study, we employ dynamical systems methods to analyse the large-scale structure by considering two distinct interaction models (linear and non-linear) within the dark sector, associated with a specific dynamical dark energy model inspired by the Veneziano ghost theory in quantum chromodynamics (QCD). In these models, the dark energy density ($ρ_{DE}$) varies with the Hubble parameter ($H$), expressed as $ρ_{DE} = αH + βH^2$. After defining the dimensionless parameters, we present autonomous equations that allow us to find the trace $\\text{Tr}(J)$ and the determinant $D(J)$. With these solutions, we demonstrate the presence of unstable, saddle, and stable fixed points, corresponding to the radiation-, matter-, and dark-energy-dominated eras, respectively. Our results suggest that these models are theoretically viable for representing the interaction between dark sector fluids."
  },
  {
    "date": "2026-01-26",
    "title": "Justification of a Relaxation Approximation for the Navier-Stokes-Cahn-Hilliard System",
    "authors": "Jan Giesselmann, Jens Keim, Fabio Leotta, Christian Rohde",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18463v1",
    "source": "arXiv",
    "abstract": "The Navier-Stokes-Cahn-Hilliard (NSCH) system governs the diffuse-interface dynamics of two incompressible and immiscible fluids. We consider a relaxation approximation of the NSCH system that is composed by a system of first-order hyperbolic balance laws and second-order elliptic operators. We prove first that the solutions of an initial boundary value problem for the approximation recover the limiting NSCH system for vanishing relaxation parameters. To cope with the singular limit we exploit the fact that the approximate solutions dissipate an almost quadratic energy, and employ the relative entropy-framework. In the second part of the work we provide numerical evidence for the analytical results, even in flow regimes not covered by the assumptions needed for the theoretical results. Using a novel marker-and-cell conservative finite-difference approach for both the approximation and the limit system, we are able to compute physically relevant interfacial flow problems including Ostwald ripening and high-velocity flow."
  },
  {
    "date": "2026-01-26",
    "title": "Phase conjugated master oscillator fiber power amplifier",
    "authors": "Tingwei Gu, Xin Zeng, Huawei Jiang, Suming Luo, Maokai Yang, Xuezong Yang, Yan Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18459v1",
    "source": "arXiv",
    "abstract": "High-power narrow-linewidth fiber lasers are fundamentally limited by stimulated Brillouin scattering (SBS), which constrains further power scaling while maintaining spectral linewidth. Traditional mitigation techniques, such as active phase modulation, often introduce trade-offs among complexity, cost, and spectral brightness. In this study, we propose and experimentally demonstrate a novel all-optical approach for spectral linewidth manipulation and SBS suppression using optical phase conjugation (OPC). By leveraging nonlinear spectral broadening followed by phase conjugation, this method enables sophisticated linewidth narrowing in fiber amplifier, resulting in narrow linewidth output and enhanced SBS threshold. Using a low-cost fiber oscillator as the seed source, we achieve a spectral compression ratio exceeding 3 times. This method not only eliminates the need for complex electro-optic modulation systems but also provides a pathway toward simpler, high-brightness fiber laser systems. Our findings underscore the viability of OPC as a transformative tool for nonlinearity management and power scaling in high-performance fiber laser architectures."
  },
  {
    "date": "2026-01-26",
    "title": "Deep Reinforcement Learning for Hybrid RIS Assisted MIMO Communications",
    "authors": "Phuong Nam Tran, Nhan Thanh Nguyen, Markku Juntti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18453v1",
    "source": "arXiv",
    "abstract": "Hybrid reconfigurable intelligent surfaces (HRIS) enhance wireless systems by combining passive reflection with active signal amplification. However, jointly optimizing the transmit beamforming with the HRIS reflection and amplification coefficients to maximize spectral efficiency (SE) is a non-convex problem, and conventional iterative solutions are computationally intensive. To address this, we propose a deep reinforcement learning (DRL) framework that learns a direct mapping from channel state information to the near-optimal transmit beamforming and HRIS configurations. The DRL model is trained offline, after which it can compute the beamforming and HRIS configurations with low complexity and latency. Simulation results demonstrate that our DRL-based method achieves 95% of the SE obtained by the alternating optimization benchmark, while significantly lowering the computational complexity."
  },
  {
    "date": "2026-01-26",
    "title": "On the existence of heavy columns in binary matrices with distinct rows",
    "authors": "Jamolidin K. Abdurakhmanov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18450v1",
    "source": "arXiv",
    "abstract": "We investigate the existence of heavy columns in binary matrices with distinct rows. A column of an m x n binary matrix is called heavy if the number of ones in it is at least m/2. We introduce two recursive algorithms, A1 and A2, that examine properties of subma trices obtained by row filtering and column deletion. We prove that if algorithm A1 returns True for a binary matrix with distinct rows, then the matrix contains at least one heavy column (Theorem 1). Further more, we prove that if algorithm A2 returns True for a binary matrix with distinct rows, distinct columns, and no all-zero columns, then the matrix also contains at least one heavy column (Theorem 2). The key innovation in A2 is an early termination condition: if exactly one row has a zero in some column, that column is immediately identified as heavy. The proofs employ a novel argument based on the existence of unpaired rows with respect to specific columns, combined with careful analysis of the recursive structure of the algorithms."
  },
  {
    "date": "2026-01-26",
    "title": "On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics",
    "authors": "Lloyd Austin Courtenay",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18448v1",
    "source": "arXiv",
    "abstract": "Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust \"diagonal\" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space."
  },
  {
    "date": "2026-01-26",
    "title": "NuMagSANS: a GPU-accelerated open-source software package for the generic computation of nuclear and magnetic small-angle neutron scattering observables of complex systems",
    "authors": "Michael P. Adams, Andreas Michels",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18444v1",
    "source": "arXiv",
    "abstract": "We present NuMagSANS, a GPU-accelerated software package for calculating nuclear and magnetic small-angle neutron scattering (SANS) cross sections and correlation functions. The program allows users to import position-dependent nuclear density and magnetization data, providing a large flexibility for analyzing the scattering signatures of complex systems, particularly magnetic materials. Full rotational control of the sample is supported, allowing a comprehensive exploration of angular-dependent scattering features. NuMagSANS includes a versatile library of approximately 100 response functions that encompass two-dimensional SANS cross sections, correlation functions, and azimuthally averaged quantities. These capabilities allow users to gain detailed insight into the structural and magnetic characteristics of their samples. GPU acceleration ensures rapid computations, even for large data sets, making NuMagSANS a powerful and efficient tool for advanced SANS analysis."
  },
  {
    "date": "2026-01-26",
    "title": "UrgentMOS: Unified Multi-Metric and Preference Learning for Robust Speech Quality Assessment",
    "authors": "Wei Wang, Wangyou Zhang, Chenda Li, Jiahe Wang, Samuele Cornell, Marvin Sach, Kohei Saijo, Yihui Fu, Zhaoheng Ni, Bing Han, Xun Gong, Mengxiao Bi, Tim Fingscheidt, Shinji Watanabe, Yanmin Qian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18438v1",
    "source": "arXiv",
    "abstract": "Automatic speech quality assessment has become increasingly important as modern speech generation systems continue to advance, while human listening tests remain costly, time-consuming, and difficult to scale. Most existing learning-based assessment models rely primarily on scarce human-annotated mean opinion score (MOS) data, which limits robustness and generalization, especially when training across heterogeneous datasets. In this work, we propose UrgentMOS, a unified speech quality assessment framework that jointly learns from diverse objective and perceptual quality metrics, while explicitly tolerating the absence of arbitrary subsets of metrics during training. By leveraging complementary quality facets under heterogeneous supervision, UrgentMOS enables effective utilization of partially annotated data and improves robustness when trained on large-scale, multi-source datasets. Beyond absolute score prediction, UrgentMOS explicitly models pairwise quality preferences by directly predicting comparative MOS (CMOS), making it well suited for preference-based evaluation scenarios commonly adopted in system benchmarking. Extensive experiments across a wide range of speech quality datasets, including simulated distortions, speech enhancement, and speech synthesis, demonstrate that UrgentMOS consistently achieves state-of-the-art performance in both absolute and comparative evaluation settings."
  },
  {
    "date": "2026-01-26",
    "title": "TopKGAT: A Top-K Objective-Driven Architecture for Recommendation",
    "authors": "Sirui Chen, Jiawei Chen, Canghong Jin, Sheng Zhou, Jingbang Chen, Wujie Sun, Can Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18432v1",
    "source": "arXiv",
    "abstract": "Recommendation systems (RS) aim to retrieve the top-K items most relevant to users, with metrics such as Precision@K and Recall@K commonly used to assess effectiveness. The architecture of an RS model acts as an inductive bias, shaping the patterns the model is inclined to learn. In recent years, numerous recommendation architectures have emerged, spanning traditional matrix factorization, deep neural networks, and graph neural networks. However, their designs are often not explicitly aligned with the top-K objective, thereby limiting their effectiveness. To address this limitation, we propose TopKGAT, a novel recommendation architecture directly derived from a differentiable approximation of top-K metrics. The forward computation of a single TopKGAT layer is intrinsically aligned with the gradient ascent dynamics of the Precision@K metric, enabling the model to naturally improve top-K recommendation accuracy. Structurally, TopKGAT resembles a graph attention network and can be implemented efficiently. Extensive experiments on four benchmark datasets demonstrate that TopKGAT consistently outperforms state-of-the-art baselines. The code is available at https://github.com/StupidThree/TopKGAT."
  },
  {
    "date": "2026-01-26",
    "title": "Analyzing the Error of Generative Diffusion Models: From Euler-Maruyama to Higher-Order Schemes",
    "authors": "Emanuel Pfarr, Radu Timofte, Frank Werner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18425v1",
    "source": "arXiv",
    "abstract": "Although generative diffusion models (GDMs) are widely used in practice, their theoretical foundations remain limited, especially concerning the impact of different discretization schemes applied to the underlying stochastic differential equation (SDE). Existing convergence analysis largely focuses on Euler-Maruyama (EM)-like methods and does not extend to higher-order schemes, which are naturally expected to provide improved discretization accuracy. In this paper, we establish asymptotic 2-Wasserstein convergence results for SDE-based discretization methods employed in sampling for GDMs. We provide an all-at-once error bound analysis of the EM method that accounts for all error sources and establish convergence under all prevalent score-matching error assumptions in the literature, assuming a strongly log-concave data distribution. Moreover, we present the first error bound result for arbitrary higher-order SDE-discretization methods with known strong L_2 convergence in dependence on the discretization grid and the score-matching error. Finally, we complement our theoretical findings with an extensive numerical study, providing comprehensive experimental evidence and showing that, contrary to popular believe, higher order discretization methods can in fact retain their theoretical advantage over EM for sampling GDMs."
  },
  {
    "date": "2026-01-26",
    "title": "Electric and magnetic timelike form factors of hyperons at large transfer momentum",
    "authors": "G. Ramalho, M. T. Peña, K. Tsushima, Myung-Ki Cheoun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18423v1",
    "source": "arXiv",
    "abstract": "There has been considerable progress in the study of the electromagnetic form factors of baryons in the timelike region, through electron-positron scattering reactions ($e^+ e^- \\to B \\bar B$), in the last two decades. Timelike experiments reveal information about the distribution of charge and magnetism inside the hyperons that cannot be obtained in spacelike experiments (electron scattering on baryons). Motivated by the novel data, we extend to the timelike region, without any further parameter fitting, a covariant quark model developed for the spacelike region that takes into account the meson cloud excitations of the baryon cores. We use the formalism to calculate the electric ($G_E$) and magnetic ($G_M$) form factors of spin 1/2 baryons in the large square transfer momentum $q^2$ region. Our calculations are compared with the available data from CLEO and BESIII above $q^2=10$ GeV$^2$. We conclude that our predictions for the effective form factors (combination between $G_E$ and $G_M$) are in good agreement with the $q^2 > 15$ GeV$^2$ data for $Λ$, $Σ^+$, $Σ^0$, $Ξ^-$ and $Ξ^0$. Upcoming data for $Σ^-$ can be used to further test our predictions. We also compare our model calculations with the available data for ratio $|G_E/G_M|$. We conclude that the present $q^2$ data range is not large enough to test our calculations, but that a more definitive test can be performed by upcoming data above $q^2=20$ GeV$^2$."
  },
  {
    "date": "2026-01-26",
    "title": "A Jacobian-free Newton-Krylov method for high-order cell-centred finite volume solid mechanics",
    "authors": "Ivan Batistic, Pablo Castrillo, Philip Cardiff",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18417v1",
    "source": "arXiv",
    "abstract": "This work extends the application of Jacobian-free Newton-Krylov (JFNK) methods to higher-order cell-centred finite-volume formulations for solid mechanics. While conventional schemes are typically limited to second-order accuracy, we present third- and fourth-order formulations employing local least-squares reconstructions for gradient evaluation and Gaussian quadrature at cell faces. These schemes enable accurate resolution of complex stress and deformation fields in linear and nonlinear solids while retaining the flexibility of finite-volume methods. A key contribution is a JFNK solution strategy for these higher-order schemes, eliminating the need to assemble complex Jacobian matrices. A compact-stencil approximate Jacobian is used as a preconditioner, providing efficiency gains similar to second-order frameworks. To enhance robustness on irregular meshes, an alpha-stabilisation scheme is incorporated, damping high-frequency error modes without compromising formal accuracy. The proposed methodology is benchmarked across a suite of two- and three-dimensional test problems involving elastic and nonlinear materials, where key performance metrics, including accuracy, computational cost, memory usage, and robustness, are systematically evaluated. Results confirm that the higher-order formulations deliver substantial accuracy improvements over second-order schemes, while the JFNK approach achieves strong performance with only minimal modifications to existing segregated frameworks. These findings underscore the potential of combining higher-order finite-volume methods with JFNK solvers to advance the state of the art in computational solid mechanics. The implementations are openly released in the solids4foam toolbox for OpenFOAM, supporting further exploration and adoption by the community."
  },
  {
    "date": "2026-01-26",
    "title": "Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings",
    "authors": "Aura Loredana Dan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18414v1",
    "source": "arXiv",
    "abstract": "Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts."
  },
  {
    "date": "2026-01-26",
    "title": "Time-Scale-Adaptable Spectrum Sharing for Hybrid Satellite-Terrestrial Networks",
    "authors": "Yanmin Wang, Wei Feng, Yunfei Chen, Yongxu Zhu, Shidong Zhou, Cheng-Xiang Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18410v1",
    "source": "arXiv",
    "abstract": "Cooperation between satellite and terrestrial wireless networks promises great potential in meeting fast-growing demands for ubiquitous communications coverage. To tackle spectrum scarcity, spectrum sharing is studied for a hybrid satellite-terrestrial network where satellite links share the same group of time-slotted sub-carriers with terrestrial links opportunistically. In particular, with coarse network-wide time synchronization, a time-scale-adaptable spectrum sharing framework is proposed based on a satellite-terrestrial cooperation time scale that can be flexibly adjusted according to practical requirements. For generality, it is assumed that both full and partial frequency reuse could be adopted among the base stations (BSs) and satellite selection is supported when multiple satellites are available. Relying on only statistical channel state information (CSI), joint link scheduling and power control are explored to maximize the average sum rate of the network while ensuring quality of service (QoS) for users. To solve the complicated mixed integer programming (MIP) problem, a low-complexity spectrum sharing scheme is presented based on link-feature-sketching-aided hierarchical link clustering and Monte-Carlo-and-successive-approximation-aided transmit power optimization. Simulation results demonstrate that by link feature sketching, diversity of the links brought by the spatial distribution of the users could be well utilized. The proposed scheme promises a significant performance gain even under strict inter-link interference constraints."
  },
  {
    "date": "2026-01-26",
    "title": "Self-assembly of quasicrystals under cyclic shear",
    "authors": "Raphaël Maire, Andrea Plati, Frank Smallenburg, Giuseppe Foffi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18403v1",
    "source": "arXiv",
    "abstract": "We investigate the self-assembly of two-dimensional dodecagonal quasicrystals driven by cyclic shear, effectively replacing thermal fluctuations with plastic rearrangements. Using particles interacting via a smoothed square-shoulder potential, we demonstrate that cyclic shearing drives initially random configurations into ordered quasicrystalline states. The resulting non-equilibrium phase diagram qualitatively mirrors that of thermal equilibrium, exhibiting square, quasicrystalline, and hexagonal phases, as well as phase coexistence. Remarkably, the shear-stabilised quasicrystal appears even where the zero-temperature equilibrium ground state favours square-hexagonal coexistence, suggesting that mechanical driving can stabilise quasicrystalline order in a way analogous to entropic effects in thermal systems. The structural quality of the self-assembled state is maximised near the yielding transition, even though the dynamics are slowest there. Yet, the system still quickly forms monodomain quasicrystals without any complex annealing protocols, unlike at equilibrium, where thermal annealing would be required. Finite-size scaling analysis reveals that global orientational order decays slowly with system size, indicative of quasi-long-range order comparable to equilibrium hexatic phases. Overall, our results establish cyclic shear as an efficient pathway for the self-assembly of complex structures."
  },
  {
    "date": "2026-01-26",
    "title": "Estimating Dense-Packed Zone Height in Liquid-Liquid Separation: A Physics-Informed Neural Network Approach",
    "authors": "Mehmet Velioglu, Song Zhai, Alexander Mitsos, Adel Mhamdi, Andreas Jupke, Manuel Dahmen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18399v1",
    "source": "arXiv",
    "abstract": "Separating liquid-liquid dispersions in gravity settlers is critical in chemical, pharmaceutical, and recycling processes. The dense-packed zone height is an important performance and safety indicator but it is often expensive and impractical to measure due to optical limitations. We propose to estimate phase heights using only inexpensive volume flow measurements. To this end, a physics-informed neural network (PINN) is first pretrained on synthetic data and physics equations derived from a low-fidelity (approximate) mechanistic model to reduce the need for extensive experimental data. While the mechanistic model is used to generate synthetic training data, only volume balance equations are used in the PINN, since the integration of submodels describing droplet coalescence and sedimentation into the PINN would be computationally prohibitive. The pretrained PINN is then fine-tuned with scarce experimental data to capture the actual dynamics of the separator. We then employ the differentiable PINN as a predictive model in an Extended Kalman Filter inspired state estimation framework, enabling the phase heights to be tracked and updated from flow-rate measurements. We first test the two-stage trained PINN by forward simulation from a known initial state against the mechanistic model and a non-pretrained PINN. We then evaluate phase height estimation performance with the filter, comparing the two-stage trained PINN with a two-stage trained purely data-driven neural network. All model types are trained and evaluated using ensembles to account for model parameter uncertainty. In all evaluations, the two-stage trained PINN yields the most accurate phase-height estimates."
  },
  {
    "date": "2026-01-26",
    "title": "Seeing through water: diffuse image-based depth measurements in three-dimensional dam-break flows",
    "authors": "Elia Buono, Roberto Bosio, Andrea Cagninei, Davide Poggi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18398v1",
    "source": "arXiv",
    "abstract": "In this work we present a dedicated experimental facility and an image-based method for measuring water depth in a radially spreading dam-break wave propagating over a horizontal plane. The facility consists of a prismatic reservoir containing a known volume of water dyed with a soluble colorant and equipped with a removable vertical breach whose geometry can be varied, and a 6.4 m x 3.4 m plane that can be inclined from 0° to 30°. The plane is enclosed within a light box providing highly uniform illumination through an array of 60 LED floodlights. Wave propagation is captured by two scientific CMOS cameras mounted on the ceiling of the light box, which record the spatial and temporal evolution of the dye-induced color intensity associated with the advancing water layer. Preliminary dry calibration tests were conducted to assess the spectral compatibility between the broadband white-LED emission, the CMOS sensor sensitivity, and the absorption properties of several dyes at different concentrations. This analysis identified the dye providing the highest attenuation within the effective spectral band of the imaging system, ensuring sensitivity to very small optical path lengths. Based on this characterization, a bi-exponential model is introduced to relate the normalized gray level to the optical path length. A series of dam-break experiments with five initial reservoir levels was performed to assess statistical repeatability. The high consistency observed across the repeated tests confirms the robustness of the measurement procedure. The validity of the reconstructed depth fields is further supported by independent estimates of the water volume released from the reservoir, obtained from an array of ultrasonic level sensors and from a calibrated analytical emptying model. Together, these comparisons confirm the reliability and accuracy of the proposed methodology."
  },
  {
    "date": "2026-01-26",
    "title": "OCR-Enhanced Multimodal ASR Can Read While Listening",
    "authors": "Junli Chen, Changli Tang, Yixuan Li, Guangzhi Sun, Chao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18393v1",
    "source": "arXiv",
    "abstract": "Visual information, such as subtitles in a movie, often helps automatic speech recognition. In this paper, we propose Donut-Whisper, an audio-visual ASR model with dual encoder to leverage visual information to improve speech recognition performance in both English and Chinese. Donut-Whisper combines the advantage of the linear and the Q-Former-based modality alignment structures via a cross-attention module, generating more powerful audio-visual features. Meanwhile, we propose a lightweight knowledge distillation scheme showcasing the potential of using audio-visual models to teach audio-only models to achieve better performance. Moreover, we propose a new multilingual audio-visual speech recognition dataset based on movie clips containing both Chinese and English partitions. As a result, Donut-Whisper achieved significantly better performance on both English and Chinese partition of the dataset compared to both Donut and Whisper large V3 baselines. In particular, an absolute 5.75% WER reduction and a 16.5% absolute CER reduction were achieved on the English and Chinese sets respectively compared to the Whisper ASR baseline."
  },
  {
    "date": "2026-01-26",
    "title": "Stability of the free boundary Willmore problem",
    "authors": "Anna Dall'Acqua, Fabian Rupp, Reiner Schätzle, Manuel Schlierf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18388v1",
    "source": "arXiv",
    "abstract": "We study the Willmore problem with free boundary by means of a new Łojasiewicz-Simon gradient inequality for functionals on infinite dimensional manifolds. In contrast to previous works, we do not rely on a gradient-like representation of the Fréchet derivative, but merely on an inequality. For the free boundary Willmore flow, we prove that solutions starting sufficiently close to a local minimizer exist for all times and converge. In the static setting, we prove quantitative stability of free boundary Willmore immersions and a local rigidity result in a neighborhood of free boundary minimal surfaces."
  },
  {
    "date": "2026-01-26",
    "title": "Assessing astrophysical foreground subtraction in DECIGO using compact binary populations inferred from the first part of the LIGO-Virgo-KAGRA's fourth observation run",
    "authors": "Takahiro S. Yamamoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18378v1",
    "source": "arXiv",
    "abstract": "Detecting the stochastic gravitational wave background (SGWB) from our Universe under the inflationary era is one of the primary scientific objectives of DECIGO, a space-borne gravitational wave detector sensitive in the 0.1 Hz frequency band. This frequency band is dominated by the gravitational waves from inspiraling compact object binaries. Subtracting these signals is necessary to search for the primordial SGWB. In this paper, we assess the feasibility of the subtraction of such binary signals by employing the population model inferred from the latest gravitational wave event catalogue of the LIGO-Virgo-KAGRA Collaboration. We find that the projection scheme, which was originally proposed by Cutler & Harms (2005), is necessary to reduce the binary signals to the level where DECIGO can detect the primordial background."
  },
  {
    "date": "2026-01-26",
    "title": "Gaze Prediction in Virtual Reality Without Eye Tracking Using Visual and Head Motion Cues",
    "authors": "Christos Petrou, Harris Partaourides, Athanasios Balomenos, Yannis Kopsinis, Sotirios Chatzis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18372v1",
    "source": "arXiv",
    "abstract": "Gaze prediction plays a critical role in Virtual Reality (VR) applications by reducing sensor-induced latency and enabling computationally demanding techniques such as foveated rendering, which rely on anticipating user attention. However, direct eye tracking is often unavailable due to hardware limitations or privacy concerns. To address this, we present a novel gaze prediction framework that combines Head-Mounted Display (HMD) motion signals with visual saliency cues derived from video frames. Our method employs UniSal, a lightweight saliency encoder, to extract visual features, which are then fused with HMD motion data and processed through a time-series prediction module. We evaluate two lightweight architectures, TSMixer and LSTM, for forecasting future gaze directions. Experiments on the EHTask dataset, along with deployment on commercial VR hardware, show that our approach consistently outperforms baselines such as Center-of-HMD and Mean Gaze. These results demonstrate the effectiveness of predictive gaze modeling in reducing perceptual lag and enhancing natural interaction in VR environments where direct eye tracking is constrained."
  },
  {
    "date": "2026-01-26",
    "title": "Nonparametric inference for spot volatility in pure-jump semimartingales",
    "authors": "Chengxin Yan, Dachuan Chen, Jia Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18371v1",
    "source": "arXiv",
    "abstract": "We provide a comprehensive analysis of spot volatility inference in pure-jump semimartingales under two asymptotic settings: fixed-$k$, where each local window uses a fixed number of observations, and large-$k$, where this number grows with sampling frequency. For both active- and possibly inactive-jump settings, we derive generally nonstandard, typically non-Gaussian limit distributions and establish valid inference, including when the jump-activity index is consistently estimated. Simulations show that fixed-$k$ asymptotics offer markedly better finite-sample accuracy, underscoring their practical advantage for nonparametric spot volatility inference."
  },
  {
    "date": "2026-01-26",
    "title": "Adversarial Synchronization",
    "authors": "Anton E. Lipin, Mikhail V. Volkov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18362v1",
    "source": "arXiv",
    "abstract": "We study a variant of the synchronization game on finite deterministic automata. In this game, Alice chooses one input letter of an automaton $A$ on each of her moves while Bob may respond with an arbitrary finite word over the input alphabet of $A$; Alice wins if the word obtained by interleaving her letters with Bob's responses resets $A$. We prove that if Alice has a winning strategy in this game on $A$, then $A$ admits a reset word whose length is strictly smaller than the number of states of $A$. In contrast, for any $k\\ge 1$, we exhibit automata with shortest reset-word length quadratic in the number of states, on which Alice nevertheless wins a version of the game in which Bob's responses are restricted to arbitrary words of length at most $k$. We provide polynomial-time algorithms for deciding the winner in various synchronization games, and we analyze the relationships between variants of synchronization games on fixed-size automata."
  },
  {
    "date": "2026-01-26",
    "title": "Uncertainty Quantification in Calibration and Simulation of Thermo-Chemical Curing of Epoxy Resins",
    "authors": "Jendrik-Alexander Tröger, Christina Steinweller, Stefan Hartmann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18359v1",
    "source": "arXiv",
    "abstract": "Curing of epoxy resins poses a particular challenge in terms of modeling, experimental investigation, and numerical implementation, as it is a thermo-chemo-mechanical process. Several constitutive relations are required to model these processes, yielding numerous material parameters. The calibration of the constitutive relations must be performed using multiple steps, wherein uncertainties unavoidably propagate. In this study, we investigate the propagation of uncertainties during both the multi-step calibration procedure and the numerical simulation of curing processes with the identified parameters. For both, we employ the first-order second-moment method, which is carefully evaluated through coverage tests and by comparing it to the Monte Carlo method as a reference. It is demonstrated that the first-order second-moment method efficiently yields reasonable results, although providing only a first-order approximation of the highly nonlinear stochastic model response."
  },
  {
    "date": "2026-01-26",
    "title": "On strong valid inequalities for a class of mixed-integer nonlinear sets with box constraints",
    "authors": "Keyan Li, Yan-Ru Wang, Wei-Kun Chen, Yu-Hong Dai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18358v1",
    "source": "arXiv",
    "abstract": "In this paper, we investigate the mixed-integer nonlinear set with box constraints $X = \\{(w,x)\\in R\\times Z^n:w\\leq f(a^Tx),0\\leq x\\leq μ\\}$, where $f$ is a univariate concave function, $a\\in R^n$, and $μ\\in Z^n_{++}$. This set arises as a substructure in many mixed-integer nonlinear optimization models and encompasses, as special cases, several previously investigated mixed-integer sets, namely the submodular maximization set, the mixed-integer knapsack set, and the mixed-integer polyhedral conic set. We present the first comprehensive polyhedral study of conv($X$). In particular, we derive a class of seed inequalities for a two-dimensional restriction of $X$, obtained by fixing all but one of the $x$ variables to their bounds in $X$, and develop two lifting procedures to obtain strong valid inequalities for conv($X$). In the first lifting procedure, we derive a subadditive approximation for the exact lifting function of the seed inequalities, and lift all fixed variables in a single phase. In the second lifting procedure, we first lift variables fixed at their lower bounds before those at their upper bounds (and vice versa), using subadditive exact and approximation lifting functions, respectively. The derived single- and two-phase lifted inequalities are shown to be facet-defining for conv($X$) under mild conditions. Moreover, for the aforementioned special cases of conv($X$), we show that the proposed lifted inequalities can either unify existing strong valid inequalities or yield new facet-defining inequalities. Finally, extensive computational experiments on expected utility maximization and weapon-target assignment problems demonstrate that the proposed lifted inequalities can substantially strengthen the continuous relaxations and significantly improve the overall computational performance of branch-and-cut algorithms."
  },
  {
    "date": "2026-01-26",
    "title": "Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books",
    "authors": "Tuhin Chakrabarty, Paramveer S. Dhillon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18353v1",
    "source": "arXiv",
    "abstract": "Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes \"good writing.\" These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor."
  },
  {
    "date": "2026-01-26",
    "title": "Forecasting the Maintained Score from the OpenSSF Scorecard for GitHub Repositories linked to PyPI libraries",
    "authors": "Alexandros Tsakpinis, Efe Berk Ergülec, Emil Schwenger, Alexander Pretschner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18344v1",
    "source": "arXiv",
    "abstract": "The OpenSSF Scorecard is widely used to assess the security posture of open-source software repositories, with the Maintained metric indicating recent development activity and helping identify potentially abandoned dependencies. However, this metric is inherently retrospective, reflecting only the past 90 days of activity and providing no insight into future maintenance, which limits its usefulness for proactive risk assessment. In this paper, we study to what extent future maintenance activity, as captured by the OpenSSF Maintained score, can be forecasted. We analyze 3,220 GitHub repositories associated with the top 1% most central PyPI libraries by PageRank and reconstruct historical Maintained scores over a three-year period. We formulate the task as multivariate time series forecasting and consider four target representations: raw scores, bucketed maintenance levels, numerical trend slopes, and categorical trend types. We compare a statistical model (VARMA), a machine learning model (Random Forest), and a deep learning model (LSTM) across training windows of 3-12 months and forecasting horizons of 1-6 months. Our results show that future maintenance activity can be predicted with meaningful accuracy, particularly for aggregated representations such as bucketed scores and trend types, achieving accuracies above 0.95 and 0.80, respectively. Simpler statistical and machine learning models perform on par with deep learning approaches, indicating that complex architectures are not required. These findings suggest that predictive modeling can effectively complement existing Scorecard metrics, enabling more proactive assessment of open-source maintenance risks."
  },
  {
    "date": "2026-01-26",
    "title": "Beyond Rigid: Benchmarking Non-Rigid Video Editing",
    "authors": "Bingzheng Qu, Kehai Chen, Xuefeng Bai, Jun Yu, Min Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18340v1",
    "source": "arXiv",
    "abstract": "Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing."
  },
  {
    "date": "2026-01-26",
    "title": "A Dataset for Automatic Vocal Mode Classification",
    "authors": "Reemt Hinrichs, Sonja Stephan, Alexander Lange, Jörn Ostermann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18339v1",
    "source": "arXiv",
    "abstract": "The Complete Vocal Technique (CVT) is a school of singing developed in the past decades by Cathrin Sadolin et al.. CVT groups the use of the voice into so called vocal modes, namely Neutral, Curbing, Overdrive and Edge. Knowledge of the desired vocal mode can be helpful for singing students. Automatic classification of vocal modes can thus be important for technology-assisted singing teaching. Previously, automatic classification of vocal modes has been attempted without major success, potentially due to a lack of data. Therefore, we recorded a novel vocal mode dataset consisting of sustained vowels recorded from four singers, three of which professional singers with more than five years of CVT-experience. The dataset covers the entire vocal range of the subjects, totaling 3,752 unique samples. By using four microphones, thereby offering a natural data augmentation, the dataset consists of more than 13,000 samples combined. An annotation was created using three CVT-experienced annotators, each providing an individual annotation. The merged annotation as well as the three individual annotations come with the published dataset. Additionally, we provide some baseline classification results. The best balanced accuracy across a 5-fold cross validation of 81.3\\,\\% was achieved with a ResNet18. The dataset can be downloaded under https://zenodo.org/records/14276415."
  },
  {
    "date": "2026-01-26",
    "title": "Integrated Channel Estimation and Sensing for Near-Field ELAA Systems",
    "authors": "Jionghui Wang, Jun Fang, Hongbin Li, Boyu Ning",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18333v1",
    "source": "arXiv",
    "abstract": "In this paper, we study the problem of uplink channel estimation for near-filed orthogonal frequency division multiplexing (OFDM) systems, where a base station (BS), equipped with an extremely large-scale antenna array (ELAA), serves multiple users over the same time-frequency resource block. A non-orthogonal pilot transmission scheme is considered to accommodate a larger number of users that can be supported by ELAA systems without incurring an excessive amount of training overhead. To facilitate efficient multi-user channel estimation, we express the received signal as a third-order low-rank tensor, which admits a canonical polyadic decomposition (CPD) model for line-of-sight (LoS) scenarios and a block term decomposition (BTD) model for non-line-of-sight (NLoS) scenarios. An alternating least squares (ALS) algorithm and a non-linear least squares (NLS) algorithm are employed to perform CPD and BTD, respectively. Channel parameters are then efficiently extracted from the recovered factor matrices. By exploiting the geometry of the propagation paths in the estimated channel, users' positions can be precisely determined in LoS scenarios. Moreover, our uniqueness analysis shows that the proposed tensor-based joint multi-user channel estimation framework is effective even when the number of pilot symbols is much smaller than the number of users, revealing its potential in training overhead reduction. Simulation results demonstrate that the proposed method achieves markedly higher channel estimation accuracy than compressed sensing (CS)-based approaches."
  },
  {
    "date": "2026-01-26",
    "title": "Cognitive Fusion of ZC Sequences and Time-Frequency Images for Out-of-Distribution Detection of Drone Signals",
    "authors": "Jie Li, Jing Li, Lu Lv, Zhanyu Ju, Fengkui Gong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18326v1",
    "source": "arXiv",
    "abstract": "We propose a drone signal out-of-distribution detection (OODD) algorithm based on the cognitive fusion of Zadoff-Chu (ZC) sequences and time-frequency images (TFI). ZC sequences are identified by analyzing the communication protocols of DJI drones, while TFI capture the time-frequency characteristics of drone signals with unknown or non-standard communication protocols. Both modalities are used jointly to enable OODD in the drone remote identification (RID) task. Specifically, ZC sequence features and TFI features are generated from the received radio frequency signals, which are then processed through dedicated feature extraction module to enhance and align them. The resultant multi-modal features undergo multi-modal feature interaction, single-modal feature fusion, and multi-modal feature fusion to produce features that integrate and complement information across modalities. Discrimination scores are computed from the fused features along both spatial and channel dimensions to capture time-frequency characteristic differences dictated by the communication protocols, and these scores will be transformed into adaptive attention weights. The weighted features are then passed through a Softmax function to produce the signal classification results. Simulation results demonstrate that the proposed algorithm outperforms existing algorithms and achieves 1.7% and 7.5% improvements in RID and OODD metrics, respectively. The proposed algorithm also performs strong robustness under varying flight conditions and across different drone types."
  },
  {
    "date": "2026-01-26",
    "title": "Possible favored Great Oxidation Event scenario on exoplanets around M-Stars with the example of TRAPPIST-1e",
    "authors": "Adam Y. Jaziri, Nathalie Carrasco, Benjamin Charnay",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18324v1",
    "source": "arXiv",
    "abstract": "The Great Oxidation Event (GOE), which marked the transition from an anoxic to an oxygenated atmosphere, occurred 2.4 billion years ago on Earth, several hundreds of millions of years after the emergence of oxygenic photosynthesis. This long delay implies that specific conditions in terms of biomass productivity and burial were necessary to trigger the GOE. It could be a limiting factor for the development of oxygenated atmospheres on inhabited exoplanets. In this study, we explore the specificities of a terrestrial planet in the habitable zone of an M dwarf for a GOE. Using a 1D coupled photochemical-climate model, we simulate the atmospheric evolution of TRAPPIST-1 e, an Earth-like exoplanet, exploring the effect of oxygen sources (biotic or abiotic). Our results show that the stellar energy distribution promotes O3 production at lower O2 concentrations compared to Earth, and the ozone layer on TRAPPIST-1 e forms more efficiently. This lowers the threshold for atmospheric oxidation, suggesting that the GOE on TRAPPIST-1 e would occur quickly after the rise of oxygenic photosynthesis, up to 1Gyrs earlier than on Earth, and would reach O2 enabling oxygenic respiration and thus the development of animals. We may question whether this is a general behavior around several M-stars. Furthermore, we discuss how the overproduction of ozone could make O3 detection possible using the James Webb Space Telescope, providing a potential method to observe oxygenation signatures on exoplanets in the near future. Previous studies predicted that for an Earth-like atmosphere O3 would require over 150 transits for detection, but our results show that significantly fewer transits could be needed."
  },
  {
    "date": "2026-01-26",
    "title": "Structural and dynamic anomalous properties of TIP4P/2005 water at extreme pressures",
    "authors": "José Martín-Roca, Alberto Zaragoza, Frédéric Caupin, Chantal Valeriani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18318v1",
    "source": "arXiv",
    "abstract": "Water shows numerous thermodynamic, dynamic, and structural anomalies. Recent experiments [Eichler et al. Phys. Rev. Lett. 134, 134101 (2025)], based on measurements of shear and bulk viscosities of liquid water up to 1.6 GPa, have reported the existence of a minimum in the variation of the structural relaxation time τα with pressure at room temperature. Here we investigate this and related properties with molecular dynamics simulations of the TIP4P/2005 water model, performed at extreme pressures commensurate with the experiments. Specifically, we compute dynamic (self-diffusion, shear and bulk viscosities, and structural relaxation time) and structural (oxygen-oxygen radial distribution function and structure factor, translational order parameter) properties down to 220 K and up to 2.7 GPa. We find good agreement with the experimental observations, and confirm the existence of a minimum in τα . The microscopic information obtained from the simulations suggests that this anomaly is connected with the sudden reorganization of the hydrogen bond network induced by pressurization."
  },
  {
    "date": "2026-01-26",
    "title": "Active topological strings in renewing nematopolar fluids",
    "authors": "Alberto Dinelli, Ludovic Dumoulin, Karsten Kruse",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18307v1",
    "source": "arXiv",
    "abstract": "Active matter often simultaneously exhibits different kinds of orientational order and, in many cases of biological interest, undergoes continuous material renewal. In renewing nematopolar fluids we find stable topological strings, structures consisting of two nematic point defects connected by a defect line in the polar field. We identify the mechanism underlying string stabilization and unveil how string length is determined. In the presence of active stress, we observe active-string chaos. Our work identifies continuous material renewal as a generic mechanism underlying the stabilization of topological defect structures in systems with mixed order parameters. It could be used for orchestrating living matter during development and other biological processes."
  },
  {
    "date": "2026-01-26",
    "title": "Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM",
    "authors": "Everlyn Asiko Chimoto, Mostafa Elhoushi, Bruce A. Bassett",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18306v1",
    "source": "arXiv",
    "abstract": "Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs."
  },
  {
    "date": "2026-01-26",
    "title": "SwipeGen: Bridging the Execution Gap in GUI Agents via Human-like Swipe Synthesis",
    "authors": "Xuan Wang, Siyuan Su, Quantong Fu, Yongxiang Hu, Yangfan Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18305v1",
    "source": "arXiv",
    "abstract": "With the widespread adoption of Graphical User Interface (GUI) agents for automating GUI interaction tasks, substantial research focused on improving GUI perception to ground task instructions into concrete action steps. However, the step execution capability of these agents has gradually emerged as a new bottleneck for task completion. In particular, existing GUI agents often adopt overly simplified strategies for handling swipe interactions, preventing them from accurately replicating human-like behavior. To address this limitation, we decompose human swipe gestures into multiple quantifiable dimensions and propose an automated pipeline SwipeGen to synthesize human-like swipe interactions through GUI exploration. Based on this pipeline, we construct and release the first benchmark for evaluating the swipe execution capability of GUI agents. Furthermore, leveraging the synthesized data, we propose GUISwiper, a GUI agent with enhanced interaction execution capabilities. Experimental results demonstrate that GUISwiper achieves a swipe execution accuracy of 69.07%, representing a 214% improvement over existing VLM baselines."
  },
  {
    "date": "2026-01-26",
    "title": "On the inclusion of bounded harmonic functions of random walks",
    "authors": "Yair Hartman, Aranka Hrušková, Omer Segev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18304v1",
    "source": "arXiv",
    "abstract": "We investigate the conditions under which the space of bounded harmonic functions of a probability measure $μ$ on a group $G$ is contained in that of another measure $θ$. We establish that asymptotic commutativity, defined by the condition $\\|μ^{*t}*θ- θ*μ^{*t}\\|_{TV} \\to 0$ as $t \\to \\infty$, is sufficient to guarantee the inclusion $H^\\infty(G, μ) \\subseteq H^\\infty(G, θ)$, provided $θ$ is absolutely continuous with respect to a convex combination of convolution powers of $μ$. By employing martingale convergence techniques rather than ergodic-theoretic arguments, we demonstrate that this result holds without topological assumptions on $G$ (such as local compactness) and extends to general Markov chains. Furthermore, utilizing hitting models for the Poisson boundary, we characterise the inclusion $H^\\infty(G, μ) \\subseteq H^\\infty(G, θ)$ as equivalent to the asymptotic invariance of $θ$ under $μ$ in the weak* topology. We apply these results to provide a probabilistic proof of the Choquet-Deny theorem for nilpotent groups, among other applications."
  },
  {
    "date": "2026-01-26",
    "title": "Suppressing Final Layer Hidden State Jumps in Transformer Pretraining",
    "authors": "Keigo Shibata, Kazuki Yano, Ryosuke Takahashi, Jaesung Lee, Wataru Ikeda, Jun Suzuki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18302v1",
    "source": "arXiv",
    "abstract": "This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture."
  },
  {
    "date": "2026-01-26",
    "title": "Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets",
    "authors": "Iaroslav Chelombitko, Mika Hämäläinen, Aleksey Komissarov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18791v1",
    "source": "arXiv",
    "abstract": "We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework."
  },
  {
    "date": "2026-01-26",
    "title": "Uniformly balanced $H$-factors in multicoloured complete graphs",
    "authors": "Agnijo Banerjee, Lawrence Hollom",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18789v1",
    "source": "arXiv",
    "abstract": "A balanced colouring of a graph is one in which every colour appears the same number of times. Given a fixed graph $H$ on $r$ vertices and a balanced $k$-colouring of the complete graph $K_{nrk}$, Hollom (2025) asked the following question: can we always find an $H$-factor $F$ covering all vertices of the complete graph $K_{nrk}$ such that the inherited colouring of $F$ is almost balanced? This is known to be the case for palettes of only two colours, or when $H$ is only a single edge. We answer the above question in full, finding an $H$-factor which is at most $C_{r,k}$ edges away from being balanced, where $C_{r,k}$ depends only on $r$ and $k$. In fact, we work in the more general setting wherein our palette of colours is a subset of $\\mathbb{S}^{d-1}$, and find an $H$-factor where the sum of the colours of all edges has bounded Euclidean norm."
  },
  {
    "date": "2026-01-26",
    "title": "Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System",
    "authors": "Tiffany Wang, Yuqian Sun, Yi Wang, Melissa Roemmele, John Joon Young Chung, Max Kreminski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18785v1",
    "source": "arXiv",
    "abstract": "The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system."
  },
  {
    "date": "2026-01-26",
    "title": "Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic",
    "authors": "Deepthi Pathare, Leo Laine, Morteza Haghir Chehreghani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18783v1",
    "source": "arXiv",
    "abstract": "Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications."
  },
  {
    "date": "2026-01-26",
    "title": "Low-Bit Quantization of Bandlimited Graph Signals via Iterative Methods",
    "authors": "Felix Krahmer, He Lyu, Rayan Saab, Jinna Qian, Anna Veselovska, Rongrong Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18782v1",
    "source": "arXiv",
    "abstract": "We study the quantization of real-valued bandlimited signals on graphs, focusing on low-bit representations. We propose iterative noise-shaping algorithms for quantization, including sampling approaches with and without vertex replacement. The methods leverage the spectral properties of the graph Laplacian and exploit graph incoherence to achieve high-fidelity approximations. Theoretical guarantees are provided for the random sampling method, and extensive numerical experiments on synthetic and real-world graphs illustrate the efficiency and robustness of the proposed schemes."
  },
  {
    "date": "2026-01-26",
    "title": "Another relation among the neutrino mass-squared differences?",
    "authors": "I. Alikhanov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18781v1",
    "source": "arXiv",
    "abstract": "Determining absolute neutrino masses remains a central challenge in particle physics. Relations among the neutrino mass-squared differences could facilitate this determination and shed additional light on the underlying mass-generation mechanism. Inspired by recent global fits of neutrino oscillation parameters, we propose a simple algebraic relation between $Δm^2_{21}$ and $Δm^2_{31}$. It provides a framework to analytically manipulate these parameters and admits specific physical interpretations. In particular, the results may point toward a vanishing $ν_1$ mass."
  },
  {
    "date": "2026-01-26",
    "title": "Virgo Filaments VI: H$α$ clumps in the filaments around the Virgo galaxy cluster",
    "authors": "G. Nagaraj, P. Jablonka, R. A. Finn, Y. M. Bahé, F. Combes, G. Castignani, B. Vulcani, G. Rudnick, D. Zakharova, R. A. Koopmann, D. Zaritsky, K. Conger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18762v1",
    "source": "arXiv",
    "abstract": "It is still not clear which environmental processes operate in filaments. Given the ubiquity of filaments and their importance in feeding clusters, a proper understanding of these mechanisms is crucial to a more complete picture of galaxy evolution. To investigate them, we need large galaxy samples with resolved imaging. For this study, we analyse resolved H$α$ maps of 685 galaxies inside and outside the filaments around the Virgo cluster in addition to extensive measurements of integrated physical properties. We create a pipeline to decompose the H$α$ images into individual clumps. We find that the number and average size of clumps in a galaxy are well-defined functions of distance and angular resolution. In particular, the power-law relation between the number of clumps and the distance of a galaxy is consistent with a fractal structure of star forming regions. We formulate an algorithm to compare filament and non-filament galaxies after removing observational differences. Although we do not have any conclusive evidence for a difference in clump size distributions between filament and non-filament galaxies, we do find that filament galaxies have slightly more peripheral clumps than their non-filament counterparts."
  },
  {
    "date": "2026-01-26",
    "title": "Unknotting number and connected sums: The knots $4_1$ and $5_1$",
    "authors": "Mark Brittenham, Susan Hermiller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18757v1",
    "source": "arXiv",
    "abstract": "We show that the knots $K\\in\\{4_1,5_1\\}$ can be paired with a corresponding knot $K^\\prime$ such that $u(K\\#K^\\prime)<u(K)+u(K^\\prime)$. As a consequence unknotting number fails to be additive for these knots. We also provide a candidate knot $K^\\prime$ for the knot $3_1$."
  },
  {
    "date": "2026-01-26",
    "title": "Efficient Trotter-Suzuki Schemes for Long-time Quantum Dynamics",
    "authors": "Marko Maležič, Johann Ostmeyer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18756v1",
    "source": "arXiv",
    "abstract": "Accurately simulating long-time dynamics of many-body systems is a challenge in both classical and quantum computing due to the accumulation of Trotter errors. While low-order Trotter-Suzuki decompositions are straightforward to implement, their rapidly growing error limits access to long-time observables. We present a framework for constructing efficient high-order Trotter-Suzuki schemes by identifying their structure and directly optimizing their parameters over a high-dimensional space. This method enables the discovery of new schemes with significantly improved efficiency compared to traditional constructions, such as those by Suzuki and Yoshida. Based on the theoretical efficiency and practical performance, we recommend two novel highly efficient schemes at $4^{\\textrm{th}}$ and $6^{\\textrm{th}}$ order. We also demonstrate the effectiveness of these decompositions on the Heisenberg model and the quantum harmonic oscillator, and find that for a fixed final time they perform better across the computational cost. Even when using large time steps, they surpass established low-order schemes like the Leapfrog. Finally, we investigate the in-practice performance of different Trotter schemes and find the decompositions with more uniform coefficients tend to feature improved error accumulation over long times. We have included this observation into our choice of recommended schemes."
  },
  {
    "date": "2026-01-26",
    "title": "Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval",
    "authors": "Amir Aavani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18747v1",
    "source": "arXiv",
    "abstract": "Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions. In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine."
  },
  {
    "date": "2026-01-26",
    "title": "Coherent control of photon pairs via quantum interference between second- and third-order quantum nonlinear processes",
    "authors": "Alessia Stefano, Samuel E. Fontaine, J. E. Sipe, Marco Liscidini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18746v1",
    "source": "arXiv",
    "abstract": "Genuine quantum interference between independent nonlinear processes of different order provides a route to coherent control that cannot be reduced to a classical field interference. Here we present an all-optical analogue of coherent carrier injection by exploiting interference between second- and third-order quantum nonlinear processes in an integrated photonic platform. Photon pairs generated via spontaneous parametric down-conversion and spontaneous four-wave mixing coherently contribute to the same final two-photon state, resulting in a phase-dependent modulation of both the generation rate and the spectral structure of the emitted biphoton state. We illustrate the features of such interference and how it can be used to shape biphoton wavefunctions and their quantum correlations. These results identify interference between nonlinear processes of different order as a distinct form of coherent quantum control within quantum nonlinear optics."
  },
  {
    "date": "2026-01-26",
    "title": "Approximate level-by-level maximum-likelihood decoding based on the Chase algorithm for high-rate concatenated stabilizer codes",
    "authors": "Takeshi Kakizaki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18743v1",
    "source": "arXiv",
    "abstract": "Fault-tolerant quantum computation (FTQC) is expected to address a wide range of computational problems. To realize large-scale FTQC, it is essential to encode logical qubits using quantum error-correcting codes. High-rate concatenated codes have recently attracted attention due to theoretical advances in fault-tolerant protocols with constant-space-overhead and polylogarithmic-time-overhead, as well as practical developments of high-rate many-hypercube codes equipped with a high-performance level-by-level minimum-distance decoder (LMDD). We propose a general, high-performance decoder for high-rate concatenated stabilizer codes that extends LMDD by leveraging the Chase algorithm to generate a suitable set of candidate errors. Our simulation results demonstrate that the proposed decoder outperforms conventional decoders for high-rate concatenated Hamming codes under bit-flip noise."
  },
  {
    "date": "2026-01-26",
    "title": "Sofic actions, halo products, and metric approximations of groups",
    "authors": "Vadim Alekseev, Henry Bradford",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18742v1",
    "source": "arXiv",
    "abstract": "We introduce the notion of a ``sofic $\\mathcal{C}$-action'' of one group on another by automorphisms, for $\\mathcal{C}$ a class of groups. We show that if $\\mathcal{C}$ is the class of (i) sofic, (ii) hyperlinear, (iii) linear sofic or (iv) weakly sofic groups, then the class $\\mathcal{C}$ is closed under taking semidirect products with sofic $\\mathcal{C}$-action. We use this to construct a wide variety of new examples of groups in the classes (i)-(iv), many of them arising as ``halo products'' in the sense of Genevois-Tessera. We have a parallel set of results producing new examples of semidirect products which are locally embeddable into finite groups. Our framework also unifies existing results in the literature, due to Hayes-Sale; Brude-Sasyk and Gao-Kunnawalkam Elayavalli-Patchell."
  },
  {
    "date": "2026-01-26",
    "title": "Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge",
    "authors": "Li Kang, Heng Zhou, Xiufeng Song, Rui Li, Bruno N. Y. Chen, Ziye Wang, Ximeng Meng, Stone Tao, Yiran Qin, Xiaohong Liu, Ruimao Zhang, Lei Bai, Yilun Du, Hao Su, Philip Torr, Zhenfei Yin, Ruihao Gong, Yejun Zeng, Fengjun Zhong, Shenghao Jin, Jinyang Guo, Xianglong Liu, Xiaojun Jia, Tianqi Shan, Wenqi Ren, Simeng Qin, Jialing Yang, Xiaoyu Ma, Tianxing Chen, Zixuan Li, Zijian Cai, Yan Qin, Yusen Qin, Qiangyu Chen, Kaixuan Wang, Zhaoming Han, Yao Mu, Ping Luo, Yuanqi Yao, Haoming Song, Jan-Nico Zaech, Fabien Despinoy, Danda Pani Paudel, Luc Van Gool",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18733v1",
    "source": "arXiv",
    "abstract": "Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems."
  },
  {
    "date": "2026-01-26",
    "title": "Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data",
    "authors": "Willem Diepeveen, Oscar Leong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18728v1",
    "source": "arXiv",
    "abstract": "Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST."
  },
  {
    "date": "2026-01-26",
    "title": "There is no Definable Grauert Direct Image Theorem",
    "authors": "Hélène Esnault, Moritz Kerz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18711v1",
    "source": "arXiv",
    "abstract": "We prove the claim in the title by showing that a definable Grauert Direct Image Theorem in o-minimal geometry would imply a weak representability-like property of the definable Picard functor. However, this weak representability cannot hold because of the Definable Chow Theorem of Peterzil and Starchenko."
  },
  {
    "date": "2026-01-26",
    "title": "Weight modules for quantum symmetric pair subalgebras",
    "authors": "Catharina Stroppel, Liao Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18709v1",
    "source": "arXiv",
    "abstract": "We develop a theory of weights for a quantum analogue of the symmetric pair (gl4,gl2 x gl2) realised as a quantum symmetric pair subalgebra. Based on Letzter's triangular decomposition we define Verma modules. Using magical operators that are compatible with weight spaces, we classify weight Verma modules and characterise their irreducible finite dimensional quotients. We then prove the existence of weight bases in tensor products by explicitly constructing some highest weight vectors. These constructions allow us to mimic the important aspects of the classical finite dimensional representation theory. Applications include a definition of rational representations, the BGG resolution, a Clebsch--Gordan formula, the Harish-Chandra isomorphism and central characters, as well as a classification and description of all irreducible polynomial representations."
  },
  {
    "date": "2026-01-26",
    "title": "Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge",
    "authors": "Xiao Liu, Jiawei Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18698v1",
    "source": "arXiv",
    "abstract": "Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve."
  },
  {
    "date": "2026-01-26",
    "title": "Bridging Instead of Replacing Online Coding Communities with AI through Community-Enriched Chatbot Designs",
    "authors": "Junling Wang, Lahari Goswami, Gustavo Kreia Umbelino, Kiara Garcia Chau, Mrinmaya Sachan, April Yi Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18697v1",
    "source": "arXiv",
    "abstract": "LLM-based chatbots like ChatGPT have become popular tools for assisting with coding tasks. However, they often produce isolated responses and lack mechanisms for social learning or contextual grounding. In contrast, online coding communities like Kaggle offer socially mediated learning environments that foster critical thinking, engagement, and a sense of belonging. Yet, growing reliance on LLMs risks diminishing participation in these communities and weakening their collaborative value. To address this, we propose Community-Enriched AI, a design paradigm that embeds social learning dynamics into LLM-based chatbots by surfacing user-generated content and social design feature from online coding communities. Using this paradigm, we implemented a RAG-based AI chatbot leveraging resources from Kaggle to validate our design. Across two empirical studies involving 28 and 12 data science learners, respectively, we found that Community-Enriched AI significantly enhances user trust, encourages engagement with community, and effectively supports learners in solving data science tasks. We conclude by discussing design implications for AI assistance systems that bridge -- rather than replace -- online coding communities."
  },
  {
    "date": "2026-01-26",
    "title": "Explainability Methods for Hardware Trojan Detection: A Systematic Comparison",
    "authors": "Paul Whitten, Francis Wolff, Chris Papachristou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18696v1",
    "source": "arXiv",
    "abstract": "Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient). Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like \"high fanin complexity near outputs indicates potential triggers.\" Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation. XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights. This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions."
  },
  {
    "date": "2026-01-26",
    "title": "Intracluster light as a dark matter tracer: how their spatial and kinematic relationship is shaped by satellite demographics",
    "authors": "G Martin, F R Pearce, N A Hatch, H J Brown, J Butler, Y M Bahe, W Cui, Y Dubois, A Knebe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18693v1",
    "source": "arXiv",
    "abstract": "We investigate how the orbital evolution and mass distribution of infalling satellite galaxies shape the phase-space and radial distributions of intracluster light (ICL) relative to the underlying cluster dark matter (DM) halo. Using N-body simulations, we follow the tidal stripping and orbital evolution of satellite galaxies as they are accreted into a live cluster halo, systematically varying satellite-to-host mass ratio and orbital circularity. We measure the specific orbital energy and angular momentum of stripped stellar and DM material, finding that the stripped stars consistently occupy lower-energy and lower-angular momentum regions of phase-space than the stripped DM. The magnitude of this difference increases strongly towards more equal satellite--to--host mass ratios, while the dependence on orbital circularity is weak. We construct a predictive model for the phase-space properties of stripped stars and DM from a whole infalling satellite population and find that the resulting phase-space difference between the components are driven primarily by the characteristic mass of the infalling satellite stellar mass function. We find that the ICL is always more centrally concentrated than the DM. The magnitude of this offset depends on the characteristic mass and increases towards higher characteristic masses. Comparisons with four independent cosmological hydrodynamical simulations show that, once the infalling satellite stellar mass function is matched, the model reproduces the radial stellar-to-DM density profile offsets to better than the inter-simulation scatter. This demonstrates that the radial relationship between the ICL and the DM distribution is largely governed by satellite demographics. With adequate constraints on the infalling satellite population, ICL density profiles can therefore be used as informative tracers of the underlying radial DM distribution in clusters."
  },
  {
    "date": "2026-01-26",
    "title": "AI-Driven Fuzzing for Vulnerability Assessment of 5G Traffic Steering Algorithms",
    "authors": "Seyed Bagher Hashemi Natanzi, Hossein Mohammadi, Bo Tang, Vuk Marojevic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18690v1",
    "source": "arXiv",
    "abstract": "Traffic Steering (TS) dynamically allocates user traffic across cells to enhance Quality of Experience (QoE), load balance, and spectrum efficiency in 5G networks. However, TS algorithms remain vulnerable to adversarial conditions such as interference spikes, handover storms, and localized outages. To address this, an AI-driven fuzz testing framework based on the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) is proposed to systematically expose hidden vulnerabilities. Using NVIDIA Sionna, five TS algorithms are evaluated across six scenarios. Results show that AI-driven fuzzing detects 34.3% more total vulnerabilities and 5.8% more critical failures than traditional testing, achieving superior diversity and edge-case discovery. The observed variance in critical failure detection underscores the stochastic nature of rare vulnerabilities. These findings demonstrate that AI-driven fuzzing offers an effective and scalable validation approach for improving TS algorithm robustness and ensuring resilient 6G-ready networks."
  },
  {
    "date": "2026-01-26",
    "title": "First observation of multi-phonon $γ$-vibrations in an odd-odd nuclear system",
    "authors": "E. H. Wang, M. Abushawish, J. H. Hamilton, A. Navin, S. Bhattacharyya, J. Dudouet, G. H. Bhat, J. A. Sheikh, S. Jehangir, S. Y. Wang, S. Sun, B. Qi, M. Rejmund, A. Lemasson, Y. H. Kim, E. Clement, F. Didierjean, R. Y. Dong, G. Duchene, B. Jacquot, C. F. Jiao, Y. X. Luo, C. Michelagnoli, A. V. Ramayya, J. O. Rasmussen, C. Schmitt, O. Stezowski, W. Z. Xu, H. Zhang, S. J. Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18688v1",
    "source": "arXiv",
    "abstract": "The identification of the first multi-phonon $γ$-vibrational bands in an odd-odd neutron-rich nucleus of the nuclear chart is presented. These high spin structures of hard to access $^{104}_{41}$Nb$_{63}$, produced in fission, were studied by combining a spectrometer with isotopic resolution coupled to a $γ$-ray tracking array and independently high-fold $γ$ coincidence measurements. Triaxial Projected Shell Model calculations for the high-spin states are in good agreement with the measured observables for the yrast, one-phonon and two-phonon $γ$ bands. The possibility of an oblate shape of an isomeric state and coexistence of triaxial and oblate configurations are investigated from the decay of the 141 keV isomer. The present work illustrates the robustness of vibration excitations in the presence of odd valence proton and neutron as well as the possibly coexisting shapes beyond the $N=60$ transitional region."
  },
  {
    "date": "2026-01-26",
    "title": "An Explicit Entire Function of Order One with All Zeros on a Line and Bounded in a Half-Plane",
    "authors": "Ralph Furmaniak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18687v1",
    "source": "arXiv",
    "abstract": "We construct a single explicit entire function $Ξ_c(s)$ of order 1, with all zeros provably on $Re(s) = 1/2$, satisfying a functional equation $Ξ_c(s) = Ξ_c(1-s)$, whose normalized form $Z_c(s) = Ξ_c(s)/[\\tfrac{1}{2}s(s-1)π^{-s/2}Γ(s/2)]$ is uniformly bounded for $Re(s) > 1 + δ$ yet satisfies $\\sup_t|Z_c(1+it)| = +\\infty$. The function thus satisfies an analogue of the Riemann Hypothesis together with the sharp bounded/unbounded transition at $σ= 1$ characteristic of $ζ$. The construction uses Hadamard products with controlled zero perturbations; the transition is proved unconditionally via a dyadic large-sieve argument and a Phragmén-Lindelöf transfer."
  },
  {
    "date": "2026-01-26",
    "title": "Learned harmonic mean estimation of the marginal likelihood for multimodal posteriors with flow matching",
    "authors": "Alicja Polanska, Jason D. McEwen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18683v1",
    "source": "arXiv",
    "abstract": "The marginal likelihood, or Bayesian evidence, is a crucial quantity for Bayesian model comparison but its computation can be challenging for complex models, even in parameters space of moderate dimension. The learned harmonic mean estimator has been shown to provide accurate and robust estimates of the marginal likelihood simply using posterior samples. It is agnostic to the sampling strategy, meaning that the samples can be obtained using any method. This enables marginal likelihood calculation and model comparison with whatever sampling is most suitable for the task. However, the internal density estimators considered previously for the learned harmonic mean can struggle with highly multimodal posteriors. In this work we introduce flow matching-based continuous normalizing flows as a powerful architecture for the internal density estimation of the learned harmonic mean. We demonstrate the ability to handle challenging multimodal posteriors, including an example in 20 parameter dimensions, showcasing the method's ability to handle complex posteriors without the need for fine-tuning or heuristic modifications to the base distribution."
  },
  {
    "date": "2026-01-26",
    "title": "Learning temporal embeddings from electronic health records of chronic kidney disease patients",
    "authors": "Aditya Kumar, Mario A. Cypko, Oliver Amft",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18675v1",
    "source": "arXiv",
    "abstract": "We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning."
  },
  {
    "date": "2026-01-26",
    "title": "Melting dynamics and mixing layer growth near the ice-ocean interface",
    "authors": "Sofía Allende, Louis-Alexandre Couston, Simon Thalabard, Benjamin Favier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18674v1",
    "source": "arXiv",
    "abstract": "Ice melting into saline water plays a fundamental role in the dynamics near the ice-ocean interface in polar oceans. The physics of ice melting involves a non-trivial interplay between thermodynamics at the interface, hydrodynamic transport in the bulk and the properties of the ambient ocean. The key control parameters are the density ratio $R_ρ$ proportional to the ambient ocean salinity and the Lewis number $Le = κ_T/κ_S$, which compares the thermal and salt diffusivities. Increasing the salinity is known to slow down melting, with the melt rate transitioning from subdiffusive to diffusive as $R_ρ$ increases. Here, we ssess the role of turbulence in this transition, using highly-resolved numerical simulations of the two-dimensional Boussinesq equations with a slowly melting upper boundary. We analyse the non-stationary growth of the temperature and meltwater mixing layers, varying the Lewis number and the density ratio. While meltwater is continuously entrained by convection inside the bulk, we identify a transition from convection to diffusion close to the interface. This transition is reflected by the formation of an interfacial boundary layer that regulates the flux of meltwater pouring into the turbulent bulk for $R_ρ\\gtrsim 10$. Using mixing-layer diagnostics based on meltwater-concentration thresholds, we observe that the turbulent layer grows super-diffusively $\\propto t^{1.33}$, while the interfacial boundary layer expands diffusively $\\propto t^{0.5}$ but with a non-universal prefactor. These results indicate that double-diffusive effects are here confined to the interface, and highlight potential limitations of diagnostics based on fixed concentration thresholds in oceanographic applications."
  },
  {
    "date": "2026-01-26",
    "title": "Uniform Computability of PAC Learning",
    "authors": "Vasco Brattka, Guillaume Chirache",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18663v1",
    "source": "arXiv",
    "abstract": "We study uniform computability properties of PAC learning using Weihrauch complexity. We focus on closed concept classes, which are either represented by positive, by negative or by full information. Among other results, we prove that proper PAC learning from positive information is equivalent to the limit operation on Baire space, whereas improper PAC learning from positive information is closely related to Weak Kőnig's Lemma and even equivalent to it, when we have some negative information about the admissible hypotheses. If arbitrary hypotheses are allowed, then improper PAC learning from positive information is still in a finitary DNC range, which implies that it is non-deterministically computable, but does not allow for probabilistic algorithms. These results can also be seen as a classification of the degree of constructivity of the Fundamental Theorem of Statistical Learning. All the aforementioned results hold if an upper bound of the VC dimension is provided as an additional input information. We also study the question of how these results are affected if the VC dimension is not given, but only promised to be finite or if concept classes are represented by negative or full information. Finally, we also classify the complexity of the VC dimension operation itself, which is a problem that is of independent interest. For positive or full information it turns out to be equivalent to the binary sorting problem, for negative information it is equivalent to the jump of sorting. This classification allows also conclusions regarding the Borel complexity of PAC learnability."
  },
  {
    "date": "2026-01-26",
    "title": "Contrasting Global and Patient-Specific Regression Models via a Neural Network Representation",
    "authors": "Max Behrens, Daiana Stolz, Eleni Papakonstantinou, Janis M. Nolde, Gabriele Bellerino, Angelika Rohde, Moritz Hess, Harald Binder",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18658v1",
    "source": "arXiv",
    "abstract": "When developing clinical prediction models, it can be challenging to balance between global models that are valid for all patients and personalized models tailored to individuals or potentially unknown subgroups. To aid such decisions, we propose a diagnostic tool for contrasting global regression models and patient-specific (local) regression models. The core utility of this tool is to identify where and for whom a global model may be inadequate. We focus on regression models and specifically suggest a localized regression approach that identifies regions in the predictor space where patients are not well represented by the global model. As localization becomes challenging when dealing with many predictors, we propose modeling in a dimension-reduced latent representation obtained from an autoencoder. Using such a neural network architecture for dimension reduction enables learning a latent representation simultaneously optimized for both good data reconstruction and for revealing local outcome-related associations suitable for robust localized regression. We illustrate the proposed approach with a clinical study involving patients with chronic obstructive pulmonary disease. Our findings indicate that the global model is adequate for most patients but that indeed specific subgroups benefit from personalized models. We also demonstrate how to map these subgroup models back to the original predictors, providing insight into why the global model falls short for these groups. Thus, the principal application and diagnostic yield of our tool is the identification and characterization of patients or subgroups whose outcome associations deviate from the global model."
  },
  {
    "date": "2026-01-26",
    "title": "A varying-coefficient model for characterizing duration-driven heterogeneity in flood-related health impacts",
    "authors": "Sarika Aggarwal, Phillip B. Nicol, Brent A. Coull, Rachel C. Nethery",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18656v1",
    "source": "arXiv",
    "abstract": "Previous work revealed associations between flood exposure and adverse health outcomes during and in the aftermath of flood events. Floods are highly heterogeneous events, largely owing to vast differences in flood durations, i.e., flash-floods versus slow-moving floods. However, little to no work has incorporated exposure duration into the modeling of flood-related health impacts or has investigated duration-driven effect heterogeneity. To address this gap, we propose an exposure duration varying coefficient modeling (EDVCM) framework for estimating exposure day-specific health effects of consecutive-day environmental exposures that vary in duration. We develop the EDVCM within an area-level self-matched study design to eliminate time-invariant confounding followed by conditional Poisson regression modeling for exposure effect estimation and adjustment of time-varying confounders. Using a Bayesian framework, we introduce duration- and exposure day-specific exposure coefficients within the conditional Poisson model and assign them a two-dimensional Gaussian process prior to allow for sharing of information across both duration and exposure day. This approach enables highly-resolved insights into duration-driven effect heterogeneity while ensuring model stability through information sharing. Through simulations, we demonstrate that the EDVCM out-performs conventional approaches in terms of both effect estimation and uncertainty quantification. We apply the EDVCM to nationwide, multi-decade Medicare claims data linked with high-resolution flood exposure measures to investigate duration-driven heterogeneity in flood effects on musculoskeletal system disease hospitalizations."
  },
  {
    "date": "2026-01-26",
    "title": "Quantum Rotation Diversity in Displaced Squeezed Binary Phase-Shift Keying",
    "authors": "Ioannis Krikidis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18655v1",
    "source": "arXiv",
    "abstract": "We propose a quantum rotation diversity (QRD) scheme for optical quantum communication using binary phase-shift-keying displaced squeezed states and homodyne detection over Gamma-Gamma turbulence channels. Consecutive temporal modes are coupled by a passive orthogonal rotation that redistributes the displacement amplitude between slots, yielding a diversity order of two under independent fading and joint maximum-likelihood detection. Analytical expressions for the symbol-error rate performance, along with asymptotic results for the diversity and coding gains, are derived. The optimal rotation angle and energy allocation between displacement and squeezing are obtained in closed form. Furthermore, we show that when both the displacement amplitude and the squeezing strength scale with the total photon number, an effective diversity order of four is achieved. Numerical results validate the analysis and demonstrate the super-diversity behaviour of the proposed QRD scheme."
  },
  {
    "date": "2026-01-26",
    "title": "FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning",
    "authors": "Liheng Yu, Zhe Zhao, Yuxuan Wang, Pengkun Wang, Binwu Wang, Yang Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18650v1",
    "source": "arXiv",
    "abstract": "Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten\". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \\textit{Heterogeneous Unlearning Deviation} and \\textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \\textbf{Supplementary Material}."
  },
  {
    "date": "2026-01-26",
    "title": "Digital Euro: Frequently Asked Questions Revisited",
    "authors": "Joe Cannataci, Benjamin Fehrensen, Mikolai Gütschow, Özgür Kesim, Bernd Lucke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18644v1",
    "source": "arXiv",
    "abstract": "The European Central Bank (ECB) is working on the \"digital euro\", an envisioned retail central bank digital currency for the Euro area. In this article, we take a closer look at the \"digital euro FAQ\", which provides answers to 26 frequently asked questions about the digital euro, and other published documents by the ECB on the topic. We question the provided answers based on our analysis of the current design in terms of privacy, technical feasibility, risks, costs and utility. In particular, we discuss the following key findings: (KF1) Central monitoring of all online digital euro transactions by the ECB threatens privacy even more than contemporary digital payment methods with segregated account databases. (KF2) The ECB's envisioned concept of a secure offline version of the digital euro offering full anonymity is in strong conflict with the actual history of hardware security breaches and mathematical evidence against it. (KF3) The legal and financial liabilities for the various parties involved remain unclear. (KF4) The design lacks well-specified economic incentives for operators as well as a discussion of its economic impact on merchants. (KF5) The ECB fails to identify tangible benefits the digital euro would create for society, in particular given that the online component of the proposed infrastructure mainly duplicates existing payment systems. (KF6) The design process has been exclusionary, with critical decisions being set in stone before public consultations. Alternative and open design ideas have not even been discussed by the ECB."
  },
  {
    "date": "2026-01-26",
    "title": "Constraint-Aware Discrete-Time PID Gain Optimization for Robotic Joint Control Under Actuator Saturation",
    "authors": "Ojasva Mishra, Xiaolong Wu, Min Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18639v1",
    "source": "arXiv",
    "abstract": "The precise regulation of rotary actuation is fundamental in autonomous robotics, yet practical PID loops deviate from continuous-time theory due to discrete-time execution, actuator saturation, and small delays and measurement imperfections. We present an implementation-aware analysis and tuning workflow for saturated discrete-time joint control. We (i) derive PI stability regions under Euler and exact zero-order-hold (ZOH) discretizations using the Jury criterion, (ii) evaluate a discrete back-calculation anti-windup realization under saturation-dominant regimes, and (iii) propose a hybrid-certified Bayesian optimization workflow that screens analytically unstable candidates and behaviorally unsafe transients while optimizing a robust IAE objective with soft penalties on overshoot and saturation duty. Baseline sweeps ($τ=1.0$~s, $Δt=0.01$~s, $u\\in[-10,10]$) quantify rise/settle trends for P/PI/PID. Under a randomized model family emulating uncertainty, delay, noise, quantization, and tighter saturation, robustness-oriented tuning improves median IAE from $0.843$ to $0.430$ while keeping median overshoot below $2\\%$. In simulation-only tuning, the certification screen rejects $11.6\\%$ of randomly sampled gains within bounds before full robust evaluation, improving sample efficiency without hardware experiments."
  },
  {
    "date": "2026-01-26",
    "title": "Universality of Many-body Projected Ensemble for Learning Quantum Data Distribution",
    "authors": "Quoc Hoan Tran, Koki Chinzei, Yasuhiro Endo, Hirotaka Oshima",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18637v1",
    "source": "arXiv",
    "abstract": "Generating quantum data by learning the underlying quantum distribution poses challenges in both theoretical and practical scenarios, yet it is a critical task for understanding quantum systems. A fundamental question in quantum machine learning (QML) is the universality of approximation: whether a parameterized QML model can approximate any quantum distribution. We address this question by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework, a method for quantum state design that uses a single many-body wave function to prepare random states. This demonstrates that MPE can approximate any distribution of pure states within a 1-Wasserstein distance error. This theorem provides a rigorous guarantee of universal expressivity, addressing key theoretical gaps in QML. For practicality, we propose an Incremental MPE variant with layer-wise training to improve the trainability. Numerical experiments on clustered quantum states and quantum chemistry datasets validate MPE's efficacy in learning complex quantum data distributions."
  },
  {
    "date": "2026-01-26",
    "title": "Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation",
    "authors": "Abeer Badawi, Md Tahmid Rahman Laskar, Elahe Rahimi, Sheri Grach, Lindsay Bertrand, Lames Danok, Frank Rudzicz, Jimmy Huang, Elham Dolatabadi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18630v1",
    "source": "arXiv",
    "abstract": "The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI."
  },
  {
    "date": "2026-01-26",
    "title": "CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search",
    "authors": "Zequn Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18625v1",
    "source": "arXiv",
    "abstract": "Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER."
  },
  {
    "date": "2026-01-26",
    "title": "Quantum gravitational stellar evolution beyond shell-crossing singularities",
    "authors": "Michał Bobula, Francesco Fazzini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18618v1",
    "source": "arXiv",
    "abstract": "Models of effective stellar collapse inspired by loop quantum gravity predict a bounce when the stellar energy density reaches the Planck scale, typically followed by the formation of shell-crossing singularities. This work aims to extend the spacetime beyond these singularities by employing a Hamiltonian formulation of the Darmois-Israel junction conditions, treating the singularity as a non-isolated thin dust shell. By construction, the shell's motion remains timelike throughout the entire evolution, regardless of the amount of initial stellar mass, and the induced metric on the shell remains continuous. The resulting stellar evolution produces an inter-universal wormhole, analogous to the simpler Oppenheimer-Snyder scenario. The proposed approach provides a general framework for any effective (or classical) theory of stellar collapse characterized by shell-crossing singularities."
  },
  {
    "date": "2026-01-26",
    "title": "Correspondence between quasinormal modes and grey-body factors of Schwarzschild--Tangherlini black holes",
    "authors": "Hyewon Han, Bogeun Gwak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18613v1",
    "source": "arXiv",
    "abstract": "We investigate the correspondence between the quasinormal modes and grey-body factors of Schwarzschild--Tangherlini black holes. The gravitational perturbations in higher-dimensional black holes can be classified into scalar, vector, and tensor types. Considering the dimension-dependent forms of their effective potentials, the correspondence was examined for each dimension and perturbation mode. The accurate quasinormal modes were computed by suitably adopting the continued fraction and integration-through-midpoints methods, depending on the structure of the singularity. The grey-body factor can be obtained through its correspondence with the quasinormal mode, and its accuracy was analyzed by calculating its difference from the numerically computed grey-body factor. The correspondence failed for $l=2$ scalar gravitational perturbations in $D\\ge7$ because the form of the potential is markedly different from that in four dimensions. The vector and tensor perturbation types exhibited good correspondence accuracies in all cases. The breakdown of the correspondence was rigorously demonstrated to stem from multiple potential barriers, and its applicability to each mode in higher dimensions was assessed."
  },
  {
    "date": "2026-01-26",
    "title": "Multimodal Privacy-Preserving Entity Resolution with Fully Homomorphic Encryption",
    "authors": "Susim Roy, Nalini Ratha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18612v1",
    "source": "arXiv",
    "abstract": "The canonical challenge of entity resolution within high-compliance sectors, where secure identity reconciliation is frequently confounded by significant data heterogeneity, including syntactic variations in personal identifiers, is a longstanding and complex problem. To this end, we introduce a novel multimodal framework operating with the voluminous data sets typical of government and financial institutions. Specifically, our methodology is designed to address the tripartite challenge of data volume, matching fidelity, and privacy. Consequently, the underlying plaintext of personally identifiable information remains computationally inaccessible throughout the matching lifecycle, empowering institutions to rigorously satisfy stringent regulatory mandates with cryptographic assurances of client confidentiality while achieving a demonstrably low equal error rate and maintaining computational tractability at scale."
  },
  {
    "date": "2026-01-26",
    "title": "PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression",
    "authors": "Fabian Fumagalli, R. Teal Witter, Christopher Musco",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18608v1",
    "source": "arXiv",
    "abstract": "Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets. In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent. Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic."
  },
  {
    "date": "2026-01-26",
    "title": "Goodness-of-Fit Checks for Joint Models",
    "authors": "Dimitris Rizopoulos, Jeremy M. G. Taylor, Isabella Kardys",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18598v1",
    "source": "arXiv",
    "abstract": "Joint models for longitudinal and time-to-event data are widely used in many disciplines. Nonetheless, existing model comparison criteria do not indicate whether a model adequately fits the data or which components may be misspecified. We introduce a Bayesian posterior predictive checks framework for assessing a joint model's fit to the longitudinal and survival processes and their association. The framework supports multiple settings, including existing subjects, new subjects with only covariates, dynamic prediction at intermediate follow-up times, and cross-validated assessment. For the longitudinal component, goodness-of-fit is assessed through the mean, variance, and correlation structure, while the survival component is evaluated using empirical cumulative distributions and probability integral transforms. The association between processes is examined using time-dependent concordance statistics. We apply these checks to the Bio-SHiFT heart failure study, and a simulation study demonstrates that they can identify model misspecification that standard information criteria fail to detect. The proposed methodology is implemented in the freely available R package JMbayes2."
  },
  {
    "date": "2026-01-26",
    "title": "On the top-dimensional $L^2$-Betti number of residually poly-$\\mathbb Z$ groups",
    "authors": "Sam P. Fisher, Pablo Sánchez-Peralta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18594v1",
    "source": "arXiv",
    "abstract": "Let $G$ be a residually poly-$\\mathbb Z$ group of finite type. We prove that $G$ admits a poly-$\\mathbb Z$ quotient with kernel $N$ satisfying $\\mathrm{cd}_{\\mathbb Q}(N) < \\mathbb{cd}_{\\mathbb Q}(G)$ if and only if the top-dimensional $L^2$-Betti number of $G$ vanishes."
  },
  {
    "date": "2026-01-26",
    "title": "Improvement of the Gilbert-Varshamov Bound for Linear Codes and Quantum Codes",
    "authors": "Chen Yuan, Ruiqi Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18590v1",
    "source": "arXiv",
    "abstract": "The Gilbert--Varshamov (GV) bound is a central benchmark in coding theory, establishing existential guarantees for error-correcting codes and serving as a baseline for both Hamming and quantum fault-tolerant information processing. Despite decades of effort, improving the GV bound is notoriously difficult, and known improvements often rely on technically heavy arguments and do not extend naturally to the quantum setting due to additional self-orthogonality constraints. In this work we develop a concise probabilistic method that yields an improvement over the classical GV bound for $q$-ary linear codes. For relative distance $δ=d/n<1-1/q$, we show that an $[n,k,d]_q$ linear code exists whenever $\\frac{q^{k}-1}{q-1}\\;<\\;\\frac{c_δ\\sqrt{n}\\, q^{n}}{\\mathrm{Vol}_q(n,d-1)}$, for positive constant $c_δ$ depending only on $δ$, where $\\mathrm{Vol}_q(n,d-1)$ denotes the volume of a $q$-ary Hamming ball. We further adapt this approach to the quantum setting by analyzing symplectic self-orthogonal structures. For $δ<1-1/q^2$, we obtain an improved quantum GV bound: there exists a $q$-ary quantum code $[[n,\\,n-k,\\,d]]$ provided that $\\frac{q^{2n-k}-1}{q-1}<\\frac{c_δ\\sqrt{n}\\cdot q^{2n}}{\\sum_{i=0}^{d-1}\\binom{n}{i}(q^2-1)^i}$. In particular, our result improves the standard quantum GV bound by an $Ω(\\sqrt{n})$ multiplicative factor."
  },
  {
    "date": "2026-01-26",
    "title": "Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs",
    "authors": "Xianzhe Meng, Qiangsheng Zeng, Ling Luo, Qinghan Yang, Jiarui Hao, Wenbo Wu, Qinyu Wang, Rui Yin, Lin Qi, Renzhi Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18588v1",
    "source": "arXiv",
    "abstract": "Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality."
  },
  {
    "date": "2026-01-26",
    "title": "Vaccine Efficacy Estimands Implied by Common Estimators Used in Individual Randomized Field Trials",
    "authors": "Michael P. Fay, Dean Follmann, Bruce J. Swihart, Lauren E. Dang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18587v1",
    "source": "arXiv",
    "abstract": "We review vaccine efficacy (VE) estimands for susceptibility in individual randomized trials with natural (unmeasured) exposure, where individual responses are measured as time from vaccination until an event (e.g., disease from the infectious agent). Common VE estimands are written as $1-θ$, where $θ$ is some ratio effect measure (e.g., ratio of incidence rates, cumulative incidences, hazards, or odds) comparing outcomes under vaccination versus control. Although the ratio effects are approximately equal with low control event rates, we explore the quality of that approximation using a nonparametric formulation. Traditionally, the primary endpoint VE estimands are full immunization (or biological) estimands that represent a subset of the intent-to-treat population, excluding those that have the event before the vaccine has been able to ramp-up to its full effect, requiring care for proper causal interpretation. Besides these primary VE estimands that summarize an effect of the vaccine over the full course of the study, we also consider local VE estimands that measure the effect at particular time points. We discuss interpretational difficulties of local VE estimands (e.g., depletion of susceptibles bias), and using frailty models as sensitivity analyses for the individual-level causal effects over time."
  },
  {
    "date": "2026-01-26",
    "title": "GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization",
    "authors": "Chenxi Liu, Selena Ling, Alec Jacobson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18585v1",
    "source": "arXiv",
    "abstract": "Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions."
  },
  {
    "date": "2026-01-26",
    "title": "Boundary condition for phonon distribution functions at a smooth crystal interface and interfacial angular momentum transfer",
    "authors": "Yuta Suzuki, Shuntaro Sumita, Yusuke Kato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18584v1",
    "source": "arXiv",
    "abstract": "We theoretically elucidate the boundary conditions for phonon distribution functions of long-wavelength acoustic phonons at smooth crystal interfaces. We first derive boundary conditions that fully incorporate reflection, transmission, and mode conversion. We obtain these conditions for phonons from those for classical lattice vibrations, using the correspondence between the quantum and classical descriptions. This formulation provides a theoretical foundation for the acoustic mismatch model, widely used to analyze Kapitza resistance. We then refine the boundary conditions to include spatial dependence parallel to the interface. The refined form captures transverse shifts of elastic wave packets, analogous to the optical Imbert--Fedorov shift, and ensures conservation of total angular momentum. Consequently, circularly polarized phonons carrying spin angular momentum (SAM) generate phonon orbital angular momentum (OAM) at the interface. We analytically determine the spatial profile of this OAM and demonstrate that SAM and OAM are both involved in the interfacial diffusion of chiral phonons. Our theory provides concise boundary conditions for phonons, with applications ranging from heat transport to phonon angular momentum transport."
  },
  {
    "date": "2026-01-26",
    "title": "Moving sample method for solving time-dependent partial differential equations",
    "authors": "Beining Xu, Haijun Yu, Jiayu Zhai, Kejun Tang, Xiaoliang Wan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18575v1",
    "source": "arXiv",
    "abstract": "Solving time-dependent partial differential equations (PDEs) that exhibit sharp gradients or local singularities is computationally demanding, as traditional physics-informed neural networks (PINNs) often suffer from inefficient point allocation that wastes resources on regions already well-resolved. This paper presents an adaptive sampling framework for PINNs aimed at efficiently solving time-dependent partial differential equations with pronounced local singularities. The method employs a residual-driven strategy, where the spatial-temporal distribution of training points is iteratively updated according to the error field from the previous iteration. This targeted allocation enables the network to concentrate computational effort on regions with significant residuals, achieving higher accuracy with fewer sampling points compared to uniform sampling. Numerical experiments on representative PDE benchmarks demonstrate that the proposed approach improves solution quality."
  },
  {
    "date": "2026-01-26",
    "title": "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability",
    "authors": "Shobhita Sundaram, John Quan, Ariel Kwiatkowski, Kartik Ahuja, Yann Ollivier, Julia Kempe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18778v1",
    "source": "arXiv",
    "abstract": "Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data."
  },
  {
    "date": "2026-01-26",
    "title": "Sparse QUBO Formulation for Efficient Embedding via Network-Based Decomposition of Equality and Inequality Constraints",
    "authors": "Kohei Suda, Soshun Naito, Yoshihiko Hasegawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18108v1",
    "source": "arXiv",
    "abstract": "Quantum annealing is a promising approach for solving combinatorial optimization problems. However, its performance is often limited by the overhead of additional qubits required for embedding logical QUBO models onto quantum annealers. This overhead becomes severe when logical QUBO models have dense connectivity. Such dense structures frequently arise when formulating equality and inequality constraints. To address this issue, we propose a method to construct a significantly sparser logical QUBO model for these constraints. By adding auxiliary variables based on specific network structures, our approach decomposes the original constraint into smaller, more manageable constraints. We demonstrate that this method reduces the number of edges (quadratic terms) from $O(N^2)$ to $O(N)$ for the one-hot constraint and to $O(N\\log N)$ in the worst case for general equality constraints, where $N$ is the number of variables. Experimental results on D-Wave's hardware show that our formulation leads to substantial reductions in the number of qubits required for embedding, shorter average chain lengths, lower chain break rates, and higher feasible solution rates compared to conventional methods. This work provides a practical tool for efficiently solving constrained optimization problems on current and future quantum annealers."
  },
  {
    "date": "2026-01-26",
    "title": "Cross-Domain Transfer with Self-Supervised Spectral-Spatial Modeling for Hyperspectral Image Classification",
    "authors": "Jianshu Chao, Tianhua Lv, Qiqiong Ma, Yunfei Qiu, Li Fang, Huifang Shen, Wei Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18088v1",
    "source": "arXiv",
    "abstract": "Self-supervised learning has demonstrated considerable potential in hyperspectral representation, yet its application in cross-domain transfer scenarios remains under-explored. Existing methods, however, still rely on source domain annotations and are susceptible to distribution shifts, leading to degraded generalization performance in the target domain. To address this, this paper proposes a self-supervised cross-domain transfer framework that learns transferable spectral-spatial joint representations without source labels and achieves efficient adaptation under few samples in the target domain. During the self-supervised pre-training phase, a Spatial-Spectral Transformer (S2Former) module is designed. It adopts a dual-branch spatial-spectral transformer and introduces a bidirectional cross-attention mechanism to achieve spectral-spatial collaborative modeling: the spatial branch enhances structural awareness through random masking, while the spectral branch captures fine-grained differences. Both branches mutually guide each other to improve semantic consistency. We further propose a Frequency Domain Constraint (FDC) to maintain frequency-domain consistency through real Fast Fourier Transform (rFFT) and high-frequency magnitude loss, thereby enhancing the model's capability to discern fine details and boundaries. During the fine-tuning phase, we introduce a Diffusion-Aligned Fine-tuning (DAFT) distillation mechanism. This aligns semantic evolution trajectories through a teacher-student structure, enabling robust transfer learning under low-label conditions. Experimental results demonstrate stable classification performance and strong cross-domain adaptability across four hyperspectral datasets, validating the method's effectiveness under resource-constrained conditions."
  },
  {
    "date": "2026-01-26",
    "title": "Area-minimizing capillary cones",
    "authors": "Benjy Firester, Raphael Tsiamis, Yipeng Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18794v1",
    "source": "arXiv",
    "abstract": "We construct non-flat minimal capillary cones with bi-orthogonal symmetry groups for any dimension and contact angle. These cones interpolate between rescalings of a singular solution to the one-phase problem and the free-boundary cone obtained by halving a Lawson cone along a hyperplane of symmetry. The existence and uniqueness of such cones is proved by solving a nonlinear free boundary equation parametrized by the contact angle and obtaining monotonicity properties for the solutions. The constructed cones are minimizing in ambient dimension $8$ or higher, for appropriate contact angles, demonstrating that the regularity theory for minimizing capillary hypersurfaces can have singularities in codimension $7$ and completing the capillary regularity theory for contact angles near $π/2$. We further develop the connection between capillary hypersurfaces and solutions of the one-phase problem, consequently producing new examples of singular minimizing free boundaries for the Alt-Caffarelli functional."
  },
  {
    "date": "2026-01-26",
    "title": "Sampling Sphere Packings with Continuum Glauber Dynamics",
    "authors": "Aiya Kuchukova, Santosh Vempala, Daniel J. Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18748v1",
    "source": "arXiv",
    "abstract": "We establish a spectral gap for Continuum Glauber dynamics on the hard sphere model assuming strong spatial mixing, thereby extending the range of parameters in which Continuum Glauber is provably rapidly mixing. To do this, we introduce continuous extensions of spectral independence and negative fields localization. Our techniques apply to general Gibbs point processes with finite-range repulsive pair potentials. As a corollary, we improve the threshold up to which packings of a fixed number of spheres can be sampled from a bounded domain."
  },
  {
    "date": "2026-01-26",
    "title": "Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents",
    "authors": "Zhihan Liu, Lin Guan, Yixin Nie, Kai Zhang, Zhuoqun Hao, Lin Chen, Asli Celikyilmaz, Zhaoran Wang, Na Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18217v1",
    "source": "arXiv",
    "abstract": "Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization."
  },
  {
    "date": "2026-01-26",
    "title": "Holography with an Inner Boundary: A Smooth Horizon as a Sum over Horizonless States",
    "authors": "Chethan Krishnan, Pradipta S. Pathak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18775v1",
    "source": "arXiv",
    "abstract": "The (holomorphic) partition function of the Euclidean BTZ black hole with boundary modulus $τ$, is the $S$-image of the Virasoro vacuum character, $χ_{\\rm vac}(-1/τ)$. This object decomposes into primaries via the modular $S$-kernel: $χ_{\\rm vac}\\left(-\\frac{1}τ\\right)=\\int_{0}^{\\infty} dP S_{0P}(P,c)χ_P(τ)$. In this paper, we provide a bulk understanding of this spectral resolution using the Chern-Simons formulation of AdS$_3$ gravity with $two$ boundaries: an asymptotic torus and an excised Wilson line at the origin (\"stretched horizon\"). At infinity, we impose standard AdS$_3$ Drinfel'd-Sokolov (DS) gauge to obtain the Alekseev-Shatashvili (AS) boundary action for a coadjoint orbit. At the inner boundary, removing the Wilson line prepares the state at the cut as a sum over orbits of the $spatial$ cycle. Re-inserting a spatial holonomy Wilson line acts as a delta-function projector onto the corresponding primary, which together with boundary gravitons, reproduces the Virasoro character (e.g., of a conical defect). But we can also consider projectors onto the $conjugate$ basis $\\tilde P$, of the dual cycle. A key observation is that this leads to $S$-kernels instead of delta functions, with the BTZ character arising when the dual cycle label is in the exceptional orbit. Our two-boundary construction provides a bulk understanding of BTZ entropy: holonomy zero modes at the horizon have an effective central charge $c_{\\rm prim}=c-1$ from the kernel measure (primaries), while the universal Dedekind-$η$ in $χ_P(τ)$ contributes $c_{\\rm desc}=1$ from boundary gravitons (descendants). Together, they reproduce the full Cardy entropy. While our methods are specific to AdS$_3$/CFT$_2$, they are an explicit illustration that smoothness of the (Euclidean) horizon may emerge from a $sum$ over bulk states which are manifestly unsmooth."
  },
  {
    "date": "2026-01-26",
    "title": "Saturation numbers for $3$-uniform Berge-$K_4$",
    "authors": "Yihan Chen, Jialin He, Tianying Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18455v1",
    "source": "arXiv",
    "abstract": "The saturation number $\\text{sat}_r(n,\\mathcal{F})$ is the minimum number of hyperedges in an $r$-uniform $\\mathcal{F}$-saturated hypergraph on $n$ vertices. We determine this parameter for $3$-uniform Berge-$K_4$ hypergraphs, proving that $\\text{sat}_3(n,\\text{Berge-}K_4)=n$ for $n =5,7,8$ and $n\\ge 96$, while $\\text{sat}_3(6,\\text{Berge-}K_4)=5$. This resolves a problem posed by English, Kritschgau, Nahvi, and Sprangel~\\cite{EKNS2024} for large $n.$ Using a computer search, we classify all extremal hypergraphs for $5\\le n\\le 8.$ For $n\\geq 96$, we further show the existence of many non-isomorphic extremal families. Our approach synthesizes structural insights with computational power."
  },
  {
    "date": "2026-01-26",
    "title": "Data-Driven Qubit Characterization and Optimal Control using Deep Learning",
    "authors": "Paul Surrey, Julian D. Teske, Tobias Hangleiter, Hendrik Bluhm, Pascal Cerfontaine",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18704v1",
    "source": "arXiv",
    "abstract": "Quantum computing requires the optimization of control pulses to achieve high-fidelity quantum gates. We propose a machine learning-based protocol to address the challenges of evaluating gradients and modeling complex system dynamics. By training a recurrent neural network (RNN) to predict qubit behavior, our approach enables efficient gradient-based pulse optimization without the need for a detailed system model. First, we sample qubit dynamics using random control pulses with weak prior assumptions. We then train the RNN on the system's observed responses, and use the trained model to optimize high-fidelity control pulses. We demonstrate the effectiveness of this approach through simulations on a single $ST_0$ qubit."
  },
  {
    "date": "2026-01-26",
    "title": "Global Optimization of Atomic Clusters via Physically-Constrained Tensor Train Decomposition",
    "authors": "Konstantin Sozykin, Nikita Rybin, Andrei Chertkov, Anh-Huy Phan, Ivan Oseledets, Alexander Shapeev, Ivan Novikov, Gleb Ryzhakov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18592v1",
    "source": "arXiv",
    "abstract": "The global optimization of atomic clusters represents a fundamental challenge in computational chemistry and materials science due to the exponential growth of local minima with system size (i.e., the curse of dimensionality). We introduce a novel framework that overcomes this limitation by exploiting the low-rank structure of potential energy surfaces through Tensor Train (TT) decomposition. Our approach combines two complementary TT-based strategies: the algebraic TTOpt method, which utilizes maximum volume sampling, and the probabilistic PROTES method, which employs generative sampling. A key innovation is the development of physically-constrained encoding schemes that incorporate molecular constraints directly into the discretization process. We demonstrate the efficacy of our method by identifying global minima of Lennard-Jones clusters containing up to 45 atoms. Furthermore, we establish its practical applicability to real-world systems by optimizing 20-atom carbon clusters using a machine-learned Moment Tensor Potential, achieving geometries consistent with quantum-accurate simulations. This work establishes TT-decomposition as a powerful tool for molecular structure prediction and provides a general framework adaptable to a wide range of high-dimensional optimization problems in computational material science."
  },
  {
    "date": "2026-01-26",
    "title": "Emergent Cooperation in Quantum Multi-Agent Reinforcement Learning Using Communication",
    "authors": "Michael Kölle, Christian Reff, Leo Sünkel, Julian Hager, Gerhard Stenzel, Claudia Linnhoff-Popien",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18419v1",
    "source": "arXiv",
    "abstract": "Emergent cooperation in classical Multi-Agent Reinforcement Learning has gained significant attention, particularly in the context of Sequential Social Dilemmas (SSDs). While classical reinforcement learning approaches have demonstrated capability for emergent cooperation, research on extending these methods to Quantum Multi-Agent Reinforcement Learning remains limited, particularly through communication. In this paper, we apply communication approaches to quantum Q-Learning agents: the Mutual Acknowledgment Token Exchange (MATE) protocol, its extension Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange (MEDIATE), the peer rewarding mechanism Gifting, and Reinforced Inter-Agent Learning (RIAL). We evaluate these approaches in three SSDs: the Iterated Prisoner's Dilemma, Iterated Stag Hunt, and Iterated Game of Chicken. Our experimental results show that approaches using MATE with temporal-difference measure (MATE\\textsubscript{TD}), AutoMATE, MEDIATE-I, and MEDIATE-S achieved high cooperation levels across all dilemmas, demonstrating that communication is a viable mechanism for fostering emergent cooperation in Quantum Multi-Agent Reinforcement Learning."
  },
  {
    "date": "2026-01-26",
    "title": "Beyond the Checkbox: Strengthening DSA Compliance Through Social Media Algorithmic Auditing",
    "authors": "Sara Solarova, Matúš Mesarčík, Branislav Pecher, Ivan Srba",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18405v1",
    "source": "arXiv",
    "abstract": "Algorithms of online platforms are required under the Digital Services Act (DSA) to comply with specific obligations concerning algorithmic transparency, user protection and privacy. To verify compliance with these requirements, DSA mandates platforms to undergo independent audits. Little is known about current auditing practices and their effectiveness in ensuring such compliance. To this end, we bridge regulatory and technical perspectives by critically examining selected audit reports across three critical algorithmic-related provisions: restrictions on profiling minors, transparency in recommender systems, and limitations on targeted advertising using sensitive data. Our analysis shows significant inconsistencies in methodologies and lack of technical depth when evaluating AI-powered systems. To enhance the depth, scale, and independence of compliance assessments, we propose to employ algorithmic auditing -- a process of behavioural assessment of AI algorithms by means of simulating user behaviour, observing algorithm responses and analysing them for audited phenomena."
  },
  {
    "date": "2026-01-26",
    "title": "Novel five-dimensional rotating Lifshitz black holes with electric and axionic charges",
    "authors": "Moisés Bravo-Gaete, Jhony A. Herrera-Mendoza, Julio Oliva, Xiangdong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.18048v1",
    "source": "arXiv",
    "abstract": "In the present paper, we construct a new family of exact charged and rotating asymptotically Lifshitz black hole solutions in five dimensions. The spacetime solves Einstein equations coupled to a dilaton, two Abelian gauge fields, and axionic scalars supplemented by two generalized Chern-Simons terms. This configuration is characterized by a range of the free dynamical exponent $z$ and possesses nontrivial thermodynamical parameters, where we verify the first law of black hole thermodynamics and derive the corresponding Smarr relation. Motivated by applications to gauge/gravity duality, we then investigate a holographic superconductor in the rotating Lifshitz background. We study the condensation of the scalar operator and the AC conductivity of the dual system. These results show that increasing the rotation parameter suppresses the condensate and weakens the superconducting phase, while increasing the dynamical critical exponent enhances the superconducting order. To the best of our knowledge, the solutions presented here are the first to demonstrate five-dimensional rotating Lifshitz black holes supported by both electric and axionic charges. This opens up a new avenue to investigate non-relativistic holography beyond static backgrounds."
  },
  {
    "date": "2026-1-26",
    "title": "ACM Past, Present, Future",
    "authors": "Yannis Ioannidis",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736280",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "ARDiS: A Portable and Unified Resource Management Framework in Real Hardware Systems",
    "authors": "Mohammed Bakr Sikal, Jeferson Gonzalez-Gomez, Andreas Noebel, Heba Khdr, Joerg Henkel",
    "publish": "ACM Transactions on Design Automation of Electronic Systems",
    "url": "https://doi.org/10.1145/3793861",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Introduction to HPC Programming",
    "authors": "Bernd Mohr",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736282",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Thermal Attack on RO-PUFs: The Cases of Bulk 65 nm and FDSOI 28 nm",
    "authors": "Aghiles DOUADI, Elena-Ioana Vatajelu, Paolo Maistri, David Hely, Vincent Beroulle, Giorgio Di Natale",
    "publish": "ACM Transactions on Design Automation of Electronic Systems",
    "url": "https://doi.org/10.1145/3793848",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Confidential Computing on Heterogeneous CPU-GPU Systems: Survey and Future Directions",
    "authors": "Qifan Wang, David Oswald",
    "publish": "ACM Computing Surveys",
    "url": "https://doi.org/10.1145/3793532",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Towards an AI-Based Solution of Protein Structure Prediction Problem",
    "authors": "Zhang Yang",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736288",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Digital Twins for Cultural Heritage: A Systematic Analysis of the State of the Art",
    "authors": "Gizealew Dagnaw, Roberta Capuano, Henry Muccini",
    "publish": "ACM Computing Surveys",
    "url": "https://doi.org/10.1145/3793541",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Utilizing Telepresence Robots in Undergraduate Nursing Simulations",
    "authors": "Kathleen M. Huun, Linda Walters",
    "publish": "eLearn",
    "url": "https://doi.org/10.1145/3793231.3709362",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "AI Hands-On",
    "authors": "Mohamed Wahib",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736296",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Earth Observation Data Analysis Using Machine Learning",
    "authors": "Naoto Yokoya",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736290",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "RISC-V prototypes for HPC: Maturity and Methods",
    "authors": "Pablo Vizcaino",
    "publish": "Proceedings of the Conference on ACM Europe Summer School on HPC Computer Architectures for AI and Dedicated Applications",
    "url": "https://doi.org/10.1145/3789242.3789246",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "A Systematic Literature Review of Healthcare Embedded Systems Using AI-based Biosignal Analysis",
    "authors": "Sumair Aziz, Girija Chetty, Roland Goecke, Raul Fernandez-Rojas",
    "publish": "ACM Computing Surveys",
    "url": "https://doi.org/10.1145/3793669",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Proceedings of the Conference on ACM Europe Summer School on HPC Computer Architectures for AI and Dedicated Applications",
    "authors": "N/A",
    "publish": "N/A",
    "url": "https://doi.org/10.1145/3789242",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 3: Machine Memories",
    "authors": "AI Generated",
    "publish": "Proceedings of the SIGGRAPH Asia 2025 Art Papers",
    "url": "https://doi.org/10.1145/3757369.3793410",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "The Digital Revolution of Earth System Modelling",
    "authors": "Peter Dueben",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736303",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Distributed Data Analytics for AI in Supercomputing Systems",
    "authors": "Josep Lluís Berral",
    "publish": "Proceedings of the Conference on ACM Europe Summer School on HPC Computer Architectures for AI and Dedicated Applications",
    "url": "https://doi.org/10.1145/3789242.3789243",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 3: Short Papers",
    "authors": "AI Generated",
    "publish": "Proceedings of the 7th ACM International Conference on Multimedia in Asia",
    "url": "https://doi.org/10.1145/3743093.3788546",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Agent-Based Simulation for Earthquake Disaster Mitigation",
    "authors": "Maddegedara Lalith",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736300",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Diagnostic Studies of High-Resolution Global Climate Model",
    "authors": "Yoshiyuki Kajikawa",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736302",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Getting Started with ROCm/HIP and its Academic Resources",
    "authors": "Kerwin Tsai",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736299",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 2: Special Sessions Papers",
    "authors": "AI Generated",
    "publish": "Proceedings of the 7th ACM International Conference on Multimedia in Asia",
    "url": "https://doi.org/10.1145/3743093.3788547",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Parallel Programming with MPI and OpenMP Hands-on",
    "authors": "Bernd Mohr, Jens Domke",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736289",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 4: Reframing Vision",
    "authors": "AI Generated",
    "publish": "Proceedings of the SIGGRAPH Asia 2025 Art Papers",
    "url": "https://doi.org/10.1145/3757369.3793411",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Integration of 3D Earthquake Simulation &amp; Real-Time Data Assimilation",
    "authors": "Kengo Najajima",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736291",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "An Active Learning Framework for Analog Circuit Multi-objective Customization",
    "authors": "Mutian Zhu, Mohsen Hassanpourghadi, Qiaochu Zhang, Mike Shuo-Wei Chen, A.F.J. Levi, Sandeep Gupta",
    "publish": "ACM Transactions on Design Automation of Electronic Systems",
    "url": "https://doi.org/10.1145/3789263",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Climate Simulations",
    "authors": "Hirofumi Tomita",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736301",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Introduction to the Use of Fugaku",
    "authors": "Jorji Nonaka",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736277",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Hands-on for Scientific Benchmarking",
    "authors": "Jens Domke",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736297",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "From Viruses to Food and New Drugs, Next Generation AI Applications and High Performance Computing",
    "authors": "Raphael Lee Tze Chuen",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736295",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "BBR Congestion Control Algorithms: Evolution, Challenges and Future Directions",
    "authors": "Akshita Abrol, Purnima Murali Mohan, Tram Truong-Huu, Mohan Gurusamy",
    "publish": "ACM Computing Surveys",
    "url": "https://doi.org/10.1145/3793537",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "From Sequence to Function: Applications of Protein Language Models in Protein Design",
    "authors": "Camila Pontes",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736294",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Molecular Dynamics Simulations of Biomolecular Systems",
    "authors": "Chigusa Kobayashi",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736292",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "HPC and AI",
    "authors": "Satoshi Matsuoka",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736276",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "A deep dive into sustainable generative AI and HPC systems",
    "authors": "Andrea Bartolini",
    "publish": "Proceedings of the Conference on ACM Europe Summer School on HPC Computer Architectures for AI and Dedicated Applications",
    "url": "https://doi.org/10.1145/3789242.3789245",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "SCPL: Enhancing Neural Network Training Throughput with Decoupled Local Losses and Model Parallelism",
    "authors": "Ming-Yao Ho, Cheng-Kai Wang, You-Teng Lin, Hung-Hsuan Chen",
    "publish": "ACM Transactions on Management Information Systems",
    "url": "https://doi.org/10.1145/3793534",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Scientific Benchmarking",
    "authors": "Jens Domke",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736285",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Introduction to HPC Applications and Systems",
    "authors": "Bernd Mohr",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736281",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Solving 3D Puzzles of Biomolecular Interactions by Integrative Modelling: Part 1",
    "authors": "Alexandre Bonvin",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736286",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Turing Lecture: A Not So Simple Matter of Software",
    "authors": "Jack Dongarra",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736275",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "authors": "N/A",
    "publish": "N/A",
    "url": "https://doi.org/10.1145/3736273",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "AI Factories in the European HPC Ecosystem",
    "authors": "Kimmo Koski",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736279",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Building and Evolving a Multilingual LLM: From First Steps to Specialization",
    "authors": "Javier Aula-Blasco, Julia Falcao",
    "publish": "Proceedings of the Conference on ACM Europe Summer School on HPC Computer Architectures for AI and Dedicated Applications",
    "url": "https://doi.org/10.1145/3789242.3789244",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Quick Start to Quantum Computing: Programming Variational Algorithms with CUDA-Q",
    "authors": "Jin-Sung Kim, Yang Juntao",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736304",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "GAEDM: Genetic Algorithm-Enhanced Static Analysis for Detection of API Hashing Obfuscation in Malware",
    "authors": "Yang Lan, Hui Shu, Zihan Sha, Fei Kang, XiaoBing Xiong, JingJing Li",
    "publish": "ACM Transactions on Privacy and Security",
    "url": "https://doi.org/10.1145/3793198",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Proceedings of the 7th Joint Workshop on CPS&amp;IoT Security and Privacy",
    "authors": "AI Generated",
    "publish": "Proceedings of the 7th Joint Workshop on CPS&amp;amp IoT Security and Privacy",
    "url": "https://doi.org/10.1145/3733801.3793389",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Introduction to Performance Analysis and Optimization of HPC Applications",
    "authors": "Bernd Mohr",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736298",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 5: Doctoral Symposium",
    "authors": "AI Generated",
    "publish": "Proceedings of the 7th ACM International Conference on Multimedia in Asia",
    "url": "https://doi.org/10.1145/3743093.3788545",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "The Use of LLMs and Other AI Models in Science",
    "authors": "Mohamed Wahib",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736283",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Scalable Methods for Storing and Retrieving Wikipedia Revision Histories for Large-Scale Analysis",
    "authors": "Amit Verma, Simran Setia, Gianluca Demartini",
    "publish": "ACM Transactions on the Web",
    "url": "https://doi.org/10.1145/3787449",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Virtual Fugaku: Your own Fugaku on Cloud Service",
    "authors": "Yuji Iguchi",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736278",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Qilimanjaro Workshop: Practical Introduction to Quantum Computing",
    "authors": "Javier Sabariego, David Acros, Guillermo Abad López, Amir Azzam",
    "publish": "Proceedings of the Conference on ACM Europe Summer School on HPC Computer Architectures for AI and Dedicated Applications",
    "url": "https://doi.org/10.1145/3789242.3789248",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 5: Subversive Agencies",
    "authors": "AI Generated",
    "publish": "Proceedings of the SIGGRAPH Asia 2025 Art Papers",
    "url": "https://doi.org/10.1145/3757369.3793412",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 6: Demo Papers",
    "authors": "AI Generated",
    "publish": "Proceedings of the 7th ACM International Conference on Multimedia in Asia",
    "url": "https://doi.org/10.1145/3743093.3788544",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 2: Ecological Worlding",
    "authors": "AI Generated",
    "publish": "Proceedings of the SIGGRAPH Asia 2025 Art Papers",
    "url": "https://doi.org/10.1145/3757369.3793409",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Solving 3D Puzzles of Biomolecular Interactions by Integrative Modelling: Part 2",
    "authors": "Alexandre Bonvin",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736287",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "A Co-optimization Framework for Multi-layer Design Rule Constraints",
    "authors": "Guohao Chen, Chang Liu, Xingyu Tong, Peng Zou, Jianli Chen, Zhifeng Lin",
    "publish": "ACM Transactions on Design Automation of Electronic Systems",
    "url": "https://doi.org/10.1145/3789670",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Scaling up Computing Chip(lets) for the Generative AI Era",
    "authors": "Luca Benini",
    "publish": "Proceedings of the Conference on ACM Europe Summer School on HPC Computer Architectures for AI and Dedicated Applications",
    "url": "https://doi.org/10.1145/3789242.3789249",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 6: Mediated Data",
    "authors": "AI Generated",
    "publish": "Proceedings of the SIGGRAPH Asia 2025 Art Papers",
    "url": "https://doi.org/10.1145/3757369.3793413",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 4: Brave New Idea",
    "authors": "AI Generated",
    "publish": "Proceedings of the 7th ACM International Conference on Multimedia in Asia",
    "url": "https://doi.org/10.1145/3743093.3788543",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "MERINDA: Model Recovery in FPGA-Based Dynamic Architecture for Edge and Physical AI",
    "authors": "Bin Xu, Ayan Banerjee, Sandeep Gupta",
    "publish": "ACM Transactions on Design Automation of Electronic Systems",
    "url": "https://doi.org/10.1145/3793545",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Expedited development of novel RISC-V instructions through an emulation-simulation framework",
    "authors": "Ivan Vargas, Carlos Rojas Morales",
    "publish": "Proceedings of the Conference on ACM Europe Summer School on HPC Computer Architectures for AI and Dedicated Applications",
    "url": "https://doi.org/10.1145/3789242.3789247",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Session Summary Podcast: Session 1: Embodied Sensing",
    "authors": "AI Generated",
    "publish": "Proceedings of the SIGGRAPH Asia 2025 Art Papers",
    "url": "https://doi.org/10.1145/3757369.3793408",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Atomistic Simulations and Applications for Drug Design",
    "authors": "Chandra Verma",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736293",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "Opening of School",
    "authors": "Terence Hung",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736274",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-26",
    "title": "AI for Materials Discovery",
    "authors": "Kedar Hippalgaonkar",
    "publish": "ASEAN School on High-Performance Computing and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3736273.3736284",
    "source": "ACM",
    "abstract": "None"
  }
]