[
  {
    "date": "2026-02-03",
    "title": "Merging Beyond: Streaming LLM Updates via Activation-Guided Rotations",
    "authors": "Yuxuan Yao, Haonan Sheng, Qingsong Lv, Han Wu, Shuqi Liu, Zehua Liu, Zengyan Liu, Jiahui Gao, Haochen Tan, Xiaojin Fu, Haoli Bai, Hing Cheung So, Zhijiang Guo, Linqi Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03237v1",
    "source": "arXiv",
    "abstract": "The escalating scale of Large Language Models (LLMs) necessitates efficient adaptation techniques. Model merging has gained prominence for its efficiency and controllability. However, existing merging techniques typically serve as post-hoc refinements or focus on mitigating task interference, often failing to capture the dynamic optimization benefits of supervised fine-tuning (SFT). In this work, we propose Streaming Merging, an innovative model updating paradigm that conceptualizes merging as an iterative optimization process. Central to this paradigm is \\textbf{ARM} (\\textbf{A}ctivation-guided \\textbf{R}otation-aware \\textbf{M}erging), a strategy designed to approximate gradient descent dynamics. By treating merging coefficients as learning rates and deriving rotation vectors from activation subspaces, ARM effectively steers parameter updates along data-driven trajectories. Unlike conventional linear interpolation, ARM aligns semantic subspaces to preserve the geometric structure of high-dimensional parameter evolution. Remarkably, ARM requires only early SFT checkpoints and, through iterative merging, surpasses the fully converged SFT model. Experimental results across model scales (1.7B to 14B) and diverse domains (e.g., math, code) demonstrate that ARM can transcend converged checkpoints. Extensive experiments show that ARM provides a scalable and lightweight framework for efficient model adaptation.",
    "title_zh": "超越融合：通过激活引导的旋转实现LLM的流式更新",
    "abstract_zh": "大型语言模型（LLMs）规模的持续扩大，对高效适配技术提出了迫切需求。模型合并技术因其高效性和可控性而受到广泛关注。然而，现有的合并方法通常仅作为事后优化手段，或侧重于缓解任务干扰问题，往往无法捕捉到监督微调（SFT）过程中动态优化所带来的优势。本文提出了一种创新的模型更新范式——**流式合并**（Streaming Merging），将合并过程概念化为一个迭代优化过程。该范式的核心是**ARM**（**A**ctivation-guided **R**otation-aware **M**erging）策略，旨在近似梯度下降的动力学行为。通过将合并系数视为学习率，并从激活子空间中推导出旋转向量，ARM能够沿着数据驱动的轨迹有效引导参数更新。与传统的线性插值方法不同，ARM通过对齐语义子空间，保留了高维参数演化过程中的几何结构。令人瞩目的是，ARM仅需早期的SFT检查点即可运行，并通过迭代合并超越了完全收敛的SFT模型。在模型规模（1.7B至14B）和多样化领域（如数学、代码）上的实验结果表明，ARM能够突破已收敛检查点的性能瓶颈。大量实验证明，ARM为高效模型适配提供了一个可扩展且轻量级的框架。"
  },
  {
    "date": "2026-02-03",
    "title": "ProOPF: Benchmarking and Improving LLMs for Professional-Grade Power Systems Optimization Modeling",
    "authors": "Chao Shen, Zihan Guo, Xu Wan, Zhenghao Yang, Yifan Zhang, Wengi Huang, Jie Song, Zongyan Zhang, Mingyang Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03070v1",
    "source": "arXiv",
    "abstract": "Growing renewable penetration introduces substantial uncertainty into power system operations, necessitating frequent adaptation of dispatch objectives and constraints and challenging expertise-intensive, near-real-time modeling workflows. Large Language Models (LLMs) provide a promising avenue for automating this process by translating natural-language (NL) operational requirements into executable optimization models via semantic reasoning and code synthesis. Yet existing LLM datasets and benchmarks for optimization modeling primarily target coarse-grained cross-domain generalization, offering limited, rigorous evaluation in power-system settings, particularly for Optimal Power Flow (OPF). We therefore introduce \\textbf{ProOPF-D} and \\textbf{ProOPF-B}, a dataset and benchmark for professional-grade OPF modeling: ProOPF-D contains 12K instances pairing NL requests with parameter adjustments and structural extensions to a canonical OPF, together with executable implementations; ProOPF-B provides 121 expert-annotated test cases with ground-truth code, enabling end-to-end evaluation under both concrete and abstract OPF modeling regimes.",
    "title_zh": "ProOPF：面向专业级电力系统优化建模的大型语言模型基准测试与优化",
    "abstract_zh": "可再生能源渗透率的不断提高给电力系统运行带来了巨大的不确定性，导致调度目标与约束需频繁调整，对依赖专业知识、近实时建模的工作流程提出了严峻挑战。大型语言模型（LLMs）通过语义推理与代码生成，能够将自然语言（NL）操作需求转化为可执行的优化模型，为自动化这一过程提供了极具前景的解决方案。然而，现有的LLM数据集和基准测试主要面向粗粒度的跨领域泛化，对电力系统场景，特别是最优潮流（OPF）问题，缺乏充分且严谨的评估。为此，我们提出了**ProOPF-D**和**ProOPF-B**：一个面向专业级OPF建模的数据集与基准测试。ProOPF-D包含12,000个实例，将自然语言请求与对标准OPF模型的参数调整及结构扩展相匹配，并附有可执行的实现代码；ProOPF-B则提供了121个由专家标注的测试用例，配有真实代码作为基准，支持在具体与抽象OPF建模范式下进行端到端评估。"
  },
  {
    "date": "2026-02-03",
    "title": "Clarify Before You Draw: Proactive Agents for Robust Text-to-CAD Generation",
    "authors": "Bo Yuan, Zelin Zhao, Petr Molodyk, Bin Hu, Yongxin Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03045v1",
    "source": "arXiv",
    "abstract": "Large language models have recently enabled text-to-CAD systems that synthesize parametric CAD programs (e.g., CadQuery) from natural language prompts. In practice, however, geometric descriptions can be under-specified or internally inconsistent: critical dimensions may be missing and constraints may conflict. Existing fine-tuned models tend to reactively follow user instructions and hallucinate dimensions when the text is ambiguous. To address this, we propose a proactive agentic framework for text-to-CadQuery generation, named ProCAD, that resolves specification issues before code synthesis. Our framework pairs a proactive clarifying agent, which audits the prompt and asks targeted clarification questions only when necessary to produce a self-consistent specification, with a CAD coding agent that translates the specification into an executable CadQuery program. We fine-tune the coding agent on a curated high-quality text-to-CadQuery dataset and train the clarifying agent via agentic SFT on clarification trajectories. Experiments show that proactive clarification significantly improves robustness to ambiguous prompts while keeping interaction overhead low. ProCAD outperforms frontier closed-source models, including Claude Sonnet 4.5, reducing the mean Chamfer distance by 79.9 percent and lowering the invalidity ratio from 4.8 percent to 0.9 percent. Our code and datasets will be made publicly available.",
    "title_zh": "在绘制之前先澄清：用于鲁棒性文本到CAD生成的主动代理",
    "abstract_zh": "大型语言模型最近推动了文本到CAD系统的发展，这些系统能够从自然语言提示中生成参数化CAD程序（例如CadQuery）。然而，在实际应用中，几何描述往往存在信息不足或内部不一致的问题：关键尺寸可能缺失，约束条件之间可能存在冲突。现有的微调模型倾向于被动地遵循用户指令，在文本模糊时还会“幻觉”生成尺寸。为解决这一问题，我们提出了一种主动式的代理框架，用于文本到CadQuery的生成，命名为ProCAD。该框架结合了一个主动澄清代理，该代理会审查用户提示，并仅在必要时提出针对性的澄清问题，以确保生成的规格自洽；同时配备一个CAD编码代理，将经过验证的规格转化为可执行的CadQuery程序。我们基于一个精心筛选的高质量文本到CadQuery数据集对编码代理进行微调，并通过代理式监督微调（agentic SFT）在澄清轨迹上训练澄清代理。实验表明，主动澄清显著提升了模型对模糊提示的鲁棒性，同时保持了较低的交互开销。ProCAD的表现优于前沿的闭源模型，包括Claude Sonnet 4.5，将平均Chamfer距离降低了79.9%，并将无效代码比例从4.8%降至0.9%。我们的代码和数据集将公开发布。"
  },
  {
    "date": "2026-02-03",
    "title": "Efficient Algorithms for Partial Constraint Satisfaction Problems over Control-flow Graphs",
    "authors": "Xuran Cai, Amir Goharshady",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03588v1",
    "source": "arXiv",
    "abstract": "In this work, we focus on the Partial Constraint Satisfaction Problem (PCSP) over control-flow graphs (CFGs) of programs. PCSP serves as a generalization of the well-known Constraint Satisfaction Problem (CSP). In the CSP framework, we define a set of variables, a set of constraints, and a finite domain $D$ that encompasses all possible values for each variable. The objective is to assign a value to each variable in such a way that all constraints are satisfied. In the graph variant of CSP, an underlying graph is considered and we have one variable corresponding to each vertex of the graph and one or several constraints corresponding to each edge. In PCSPs, we allow for certain constraints to be violated at a specified cost, aiming to find a solution that minimizes the total cost. Numerous classical compiler optimization tasks can be framed as PCSPs over control-flow graphs. Examples include Register Allocation, Lifetime-optimal Speculative Partial Redundancy Elimination (LOSPRE), and Optimal Placement of Bank Selection Instructions. On the other hand, it is well-known that control-flow graphs of structured programs are sparse and decomposable in a variety of ways. In this work, we rely on the Series-Parallel-Loop (SPL) decompositions as introduced by~\\cite{RegisterAllocation}. Our main contribution is a general algorithm for PCSPs over SPL graphs with a time complexity of \\(O(|G| \\cdot |D|^6)\\), where \\(|G|\\) represents the size of the control-flow graph. Note that for any fixed domain $D,$ this yields a linear-time solution. Our algorithm can be seen as a generalization and unification of previous SPL-based approaches for register allocation and LOSPRE. In addition, we provide experimental results over another classical PCSP task, i.e. Optimal Bank Selection, achieving runtimes four times better than the previous state of the art.",
    "title_zh": "控制流图上部分约束满足问题的高效算法",
    "abstract_zh": "在本研究中，我们关注程序控制流图（CFG）上的部分约束满足问题（PCSP）。PCSP是众所周知的约束满足问题（CSP）的一种推广形式。在CSP框架中，我们定义一组变量、一组约束以及一个有限域 $D$，该域包含了每个变量的所有可能取值。目标是为每个变量分配一个值，使得所有约束均被满足。在CSP的图版本中，考虑一个基础图结构，图中的每个顶点对应一个变量，每条边对应一个或多个约束。而在PCSP中，允许某些约束以指定代价被违反，目标是寻找一个使总代价最小的解。许多经典的编译器优化任务都可以被建模为控制流图上的PCSP，例如寄存器分配、生命周期最优的推测性部分冗余消除（LOSPRE），以及银行选择指令的最优放置。另一方面，众所周知，结构化程序的控制流图具有稀疏性，并且可以通过多种方式分解。在本研究中，我们采用由~\\cite{RegisterAllocation} 提出的串联-并联-循环（SPL）分解方法。我们的主要贡献是一个针对SPL图上的PCSP的通用算法，其时间复杂度为 \\(O(|G| \\cdot |D|^6)\\)，其中 \\(|G|\\) 表示控制流图的大小。值得注意的是，对于任意固定的域 $D$，该算法可实现线性时间复杂度。我们的算法可被视为先前基于SPL的寄存器分配与LOSPRE方法的推广与统一。此外，我们在另一个经典PCSP任务——最优银行选择上进行了实验，结果表明其运行时间比此前最先进的方法快了四倍。"
  },
  {
    "date": "2026-02-03",
    "title": "Learning to Reason Faithfully through Step-Level Faithfulness Maximization",
    "authors": "Runquan Gui, Yafu Li, Xiaoye Qu, Ziyan Liu, Yeqiu Cheng, Yu Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03507v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has markedly improved the performance of Large Language Models (LLMs) on tasks requiring multi-step reasoning. However, most RLVR pipelines rely on sparse outcome-based rewards, providing little supervision over intermediate steps and thus encouraging over-confidence and spurious reasoning, which in turn increases hallucinations. To address this, we propose FaithRL, a general reinforcement learning framework that directly optimizes reasoning faithfulness. We formalize a faithfulness-maximization objective and theoretically show that optimizing it mitigates over-confidence. To instantiate this objective, we introduce a geometric reward design and a faithfulness-aware advantage modulation mechanism that assigns step-level credit by penalizing unsupported steps while preserving valid partial derivations. Across diverse backbones and benchmarks, FaithRL consistently reduces hallucination rates while maintaining (and often improving) answer correctness. Further analysis confirms that FaithRL increases step-wise reasoning faithfulness and generalizes robustly. Our code is available at https://github.com/aintdoin/FaithRL.",
    "title_zh": "通过逐步忠实性最大化来学习忠实地推理",
    "abstract_zh": "基于可验证奖励的强化学习（RLVR）显著提升了大型语言模型（LLMs）在需要多步推理任务上的表现。然而，大多数RLVR流程依赖稀疏的结果奖励，对中间推理步骤的监督极为有限，从而导致模型产生过度自信和虚假推理，进一步加剧了幻觉现象。为解决这一问题，我们提出FaithRL——一种通用的强化学习框架，直接优化推理过程的忠实性。我们形式化了一个最大化忠实性的目标函数，并从理论上证明了优化该目标可有效缓解过度自信问题。为实现这一目标，我们引入了一种几何奖励设计方法，以及一种考虑忠实性的优势调制机制，该机制通过惩罚缺乏支持的推理步骤，同时保留有效的部分推导过程，实现对每一步的精准信用分配。在多种模型架构和基准测试中，FaithRL均能持续降低幻觉率，同时保持（甚至提升）答案的正确性。进一步分析表明，FaithRL显著提高了推理步骤的忠实性，并展现出良好的泛化能力。我们的代码已开源，地址为：https://github.com/aintdoin/FaithRL。"
  },
  {
    "date": "2026-02-03",
    "title": "Reading Between the Code Lines: On the Use of Self-Admitted Technical Debt for Security Analysis",
    "authors": "Nicolás E. Díaz Ferreyra, Moritz Mock, Max Kretschmann, Barbara Russo, Mojtaba Shahin, Mansooreh Zahedi, Riccardo Scandariato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03470v1",
    "source": "arXiv",
    "abstract": "Static Analysis Tools (SATs) are central to security engineering activities, as they enable early identification of code weaknesses without requiring execution. However, their effectiveness is often limited by high false-positive rates and incomplete coverage of vulnerability classes. At the same time, developers frequently document security-related shortcuts and compromises as Self-Admitted Technical Debt (SATD) in software artifacts, such as code comments. While prior work has recognized SATD as a rich source of security information, it remains unclear whether -and in what ways- it is utilized during SAT-aided security analysis. OBJECTIVE: This work investigates the extent to which security-related SATD complements the output produced by SATs and helps bridge some of their well-known limitations. METHOD: We followed a mixed-methods approach consisting of (i) the analysis of a SATD-annotated vulnerability dataset using three state-of-the-art SATs and (ii) an online survey with 72 security practitioners. RESULTS: The combined use of all SATs flagged 114 of the 135 security-related SATD instances, spanning 24 distinct Common Weakness Enumeration (CWE) identifiers. A manual mapping of the SATD comments revealed 33 unique CWE types, 6 of which correspond to categories that SATs commonly overlook or struggle to detect (e.g., race conditions). Survey responses further suggest that developers frequently pair SAT outputs with SATD insights to better understand the impact and root causes of security weaknesses and to identify suitable fixes. IMPLICATIONS: Our findings show that such SATD-encoded information can be a meaningful complement to SAT-driven security analysis, while helping to overcome some of SATs' practical shortcomings.",
    "title_zh": "在代码行之间：论利用自认的技术债务进行安全分析",
    "abstract_zh": "静态分析工具（SATs）在安全工程活动中占据核心地位，因为它们能够在不执行代码的情况下实现对代码缺陷的早期识别。然而，其有效性常常受到高误报率以及对漏洞类别覆盖不全的限制。与此同时，开发人员经常在软件制品（如代码注释）中以“自认技术债务”（SATD）的形式记录与安全相关的权宜之计和妥协方案。尽管先前的研究已认识到SATD是安全信息的丰富来源，但目前尚不明确：在SAT辅助的安全分析过程中，SATD在多大程度上被利用，以及以何种方式被利用。\n\n**研究目标**：本文旨在探究安全相关的SATD在多大程度上能够补充SAT工具的输出，并帮助克服其众所周知的局限性。\n\n**研究方法**：本研究采用混合研究方法，包括（i）使用三种先进的SAT工具对一个标注了SATD的漏洞数据集进行分析；以及（ii）对72名安全从业者开展在线调查。\n\n**研究结果**：所有SAT工具联合使用时，成功识别出135个与安全相关的SATD实例中的114个，覆盖了24种不同的通用弱点枚举（CWE）标识符。通过对SATD注释进行人工映射，我们识别出33种独特的CWE类型，其中6种属于SAT工具通常忽视或难以检测的类别（例如，竞争条件）。调查结果进一步表明，开发人员经常将SAT的输出与SATD提供的信息相结合，以更深入理解安全缺陷的影响和根本原因，并找到合适的修复方案。\n\n**研究意义**：我们的研究发现表明，SATD中编码的信息可以作为SAT驱动安全分析的有意义补充，有助于克服SAT工具在实际应用中的一些局限性。"
  },
  {
    "date": "2026-02-03",
    "title": "RAL-Bench: Benchmarking for Application-Level Functional Correctness and Non-Functional Quality Attributes",
    "authors": "Ruwei Pan, Yakun Zhang, Qingyuan Liang, Yueheng Zhu, Chao Liu, Lu Zhang, Hongyu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03462v1",
    "source": "arXiv",
    "abstract": "Code generation has advanced rapidly with code-focused large language models (LLMs), especially on snippet-level tasks. However, application-level generation requires producing a runnable multi-file repository with correct structure, dependencies, and end-to-end executability, and real-world software must satisfy both functional correctness and non-functional quality (e.g., maintainability, security). Existing benchmarks provide a limited execution-based assessment of these requirements at the application level. We ask: Can current LLMs generate application-level repositories that meet both functional and non-functional criteria? We propose RAL-Bench, a benchmark and evaluation framework for application-level code generation. For each task, we distill a concise natural-language requirement from a high-quality reference project, build black-box system tests covering functional and non-functional attributes, and keep only tests that pass on the reference repository to ensure a sound oracle and an end-to-end executable suite. Functional correctness is measured by system-test pass rate. Non-functional quality is measured along five ISO/IEC 25010-inspired dimensions and aggregated with an Analytic Hierarchy Process (AHP)-derived weight vector, with per-dimension diagnostics and baseline-normalized scoring using reference measurements. Across 16 LLMs evaluated zero-shot with greedy decoding, functional correctness is the dominant bottleneck: no model exceeds a 45% functional pass rate under our requirement-driven, reference-validated tests. We release RAL-Bench at https://github.com/Wwstarry/RAL-Bench. .",
    "title_zh": "RAL-Bench：面向应用级功能正确性与非功能质量属性的基准测试",
    "abstract_zh": "代码生成在以代码为中心的大语言模型（LLMs）推动下取得了快速进展，尤其在代码片段级别的任务中表现突出。然而，应用级生成需要创建可运行的多文件项目仓库，具备正确的项目结构、依赖关系以及端到端的可执行性。现实世界中的软件不仅需要满足功能正确性，还需兼顾非功能性质量（如可维护性、安全性等）。现有的基准测试在应用级别对这些要求的评估仍局限于有限的执行性评估。我们提出的问题是：当前的 LLM 能否生成同时满足功能与非功能性标准的应用级代码仓库？为此，我们提出了 RAL-Bench——一个面向应用级代码生成的基准测试与评估框架。针对每个任务，我们从高质量参考项目中提炼出简洁的自然语言需求，构建覆盖功能与非功能性属性的黑盒系统测试，并仅保留那些在参考仓库上通过的测试，以确保评估的可靠依据和端到端可执行的测试套件。功能正确性通过系统测试通过率来衡量；非功能性质量则依据五个受 ISO/IEC 25010 启发的维度进行评估，采用基于层次分析法（AHP）推导的权重向量进行综合，并提供各维度的诊断信息，以及基于参考测量结果的基准归一化评分。在对 16 个 LLM 进行零样本、贪婪解码评估中，功能正确性成为主要瓶颈：在我们基于需求驱动、参考验证的测试下，没有任何模型的功能通过率超过 45%。我们已将 RAL-Bench 开源发布于 https://github.com/Wwstarry/RAL-Bench。"
  },
  {
    "date": "2026-02-03",
    "title": "medR: Reward Engineering for Clinical Offline Reinforcement Learning via Tri-Drive Potential Functions",
    "authors": "Qianyi Xu, Gousia Habib, Feng Wu, Yanrui Du, Zhihui Chen, Swapnil Mishra, Dilruk Perera, Mengling Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03305v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning (RL) offers a powerful framework for optimizing dynamic treatment regimes (DTRs). However, clinical RL is fundamentally bottlenecked by reward engineering: the challenge of defining signals that safely and effectively guide policy learning in complex, sparse offline environments. Existing approaches often rely on manual heuristics that fail to generalize across diverse pathologies. To address this, we propose an automated pipeline leveraging Large Language Models (LLMs) for offline reward design and verification. We formulate the reward function using potential functions consisted of three core components: survival, confidence, and competence. We further introduce quantitative metrics to rigorously evaluate and select the optimal reward structure prior to deployment. By integrating LLM-driven domain knowledge, our framework automates the design of reward functions for specific diseases while significantly enhancing the performance of the resulting policies.",
    "title_zh": "medR：基于三重驱动势函数的临床离线强化学习奖励工程",
    "abstract_zh": "强化学习（RL）为优化动态治疗方案（DTRs）提供了一个强大的框架。然而，临床强化学习在本质上受限于奖励工程：即在复杂且稀疏的离线环境中，如何定义能够安全有效地引导策略学习的信号。现有方法通常依赖于人工启发式规则，难以在不同疾病类型间泛化。为解决这一问题，我们提出了一种基于大语言模型（LLMs）的自动化流程，用于离线奖励设计与验证。我们通过由三个核心组成部分构成的势函数来构建奖励函数：生存、置信度和能力。此外，我们引入了定量指标，以严格评估并选择最优的奖励结构，从而在部署前确保其有效性。通过整合LLM驱动的领域知识，我们的框架能够自动化地为特定疾病设计奖励函数，显著提升所生成策略的性能。"
  },
  {
    "date": "2026-02-03",
    "title": "Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation",
    "authors": "Ziru Chen, Dongdong Chen, Ruinan Jin, Yingbin Liang, Yujia Xie, Huan Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03806v1",
    "source": "arXiv",
    "abstract": "Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs' in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt.",
    "title_zh": "连接在线与离线强化学习：用于多轮代码生成的上下文相关老虎机学习",
    "abstract_zh": "近年来，利用强化学习（RL）在真实任务上训练大型语言模型（LLMs）引起了广泛关注，例如多轮代码生成任务。尽管在线强化学习（online RL）通常表现优于离线强化学习（offline RL），但其较高的训练成本和不稳定性限制了其广泛应用。本文基于一个关键观察：多轮代码生成可被建模为一种单步可恢复的马尔可夫决策过程，提出了一种结合在线与离线RL优势的新方法——基于离线轨迹的上下文Bandit学习（Cobalt）。Cobalt首先使用一个参考LLM收集代码生成轨迹，并将这些轨迹拆分为部分轨迹作为上下文提示。在在线Bandit学习阶段，LLM通过单步代码生成来完成每个部分轨迹提示。实验结果表明，Cobalt在LiveCodeBench基准上显著优于基于GRPO和VeRPO的两种多轮在线RL基线方法，分别将R1-Distill 8B和Qwen3 8B的Pass@1得分提升了最高达9.0和6.2个百分点。此外，我们分析了LLM在上下文中可能出现的奖励欺骗行为，并通过引入扰动轨迹对Cobalt训练进行增强，以缓解该问题。总体而言，我们的研究结果表明，Cobalt是一种极具前景的解决方案，适用于多轮迭代决策任务，如多轮代码生成。我们的代码与数据已开源，地址为：https://github.com/OSU-NLP-Group/cobalt。"
  },
  {
    "date": "2026-02-03",
    "title": "FullStack-Agent: Enhancing Agentic Full-Stack Web Coding via Development-Oriented Testing and Repository Back-Translation",
    "authors": "Zimu Lu, Houxing Ren, Yunqiao Yang, Ke Wang, Zhuofan Zong, Mingjie Zhan, Hongsheng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03798v1",
    "source": "arXiv",
    "abstract": "Assisting non-expert users to develop complex interactive websites has become a popular task for LLM-powered code agents. However, existing code agents tend to only generate frontend web pages, masking the lack of real full-stack data processing and storage with fancy visual effects. Notably, constructing production-level full-stack web applications is far more challenging than only generating frontend web pages, demanding careful control of data flow, comprehensive understanding of constantly updating packages and dependencies, and accurate localization of obscure bugs in the codebase. To address these difficulties, we introduce FullStack-Agent, a unified agent system for full-stack agentic coding that consists of three parts: (1) FullStack-Dev, a multi-agent framework with strong planning, code editing, codebase navigation, and bug localization abilities. (2) FullStack-Learn, an innovative data-scaling and self-improving method that back-translates crawled and synthesized website repositories to improve the backbone LLM of FullStack-Dev. (3) FullStack-Bench, a comprehensive benchmark that systematically tests the frontend, backend and database functionalities of the generated website. Our FullStack-Dev outperforms the previous state-of-the-art method by 8.7%, 38.2%, and 15.9% on the frontend, backend, and database test cases respectively. Additionally, FullStack-Learn raises the performance of a 30B model by 9.7%, 9.5%, and 2.8% on the three sets of test cases through self-improvement, demonstrating the effectiveness of our approach. The code is released at https://github.com/mnluzimu/FullStack-Agent.",
    "title_zh": "全栈代理：通过面向开发的测试与仓库反向翻译增强智能全栈Web开发",
    "abstract_zh": "帮助非专业用户开发复杂的交互式网站已成为基于大语言模型（LLM）的代码代理的热门任务。然而，现有的代码代理往往仅能生成前端网页，通过精美的视觉效果掩盖了缺乏真实全栈数据处理与存储能力的缺陷。值得注意的是，构建生产级别的全栈Web应用远比仅生成前端页面更具挑战性，这需要对数据流进行精细控制，全面理解不断更新的包和依赖关系，并准确定位代码库中的隐蔽错误。\n\n为应对这些难题，我们提出了FullStack-Agent——一个统一的全栈智能体编码系统，包含三个核心部分：(1) FullStack-Dev，一个具备强大规划能力、代码编辑、代码库导航及错误定位功能的多智能体框架；(2) FullStack-Learn，一种创新的数据扩展与自我提升方法，通过将爬取和合成的网站仓库进行反向翻译，以优化FullStack-Dev的底层大语言模型；(3) FullStack-Bench，一个全面的基准测试集，系统性地评估生成网站的前端、后端和数据库功能。\n\n实验结果表明，我们的FullStack-Dev在前端、后端和数据库测试用例上分别优于此前最先进的方法8.7%、38.2%和15.9%。此外，通过自我改进，FullStack-Learn使一个300亿参数的模型在三类测试用例上的性能分别提升了9.7%、9.5%和2.8%，充分验证了该方法的有效性。相关代码已开源，地址为：https://github.com/mnluzimu/FullStack-Agent。"
  },
  {
    "date": "2026-02-03",
    "title": "Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL",
    "authors": "Ian Wu, Yuxiao Qu, Amrith Setlur, Aviral Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03773v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) that can continually improve beyond their training budgets are able to solve increasingly difficult problems by adapting at test time, a property we refer to as extrapolation. However, standard reinforcement learning (RL) operates over fixed problem distributions and training budgets, which limits extrapolation amidst distribution shift at test time. To address this, we introduce RC, an iterative decoding algorithm that replaces standard autoregressive decoding during both training and inference. RC exploits an asymmetry between the response generation and summarization capabilities of LLMs to construct reasoning chains that consistently improve across iterations. Models trained to use RC can extrapolate and continually improve over reasoning horizons more than an order of magnitude longer than those seen during training. Empirically, training a 4B model with RC using a 16k-token training budget improves performance on HMMT 2025 from 40% to nearly 70% with 0.5m tokens at test time, outperforming both comparably sized models and many larger reasoning LLMs. Finally, we also show that models trained with RC can more effectively leverage existing scaffolds to further scale test-time performance, due to the improved summary-conditioned generation abilities learned through training.",
    "title_zh": "推理缓存：通过短时域强化学习实现长期持续改进",
    "abstract_zh": "能够超越其训练预算持续改进的大型语言模型（LLMs），可以通过在测试时进行自适应来解决日益复杂的任务，这种特性我们称之为外推能力。然而，标准的强化学习（RL）在固定的任务分布和训练预算下运行，这限制了其在测试时面对分布变化时的外推能力。为解决这一问题，我们提出了RC（Reasoning Chain），一种迭代解码算法，它在训练和推理阶段均替代了传统的自回归解码方式。RC利用大型语言模型在生成回应与总结信息之间存在的能力不对称性，构建出能够逐轮持续改进的推理链。经过RC训练的模型，能够在远超训练阶段所见的推理时序长度（超过一个数量级）上实现持续外推与性能提升。实证研究表明，使用16k token训练预算训练一个40亿参数的模型，结合RC方法后，在HMMT 2025测试中性能从40%提升至接近70%，仅需0.5M token的测试时计算量，便超越了同等规模的模型以及许多更大规模的推理型LLM。最后，我们还发现，经过RC训练的模型能更有效地利用现有的推理支架（scaffolds），从而在测试时进一步提升性能，这得益于训练过程中所习得的、基于摘要条件的生成能力的显著增强。"
  },
  {
    "date": "2026-02-03",
    "title": "SWE-Refactor: A Repository-Level Benchmark for Real-World LLM-Based Code Refactoring",
    "authors": "Yisen Xu, Jinqiu Yang, Tse-Hsun, Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03712v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have recently attracted wide interest for tackling software engineering tasks. In contrast to code generation, refactoring demands precise, semantics-preserving edits that improve program structure, which also makes automated evaluation challenging. However, existing refactoring benchmarks commonly suffer from three shortcomings: limited coverage of refactoring scenarios, the inclusion of instances that mix refactoring with unrelated changes, and insufficient repository-level context for realistic assessment. To mitigate these issues, we introduce SWE-Refactor, a new benchmark for LLM-based code refactoring. SWE-Refactor comprises 1,099 developer-written, behavior-preserving refactorings mined from 18 Java projects, including 922 atomic and 177 compound instances. Each instance is validated via compilation, test execution, and automated refactoring detection tools to ensure correctness. We evaluate nine widely used LLMs on SWE-Refactor, covering models such as GPT-4o-mini, DeepSeek-V3, and CodeLLaMa, to provide representative reference results. Our results show that complex and compound refactorings remain the primary source of failures; notably, an OpenAI Codex agent achieves only 39.4% success on compound instances. We release SWE-Refactor and all evaluation results to facilitate future research on LLM-based code refactoring.",
    "title_zh": "SWE-Refactor：一个面向真实世界基于大语言模型的代码重构的仓库级基准",
    "abstract_zh": "大型语言模型（LLMs）最近在解决软件工程任务方面引起了广泛关注。与代码生成不同，重构要求精确且语义保持不变的修改，以改善程序结构，这也使得自动化评估变得极具挑战性。然而，现有的重构基准普遍存在三个缺陷：覆盖的重构场景有限、包含将重构与其他无关更改混合的实例，以及缺乏足够的仓库级上下文以进行真实可靠的评估。为缓解这些问题，我们提出了 SWE-Refactor——一个面向 LLM 的代码重构新基准。SWE-Refactor 包含从 18 个 Java 项目中挖掘出的 1,099 个由开发者编写的、行为保持不变的重构实例，其中包括 922 个原子型重构和 177 个复合型重构。每个实例均通过编译、测试执行以及自动重构检测工具进行了验证，以确保其正确性。我们在 SWE-Refactor 上评估了九种广泛使用的 LLM，涵盖 GPT-4o-mini、DeepSeek-V3 和 CodeLLaMa 等模型，以提供具有代表性的参考结果。实验结果显示，复杂及复合型重构仍是失败的主要来源；特别地，OpenAI Codex 代理在复合型实例上的成功率仅为 39.4%。我们已公开发布 SWE-Refactor 及所有评估结果，以促进未来基于 LLM 的代码重构研究。"
  },
  {
    "date": "2026-02-03",
    "title": "Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration",
    "authors": "Bowei He, Minda Hu, Zenan Xu, Hongru Wang, Licheng Zong, Yankai Chen, Chen Ma, Xue Liu, Pluto Zhou, Irwin King",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03647v1",
    "source": "arXiv",
    "abstract": "Search-integrated reasoning enables language agents to transcend static parametric knowledge by actively querying external sources. However, training these agents via reinforcement learning is hindered by the multi-scale credit assignment problem: existing methods typically rely on sparse, trajectory-level rewards that fail to distinguish between high-quality reasoning and fortuitous guesses, leading to redundant or misleading search behaviors. To address this, we propose Search-R2, a novel Actor-Refiner collaboration framework that enhances reasoning through targeted intervention, with both components jointly optimized during training. Our approach decomposes the generation process into an Actor, which produces initial reasoning trajectories, and a Meta-Refiner, which selectively diagnoses and repairs flawed steps via a 'cut-and-regenerate' mechanism. To provide fine-grained supervision, we introduce a hybrid reward design that couples outcome correctness with a dense process reward quantifying the information density of retrieved evidence. Theoretically, we formalize the Actor-Refiner interaction as a smoothed mixture policy, proving that selective correction yields strict performance gains over strong baselines. Extensive experiments across various general and multi-hop QA datasets demonstrate that Search-R2 consistently outperforms strong RAG and RL-based baselines across model scales, achieving superior reasoning accuracy with minimal overhead.",
    "title_zh": "Search-R2：通过演员-精炼者协作增强搜索集成推理",
    "abstract_zh": "搜索集成推理使语言代理能够超越静态参数化知识，通过主动查询外部资源来增强能力。然而，利用强化学习训练这些代理时，会受到多尺度信用分配问题的制约：现有方法通常依赖稀疏的轨迹级奖励，难以区分高质量推理与偶然猜对，从而导致冗余或误导性的搜索行为。为解决这一问题，我们提出 Search-R2，一种新颖的 Actor-Refiner 协作框架，通过有针对性的干预提升推理能力，并在训练过程中联合优化两个组件。我们的方法将生成过程分解为两个部分：Actor 负责生成初始推理轨迹，而 Meta-Refiner 则通过“剪裁并重生成”机制，选择性地诊断并修复错误步骤。为提供细粒度监督，我们引入了一种混合奖励设计，将结果正确性与一个密集的过程奖励相结合，后者用于量化检索证据的信息密度。理论上，我们将 Actor-Refiner 的交互形式化为一种平滑混合策略，并证明选择性修正相较于强基线能带来严格性能提升。在多种通用及多跳问答数据集上的大量实验表明，Search-R2 在不同模型规模下均持续优于强大的 RAG 和基于强化学习的基线方法，在几乎无额外开销的情况下实现了更优的推理准确率。"
  },
  {
    "date": "2026-02-03",
    "title": "TRE: Encouraging Exploration in the Trust Region",
    "authors": "Chao Huang, Yujing Lu, Quangang Li, Shenghe Wang, Yan Wang, Yueyang Zhang, Long Xia, Jiashu Zhao, Zhiyuan Sun, Daiting Shi, Tingwen Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03635v1",
    "source": "arXiv",
    "abstract": "Entropy regularization is a standard technique in reinforcement learning (RL) to enhance exploration, yet it yields negligible effects or even degrades performance in Large Language Models (LLMs). We attribute this failure to the cumulative tail risk inherent to LLMs with massive vocabularies and long generation horizons. In such environments, standard global entropy maximization indiscriminately dilutes probability mass into the vast tail of invalid tokens rather than focusing on plausible candidates, thereby disrupting coherent reasoning. To address this, we propose Trust Region Entropy (TRE), a method that encourages exploration strictly within the model's trust region. Extensive experiments across mathematical reasoning (MATH), combinatorial search (Countdown), and preference alignment (HH) tasks demonstrate that TRE consistently outperforms vanilla PPO, standard entropy regularization, and other exploration baselines. Our code is available at https://github.com/WhyChaos/TRE-Encouraging-Exploration-in-the-Trust-Region.",
    "title_zh": "TRE：在信任区域中鼓励探索",
    "abstract_zh": "熵正则化是强化学习（RL）中一种标准的探索增强技术，但在大型语言模型（LLMs）中却往往效果甚微，甚至导致性能下降。我们认为这一失败源于LLMs固有的累积尾部风险——由于词汇量巨大且生成长度较长，标准的全局熵最大化会将概率质量无差别地分散到大量无效词元的庞大尾部中，而非聚焦于合理的候选词元，从而破坏了连贯的推理过程。为解决这一问题，我们提出了信任区域熵（Trust Region Entropy, TRE）方法，该方法严格限制探索范围在模型的信任区域内。在数学推理（MATH）、组合搜索（Countdown）和偏好对齐（HH）等任务上的大量实验表明，TRE始终优于原始PPO、标准熵正则化及其他探索基线方法。我们的代码已开源，地址为：https://github.com/WhyChaos/TRE-Encouraging-Exploration-in-the-Trust-Region。"
  },
  {
    "date": "2026-02-03",
    "title": "UniGeM: Unifying Data Mixing and Selection via Geometric Exploration and Mining",
    "authors": "Changhao Wang, Yunfei Yu, Xinhao Yao, Jiaolong Yang, Riccardo Cantoro, Chaobo Li, Qing Cui, Jun Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03772v1",
    "source": "arXiv",
    "abstract": "The scaling of Large Language Models (LLMs) is increasingly limited by data quality. Most methods handle data mixing and sample selection separately, which can break the structure in code corpora. We introduce \\textbf{UniGeM}, a framework that unifies mixing and selection by treating data curation as a \\textit{manifold approximation} problem without training proxy models or relying on external reference datasets. UniGeM operates hierarchically: \\textbf{Macro-Exploration} learns mixing weights with stability-based clustering; \\textbf{Micro-Mining} filters high-quality instances by their geometric distribution to ensure logical consistency. Validated by training 8B and 16B MoE models on 100B tokens, UniGeM achieves \\textbf{2.0$\\times$ data efficiency} over a random baseline and further improves overall performance compared to SOTA methods in reasoning-heavy evaluations and multilingual generalization.",
    "title_zh": "UniGeM：通过几何探索与挖掘统一数据混合与选择",
    "abstract_zh": "大型语言模型（LLMs）的规模扩展正日益受到数据质量的限制。现有大多数方法将数据混合与样本选择分开处理，这可能导致代码语料库中结构的破坏。我们提出了 \\textbf{UniGeM}，一个将混合与选择统一起来的框架，将数据整理视为一个无需训练代理模型或依赖外部参考数据集的 \\textit{流形逼近} 问题。UniGeM 采用分层机制：\\textbf{宏观探索} 通过基于稳定性的聚类学习混合权重；\\textbf{微观挖掘} 则根据样本的几何分布筛选高质量实例，以确保逻辑一致性。在 1000 亿个标记上训练 80 亿和 160 亿参数的 MoE 模型的验证中，UniGeM 相比随机基线实现了 \\textbf{2.0 倍的数据效率}，并在推理密集型评估和多语言泛化任务中进一步超越了当前最先进方法的性能。"
  },
  {
    "date": "2026-02-03",
    "title": "Improving Deep Learning Library Testing with Machine Learning",
    "authors": "Facundo Molina, M M Abid Naziri, Feiran Qin, Alessandra Gorla, Marcelo d'Amorim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03755v1",
    "source": "arXiv",
    "abstract": "Deep Learning (DL) libraries like TensorFlow and Pytorch simplify machine learning (ML) model development but are prone to bugs due to their complex design. Bug-finding techniques exist, but without precise API specifications, they produce many false alarms. Existing methods to mine API specifications lack accuracy. We explore using ML classifiers to determine input validity. We hypothesize that tensor shapes are a precise abstraction to encode concrete inputs and capture relationships of the data. Shape abstraction severely reduces problem dimensionality, which is important to facilitate ML training. Labeled data are obtained by observing runtime outcomes on a sample of inputs and classifiers are trained on sets of labeled inputs to capture API constraints. Our evaluation, conducted over 183 APIs from TensorFlow and Pytorch, shows that the classifiers generalize well on unseen data with over 91% accuracy. Integrating these classifiers into the pipeline of ACETest, a SoTA bug-finding technique, improves its pass rate from ~29% to ~61%. Our findings suggest that ML-enhanced input classification is an important aid to scale DL library testing.",
    "title_zh": "利用机器学习改进深度学习库的测试",
    "abstract_zh": "深度学习（DL）库如TensorFlow和PyTorch虽然简化了机器学习（ML）模型的开发，但由于其复杂的设计，容易引入错误。现有的错误检测技术虽已存在，但在缺乏精确API规范的情况下，会产生大量误报。目前用于挖掘API规范的方法准确率较低。我们探索使用机器学习分类器来判断输入的有效性。我们假设张量形状是一种精确的抽象方式，能够编码具体的输入并捕捉数据之间的关系。形状抽象能显著降低问题的维度，这对促进机器学习训练至关重要。通过观察一组样本输入在运行时的输出结果，我们获取了带标签的数据，并利用这些带标签的输入集训练分类器，以捕捉API的约束条件。我们在TensorFlow和PyTorch的183个API上进行评估，结果表明，这些分类器在未见过的数据上具有良好的泛化能力，准确率超过91%。将这些分类器集成到ACETest（一种当前最先进的错误检测技术）的流程中后，其通过率从约29%提升至约61%。我们的研究结果表明，基于机器学习的输入分类是扩展深度学习库测试的重要辅助手段。"
  },
  {
    "date": "2026-02-03",
    "title": "CUBO: Self-Contained Retrieval-Augmented Generation on Consumer Laptops 10 GB Corpora, 16 GB RAM, Single-Device Deployment",
    "authors": "Paolo Astrino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03731v1",
    "source": "arXiv",
    "abstract": "Organizations handling sensitive documents face a tension: cloud-based AI risks GDPR violations, while local systems typically require 18-32 GB RAM. This paper presents CUBO, a systems-oriented RAG platform for consumer laptops with 16 GB shared memory. CUBO's novelty lies in engineering integration of streaming ingestion (O(1) buffer overhead), tiered hybrid retrieval, and hardware-aware orchestration that enables competitive Recall@10 (0.48-0.97 across BEIR domains) within a hard 15.5 GB RAM ceiling. The 37,000-line codebase achieves retrieval latencies of 185 ms (p50) on C1,300 laptops while maintaining data minimization through local-only processing aligned with GDPR Art. 5(1)(c). Evaluation on BEIR benchmarks validates practical deployability for small-to-medium professional archives. The codebase is publicly available at https://github.com/PaoloAstrino/CUBO.",
    "title_zh": "CUBO：在消费级笔记本电脑上实现自包含的检索增强生成，支持10 GB语料库、16 GB内存，单设备部署",
    "abstract_zh": "处理敏感文档的组织面临一个两难困境：基于云的AI存在违反GDPR的风险，而本地系统通常需要18至32 GB的内存。本文提出CUBO，一个面向配备16 GB共享内存的消费级笔记本电脑的系统导向型RAG平台。CUBO的创新之处在于工程上实现了流式数据摄入（O(1)缓冲开销）、分层混合检索以及硬件感知编排的集成，使其在严格的15.5 GB内存限制内，仍能实现具有竞争力的Recall@10表现（在BEIR各领域中为0.48至0.97）。该平台拥有37,000行代码，在C1,300台笔记本电脑上实现了185毫秒（p50）的检索延迟，同时通过仅在本地处理数据，符合GDPR第5(1)(c)条关于数据最小化的要求。在BEIR基准上的评估验证了其在中小型专业档案中的实际可部署性。代码库已公开发布于 https://github.com/PaoloAstrino/CUBO。"
  },
  {
    "date": "2026-02-03",
    "title": "LLM-Inspired Pretrain-Then-Finetune for Small-Data, Large-Scale Optimization",
    "authors": "Zishi Zhang, Jinhui Han, Ming Hu, Yijie Peng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03690v1",
    "source": "arXiv",
    "abstract": "We consider small-data, large-scale decision problems in which a firm must make many operational decisions simultaneously (e.g., across a large product portfolio) while observing only a few, potentially noisy, data points per instance. Inspired by the success of large language models (LLMs), we propose a pretrain-then-finetune approach built on a designed Transformer model to address this challenge. The model is first pretrained on large-scale, domain-informed synthetic data that encode managerial knowledge and structural features of the decision environment, and is then fine-tuned on real observations. This new pipeline offers two complementary advantages: pretraining injects domain knowledge into the learning process and enables the training of high-capacity models using abundant synthetic data, while finetuning adapts the pretrained model to the operational environment and improves alignment with the true data-generating regime. While we have leveraged the Transformer's state-of-the-art representational capacity, particularly its attention mechanism, to efficiently extract cross-task structure, our approach is not an off-the-shelf application. Instead, it relies on problem-specific architectural design and a tailored training procedure to match the decision setting. Theoretically, we develop the first comprehensive error analysis regarding Transformer learning in relevant contexts, establishing nonasymptotic guarantees that validate the method's effectiveness. Critically, our analysis reveals how pretraining and fine-tuning jointly determine performance, with the dominant contribution governed by whichever is more favorable. In particular, finetuning exhibits an economies-of-scale effect, whereby transfer learning becomes increasingly effective as the number of instances grows.",
    "title_zh": "基于大语言模型启发的“预训练-微调”范式在小数据、大规模优化中的应用",
    "abstract_zh": "我们研究的是小数据、大规模决策问题，其中企业需要在观察到每个实例仅有少量且可能带有噪声的数据点的情况下，同时做出大量运营决策（例如，在大规模产品组合中）。受大型语言模型（LLMs）成功的启发，我们提出了一种基于定制Transformer模型的“预训练-微调”方法来应对这一挑战。该模型首先在大规模、具有领域知识的合成数据上进行预训练，这些合成数据编码了管理知识以及决策环境的结构特征；随后在真实观测数据上进行微调。这一新流程具有两个互补的优势：预训练将领域知识注入学习过程，使高容量模型能够利用丰富的合成数据进行训练；而微调则使预训练模型适应实际运营环境，提升其与真实数据生成机制的一致性。\n\n尽管我们利用了Transformer模型卓越的表征能力，尤其是其注意力机制，以高效提取跨任务的结构信息，但我们的方法并非简单的现成应用。相反，它依赖于针对具体问题设计的网络架构和量身定制的训练流程，以匹配实际的决策场景。理论上，我们首次建立了关于Transformer在相关情境下学习行为的全面误差分析，给出了非渐近性保证，验证了该方法的有效性。关键的是，我们的分析揭示了预训练与微调共同决定了最终性能，其中起主导作用的因素取决于两者中更为有利的一方。特别地，微调表现出规模经济效应：随着实例数量的增加，迁移学习的效果愈发显著。"
  },
  {
    "date": "2026-02-03",
    "title": "Beyond Variance: Prompt-Efficient RLVR via Rare-Event Amplification and Bidirectional Pairing",
    "authors": "Xin Sheng, Jiaxin Li, Yujuan Pang, Ran Peng, Yong Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03452v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) is effective for training large language models on deterministic outcome reasoning tasks. Prior work shows RLVR works with few prompts, but prompt selection is often based only on training-accuracy variance, leading to unstable optimization directions and weaker transfer. We revisit prompt selection from a mechanism-level view and argue that an effective minibatch should provide both (i) a reliable positive anchor and (ii) explicit negative learning signals from rare failures. Based on this principle, we propose \\emph{positive--negative pairing}: at each update, we sample a hard-but-solvable $q^{+}$ and an easy-but-brittle prompt $q^{-}$(high success rate but not perfect), characterized by low and high empirical success rates under multiple rollouts. We further introduce Weighted GRPO, which reweights binary outcomes at the pair level and uses group-normalized advantages to amplify rare successes on $q^{+}$ into sharp positive guidance while turning rare failures on $q^{-}$ into strong negative penalties. This bidirectional signal provides informative learning feedback for both successes and failures, improving sample efficiency without suppressing exploration. On Qwen2.5-Math-7B, a single paired minibatch per update consistently outperforms a GRPO baseline that selects two prompts via commonly used variance-based selection heuristics: AIME~2025 Pass@8 improves from 16.8 to 22.2, and AMC23 Pass@64 from 94.0 to 97.0, while remaining competitive with large-scale RLVR trained from a pool of 1209 training prompts. Similar gains are observed on Qwen2.5-Math-7B-Instruct.",
    "title_zh": "超越方差：通过罕见事件增强与双向配对实现高效的提示优化RLVR",
    "abstract_zh": "基于可验证奖励的强化学习（RLVR）在训练大语言模型进行确定性结果推理任务方面表现优异。先前的研究表明，RLVR仅需少量提示即可有效工作，但提示选择通常仅基于训练准确率的方差，这导致优化方向不稳定且泛化能力较弱。本文从机制层面重新审视提示选择问题，提出一个有效的小批量应同时满足两个条件：(i) 提供可靠的正向锚点；(ii) 从罕见失败中获取明确的负向学习信号。基于这一原则，我们提出**正负提示配对**（positive–negative pairing）策略：在每次更新时，我们采样一个“难但可解”的提示 $q^{+}$ 和一个“易但脆弱”的提示 $q^{-}$（即成功率高但不完美），二者分别表现为在多次回放中具有低和高经验成功率。我们进一步引入**加权GRPO**（Weighted GRPO），该方法在配对层面重新加权二元结果，并采用组归一化的优势值，将 $q^{+}$ 上的罕见成功转化为强烈的正向引导，同时将 $q^{-}$ 上的罕见失败转化为强有力的负向惩罚。这种双向信号为成功与失败均提供了富有信息量的学习反馈，在不抑制探索的前提下显著提升了样本效率。在Qwen2.5-Math-7B模型上，每次更新仅使用一个配对小批量，其性能持续优于采用常见方差驱动选择策略的GRPO基线：AIME 2025 Pass@8得分从16.8提升至22.2，AMC23 Pass@64得分从94.0提升至97.0，且在性能上仍可与基于1209个训练提示的大规模RLVR方法相媲美。在Qwen2.5-Math-7B-Instruct上也观察到了类似的性能提升。"
  },
  {
    "date": "2026-02-03",
    "title": "Ontology-to-tools compilation for executable semantic constraint enforcement in LLM agents",
    "authors": "Xiaochi Zhou, Patrick Bulter, Changxuan Yang, Simon D. Rihm, Thitikarn Angkanaporn, Jethro Akroyd, Sebastian Mosbach, Markus Kraft",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03439v1",
    "source": "arXiv",
    "abstract": "We introduce ontology-to-tools compilation as a proof-of-principle mechanism for coupling large language models (LLMs) with formal domain knowledge. Within The World Avatar (TWA), ontological specifications are compiled into executable tool interfaces that LLM-based agents must use to create and modify knowledge graph instances, enforcing semantic constraints during generation rather than through post-hoc validation. Extending TWA's semantic agent composition framework, the Model Context Protocol (MCP) and associated agents are integral components of the knowledge graph ecosystem, enabling structured interaction between generative models, symbolic constraints, and external resources. An agent-based workflow translates ontologies into ontology-aware tools and iteratively applies them to extract, validate, and repair structured knowledge from unstructured scientific text. Using metal-organic polyhedra synthesis literature as an illustrative case, we show how executable ontological semantics can guide LLM behaviour and reduce manual schema and prompt engineering, establishing a general paradigm for embedding formal knowledge into generative systems.",
    "title_zh": "用于LLM智能体中可执行语义约束强制的本体到工具的编译",
    "abstract_zh": "我们提出“本体到工具的编译”作为一种原理验证机制，用于将大型语言模型（LLMs）与形式化领域知识相耦合。在“世界化身”（The World Avatar, TWA）系统中，本体规范被编译为可执行的工具接口，基于LLM的智能体必须使用这些接口来创建和修改知识图谱实例，从而在生成过程中强制执行语义约束，而非依赖于生成后的验证。在扩展TWA的语义智能体组合框架的基础上，模型上下文协议（Model Context Protocol, MCP）及其相关智能体成为知识图谱生态系统的核心组成部分，实现了生成模型、符号约束与外部资源之间的结构化交互。基于智能体的工作流将本体转化为具备本体感知能力的工具，并迭代地应用这些工具，从非结构化的科学文本中提取、验证和修复结构化知识。以金属有机多面体合成文献为例，我们展示了可执行的本体语义如何引导LLM的行为，减少对人工模式设计和提示工程的依赖，从而建立了一种将形式化知识嵌入生成式系统的一般性范式。"
  },
  {
    "date": "2026-02-03",
    "title": "When control meets large language models: From words to dynamics",
    "authors": "Komeil Nosrati, Aleksei Tepljakov, Juri Belikov, Eduard Petlenkov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03433v1",
    "source": "arXiv",
    "abstract": "While large language models (LLMs) are transforming engineering and technology through enhanced control capabilities and decision support, they are simultaneously evolving into complex dynamical systems whose behavior must be regulated. This duality highlights a reciprocal connection in which prompts support control system design while control theory helps shape prompts to achieve specific goals efficiently. In this study, we frame this emerging interconnection of LLM and control as a bidirectional continuum, from prompt design to system dynamics. First, we investigate how LLMs can advance the field of control in two distinct capacities: directly, by assisting in the design and synthesis of controllers, and indirectly, by augmenting research workflows. Second, we examine how control concepts help LLMs steer their trajectories away from undesired meanings, improving reachability and alignment via input optimization, parameter editing, and activation-level interventions. Third, we look into deeper integrations by treating LLMs as dynamic systems within a state-space framework, where their internal representations are closely linked to external control loops. Finally, we identify key challenges and outline future research directions to understand LLM behavior and develop interpretable and controllable LLMs that are as trustworthy and robust as their electromechanical counterparts, thereby ensuring they continue to support and safeguard society.",
    "title_zh": "当控制遇上大语言模型：从文字到动态",
    "abstract_zh": "尽管大型语言模型（LLMs）正通过增强的控制能力与决策支持，深刻变革工程与技术领域，但它们自身也在演变为复杂的动态系统，其行为必须加以调控。这种双重特性凸显出一种相互关联的关系：提示（prompts）为控制系统设计提供支持，而控制理论则反过来帮助优化提示，以高效实现特定目标。在本研究中，我们将LLM与控制之间的新兴互动关系视为一个双向连续体，涵盖从提示设计到系统动态的全过程。首先，我们探讨LLM如何以两种不同方式推动控制领域的发展：直接地，协助控制器的设计与综合；间接地，增强科研工作流程。其次，我们研究控制概念如何帮助LLM引导其演化轨迹，避免产生不期望的语义，通过输入优化、参数编辑和激活层干预等手段，提升可达性与对齐性。第三，我们深入探索更深层次的融合，将LLM视为状态空间框架下的动态系统，使其内部表征与外部控制回路紧密关联。最后，我们识别出关键挑战，并提出未来研究方向，旨在深入理解LLM的行为机制，发展可解释、可控制的LLM，使其具备与机电系统同等的可信度与鲁棒性，从而确保其持续为社会提供支持并加以保护。"
  },
  {
    "date": "2026-02-03",
    "title": "SWE-World: Building Software Engineering Agents in Docker-Free Environments",
    "authors": "Shuang Sun, Huatong Song, Lisheng Huang, Jinhao Jiang, Ran Le, Zhihao Lv, Zongchao Chen, Yiwen Hu, Wenyang Luo, Wayne Xin Zhao, Yang Song, Hongteng Xu, Tao Zhang, Ji-Rong Wen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03419v1",
    "source": "arXiv",
    "abstract": "Recent advances in large language models (LLMs) have enabled software engineering agents to tackle complex code modification tasks. Most existing approaches rely on execution feedback from containerized environments, which require dependency-complete setup and physical execution of programs and tests. While effective, this paradigm is resource-intensive and difficult to maintain, substantially complicating agent training and limiting scalability. We propose SWE-World, a Docker-free framework that replaces physical execution environments with a learned surrogate for training and evaluating software engineering agents. SWE-World leverages LLM-based models trained on real agent-environment interaction data to predict intermediate execution outcomes and final test feedback, enabling agents to learn without interacting with physical containerized environments. This design preserves the standard agent-environment interaction loop while eliminating the need for costly environment construction and maintenance during agent optimization and evaluation. Furthermore, because SWE-World can simulate the final evaluation outcomes of candidate trajectories without real submission, it enables selecting the best solution among multiple test-time attempts, thereby facilitating effective test-time scaling (TTS) in software engineering tasks. Experiments on SWE-bench Verified demonstrate that SWE-World raises Qwen2.5-Coder-32B from 6.2\\% to 52.0\\% via Docker-free SFT, 55.0\\% with Docker-free RL, and 68.2\\% with further TTS. The code is available at https://github.com/RUCAIBox/SWE-World",
    "title_zh": "SWE-World：在无Docker环境中构建软件工程代理",
    "abstract_zh": "近年来，大型语言模型（LLMs）的进展使得软件工程智能体能够处理复杂的代码修改任务。现有大多数方法依赖于容器化环境中的执行反馈，这需要完整的依赖配置以及程序和测试的真实执行。尽管这些方法有效，但其资源消耗大且难以维护，显著增加了智能体训练的复杂性，并限制了可扩展性。为此，我们提出了 SWE-World——一个无需 Docker 的框架，该框架通过学习得到的代理模型替代真实的执行环境，用于软件工程智能体的训练与评估。SWE-World 利用基于真实智能体-环境交互数据训练的 LLM 模型，预测中间执行结果和最终测试反馈，使智能体能够在不与物理容器环境交互的情况下进行学习。该设计保留了标准的智能体-环境交互循环，同时在智能体优化与评估过程中消除了昂贵的环境构建与维护需求。此外，由于 SWE-World 能够在不实际提交的情况下模拟候选执行路径的最终评估结果，因此可在测试时从多个尝试中选择最优解，从而有效支持软件工程任务中的测试时扩展（Test-Time Scaling, TTS）。在 SWE-bench Verified 上的实验表明，通过无 Docker 的监督微调（SFT），SWE-World 将 Qwen2.5-Coder-32B 的性能从 6.2% 提升至 52.0%；通过无 Docker 的强化学习（RL）进一步提升至 55.0%；再结合 TTS 后达到 68.2%。代码已开源，地址为：https://github.com/RUCAIBox/SWE-World"
  },
  {
    "date": "2026-02-03",
    "title": "Socratic-Geo: Synthetic Data Generation and Geometric Reasoning via Multi-Agent Interaction",
    "authors": "Zhengbo Jiao, Shaobo Wang, Zifan Zhang, Wei Wang, Bing Zhao, Hu Wei, Linfeng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03414v1",
    "source": "arXiv",
    "abstract": "Multimodal Large Language Models (MLLMs) have significantly advanced vision-language understanding. However, even state-of-the-art models struggle with geometric reasoning, revealing a critical bottleneck: the extreme scarcity of high-quality image-text pairs. Human annotation is prohibitively expensive, while automated methods fail to ensure fidelity and training effectiveness. Existing approaches either passively adapt to available images or employ inefficient random exploration with filtering, decoupling generation from learning needs. We propose Socratic-Geo, a fully autonomous framework that dynamically couples data synthesis with model learning through multi-agent interaction. The Teacher agent generates parameterized Python scripts with reflective feedback (Reflect for solvability, RePI for visual validity), ensuring image-text pair purity. The Solver agent optimizes reasoning through preference learning, with failure paths guiding Teacher's targeted augmentation. Independently, the Generator learns image generation capabilities on accumulated \"image-code-instruction\" triplets, distilling programmatic drawing intelligence into visual generation. Starting from only 108 seed problems, Socratic-Solver achieves 49.11 on six benchmarks using one-quarter of baseline data, surpassing strong baselines by 2.43 points. Socratic-Generator achieves 42.4% on GenExam, establishing new state-of-the-art for open-source models, surpassing Seedream-4.0 (39.8%) and approaching Gemini-2.5-Flash-Image (43.1%).",
    "title_zh": "苏格拉底-Geo：通过多智能体交互生成合成数据与几何推理",
    "abstract_zh": "多模态大语言模型（MLLMs）在视觉-语言理解方面取得了显著进展。然而，即便是最先进的模型在几何推理任务上仍表现不佳，暴露出一个关键瓶颈：高质量图像-文本配对数据极度稀缺。人工标注成本过高，而自动化方法又难以保证数据的真实性和训练有效性。现有方法要么被动适应现有图像，要么采用低效的随机探索结合过滤策略，导致数据生成与模型学习过程脱节。为此，我们提出Socratic-Geo，一个完全自主的框架，通过多智能体交互实现数据合成与模型学习的动态耦合。教师（Teacher）智能体生成带有反思反馈的参数化Python脚本（Reflect用于判断可解性，RePI用于验证视觉合理性），确保图像-文本对的质量纯净。求解器（Solver）智能体通过偏好学习优化推理能力，失败路径则引导教师进行有针对性的数据增强。与此同时，生成器（Generator）在积累的“图像-代码-指令”三元组上学习图像生成能力，将程序化绘图的智能提炼为视觉生成能力。仅从108个种子问题出发，Socratic-Solver在六个基准测试上达到49.11分，仅使用基线数据的四分之一，超越强基线模型2.43分。Socratic-Generator在GenExam测试中取得42.4%的准确率，为开源模型树立了新标杆，超越Seedream-4.0（39.8%），并接近Gemini-2.5-Flash-Image（43.1%）的水平。"
  },
  {
    "date": "2026-02-03",
    "title": "LogicScan: An LLM-driven Framework for Detecting Business Logic Vulnerabilities in Smart Contracts",
    "authors": "Jiaqi Gao, Zijian Zhang, Yuqiang Sun, Ye Liu, Chengwei Liu, Han Liu, Yi Li, Yang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03271v1",
    "source": "arXiv",
    "abstract": "Business logic vulnerabilities have become one of the most damaging yet least understood classes of smart contract vulnerabilities. Unlike traditional bugs such as reentrancy or arithmetic errors, these vulnerabilities arise from missing or incorrectly enforced business invariants and are tightly coupled with protocol semantics. Existing static analysis techniques struggle to capture such high-level logic, while recent large language model based approaches often suffer from unstable outputs and low accuracy due to hallucination and limited verification. In this paper, we propose LogicScan, an automated contrastive auditing framework for detecting business logic vulnerabilities in smart contracts. The key insight behind LogicScan is that mature, widely deployed on-chain protocols implicitly encode well-tested and consensus-driven business invariants. LogicScan systematically mines these invariants from large-scale on-chain contracts and reuses them as reference constraints to audit target contracts. To achieve this, LogicScan introduces a Business Specification Language (BSL) to normalize diverse implementation patterns into structured, verifiable logic representations. It further combines noise-aware logic aggregation with contrastive auditing to identify missing or weakly enforced invariants while mitigating LLM-induced false positives. We evaluate LogicScan on three real-world datasets, including DeFiHacks, Web3Bugs, and a set of top-200 audited contracts. The results show that LogicScan achieves an F1 score of 85.2%, significantly outperforming state-of-the-art tools while maintaining a low false-positive rate on production-grade contracts. Additional experiments demonstrate that LogicScan maintains consistent performance across different LLMs and is cost-effective, and that its false-positive suppression mechanisms substantially improve robustness.",
    "title_zh": "LogicScan：一种由大语言模型驱动的智能合约业务逻辑漏洞检测框架",
    "abstract_zh": "业务逻辑漏洞已成为最具破坏性 yet最不为人所理解的智能合约漏洞类别之一。与重入或算术错误等传统漏洞不同，这类漏洞源于缺失或错误执行的业务不变性（business invariants），且与协议语义紧密耦合。现有的静态分析技术难以捕捉此类高层逻辑，而近期基于大语言模型（LLM）的方法则常因幻觉现象和验证能力有限，导致输出不稳定、准确率低下。本文提出 LogicScan，一种用于检测智能合约中业务逻辑漏洞的自动化对比审计框架。LogicScan 的核心洞察在于：成熟且广泛部署的链上协议隐式地编码了经过充分验证、共识驱动的业务不变性。LogicScan 系统性地从大规模链上合约中挖掘这些不变性，并将其作为参考约束用于审计目标合约。为实现这一目标，LogicScan 引入了一种业务规范语言（Business Specification Language, BSL），将多样化的实现模式统一为结构化、可验证的逻辑表示。同时，它结合了抗噪逻辑聚合与对比审计机制，在识别缺失或弱约束的不变性的同时，有效缓解了 LLM 引发的误报问题。我们在三个真实世界数据集上对 LogicScan 进行了评估，包括 DeFiHacks、Web3Bugs 以及前 200 名经审计的合约集合。结果表明，LogicScan 的 F1 得分为 85.2%，显著优于现有最先进工具，同时在生产级合约上保持了较低的误报率。额外实验进一步证明，LogicScan 在不同 LLM 上均表现出一致的性能，具备良好的成本效益，且其误报抑制机制显著提升了系统的鲁棒性。"
  },
  {
    "date": "2026-02-03",
    "title": "Short Chains, Deep Thoughts: Balancing Reasoning Efficiency and Intra-Segment Capability via Split-Merge Optimization",
    "authors": "Runquan Gui, Jie Wang, Zhihai Wang, Chi Ma, Jianye Hao, Feng Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03141v1",
    "source": "arXiv",
    "abstract": "While Large Reasoning Models (LRMs) have demonstrated impressive capabilities in solving complex tasks through the generation of long reasoning chains, this reliance on verbose generation results in significant latency and computational overhead. To address these challenges, we propose \\textbf{CoSMo} (\\textbf{Co}nsistency-Guided \\textbf{S}plit-\\textbf{M}erge \\textbf{O}ptimization), a framework designed to eliminate structural redundancy rather than indiscriminately restricting token volume. Specifically, CoSMo utilizes a split-merge algorithm that dynamically refines reasoning chains by merging redundant segments and splitting logical gaps to ensure coherence. We then employ structure-aligned reinforcement learning with a novel segment-level budget to supervise the model in maintaining efficient reasoning structures throughout training. Extensive experiments across multiple benchmarks and backbones demonstrate that CoSMo achieves superior performance, improving accuracy by \\textbf{3.3} points while reducing segment usage by \\textbf{28.7\\%} on average compared to reasoning efficiency baselines.",
    "title_zh": "短链深思：通过拆分-合并优化实现推理效率与段内能力的平衡",
    "abstract_zh": "尽管大型推理模型（LRMs）通过生成长推理链在解决复杂任务方面展现出卓越能力，但其对冗长生成的依赖导致了显著的延迟和计算开销。为应对这些挑战，我们提出了**CoSMo**（**Co**nsistency-Guided **S**plit-**M**erge **O**ptimization）框架，该框架旨在消除结构冗余，而非盲目限制词元数量。具体而言，CoSMo采用一种分拆-合并算法，通过动态合并冗余段落并拆分逻辑断层，以确保推理链的连贯性。随后，我们引入一种基于结构对齐的强化学习方法，并设计了一种新颖的段落级预算机制，以在训练过程中指导模型保持高效的推理结构。在多个基准测试和不同模型架构上的大量实验表明，CoSMo在性能上表现优异，相较于推理效率基线，平均准确率提升**3.3**个百分点，同时段落数量减少**28.7%**。"
  },
  {
    "date": "2026-02-03",
    "title": "Task--Specificity Score: Measuring How Much Instructions Really Matter for Supervision",
    "authors": "Pritam Kadasi, Abhishek Upperwal, Mayank Singh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03103v1",
    "source": "arXiv",
    "abstract": "Instruction tuning is now the default way to train and adapt large language models, but many instruction--input--output pairs are only weakly specified: for a given input, the same output can remain plausible under several alternative instructions. This raises a simple question: \\emph{does the instruction uniquely determine the target output?} We propose the \\textbf{Task--Specificity Score (TSS)} to quantify how much an instruction matters for predicting its output, by contrasting the true instruction against plausible alternatives for the same input. We further introduce \\textbf{TSS++}, which uses hard alternatives and a small quality term to mitigate easy-negative effects. Across three instruction datasets (\\textsc{Alpaca}, \\textsc{Dolly-15k}, \\textsc{NI-20}) and three open LLMs (Gemma, Llama, Qwen), we show that selecting task-specific examples improves downstream performance under tight token budgets and complements quality-based filters such as perplexity and IFD.",
    "title_zh": "任务——具体性评分：衡量指令在监督中的实际重要性",
    "abstract_zh": "指令微调如今已成为训练和调整大型语言模型的默认方法，但许多指令-输入-输出对的描述仅是弱约束的：对于给定的输入，存在多种不同的指令仍可对应同样合理的输出。这引出一个简单却关键的问题：**指令是否唯一决定了目标输出？** 为此，我们提出了**任务特异性得分（Task-Specificity Score, TSS）**，通过将真实指令与同一输入下的合理替代指令进行对比，量化指令在预测输出时的重要性。我们进一步引入了**TSS++**，采用硬负例（hard alternatives）并加入一个小的品质修正项，以缓解“易负例”（easy-negative）带来的偏差问题。在三个指令数据集（\\textsc{Alpaca}、\\textsc{Dolly-15k}、\\textsc{NI-20}）和三个开源大模型（Gemma、Llama、Qwen）上的实验表明，选择任务特异性高的样本能够显著提升在严格token预算下的下游任务性能，并且与基于质量的过滤方法（如困惑度和IFD）具有良好的互补性。"
  },
  {
    "date": "2026-02-03",
    "title": "AERO: Autonomous Evolutionary Reasoning Optimization via Endogenous Dual-Loop Feedback",
    "authors": "Zhitao Gao, Jie Ma, Xuhong Li, Pengyu Li, Ning Qu, Yaqiang Wu, Hui Liu, Jun Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03084v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have achieved significant success in complex reasoning but remain bottlenecked by reliance on expert-annotated data and external verifiers. While existing self-evolution paradigms aim to bypass these constraints, they often fail to identify the optimal learning zone and risk reinforcing collective hallucinations and incorrect priors through flawed internal feedback. To address these challenges, we propose \\underline{A}utonomous \\underline{E}volutionary \\underline{R}easoning \\underline{O}ptimization (AERO), an unsupervised framework that achieves autonomous reasoning evolution by internalizing self-questioning, answering, and criticism within a synergistic dual-loop system. Inspired by the \\textit{Zone of Proximal Development (ZPD)} theory, AERO utilizes entropy-based positioning to target the ``solvability gap'' and employs Independent Counterfactual Correction for robust verification. Furthermore, we introduce a Staggered Training Strategy to synchronize capability growth across functional roles and prevent curriculum collapse. Extensive evaluations across nine benchmarks spanning three domains demonstrate that AERO achieves average performance improvements of 4.57\\% on Qwen3-4B-Base and 5.10\\% on Qwen3-8B-Base, outperforming competitive baselines. Code is available at https://github.com/mira-ai-lab/AERO.",
    "title_zh": "AERO：通过内生双回路反馈实现自主进化推理优化",
    "abstract_zh": "大规模语言模型（LLMs）在复杂推理任务中取得了显著成功，但仍受限于对专家标注数据和外部验证器的依赖。尽管现有的自进化范式旨在突破这些限制，但它们往往难以识别最优的学习区域，并可能因内部反馈机制存在缺陷而加剧集体幻觉和错误先验的传播。为解决上述挑战，我们提出了一种名为 **AERO**（Autonomous Evolutionary Reasoning Optimization，自主进化推理优化）的无监督框架。该框架通过在一个协同双循环系统中内化自我提问、自答与批判机制，实现推理能力的自主演化。受“最近发展区（Zone of Proximal Development, ZPD）”理论启发，AERO 采用基于熵的定位方法，精准聚焦于“可解性差距”区域，并引入独立反事实修正（Independent Counterfactual Correction）以增强验证的鲁棒性。此外，我们设计了分阶段训练策略（Staggered Training Strategy），以协调各功能角色的能力增长，有效防止课程坍缩问题。在涵盖三个领域的九个基准测试上的大量实验表明，AERO 在 Qwen3-4B-Base 上实现了平均 4.57% 的性能提升，在 Qwen3-8B-Base 上更是达到 5.10% 的提升，显著优于现有竞争性基线方法。代码已开源，地址为：https://github.com/mira-ai-lab/AERO。"
  },
  {
    "date": "2026-02-03",
    "title": "RC-GRPO: Reward-Conditioned Group Relative Policy Optimization for Multi-Turn Tool Calling Agents",
    "authors": "Haitian Zhong, Jixiu Zhai, Lei Song, Jiang Bian, Qiang Liu, Tieniu Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03025v1",
    "source": "arXiv",
    "abstract": "Multi-turn tool calling is challenging for Large Language Models (LLMs) because rewards are sparse and exploration is expensive. A common recipe, SFT followed by GRPO, can stall when within-group reward variation is low (e.g., more rollouts in a group receive the all 0 or all 1 reward), making the group-normalized advantage uninformative and yielding vanishing updates. To address this problem, we propose RC-GRPO (Reward-Conditioned Group Relative Policy Optimization), which treats exploration as a controllable steering problem via discrete reward tokens. We first fine-tune a Reward-Conditioned Trajectory Policy (RCTP) on mixed-quality trajectories with reward goal special tokens (e.g., <|high_reward|>, <|low_reward|>) injected into the prompts, enabling the model to learn how to generate distinct quality trajectories on demand. Then during RL, we sample diverse reward tokens within each GRPO group and condition rollouts on the sampled token to improve within-group diversity, improving advantage gains. On the Berkeley Function Calling Leaderboard v4 (BFCLv4) multi-turn benchmark, our method yields consistently improved performance than baselines, and the performance on Qwen-2.5-7B-Instruct even surpasses all closed-source API models.",
    "title_zh": "RC-GRPO：用于多轮工具调用智能体的奖励条件组相对策略优化",
    "abstract_zh": "多轮工具调用对大型语言模型（LLMs）而言具有挑战性，主要因为奖励稀疏且探索成本高昂。一种常见的训练方法是先进行监督微调（SFT），再采用GRPO（Group Relative Policy Optimization）进行强化学习，但当组内奖励差异较小时（例如，同一组内的多个采样轨迹均获得全0或全1的奖励），组内归一化的优势值会变得无意义，导致更新信号消失，训练停滞。为解决这一问题，我们提出RC-GRPO（Reward-Conditioned Group Relative Policy Optimization），将探索视为一个可通过离散奖励标记进行可控引导的问题。我们首先在混合质量的轨迹数据上微调一个奖励条件轨迹策略（RCTP），并在提示中注入特定的奖励目标标记（如<|high_reward|>、<|low_reward|>），使模型学会按需生成不同质量的轨迹。在强化学习阶段，我们于每个GRPO组内采样多样化的奖励标记，并将其作为条件用于轨迹生成，从而提升组内多样性，增强优势估计的有效性。在伯克利函数调用排行榜v4（BFCLv4）多轮基准测试中，我们的方法持续优于各类基线模型，其中Qwen-2.5-7B-Instruct的表现甚至超越了所有闭源API模型。"
  },
  {
    "date": "2026-02-03",
    "title": "STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models",
    "authors": "Jiliang Ni, Jiachen Pu, Zhongyi Yang, Jingfeng Luo, Conggang Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03022v1",
    "source": "arXiv",
    "abstract": "The proliferation of Large Language Models (LLMs) in function calling is pivotal for creating advanced AI agents, yet their large scale hinders widespread adoption, necessitating transferring their capabilities into smaller ones. However, existing paradigms are often plagued by overfitting, training instability, ineffective binary rewards for multi-solution tasks, and the difficulty of synergizing techniques. We introduce STAR: Similarity-guided Teacher-Assisted Refinement, a novel holistic framework that effectively transfers LLMs' capabilities to super-tiny models. STAR consists of two core technical innovations: (1) Constrained Knowledge Distillation (CKD), a training objective that augments top-k forward KL divergence to suppress confidently incorrect predictions, ensuring training stability while preserving exploration capacity for downstream RL. STAR holistically synergizes these strategies within a cohesive training curriculum, enabling super-tiny models to achieve exceptional performance on complex function calling tasks; (2) Similarity-guided RL (Sim-RL), a RL mechanism that introduces a fine-grained, similarity-based reward. This provides a robust, continuous, and rich signal for better policy optimization by evaluating the similarity between generated outputs and the ground truth. Extensive experiments on challenging and renowned benchmarks demonstrate the effectiveness of our method. Our STAR models establish SOTA in their size classes, significantly outperforming baselines. Remarkably, our 0.6B STAR model achieves the best performance among all open models under 1B, surpassing even several well-known open models at a larger scale. STAR demonstrates a training framework that distills capabilities of LLMs into super-tiny models, paving the way for powerful, accessible, and efficient AI agents.",
    "title_zh": "STAR：基于相似性的教师辅助精炼超小型函数调用模型",
    "abstract_zh": "大型语言模型（LLMs）在函数调用中的广泛应用对于构建先进的AI智能体至关重要，但其庞大的规模限制了其广泛部署，因此亟需将它们的能力迁移至更小的模型中。然而，现有的方法通常面临过拟合、训练不稳定、多解任务中无效的二元奖励机制，以及技术协同困难等问题。为此，我们提出了STAR：基于相似性的教师辅助精炼（Similarity-guided Teacher-Assisted Refinement），一种全新的整体性框架，能够高效地将LLMs的能力迁移至超小型模型。STAR包含两项核心技术创新：（1）约束性知识蒸馏（Constrained Knowledge Distillation, CKD），一种增强型训练目标，通过引入top-k前向KL散度来抑制置信度高的错误预测，从而在保证训练稳定性的同时，保留下游强化学习（RL）中的探索能力；STAR将这些策略有机整合进一个连贯的训练课程中，使超小型模型在复杂函数调用任务上实现卓越性能；（2）基于相似性的强化学习（Sim-RL），一种新型强化学习机制，引入细粒度、基于相似度的奖励信号。该机制通过评估生成输出与真实答案之间的相似性，提供稳健、连续且丰富的反馈信号，显著提升策略优化效果。在多个具有挑战性且广受认可的基准测试中，大量实验充分验证了本方法的有效性。我们的STAR模型在各自参数规模类别中均达到当前最优（SOTA）水平，显著超越各类基线模型。尤为突出的是，我们的0.6B参数STAR模型在所有10亿参数以下的开源模型中表现最佳，甚至超越了多个参数规模更大的知名开源模型。STAR展示了一种将大模型能力高效蒸馏至超小型模型的训练框架，为构建强大、可及且高效的AI智能体开辟了新路径。"
  },
  {
    "date": "2026-02-03",
    "title": "CL-bench: A Benchmark for Context Learning",
    "authors": "Shihan Dou, Ming Zhang, Zhangyue Yin, Chenhao Huang, Yujiong Shen, Junzhe Wang, Jiayi Chen, Yuchen Ni, Junjie Ye, Cheng Zhang, Huaibing Xie, Jianglu Hu, Shaolei Wang, Weichao Wang, Yanling Xiao, Yiting Liu, Zenan Xu, Zhen Guo, Pluto Zhou, Tao Gui, Zuxuan Wu, Xipeng Qiu, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang, Di Wang, Shunyu Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03587v1",
    "source": "arXiv",
    "abstract": "Current language models (LMs) excel at reasoning over prompts using pre-trained knowledge. However, real-world tasks are far more complex and context-dependent: models must learn from task-specific context and leverage new knowledge beyond what is learned during pre-training to reason and resolve tasks. We term this capability context learning, a crucial ability that humans naturally possess but has been largely overlooked. To this end, we introduce CL-bench, a real-world benchmark consisting of 500 complex contexts, 1,899 tasks, and 31,607 verification rubrics, all crafted by experienced domain experts. Each task is designed such that the new content required to resolve it is contained within the corresponding context. Resolving tasks in CL-bench requires models to learn from the context, ranging from new domain-specific knowledge, rule systems, and complex procedures to laws derived from empirical data, all of which are absent from pre-training. This goes far beyond long-context tasks that primarily test retrieval or reading comprehension, and in-context learning tasks, where models learn simple task patterns via instructions and demonstrations. Our evaluations of ten frontier LMs find that models solve only 17.2% of tasks on average. Even the best-performing model, GPT-5.1, solves only 23.7%, revealing that LMs have yet to achieve effective context learning, which poses a critical bottleneck for tackling real-world, complex context-dependent tasks. CL-bench represents a step towards building LMs with this fundamental capability, making them more intelligent and advancing their deployment in real-world scenarios.",
    "title_zh": "CL-bench：一个上下文学习基准测试",
    "abstract_zh": "当前的语言模型（LMs）在利用预训练知识对提示进行推理方面表现出色。然而，现实世界中的任务要复杂得多，且高度依赖上下文：模型必须从特定任务的上下文中学习，并利用预训练阶段未涵盖的新知识来推理并完成任务。我们将这种能力称为“上下文学习”，这是人类与生俱来的重要能力，但长期以来却未受到足够重视。为此，我们提出了CL-bench，一个真实世界基准，包含500个复杂上下文、1,899个任务以及31,607条验证标准，所有内容均由经验丰富的领域专家精心设计。每个任务都确保解决所需的新信息均包含在对应的上下文中。要完成CL-bench中的任务，模型必须从上下文中学习，包括新领域的专业知识、规则体系、复杂流程，甚至基于实证数据推导出的法律等，而这些在预训练阶段均未涉及。这远远超越了仅测试检索或阅读理解能力的长上下文任务，也不同于仅通过指令和示例学习简单任务模式的“上下文学习”任务。我们对十种前沿语言模型的评估显示，模型平均仅能解决17.2%的任务。即使表现最佳的模型GPT-5.1，也仅能解决23.7%，这表明当前语言模型尚未实现有效的上下文学习，而这正是应对现实世界中复杂、上下文依赖任务的关键瓶颈。CL-bench的提出，标志着迈向构建具备这一基础能力的语言模型的重要一步，有助于提升模型的智能水平，并推动其在真实场景中的广泛应用。"
  },
  {
    "date": "2026-02-03",
    "title": "Scaling Test-Driven Code Generation from Functions to Classes: An Empirical Study",
    "authors": "Yunhao Liang, Ruixuan Ying, Shiwen Ni, Zhe Cui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03557v1",
    "source": "arXiv",
    "abstract": "Test-driven development (TDD) has been adopted to improve Large Language Model (LLM)-based code generation by using tests as executable specifications. However, existing TDD-style code generation studies are largely limited to function-level tasks, leaving class-level synthesis where multiple methods interact through shared state and call dependencies underexplored. In this paper, we scale test-driven code generation from functions to classes via an iterative TDD framework. Our approach first analyzes intra-class method dependencies to derive a feasible generation schedule, and then incrementally implements each method under method-level public tests with reflection-style execution feedback and bounded repair iterations. To support test-driven generation and rigorous class-level evaluation, we construct ClassEval-TDD, a cleaned and standardized variant of ClassEval with consistent specifications, deterministic test environments, and complete method-level public tests. We conduct an empirical study across eight LLMs and compare against the strongest direct-generation baseline (the best of holistic, incremental, and compositional strategies). Our class-level TDD framework consistently improves class-level correctness by 12 to 26 absolute points and achieves up to 71% fully correct classes, while requiring only a small number of repairs on average. These results demonstrate that test-driven generation can effectively scale beyond isolated functions and substantially improve class-level code generation reliability. All code and data are available at https://anonymous.4open.science/r/ClassEval-TDD-C4C9/",
    "title_zh": "从函数到类的可扩展性测试驱动代码生成：一项实证研究",
    "abstract_zh": "测试驱动开发（TDD）已被用于通过将测试作为可执行规范来提升基于大语言模型（LLM）的代码生成质量。然而，现有的TDD风格代码生成研究主要局限于函数级任务，对于类级合成这一复杂场景——其中多个方法通过共享状态和调用依赖相互作用——仍缺乏深入探索。本文提出一种从函数级向类级扩展的迭代式TDD框架，实现测试驱动的类级代码生成。我们的方法首先分析类内方法间的依赖关系，推导出可行的生成顺序；随后在方法级公开测试的约束下，逐个增量式实现每个方法，并结合反射式执行反馈与有限次数的修复迭代进行优化。为支持测试驱动生成及严格的类级评估，我们构建了ClassEval-TDD——一个经过清洗和标准化的ClassEval变体，具备一致的规范、确定性的测试环境以及完整的、方法级的公开测试。我们在八种大语言模型上进行了实证研究，并与最强的直接生成基线（综合、增量和组合策略中的最优者）进行对比。结果表明，我们的类级TDD框架在类级正确性上平均提升12至26个百分点，最高实现71%的类完全正确，且平均修复次数极少。这些结果证明，测试驱动生成能够有效突破孤立函数的局限，显著提升类级代码生成的可靠性。所有代码与数据均可在 https://anonymous.4open.science/r/ClassEval-TDD-C4C9/ 获取。"
  },
  {
    "date": "2026-02-03",
    "title": "WARP Logic Neural Networks",
    "authors": "Lino Gerlach, Thore Gerlach, Liv Våge, Elliott Kauffman, Isobel Ojalvo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03527v1",
    "source": "arXiv",
    "abstract": "Fast and efficient AI inference is increasingly important, and recent models that directly learn low-level logic operations have achieved state-of-the-art performance. However, existing logic neural networks incur high training costs, introduce redundancy or rely on approximate gradients, which limits scalability. To overcome these limitations, we introduce WAlsh Relaxation for Probabilistic (WARP) logic neural networks -- a novel gradient-based framework that efficiently learns combinations of hardware-native logic blocks. We show that WARP yields the most parameter-efficient representation for exactly learning Boolean functions and that several prior approaches arise as restricted special cases. Training is improved by introducing learnable thresholding and residual initialization, while we bridge the gap between relaxed training and discrete logic inference through stochastic smoothing. Experiments demonstrate faster convergence than state-of-the-art baselines, while scaling effectively to deeper architectures and logic functions with higher input arity.",
    "title_zh": "WARP逻辑神经网络",
    "abstract_zh": "快速高效的AI推理日益重要，近年来，一些直接学习低级逻辑操作的模型已达到最先进的性能。然而，现有的逻辑神经网络存在训练成本高、引入冗余或依赖近似梯度等问题，限制了其可扩展性。为克服这些局限，我们提出了用于概率逻辑的沃尔什松弛（WAlsh Relaxation for Probabilistic, WARP）神经网络——一种新型基于梯度的框架，能够高效学习硬件原生逻辑模块的组合。我们证明，WARP能够以最精简的参数量精确学习布尔函数，且多种先前方法可视为其受限的特例。通过引入可学习的阈值机制和残差初始化，我们进一步提升了训练效果；同时，借助随机平滑技术，弥合了松弛化训练与离散逻辑推理之间的差距。实验表明，WARP在收敛速度上优于现有最先进基线方法，同时在更深的网络架构以及更高输入元数的逻辑函数上也表现出良好的可扩展性。"
  },
  {
    "date": "2026-02-03",
    "title": "Conflict-Resolving and Sharpness-Aware Minimization for Generalized Knowledge Editing with Multiple Updates",
    "authors": "Duy Nguyen, Hanqi Xiao, Archiki Prasad, Elias Stengel-Eskin, Hyunji Lee, Mohit Bansal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03696v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) rely on internal knowledge to solve many downstream tasks, making it crucial to keep them up to date. Since full retraining is expensive, prior work has explored efficient alternatives such as model editing and parameter-efficient fine-tuning. However, these approaches often break down in practice due to poor generalization across inputs, limited stability, and knowledge conflict. To address these limitations, we propose the CoRSA (Conflict-Resolving and Sharpness-Aware Minimization) training framework, a parameter-efficient, holistic approach for knowledge editing with multiple updates. CoRSA tackles multiple challenges simultaneously: it improves generalization to different input forms and enhances stability across multiple updates by minimizing loss curvature, and resolves conflicts by maximizing the margin between new and prior knowledge. Across three widely used fact editing benchmarks, CoRSA achieves significant gains in generalization, outperforming baselines with average absolute improvements of 12.42% over LoRA and 10% over model editing methods. With multiple updates, it maintains high update efficacy while reducing catastrophic forgetting by 27.82% compared to LoRA. CoRSA also generalizes to the code domain, outperforming the strongest baseline by 5.48% Pass@5 in update efficacy.",
    "title_zh": "多更新下的广义知识编辑中的冲突消解与锐度感知最小化",
    "abstract_zh": "大型语言模型（LLMs）依赖于其内部知识来解决众多下游任务，因此保持模型知识的时效性至关重要。由于全量重训练成本高昂，先前的研究探索了诸如模型编辑和参数高效微调等高效替代方案。然而，这些方法在实际应用中常常因输入泛化能力差、稳定性有限以及知识冲突等问题而失效。为解决上述局限，我们提出了 CoRSA（冲突缓解与尖锐度感知最小化）训练框架，这是一种参数高效、整体性的多更新知识编辑方法。CoRSA 同时应对多个挑战：通过最小化损失曲率，提升对不同输入形式的泛化能力，并增强多次更新下的稳定性；通过最大化新旧知识之间的间隔，有效缓解知识冲突。在三个广泛使用的事实编辑基准上，CoRSA 在泛化性能上取得显著提升，相较于 LoRA 基线平均绝对提升 12.42%，相较于模型编辑方法提升 10%。在多次更新场景下，CoRSA 保持了高更新有效性，同时相比 LoRA 将灾难性遗忘降低了 27.82%。此外，CoRSA 在代码领域也展现出良好泛化能力，在更新有效性指标 Pass@5 上超越最强基线 5.48%。"
  },
  {
    "date": "2026-02-03",
    "title": "Large Language Models Can Take False First Steps at Inference-time Planning",
    "authors": "Haijiang Yan, Jian-Qiao Zhu, Adam Sanborn",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02991v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have been shown to acquire sequence-level planning abilities during training, yet their planning behavior exhibited at inference time often appears short-sighted and inconsistent with these capabilities. We propose a Bayesian account for this gap by grounding planning behavior in the evolving generative context: given the subtle differences between natural language and the language internalized by LLMs, accumulated self-generated context drives a planning-shift during inference and thereby creates the appearance of compromised planning behavior. We further validate the proposed model through two controlled experiments: a random-generation task demonstrating constrained planning under human prompts and increasing planning strength as self-generated context accumulates, and a Gaussian-sampling task showing reduced initial bias when conditioning on self-generated sequences. These findings provide a theoretical explanation along with empirical evidence for characterizing how LLMs plan ahead during inference.",
    "title_zh": "大型语言模型在推理时规划中可能迈出错误的初始步骤",
    "abstract_zh": "大型语言模型（LLMs）在训练过程中展现出序列级规划能力，然而在推理阶段表现出的规划行为却常常显得短视且与其潜在能力不一致。我们提出一种贝叶斯解释来弥合这一差距：将规划行为根植于不断演化的生成上下文之中。由于自然语言与LLMs内部内化的语言之间存在细微差异，随着模型自我生成的上下文不断积累，推理过程中的规划策略会发生转变，从而导致看似规划能力受损的现象。我们通过两项受控实验进一步验证了该模型：第一项为随机生成任务，展示了在人类提示下规划受到限制，但随着自我生成上下文的积累，规划能力逐渐增强；第二项为高斯采样任务，表明在基于自我生成序列进行条件化时，初始偏差显著降低。这些发现为理解LLMs在推理过程中如何进行前瞻性规划，提供了理论解释与实证支持。"
  },
  {
    "date": "2026-02-03",
    "title": "Learning to Repair Lean Proofs from Compiler Feedback",
    "authors": "Evan Wang, Simon Chess, Daniel Lee, Siyuan Ge, Ajit Mallavarapu, Vasily Ilin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02990v1",
    "source": "arXiv",
    "abstract": "As neural theorem provers become increasingly agentic, the ability to interpret and act on compiler feedback is critical. However, existing Lean datasets consist almost exclusively of correct proofs, offering little supervision for understanding and repairing failures. We study Lean proof repair as a supervised learning problem: given an erroneous proof and compiler feedback, predict both a corrected proof and a natural-language diagnosis grounded in the same feedback. We introduce APRIL (Automated Proof Repair in Lean), a dataset of 260,000 supervised tuples pairing systematically generated proof failures with compiler diagnostics and aligned repair and explanation targets. Training language models on APRIL substantially improves repair accuracy and feedback-conditioned reasoning; in our single-shot repair evaluation setting, a finetuned 4B-parameter model outperforms the strongest open-source baseline. We view diagnostic-conditioned supervision as a complementary training signal for feedback-using provers. Our dataset is available at \\href{https://huggingface.co/datasets/uw-math-ai/APRIL}{this link}.",
    "title_zh": "从编译器反馈中学习修复 Lean 证明",
    "abstract_zh": "随着神经定理证明器日益具备自主性，理解并响应编译器反馈的能力变得至关重要。然而，现有的 Lean 数据集几乎全部由正确证明构成，难以提供足够的监督信号来帮助模型理解并修复错误。本文将 Lean 证明修复问题视为一个监督学习任务：给定一个存在错误的证明及编译器反馈，模型需同时预测一个修正后的证明以及基于相同反馈的自然语言诊断。我们提出了 APRIL（Automated Proof Repair in Lean），一个包含 26 万组监督样本的数据集，其中系统性地生成了证明失败案例，并配以编译器诊断信息，以及对齐的修复结果与解释目标。在 APRIL 上训练语言模型显著提升了修复准确率和基于反馈的推理能力；在单次修复评估设置中，一个微调后的 40 亿参数模型超越了当前最强的开源基线。我们认为，基于诊断的监督信号可作为使用反馈的证明器的互补训练信号。我们的数据集已发布于 \\href{https://huggingface.co/datasets/uw-math-ai/APRIL}{此链接}。"
  },
  {
    "date": "2026-02-03",
    "title": "Testing Framework Migration with Large Language Models",
    "authors": "Altino Alves, João Eduardo Montandon, Andre Hora",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02964v1",
    "source": "arXiv",
    "abstract": "Python developers rely on two major testing frameworks: \\texttt{unittest} and \\texttt{Pytest}. While \\texttt{Pytest} offers simpler assertions, reusable fixtures, and better interoperability, migrating existing suites from \\texttt{unittest} remains a manual and time-consuming process. Automating this migration could substantially reduce effort and accelerate test modernization. In this paper, we investigate the capability of Large Language Models (LLMs) to automate test framework migrations from \\texttt{unittest} to \\texttt{Pytest}. We evaluate GPT 4o and Claude Sonnet 4 under three prompting strategies (Zero-shot, One-shot, and Chain-of-Thought) and two temperature settings (0.0 and 1.0). To support this analysis, we first introduce a curated dataset of real-world migrations extracted from the top 100 Python open-source projects. Next, we actually execute the LLM-generated test migrations in their respective test suites. Overall, we find that 51.5% of the LLM-generated test migrations failed, while 48.5% passed. The results suggest that LLMs can accelerate test migration, but there are often caveats. For example, Claude Sonnet 4 exhibited more conservative migrations (e.g., preserving class-based tests and legacy \\texttt{unittest} references), while GPT-4o favored more transformations (e.g., to function-based tests). We conclude by discussing multiple implications for practitioners and researchers.",
    "title_zh": "大型语言模型在测试框架迁移中的应用",
    "abstract_zh": "Python 开发者主要依赖两大测试框架：\\texttt{unittest} 和 \\texttt{Pytest}。尽管 \\texttt{Pytest} 提供了更简洁的断言语法、可复用的夹具（fixtures）以及更好的互操作性，但将现有的 \\texttt{unittest} 测试套件迁移到 \\texttt{Pytest} 仍是一个手动且耗时的过程。若能自动化这一迁移流程，将显著降低工作量并加速测试现代化进程。本文研究了大型语言模型（LLMs）在自动化从 \\texttt{unittest} 迁移至 \\texttt{Pytest} 测试框架方面的潜力。我们评估了 GPT-4o 和 Claude Sonnet 4 在三种提示策略（零样本、单样本和思维链）以及两种温度设置（0.0 和 1.0）下的表现。为支持该分析，我们首先构建了一个精心筛选的真实世界迁移案例数据集，数据来源于排名前 100 的 Python 开源项目。随后，我们实际在对应测试套件中执行了 LLM 生成的迁移代码。总体而言，51.5% 的 LLM 生成的测试迁移失败，而 48.5% 成功通过。结果表明，LLMs 能够加速测试迁移，但存在诸多需要注意的问题。例如，Claude Sonnet 4 的迁移策略更为保守（如保留基于类的测试结构和旧的 \\texttt{unittest} 引用），而 GPT-4o 则更倾向于进行深度重构（如转换为函数式测试）。最后，我们讨论了这些发现对实践者和研究者的多重启示。"
  },
  {
    "date": "2026-02-03",
    "title": "RPG-AE: Neuro-Symbolic Graph Autoencoders with Rare Pattern Mining for Provenance-Based Anomaly Detection",
    "authors": "Asif Tauhid, Sidahmed Benabderrahmane, Mohamad Altrabulsi, Ahamed Foisal, Talal Rahwan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02929v1",
    "source": "arXiv",
    "abstract": "Advanced Persistent Threats (APTs) are sophisticated, long-term cyberattacks that are difficult to detect because they operate stealthily and often blend into normal system behavior. This paper presents a neuro-symbolic anomaly detection framework that combines a Graph Autoencoder (GAE) with rare pattern mining to identify APT-like activities in system-level provenance data. Our approach first constructs a process behavioral graph using k-Nearest Neighbors based on feature similarity, then learns normal relational structure using a Graph Autoencoder. Anomaly candidates are identified through deviations between observed and reconstructed graph structure. To further improve detection, we integrate an rare pattern mining module that discovers infrequent behavioral co-occurrences and uses them to boost anomaly scores for processes exhibiting rare signatures. We evaluate the proposed method on the DARPA Transparent Computing datasets and show that rare-pattern boosting yields substantial gains in anomaly ranking quality over the baseline GAE. Compared with existing unsupervised approaches on the same benchmark, our single unified model consistently outperforms individual context-based detectors and achieves performance competitive with ensemble aggregation methods that require multiple separate detectors. These results highlight the value of coupling graph-based representation learning with classical pattern mining to improve both effectiveness and interpretability in provenance-based security anomaly detection.",
    "title_zh": "RPG-AE：基于罕见模式挖掘的神经符号图自编码器在溯源异常检测中的应用",
    "abstract_zh": "高级持续性威胁（APTs）是一类复杂且长期存在的网络攻击，因其隐蔽性强、常与正常系统行为融为一体，难以被察觉。本文提出了一种神经符号异常检测框架，将图自编码器（GAE）与稀有模式挖掘相结合，用于识别系统级溯源数据中的APT类行为。我们的方法首先基于特征相似性，利用k-近邻算法构建进程行为图，随后通过图自编码器学习正常的关系结构。异常候选者通过观测图结构与重构图结构之间的偏差来识别。为进一步提升检测效果，我们引入了稀有模式挖掘模块，用于发现罕见的行为共现模式，并利用这些稀有特征显著提升表现出异常签名的进程的异常评分。我们在DARPA透明计算数据集上对所提方法进行了评估，结果表明，引入稀有模式增强后，异常排序质量相比基线GAE模型有显著提升。与同一基准上现有的无监督方法相比，我们的单一统一模型始终优于各个基于上下文的独立检测器，且性能可与需要多个独立检测器的集成聚合方法相媲美。这些结果凸显了将基于图的表示学习与经典模式挖掘相结合，在提升溯源安全异常检测的检测效果与可解释性方面的价值。"
  },
  {
    "date": "2026-02-03",
    "title": "Quantum Circuit Generation via test-time learning with large language models",
    "authors": "Adriano Macarone-Palmieri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03466v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) can generate structured artifacts, but using them as dependable optimizers for scientific design requires a mechanism for iterative improvement under black-box evaluation. Here, we cast quantum circuit synthesis as a closed-loop, test-time optimization problem: an LLM proposes edits to a fixed-length gate list, and an external simulator evaluates the resulting state with the Meyer-Wallach (MW) global entanglement measure. We introduce a lightweight test-time learning recipe that can reuse prior high-performing candidates as an explicit memory trace, augments prompts with a score-difference feedback, and applies restart-from-the-best sampling to escape potential plateaus. Across fixed 20-qubit settings, the loop without feedback and restart-from-the-best improves random initial circuits over a range of gate budgets. To lift up this performance and success rate, we use the full learning strategy. For 25-qubit, it mitigates a pronounced performance plateau when naive querying is used. Beyond raw scores, we analyze the structure of synthesized states and find that high MW solutions can correspond to stabilizer or graph-state-like constructions, but full connectivity is not guaranteed due to the metric property and prompt design. These results illustrate both the promise and the pitfalls of memory evaluator-guided LLM optimization for circuit synthesis, highlighting the critical role of prior human-made theoretical theorem to optimally design a custom tool in support of research.",
    "title_zh": "通过大型语言模型在测试时学习生成量子电路",
    "abstract_zh": "大型语言模型（LLMs）能够生成结构化成果，但要将其作为科学设计中可靠的优化器，需要在黑箱评估条件下实现迭代改进的机制。本文将量子电路合成问题转化为一个闭环、测试时优化的问题：LLM提出对固定长度门列表的修改建议，外部模拟器则通过Meyer-Wallach（MW）全局纠缠度量来评估生成态的质量。我们提出了一种轻量级的测试时学习策略，该策略可复用先前表现优异的候选解作为显式记忆痕迹，通过在提示中加入得分差反馈信息，并采用“从最优解重启”的采样方式以突破潜在的性能平台期。在固定20量子比特的设置下，即使不使用反馈机制和“从最优解重启”策略，该闭环系统仍能优于随机初始化的电路，在多种门预算条件下实现性能提升。为进一步提高性能与成功率，我们采用了完整的学习策略。在25量子比特场景中，该策略有效缓解了在直接查询时出现的显著性能平台问题。除了原始得分外，我们还分析了合成态的结构特征，发现高MW值的解往往对应于稳定子态或图态类构造，但因度量本身的特性及提示设计的限制，全连接性并非必然结果。这些结果揭示了基于记忆-评估器引导的LLM优化在电路合成中的潜力与局限，强调了在设计支持科研的定制化工具时，人类先验理论定理的关键作用。"
  },
  {
    "date": "2026-02-03",
    "title": "SWE-Master: Unleashing the Potential of Software Engineering Agents via Post-Training",
    "authors": "Huatong Song, Lisheng Huang, Shuang Sun, Jinhao Jiang, Ran Le, Daixuan Cheng, Guoxin Chen, Yiwen Hu, Zongchao Chen, Wayne Xin Zhao, Yang Song, Tao Zhang, Ji-Rong Wen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03411v1",
    "source": "arXiv",
    "abstract": "In this technical report, we present SWE-Master, an open-source and fully reproducible post-training framework for building effective software engineering agents. SWE-Master systematically explores the complete agent development pipeline, including teacher-trajectory synthesis and data curation, long-horizon SFT, RL with real execution feedback, and inference framework design. Starting from an open-source base model with limited initial SWE capability, SWE-Master demonstrates how systematical optimization method can elicit strong long-horizon SWE task solving abilities. We evaluate SWE-Master on SWE-bench Verified, a standard benchmark for realistic software engineering tasks. Under identical experimental settings, our approach achieves a resolve rate of 61.4\\% with Qwen2.5-Coder-32B, substantially outperforming existing open-source baselines. By further incorporating test-time scaling~(TTS) with LLM-based environment feedback, SWE-Master reaches 70.8\\% at TTS@8, demonstrating a strong performance potential. SWE-Master provides a practical and transparent foundation for advancing reproducible research on software engineering agents. The code is available at https://github.com/RUCAIBox/SWE-Master.",
    "title_zh": "SWE-Master：通过后训练释放软件工程智能体的潜力",
    "abstract_zh": "在本技术报告中，我们提出了 SWE-Master，这是一个开源且完全可复现的后训练框架，用于构建高效的软件工程智能体。SWE-Master 系统性地探索了智能体开发的完整流程，涵盖教师轨迹生成与数据整理、长程监督微调（SFT）、基于真实执行反馈的强化学习，以及推理框架设计。从一个初始软件工程能力有限的开源基础模型出发，SWE-Master 展示了系统性优化方法如何激发智能体在长程软件工程任务上的强大求解能力。我们在 SWE-bench Verified 这一标准基准上对 SWE-Master 进行评估，该基准用于衡量真实场景下的软件工程任务表现。在相同的实验设置下，我们的方法在 Qwen2.5-Coder-32B 模型上实现了 61.4% 的问题解决率，显著优于现有的开源基线。通过进一步引入基于大语言模型的环境反馈的测试时扩展（TTS），SWE-Master 在 TTS@8 时达到 70.8% 的解决率，展现出强大的性能潜力。SWE-Master 为推进可复现的软件工程智能体研究提供了实用且透明的基础。代码已开源，地址为：https://github.com/RUCAIBox/SWE-Master。"
  },
  {
    "date": "2026-02-03",
    "title": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling",
    "authors": "Ning Ding, Fangcheng Liu, Kyungrae Kim, Linji Hao, Kyeng-Hun Lee, Hyeonmok Ko, Yehui Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03359v1",
    "source": "arXiv",
    "abstract": "Scaling Large Language Models (LLMs) typically relies on increasing the number of parameters or test-time computations to boost performance. However, these strategies are impractical for edge device deployment due to limited RAM and NPU resources. Despite hardware constraints, deploying performant LLM on edge devices such as smartphone remains crucial for user experience. To address this, we propose MeKi (Memory-based Expert Knowledge Injection), a novel system that scales LLM capacity via storage space rather than FLOPs. MeKi equips each Transformer layer with token-level memory experts that injects pre-stored semantic knowledge into the generation process. To bridge the gap between training capacity and inference efficiency, we employ a re-parameterization strategy to fold parameter matrices used during training into a compact static lookup table. By offloading the knowledge to ROM, MeKi decouples model capacity from computational cost, introducing zero inference latency overhead. Extensive experiments demonstrate that MeKi significantly outperforms dense LLM baselines with identical inference speed, validating the effectiveness of memory-based scaling paradigm for on-device LLMs. Project homepage is at https://github.com/ningding-o/MeKi.",
    "title_zh": "MeKi：基于记忆的专家知识注入，实现高效的大规模语言模型扩展",
    "abstract_zh": "大规模语言模型（LLM）的扩展通常依赖于增加参数量或测试时的计算量来提升性能。然而，由于边缘设备的内存（RAM）和神经网络处理单元（NPU）资源有限，这些策略在边缘设备部署中并不实用。尽管存在硬件限制，但在智能手机等边缘设备上部署高性能的LLM对于提升用户体验仍然至关重要。为此，我们提出了MeKi（基于内存的专家知识注入）系统，一种通过存储空间而非浮点运算量（FLOPs）来扩展LLM能力的新方法。MeKi在每个Transformer层中引入基于token级别的记忆专家，将预先存储的语义知识注入生成过程。为了弥合训练阶段容量与推理效率之间的差距，我们采用重参数化策略，将训练过程中使用的参数矩阵折叠为一个紧凑的静态查找表。通过将知识卸载至只读存储器（ROM），MeKi实现了模型容量与计算成本的解耦，从而引入零推理延迟开销。大量实验表明，MeKi在保持与密集LLM基线相同推理速度的前提下，显著优于后者，验证了基于内存扩展范式在设备端LLM中的有效性。项目主页见：https://github.com/ningding-o/MeKi。"
  },
  {
    "date": "2026-02-03",
    "title": "Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention",
    "authors": "Rakshith Vasudev, Melisa Russak, Dan Bikel, Waseem Alshikh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03338v1",
    "source": "arXiv",
    "abstract": "Proactive interventions by LLM critic models are often assumed to improve reliability, yet their effects at deployment time are poorly understood. We show that a binary LLM critic with strong offline accuracy (AUROC 0.94) can nevertheless cause severe performance degradation, inducing a 26 percentage point (pp) collapse on one model while affecting another by near zero pp. This variability demonstrates that LLM critic accuracy alone is insufficient to determine whether intervention is safe. We identify a disruption-recovery tradeoff: interventions may recover failing trajectories but also disrupt trajectories that would have succeeded. Based on this insight, we propose a pre-deployment test that uses a small pilot of 50 tasks to estimate whether intervention is likely to help or harm, without requiring full deployment. Across benchmarks, the test correctly anticipates outcomes: intervention degrades performance on high-success tasks (0 to -26 pp), while yielding a modest improvement on the high-failure ALFWorld benchmark (+2.8 pp, p=0.014). The primary value of our framework is therefore identifying when not to intervene, preventing severe regressions before deployment.",
    "title_zh": "代理的准确故障预测并不意味着有效的故障预防",
    "abstract_zh": "大语言模型（LLM）批评者模型的主动干预通常被认为能够提升系统可靠性，但其在实际部署时的效果却鲜为人知。我们发现，即使一个二元LLM批评者在离线测试中表现出极高的准确率（AUROC达0.94），仍可能引发严重的性能下降：在某一模型上导致26个百分点（pp）的显著崩溃，而在另一模型上几乎毫无影响（接近0 pp）。这种差异表明，仅凭LLM批评者的准确率不足以判断干预是否安全。我们识别出一种“干扰-恢复”权衡关系：干预虽可挽救失败的推理路径，但也可能干扰本可成功的路径。基于这一洞见，我们提出了一种预部署测试方法，仅需50个任务的小规模试点即可评估干预是否可能带来帮助或造成损害，而无需进行全面部署。在多个基准测试中，该测试均能正确预测结果：对于高成功率的任务，干预反而导致性能下降（-26 pp）；而对于高失败率的ALFWorld基准，干预则带来适度改善（+2.8 pp，p=0.014）。因此，本框架的核心价值在于识别出“不应干预”的场景，从而在部署前有效避免严重性能退化。"
  },
  {
    "date": "2026-02-03",
    "title": "Agentic Proposing: Enhancing Large Language Model Reasoning via Compositional Skill Synthesis",
    "authors": "Zhengbo Jiao, Shaobo Wang, Zifan Zhang, Xuan Ren, Wei Wang, Bing Zhao, Hu Wei, Linfeng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03279v1",
    "source": "arXiv",
    "abstract": "Advancing complex reasoning in large language models relies on high-quality, verifiable datasets, yet human annotation remains cost-prohibitive and difficult to scale. Current synthesis paradigms often face a recurring trade-off: maintaining structural validity typically restricts problem complexity, while relaxing constraints to increase difficulty frequently leads to inconsistent or unsolvable instances. To address this, we propose Agentic Proposing, a framework that models problem synthesis as a goal-driven sequential decision process where a specialized agent dynamically selects and composes modular reasoning skills. Through an iterative workflow of internal reflection and tool-use, we develop the Agentic-Proposer-4B using Multi-Granularity Policy Optimization (MGPO) to generate high-precision, verifiable training trajectories across mathematics, coding, and science. Empirical results demonstrate that downstream solvers trained on agent-synthesized data significantly outperform leading baselines and exhibit robust cross-domain generalization. Notably, a 30B solver trained on only 11,000 synthesized trajectories achieves a state-of-the-art 91.6% accuracy on AIME25, rivaling frontier-scale proprietary models such as GPT-5 and proving that a small volume of high-quality synthetic signals can effectively substitute for massive human-curated datasets.",
    "title_zh": "代理式提案：通过组合式技能合成增强大语言模型的推理能力",
    "abstract_zh": "在大型语言模型中推进复杂推理能力，依赖于高质量且可验证的数据集，但人工标注成本高昂且难以扩展。当前的合成范式常常面临一个反复出现的权衡：保持结构有效性通常会限制问题的复杂度，而放宽约束以提升难度则往往导致不一致或无法求解的实例。为解决这一问题，我们提出“代理提议”（Agentic Proposing）框架，将问题合成建模为一种目标驱动的序列决策过程，其中专门的代理能够动态选择并组合模块化的推理技能。通过结合内部反思与工具使用的迭代工作流，我们基于多粒度策略优化（MGPO）开发了 Agentic-Proposer-4B，成功生成了在数学、编程和科学领域均具备高精度与可验证性的训练轨迹。实证结果表明，基于代理合成数据训练的下游求解器显著优于现有领先基线，并展现出强大的跨领域泛化能力。值得注意的是，仅使用11,000条合成轨迹训练的30B规模求解器，在AIME25测试集上达到了91.6%的准确率，媲美GPT-5等前沿的超大规模专有模型，证明了少量高质量合成信号足以有效替代海量人工标注数据集。"
  },
  {
    "date": "2026-02-03",
    "title": "Exploring the Role of Tracing in AI-Supported Planning for Algorithmic Reasoning",
    "authors": "Yoshee Jain, Heejin Do, Zihan Wu, April Yi Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03197v1",
    "source": "arXiv",
    "abstract": "AI-powered planning tools show promise in supporting programming learners by enabling early, formative feedback on their thinking processes prior to coding. To date, however, most AI-supported planning tools rely on students' natural-language explanations, using LLMs to interpret learners' descriptions of their algorithmic intent. Prior to the emergence of LLM-based systems, CS education research extensively studied trace-based planning in pen-and-paper settings, demonstrating that reasoning through stepwise execution with explicit state transitions helps learners build and refine mental models of program behavior. Despite its potential, little is known about how tracing interacts with AI-mediated feedback and whether integrating tracing into AI-supported planning tools leads to different learning processes or interaction dynamics compared to natural-language-based planning alone. We study how requiring learners to produce explicit execution traces with an AI-supported planning tool affects their algorithmic reasoning. In a between-subjects study with 20 students, tracing shifted learners away from code-like, line-by-line descriptions toward more goal-driven reasoning about program behavior. Moreover, it led to more consistent partially correct solutions, although final coding performance remained comparable across conditions. Notably, tracing did not significantly affect the quality or reliability of LLM-generated feedback. These findings reveal tradeoffs in combining tracing with AI-supported planning and inform design guidelines for integrating natural language, tracing, and coding to support iterative reasoning throughout the programming process.",
    "title_zh": "探索追踪在AI辅助规划中的作用：面向算法推理",
    "abstract_zh": "基于人工智能的规划工具在支持编程学习者方面展现出巨大潜力，能够在其编写代码之前，提供关于其思维过程的早期、形成性反馈。然而，迄今为止，大多数基于AI的规划工具仍依赖学生以自然语言描述其算法意图，利用大型语言模型（LLM）来解析学习者对程序设计思路的说明。在LLM系统出现之前，计算机科学教育研究已广泛探讨了纸笔环境下的基于追踪的规划方法，研究发现，通过显式地逐步执行并追踪状态变化来推理程序行为，有助于学习者构建并完善对程序运行机制的心理模型。尽管如此，目前仍缺乏对追踪与AI反馈机制如何相互作用的深入理解，也尚不清楚将追踪整合进AI支持的规划工具，是否会导致与仅依赖自然语言描述的规划方式不同的学习过程或交互模式。\n\n本研究探讨了在AI支持的规划工具中要求学习者生成显式执行追踪，对其算法推理能力的影响。在一项包含20名学生的组间实验中，我们发现，要求进行追踪使学习者从类似代码的逐行描述，转向更具目标导向的程序行为推理。此外，追踪还促使学习者产生更一致的、部分正确的解决方案，尽管最终的编码表现两组之间并无显著差异。值得注意的是，追踪并未显著影响LLM生成反馈的质量或可靠性。\n\n这些发现揭示了在AI支持的规划中结合追踪所涉及的权衡，为设计融合自然语言、追踪与编码的工具提供了重要启示，有助于在整个编程过程中支持学习者进行迭代式思维与持续改进。"
  },
  {
    "date": "2026-02-03",
    "title": "Reinforcement Learning with Promising Tokens for Large Language Models",
    "authors": "Jing-Cheng Pang, Liang Lu, Xian Tang, Kun Jiang, Sijie Wu, Kai Zhang, Xubin Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03195v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning (RL) has emerged as a key paradigm for aligning and optimizing large language models (LLMs). Standard approaches treat the LLM as the policy and apply RL directly over the full vocabulary space. However, this formulation includes the massive tail of contextually irrelevant tokens in the action space, which could distract the policy from focusing on decision-making among the truly reasonable tokens. In this work, we verify that valid reasoning paths could inherently concentrate within a low-rank subspace. Based on this insight, we introduce Reinforcement Learning with Promising Tokens (RLPT), a framework that mitigates the action space issue by decoupling strategic decision-making from token generation. Specifically, RLPT leverages the semantic priors of the base model to identify a dynamic set of \\emph{promising tokens} and constrains policy optimization exclusively to this refined subset via masking. Theoretical analysis and empirical results demonstrate that RLPT effectively reduces gradient variance, stabilizes the training process, and improves sample efficiency. Experiment results on math, coding, and telecom reasoning show that RLPT outperforms standard RL baselines and integrates effectively across various model sizes (4B and 8B) and RL algorithms (GRPO and DAPO).",
    "title_zh": "基于有前景标记的大型语言模型强化学习",
    "abstract_zh": "强化学习（RL）已成为对齐和优化大语言模型（LLM）的关键范式。传统方法将LLM视为策略，并直接在完整的词汇空间上应用强化学习。然而，这种设定将大量语境无关的词元（tokens）纳入动作空间，可能分散策略对真正合理词元之间决策的注意力。在本工作中，我们验证了有效的推理路径本质上可集中于一个低秩子空间。基于这一洞察，我们提出了“有希望词元的强化学习”（Reinforcement Learning with Promising Tokens, RLPT）框架，通过将战略决策与词元生成解耦，缓解动作空间过大的问题。具体而言，RLPT利用基础模型的语义先验，动态识别出一组**有希望的词元**，并通过掩码机制将策略优化严格限制在这一精炼子集内。理论分析与实证结果表明，RLPT能有效降低梯度方差，稳定训练过程，并提升样本效率。在数学、编程和电信推理任务上的实验结果表明，RLPT优于标准强化学习基线方法，并能有效适配不同模型规模（4B和8B）以及多种强化学习算法（GRPO和DAPO）。"
  },
  {
    "date": "2026-02-03",
    "title": "Synthesizing File-Level Data for Unit Test Generation with Chain-of-Thoughts via Self-Debugging",
    "authors": "Ziyue Hua, Tianyu Chen, Yeyun Gong, Shuai Lu, Peng Cheng, Qinglin Zhu, Yibo He, Yingjie Fu, Wenpin Jiao, Wei Yang, Tao Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03181v1",
    "source": "arXiv",
    "abstract": "Automatic unit test (UT) generation is essential for software quality assurance, but existing approaches--including symbolic execution, search-based approaches, and recent LLM-based generators--struggle to produce human-quality tests with correct, meaningful assertions and reliable chain-of-thought (CoT) explanations. We identify a gap in UT training data: repository-mined tests lack developer CoTs, while LLM-distilled CoTs are often incorrect or incomplete. To address this issue, we propose a novel data-distillation approach that uses self-debugging to produce high-quality UT training examples paired with faithful CoTs. Our approach combines (1) guided test repair, a heuristic loop (error-, failure-, and coverage-focused steps) that asks the used model to diagnose and iteratively fix generated tests, and (2) CoT compression, which compacts original and debugging CoTs into concise explanations that directly justify correct tests. We apply this pipeline to a large corpus of open-source projects to construct a dataset of 74,518 high-quality <focal method, test, CoT> examples, and then use it for supervised fine-tuning of a base model. An empirical evaluation shows that the fine-tuned model achieves high UT generation effectiveness: it attains a pass rate of 36.17% on test assertions, a branch coverage of 43.90%, and a mutation score of 88.66%, substantially higher than state-of-the-art commercial models like o4-mini.",
    "title_zh": "通过自调试的思维链实现文件级数据的综合以生成单元测试",
    "abstract_zh": "自动化单元测试（UT）生成对于保障软件质量至关重要，但现有方法——包括符号执行、基于搜索的方法以及近期的基于大语言模型（LLM）的生成器——在生成具备正确且有意义断言、并附有可靠思维链（CoT）解释的人类水平测试方面仍面临挑战。我们发现当前UT训练数据存在明显缺口：从代码仓库中挖掘的测试缺乏开发者的思维链，而由LLM提炼出的思维链则常常错误或不完整。为解决这一问题，我们提出一种新颖的数据提炼方法，通过自调试机制生成高质量的UT训练样本，并配以忠实可信的思维链。该方法结合了两个核心组件：（1）引导式测试修复，即采用一种启发式循环（包含错误检测、失败分析和覆盖率优化等步骤），让所用模型诊断并迭代修复生成的测试；（2）思维链压缩，将原始思维链与调试过程中的思维链进行整合与精炼，生成简洁明了的解释，直接支撑正确测试的合理性。我们将该流程应用于大规模开源项目语料库，构建了一个包含74,518个高质量的<目标方法, 测试用例, 思维链>三元组的数据集，并以此对基础模型进行监督微调。实证评估表明，微调后的模型在单元测试生成方面表现出显著优势：其测试断言通过率达到36.17%，分支覆盖率达43.90%，突变测试得分高达88.66%，远超当前最先进的商业模型（如o4-mini）。"
  },
  {
    "date": "2026-02-03",
    "title": "ReMiT: RL-Guided Mid-Training for Iterative LLM Evolution",
    "authors": "Junjie Huang, Jiarui Qin, Di Yin, Weiwen Liu, Yong Yu, Xing Sun, Weinan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03075v1",
    "source": "arXiv",
    "abstract": "Standard training pipelines for large language models (LLMs) are typically unidirectional, progressing from pre-training to post-training. However, the potential for a bidirectional process--where insights from post-training retroactively improve the pre-trained foundation--remains unexplored. We aim to establish a self-reinforcing flywheel: a cycle in which reinforcement learning (RL)-tuned model strengthens the base model, which in turn enhances subsequent post-training performance, requiring no specially trained teacher or reference model. To realize this, we analyze training dynamics and identify the mid-training (annealing) phase as a critical turning point for model capabilities. This phase typically occurs at the end of pre-training, utilizing high-quality corpora under a rapidly decaying learning rate. Building upon this insight, we introduce ReMiT (Reinforcement Learning-Guided Mid-Training). Specifically, ReMiT leverages the reasoning priors of RL-tuned models to dynamically reweight tokens during the mid-training phase, prioritizing those pivotal for reasoning. Empirically, ReMiT achieves an average improvement of 3\\% on 10 pre-training benchmarks, spanning math, code, and general reasoning, and sustains these gains by over 2\\% throughout the post-training pipeline. These results validate an iterative feedback loop, enabling continuous and self-reinforcing evolution of LLMs.",
    "title_zh": "ReMiT：基于强化学习的训练中迭代式大语言模型演化",
    "abstract_zh": "大型语言模型（LLM）的标准训练流程通常是单向的，从预训练逐步过渡到后训练。然而，双向流程的潜力——即后训练阶段获得的洞见可反过来优化预训练基础模型——尚未被充分探索。我们旨在构建一个自我强化的飞轮机制：通过强化学习（RL）微调的模型增强基础模型，而这一增强又反过来提升后续后训练的表现，整个过程无需依赖专门训练的教师模型或参考模型。为实现这一目标，我们分析了训练过程中的动态变化，识别出中段训练（退火）阶段是模型能力发展的关键转折点。该阶段通常出现在预训练末期，利用高质量语料库，并在学习率快速衰减的条件下进行。基于这一发现，我们提出了 ReMiT（强化学习引导的中段训练）。具体而言，ReMiT 利用 RL 微调模型所具备的推理先验知识，在中段训练阶段动态重加权 token，优先关注对推理至关重要的关键 token。实证结果表明，ReMiT 在涵盖数学、代码和通用推理的10个预训练基准上实现了平均3%的性能提升，并在后续整个后训练流程中保持超过2%的持续增益。这些结果验证了迭代反馈循环的有效性，推动了大型语言模型的持续、自我强化的演进。"
  },
  {
    "date": "2026-02-03",
    "title": "Bongards at the Boundary of Perception and Reasoning: Programs or Language?",
    "authors": "Cassidy Langenfeld, Claas Beger, Gloria Geng, Wasu Top Piriyakulkij, Keya Hu, Yewen Pu, Kevin Ellis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03038v1",
    "source": "arXiv",
    "abstract": "Vision-Language Models (VLMs) have made great strides in everyday visual tasks, such as captioning a natural image, or answering commonsense questions about such images. But humans possess the puzzling ability to deploy their visual reasoning abilities in radically new situations, a skill rigorously tested by the classic set of visual reasoning challenges known as the Bongard problems. We present a neurosymbolic approach to solving these problems: given a hypothesized solution rule for a Bongard problem, we leverage LLMs to generate parameterized programmatic representations for the rule and perform parameter fitting using Bayesian optimization. We evaluate our method on classifying Bongard problem images given the ground truth rule, as well as on solving the problems from scratch.",
    "title_zh": "邦加德在感知与推理的边界：程序还是语言？",
    "abstract_zh": "视觉-语言模型（VLMs）在日常视觉任务中取得了显著进展，例如为自然图像生成描述，或回答关于这些图像的常识性问题。然而，人类具备一种令人困惑的能力：能够在完全新颖的情境中运用其视觉推理能力，这一能力在经典的“博加德问题”（Bongard problems）系列视觉推理挑战中得到了严格检验。本文提出了一种神经符号方法来解决这些问题：给定一个关于博加德问题的假设解题规则，我们利用大语言模型（LLMs）生成该规则的参数化程序表示，并通过贝叶斯优化进行参数拟合。我们在两种任务上评估了该方法：一是根据已知的正确规则对博加德问题图像进行分类；二是从零开始解决这些难题。"
  },
  {
    "date": "2026-02-03",
    "title": "Layered Modal ML: Syntax and Full Abstraction",
    "authors": "Haoxuan Yin, Andrzej S. Murawski, C. -H. Luke Ong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03033v1",
    "source": "arXiv",
    "abstract": "MetaML-style metaprogramming languages allow programmers to construct, manipulate and run code. In the presence of higher-order references for code, ensuring type safety is challenging, as free variables can escape their binders. In this paper, we present Layered Modal ML (LMML), \\textit{the first metaprogramming language that supports storing and running open code under a strong type safety guarantee}. The type system utilises contextual modal types to track and reason about free variables in code explicitly. A crucial concern in metaprogramming-based program optimisations is whether the optimised program preserves the meaning of the original program. Addressing this question requires a notion of program equivalence and techniques to reason about it. In this paper, we provide a semantic model that captures contextual equivalence for LMML, establishing \\textit{the first full abstraction result for an imperative MetaML-style language}. Our model is based on traces derived via operational game semantics, where the meaning of a program is modelled by its possible interactions with the environment. We also establish a novel closed instances of use theorem that accounts for both call-by-value and call-by-name closing substitutions.",
    "title_zh": "分层模态ML：语法与完全抽象",
    "abstract_zh": "MetaML风格的元编程语言允许程序员构造、操作并执行代码。当代码中存在高阶引用时，确保类型安全变得极具挑战性，因为自由变量可能逃逸其绑定作用域。本文提出了一种分层模态ML（Layered Modal ML，简称LMML），它是**首个支持在强类型安全保证下存储和运行开放代码的元编程语言**。其类型系统采用上下文模态类型来显式追踪和推理代码中的自由变量。在基于元编程的程序优化中，一个关键问题是：优化后的程序是否保持了原程序的语义。要回答这一问题，需要引入程序等价性的概念以及相应的推理技术。本文提供了一个语义模型，用于刻画LMML中的上下文等价性，从而实现了**首个针对命令式MetaML风格语言的完全抽象结果**。我们的模型基于通过操作性博弈语义生成的执行轨迹，将程序的语义建模为其与环境之间可能的交互行为。此外，我们还建立了一个新颖的“闭合实例使用定理”，该定理同时适用于按值和按名的闭合代换。"
  },
  {
    "date": "2026-02-03",
    "title": "CVE-Factory: Scaling Expert-Level Agentic Tasks for Code Security Vulnerability",
    "authors": "Xianzhen Luo, Jingyuan Zhang, Shiqi Zhou, Rain Huang, Chuan Xiao, Qingfu Zhu, Zhiyuan Ma, Xing Yue, Yang Yue, Wencong Zeng, Wanxiang Che",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03012v1",
    "source": "arXiv",
    "abstract": "Evaluating and improving the security capabilities of code agents requires high-quality, executable vulnerability tasks. However, existing works rely on costly, unscalable manual reproduction and suffer from outdated data distributions. To address these, we present CVE-Factory, the first multi-agent framework to achieve expert-level quality in automatically transforming sparse CVE metadata into fully executable agentic tasks. Cross-validation against human expert reproductions shows that CVE-Factory achieves 95\\% solution correctness and 96\\% environment fidelity, confirming its expert-level quality. It is also evaluated on the latest realistic vulnerabilities and achieves a 66.2\\% verified success. This automation enables two downstream contributions. First, we construct LiveCVEBench, a continuously updated benchmark of 190 tasks spanning 14 languages and 153 repositories that captures emerging threats including AI-tooling vulnerabilities. Second, we synthesize over 1,000 executable training environments, the first large-scale scaling of agentic tasks in code security. Fine-tuned Qwen3-32B improves from 5.3\\% to 35.8\\% on LiveCVEBench, surpassing Claude 4.5 Sonnet, with gains generalizing to Terminal Bench (12.5\\% to 31.3\\%). We open-source CVE-Factory, LiveCVEBench, Abacus-cve (fine-tuned model), training dataset, and leaderboard. All resources are available at https://github.com/livecvebench/CVE-Factory .",
    "title_zh": "CVE-Factory：面向代码安全漏洞的专家级智能体任务规模化",
    "abstract_zh": "评估并提升代码智能体的安全能力，需要高质量、可执行的漏洞任务。然而，现有研究依赖于成本高昂且难以扩展的手动复现，且面临数据分布过时的问题。为解决上述挑战，我们提出 CVE-Factory——首个多智能体框架，能够自动将稀疏的 CVE 元数据转化为完全可执行的智能体任务，并达到专家级质量。与人工专家复现结果进行交叉验证表明，CVE-Factory 在解决方案正确性上达到 95%，环境保真度达 96%，充分证明其具备专家级质量。该框架在最新真实漏洞上的评估中实现了 66.2% 的验证成功率。这一自动化能力推动了两项下游贡献：第一，我们构建了 LiveCVEBench，一个持续更新的基准测试集，包含 190 个任务，覆盖 14 种编程语言和 153 个代码仓库，能够捕捉包括 AI 工具链漏洞在内的新兴安全威胁；第二，我们生成了超过 1,000 个可执行的训练环境，首次实现了代码安全领域智能体任务的大规模扩展。经过微调的 Qwen3-32B 模型在 LiveCVEBench 上的表现从 5.3% 提升至 35.8%，超越 Claude 4.5 Sonnet，且性能提升在 Terminal Bench 上也得到验证（从 12.5% 提升至 31.3%）。我们已将 CVE-Factory、LiveCVEBench、Abacus-cve（微调模型）、训练数据集及排行榜全部开源，所有资源均可在 https://github.com/livecvebench/CVE-Factory 获取。"
  },
  {
    "date": "2026-02-03",
    "title": "Distilling LLM Reasoning into Graph of Concept Predictors",
    "authors": "Ziyang Yu, Liang Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03006v1",
    "source": "arXiv",
    "abstract": "Deploying Large Language Models (LLMs) for discriminative workloads is often limited by inference latency, compute, and API costs at scale. Active distillation reduces these costs by querying an LLM oracle to train compact discriminative students, but most pipelines distill only final labels, discarding intermediate reasoning signals and offering limited diagnostics of what reasoning is missing and where errors arise. We propose Graph of Concept Predictors (GCP), a reasoning-aware active distillation framework that externalizes the teacher's decision process as a directed acyclic graph and mirrors it with modular concept predictors in the student. GCP enhances sample efficiency through a graph-aware acquisition strategy that targets uncertainty and disagreement at critical reasoning nodes. Additionally, it improves training stability and efficiency by performing targeted sub-module retraining, which attributes downstream loss to specific concept predictors and updates only the most influential modules. Experiments on eight NLP classification benchmarks demonstrate that GCP enhances performance under limited annotation budgets while yielding more interpretable and controllable training dynamics. Code is available at: https://github.com/Ziyang-Yu/GCP.",
    "title_zh": "将大语言模型的推理过程提炼为概念预测器图",
    "abstract_zh": "将大型语言模型（LLMs）应用于判别性任务时，通常受限于推理延迟、计算资源以及大规模应用下的API成本。主动蒸馏通过查询LLM“教师”来训练轻量级的判别性“学生”模型，从而降低这些成本。然而，大多数现有蒸馏流程仅利用最终的标签信息，忽略了中间推理过程中的信号，导致难以诊断推理缺失的具体环节以及错误发生的位置。为此，我们提出图式概念预测器（Graph of Concept Predictors, GCP），一种具备推理感知能力的主动蒸馏框架。GCP将教师模型的决策过程显式建模为有向无环图（DAG），并在学生模型中通过模块化的概念预测器进行对应映射。GCP通过一种图感知的样本选择策略，聚焦于关键推理节点上的不确定性和分歧，显著提升样本效率。此外，通过针对性地对子模块进行重训练，GCP能够将下游损失归因于特定的概念预测器，并仅更新最具影响力的模块，从而提升训练的稳定性和效率。在八个自然语言处理分类基准上的实验表明，GCP在标注预算有限的情况下仍能显著提升模型性能，同时提供更具可解释性和可控性的训练过程。代码已开源，地址为：https://github.com/Ziyang-Yu/GCP。"
  },
  {
    "date": "2026-02-03",
    "title": "Beyond Tokens: Semantic-Aware Speculative Decoding for Efficient Inference by Probing Internal States",
    "authors": "Ximing Dong, Shaowei Wang, Dayi Lin, Boyuan Chen, Ahmed E. Hassan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03708v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) achieve strong performance across many tasks but suffer from high inference latency due to autoregressive decoding. The issue is exacerbated in Large Reasoning Models (LRMs), which generate lengthy chains of thought. While speculative decoding accelerates inference by drafting and verifying multiple tokens in parallel, existing methods operate at the token level and ignore semantic equivalence (i.e., different token sequences expressing the same meaning), leading to inefficient rejections. We propose SemanticSpec, a semantic-aware speculative decoding framework that verifies entire semantic sequences instead of tokens. SemanticSpec introduces a semantic probability estimation mechanism that probes the model's internal hidden states to assess the likelihood of generating sequences with specific meanings.Experiments on four benchmarks show that SemanticSpec achieves up to 2.7x speedup on DeepSeekR1-32B and 2.1x on QwQ-32B, consistently outperforming token-level and sequence-level baselines in both efficiency and effectiveness.",
    "title_zh": "超越令牌：通过探测内部状态实现语义感知的推测解码以实现高效推理",
    "abstract_zh": "大型语言模型（LLMs）在众多任务上表现出色，但其自回归解码机制导致推理延迟较高。这一问题在大型推理模型（LRMs）中尤为突出，因为它们需要生成较长的思维链。虽然推测解码通过并行地草拟和验证多个标记来加速推理，但现有方法仅在标记层面操作，忽略了语义等价性（即不同标记序列表达相同含义），从而导致大量无效拒绝。我们提出了SemanticSpec——一种语义感知的推测解码框架，它不再逐标记验证，而是对整个语义序列进行验证。SemanticSpec引入了一种语义概率估计机制，通过探测模型内部的隐藏状态，评估生成具有特定语义的序列的可能性。在四个基准测试上的实验表明，SemanticSpec在DeepSeekR1-32B上实现了最高达2.7倍的加速，在QwQ-32B上实现了2.1倍加速，无论在效率还是效果上均持续优于现有的标记级和序列级基线方法。"
  },
  {
    "date": "2026-02-03",
    "title": "Don't believe everything you read: Understanding and Measuring MCP Behavior under Misleading Tool Descriptions",
    "authors": "Zhihao Li, Boyang Ma, Xuelong Dai, Minghui Xu, Yue Zhang, Biwei Yan, Kun Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03580v1",
    "source": "arXiv",
    "abstract": "The Model Context Protocol (MCP) enables large language models to invoke external tools through natural-language descriptions, forming the foundation of many AI agent applications. However, MCP does not enforce consistency between documented tool behavior and actual code execution, even though MCP Servers often run with broad system privileges. This gap introduces a largely unexplored security risk. We study how mismatches between externally presented tool descriptions and underlying implementations systematically shape the mental models and decision-making behavior of intelligent agents. Specifically, we present the first large-scale study of description-code inconsistency in the MCP ecosystem. We design an automated static analysis framework and apply it to 10,240 real-world MCP Servers across 36 categories. Our results show that while most servers are highly consistent, approximately 13% exhibit substantial mismatches that can enable undocumented privileged operations, hidden state mutations, or unauthorized financial actions. We further observe systematic differences across application categories, popularity levels, and MCP marketplaces. Our findings demonstrate that description-code inconsistency is a concrete and prevalent attack surface in MCP-based AI agents, and motivate the need for systematic auditing and stronger transparency guarantees in future agent ecosystems.",
    "title_zh": "不要轻信你读到的一切：理解并衡量在误导性工具描述下的MCP行为",
    "abstract_zh": "模型上下文协议（MCP）使大型语言模型能够通过自然语言描述调用外部工具，构成了众多AI智能体应用的基础。然而，MCP并未强制要求工具的文档行为与实际代码执行保持一致，尽管MCP服务器通常以广泛的系统权限运行。这一差距带来了大量尚未被充分探索的安全风险。我们研究了外部呈现的工具描述与底层实现之间的不一致如何系统性地影响智能体的认知模型和决策行为。具体而言，我们首次对MCP生态系统中的描述-代码不一致性进行了大规模研究。我们设计了一套自动化静态分析框架，并将其应用于涵盖36个类别、共计10,240个真实世界的MCP服务器。结果显示，虽然大多数服务器在描述与实现之间高度一致，但约有13%存在显著不一致，可能导致未记录的特权操作、隐藏的状态变更或未经授权的金融行为。此外，我们还观察到不同应用类别、流行度水平以及MCP市场之间存在系统性差异。我们的研究证明，描述-代码不一致性是基于MCP的AI智能体中一个真实且普遍存在的攻击面，这凸显了未来智能体生态系统中亟需开展系统性审计以及更强透明度保障的必要性。"
  },
  {
    "date": "2026-02-03",
    "title": "Causal Inference for the Effect of Code Coverage on Bug Introduction",
    "authors": "Lukas Schulte, Gordon Fraser, Steffen Herbold",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03585v1",
    "source": "arXiv",
    "abstract": "Context: Code coverage is widely used as a software quality assurance measure. However, its effect, and specifically the advisable dose, are disputed in both the research and engineering communities. Prior work reports only correlational associations, leaving results vulnerable to confounding factors. Objective: We aim to quantify the causal effect of code coverage (exposure) on bug introduction (outcome) in the context of mature JavaScript and TypeScript open source projects, addressing both the overall effect and its variance across coverage levels. Method: We construct a causal directed acyclic graph to identify confounders within the software engineering process, modeling key variables from the source code, issue- and review systems, and continuous integration. Using generalized propensity score adjustment, we will apply doubly robust regression-based causal inference for continuous exposure to a novel dataset of bug-introducing and non-bug-introducing changes. We estimate the average treatment effect and dose-response relationship to examine potential non-linear patterns (e.g., thresholds or diminishing returns) within the projects of our dataset.",
    "title_zh": "代码覆盖率对引入缺陷影响的因果推断",
    "abstract_zh": "代码覆盖率被广泛用作软件质量保证的度量指标。然而，其实际效果，特别是推荐的使用程度，在研究界和工程界均存在争议。以往的研究仅报告了相关性关联，使得结果容易受到混杂因素的影响。  \n目标：我们旨在量化代码覆盖率（暴露因素）对缺陷引入（结果变量）的因果效应，研究对象为成熟的 JavaScript 和 TypeScript 开源项目，既评估整体效应，也分析不同覆盖率水平下的效应差异。  \n方法：我们构建了一个因果有向无环图（DAG），以识别软件工程流程中的混杂因素，建模来自源代码、问题与评审系统以及持续集成系统的多个关键变量。通过广义倾向得分调整，我们采用双重稳健的回归型因果推断方法，对一个包含引入缺陷与未引入缺陷的变更的新数据集进行分析。我们估计平均处理效应（ATE）及剂量-反应关系，以检验项目数据集中可能存在的非线性模式（如阈值效应或边际递减效应）。"
  },
  {
    "date": "2026-02-03",
    "title": "Beyond Blame: Rethinking SZZ with Knowledge Graph Search",
    "authors": "Yu Shi, Hao Li, Bram Adams, Ahmed E. Hassan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.02934v1",
    "source": "arXiv",
    "abstract": "Identifying Bug-Inducing Commits (BICs) is fundamental for understanding software defects and enabling downstream tasks such as defect prediction and automated program repair. Yet existing SZZ-based approaches are limited by their reliance on git blame, which restricts the search space to commits that directly modified the fixed lines. Our preliminary study on 2,102 validated bug-fixing commits reveals that this limitation is significant: over 40% of cases cannot be solved by blame alone, as 28% of BICs require traversing commit history beyond blame results and 14% are blameless. We present AgenticSZZ, the first approach to apply Temporal Knowledge Graphs (TKGs) to software evolution analysis. AgenticSZZ reframes BIC identification from a ranking problem over blame commits into a graph search problem, where temporal ordering is fundamental to causal reasoning about bug introduction. The approach operates in two phases: (1) constructing a TKG that encodes commits with temporal and structural relationships, expanding the search space by traversing file history backward from two reference points (blame commits and the BFC); and (2) leveraging an LLM agent to navigate the graph using specialized tools for candidate exploration and causal analysis. Evaluation on three datasets shows that AgenticSZZ achieves F1-scores of 0.48 to 0.74, with statistically significant improvements over state-of-the-art by up to 27%. Our ablation study confirms that both components are essential, reflecting a classic exploration-exploitation trade-off: the TKG expands the search space while the agent provides intelligent selection. By transforming BIC identification into a graph search problem, we open a new research direction for temporal and causal reasoning in software evolution analysis.",
    "title_zh": "超越责备：基于知识图谱搜索重新思考SZZ",
    "abstract_zh": "识别引入缺陷的提交（BICs）对于理解软件缺陷以及支持缺陷预测、自动化程序修复等下游任务至关重要。然而，现有的基于SZZ的方法受限于对git blame的依赖，这使得搜索范围仅限于直接修改修复行的提交。我们对2,102个已验证的修复缺陷提交进行的初步研究表明，这一限制具有显著影响：超过40%的情况无法仅通过blame解决，其中28%的BIC需要在blame结果之外回溯提交历史，另有14%的BIC根本无法通过blame定位。\n\n为此，我们提出了AgenticSZZ，这是首个将时间知识图谱（TKGs）应用于软件演化分析的方法。AgenticSZZ将BIC识别从对blame提交的排序问题，重构为一个基于图的搜索问题，其中时间顺序成为因果推理缺陷引入的关键。该方法分为两个阶段：（1）构建一个时间知识图谱，编码提交之间的时空关系，通过从两个参考点（blame提交和BFC）向后遍历文件历史，显著扩展搜索空间；（2）利用大语言模型（LLM）代理，借助专用工具在图中导航，实现候选提交的探索与因果分析。\n\n在三个数据集上的评估表明，AgenticSZZ的F1分数达到0.48至0.74，相比当前最先进方法，提升幅度高达27%，且具有统计显著性。消融实验进一步证实，两个组件均不可或缺，体现了经典的探索与利用之间的权衡：TKG扩展了搜索空间，而代理则实现了智能筛选。通过将BIC识别转化为图搜索问题，我们为软件演化分析中的时间与因果推理开辟了全新的研究方向。"
  },
  {
    "date": "2026-02-03",
    "title": "A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces",
    "authors": "Mingxuan Du, Benfeng Xu, Chiwei Zhu, Shaohan Wang, Pengyu Wang, Xiaorui Wang, Zhendong Mao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03442v1",
    "source": "arXiv",
    "abstract": "Frontier language models have demonstrated strong reasoning and long-horizon tool-use capabilities. However, existing RAG systems fail to leverage these capabilities. They still rely on two paradigms: (1) designing an algorithm that retrieves passages in a single shot and concatenates them into the model's input, or (2) predefining a workflow and prompting the model to execute it step-by-step. Neither paradigm allows the model to participate in retrieval decisions, preventing efficient scaling with model improvements. In this paper, we introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model. A-RAG provides three retrieval tools: keyword search, semantic search, and chunk read, enabling the agent to adaptively search and retrieve information across multiple granularities. Experiments on multiple open-domain QA benchmarks show that A-RAG consistently outperforms existing approaches with comparable or lower retrieved tokens, demonstrating that A-RAG effectively leverages model capabilities and dynamically adapts to different RAG tasks. We further systematically study how A-RAG scales with model size and test-time compute. We will release our code and evaluation suite to facilitate future research. Code and evaluation suite are available at https://github.com/Ayanami0730/arag.",
    "title_zh": "A-RAG：通过分层检索接口实现智能体检索增强生成的扩展",
    "abstract_zh": "前沿语言模型已展现出强大的推理能力和长周期工具使用能力。然而，现有的检索增强生成（RAG）系统尚未能有效利用这些能力。它们仍依赖于两种范式：（1）设计一种算法，一次性检索段落并将其拼接为模型输入；（2）预先定义工作流程，并提示模型逐步执行。这两种范式均无法让模型参与检索决策过程，从而限制了系统随模型能力提升而高效扩展的潜力。本文提出A-RAG，一种代理式RAG框架，该框架将分层检索接口直接暴露给模型。A-RAG提供三种检索工具：关键词搜索、语义搜索和段落读取，使智能体能够根据需求在多个粒度上自适应地搜索与获取信息。在多个开放域问答基准上的实验表明，A-RAG在保持或减少检索词元数量的同时，持续优于现有方法，充分证明了其有效利用模型能力并动态适应不同RAG任务的特性。我们进一步系统性地研究了A-RAG在模型规模和推理时计算资源方面的扩展性。我们将公开代码与评估套件，以促进未来研究。代码与评估套件请访问：https://github.com/Ayanami0730/arag。"
  },
  {
    "date": "2026-02-03",
    "title": "Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning",
    "authors": "Zhicheng Yang, Zhijiang Guo, Yinya Huang, Yongxin Wang, Wenlei Shi, Yiwei Wang, Xiaodan Liang, Jing Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03249v1",
    "source": "arXiv",
    "abstract": "Scaling test-time compute via long Chain-ofThought unlocks remarkable gains in reasoning capabilities, yet it faces practical limits due to the linear growth of KV cache and quadratic attention complexity. In this paper, we introduce Accordion-Thinking, an end-to-end framework where LLMs learn to self-regulate the granularity of the reasoning steps through dynamic summarization. This mechanism enables a Fold inference mode, where the model periodically summarizes its thought process and discards former thoughts to reduce dependency on historical tokens. We apply reinforcement learning to incentivize this capability further, uncovering a critical insight: the accuracy gap between the highly efficient Fold mode and the exhaustive Unfold mode progressively narrows and eventually vanishes over the course of training. This phenomenon demonstrates that the model learns to encode essential reasoning information into compact summaries, achieving effective compression of the reasoning context. Our Accordion-Thinker demonstrates that with learned self-compression, LLMs can tackle complex reasoning tasks with minimal dependency token overhead without compromising solution quality, and it achieves a 3x throughput while maintaining accuracy on a 48GB GPU memory configuration, while the structured step summaries provide a human-readable account of the reasoning process.",
    "title_zh": "手风琴式思维：用于高效且可读的大型语言模型推理的自我调节步骤摘要",
    "abstract_zh": "通过在推理阶段扩展思维链（Chain-of-Thought）的长度，可以显著提升大语言模型的推理能力，但这一方法受限于键值缓存（KV cache）的线性增长以及注意力计算的二次复杂度。本文提出了一种端到端框架——Accordion-Thinking，其中大语言模型通过动态摘要机制，自主调节推理步骤的粒度。该机制支持“折叠”（Fold）推理模式，即模型定期对自身思考过程进行总结，并丢弃早期的推理内容，从而降低对历史 token 的依赖。我们进一步采用强化学习来激励这一能力，发现一个关键洞见：在训练过程中，高效“折叠”模式与耗时的“展开”（Unfold）模式之间的准确率差距逐渐缩小，最终完全消失。这一现象表明，模型能够将关键推理信息高效编码至紧凑的摘要中，实现推理上下文的有效压缩。我们的 Accordion-Thinker 框架证明，通过学习到的自我压缩机制，大语言模型可以在几乎不增加 token 依赖的前提下，完成复杂的推理任务，同时保持解决方案的高质量。在 48GB 显存配置下，该方法实现了 3 倍的吞吐量提升，且准确率不受影响，同时结构化的步骤摘要还提供了人类可读的推理过程记录。"
  },
  {
    "date": "2026-02-03",
    "title": "Beyond Quantity: Trajectory Diversity Scaling for Code Agents",
    "authors": "Guhong Chen, Chenghao Sun, Cheng Fu, Qiyao Wang, Zhihong Huang, Chaopeng Wei, Guangxu Chen, Feiteng Fang, Ahmadreza Argha, Bing Zhao, Xander Xu, Qi Han, Hamid Alinejad-Rokny, Qiang Qu, Binhua Li, Shiwen Ni, Min Yang, Hu Wei, Yongbin Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03219v1",
    "source": "arXiv",
    "abstract": "As code large language models (LLMs) evolve into tool-interactive agents via the Model Context Protocol (MCP), their generalization is increasingly limited by low-quality synthetic data and the diminishing returns of quantity scaling. Moreover, quantity-centric scaling exhibits an early bottleneck that underutilizes trajectory data. We propose TDScaling, a Trajectory Diversity Scaling-based data synthesis framework for code agents that scales performance through diversity rather than raw volume. Under a fixed training budget, increasing trajectory diversity yields larger gains than adding more trajectories, improving the performance-cost trade-off for agent training. TDScaling integrates four innovations: (1) a Business Cluster mechanism that captures real-service logical dependencies; (2) a blueprint-driven multi-agent paradigm that enforces trajectory coherence; (3) an adaptive evolution mechanism that steers synthesis toward long-tail scenarios using Domain Entropy, Reasoning Mode Entropy, and Cumulative Action Complexity to prevent mode collapse; and (4) a sandboxed code tool that mitigates catastrophic forgetting of intrinsic coding capabilities. Experiments on general tool-use benchmarks (BFCL, tau^2-Bench) and code agent tasks (RebenchT, CodeCI, BIRD) demonstrate a win-win outcome: TDScaling improves both tool-use generalization and inherent coding proficiency. We plan to release the full codebase and the synthesized dataset (including 30,000+ tool clusters) upon publication.",
    "title_zh": "超越数量：代码智能体轨迹多样性扩展",
    "abstract_zh": "随着代码大语言模型（LLMs）通过模型上下文协议（MCP）演变为工具交互式智能体，其泛化能力正日益受到低质量合成数据以及数量扩展带来的收益递减的制约。此外，以数量为中心的扩展方式存在早期瓶颈，导致轨迹数据利用不充分。为此，我们提出TDScaling——一种基于轨迹多样性的数据合成框架，专为代码智能体设计，通过提升多样性而非单纯增加数据量来实现性能提升。在固定训练预算下，增加轨迹多样性所带来的性能增益远超单纯增加轨迹数量，显著优化了智能体训练中的性能-成本权衡。TDScaling集成了四项创新：（1）业务簇机制，用于捕捉真实服务中的逻辑依赖关系；（2）蓝图驱动的多智能体范式，确保轨迹的一致性与连贯性；（3）自适应演化机制，利用领域熵、推理模式熵和累积动作复杂度，引导合成过程聚焦于长尾场景，有效防止模式崩溃；（4）沙箱化代码工具，缓解内在编码能力的灾难性遗忘问题。在通用工具使用基准（BFCL、tau^2-Bench）以及代码智能体任务（RebenchT、CodeCI、BIRD）上的实验表明，TDScaling实现了双赢效果：不仅显著提升了工具使用的泛化能力，也增强了智能体的内在编码能力。我们计划在论文发表后公开完整的代码库及合成数据集（包含30,000多个工具簇）。"
  },
  {
    "date": "2026-02-03",
    "title": "Contrastive Concept-Tree Search for LLM-Assisted Algorithm Discovery",
    "authors": "Timothee Leleu, Sudeera Gunathilaka, Federico Ghimenti, Surya Ganguli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03132v1",
    "source": "arXiv",
    "abstract": "Large language Model (LLM)-assisted algorithm discovery is an iterative, black-box optimization process over programs to approximatively solve a target task, where an LLM proposes candidate programs and an external evaluator provides task feedback. Despite intense recent research on the topic and promising results, how can the LLM internal representation of the space of possible programs be maximally exploited to improve performance is an open question. Here, we introduce Contrastive Concept-Tree Search (CCTS), which extracts a hierarchical concept representation from the generated programs and learns a contrastive concept model that guides parent selection. By reweighting parents using a likelihood-ratio score between high- and low-performing solutions, CCTS biases search toward useful concept combinations and away from misleading ones, providing guidance through an explicit concept hierarchy rather than the algorithm lineage constructed by the LLM. We show that CCTS improves search efficiency over fitness-based baselines and produces interpretable, task-specific concept trees across a benchmark of open Erdős-type combinatorics problems. Our analysis indicates that the gains are driven largely by learning which concepts to avoid. We further validate these findings in a controlled synthetic algorithm-discovery environment, which reproduces qualitatively the search dynamics observed with the LLMs.",
    "title_zh": "对比概念树搜索在大语言模型辅助算法发现中的应用",
    "abstract_zh": "大型语言模型（LLM）辅助的算法发现是一种在程序空间中进行迭代、黑箱优化的过程，旨在近似求解目标任务。在此过程中，LLM提出候选程序，而外部评估器则提供任务反馈。尽管该领域近年来研究十分活跃并取得了令人鼓舞的结果，但如何最大限度地利用LLM对可能程序空间的内部表征以提升性能，仍是尚未解决的关键问题。\n\n本文提出对比概念树搜索（Contrastive Concept-Tree Search, CCTS），该方法从生成的程序中提取分层的概念表示，并学习一个对比概念模型，用于指导父程序的选择。CCTS通过计算高性能与低性能解决方案之间的似然比得分，对父程序进行重加权，从而引导搜索过程聚焦于有效的概念组合，同时避开具有误导性的组合。这一机制基于显式的概念层次结构进行引导，而非依赖LLM自身构建的算法演化谱系。\n\n我们证明，CCTS在搜索效率上优于基于适应度的基线方法，并在一系列开放的Erdős型组合数学问题基准测试中，生成了可解释且任务特定的概念树。分析表明，性能提升主要源于模型学会了识别应避免的概念。此外，我们在一个受控的合成算法发现环境中进一步验证了这些发现，该环境在定性上复现了LLM在实际搜索中观察到的动力学行为。"
  },
  {
    "date": "2026-02-03",
    "title": "Use Graph When It Needs: Efficiently and Adaptively Integrating Retrieval-Augmented Generation with Graphs",
    "authors": "Su Dong, Qinggang Zhang, Yilin Xiao, Shengyuan Chen, Chuang Zhou, Xiao Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03578v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) often struggle with knowledge-intensive tasks due to hallucinations and outdated parametric knowledge. While Retrieval-Augmented Generation (RAG) addresses this by integrating external corpora, its effectiveness is limited by fragmented information in unstructured domain documents. Graph-augmented RAG (GraphRAG) emerged to enhance contextual reasoning through structured knowledge graphs, yet paradoxically underperforms vanilla RAG in real-world scenarios, exhibiting significant accuracy drops and prohibitive latency despite gains on complex queries. We identify the rigid application of GraphRAG to all queries, regardless of complexity, as the root cause. To resolve this, we propose an efficient and adaptive GraphRAG framework called EA-GraphRAG that dynamically integrates RAG and GraphRAG paradigms through syntax-aware complexity analysis. Our approach introduces: (i) a syntactic feature constructor that parses each query and extracts a set of structural features; (ii) a lightweight complexity scorer that maps these features to a continuous complexity score; and (iii) a score-driven routing policy that selects dense RAG for low-score queries, invokes graph-based retrieval for high-score queries, and applies complexity-aware reciprocal rank fusion to handle borderline cases. Extensive experiments on a comprehensive benchmark, consisting of two single-hop and two multi-hop QA benchmarks, demonstrate that our EA-GraphRAG significantly improves accuracy, reduces latency, and achieves state-of-the-art performance in handling mixed scenarios involving both simple and complex queries.",
    "title_zh": "需要时使用图：高效且自适应地将检索增强生成与图结合",
    "abstract_zh": "大型语言模型（LLMs）在处理知识密集型任务时，常因幻觉现象和过时的参数化知识而表现不佳。尽管检索增强生成（RAG）通过引入外部语料库缓解了这一问题，但其效果受限于非结构化领域文档中信息的碎片化。图增强型RAG（GraphRAG）应运而生，旨在通过结构化的知识图谱提升上下文推理能力。然而，令人意外的是，在真实场景中，GraphRAG的表现反而逊于传统的RAG，尽管在复杂查询上有所提升，却伴随着显著的准确率下降和高昂的延迟开销。我们发现，将GraphRAG机械地应用于所有查询（无论其复杂程度如何）是导致性能下降的根本原因。\n\n为解决该问题，我们提出了一种高效且自适应的GraphRAG框架——EA-GraphRAG，它通过语法感知的复杂度分析，动态融合RAG与GraphRAG两种范式。我们的方法包含三个核心组件：(i) 一种句法特征构造器，能够解析每个查询并提取一组结构化特征；(ii) 一个轻量级复杂度评分器，将这些特征映射为连续的复杂度得分；(iii) 一种基于得分的路由策略：对低分查询采用密集型RAG，对高分查询调用基于图的检索，并对处于临界状态的查询应用考虑复杂度的倒数排名融合（reciprocal rank fusion）。  \n\n在涵盖两个单跳和两个多跳问答基准的综合性评测集上进行的大量实验表明，EA-GraphRAG显著提升了准确率，降低了延迟，并在同时包含简单与复杂查询的混合场景下达到了当前最优性能。"
  },
  {
    "date": "2026-02-03",
    "title": "Can Large Language Models Generalize Procedures Across Representations?",
    "authors": "Fangru Lin, Valentin Hofmann, Xingchen Wan, Weixing Wang, Zifeng Ding, Anthony G. Cohn, Janet B. Pierrehumbert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03542v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are trained and tested extensively on symbolic representations such as code and graphs, yet real-world user tasks are often specified in natural language. To what extent can LLMs generalize across these representations? Here, we approach this question by studying isomorphic tasks involving procedures represented in code, graphs, and natural language (e.g., scheduling steps in planning). We find that training LLMs with popular post-training methods on graphs or code data alone does not reliably generalize to corresponding natural language tasks, while training solely on natural language can lead to inefficient performance gains. To address this gap, we propose a two-stage data curriculum that first trains on symbolic, then natural language data. The curriculum substantially improves model performance across model families and tasks. Remarkably, a 1.5B Qwen model trained by our method can closely match zero-shot GPT-4o in naturalistic planning. Finally, our analysis suggests that successful cross-representation generalization can be interpreted as a form of generative analogy, which our curriculum effectively encourages.",
    "title_zh": "大型语言模型能否在不同表示之间泛化程序？",
    "abstract_zh": "大型语言模型（LLMs）在代码、图表等符号化表示上进行了大量训练与测试，但现实世界中的用户任务通常以自然语言形式提出。那么，这些模型在不同表示形式之间具备多强的泛化能力？本文通过研究在代码、图表和自然语言中以同构形式呈现的过程性任务（例如规划中的步骤调度），探讨了这一问题。我们发现，仅使用主流后训练方法在图表或代码数据上进行训练，难以可靠地推广到对应的自然语言任务；而仅在自然语言数据上训练，则可能导致性能提升效率低下。为弥补这一差距，我们提出一种两阶段数据课程：先在符号化数据上训练，再过渡到自然语言数据。该课程显著提升了多种模型家族和任务上的表现。令人惊讶的是，采用该方法训练的15亿参数Qwen模型，在自然主义规划任务中几乎可媲美零样本GPT-4o的表现。最后，我们的分析表明，成功的跨表示泛化可被理解为一种生成式类比，而我们的数据课程有效促进了这种类比能力的发展。"
  },
  {
    "date": "2026-02-03",
    "title": "Conformal Thinking: Risk Control for Reasoning on a Compute Budget",
    "authors": "Xi Wang, Anushri Suresh, Alvin Zhang, Rishi More, William Jurayj, Benjamin Van Durme, Mehrdad Farajtabar, Daniel Khashabi, Eric Nalisnick",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03814v1",
    "source": "arXiv",
    "abstract": "Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances (risking premature stoppage). Given a target risk and a validation set, we use distribution-free risk control to optimally specify these stopping mechanisms. For scenarios with multiple budget controlling criteria, we incorporate an efficiency loss to select the most computationally efficient exiting mechanism. Empirical results across diverse reasoning tasks and models demonstrate the effectiveness of our risk control approach, demonstrating computational efficiency gains from the lower threshold and ensemble stopping mechanisms while adhering to the user-specified risk target.",
    "title_zh": "共形思维：在计算预算约束下的推理风险控制",
    "abstract_zh": "推理型大语言模型（LLMs）能够实现测试时的扩展性，即随着分词预算（token budget）的增加，数据集级别的准确率也随之提升，这推动了自适应推理的发展——在计算能提高可靠性时才消耗分词，而在进一步计算不太可能带来帮助时则提前停止。然而，设定分词预算以及自适应推理的阈值，是一项实际挑战，其中涉及根本性的风险-准确率权衡问题。本文将预算设定问题重新定义为风险控制问题，在限制错误率的同时最小化计算开销。我们的框架引入了一个上界阈值，当模型足够自信时停止推理（存在输出错误的风险）；同时提出一种新型的参数化下界阈值，用于提前终止那些无法解决的问题实例（存在过早停止的风险）。在给定目标风险水平和验证集的前提下，我们采用无需分布假设的风险控制方法，以最优方式确定这些停止机制。对于存在多种预算控制标准的场景，我们引入效率损失指标，以选择计算效率最高的退出机制。在多种推理任务和模型上的实证结果表明，所提出的基于风险控制的方法具有显著有效性：下界阈值和集成停止机制在满足用户指定风险目标的前提下，显著提升了计算效率。"
  },
  {
    "date": "2026-02-03",
    "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration",
    "authors": "Jianhao Ruan, Zhihao Xu, Yiran Peng, Fashen Ren, Zhaoyang Yu, Xinbing Liang, Jinyu Xiang, Bang Liu, Chenglin Wu, Yuyu Luo, Jiayi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03786v1",
    "source": "arXiv",
    "abstract": "Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra",
    "title_zh": "AOrchestra：用于智能体编排的子智能体自动生成自动化系统",
    "abstract_zh": "语言代理在任务自动化方面展现出巨大潜力。随着对日益复杂、长周期任务自动化需求的提升，催生了“子代理作为工具”的多轮任务求解范式。然而，现有设计仍缺乏对子代理的动态抽象视角，从而限制了系统的适应能力。为此，我们提出了一种统一且与框架无关的代理抽象方法，将任意代理建模为一个四元组：指令（Instruction）、上下文（Context）、工具（Tools）和模型（Model）。该四元组充当能力的组合式“配方”，使系统能够按需生成针对特定任务的专用执行器。基于这一抽象，我们构建了名为 AOrchestra 的智能体系统，其中中央协调器在每一步动态实例化该四元组：它筛选与任务相关的上下文，选择合适的工具与模型，并通过即时自动创建代理的方式委派执行任务。这种设计显著降低了人工工程成本，同时保持了框架无关性，支持多种代理作为任务执行器的即插即用。此外，该系统还实现了可控的性能-成本权衡，使系统能够逼近帕累托最优。在三个具有挑战性的基准测试（GAIA、SWE-Bench、Terminal-Bench）中，AOrchestra 搭配 Gemini-3-Flash 时，相对于最强基线实现了 16.28% 的相对性能提升。代码已开源：https://github.com/FoundationAgents/AOrchestra"
  },
  {
    "date": "2026-02-03",
    "title": "Context Compression via Explicit Information Transmission",
    "authors": "Jiangnan Ye, Hanqi Yan, Zhenyi Shen, Heng Chang, Ye Mao, Yulan He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03784v1",
    "source": "arXiv",
    "abstract": "Long-context inference with Large Language Models (LLMs) is costly due to quadratic attention and growing key-value caches, motivating context compression. In this work, we study soft context compression, where a long context is condensed into a small set of continuous representations. Existing methods typically re-purpose the LLM itself as a trainable compressor, relying on layer-by-layer self-attention to iteratively aggregate information. We argue that this paradigm suffers from two structural limitations: (i) progressive representation overwriting across layers (ii) uncoordinated allocation of compression capacity across tokens. We propose ComprExIT (Context Compression via Explicit Information Transmission), a lightweight framework that formulates soft compression into a new paradigm: explicit information transmission over frozen LLM hidden states. This decouples compression from the model's internal self-attention dynamics. ComprExIT performs (i) depth-wise transmission to selectively transmit multi-layer information into token anchors, mitigating progressive overwriting, and (ii) width-wise transmission to aggregate anchors into a small number of slots via a globally optimized transmission plan, ensuring coordinated allocation of information. Across six question-answering benchmarks, ComprExIT consistently outperforms state-of-the-art context compression methods while introducing only ~1% additional parameters, demonstrating that explicit and coordinated information transmission enables more effective and robust long-context compression.",
    "title_zh": "通过显式信息传输进行上下文压缩",
    "abstract_zh": "长上下文推理在大型语言模型（LLMs）中成本高昂，主要由于注意力机制的二次复杂度以及不断增长的键值缓存，这促使了上下文压缩技术的发展。在本研究中，我们探讨了软性上下文压缩方法，即把长上下文压缩为一组少量的连续表示。现有方法通常将LLM自身重新用作可训练的压缩器，依赖逐层自注意力机制迭代聚合信息。我们认为这种范式存在两个结构性缺陷：（i）层间信息表示的逐步覆盖问题；（ii）不同token之间压缩能力分配缺乏协调。为此，我们提出了ComprExIT（通过显式信息传输实现上下文压缩），这是一种轻量级框架，将软压缩重新定义为一种新范式：在冻结的LLM隐藏状态上进行显式信息传输。该方法将压缩过程与模型内部自注意力动态解耦。ComprExIT通过（i）深度方向的信息传输，有选择地将多层信息传递至标记锚点，缓解了信息逐步覆盖的问题；（ii）宽度方向的信息传输，通过全局优化的传输方案将锚点聚合为少量槽位，确保信息分配的协调性。在六个问答基准测试中，ComprExIT始终优于当前最先进的上下文压缩方法，同时仅引入约1%的额外参数，证明了显式且协调的信息传输能够实现更高效、更鲁棒的长上下文压缩。"
  },
  {
    "date": "2026-02-03",
    "title": "mopri - An Analysis Framework for Unveiling Privacy Violations in Mobile Apps",
    "authors": "Cornell Ziepel, Stephan Escher, Sebastian Rehms, Stefan Köpsell",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03671v1",
    "source": "arXiv",
    "abstract": "Everyday services of society increasingly rely on mobile applications, resulting in a conflicting situation between the possibility of participation on the one side and user privacy and digital freedom on the other. In order to protect users' rights to informational self-determination, regulatory approaches for the collection and processing of personal data have been developed, such as the EU's GDPR. However, inspecting the compliance of mobile apps with privacy regulations remains difficult. Thus, in order to enable end users and enforcement bodies to verify and enforce data protection compliance, we propose mopri, a conceptual framework designed for analyzing the behavior of mobile apps through a comprehensive, adaptable, and user-centered approach. Recognizing the gaps in existing frameworks, mopri serves as a foundation for integrating various analysis tools into a streamlined, modular pipeline that employs static and dynamic analysis methods. Building on this concept, a prototype has been developed which effectively extracts permissions and tracking libraries while employing robust methods for dynamic traffic recording and decryption. Additionally, it incorporates result enrichment and reporting features that enhance the clarity and usability of the analysis outcomes. The prototype showcases the feasibility of a holistic and modular approach to privacy analysis, emphasizing the importance of continuous adaptation to the evolving challenges presented by the mobile app ecosystem.",
    "title_zh": "mopri - 一种揭示移动应用隐私违规行为的分析框架",
    "abstract_zh": "现代社会的日常服务越来越依赖移动应用程序，这导致了参与可能性与用户隐私及数字自由之间的矛盾。为保护用户的信息自决权，监管机构已制定出针对个人数据收集与处理的规范，例如欧盟的《通用数据保护条例》（GDPR）。然而，检测移动应用是否符合隐私法规仍面临诸多困难。为此，为使终端用户和监管机构能够验证并执行数据保护合规性，我们提出了mopri——一种概念性框架，旨在通过全面、可适应且以用户为中心的方法分析移动应用的行为。针对现有框架的不足，mopri为整合多种分析工具提供了一个基础，构建了一个简洁、模块化的分析流程，融合了静态与动态分析方法。基于该理念，我们开发了一个原型系统，能够有效提取应用权限和追踪库信息，并采用稳健的方法实现动态网络流量的记录与解密。此外，该系统还集成了结果增强与报告功能，显著提升了分析结果的清晰度与可用性。该原型验证了整体化、模块化隐私分析方法的可行性，凸显了持续适应移动应用生态系统不断演变挑战的重要性。"
  },
  {
    "date": "2026-02-03",
    "title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques",
    "authors": "David P. Woodruff, Vincent Cohen-Addad, Lalit Jain, Jieming Mao, Song Zuo, MohammadHossein Bateni, Simina Branzei, Michael P. Brenner, Lin Chen, Ying Feng, Lance Fortnow, Gang Fu, Ziyi Guan, Zahra Hadizadeh, Mohammad T. Hajiaghayi, Mahdi JafariRaviz, Adel Javanmard, Karthik C. S., Ken-ichi Kawarabayashi, Ravi Kumar, Silvio Lattanzi, Euiwoong Lee, Yi Li, Ioannis Panageas, Dimitris Paparas, Benjamin Przybocki, Bernardo Subercaseaux, Ola Svensson, Shayan Taherijam, Xuan Wu, Eylon Yogev, Morteza Zadimoghaddam, Samson Zhou, Vahab Mirrokni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03837v1",
    "source": "arXiv",
    "abstract": "Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google's Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a \"neuro-symbolic\" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.",
    "title_zh": "利用Gemini加速科学研究：案例研究与常用技术",
    "abstract_zh": "大型语言模型（LLMs）的最新进展为加速科学研究开辟了新的途径。尽管这些模型在协助处理常规任务方面日益强大，但它们在推动新颖的、专家级数学发现方面的潜力仍不甚清晰。本文通过一系列案例研究，展示了研究人员如何成功与先进的AI模型——特别是基于谷歌Gemini的模型（尤其是Gemini Deep Think及其高级变体）——协作，解决了开放性问题、推翻了原有猜想，并在理论计算机科学等多个领域生成了新的证明。此外，该方法也拓展至经济学、优化和物理学等其他学科。基于这些实践经验，我们提炼出在理论研究中实现高效人机协作的若干通用策略，如迭代精炼、问题分解以及跨学科知识迁移。虽然大部分成果源于这种互动式、对话式的合作模式，但我们还特别指出了一些突破标准聊天界面限制的实例：例如将模型部署为严格的对抗性审稿人，以发现现有证明中的细微漏洞；或将模型嵌入“神经符号”循环中，使其自主编写并执行代码，以验证复杂的推导过程。这些案例共同凸显了人工智能不仅是一种自动化工具，更可作为科学发现创造性过程中的灵活而真实的合作伙伴。"
  },
  {
    "date": "2026-02-03",
    "title": "Self-Verification Dilemma: Experience-Driven Suppression of Overused Checking in LLM Reasoning",
    "authors": "Quanyu Long, Kai Jie Jiang, Jianda Chen, Xu Guo, Leilei Gan, Wenya Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03485v1",
    "source": "arXiv",
    "abstract": "Large Reasoning Models (LRMs) achieve strong performance by generating long reasoning traces with reflection. Through a large-scale empirical analysis, we find that a substantial fraction of reflective steps consist of self-verification (recheck) that repeatedly confirm intermediate results. These rechecks occur frequently across models and benchmarks, yet the vast majority are confirmatory rather than corrective, rarely identifying errors and altering reasoning outcomes. This reveals a mismatch between how often self-verification is activated and how often it is actually useful. Motivated by this, we propose a novel, experience-driven test-time framework that reduces the overused verification. Our method detects the activation of recheck behavior, consults an offline experience pool of past verification outcomes, and estimates whether a recheck is likely unnecessary via efficient retrieval. When historical experience suggests unnecessary, a suppression signal redirects the model to proceed. Across multiple model and benchmarks, our approach reduces token usage up to 20.3% while maintaining the accuracy, and in some datasets even yields accuracy improvements.",
    "title_zh": "自我验证困境：基于经验的抑制在大语言模型推理中过度检查的问题",
    "abstract_zh": "大型推理模型（LRMs）通过生成包含反思的长推理轨迹，实现了优异的性能。通过大规模的实证分析，我们发现大量反思步骤本质上是自我验证（重新检查），即反复确认中间结果。这种重新检查在不同模型和基准测试中频繁出现，但绝大多数都是确认性而非纠正性的，极少能发现错误或改变推理结果。这揭示了模型激活自我验证的频率与其实际效用之间存在显著不匹配。受此启发，我们提出了一种新颖的、基于经验的测试时框架，旨在减少过度使用的验证行为。我们的方法能够检测到重新检查行为的触发，查询离线积累的历史验证结果经验池，并通过高效的检索估算某次重新检查是否可能并不必要。当历史经验表明该检查无必要时，系统会发出抑制信号，引导模型直接继续推理。在多个模型和基准测试中，该方法将token使用量最多降低了20.3%，同时保持了原有准确率，甚至在某些数据集上实现了准确率的提升。"
  },
  {
    "date": "2026-02-03",
    "title": "Verified Critical Step Optimization for LLM Agents",
    "authors": "Mukai Li, Qingcheng Zeng, Tianqing Fang, Zhenwen Liang, Linfeng Song, Qi Liu, Haitao Mi, Dong Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03412v1",
    "source": "arXiv",
    "abstract": "As large language model agents tackle increasingly complex long-horizon tasks, effective post-training becomes critical. Prior work faces fundamental challenges: outcome-only rewards fail to precisely attribute credit to intermediate steps, estimated step-level rewards introduce systematic noise, and Monte Carlo sampling approaches for step reward estimation incur prohibitive computational cost. Inspired by findings that only a small fraction of high-entropy tokens drive effective RL for reasoning, we propose Critical Step Optimization (CSO), which focuses preference learning on verified critical steps, decision points where alternate actions demonstrably flip task outcomes from failure to success. Crucially, our method starts from failed policy trajectories rather than expert demonstrations, directly targeting the policy model's weaknesses. We use a process reward model (PRM) to identify candidate critical steps, leverage expert models to propose high-quality alternatives, then continue execution from these alternatives using the policy model itself until task completion. Only alternatives that the policy successfully executes to correct outcomes are verified and used as DPO training data, ensuring both quality and policy reachability. This yields fine-grained, verifiable supervision at critical decisions while avoiding trajectory-level coarseness and step-level noise. Experiments on GAIA-Text-103 and XBench-DeepSearch show that CSO achieves 37% and 26% relative improvement over the SFT baseline and substantially outperforms other post-training methods, while requiring supervision at only 16% of trajectory steps. This demonstrates the effectiveness of selective verification-based learning for agent post-training.",
    "title_zh": "LLM Agent 的验证关键步骤优化",
    "abstract_zh": "随着大型语言模型代理逐步应对日益复杂的长周期任务，有效的后训练方法变得至关重要。以往的研究面临根本性挑战：仅基于结果的奖励无法精确地将责任归因于中间步骤，而估计的步骤级奖励则引入系统性噪声，基于蒙特卡洛采样的步骤奖励估计方法又带来难以承受的计算开销。受“仅有少量高熵 token 能有效驱动推理型强化学习”这一发现的启发，我们提出**关键步骤优化**（Critical Step Optimization, CSO），该方法将偏好学习聚焦于经过验证的关键步骤——即在这些决策点上，选择不同的动作能够明确地将任务结果从失败转变为成功。至关重要的是，我们的方法从失败的策略轨迹出发，而非依赖专家示范，从而直接针对策略模型的薄弱环节进行优化。我们使用过程奖励模型（Process Reward Model, PRM）识别候选关键步骤，借助专家模型提出高质量的替代动作，随后由策略模型自身从这些替代动作继续执行直至任务完成。只有那些策略模型能够成功执行并达成正确结果的替代路径才被验证并作为DPO训练数据，从而确保数据质量与策略可达性。这种方法在关键决策点上实现了细粒度、可验证的监督，同时避免了轨迹级的粗粒度和步骤级的噪声问题。在GAIA-Text-103和XBench-DeepSearch上的实验表明，CSO相较于SFT基线分别实现了37%和26%的相对性能提升，显著优于其他后训练方法，且仅需在16%的轨迹步骤上进行人工监督。这充分证明了基于选择性验证的学习策略在代理后训练中的有效性。"
  },
  {
    "date": "2026-02-03",
    "title": "GFlowPO: Generative Flow Network as a Language Model Prompt Optimizer",
    "authors": "Junmo Cho, Suhan Kim, Sangjune An, Minsu Kim, Dong Bok Lee, Heejun Lee, Sung Ju Hwang, Hae Beom Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03358v1",
    "source": "arXiv",
    "abstract": "Finding effective prompts for language models (LMs) is critical yet notoriously difficult: the prompt space is combinatorially large, rewards are sparse due to expensive target-LM evaluation. Yet, existing RL-based prompt optimizers often rely on on-policy updates and a meta-prompt sampled from a fixed distribution, leading to poor sample efficiency. We propose GFlowPO, a probabilistic prompt optimization framework that casts prompt search as a posterior inference problem over latent prompts regularized by a meta-prompted reference-LM prior. In the first step, we fine-tune a lightweight prompt-LM with an off-policy Generative Flow Network (GFlowNet) objective, using a replay-based training policy that reuses past prompt evaluations to enable sample-efficient exploration. In the second step, we introduce Dynamic Memory Update (DMU), a training-free mechanism that updates the meta-prompt by injecting both (i) diverse prompts from a replay buffer and (ii) top-performing prompts from a small priority queue, thereby progressively concentrating the search process on high-reward regions. Across few-shot text classification, instruction induction benchmarks, and question answering tasks, GFlowPO consistently outperforms recent discrete prompt optimization baselines.",
    "title_zh": "GFlowPO：生成流网络作为语言模型提示优化器",
    "abstract_zh": "为语言模型（LMs）寻找有效的提示（prompt）至关重要，但一直极具挑战性：提示空间呈组合爆炸式增长，而由于目标语言模型评估成本高昂，奖励信号又十分稀疏。然而，现有的基于强化学习（RL）的提示优化方法通常依赖于在线策略更新，并从固定分布中采样元提示（meta-prompt），导致样本效率低下。我们提出 GFlowPO，一种基于概率的提示优化框架，将提示搜索建模为在由元提示引导的参考语言模型先验正则化下的潜在提示后验推断问题。在第一步中，我们使用基于回放缓冲区的训练策略，通过离策略生成流网络（GFlowNet）目标对轻量级提示语言模型进行微调，从而复用过往的提示评估结果，实现高效的探索。在第二步中，我们引入无需训练的动态记忆更新机制（Dynamic Memory Update, DMU），通过向元提示注入两部分信息来持续优化搜索过程：(i) 来自回放缓冲区的多样化提示，以及 (ii) 来自小型优先队列的高性能提示，从而逐步将搜索聚焦于高奖励区域。在少样本文本分类、指令归纳基准和问答任务等多个场景中，GFlowPO 均显著优于近期的离散提示优化基线方法。"
  },
  {
    "date": "2026-02-03",
    "title": "Test-time Recursive Thinking: Self-Improvement without External Feedback",
    "authors": "Yufan Zhuang, Chandan Singh, Liyuan Liu, Yelong Shen, Dinghuai Zhang, Jingbo Shang, Jianfeng Gao, Weizhu Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03094v1",
    "source": "arXiv",
    "abstract": "Modern Large Language Models (LLMs) have shown rapid improvements in reasoning capabilities, driven largely by reinforcement learning (RL) with verifiable rewards. Here, we ask whether these LLMs can self-improve without the need for additional training. We identify two core challenges for such systems: (i) efficiently generating diverse, high-quality candidate solutions, and (ii) reliably selecting correct answers in the absence of ground-truth supervision. To address these challenges, we propose Test-time Recursive Thinking (TRT), an iterative self-improvement framework that conditions generation on rollout-specific strategies, accumulated knowledge, and self-generated verification signals. Using TRT, open-source models reach 100% accuracy on AIME-25/24, and on LiveCodeBench's most difficult problems, closed-source models improve by 10.4-14.8 percentage points without external feedback.",
    "title_zh": "测试时的递归思维：无需外部反馈的自我提升",
    "abstract_zh": "现代大型语言模型（LLMs）在推理能力方面取得了快速进步，这主要得益于基于可验证奖励的强化学习（RL）。本文探讨了这些LLMs是否能够在无需额外训练的情况下实现自我提升。我们识别出此类系统面临的两个核心挑战：（i）高效生成多样化且高质量的候选解决方案；（ii）在缺乏真实标签监督的情况下，可靠地选出正确答案。为应对这些挑战，我们提出了测试时递归思维（Test-time Recursive Thinking, TRT）框架，该框架通过滚动策略、累积知识以及自生成的验证信号来指导生成过程。借助TRT，开源模型在AIME-25/24数据集上达到100%的准确率；而在LiveCodeBench中最具挑战性的问题上，闭源模型的性能提升了10.4至14.8个百分点，且无需外部反馈。"
  },
  {
    "date": "2026-02-03",
    "title": "Beyond the Commit: Developer Perspectives on Productivity with AI Coding Assistants",
    "authors": "Valerie Chen, Jasmyn He, Behnjamin Williams, Jason Valentino, Ameet Talwalkar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03593v1",
    "source": "arXiv",
    "abstract": "Measuring developer productivity is a topic that has attracted attention from both academic research and industrial practice. In the age of AI coding assistants, it has become even more important for both academia and industry to understand how to measure their impact on developer productivity, and to reconsider whether earlier measures and frameworks still apply. This study analyzes the validity of different approaches to evaluating the productivity impacts of AI coding assistants by leveraging mixed-method research. At BNY Mellon, we conduct a survey with 2989 developer responses and 11 in-depth interviews. Our findings demonstrate that a multifaceted approach is needed to measure AI productivity impacts: survey results expose conflicting perspectives on AI tool usefulness, while interviews elicit six distinct factors that capture both short-term and long-term dimensions of productivity. In contrast to prior work, our factors highlight the importance of long-term metrics like technical expertise and ownership of work. We hope this work encourages future research to incorporate a broader range of human-centered factors, and supports industry in adopting more holistic approaches to evaluating developer productivity.",
    "title_zh": "超越承诺：开发者视角下的AI编程助手对生产力的影响",
    "abstract_zh": "衡量开发人员生产力是一个受到学术研究和工业实践共同关注的话题。在人工智能编程助手兴起的时代，学术界和产业界都更加重视如何评估这些工具对开发人员生产力的影响，并重新思考以往的衡量方法和框架是否仍然适用。本研究通过混合方法研究，分析了不同评估人工智能编程助手生产力影响方式的有效性。在纽约梅隆银行（BNY Mellon），我们开展了包含2989名开发人员回复的调查以及11次深度访谈。研究结果表明，要全面衡量人工智能对生产力的影响，需要采用多维度的方法：调查结果揭示了开发者对AI工具实用性的看法存在矛盾；而访谈则提炼出六个关键因素，涵盖了短期与长期两个层面的生产力表现。与以往研究不同，我们的研究强调了长期指标的重要性，如技术专长和对工作的主导权。我们希望这项工作能激励未来的研究纳入更广泛的人本化因素，同时支持产业界采用更为全面的方法来评估开发人员的生产力。"
  },
  {
    "date": "2026-02-03",
    "title": "Not All Negative Samples Are Equal: LLMs Learn Better from Plausible Reasoning",
    "authors": "Zixiang Di, Jinyi Han, Shuo Zhang, Ying Liao, Zhi Li, Xiaofeng Ji, Yongqi Wang, Zheming Yang, Ming Gao, Bingdong Li, Jie Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03516v1",
    "source": "arXiv",
    "abstract": "Learning from negative samples holds great promise for improving Large Language Model (LLM) reasoning capability, yet existing methods treat all incorrect responses as equally informative, overlooking the crucial role of sample quality. To address this, we propose Plausible Negative Samples (PNS), a method that synthesizes high-quality negative samples exhibiting expected format and structural coherence while ultimately yielding incorrect answers. PNS trains a dedicated model via reverse reinforcement learning (RL) guided by a composite reward combining format compliance, accuracy inversion, reward model assessment, and chain-of-thought evaluation, generating responses nearly indistinguishable from correct solutions. We further validate PNS as a plug-and-play data source for preference optimization across three backbone models on seven mathematical reasoning benchmarks. Results demonstrate that PNS consistently outperforms other negative sample synthesis methods, achieving an average improvement of 2.03% over RL-trained models.",
    "title_zh": "并非所有负样本都是一样的：大语言模型从合理的推理中学习得更好",
    "abstract_zh": "从负样本中学习对于提升大语言模型（LLM）的推理能力具有巨大潜力，然而现有方法将所有错误回答视为同等信息量，忽视了样本质量的关键作用。为解决这一问题，我们提出了合理负样本（Plausible Negative Samples, PNS），该方法生成高质量的负样本，这些样本在格式和结构上符合预期，但最终结果仍为错误。PNS通过反向强化学习（RL）训练一个专用模型，其奖励函数由格式合规性、准确率反转、奖励模型评估以及思维链（chain-of-thought）评价等多个维度共同构成，从而生成几乎与正确答案无法区分的响应。我们进一步验证了PNS作为即插即用的数据源，在三种基础模型上对七个数学推理基准任务进行偏好优化的有效性。实验结果表明，PNS始终优于其他负样本生成方法，在平均性能上比经过强化学习训练的模型提升了2.03%。"
  },
  {
    "date": "2026-02-03",
    "title": "From Separate Compilation to Sound Language Composition",
    "authors": "Federico Bruzzone, Walter Cazzola, Luca Favalli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03777v1",
    "source": "arXiv",
    "abstract": "The development of programming languages involves complex theoretical and practical challenges, particularly when addressing modularity and reusability through language extensions. While language workbenches aim to enable modular development under the constraints of the language extension problem, one critical constraint -- separate compilation -- is often relaxed due to its complexity. However, this relaxation undermines artifact reusability and integration with common dependency systems. A key difficulty under separate compilation arises from managing attribute grammars, as extensions may introduce new attributes that invalidate previously generated abstract syntax tree structures. Existing approaches, such as the use of dynamic maps in the Neverlang workbench, favor flexibility at the cost of compile-time correctness, leading to potential runtime errors due to undefined attributes. This work addresses this issue by introducing nlgcheck, a theoretically sound static analysis tool based on data-flow analysis for the Neverlang language workbench. nlgcheck detects potential runtime errors -- such as undefined attribute accesses -- at compile time, preserving separate compilation while maintaining strong static correctness guarantees. Experimental evaluation using mutation testing on Neverlang-based projects demonstrates that nlgcheck effectively enhances robustness without sacrificing modularity or flexibility and with a level of performance that does not impede its adoption in daily development activities.",
    "title_zh": "从分离编译到语言的可靠组合",
    "abstract_zh": "编程语言的发展涉及复杂的理论与实践挑战，尤其是在通过语言扩展实现模块化和可重用性方面。尽管语言工作台旨在在语言扩展问题的约束下支持模块化开发，但一个关键约束——分离编译——常常因其实现复杂性而被放宽。然而，这种放宽会削弱生成产物的可重用性，并影响与常见依赖管理系统的集成。在分离编译的背景下，一个核心难题是属性文法的管理：语言扩展可能引入新的属性，从而导致先前生成的抽象语法树结构失效。现有的方法，如Neverlang工作台中采用的动态映射机制，虽然提升了灵活性，却以牺牲编译时正确性为代价，可能导致因访问未定义属性而引发运行时错误。本文提出nlgcheck，一个基于数据流分析、理论严谨的静态分析工具，专为Neverlang语言工作台设计。nlgcheck能够在编译时检测潜在的运行时错误（如未定义属性的访问），在保持分离编译的同时，确保强静态正确性。通过在基于Neverlang的项目上使用变异测试进行实验评估，结果表明，nlgcheck能有效提升系统鲁棒性，且不牺牲模块化或灵活性，同时具备足够高的性能，不会阻碍其在日常开发中的应用。"
  },
  {
    "date": "2026-02-03",
    "title": "Agent Primitives: Reusable Latent Building Blocks for Multi-Agent Systems",
    "authors": "Haibo Jin, Kuang Peng, Ye Yu, Xiaopeng Yuan, Haohan Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03695v1",
    "source": "arXiv",
    "abstract": "While existing multi-agent systems (MAS) can handle complex problems by enabling collaboration among multiple agents, they are often highly task-specific, relying on manually crafted agent roles and interaction prompts, which leads to increased architectural complexity and limited reusability across tasks. Moreover, most MAS communicate primarily through natural language, making them vulnerable to error accumulation and instability in long-context, multi-stage interactions within internal agent histories. In this work, we propose \\textbf{Agent Primitives}, a set of reusable latent building blocks for LLM-based MAS. Inspired by neural network design, where complex models are built from reusable components, we observe that many existing MAS architectures can be decomposed into a small number of recurring internal computation patterns. Based on this observation, we instantiate three primitives: Review, Voting and Selection, and Planning and Execution. All primitives communicate internally via key-value (KV) cache, which improves both robustness and efficiency by mitigating information degradation across multi-stage interactions. To enable automatic system construction, an Organizer agent selects and composes primitives for each query, guided by a lightweight knowledge pool of previously successful configurations, forming a primitive-based MAS. Experiments show that primitives-based MAS improve average accuracy by 12.0-16.5\\% over single-agent baselines, reduce token usage and inference latency by approximately 3$\\times$-4$\\times$ compared to text-based MAS, while incurring only 1.3$\\times$-1.6$\\times$ overhead relative to single-agent inference and providing more stable performance across model backbones.",
    "title_zh": "代理原语：多智能体系统中可重用的潜在构建模块",
    "abstract_zh": "现有的多智能体系统（MAS）通过多个智能体之间的协作能够处理复杂问题，但通常高度依赖特定任务，需要人工设计智能体角色和交互提示，导致系统架构复杂度高，跨任务复用性差。此外，大多数MAS主要通过自然语言进行通信，在长上下文、多阶段的内部智能体交互过程中，容易出现错误累积和系统不稳定的问题。本文提出了一种名为**智能体原语（Agent Primitives）**的可复用潜在构建模块，用于基于大语言模型（LLM）的多智能体系统。受神经网络设计的启发——复杂模型由可复用组件构建而成，我们观察到，许多现有的MAS架构可被分解为少数几种反复出现的内部计算模式。基于这一发现，我们实例化了三种原语：**审查（Review）**、**投票与选择（Voting and Selection）**，以及**规划与执行（Planning and Execution）**。所有原语通过键值缓存（KV cache）进行内部通信，有效缓解了多阶段交互中信息退化的问题，从而提升了系统的鲁棒性与效率。为实现系统的自动化构建，一个“组织者”（Organizer）智能体根据轻量级的历史成功配置知识库，自动选择并组合合适的原语以应对每个查询，从而形成基于原语的多智能体系统。实验结果表明，基于原语的MAS相比单智能体基线平均准确率提升12.0%–16.5%，在token使用量和推理延迟方面比基于文本的MAS降低约3–4倍，同时相对于单智能体推理仅增加1.3–1.6倍的开销，并在不同模型主干上展现出更稳定的性能表现。"
  },
  {
    "date": "2026-02-03",
    "title": "Can Developers rely on LLMs for Secure IaC Development?",
    "authors": "Ehsan Firouzi, Shardul Bhatt, Mohammad Ghafari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03648v1",
    "source": "arXiv",
    "abstract": "We investigated the capabilities of GPT-4o and Gemini 2.0 Flash for secure Infrastructure as Code (IaC) development. For security smell detection, on the Stack Overflow dataset, which primarily contains small, simplified code snippets, the models detected at least 71% of security smells when prompted to analyze code from a security perspective (general prompt). With a guided prompt (adding clear, step-by-step instructions), this increased to 78%.In GitHub repositories, which contain complete, real-world project scripts, a general prompt was less effective, leaving more than half of the smells undetected. However, with the guided prompt, the models uncovered at least 67% of the smells. For secure code generation, we prompted LLMs with 89 vulnerable synthetic scenarios and observed that only 7% of the generated scripts were secure. Adding an explicit instruction to generate secure code increased GPT secure output rate to 17%, while Gemini changed little (8%). These results highlight the need for further research to improve LLMs' capabilities in assisting developers with secure IaC development.",
    "title_zh": "开发者能否依赖大语言模型进行安全的基础设施即代码（IaC）开发？",
    "abstract_zh": "我们研究了GPT-4o和Gemini 2.0 Flash在安全基础设施即代码（IaC）开发中的能力。在安全异味检测方面，针对主要包含小型、简化代码片段的Stack Overflow数据集，当以安全视角提示模型分析代码时（通用提示），两个模型至少检测到了71%的安全异味；而采用引导式提示（即添加清晰、分步骤的指令）后，检测率提升至78%。在GitHub仓库数据集（包含完整、真实世界项目脚本）中，通用提示效果较差，导致超过一半的安全异味未被发现；但使用引导式提示后，模型至少识别出了67%的安全异味。在安全代码生成方面，我们向大语言模型（LLM）输入了89个存在漏洞的合成场景，结果发现仅有7%生成的脚本是安全的。当明确要求生成安全代码时，GPT的安全部分输出率提升至17%，而Gemini的提升不明显（仍为8%）。这些结果凸显了进一步研究的必要性，以提升大语言模型在辅助开发者实现安全IaC开发方面的能力。"
  },
  {
    "date": "2026-02-03",
    "title": "Can LLMs Do Rocket Science? Exploring the Limits of Complex Reasoning with GTOC 12",
    "authors": "Iñaki del Campo, Pablo Cuervo, Victor Rodriguez-Fernandez, Roberto Armellin, Jack Yarndley",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03630v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in code generation and general reasoning, yet their capacity for autonomous multi-stage planning in high-dimensional, physically constrained environments remains an open research question. This study investigates the limits of current AI agents by evaluating them against the 12th Global Trajectory Optimization Competition (GTOC 12), a complex astrodynamics challenge requiring the design of a large-scale asteroid mining campaign. We adapt the MLE-Bench framework to the domain of orbital mechanics and deploy an AIDE-based agent architecture to autonomously generate and refine mission solutions. To assess performance beyond binary validity, we employ an \"LLM-as-a-Judge\" methodology, utilizing a rubric developed by domain experts to evaluate strategic viability across five structural categories. A comparative analysis of models, ranging from GPT-4-Turbo to reasoning-enhanced architectures like Gemini 2.5 Pro, and o3, reveals a significant trend: the average strategic viability score has nearly doubled in the last two years (rising from 9.3 to 17.2 out of 26). However, we identify a critical capability gap between strategy and execution. While advanced models demonstrate sophisticated conceptual understanding, correctly framing objective functions and mission architectures, they consistently fail at implementation due to physical unit inconsistencies, boundary condition errors, and inefficient debugging loops. We conclude that, while current LLMs often demonstrate sufficient knowledge and intelligence to tackle space science tasks, they remain limited by an implementation barrier, functioning as powerful domain facilitators rather than fully autonomous engineers.",
    "title_zh": "大语言模型能做火箭科学吗？探索GTOC 12中复杂推理的极限",
    "abstract_zh": "大型语言模型（LLMs）在代码生成和通用推理方面已展现出卓越的能力，但在高维、物理约束复杂的环境中实现自主的多阶段规划，其能力仍是一个开放的研究问题。本研究通过评估AI代理在第12届全球轨迹优化竞赛（GTOC 12）中的表现，探索当前人工智能代理的极限。GTOC 12是一项复杂的天体动力学挑战，要求设计大规模小行星采矿任务。我们针对轨道力学领域对MLE-Bench框架进行了适配，并部署了一种基于AIDE的代理架构，以实现任务方案的自主生成与迭代优化。为超越简单的“有效/无效”二元评估，我们采用“LLM作为裁判”（LLM-as-a-Judge）的方法，利用领域专家制定的评分标准，从五个结构性维度评估方案的战略可行性。对多种模型的对比分析显示，从GPT-4-Turbo到增强推理能力的架构如Gemini 2.5 Pro和o3，呈现出显著趋势：平均战略可行性得分在两年内几乎翻倍（从26分中的9.3分提升至17.2分）。然而，我们识别出一个关键的能力鸿沟——战略与执行之间的脱节。尽管先进模型展现出复杂的概念理解能力，能够正确设定目标函数和任务架构，但在实际执行中却频繁因物理单位不一致、边界条件错误以及低效的调试循环而失败。结论表明，尽管当前LLMs通常具备完成空间科学任务所需的知识与智能，但其仍受限于实现层面的障碍，更像强大的领域协作者，而非真正意义上的全自主工程师。"
  },
  {
    "date": "2026-02-03",
    "title": "ProAct: A Benchmark and Multimodal Framework for Structure-Aware Proactive Response",
    "authors": "Xiaomeng Zhu, Fengming Zhu, Weijie Zhou, Ye Tian, Zhenlin Hu, Yufei Huang, Yuchun Guo, Xinyu Wu, Zhengyou Zhang, Fangzhen Lin, Xuantang Xiong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03430v1",
    "source": "arXiv",
    "abstract": "While passive agents merely follow instructions, proactive agents align with higher-level objectives, such as assistance and safety by continuously monitoring the environment to determine when and how to act. However, developing proactive agents is hindered by the lack of specialized resources. To address this, we introduce ProAct-75, a benchmark designed to train and evaluate proactive agents across diverse domains, including assistance, maintenance, and safety monitoring. Spanning 75 tasks, our dataset features 91,581 step-level annotations enriched with explicit task graphs. These graphs encode step dependencies and parallel execution possibilities, providing the structural grounding necessary for complex decision-making. Building on this benchmark, we propose ProAct-Helper, a reference baseline powered by a Multimodal Large Language Model (MLLM) that grounds decision-making in state detection, and leveraging task graphs to enable entropy-driven heuristic search for action selection, allowing agents to execute parallel threads independently rather than mirroring the human's next step. Extensive experiments demonstrate that ProAct-Helper outperforms strong closed-source models, improving trigger detection mF1 by 6.21%, saving 0.25 more steps in online one-step decision, and increasing the rate of parallel actions by 15.58%.",
    "title_zh": "ProAct：一种面向结构感知主动响应的基准与多模态框架",
    "abstract_zh": "与被动代理仅遵循指令不同，主动代理会与更高层次的目标（如辅助、安全等）保持一致，通过持续监控环境来判断何时以及如何采取行动。然而，主动代理的发展受到缺乏专门资源的制约。为解决这一问题，我们提出了 ProAct-75——一个用于在多个领域（包括辅助、维护和安全监控）训练与评估主动代理的基准数据集。该数据集涵盖75个任务，包含91,581条步骤级标注，并附有明确的任务图。这些任务图编码了步骤间的依赖关系以及并行执行的可能性，为复杂决策提供了必要的结构基础。基于此基准，我们提出了 ProAct-Helper，这是一个由多模态大语言模型（MLLM）驱动的参考基线系统，其决策以状态检测为基础，并利用任务图实现基于熵驱动的启发式搜索以选择动作，使代理能够独立执行并行任务线程，而非简单模仿人类的下一步操作。大量实验表明，ProAct-Helper 在性能上优于多个强大的闭源模型：触发检测的 mF1 提升了 6.21%，在线单步决策中平均节省 0.25 步，同时并行动作的发生率提高了 15.58%。"
  },
  {
    "date": "2026-02-03",
    "title": "Precision in Practice: Knowledge Guided Code Summarizing Grounded in Industrial Expectations",
    "authors": "Jintai Li, Songqiang Chen, Shuo Jin, Xiaoyuan Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03400v1",
    "source": "arXiv",
    "abstract": "Code summaries are essential for helping developers understand code functionality and reducing maintenance and collaboration costs. Although recent advances in large language models (LLMs) have significantly improved automatic code summarization, the practical usefulness of generated summaries in industrial settings remains insufficiently explored. In collaboration with documentation experts from the industrial HarmonyOS project, we conducted a questionnaire study showing that over 57.4% of code summaries produced by state-of-the-art approaches were rejected due to violations of developers' expectations for industrial documentation. Beyond semantic similarity to reference summaries, developers emphasize additional requirements, including the use of appropriate domain terminology, explicit function categorization, and the avoidance of redundant implementation details. To address these expectations, we propose ExpSum, an expectation-aware code summarization approach that integrates function metadata abstraction, informative metadata filtering, context-aware domain knowledge retrieval, and constraint-driven prompting to guide LLMs in generating structured, expectation-aligned summaries. We evaluate ExpSum on the HarmonyOS project and widely used code summarization benchmarks. Experimental results show that ExpSum consistently outperforms all baselines, achieving improvements of up to 26.71% in BLEU-4 and 20.10% in ROUGE-L on HarmonyOS. Furthermore, LLM-based evaluations indicate that ExpSum-generated summaries better align with developer expectations across other projects, demonstrating its effectiveness for industrial code documentation.",
    "title_zh": "实践中的精准：基于工业期望的知识引导代码摘要",
    "abstract_zh": "代码摘要对于帮助开发者理解代码功能、降低维护与协作成本至关重要。尽管大型语言模型（LLMs）的最新进展显著提升了自动代码摘要的质量，但生成摘要在工业场景中的实际可用性仍缺乏充分探索。我们与HarmonyOS工业项目中的文档专家合作，开展了一项问卷调查，结果显示，超过57.4%由当前最先进方法生成的代码摘要因不符合开发者对工业级文档的预期而被拒绝。除了语义上与参考摘要的相似性外，开发者还特别强调其他关键要求：使用恰当的领域术语、明确的功能分类，以及避免冗余的实现细节。为满足这些需求，我们提出ExpSum——一种面向开发期望的代码摘要生成方法。该方法通过集成函数元数据抽象、信息性元数据过滤、上下文感知的领域知识检索，以及基于约束的提示设计，引导LLM生成结构化且符合预期的摘要。我们在HarmonyOS项目及广泛使用的代码摘要基准数据集上对ExpSum进行了评估。实验结果表明，ExpSum在所有基线方法中表现最优，在HarmonyOS数据集上BLEU-4指标提升最高达26.71%，ROUGE-L指标提升最高达20.10%。此外，基于LLM的评估也显示，ExpSum生成的摘要在多个其他项目中均更符合开发者预期，充分证明了其在工业代码文档场景中的有效性。"
  },
  {
    "date": "2026-02-03",
    "title": "MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research",
    "authors": "Yifan Shi, Jialong Shi, Jiayi Wang, Ye Fan, Jianyong Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.03318v1",
    "source": "arXiv",
    "abstract": "Operations Research (OR) relies on expert-driven modeling-a slow and fragile process ill-suited to novel scenarios. While large language models (LLMs) can automatically translate natural language into optimization models, existing approaches either rely on costly post-training or employ multi-agent frameworks, yet most still lack reliable collaborative error correction and task-specific retrieval, often leading to incorrect outputs. We propose MIRROR, a fine-tuning-free, end-to-end multi-agent framework that directly translates natural language optimization problems into mathematical models and solver code. MIRROR integrates two core mechanisms: (1) execution-driven iterative adaptive revision for automatic error correction, and (2) hierarchical retrieval to fetch relevant modeling and coding exemplars from a carefully curated exemplar library. Experiments show that MIRROR outperforms existing methods on standard OR benchmarks, with notable results on complex industrial datasets such as IndustryOR and Mamo-ComplexLP. By combining precise external knowledge infusion with systematic error correction, MIRROR provides non-expert users with an efficient and reliable OR modeling solution, overcoming the fundamental limitations of general-purpose LLMs in expert optimization tasks.",
    "title_zh": "MIRROR：一种用于运筹学优化建模的多智能体框架，具备迭代自适应修订与分层检索功能",
    "abstract_zh": "运筹学（OR）依赖于专家驱动的建模过程，这一过程缓慢且脆弱，难以应对新场景。尽管大型语言模型（LLMs）能够自动将自然语言转化为优化模型，但现有方法要么依赖昂贵的微调训练，要么采用多智能体框架，而大多数方法仍缺乏可靠的协作式错误修正机制和任务特定的检索能力，常常导致输出错误。我们提出MIRROR，一种无需微调、端到端的多智能体框架，可直接将自然语言优化问题转化为数学模型和求解器代码。MIRROR集成了两项核心机制：（1）基于执行反馈的迭代自适应修正，实现自动错误纠正；（2）分层检索机制，从精心构建的示例库中获取相关的建模与编码范例。实验表明，MIRROR在标准运筹学基准测试中优于现有方法，在复杂工业数据集（如IndustryOR和Mamo-ComplexLP）上表现尤为突出。通过结合精准的外部知识注入与系统化的错误修正，MIRROR为非专家用户提供了高效且可靠的运筹学建模解决方案，克服了通用大语言模型在专业优化任务中的根本局限性。"
  },
  {
    "date": "2026-2-3",
    "title": "Conversational Smart Assistant on a Microcontroller with Cloud-Based LLM Function Offloading",
    "authors": "Dang Quoc-Minh Do, Nguyen Hoang Nguyen, Quang Nho-Dang Nguyen, Tuan Anh Hoang, Khoa Quoc Nguyen, Thuan Huu Huynh",
    "publish": "2025 RIVF International Conference on Computing and Communication Technologies (RIVF)",
    "url": "https://doi.org/10.1109/rivf68649.2025.11365064",
    "source": "IEEE",
    "abstract": "This paper presents a conversational smart assistant architecture that integrates a resource-constrained microcontroller frontend with a cloud-based large language model (LLM) backend. The device captures user query audio, compresses it, and streams it in real time to the server over a lightweight custom TCP protocol. On the server, Google Speech-to-Text (STT) transcribes the input, which is then processed by OpenAI's Generative Pre-trained Transformer (GPT) model for natural language understanding. Depending on the query, the model either generates a direct response or issues structured function calls to access real-time information (e.g., breaking news) via public APIs or a headless browser, or to execute taskoriented functions such as reminder scheduling and voice note recording. The final response is synthesized into speech using Google Text-to-Speech (TTS), compressed and streamed back to the device for playback. Experimental results show low latency, efficient bandwidth usage, and cost-effective operation, demonstrating the practicality of the proposed architecture for embedded conversational interfaces and wearable IoT assistants.",
    "title_zh": "基于云的大型语言模型功能卸载的微控制器对话式智能助手",
    "abstract_zh": "本文提出了一种对话式智能助手架构，该架构将资源受限的微控制器前端与基于云的大语言模型（LLM）后端相结合。设备捕获用户语音查询，对其进行压缩，并通过轻量级自定义TCP协议实时流式传输至服务器。在服务器端，Google语音识别（STT）将输入语音转录为文本，随后由OpenAI的生成式预训练变换器（GPT）模型进行自然语言理解。根据查询内容，该模型可直接生成响应，或发出结构化函数调用，通过公共API或无头浏览器获取实时信息（如突发新闻），或执行任务导向型功能，如提醒设置和语音笔记录制。最终的响应通过Google文本转语音（TTS）合成语音，压缩后流式回传至设备进行播放。实验结果表明，该架构具有低延迟、高效带宽利用和低成本运行的特点，充分展示了其在嵌入式对话界面及可穿戴物联网助手中的实际应用潜力。"
  },
  {
    "date": "2026-2-3",
    "title": "Design and Exploration of a Parameterized Hybrid Routing Architecture for FPGAs",
    "authors": "Yuanqi Wang, Yunfei Dai, Xianfeng Cao, Eric Ren, Xifan Tang, Weijun Qin, Tao Li, Lingli Wang",
    "publish": "2025 International Conference on Field Programmable Technology (ICFPT)",
    "url": "https://doi.org/10.1109/icfpt67023.2025.00014",
    "source": "IEEE",
    "abstract": "As modern FPGAs continue to scale, the routing architecture increasingly dominates both area and delay. However, traditional homogeneous routing architectures struggle to efficiently accommodate spatially varying routing demands, often resulting in imbalanced routing resource utilization across different regions. This inefficiency contributes to increased routing area and critical path delay (CPD). To address this limitation, this paper proposes a hybrid FPGA routing architecture that introduces spatial heterogeneity into interconnect block configurations. The proposed architecture is fully parameterized, allowing different regions of the FPGA fabric to adopt distinct routing topologies tailored to local connectivity requirements. To support this architecture within the Verilog-to-Routing (VTR) toolchain, we extend the architecture description file format and enhance the routing resource graph (RRG) generator to support region-specific interconnect features. Furthermore, to efficiently search the vast parameter space, we employ a parallel Bayesian optimization (BO)-based design space exploration (DSE) framework for automated identification of optimal architecture configurations. Experimental results on the VTR benchmark suite demonstrate that the proposed hybrid routing architecture achieves up to 7.9% reduction in routing area, 2.5% improvement in CPD, and 10.1 % improvement in area-delay product (ADP) compared to the state-of-the-art VIB architecture. Additional analysis also shows a 38.09 % reduction in routing detour, confirming the effectiveness of the hybrid architecture in improving routing compactness and reducing wire overhead.",
    "title_zh": "FPGA参数化混合路由架构的设计与探索",
    "abstract_zh": "随着现代FPGA的持续扩展，布线架构在面积和延迟方面所占比例日益增加。然而，传统的同质化布线架构难以高效应对空间分布不均的布线需求，常导致不同区域间的布线资源利用率失衡，进而造成布线面积增大和关键路径延迟（CPD）上升。为解决这一问题，本文提出一种混合型FPGA布线架构，通过在互连模块配置中引入空间异质性，实现对局部连接需求的灵活适配。该架构完全参数化，使FPGA阵列的不同区域可采用针对本地连接特性量身定制的布线拓扑结构。为支持该架构在Verilog-to-Routing（VTR）工具链中的应用，我们扩展了架构描述文件格式，并改进了布线资源图（RRG）生成器，以支持区域特异性互连功能。此外，为高效探索庞大的参数空间，本文采用基于并行贝叶斯优化（BO）的设计空间探索（DSE）框架，实现对最优架构配置的自动化识别。在VTR基准测试集上的实验结果表明，与当前最先进的VIB架构相比，所提出的混合布线架构可实现最高达7.9%的布线面积缩减、2.5%的关键路径延迟改善以及10.1%的面积-延迟乘积（ADP）提升。进一步分析还显示，布线迂回程度降低了38.09%，充分验证了该混合架构在提升布线紧凑性、降低布线开销方面的有效性。"
  },
  {
    "date": "2026-2-3",
    "title": "Designing a Testbed for Neural Network Operations on an FPGA Using VHDL",
    "authors": "Kwadwo Ansong Annor, Nathan Amanquah, Kojo Nyarku Baidoo, Oracking Amenreynolds",
    "publish": "2025 13th International Conference on Intelligent Embedded, MicroElectronics, Communication and Optical Networks (IEMECON)",
    "url": "https://doi.org/10.1109/iemecon69302.2025.11365950",
    "source": "IEEE",
    "abstract": "Neural network inference in embedded systems often faces computational and memory constraints, making hardware acceleration an essential optimization strategy. A primary feature of neural network operations is the use of matrix computations, particularly repeated multiplications and additions. If these repetitive steps can be optimized, the inference time can be shorted. This paper presents the design of an FPGA-based testbed for exploring neural network operations in hardware, with a focus on fixed-point arithmetic, matrix multiplication, and activation functions. The testbed enables detailed examination of data flow and performance characteristics of neural network inference in constrained environments. This work aims to make the implementation details available to support future research and education in embedded machine learning, offering a practical reference for deploying neural networks for real-time, resource-constrained applications. The results from implementing a feedforward deep neural network, initially trained in MATLAB, and implemented on an Artix-7 FPGA using an 8.8 fixed-point format to reflect real-world resource limitations are also provided.",
    "title_zh": "使用VHDL在FPGA上设计神经网络运算的测试平台",
    "abstract_zh": "嵌入式系统中的神经网络推理通常面临计算和内存资源的限制，因此硬件加速成为一项至关重要的优化策略。神经网络运算的一个主要特征是大量使用矩阵计算，尤其是重复的乘法和加法操作。如果能够对这些重复步骤进行优化，推理时间便可显著缩短。本文提出了一种基于FPGA的测试平台设计，用于在硬件层面探索神经网络运算，重点聚焦于定点数运算、矩阵乘法以及激活函数。该测试平台能够对受限环境下的神经网络推理数据流和性能特征进行详细分析。本研究旨在公开实现细节，以支持未来在嵌入式机器学习领域的研究与教学工作，为实时、资源受限应用场景中部署神经网络提供实用参考。文中还展示了将一个在MATLAB中初始训练的前馈深度神经网络，采用8.8定点格式在Artix-7 FPGA上实现的结果，以反映实际资源限制下的运行情况。"
  },
  {
    "date": "2026-2-3",
    "title": "BOAMLS: Bayesian Optimization with Attention Mechanism for FPGA Logic Synthesis (PhD Forum Paper)",
    "authors": "Xijun Cheng, Zhongyan Xu, Jicong Fan, Yun Qian, Xiaofeng Gu, Zhiguo Yu",
    "publish": "2025 International Conference on Field Programmable Technology (ICFPT)",
    "url": "https://doi.org/10.1109/icfpt67023.2025.00052",
    "source": "IEEE",
    "abstract": "The continuous scaling of integrated circuits causes excessive growth in both area and delay, underscoring the critical need for logic synthesis to reduce redundancies. Nevertheless, prevailing methods for FPGA logic optimization exhibit limited efficiency and are susceptible to convergence into local optima. To address these challenges, this paper proposes BOAMLS, a Bayesian optimization framework with an attention mechanism for FPGA logic synthesis, enhancing high-dimensional design space exploration efficiency. Furthermore, an adaptive acquisition function is designed to prevent the Bayesian optimization process from getting trapped in local optima, thereby strengthening the overall robustness and global search performance. Experimental results on the EPFL benchmark show that, compared with RESYN2, the proposed framework achieves a geometric mean reduction of 11.44% in LUT-6 count under timing constraints.",
    "title_zh": "BOAMLS：基于注意力机制的贝叶斯优化在FPGA逻辑综合中的应用（博士论坛论文）",
    "abstract_zh": "集成电路的持续缩放导致面积和延迟的过度增长，凸显了逻辑综合减少冗余的迫切需求。然而，现有的FPGA逻辑优化方法效率有限，且容易陷入局部最优。为解决这些问题，本文提出BOAMLS，一种结合注意力机制的贝叶斯优化框架，用于FPGA逻辑综合，以提升高维设计空间探索的效率。此外，设计了一种自适应采集函数，防止贝叶斯优化过程陷入局部最优，从而增强整体的鲁棒性与全局搜索能力。在EPFL基准测试集上的实验结果表明，与RESYN2相比，所提出的框架在满足时序约束的前提下，LUT-6数量的几何平均减少了11.44%。"
  },
  {
    "date": "2026-2-3",
    "title": "Automatic SystemVerilog Assertion Generation: Challenges and Opportunities",
    "authors": "Raheel Afsharmazayejani, Hammond Pearce, Benjamin Tan",
    "publish": "2025 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)",
    "url": "https://doi.org/10.1109/ccece64018.2025.11364438",
    "source": "IEEE",
    "abstract": "As modern semiconductor devices have become increasingly complex, guaranteeing their functional correctness and security assurance has become more challenging. Assertion-based verification (ABV) is a typical method to detect functional and security issues at the RTL stage of the design process. Properties - often expressed as SystemVerilog Assertions (SVAs) - are constructed to formally specify a design’s expected behavior by enabling automatic checks during simulation and formal verification. Although writing assertions enhances semiconductor assurance before fabrication, it requires expertise and is a time-consuming process, motivating the development of automated methods to facilitate the entire procedure. This article explores the various methodologies and best practices to enhance the automation of the SVA generation and presents insights into the challenges and opportunities in this area.",
    "title_zh": "自动系统Verilog断言生成：挑战与机遇",
    "abstract_zh": "随着现代半导体器件日益复杂，确保其功能正确性和安全性变得愈发具有挑战性。基于断言的验证（Assertion-Based Verification, ABV）是设计流程中在RTL阶段检测功能与安全问题的典型方法。通过构建属性——通常以SystemVerilog断言（SVAs）的形式表达——可以形式化地指定设计的预期行为，从而在仿真和形式化验证过程中实现自动检查。尽管编写断言能够显著提升芯片流片前的保障水平，但这一过程需要专业知识且耗时较长，因而推动了自动化方法的发展，以简化整个断言生成流程。本文探讨了提升SVAs自动生成自动化水平的各种方法与最佳实践，并深入分析了该领域面临的挑战与未来机遇。"
  },
  {
    "date": "2026-2-3",
    "title": "Trust, but Verify",
    "authors": "Michael J. Yuan, Carlos Lospoy, Sydney Lai, James Snewin, Ju Long",
    "publish": "Computer",
    "url": "https://doi.org/10.1109/mc.2025.3600630",
    "source": "IEEE",
    "abstract": "We demonstrate that in a cluster of mostly honest nodes, we can detect nodes that run unauthorized or incorrect large language models (LLMs) through the social consensus of their peers. We discuss an intersubjective validation system to encourage honest behavior from LLM nodes.",
    "title_zh": "信任，但要核实。",
    "abstract_zh": "我们证明，在一个大多数节点都诚实的集群中，可以通过其同伴之间的社会共识来检测运行未经授权或错误大型语言模型（LLM）的节点。我们讨论了一种交互主观验证系统，以鼓励LLM节点保持诚实行为。"
  },
  {
    "date": "2026-2-3",
    "title": "Design and Implementation of 4-bit ALU Using 90nm CMOS Technology",
    "authors": "Vishal Sanjay Raju, Karthi Pradeep",
    "publish": "2025 13th International Conference on Intelligent Embedded, MicroElectronics, Communication and Optical Networks (IEMECON)",
    "url": "https://doi.org/10.1109/iemecon69302.2025.11365939",
    "source": "IEEE",
    "abstract": "This paper presents a 4-bit Arithmetic Logic Unit (ALU) design and implementation using 90 nm CMOS (Complementary Metal-Oxide-Semiconductor) technology. The ALU is a fundamental building block of any central processing unit (CPU), microcontroller unit (MCU), GPU's, DSP's etc. and is responsible for performing arithmetic and logical operations. The design process involves the schematic design of adder, subtractor, comparator, 1 's complement and decoder for the development of the ALU architecture followed by simulation of the design using Cadence Virtuoso EDA (Electronic Design Automation) tools. The implementation phase focuses on layout design to ensure the functionality and manufacturability of the ALU. The performance metrics such as power consumption, area, and speed are analyzed to validate the efficiency of the design. The successful realization of the 4-bit ALU showcases the potential for advancements in integrated circuit design and the practical application of CMOS technology in modern computing systems.",
    "title_zh": "基于90nm CMOS技术的4位ALU设计与实现",
    "abstract_zh": "本文提出了一种基于90纳米CMOS（互补金属氧化物半导体）技术的4位算术逻辑单元（ALU）设计与实现。ALU是中央处理器（CPU）、微控制器单元（MCU）、图形处理器（GPU）以及数字信号处理器（DSP）等系统中的基本构建模块，负责执行算术和逻辑运算。设计过程包括加法器、减法器、比较器、反码电路及译码器的原理图设计，以构建ALU的整体架构，随后利用Cadence Virtuoso EDA（电子设计自动化）工具对设计进行仿真验证。实现阶段则重点进行版图设计，以确保ALU的功能性与可制造性。通过分析功耗、面积和速度等性能指标，验证了该设计的高效性。4位ALU的成功实现展示了集成电路设计技术的进步潜力，以及CMOS技术在现代计算系统中实际应用的广阔前景。"
  },
  {
    "date": "2026-2-3",
    "title": "Lightweight Statistical Model for Bash Command Recommendation",
    "authors": "Cuong Tran Manh, Duy Ngo Hoang, Hieu Dinh Vo",
    "publish": "2025 RIVF International Conference on Computing and Communication Technologies (RIVF)",
    "url": "https://doi.org/10.1109/rivf68649.2025.11365121",
    "source": "IEEE",
    "abstract": "Command-line interfaces like Bash are essential tools for developers and system administrators, enabling efficient interaction with operating systems. However, existing support tools, such as auto-completion, still rely on simple solutions based on history lookups or pre-defined, static rules, failing to learn from individual user workflows and adapt to personalized patterns. This paper presents a lightweight, data-driven approach for Bash command recommendation using a statistical n-gram model designed to run efficiently on typical hardware without NPUs/GPUs or cloud-based services, thereby ensuring data privacy and low latency. This paper also introduces a novel sessionized dataset constructed from GitHub user histories and Q&A forums. Our model handles two key tasks, which are are intra-command completion and inter-command prediction. Experiments show high effectiveness and efficiency: key results include <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{7 0 \\%}$</tex> Top-1 accuracy for intra-command completion, over <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{7 1 \\%}$</tex> Top-3 accuracy for inter-command, and latencies under 50 ms on a mid-range CPU. This work confirms that a lightweight approach can provide a more personalized and practical command line experience, outperforming rule-based tools like bash-completion in adaptability while avoiding the computational overhead and data privacy risks of cloud-based LLMs.",
    "title_zh": "轻量级统计模型用于Bash命令推荐",
    "abstract_zh": "命令行界面（如 Bash）是开发人员和系统管理员不可或缺的工具，能够高效地与操作系统进行交互。然而，现有的支持工具（如自动补全）仍依赖于基于历史记录查找或预定义静态规则的简单解决方案，无法从用户个人的工作流程中学习，也无法适应个性化的使用模式。本文提出了一种轻量级、数据驱动的 Bash 命令推荐方法，采用统计 n-gram 模型，能够在普通硬件（无需 NPU/GPU 或云服务）上高效运行，从而确保数据隐私并实现低延迟。本文还构建了一个新颖的会话化数据集，其数据来源于 GitHub 用户历史记录和问答论坛。我们的模型能够处理两个关键任务：命令内补全（intra-command completion）和命令间预测（inter-command prediction）。实验结果表明，该方法在有效性和效率方面均表现出色：命令内补全的 Top-1 准确率高达 70%，命令间预测的 Top-3 准确率超过 71%，在中端 CPU 上延迟低于 50 毫秒。本研究证实，轻量级方法能够提供更加个性化且实用的命令行体验，在适应性方面优于基于规则的工具（如 bash-completion），同时避免了基于云的大语言模型所带来的计算开销和数据隐私风险。"
  },
  {
    "date": "2026-2-3",
    "title": "Design and Implementation of Low-Area FIR Filter Using Partial Product Based Methodology",
    "authors": "N Siva Naga Malleswari, Bommina Lakshmi Lavanya, Tottaramudi Prasanthi Devi, Polukonda Harshitha",
    "publish": "2025 13th International Conference on Intelligent Embedded, MicroElectronics, Communication and Optical Networks (IEMECON)",
    "url": "https://doi.org/10.1109/iemecon69302.2025.11365782",
    "source": "IEEE",
    "abstract": "A block-based FIR filter architecture using the partial product method has been designed for a filter order of 32 with block size 8. Verilog HDL was used for implementation, and the design was simulated using Xilinx Vivado. The architecture is evaluated using area delay product (ADP) and energy-per-output (EPO) metrics. The proposed filter achieves an ADP of <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\text{1, 1 5 5} \\mu \\mathrm{m}^{\\mathrm{2}} \\cdot \\text{n s}$</tex>, demonstrating a <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\text{9 5. 9 \\%}$</tex> improvement over the reference ASIC-based architecture. However, this gain in speed and area efficiency results in an increase in energy consumption, with EPO reaching <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$132.50 \\text{pJ} 911 \\%$</tex> higher than the ASIC implementation. These results highlight the effectiveness of design in applications that prioritize speed and resource efficiency over power consumption.",
    "title_zh": "基于部分积方法的低面积FIR滤波器设计与实现",
    "abstract_zh": "针对32阶、分块大小为8的FIR滤波器，设计了一种基于部分积方法的分块架构。该设计采用Verilog HDL实现，并在Xilinx Vivado环境中进行了仿真。通过面积-延迟乘积（ADP）和每输出能量（EPO）指标对架构进行评估。所提出的滤波器实现了1,155 μm²·ns的ADP，相较于参考的ASIC架构提升了95.9%。然而，这种速度与面积效率的提升也带来了能耗的增加，EPO达到132.50 pJ，比ASIC实现高出911%。这些结果表明，该设计在对速度和资源效率要求较高而对功耗相对不敏感的应用中具有显著优势。"
  },
  {
    "date": "2026-2-3",
    "title": "CITRAP: A Configurable Infrastructure Template for Rapid Prototyping on FPGAs",
    "authors": "Vitalii Burtsev, Martin Wilhelm, Nandhish Thathanur Rajappa, Ilia Sozutov, Thilo Pionteck",
    "publish": "2025 International Conference on Field Programmable Technology (ICFPT)",
    "url": "https://doi.org/10.1109/icfpt67023.2025.00035",
    "source": "IEEE",
    "abstract": "Despite advances in high-level tool chains, rapid prototyping of FPGA-based accelerators poses significant challenges. First, creating the basic interface infrastructure for the Unit Under Test evaluation, such as PCIe interfaces and DRAM controllers, is a time-consuming process. Second, with each iteration of UUT debugging, the static design requires complete synthesis from scratch. Third, frameworks with a high level of abstraction do not provide direct access to the UUT signals for debugging. In this paper, we introduce an open-source solution called CITRAP, a lightweight and reusable template that supports native debugging tools. It simplifies the process of creating infrastructure through the use of template scripts and standard IP-cores. The hardware design consists of two parts: a static infrastructure partition and a user logic partition. The static partition provides the infrastructure with interfaces, is synthesized only once, and stays untouched in the FPGA throughout debugging iterations. The user logic partition hosts the UUT, supports IP-cores for debugging and can be resynthesized and reconfigured independently by using Xilinx's Dynamic Function Exchange technology. Unlike more complex frameworks such as XRT, TAPASCO and OpenCPI, our approach does not introduce new abstraction overhead, allows for faster design cycles while providing full access to debug signals.",
    "title_zh": "CITRAP：一种用于FPGA快速原型设计的可配置基础设施模板",
    "abstract_zh": "尽管高级工具链取得了进展，基于FPGA的加速器快速原型设计仍面临诸多挑战。首先，为待测单元（UUT）评估构建基本的接口基础设施（如PCIe接口和DRAM控制器）耗时较长。其次，在每次UUT调试迭代过程中，静态设计都需要从头开始进行完整综合。第三，抽象层次较高的框架无法直接访问UUT的信号，不利于调试。本文提出了一种名为CITRAP的开源解决方案，这是一种轻量级且可复用的模板，支持原生调试工具。通过使用模板脚本和标准IP核，CITRAP简化了基础设施的构建过程。硬件设计分为两部分：静态基础设施分区和用户逻辑分区。静态分区提供接口所需的基础设施，仅需综合一次，并在FPGA上调试迭代过程中保持不变。用户逻辑分区用于承载UUT，支持用于调试的IP核，可借助Xilinx的动态功能交换（Dynamic Function Exchange）技术独立地重新综合与重新配置。与XRT、TAPASCO和OpenCPI等更复杂的框架相比，我们的方法不引入新的抽象开销，在提供完整调试信号访问的同时，显著加快了设计迭代速度。"
  },
  {
    "date": "2026-2-3",
    "title": "Design and Optimization Strategies for Streamlined Power Grid Automation Systems",
    "authors": "S Chaitrashree, Eleena Mohapatra",
    "publish": "2025 6th International Conference on Communication, Computing &amp;amp; Industry 6.0 (C2I6)",
    "url": "https://doi.org/10.1109/c2i666499.2025.11366960",
    "source": "IEEE",
    "abstract": "Power grid planning is a crucial stage in System-on-Chip (SoC) physical design, ensuring that voltage is distributed uniformly across logic, memory, and analog regions while minimizing IR-drop, electromigration, and noise issues. Traditional flows rely on manual Tcl scripts, which require repeated customization per block and per technology node. These methods are not scalable, often consume $2-3$ hours of manual effort, and increase susceptibility to human error. This paper presents a Python-driven automation framework for PSDL (Power supply definition Language) based power grid generation. The framework eliminates manual Tcl coding by accepting design specifications such as stripe width, step size, metal layers, offsets, and power domains as input in a structured CSV/XLS file. A Python parser processes this file, dynamically generating PSDL code that defines both pattern specifications and region constraints. The validated script is then executed in Innovus to route the power mesh across multi-layer stacks (M1-M8). Compared with conventional flows, the proposed automation achieved up to a 90% reduction in setup time, cutting power grid creation from 120-180 minutes to under 10 minutes. Additionally, it improved verification reliability by 35%, reduced debugging iterations, and enabled seamless multi-domain support. This structured and reusable approach significantly enhances accuracy, productivity, and scalability in advanced SoC power planning.",
    "title_zh": "简化电力电网自动化系统的设计与优化策略",
    "abstract_zh": "电源网络规划是片上系统（SoC）物理设计中的关键阶段，旨在确保逻辑、存储和模拟区域之间的电压分布均匀，同时最大限度地降低IR压降、电迁移及噪声等问题。传统方法依赖于手动编写的Tcl脚本，需针对每个模块和每种工艺节点反复进行定制，不仅难以扩展，通常还需耗费2至3小时的人工操作时间，且极易引入人为错误。本文提出了一种基于Python的自动化框架，用于驱动基于PSDL（电源供应定义语言）的电源网格生成。该框架通过结构化的CSV/XLS文件接收设计参数，如条带宽度、步进尺寸、金属层、偏移量以及电源域等信息，完全取代了传统的手动Tcl编码。一个Python解析器会读取这些输入数据，并动态生成包含模式定义与区域约束的PSDL代码。经验证的脚本随后在Innovus中执行，实现多层堆叠（M1-M8）上的电源网格布线。与传统流程相比，该自动化方案将设置时间最多减少90%，使电源网格创建时间从原来的120-180分钟缩短至10分钟以内。此外，验证可靠性提升35%，调试迭代次数显著减少，并支持无缝的多电源域集成。这种结构化、可复用的方法显著提升了先进SoC电源规划中的准确性、生产效率与可扩展性。"
  },
  {
    "date": "2026-2-3",
    "title": "Self Replication Mode for Network Intrusion Detection of Imperative Node Evaluator",
    "authors": "B. Sarvesan, R. Elankavi, Potli Harshavardhanreddy, G Jahnavi, Penakalapati Harsha Vardhan, Bayatapalle Jahnavi",
    "publish": "2025 13th International Conference on Intelligent Embedded, MicroElectronics, Communication and Optical Networks (IEMECON)",
    "url": "https://doi.org/10.1109/iemecon69302.2025.11365773",
    "source": "IEEE",
    "abstract": "Security is now a critical concern for modern systems due to network expansion. Keeping an eye out for anomalies in user behavior is a helpful fraud detection tactic. This is a plan for an intrusion detection system using techniques like self-replication and pattern matching. The system notifies other nodes to be on the lookout for potentially damaging event sequences by identifying potentially dangerous symptoms in the surrounding environment. The suggested model, Imperative Node Evaluator with Self Replication Code and Auto Triggering Mode (INE-SRC-ATM), is made to automatically trigger nodes to secure the network and lessen false alarms, as well as to automatically repair the network in the event of an intrusion. When there is a difference in characteristics that raise the bar for network security, the suggested model reacts instantly. Both the accuracy of self-replication triggering and the degrees of intrusion detection demonstrate good performance of this model in intrusion detection.",
    "title_zh": "指令节点评估的网络入侵检测自复制模式",
    "abstract_zh": "由于网络的扩展，安全已成为现代系统中一个至关重要的问题。监控用户行为中的异常是有效的欺诈检测策略之一。本文提出了一种基于自复制和模式匹配技术的入侵检测系统方案。该系统通过识别周围环境中的潜在危险征兆，通知其他节点提高警惕，防范可能造成损害的事件序列。所提出的模型——具有自复制代码与自动触发模式的强制性节点评估器（INE-SRC-ATM），旨在自动触发节点以保护网络、减少误报，并在发生入侵时自动修复网络。当网络安全性特征出现差异并达到更高安全标准时，该模型能够立即响应。实验结果表明，该模型在自复制触发的准确性以及入侵检测的灵敏度方面均表现出色。"
  },
  {
    "date": "2026-2-3",
    "title": "A Quad-core 32-bit RISC-V CPU Implementation with Design Verification on 130 nm CMOS Process",
    "authors": "Le-Thanh-Nhon Nguyen, Khai-Minh Ma, Tran-Bao-Thuong Cao, Duc-Hung Le",
    "publish": "2025 RIVF International Conference on Computing and Communication Technologies (RIVF)",
    "url": "https://doi.org/10.1109/rivf68649.2025.11365156",
    "source": "IEEE",
    "abstract": "This paper presents implementation of a System-on-Chip consisting of 4 CPU cores, each core contains 32-bit RISC-V architecture. The authors proposed a script to implement a complete back-end flow from Place-and-Route to design verification on Skywater 130 nm process. The system had the core size <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$2.5 \\times 3.5 \\text{mm}$</tex>, approximately <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$10 \\text{mm}^{2}$</tex>. The operation frequency is 100 MHz. The author proposed a digital design and verification design flow with SystemVerilog to verify the functions of the system after back-end design process for improving the correctness of the design.",
    "title_zh": "基于130 nm CMOS工艺的四核32位RISC-V CPU实现及其设计验证",
    "abstract_zh": "本文介绍了基于4个CPU核心的片上系统（System-on-Chip）的实现，每个核心均采用32位RISC-V架构。作者提出了一套脚本，实现了从布局布线（Place-and-Route）到设计验证的完整后端流程，工艺节点为Skywater 130 nm。该系统的核心尺寸为$2.5 \\times 3.5 \\text{mm}$，约为$10 \\text{mm}^{2}$，工作频率为100 MHz。作者提出了一种基于SystemVerilog的数字设计与验证流程，用于在后端设计完成后验证系统的功能，以提高设计的正确性。"
  },
  {
    "date": "2026-2-3",
    "title": "No More Hidden Pitfalls? Exposing Smart Contract Bad Practices with LLM-Powered Hybrid Analysis",
    "authors": "Xiaoqi Li, Zongwei Li, Wenkai Li, Yuqing Zhang, Xin Wang",
    "publish": "ACM Transactions on Software Engineering and Methodology",
    "url": "https://doi.org/10.1145/3795692",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "不再有隐藏的陷阱？利用LLM驱动的混合分析揭露智能合约的不良实践",
    "abstract_zh": "None"
  },
  {
    "date": "2026-2-3",
    "title": "TaK-Fuzz: Transaction-aware Knowledge Smart Contract Fuzzing with Retrieval-Augmented Generation and Language Models",
    "authors": "Nguyen Ho Nhat Khoa, Nguyen Thanh Kiet, Vo Truong Trung Hieu, Truong Thi Hoang Hao, Phan The Duy",
    "publish": "2025 RIVF International Conference on Computing and Communication Technologies (RIVF)",
    "url": "https://doi.org/10.1109/rivf68649.2025.11365172",
    "source": "IEEE",
    "abstract": "Ensuring smart contract security remains a major challenge in the blockchain ecosystem, and automated fuzzing is vital for detecting vulnerabilities. Traditional fuzzing methods often lack sufficient code coverage and resource efficiency, especially in complex contracts. In this work, we introduce TaK-Fuzz, a transaction-aware fuzzing framework that leverages RetrievalAugmented Generation and expert knowledge extracted from audit reports to guide intelligent creation of testcases. TaK-Fuzz has a vector database of vulnerability patterns from audited contracts and, for each fuzzing target, retrieves relevant entries based on semantic similarity. These insights are then used as context for a large language model, which applies Chain-of-Thought (CoT) reasoning to generate focused and effective test cases for smart contract fuzzing. Experimental evaluation shows that TaK-Fuzz consistently outperforms the baseline MuFuzz across code coverage, vulnerability detection, and efficiency. For instance, on the Soli-Audit dataset, TaK-Fuzz achieves nearly complete branch coverage (99.43 %) while requiring only a fraction of the testcases compared to MuFuzz. Overall, it not only improves recall in detecting critical vulnerabilities but also reduces resource consumption by orders of magnitude. These results confirm that by combining knowledge retrieval with reasoning-driven test generation, TaK-Fuzz maximizes vulnerability discovery while maintaining high efficiency, establishing itself as a robust solution for smart contract fuzzing.",
    "title_zh": "TaK-Fuzz：基于检索增强生成与语言模型的交易感知知识智能合约模糊测试",
    "abstract_zh": "确保智能合约安全仍是区块链生态系统中的重大挑战，而自动化模糊测试在漏洞检测中至关重要。传统模糊测试方法往往在代码覆盖率和资源效率方面表现不足，尤其是在复杂合约场景下。本文提出了一种名为TaK-Fuzz的交易感知模糊测试框架，该框架利用检索增强生成技术（Retrieval-Augmented Generation）以及从审计报告中提取的专家知识，指导智能生成测试用例。TaK-Fuzz构建了一个基于已审计合约的漏洞模式向量数据库，针对每个模糊测试目标，通过语义相似性检索相关条目。这些检索到的洞察作为上下文输入大型语言模型，模型采用思维链（Chain-of-Thought, CoT）推理机制，生成针对性强且高效的智能合约模糊测试用例。实验评估表明，TaK-Fuzz在代码覆盖率、漏洞检测能力及执行效率方面均持续优于基线方法MuFuzz。例如，在Soli-Audit数据集上，TaK-Fuzz实现了接近完全的分支覆盖率（99.43%），同时所需测试用例数量仅为MuFuzz的极小部分。总体而言，该方法不仅显著提升了对关键漏洞的召回率，还使资源消耗降低了一个数量级以上。结果表明，通过将知识检索与基于推理的测试生成相结合，TaK-Fuzz在保证高效率的同时最大化漏洞发现能力，成为智能合约模糊测试领域一项稳健可靠的解决方案。"
  },
  {
    "date": "2026-2-3",
    "title": "Assessing Methods to Categorize Questions According to Cognitive Level based on Blooms Taxonomy: Constraints and Future Direction",
    "authors": "Pranit Das, Dhriti Chakraborty, Prasenjit Choudhury",
    "publish": "2025 Seventh International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN)",
    "url": "https://doi.org/10.1109/icrcicn68210.2025.11364827",
    "source": "IEEE",
    "abstract": "Automated systems that classify questions according to Bloom’s Taxonomy (BT) levels often struggle to accurately capture the underlying cognitive complexity. Existing supervised learning approaches frequently fail to distinguish between factual, analytical, and creative queries, as a result, chatbots and various educational platforms generate generic and one-size-fitsall responses. The objective of this study is to evaluate machine learning (ML) and deep learning (DL) approaches for BTbased question classification using 2,532 questions from multiple datasets and compare it with prompt based approaches. Crossdataset evaluation reveal a significant decline in performance in ML and DL approaches, highlighting the limitations of supervised learning techniques. Further analysis of out-of-vocabulary (OOV) terms uncovers gaps in the coverage of BT action verbs, which hinders accurate classification. These findings demonstrate that ML and DL approaches fail to reliably classify questions, revealing substantial limitations in identifying learning intent and information need, that significantly hinders the ability to deliver personalized content. To mitigate these issues, promptbased generative classification approaches using instructiontuned Large Language Model (LLM) is tested. Without relying on fixed vocabularies, the method nullifies OOV errors and better handles verb overlap by using LLM’s contextual knowledge trained on vast natural language.",
    "title_zh": "基于布卢姆分类法评估对问题进行认知层次分类的方法：局限性与未来方向",
    "abstract_zh": "根据布卢姆教育目标分类法（Bloom’s Taxonomy, BT）对问题进行自动分类的系统，通常难以准确捕捉其背后的认知复杂性。现有的监督学习方法常常无法有效区分事实性、分析性和创造性问题，导致聊天机器人和各类教育平台生成通用化、千篇一律的回答。本研究旨在评估机器学习（ML）与深度学习（DL）方法在基于BT的问题分类中的表现，使用来自多个数据集的2,532个问题进行实验，并与基于提示（prompt-based）的方法进行对比。跨数据集评估结果显示，ML与DL方法的性能显著下降，凸显了监督学习技术的局限性。进一步对未登录词（OOV）的分析揭示了BT动作动词覆盖不足的问题，这严重影响了分类的准确性。研究结果表明，ML与DL方法在问题分类上难以可靠地进行，暴露出其在识别学习意图和信息需求方面存在重大缺陷，从而严重制约了个性化内容的精准推送。为缓解上述问题，本文测试了基于提示的生成式分类方法，采用经过指令微调的大语言模型（LLM）。该方法无需依赖固定词汇表，有效避免了OOV错误，并通过LLM在海量自然语言数据上训练所得的上下文理解能力，更好地处理了动词之间的语义重叠问题。"
  },
  {
    "date": "2026-2-3",
    "title": "SPECK Algorithm Implementation in VLSI: A Verilog-Based Approach for Efficient Simulation, Synthesis and Cryptographic Enhancement",
    "authors": "S.R. Arun Raj, G. Ramana Murthy, Pravin A. Dwaramwar, C. Thangamani, Dilip I. Sangotra, T.C. Manjunath",
    "publish": "2025 6th International Conference on Communication, Computing &amp;amp; Industry 6.0 (C2I6)",
    "url": "https://doi.org/10.1109/c2i666499.2025.11366956",
    "source": "IEEE",
    "abstract": "Cryptography plays a key role in ensuring data security in resources, such as IoT devices, built -in systems and wireless sensor networks. Speck algorithm is a light encryption block designed by the NSA in 2013, which offers a balance between security and efficiency. This project focuses on the design, simulation and implementation of the RTL algorithm with the Verilog. The primary objectives of this work include designing the effective Verilog code to verify its correctness through simulation. The design includes the implementation of key expansion, encryption and decryption processes in optimization for area, performance and performance. The verilog -based design is simulated and verified by testing shots to ensure that correctness is correct. This work contributes to ongoing hardware security research by providing an efficient and scalable implementation of Speck -based verilog, suitable for IoT and built -in systems. Index expressions Performance analysis, verilog, design RTL, encryption, key spot, expansion, simulation, light cryptography, decryption…",
    "title_zh": "SPECK算法在VLSI中的实现：基于Verilog的高效仿真、综合与密码学增强方法",
    "abstract_zh": "密码学在确保物联网设备、嵌入式系统和无线传感器网络等资源受限环境中的数据安全方面发挥着关键作用。Speck算法是由美国国家安全局（NSA）于2013年设计的一种轻量级分组加密算法，兼顾了安全性与效率。本项目聚焦于Speck算法的RTL级设计、仿真与实现，采用Verilog语言进行开发。本工作的主要目标包括：设计高效的Verilog代码，并通过仿真验证其正确性。设计内容涵盖密钥扩展、加密与解密过程的优化，以实现面积、性能和能效的综合优化。基于Verilog的硬件设计通过测试用例进行仿真与验证，确保其功能正确。本研究为硬件安全领域的持续发展提供了高效且可扩展的Speck算法Verilog实现方案，适用于物联网及嵌入式系统应用场景。  \n关键词：性能分析，Verilog，RTL设计，加密，密钥扩展，仿真，轻量级密码学，解密"
  }
]