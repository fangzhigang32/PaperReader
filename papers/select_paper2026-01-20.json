[
  {
    "date": "2026-01-20",
    "title": "Reasoning is a Modality",
    "authors": "Zhiguang Liu, Yi Shang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13562v1",
    "source": "arXiv",
    "abstract": "The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.",
    "title_zh": "推理是一种可能性。",
    "abstract_zh": "抽象与推理语料库（ARC）为研究抽象推理这一人类智能的核心能力提供了一个精炼的实验平台。现代人工智能系统，包括大语言模型（LLMs）和视觉Transformer（ViTs），在很大程度上仅作为行为序列预测机器运行：它们通过建模标记统计来匹配可观测行为，而缺乏一个持续且可读的心理状态。这导致了与人类行为之间的差距：人类能够通过解码内部状态来解释某个行为，而AI系统虽然可以生成流畅的“事后合理化”解释，但这些解释并不基于真实的内在状态。我们提出假设：推理应被视为一种独立的模态——它应当作为一个与规则应用所依赖的底层工作空间相分离的独立通道存在。为了验证这一假设，我们在将ARC任务视为视觉推理问题的背景下，设计了一种新型的角色分离Transformer模块，该模块将全局控制器标记与网格工作区标记分离开来，从而支持迭代式规则执行。在以视觉为中心的VARC协议下进行训练和评估，我们的方法在ARC-1上的准确率达到62.6%，超过了平均人类表现（60.2%），并显著优于以往的方法。定性分析表明，相较于密集型ViT基线模型，我们的模型展现出更连贯的规则应用结构，这与从“看似合理的概率块”向由控制器驱动的推理模式转变的趋势一致。"
  },
  {
    "date": "2026-01-20",
    "title": "Multi-Location Software Model Completion",
    "authors": "Alisa Welter, Christof Tinnes, Sven Apel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13894v1",
    "source": "arXiv",
    "abstract": "In model-driven engineering and beyond, software models are key development artifacts. In practice, they often grow to substantial size and complexity, undergoing thousands of modifications over time due to evolution, refactoring, and maintenance. The rise of AI has sparked interest in how software modeling activities can be automated. Recently, LLM-based approaches for software model completion have been proposed, however, the state of the art supports only single-location model completion by predicting changes at a specific location. Going beyond, we aim to bridge the gap toward handling coordinated changes that span multiple locations across large, complex models. Specifically, we propose a novel global embedding-based next focus predictor, NextFocus, which is capable of multi-location model completion for the first time. The predictor consists of a neural network with an attention mechanism that is trained on historical software model evolution data. Starting from an existing change, it predicts further model elements to change, potentially spanning multiple parts of the model. We evaluate our approach on multi-location model changes that have actually been performed by developers in real-world projects. NextFocus achieves promising results for multi-location model completion, even when changes are heavily spread across the model. It achieves an average Precision@k score of 0.98 for $k \\leq 10$, significantly outperforming the three baseline approaches.",
    "title_zh": "多地点软件模型补全",
    "abstract_zh": "在模型驱动工程及其他领域，软件模型是关键的开发资产。实际上，这些模型往往随着时间推移不断演化、重构和维护，经历数千次修改，规模与复杂性持续增长。随着人工智能的兴起，人们开始关注如何自动化软件建模活动。近年来，基于大语言模型（LLM）的软件模型补全方法被提出，但当前最先进的技术仅支持单一位置的模型补全，即只能预测特定位置的变更。而我们则致力于突破这一局限，推动对跨多个位置的协调变更处理能力的发展，以应对大型复杂模型中的多位置变更需求。为此，我们提出了一种全新的基于全局嵌入的“下一个关注点”预测器——NextFocus，首次实现了多位置模型补全。该预测器采用带有注意力机制的神经网络，并基于历史软件模型演化数据进行训练。从一个已有的变更出发，它能够预测后续需要修改的多个模型元素，可能涉及模型的不同部分。我们在真实项目中开发者实际执行过的多位置模型变更上评估了本方法。实验结果表明，NextFocus在多位置模型补全任务中表现优异，即使变更广泛分布于整个模型，仍能取得良好效果。当 $k \\leq 10$ 时，其平均 Precision@k 达到 0.98，显著优于三种基线方法。"
  },
  {
    "date": "2026-01-20",
    "title": "Area-universality in Outerplanar Graphs",
    "authors": "Ravi Suthar, Raveena, Krishnendra Shekhawat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13781v1",
    "source": "arXiv",
    "abstract": "A rectangular floorplan is a partition of a rectangle into smaller rectangles such that no four rectangles meet at a single point. Rectangular floorplans arise naturally in a variety of applications, including VLSI design, architectural layout, and cartography, where efficient and flexible spatial subdivisions are required. A central concept in this domain is that of area-universality: a floorplan (or more generally, a rectangular layout) is area-universal if, for any assignment of target areas to its constituent rectangles, there exists a combinatorially equivalent layout that realizes these areas. In this paper, we investigate the structural conditions under which an outerplanar graph admits an area-universal rectangular layout. We establish a necessary and sufficient condition for area-universality in this setting, thereby providing a complete characterization of admissible outerplanar graphs. Furthermore, we present an algorithmic construction that guarantees that the resulting layout is always area-universal.",
    "title_zh": "外平面图中的区域通用性",
    "abstract_zh": "一个矩形平面图是将一个矩形分割成若干较小矩形的一种划分方式，且不存在四个矩形在同一点交汇的情况。矩形平面图在多种应用中自然出现，包括超大规模集成电路（VLSI）设计、建筑设计以及地图绘制等领域，这些领域均需要高效且灵活的空间划分。该领域的一个核心概念是面积通用性：若一个平面图（或更一般地，一个矩形布局）具有面积通用性，则对于其各个组成部分矩形的任意目标面积分配，都存在一个组合等价的布局能够实现这些面积。本文研究了在外平面图条件下，何种结构特征使其能够拥有面积通用的矩形布局。我们建立了该情形下面积通用性的充要条件，从而对可实现的外平面图给出了完整的刻画。此外，我们提出了一种算法构造方法，保证所生成的布局始终具备面积通用性。"
  },
  {
    "date": "2026-01-20",
    "title": "Generative Intent Prediction Agentic AI empowered Edge Service Function Chain Orchestration",
    "authors": "Yan Sun, Shaoyong Guo, Sai Huang, Zhiyong Feng, Feng Qi, Xuesong Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13694v1",
    "source": "arXiv",
    "abstract": "With the development of artificial intelligence (AI), Agentic AI (AAI) based on large language models (LLMs) is gradually being applied to network management. However, in edge network environments, high user mobility and implicit service intents pose significant challenges to the passive and reactive management of traditional AAI. To address the limitations of existing approaches in handling dynamic demands and predicting users' implicit intents, in this paper we propose an edge service function chain (SFC) orchestration framework empowered by a Generative Intent Prediction Agent (GIPA). Our GIPA aims to shift the paradigm from passive execution to proactive prediction and orchestration. First, we construct a multidimensional intent space that includes functional preferences, QoS sensitivity, and resource requirements, enabling the mapping from unstructured natural language to quantifiable physical resource demands. Second, to cope with the complexity and randomness of intent sequences, we design an intent prediction model based on a Generative Diffusion Model (GDM), which reconstructs users' implicit intents from multidimensional context through a reverse denoising process. Finally, the predicted implicit intents are embedded as global prompts into the SFC orchestration model to guide the network in proactively and ahead-of-time optimizing SFC deployment strategies. Experiment results show that GIPA outperforms existing baseline methods in highly concurrent and highly dynamic scenarios.",
    "title_zh": "生成式意图预测赋能的智能边缘服务功能链编排",
    "abstract_zh": "随着人工智能（AI）的发展，基于大语言模型（LLMs）的代理型人工智能（AAI）正逐步应用于网络管理。然而，在边缘网络环境中，用户高度移动性以及服务意图的隐含性给传统AAI被动、反应式的管理模式带来了巨大挑战。为解决现有方法在应对动态需求及预测用户隐含意图方面的局限性，本文提出了一种由生成式意图预测代理（GIPA）驱动的边缘服务功能链（SFC）编排框架。我们的GIPA旨在实现从被动执行向主动预测与编排范式的转变。首先，我们构建了一个包含功能偏好、QoS敏感度和资源需求在内的多维意图空间，实现了从非结构化自然语言到可量化的物理资源需求的映射。其次，针对意图序列的复杂性与随机性，我们设计了一种基于生成式扩散模型（GDM）的意图预测模型，通过逆向去噪过程从多维上下文中重构用户的隐含意图。最后，将预测得到的隐含意图作为全局提示嵌入SFC编排模型中，引导网络提前、主动地优化SFC部署策略。实验结果表明，在高并发、高度动态的场景下，GIPA显著优于现有的基线方法。"
  },
  {
    "date": "2026-01-20",
    "title": "ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch",
    "authors": "Zheng Liu, Honglin Lin, Chonghan Qin, Xiaoyang Wang, Xin Gao, Yu Li, Mengzhang Cai, Yun Zhu, Zhanping Zhong, Qizhi Pei, Zhuoshi Pan, Xiaoran Shang, Bin Cui, Conghui He, Wentao Zhang, Lijun Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13606v1",
    "source": "arXiv",
    "abstract": "Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.",
    "title_zh": "ChartVerse：通过从零开始的可靠程序合成实现图表推理的扩展",
    "abstract_zh": "图表推理是视觉语言模型（VLMs）的一项关键能力。然而，由于高质量训练数据的缺乏，开源模型的发展受到严重制约。现有的数据集面临双重挑战：合成图表通常过于简单且重复性高，而相应的问答对则容易出现幻觉，缺乏完成复杂任务所需的推理深度。为弥合这一差距，我们提出了 ChartVerse——一个可扩展的框架，旨在从零开始合成复杂的图表与可靠的推理数据。\n\n（1）为解决模式单一的问题，我们首先引入**滚动后验熵**（Rollout Posterior Entropy, RPE），这是一种新颖的度量指标，用于量化图表的复杂程度。基于RPE的指导，我们开发了具备复杂度感知能力的图表编码器，能够通过可执行程序自主生成多样且高复杂度的图表。\n\n（2）为确保推理的严谨性，我们提出**基于真实答案的逆向问答合成**方法。不同于传统的生成范式，我们采用“先答后问”的策略：直接从源代码中提取确定性答案，再根据这些锚点生成条件化问题，并强制进行严格的逻辑一致性验证。为进一步提升难度与推理深度，我们依据模型失败率筛选样本，并提炼高质量的思维链（Chain-of-Thought, CoT）推理过程。\n\n我们利用 Qwen3-VL-30B-A3B-Thinking 作为教师模型，构建了 ChartVerse-SFT-600K 和 ChartVerse-RL-40K 数据集。实验结果表明，ChartVerse-8B 在性能上达到当前最优水平，显著超越其教师模型，并接近更强的 Qwen3-VL-32B-Thinking 模型的表现。"
  },
  {
    "date": "2026-01-20",
    "title": "Counterexample Classification against Signal Temporal Logic Specifications",
    "authors": "Zhenya Zhang, Parv Kapoor, Jie An, Eunsuk Kang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13743v1",
    "source": "arXiv",
    "abstract": "Signal Temporal Logic (STL) has been widely adopted as a specification language for specifying desirable behaviors of hybrid systems. By monitoring a given STL specification, we can detect the executions that violate it, which are often referred to as counterexamples. In practice, these counterexamples may arise from different causes and thus are relevant to different system defects. To effectively address this, we need a proper criterion for classifying these counterexamples, by which we can comprehend the possible violation patterns and the distributions of these counterexamples with respect to the patterns. In this paper, we propose a classification criterion by using parametric signal temporal logic (PSTL) to represent each class. Due to this formalism, identifying the classes of a counterexample requires finding proper parameter values of PSTL that enable a class to include the counterexample. To improve the efficiency of class identification, we further derive an inclusion relation between different classes, and then propose a binary search-like approach over it that significantly prunes the classes needed to query. We implement a prototype tool and experimentally evaluate its effectiveness on two widely-studied systems.",
    "title_zh": "针对信号时序逻辑规范的反例分类",
    "abstract_zh": "信号时序逻辑（STL）已被广泛用作描述混合系统期望行为的规范语言。通过监控给定的STL规范，我们可以检测出违反该规范的执行路径，这些路径通常被称为反例。在实际应用中，这些反例可能由不同原因引起，因而与不同的系统缺陷相关。为了有效应对这一问题，我们需要一个合适的分类标准，以便理解可能的违规模式以及反例在各类模式中的分布情况。本文提出了一种基于参数化信号时序逻辑（PSTL）来表示每一类反例的分类准则。由于采用了这种形式化方法，确定某个反例所属类别需要找到适当的PSTL参数值，使得该类别能够包含该反例。为提高类别识别的效率，我们进一步推导出不同类别之间的包含关系，并在此基础上提出一种类似二分查找的搜索策略，显著减少了需查询的类别数量。我们实现了一个原型工具，并在两个广泛研究的系统上进行了实验评估，验证了该方法的有效性。"
  },
  {
    "date": "2026-01-20",
    "title": "AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent",
    "authors": "Sun Hui, Ding Yanfeng, Huidong Ma, Chang Xu, Keyan Jin, Lizheng Zu, Cheng Zhong, xiaoguang Liu, Gang Wang, Wentong Cai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13559v1",
    "source": "arXiv",
    "abstract": "Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.",
    "title_zh": "AgentGC：基于进化学习的基因组数据无损压缩方法，结合大语言模型驱动的多智能体系统",
    "abstract_zh": "无损压缩在基因组数据（GD）的存储、共享与管理方面取得了显著进展。当前基于学习的方法存在不可演化性，且面临低层次压缩建模、适应性有限以及用户界面不友好等问题。为此，我们提出了AgentGC——首个基于智能体的进化式基因组数据压缩器，其架构包含三层：由多个智能体组成的领导（Leader）与工作（Worker）机制。具体而言：1）用户层通过Leader结合大语言模型（LLM），提供友好的用户交互界面；2）认知层由Leader驱动，利用LLM实现算法-数据-系统三者的联合优化，有效解决低层次建模和适应性不足的问题；3）压缩层由Worker主导，基于自动化的多知识学习框架完成压缩与解压操作。在此基础上，我们设计了三种模式以支持不同应用场景：CP模式侧重压缩率优先，TP模式侧重吞吐量优先，BM模式则为平衡模式。在9个数据集上与14个基线方法对比，AgentGC在压缩率上平均提升分别为16.66%、16.11%和16.33%，在吞吐量上分别提升4.73倍、9.23倍和9.15倍。"
  },
  {
    "date": "2026-01-20",
    "title": "Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models",
    "authors": "Changshuo Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13533v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the \"reason first, recommend later\" paradigm to achieve \"reasoning while recommending\", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.",
    "title_zh": "推理式推荐：生成重排序模型中的熵引导潜在推理",
    "abstract_zh": "强化学习在生成重排序场景中发挥着关键作用，得益于其探索与利用的平衡能力。然而，现有的生成方法大多无法适应模型难度在列表生成过程中动态变化的熵值，导致难以准确捕捉复杂的偏好关系。鉴于语言模型通过融入推理能力取得了显著突破，我们借鉴这一思路，引入一种潜在推理机制，实验验证表明该机制能有效降低模型决策过程中的熵值。基于此，我们提出了熵引导的潜在推理（Entropy-Guided Latent Reasoning, EGLR）推荐模型，具备三大核心优势：首先，该模型摒弃了“先推理、后推荐”的传统范式，实现了“边推荐边推理”，专为列表生成这一高难度任务设计，支持生成过程中的实时推理；其次，它采用熵引导的变长推理机制，结合上下文感知的推理标记与动态温度调节，既拓展了推理过程的探索广度，又提升了推荐阶段的利用精度，从而实现更精准的探索-利用权衡；第三，该模型采用轻量级集成设计，无需复杂的独立模块或后期处理，可轻松适配现有模型。在两个真实数据集上的实验结果验证了该模型的有效性，其显著优势在于能够兼容现有生成重排序模型并提升其性能。进一步分析也证明了其在实际部署中的价值以及广阔的研究潜力。"
  },
  {
    "date": "2026-01-20",
    "title": "On Autopilot? An Empirical Study of Human-AI Teaming and Review Practices in Open Source",
    "authors": "Haoyu Gao, Peerachai Banyongrakkul, Hao Guan, Mansooreh Zahedi, Christoph Treude",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13754v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) increasingly automate software engineering tasks. While recent studies highlight the accelerated adoption of ``AI as a teammate'' in Open Source Software (OSS), developer interaction patterns remain under-explored. In this work, we investigated project-level guidelines and developers' interactions with AI-assisted pull requests (PRs) by expanding the AIDev dataset to include finer-grained contributor code ownership and a comparative baseline of human-created PRs. We found that over 67.5\\% of AI-co-authored PRs originate from contributors without prior code ownership. Despite this, the majority of repositories lack guidelines for AI-coding agent usage. Notably, we observed a distinct interaction pattern: AI-co-authored PRs are merged significantly faster with minimal feedback. In contrast to human-created PRs where non-owner developers receive the most feedback, AI-co-authored PRs from non-owners receive the least, with approximately 80\\% merged without any explicit review. Finally, we discuss implications for developers and researchers.",
    "title_zh": "自动驾驶？开源领域人机协同与审查实践的实证研究",
    "abstract_zh": "大型语言模型（LLMs）正日益自动化软件工程任务。尽管近期研究强调了“AI作为团队成员”在开源软件（OSS）中的加速采用，但开发者与AI协作的互动模式仍鲜有深入探讨。本文通过扩展AIDev数据集，引入更细粒度的贡献者代码所有权信息，并构建了由人类创建PR的对比基准，系统研究了项目层面的指导规范以及开发者对AI辅助拉取请求（PR）的交互行为。研究发现，超过67.5%的AI共同撰写的PR来自此前无代码所有权的贡献者。然而，大多数代码仓库缺乏关于AI编码代理使用的明确规范。值得注意的是，我们观察到一种显著的互动模式：AI共同撰写的PR合并速度显著更快，且获得的反馈极少；相比之下，在人类创建的PR中，非所有者开发者通常会收到最多反馈，而AI协助下由非所有者提交的PR却获得最少反馈，约80%的此类PR在未经过任何显式审查的情况下即被合并。最后，本文讨论了这些发现对开发者和研究人员的启示。"
  },
  {
    "date": "2026-01-20",
    "title": "ORCA -- An Automated Threat Analysis Pipeline for O-RAN Continuous Development",
    "authors": "Felix Klement, Alessandro Brighente, Michele Polese, Mauro Conti, Stefan Katzenbeisser",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13681v1",
    "source": "arXiv",
    "abstract": "The Open-Radio Access Network (O-RAN) integrates numerous software components in a cloud-like deployment, opening the radio access network to previously unconsidered security threats. With the ever-evolving threat landscape, integrating security practices through a DevSecOps approach is essential for fast and secure releases. Current vulnerability assessment practices often rely on manual, labor-intensive, and subjective investigations, leading to inconsistencies in the threat analysis. To mitigate these issues, we establish an automated pipeline that leverages Natural Language Processing (NLP) to minimize human intervention and associated biases. By mapping real-world vulnerabilities to predefined threat lists with a standardized input format, our approach is the first to enable iterative, quantitative, and efficient assessments, generating reliable threat scores for both individual vulnerabilities and entire system components within O-RAN. We illustrate the effectiveness of our framework through an example implementation for O-RAN, showcasing how continuous security testing can integrate into automated testing pipelines to address the unique security challenges of this paradigm shift in telecommunications.",
    "title_zh": "ORCA——面向O-RAN持续开发的自动化威胁分析流程",
    "abstract_zh": "开放无线接入网（O-RAN）采用类似云的部署方式，集成了大量软件组件，这使得无线接入网络面临此前未曾考虑过的安全威胁。随着威胁环境不断演变，采用DevSecOps方法将安全实践融入开发流程，对于实现快速且安全的发布至关重要。然而，当前的漏洞评估方法大多依赖于手动、耗时且主观的调查，导致威胁分析结果不一致。为解决这些问题，我们建立了一个自动化流程，利用自然语言处理（NLP）技术减少人工干预及其带来的偏见。通过将真实世界中的漏洞映射到预定义的威胁列表，并采用标准化输入格式，我们的方法首次实现了迭代式、可量化的高效评估，能够为O-RAN中的单个漏洞及整个系统组件生成可靠的威胁评分。我们通过一个O-RAN的实际应用案例展示了该框架的有效性，说明持续安全测试如何融入自动化测试流程，以应对电信领域这一范式转变所带来的独特安全挑战。"
  },
  {
    "date": "2026-01-20",
    "title": "Foundations of Global Consistency Checking with Noisy LLM Oracles",
    "authors": "Paul He, Elke Kirschbaum, Shiva Kasiviswanathan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13600v1",
    "source": "arXiv",
    "abstract": "Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.",
    "title_zh": "基于噪声大模型代理的全球一致性检查基础",
    "abstract_zh": "确保自然语言事实集合的全局一致性对于事实核查、摘要生成和知识库构建等任务至关重要。尽管大型语言模型（LLMs）能够评估小规模事实子集的一致性，但其判断存在噪声，且成对检查不足以保证全局一致性。我们形式化了这一问题，并证明在最坏情况下，验证全局一致性需要指数级数量的预言机查询。为使该任务更具实用性，我们提出一种自适应的分治算法，用于识别事实的最小不一致子集（MUSes），并可选地通过击中集（hitting-sets）计算最小修复方案。我们的方法具有低阶多项式查询复杂度。在合成数据和真实LLM预言机上的实验表明，该方法能高效检测并定位不一致之处，为基于LLM评估器的语言一致性验证提供了一个可扩展的框架。"
  },
  {
    "date": "2026-01-20",
    "title": "Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration",
    "authors": "LSST Dark Energy Science Collaboration, Eric Aubourg, Camille Avestruz, Matthew R. Becker, Biswajit Biswas, Rahul Biswas, Boris Bolliet, Adam S. Bolton, Clecio R. Bom, Raphaël Bonnet-Guerrini, Alexandre Boucaud, Jean-Eric Campagne, Chihway Chang, Aleksandra Ćiprijanović, Johann Cohen-Tanugi, Michael W. Coughlin, John Franklin Crenshaw, Juan C. Cuevas-Tello, Juan de Vicente, Seth W. Digel, Steven Dillmann, Mariano Javier de León Dominguez Romero, Alex Drlica-Wagner, Sydney Erickson, Alexander T. Gagliano, Christos Georgiou, Aritra Ghosh, Matthew Grayling, Kirill A. Grishin, Alan Heavens, Lindsay R. House, Mustapha Ishak, Wassim Kabalan, Arun Kannawadi, François Lanusse, C. Danielle Leonard, Pierre-François Léget, Michelle Lochner, Yao-Yuan Mao, Peter Melchior, Grant Merz, Martin Millon, Anais Möller, Gautham Narayan, Yuuki Omori, Hiranya Peiris, Laurence Perreault-Levasseur, Andrés A. Plazas Malagón, Nesar Ramachandra, Benjamin Remy, Cécile Roucelle, Jaime Ruiz-Zapatero, Stefan Schuldt, Ignacio Sevilla-Noarbe, Ved G. Shah, Tjitske Starkenburg, Stephen Thorp, Laura Toribio San Cipriano, Tilman Tröster, Roberto Trotta, Padma Venkatraman, Amanda Wasserman, Tim White, Justine Zeghal, Tianqing Zhang, Yuanyuan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14235v1",
    "source": "arXiv",
    "abstract": "The Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful, scalable, and operationally reliable. Artificial intelligence and machine learning (AI/ML) are already embedded across DESC science workflows, from photometric redshifts and transient classification to weak lensing inference and cosmological simulations. Yet their utility for precision cosmology hinges on trustworthy uncertainty quantification, robustness to covariate shift and model misspecification, and reproducible integration within scientific pipelines. This white paper surveys the current landscape of AI/ML across DESC's primary cosmological probes and cross-cutting analyses, revealing that the same core methodologies and fundamental challenges recur across disparate science cases. Since progress on these cross-cutting challenges would benefit multiple probes simultaneously, we identify key methodological research priorities, including Bayesian inference at scale, physics-informed methods, validation frameworks, and active learning for discovery. With an eye on emerging techniques, we also explore the potential of the latest foundation model methodologies and LLM-driven agentic AI systems to reshape DESC workflows, provided their deployment is coupled with rigorous evaluation and governance. Finally, we discuss critical software, computing, data infrastructure, and human capital requirements for the successful deployment of these new methodologies, and consider associated risks and opportunities for broader coordination with external actors.",
    "title_zh": "人工智能/机器学习在鲁宾LSST暗能量科学合作项目中的机遇",
    "abstract_zh": "薇拉·C·鲁宾天文台的太空与时间遗产调查（LSST）将产生前所未有的海量异构天文学数据（图像、星表和警报），这对传统的数据分析流程提出了严峻挑战。LSST暗能量科学合作组织（DESC）旨在从这些数据中获得对暗能量和暗物质的稳健约束，这需要具备统计强大性、可扩展性和操作可靠性的方法。人工智能与机器学习（AI/ML）已深度融入DESC的各类科学工作流，涵盖测光红移估算、暂现源分类、弱引力透镜推断以及宇宙学模拟等多个方面。然而，其在精密宇宙学中的应用价值取决于可信的不确定性量化、对协变量偏移和模型误设的鲁棒性，以及在科学流程中可重复的集成能力。本文白皮书系统梳理了AI/ML在DESC主要宇宙学探针及跨领域分析中的当前应用现状，发现尽管科学应用场景各异，但核心方法论与基本挑战却反复出现。鉴于解决这些跨领域挑战能够同时惠及多个探测手段，我们明确了若干关键的方法研究优先方向，包括大规模贝叶斯推断、物理信息驱动的方法、验证框架，以及用于科学发现的主动学习。同时，着眼于新兴技术，我们探讨了最新基础模型方法和由大语言模型（LLM）驱动的智能体式AI系统重塑DESC工作流程的潜力，前提是其部署必须伴随严格的评估与治理机制。最后，本文讨论了成功实施这些新方法所必需的关键软件、计算与数据基础设施，以及人力资源需求，并就与外部机构加强协作所带来的潜在风险与机遇进行了深入思考。"
  },
  {
    "date": "2026-01-20",
    "title": "InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning",
    "authors": "Matthew Y. R. Yang, Hao Bai, Ian Wu, Gene Yang, Amrith Setlur, Aviral Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14209v1",
    "source": "arXiv",
    "abstract": "Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.",
    "title_zh": "InT：自提出干预实现大模型推理中的信用分配",
    "abstract_zh": "结果-奖励强化学习（RL）已被证明在提升大型语言模型（LLMs）的推理能力方面非常有效。然而，标准的强化学习仅在最终答案层面分配奖励：当结果错误时，会惩罚整个推理过程；而当结果正确时，则对所有步骤进行均匀强化。这种机制导致在失败的推理轨迹中，正确的中间步骤可能被抑制，而在成功的轨迹中，无关或虚假的步骤也可能被错误地强化。我们称这一缺陷为“信用分配”问题。虽然一个自然的解决方案是训练一个过程奖励模型，但准确优化此类模型以识别出纠正性推理步骤仍极具挑战性。\n\n为此，我们提出了**干预训练**（Intervention Training, InT）——一种新的训练范式。在此范式中，模型能够自主地对其自身的推理轨迹进行细粒度的信用分配，通过提出简短、有针对性的修正措施，引导推理路径向更高奖励的方向发展。利用数学推理数据集中常见的参考解答，并基于“验证模型生成的答案比从零开始生成正确答案更容易”这一事实，模型可识别出其推理过程中第一个错误，并提出单步干预来将推理轨迹引导至正确解法。\n\n随后，我们将该策略应用于监督微调（SFT），将从初始状态到出错点的推理轨迹与提出的干预措施拼接起来，从而将错误定位到具体导致失败的那一步。实验表明，经过此方法训练后的模型，作为强化学习训练的初始化起点，表现远优于传统方法。在完成InT及后续的强化学习微调后，我们在IMO-AnswerBench基准上相较40亿参数的基础模型，准确率提升了近14%，甚至超越了如gpt-oss-20b等更大规模的开源模型。"
  },
  {
    "date": "2026-01-20",
    "title": "Verifying Floating-Point Programs in Stainless",
    "authors": "Andrea Gilot, Axel Bergström, Eva Darulova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14059v1",
    "source": "arXiv",
    "abstract": "We extend the Stainless deductive verifier with floating-point support, providing the first automated verification support for floating-point numbers for a subset of Scala that includes polymorphism, recursion and higher-order functions. We follow the recent approach in the KeY verifier to axiomatise reasoning about mathematical functions, but go further by supporting all functions from Scala's math API, and by verifying the correctness of the axioms against the actual implementation in Stainless itself. We validate Stainless' floating-point support on a new set of benchmarks sampled from real-world code from GitHub, showing that it can verify specifications about, e.g., ranges of output or absence of special values for most supported functions, or produce counter-examples when the specifications do not hold.",
    "title_zh": "在Stainless中验证浮点数程序",
    "abstract_zh": "我们扩展了Stainless的归纳验证器，增加了对浮点数的支持，首次为包含泛型、递归和高阶函数的Scala子集提供了自动化的浮点数验证支持。我们借鉴了KeY验证器近期采用的方法，通过公理化方式处理数学函数的推理，但进一步拓展了功能，不仅支持Scala数学API中的所有函数，还验证了这些公理与Stainless自身实现的一致性。我们在从GitHub上真实代码中采样的一组新基准测试上验证了Stainless的浮点数支持能力，结果表明，它能够验证大多数受支持函数的输出范围或特殊值不存在等规格说明；当规格不成立时，还能生成反例。"
  },
  {
    "date": "2026-01-20",
    "title": "Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants",
    "authors": "Yunhe Wang, Kai Han, Huiling Zhen, Yuchuan Tian, Hanting Chen, Yongbing Huang, Yufei Cui, Yingte Shu, Shan Gao, Ismail Elezi, Roy Vaughan Miles, Songcen Xu, Feng Wen, Chao Xu, Sinan Zeng, Dacheng Tao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14041v1",
    "source": "arXiv",
    "abstract": "The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.",
    "title_zh": "扩散语言模型及其变体未来发展的十大开放性挑战",
    "abstract_zh": "当前大型语言模型（LLMs）的范式主要由自回归（AR）架构定义，其文本生成采用逐字“一块砖接一块砖”的顺序过程。尽管取得了显著成功，但AR模型本质上受限于因果瓶颈，难以实现全局结构预判与迭代优化。扩散语言模型（DLMs）提供了一种变革性替代方案，将文本生成视为一种整体性的、双向去噪过程，犹如雕塑家逐步雕琢杰作。然而，DLMs的潜力尚未被充分挖掘，往往仍被束缚在AR遗留的基础设施与优化框架之中。在本文观点中，我们识别出十项根本性挑战，涵盖架构惯性、梯度稀疏性以及线性推理能力的局限，这些因素阻碍了DLMs达到其“GPT-4时刻”。为此，我们提出一个以四大支柱为核心的战略路线图：基础架构、算法优化、认知推理与统一多模态智能。通过转向以扩散原生（diffusion-native）为特征的生态系统，实现多尺度分词、主动重掩码和潜在思维等机制，我们有望突破因果视野的限制。我们认为，这一转型对于发展具备复杂结构推理、动态自我修正能力以及无缝多模态融合能力的下一代人工智能至关重要。"
  },
  {
    "date": "2026-01-20",
    "title": "Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores",
    "authors": "Esma Balkır, Alice Pernthaller, Marco Basaldella, José Hernández-Orallo, Nigel Collier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13885v1",
    "source": "arXiv",
    "abstract": "Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions.",
    "title_zh": "信心充足的排名（用更少的项目）：基于连续评分的自适应大模型评估",
    "abstract_zh": "计算机自适应测试（CAT）在多项选择基准上已证明对大型语言模型（LLM）的高效评估具有显著效果。然而，现代LLM评估越来越多地依赖于生成任务，其输出评分是连续而非简单的正确/错误标记。本文提出了一种基于项目反应理论（IRT）的自适应测试的合理扩展，适用于连续有界评分（如ROUGE、BLEU及LLM作为评判者等指标），通过将传统的伯努利响应分布替换为异方差正态分布来实现。在此基础上，我们引入了一种具备不确定性感知能力的排序器，并设计了自适应停止准则，在尽可能少的测试项和最低成本下实现了可靠的模型排序。我们在涵盖n-gram基础、嵌入式以及LLM作为评判者等多种度量标准的五个基准上验证了该方法的有效性。结果表明，本方法仅使用2%的测试项，便在排名相关性上比随机采样提升了0.12的τ值，且在置信预测中达到了95%的准确率。"
  },
  {
    "date": "2026-01-20",
    "title": "The Quest for Reliable AI Accelerators: Cross-Layer Evaluation and Design Optimization",
    "authors": "Meng Li, Tong Xie, Zuodong Zhang, Runsheng Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14148v1",
    "source": "arXiv",
    "abstract": "As the CMOS technology pushes to the nanoscale, aging effects and process variations have become increasingly pronounced, posing significant reliability challenges for AI accelerators. Traditional guardband-based design approaches, which rely on pessimistic timing margin, sacrifice significant performance and computational efficiency, rendering them inadequate for high-performance AI computing demands. Current reliability-aware AI accelerator design faces two core challenges: (1) the lack of systematic cross-layer analysis tools to capture coupling reliability effects across device, circuit, architecture, and application layers; and (2) the fundamental trade-off between conventional reliability optimization and computational efficiency. To address these challenges, this paper systematically presents a series of reliability-aware accelerator designs, encompassing (1) aging and variation-aware dynamic timing analyzer, (2) accelerator dataflow optimization using critical input pattern reduction, and (3) resilience characterization and novel architecture design for large language models (LLMs). By tightly integrating cross-layer reliability modeling and AI workload characteristics, these co-optimization approaches effectively achieve reliable and efficient AI acceleration.",
    "title_zh": "寻找可靠的AI加速器：跨层评估与设计优化",
    "abstract_zh": "随着CMOS技术向纳米尺度推进，老化效应与工艺波动日益显著，给AI加速器的可靠性带来了严峻挑战。传统的基于保护带（guardband）的设计方法依赖于过于保守的时间裕量，导致性能和计算效率大幅牺牲，已无法满足高性能AI计算的需求。当前面向可靠性的AI加速器设计面临两大核心难题：（1）缺乏系统化的跨层分析工具，难以全面捕捉器件、电路、架构及应用层之间的耦合可靠性效应；（2）传统可靠性优化与计算效率之间存在根本性权衡。为应对这些挑战，本文系统地提出了一系列面向可靠性的加速器设计方法，包括：（1）考虑老化与工艺变化的动态时序分析器；（2）通过关键输入模式缩减实现的加速器数据流优化；（3）针对大语言模型（LLMs）的鲁棒性表征与新型架构设计。通过紧密融合跨层可靠性建模与AI工作负载特性，这些协同优化方法有效实现了高可靠性与高效率的AI加速。"
  },
  {
    "date": "2026-01-20",
    "title": "Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition",
    "authors": "Gorgi Pavlov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13953v1",
    "source": "arXiv",
    "abstract": "Learning precise Boolean logic via gradient descent remains challenging: neural networks typically converge to \"fuzzy\" approximations that degrade under quantization. We introduce Hierarchical Spectral Composition, a differentiable architecture that selects spectral coefficients from a frozen Boolean Fourier basis and composes them via Sinkhorn-constrained routing with column-sign modulation. Our approach draws on recent insights from Manifold-Constrained Hyper-Connections (mHC), which demonstrated that projecting routing matrices onto the Birkhoff polytope preserves identity mappings and stabilizes large-scale training. We adapt this framework to logic synthesis, adding column-sign modulation to enable Boolean negation -- a capability absent in standard doubly stochastic routing. We validate our approach across four phases of increasing complexity: (1) For n=2 (16 Boolean operations over 4-dim basis), gradient descent achieves 100% accuracy with zero routing drift and zero-loss quantization to ternary masks. (2) For n=3 (10 three-variable operations), gradient descent achieves 76% accuracy, but exhaustive enumeration over 3^8 = 6561 configurations proves that optimal ternary masks exist for all operations (100% accuracy, 39% sparsity). (3) For n=4 (10 four-variable operations over 16-dim basis), spectral synthesis -- combining exact Walsh-Hadamard coefficients, ternary quantization, and MCMC refinement with parallel tempering -- achieves 100% accuracy on all operations. This progression establishes (a) that ternary polynomial threshold representations exist for all tested functions, and (b) that finding them requires methods beyond pure gradient descent as dimensionality grows. All operations enable single-cycle combinational logic inference at 10,959 MOps/s on GPU, demonstrating viability for hardware-efficient neuro-symbolic logic synthesis.",
    "title_zh": "可微逻辑综合：通过Sinkhorn约束组合进行谱系数选择",
    "abstract_zh": "通过梯度下降学习精确的布尔逻辑仍然充满挑战：神经网络通常收敛到“模糊”的近似解，这些解在量化后性能会显著下降。我们提出了一种可微分架构——**分层谱合成（Hierarchical Spectral Composition）**，该方法从一个固定的布尔傅里叶基中选择谱系数，并通过Sinkhorn约束路由与列符号调制进行组合。我们的方法借鉴了近期关于流形约束超连接（Manifold-Constrained Hyper-Connections, mHC）的研究成果，该研究发现将路由矩阵投影到Birkhoff多面体上能够保持恒等映射并稳定大规模训练过程。我们将这一框架应用于逻辑综合，引入**列符号调制**以实现布尔取反功能——这是标准双随机路由所不具备的能力。\n\n我们在四个逐步增加复杂度的阶段验证了本方法的有效性：\n\n1. **n=2**（基于4维基的16个布尔运算）：梯度下降实现了100%准确率，无路由漂移，且量化至三值掩码时损失为零；  \n2. **n=3**（10个三变量运算）：梯度下降达到76%准确率，但通过穷举搜索3⁸ = 6561种配置，证明所有运算均存在最优三值掩码（100%准确率，39%稀疏度）；  \n3. **n=4**（10个四变量运算，基于16维基）：采用谱合成方法——结合精确的Walsh-Hadamard系数、三值量化以及带有平行退火的MCMC优化——在所有运算上均实现100%准确率。\n\n这一进展确立了两点关键结论：  \n(a) 所有测试函数都存在三值多项式阈值表示；  \n(b) 随着维度增长，单纯依赖梯度下降已不足以找到最优解，必须采用更复杂的优化策略。\n\n所有运算均可在GPU上实现单周期组合逻辑推理，速度达10,959 MOps/s，充分展示了其在硬件高效神经符号逻辑综合中的可行性。"
  },
  {
    "date": "2026-01-20",
    "title": "Towards robust long-context understanding of large language model via active recap learning",
    "authors": "Chenyu Hui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13734v1",
    "source": "arXiv",
    "abstract": "In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM",
    "title_zh": "通过主动回顾学习提升大语言模型的鲁棒性长上下文理解能力",
    "abstract_zh": "本文提出了一种主动回顾学习（Active Recap Learning, ARL）框架，旨在提升大语言模型（LLM）对长文本上下文的理解能力。ARL通过在持续预训练阶段进行有针对性的序列构建，以及在推理阶段实施回溯性摘要，使模型能够主动回顾并总结先前内容。首先，我们基于长上下文与短上下文前向传播之间的损失差异，识别出准备好的长文本中的关键标记，并找出最相关的前序段落，随后利用大语言模型对这些段落进行摘要。其次，ARL赋予模型在推理过程中自主生成并使用这些回溯性摘要的能力，从而在段落间建立起一种递归记忆机制。实验结果表明，ARL在RULER上取得了26.8%的显著提升，在LongBench上实现了9.44%的改进。总体而言，ARL提供了一种简单而有效的基于持续预训练的方法，以增强模型对长上下文的理解能力，推动了大语言模型中可扩展记忆增强技术的发展。"
  },
  {
    "date": "2026-01-20",
    "title": "CodeContests-O: Powering LLMs via Feedback-Driven Iterative Test Case Generation",
    "authors": "Jianfeng Cai, Jinhua Zhu, Ruopei Sun, Kangwen Zhao, Dongyun Xue, Mingxiao Feng, Wengang Zhou, Houqiang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13682v1",
    "source": "arXiv",
    "abstract": "The rise of reasoning models necessitates large-scale verifiable data, for which programming tasks serve as an ideal source. However, while competitive programming platforms provide abundant problems and solutions, high-quality test cases for verification remain scarce. Existing approaches attempt to synthesize test cases using Large Language Models (LLMs), but rely solely on the model's intrinsic generation capabilities without external feedback, frequently resulting in insufficiently diverse cases. To address this limitation, we propose a $\\textbf{Feedback-Driven Iterative Framework}$ for comprehensive test case construction. Specifically, our method leverages the LLM to generate initial test cases, executes them against known correct and incorrect solutions, and utilizes the failed results as feedback to guide the LLM in refining the test cases toward high fidelity and discriminability. We then apply this method to the CodeContests dataset to construct an optimized high-quality derivative, $\\textbf{CodeContests-O}$. Evaluating against the entire pool of solutions ($1.1 \\times 10^7$ in total), our dataset achieves an average True Positive Rate (TPR) of $89.37\\%$ and True Negative Rate (TNR) of $90.89\\%$, significantly outperforming the CodeContests and CodeContests+ by margins of $4.32\\%$ and $9.37\\%$, respectively. Furthermore, fine-tuning the Qwen2.5-7B model on CodeContests-O results in a $9.52\\%$ improvement on LiveCodeBench (Pass@1). Experiments demonstrate the effectiveness of our framework and the quality of CodeContests-O. To support reproducibility and facilitate future research, we release the $\\href{https://github.com/cai-jianfeng/CodeContests-O}{code}$ and $\\href{https://huggingface.co/datasets/caijanfeng/CodeContests-O}{dataset}$.",
    "title_zh": "CodeContests-O：通过反馈驱动的迭代测试用例生成为大语言模型赋能",
    "abstract_zh": "推理模型的兴起需要大规模可验证的数据，而编程任务正是理想的来源。然而，尽管竞赛编程平台提供了丰富的题目和解答，高质量的测试用例却仍然稀缺。现有的方法尝试使用大语言模型（LLMs）生成测试用例，但仅依赖模型自身的生成能力，缺乏外部反馈，导致生成的测试用例多样性不足。为解决这一局限性，我们提出了一种**基于反馈驱动的迭代框架**，用于全面构建高质量的测试用例。具体而言，我们的方法首先利用LLM生成初始测试用例，然后在已知正确与错误的解法上执行这些用例，并将失败结果作为反馈，引导LLM不断优化测试用例，使其具备更高的保真度和区分能力。我们将该方法应用于CodeContests数据集，构建了一个优化后的高质量衍生数据集——**CodeContests-O**。在对总计1.1×10⁷个解法的整体评估中，我们的数据集达到了平均93.7%的真正例率（TPR）和90.89%的真负例率（TNR），分别比CodeContests和CodeContests+高出4.32%和9.37%。此外，在CodeContests-O上微调Qwen2.5-7B模型后，其在LiveCodeBench上的Pass@1指标提升了9.52%。实验结果充分证明了我们框架的有效性以及CodeContests-O数据集的高质量。为支持可复现性并推动后续研究，我们已公开发布代码与数据集：[代码](https://github.com/cai-jianfeng/CodeContests-O) 和 [数据集](https://huggingface.co/datasets/caijanfeng/CodeContests-O)。"
  },
  {
    "date": "2026-01-20",
    "title": "Foundational VeriFast: Pragmatic Certification of Verification Tool Results through Hinted Mirroring",
    "authors": "Bart Jacobs",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13727v1",
    "source": "arXiv",
    "abstract": "VeriFast is a leading tool for the modular formal verification of correctness properties of single-threaded and multi-threaded C and Rust programs. It verifies a program by symbolically executing each function in isolation, exploiting user-annotated preconditions, postconditions, and loop invariants written in a form of separation logic, and using a separation logic-based symbolic representation of memory. However, the tool itself, written in roughly 30K lines of OCaml code, has not been formally verified. Therefore, bugs in the tool could cause it to falsely report the correctness of the input program. We here report on an early result extending VeriFast to emit, upon successful verification of a Rust program, a Rocq proof script that proves correctness of the program with respect to a Rocq-encoded axiomatic semantics of Rust. This significantly enhances VeriFast's applicability in safety-critical domains. We apply hinted mirroring: we record key information from VeriFast's symbolic execution run, and use it to direct a replay of the run in Rocq.",
    "title_zh": "基础VeriFast：通过提示镜像实现验证工具结果的实用化认证",
    "abstract_zh": "VeriFast 是一款领先的工具，用于对单线程和多线程的 C 与 Rust 程序的正确性属性进行模块化形式化验证。它通过符号执行每个函数的独立方式来验证程序，利用用户标注的前置条件、后置条件以及循环不变式（以分离逻辑的形式编写），并采用基于分离逻辑的内存符号表示。然而，该工具本身由约 3 万行 OCaml 代码编写，尚未经过形式化验证。因此，工具中的缺陷可能导致其错误地报告输入程序为正确。本文报告了一项早期成果：将 VeriFast 扩展为在成功验证 Rust 程序后，生成一个 Rocq 证明脚本，该脚本可证明程序相对于 Rust 的 Rocq 编码公理语义的正确性。这一改进显著提升了 VeriFast 在安全关键领域中的应用价值。我们采用了“提示镜像”（hinted mirroring）方法：记录 VeriFast 符号执行过程中的关键信息，并利用这些信息指导在 Rocq 中重放该执行过程。"
  },
  {
    "date": "2026-01-20",
    "title": "SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories",
    "authors": "Aditya Bharat Soni, Rajat Ghosh, Vaishnavi Bhargava, Valerie Chen, Debojyoti Dutta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13713v1",
    "source": "arXiv",
    "abstract": "Software testing is crucial for ensuring the correctness and reliability of software systems. Automated generation of issue reproduction tests from natural language issue descriptions enhances developer productivity by simplifying root cause analysis, promotes test-driven development -- \"test first, write code later\", and can be used for improving the effectiveness of automated issue resolution systems like coding agents. Existing methods proposed for this task predominantly rely on closed-source LLMs, with limited exploration of open models. To address this, we propose SWE-Tester -- a novel pipeline for training open-source LLMs to generate issue reproduction tests. First, we curate a high-quality training dataset of 41K instances from 2.6K open-source GitHub repositories and use it to train LLMs of varying sizes and families. The fine-tuned models achieve absolute improvements of up to 10\\% in success rate and 21\\% in change coverage on SWT-Bench Verified. Further analysis shows consistent improvements with increased inference-time compute, more data, and larger models. These results highlight the effectiveness of our framework for advancing open-source LLMs in this domain.",
    "title_zh": "SWE-Tester：用于真实仓库中问题复现的开源大模型训练",
    "abstract_zh": "软件测试对于确保软件系统的正确性和可靠性至关重要。从自然语言问题描述中自动生成问题复现测试，能够提升开发者的生产力，简化根本原因分析，推动“测试先行、后写代码”的测试驱动开发模式，并可用于提升自动化问题修复系统（如编程代理）的有效性。现有针对该任务的方法主要依赖闭源大模型，对开源模型的探索相对有限。为此，我们提出了 SWE-Tester——一种用于训练开源大模型生成问题复现测试的新颖流水线。首先，我们从2600个开源GitHub仓库中精心构建了一个包含4.1万条实例的高质量训练数据集，并利用该数据集训练了不同规模和架构的大模型。经过微调后的模型在SWT-Bench Verified基准上，成功率达到最高10%的绝对提升，代码变更覆盖率提升达21%。进一步分析表明，随着推理时计算资源的增加、数据量的扩充以及模型规模的扩大，性能均呈现持续提升。这些结果充分证明了我们框架在推动开源大模型在此领域发展的有效性。"
  },
  {
    "date": "2026-01-20",
    "title": "Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning",
    "authors": "Zhihang Yuan, Chengyu Yue, Long Huang, Litu Ou, Lei Shi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13697v1",
    "source": "arXiv",
    "abstract": "Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.",
    "title_zh": "不确定性感知的梯度信噪比数据选择用于指令微调",
    "abstract_zh": "指令微调是适应大型语言模型（LLMs）的标准范式，但现代指令数据集通常规模庞大、噪声较多且存在冗余，导致使用全部数据进行微调成本高昂，且往往并不必要。现有的数据选择方法要么构建昂贵的梯度数据存储，要么依赖弱代理模型分配静态分数，普遍忽略了随训练过程演化的不确定性，因而错失了提升LLM可解释性的重要来源。我们提出GRADFILTERING，一种无需依赖具体目标、具备不确定性感知能力的数据选择框架。该框架利用一个小型GPT-2代理模型，结合LoRA集成方法，并将每个样本的梯度聚合为梯度信噪比（G-SNR）作为效用指标。实验结果表明，GRADFILTERING在大多数基于LLM作为评判者的评估任务中，以及在人工评估中，表现与随机子集或强基线方法相当甚至更优。此外，在相同计算预算下，由GRADFILTERING筛选出的数据子集收敛速度显著快于其他竞争性过滤方法，充分体现了不确定性感知评分的优势。"
  },
  {
    "date": "2026-01-20",
    "title": "AI IDEs or Autonomous Agents? Measuring the Impact of Coding Agents on Software Development",
    "authors": "Shyam Agarwal, Hao He, Bogdan Vasilescu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13597v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM)-based coding agents increasingly act as autonomous contributors that generate and merge pull requests, yet their real-world effects on software projects are unclear, especially relative to widely adopted IDE-based AI assistants. We present a longitudinal causal study of agent adoption in open-source repositories using staggered difference-in-differences with matched controls. Using the AIDev dataset, we define adoption as the first agent-generated pull request and analyze monthly repository-level outcomes spanning development velocity (commits, lines added) and software quality (static-analysis warnings, cognitive complexity, duplication, and comment density). Results show large, front-loaded velocity gains only when agents are the first observable AI tool in a project; repositories with prior AI IDE usage experience minimal or short-lived throughput benefits. In contrast, quality risks are persistent across settings, with static-analysis warnings and cognitive complexity rising roughly 18% and 35%, indicating sustained agent-induced complexity debt even when velocity advantages fade. These heterogeneous effects suggest diminishing returns to AI assistance and highlight the need for quality safeguards, provenance tracking, and selective deployment of autonomous agents. Our findings establish an empirical basis for understanding how agentic and IDE-based tools interact, and motivate research on balancing acceleration with maintainability in AI-integrated development workflows.",
    "title_zh": "AI IDE 或自主代理？衡量编码代理对软件开发的影响",
    "abstract_zh": "基于大语言模型（LLM）的编码代理正越来越多地作为自主贡献者，参与生成和合并拉取请求（pull requests），但其在真实软件项目中的实际影响尚不明确，尤其与广泛采用的IDE集成AI助手相比。本文通过一项纵向因果研究，分析了开源仓库中代理工具的采纳情况，采用分阶段差异法（staggered difference-in-differences）并结合匹配对照组的方法。基于AIDev数据集，我们将“采纳”定义为首个由代理生成的拉取请求，并分析了涵盖开发速度（提交次数、新增代码行数）和软件质量（静态分析警告、认知复杂度、代码重复率及注释密度）等维度的月度仓库级指标。\n\n研究结果表明：当代理是项目中首个可观察到的AI工具时，会带来显著且集中爆发式的开发速度提升；然而，在已有AI IDE使用经验的项目中，代理带来的吞吐量增益则微弱或短暂。相比之下，质量风险在各类场景下均持续存在：静态分析警告和认知复杂度分别上升约18%和35%，表明即使速度优势消失，代理引入的“复杂性债务”仍长期累积。这些异质性影响揭示了AI辅助作用的边际递减趋势，凸显了对质量保障、代码溯源追踪以及自主代理选择性部署的迫切需求。\n\n本研究为理解代理型工具与IDE集成型AI工具之间的交互机制提供了实证基础，并推动未来研究关注如何在AI融合开发流程中实现加速与可维护性之间的平衡。"
  },
  {
    "date": "2026-01-20",
    "title": "Toward Efficient Agents: Memory, Tool learning, and Planning",
    "authors": "Xiaofang Yang, Lijun Li, Heng Zhou, Tong Zhu, Xiaoye Qu, Yuchen Fan, Qianshan Wei, Rui Ye, Li Kang, Yiran Qin, Zhiqiang Kou, Daizong Liu, Qi Li, Ning Ding, Siheng Chen, Jing Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14192v1",
    "source": "arXiv",
    "abstract": "Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.",
    "title_zh": "迈向高效智能体：记忆、工具学习与规划",
    "abstract_zh": "近年来，将大型语言模型扩展为智能体系统引起了越来越多的关注。尽管智能体的有效性持续提升，但效率——这对实际部署至关重要——却常常被忽视。因此，本文从智能体的三个核心组成部分——记忆、工具学习和规划——出发，探讨效率问题，考虑延迟、token数量、步骤数等各类成本。旨在对智能体系统本身的效率进行深入研究，我们综述了近期一系列实现方式各异但往往在高层原则上趋于一致的方法，包括但不限于：通过压缩与管理来限制上下文规模、设计强化学习奖励以最小化工具调用次数，以及采用受控搜索机制以提高效率，这些内容均进行了详细讨论。相应地，我们从两个互补的角度定义效率：一是在固定成本预算下比较有效性；二是在相近有效性水平下比较成本。这一权衡关系也可通过有效性和成本之间的帕累托前沿来理解。基于此视角，我们还梳理了面向效率的基准测试，总结了这些组件的评估协议，并整合了基准测试与方法学研究中常报告的效率指标。此外，我们还探讨了关键挑战与未来方向，旨在提供具有前景的洞见。"
  },
  {
    "date": "2026-01-20",
    "title": "An Empirical Study on Remote Code Execution in Machine Learning Model Hosting Ecosystems",
    "authors": "Mohammed Latif Siddiq, Tanzim Hossain Romel, Natalie Sekerak, Beatrice Casey, Joanna C. S. Santos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14163v1",
    "source": "arXiv",
    "abstract": "Model-sharing platforms, such as Hugging Face, ModelScope, and OpenCSG, have become central to modern machine learning development, enabling developers to share, load, and fine-tune pre-trained models with minimal effort. However, the flexibility of these ecosystems introduces a critical security concern: the execution of untrusted code during model loading (i.e., via trust_remote_code or trust_repo). In this work, we conduct the first large-scale empirical study of custom model loading practices across five major model-sharing platforms to assess their prevalence, associated risks, and developer perceptions. We first quantify the frequency with which models require custom code to function and identify those that execute arbitrary Python files during loading. We then apply three complementary static analysis tools: Bandit, CodeQL, and Semgrep, to detect security smells and potential vulnerabilities, categorizing our findings by CWE identifiers to provide a standardized risk taxonomy. We also use YARA to identify malicious patterns and payload signatures. In parallel, we systematically analyze the documentation, API design, and safety mechanisms of each platform to understand their mitigation strategies and enforcement levels. Finally, we conduct a qualitative analysis of over 600 developer discussions from GitHub, Hugging Face, and PyTorch Hub forums, as well as Stack Overflow, to capture community concerns and misconceptions regarding security and usability. Our findings reveal widespread reliance on unsafe defaults, uneven security enforcement across platforms, and persistent confusion among developers about the implications of executing remote code. We conclude with actionable recommendations for designing safer model-sharing infrastructures and striking a balance between usability and security in future AI ecosystems.",
    "title_zh": "机器学习模型托管生态系统中的远程代码执行问题实证研究",
    "abstract_zh": "模型共享平台（如 Hugging Face、ModelScope 和 OpenCSG）已成为现代机器学习开发的核心，使开发者能够以极低的投入实现预训练模型的共享、加载与微调。然而，这些生态系统的灵活性也带来了关键的安全隐患：在加载模型时执行未经信任的代码（例如通过 `trust_remote_code` 或 `trust_repo` 选项）。在本研究中，我们首次对五大主流模型共享平台上的自定义模型加载实践进行了大规模实证研究，旨在评估其普遍性、相关风险以及开发者的认知态度。\n\n我们首先量化了模型正常运行所需自定义代码的频率，并识别出那些在加载过程中执行任意 Python 文件的模型。随后，我们采用三种互补的静态分析工具——Bandit、CodeQL 和 Semgrep——检测代码中的安全异味（security smells）及潜在漏洞，并依据 CWE 编号对发现的问题进行分类，构建了一个标准化的风险分类体系。同时，我们使用 YARA 工具识别恶意模式和攻击载荷签名。\n\n与此同时，我们系统地分析了各平台的文档说明、API 设计及安全机制，以理解其缓解策略的实施程度与执行力度。最后，我们对来自 GitHub、Hugging Face、PyTorch Hub 论坛以及 Stack Overflow 的超过 600 条开发者讨论进行了定性分析，深入捕捉社区在安全性和可用性方面的关切与误解。\n\n研究结果揭示：普遍存在对不安全默认设置的依赖，各平台间安全措施的执行存在显著差异，且开发者对远程代码执行后果仍存在持续性的混淆。基于此，我们提出了可操作的建议，呼吁设计更安全的模型共享基础设施，并在未来人工智能生态系统中实现可用性与安全性之间的有效平衡。"
  },
  {
    "date": "2026-01-20",
    "title": "Toward self-coding information systems",
    "authors": "Rodrigo Falcão, Frank Elberzhager, Karthik Vaidhyanathan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14132v1",
    "source": "arXiv",
    "abstract": "In this extended abstract, we propose a novel research topic in the field of agentic AI, which we refer to as self-coding information systems. These systems will be able to dynamically adapt their structure or behavior by evaluating potential adaptation decisions, generate source code, test, and (re)deploy their source code autonomously, at runtime, reducing the time to market of new features. Here we motivate the topic, provide a formal definition of self-coding information systems, discuss some expected impacts of the new technology, and indicate potential research directions.",
    "title_zh": "面向自编码信息系统",
    "abstract_zh": "在本文的扩展摘要中，我们提出了一项关于代理型人工智能（agentic AI）领域的创新研究课题，称之为“自编码信息系统”。这类系统能够通过评估潜在的适应性决策，动态地调整其结构或行为，自主生成源代码、进行测试，并在运行时（runtime）自动部署或重新部署代码，从而显著缩短新功能推向市场的时间。本文旨在阐明该研究主题的意义，给出自编码信息系统的正式定义，探讨该新技术可能带来的预期影响，并指明未来潜在的研究方向。"
  },
  {
    "date": "2026-01-20",
    "title": "LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems",
    "authors": "Badri N. Patro, Vijay S. Agneeswaran",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14053v1",
    "source": "arXiv",
    "abstract": "The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.",
    "title_zh": "LLMOrbit：大型语言模型的环形分类体系——从扩展瓶颈到智能体AI系统",
    "abstract_zh": "人工智能领域已从基础的Transformer架构实现了跨越式发展，迈向具备推理能力、接近人类水平性能的系统。我们提出LLMOrbit——一个全面的环形分类体系，用于梳理2019至2025年间大型语言模型的发展脉络。本综述分析了来自15家机构的超过50个模型，通过八个相互关联的轨道维度，系统记录了现代大语言模型、生成式AI及智能体系统在架构创新、训练方法与效率模式方面的演进。\n\n我们识别出三大关键危机：（1）数据稀缺（9–27万亿token将在2026–2028年间耗尽），（2）成本呈指数级增长（五年内从300万美元飙升至超3亿美元），以及（3）能源消耗不可持续（增长达22倍），由此确立了制约“蛮力扩展”策略的“规模墙”。\n\n我们的分析揭示了六种突破该墙的新范式：（1）推理时计算（如o1、DeepSeek-R1以10倍推理算力实现GPT-4性能）；（2）量化压缩（实现4–8倍压缩率）；（3）分布式边缘计算（成本降低10倍）；（4）模型融合；（5）高效训练（ORPO将内存需求减少50%）；（6）小型专用模型（Phi-4 14B参数量媲美更大模型）。同时，三种范式转型正在形成：（1）后训练阶段的显著提升（RLHF、GRPO、纯强化学习贡献显著，DeepSeek-R1在MATH测评中达到79.8%）；（2）效率革命（MoE路由提升18倍效率，多头潜在注意力实现8倍KV缓存压缩，使GPT-4级别性能成本低于每千token 0.3美元）；（3）普惠化趋势（开源Llama 3在MMLU上达到88.6%，超越GPT-4的86.4%）。\n\n本文深入剖析关键技术（如RLHF、PPO、DPO、GRPO、ORPO），追溯从被动生成到工具使用型智能体的演化路径（ReAct、RAG、多智能体系统），并系统评估后训练阶段的创新成果。"
  },
  {
    "date": "2026-01-20",
    "title": "\"The Whole Is Greater Than the Sum of Its Parts\": A Compatibility-Aware Multi-Teacher CoT Distillation Framework",
    "authors": "Jin Cui, Jiaqi Guo, Jiepeng Zhou, Ruixuan Yang, Jiayi Lu, Jiajun Xu, Jiangcheng Song, Boran Zhao, Pengju Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13992v1",
    "source": "arXiv",
    "abstract": "Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect \"epiphany moments\" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.",
    "title_zh": "“整体大于部分之和”：一种兼容性感知的多教师思维链蒸馏框架",
    "abstract_zh": "思维链（Chain-of-Thought, CoT）推理赋予大型语言模型（LLMs）卓越的能力，但通常需要庞大的参数规模。为此，CoT蒸馏作为一种有前景的范式应运而生，旨在将推理能力迁移至轻量级学生模型（SLMs）中。然而，现有方法多依赖单一教师模型，限制了学生模型的潜力——因为单个LLM往往存在独特的能力偏见，且容易发生灾难性遗忘。尽管利用多样化的教师模型看似理想，但如何有效融合其监督信号仍具挑战：教师与学生之间的不匹配可能加剧幻觉现象，而被动的监督又难以确保学生真正内化逻辑。针对这一问题，我们提出COMPACT框架，通过基于多维度评估指标动态调整教师梯度权重，实现对不同教师监督信号的自适应融合。该框架包含三个核心机制：（1）基于图结构的一致性（Graph-based Consensus），通过识别主流推理路径来过滤误导性推理过程；（2）基于互信息的适应性（Mutual-Information-based Adaptability），用于捕捉“顿悟时刻”，判断学生是否真正理解推理流程，而非简单模仿；（3）基于损失的难度评估（Loss-based Difficulty），用以衡量学生对教师指导的接受程度，防止负面迁移。大量实验与潜在空间分析表明，COMPACT能够在不破坏模型原有知识结构的前提下，有效整合多种推理能力，在多个基准测试中达到领先性能，同时显著缓解灾难性遗忘问题。"
  },
  {
    "date": "2026-01-20",
    "title": "VulnResolver: A Hybrid Agent Framework for LLM-Based Automated Vulnerability Issue Resolution",
    "authors": "Mingming Zhang, Xu Wang, Jian Zhang, Xiangxin Meng, Jiayi Zhang, Chunming Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13933v1",
    "source": "arXiv",
    "abstract": "As software systems grow in complexity, security vulnerabilities have become increasingly prevalent, posing serious risks and economic costs. Although automated detection tools such as fuzzers have advanced considerably, effective resolution still often depends on human expertise. Existing automated vulnerability repair (AVR) methods rely heavily on manually provided annotations (e.g., fault locations or CWE labels), which are often difficult and time-consuming to obtain, while overlooking the rich, naturally embedded semantic context found in issue reports from developers. In this paper, we present VulnResolver, the first LLM-based hybrid agent framework for automated vulnerability issue resolution. VulnResolver unites the adaptability of autonomous agents with the stability of workflow-guided repair through two specialized agents. The Context Pre-Collection Agent (CPCAgent) adaptively explores the repository to gather dependency and contextual information, while the Safety Property Analysis Agent (SPAAgent) generates and validates the safety properties violated by vulnerabilities. Together, these agents produce structured analyses that enrich the original issue reports, enabling more accurate vulnerability localization and patch generation. Evaluations on the SEC-bench benchmark show that VulnResolver resolves 75% of issues on SEC-bench Lite, achieving the best resolution performance. On SEC-bench Full, VulnResolver also significantly outperforms the strongest baseline, the agent-based OpenHands, confirming its effectiveness. Overall, VulnResolver delivers an adaptive and security-aware framework that advances end-to-end automated vulnerability issue resolution through workflow stability and the specialized agents' capabilities in contextual reasoning and property-based analysis.",
    "title_zh": "VulnResolver：一种基于大语言模型的自动化漏洞修复混合智能体框架",
    "abstract_zh": "随着软件系统复杂性的不断增加，安全漏洞日益普遍，带来了严重的风险和经济成本。尽管自动化检测工具（如模糊测试器）已取得显著进展，但有效的漏洞修复仍往往依赖于人工专业知识。现有的自动化漏洞修复（AVR）方法严重依赖手动提供的标注信息（例如故障位置或CWE标签），而这些信息通常难以获取且耗时费力，同时忽略了开发者提交的问题报告中天然蕴含的丰富语义上下文。本文提出VulnResolver，这是首个基于大语言模型（LLM）的混合智能体框架，用于自动化漏洞问题的解决。VulnResolver通过两个专用智能体，将自主智能体的灵活性与流程引导修复的稳定性相结合：上下文预采集智能体（CPCAgent）自适应地探索代码仓库，收集依赖关系和上下文信息；安全属性分析智能体（SPAAgent）则生成并验证漏洞所违反的安全属性。这两个智能体共同生成结构化的分析结果，丰富了原始问题报告，从而实现更精准的漏洞定位与补丁生成。在SEC-bench基准上的评估表明，VulnResolver在SEC-bench Lite上成功解决了75%的问题，达到最佳修复性能；在SEC-bench Full上，VulnResolver也显著优于最强基线方法——基于智能体的OpenHands，充分验证了其有效性。总体而言，VulnResolver提供了一个具备自适应性与安全感知能力的框架，通过流程稳定性以及专用智能体在上下文推理和基于属性分析方面的能力，推动了端到端自动化漏洞问题修复的发展。"
  },
  {
    "date": "2026-01-20",
    "title": "Multi-Objective Hierarchical Optimization with Large Language Models",
    "authors": "Andrej Schwanke, Lyubomir Ivanov, David Salinas, Frank Hutter, Arber Zela",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13892v1",
    "source": "arXiv",
    "abstract": "Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.",
    "title_zh": "基于大语言模型的多目标分层优化",
    "abstract_zh": "尽管大型语言模型（LLMs）在多个领域得到了广泛应用，尤其是凭借其强大的推理能力，但它们目前仍不是实现多目标优化的即插即用解决方案。传统方法之所以在基准测试中表现优异，是因为其内在具备处理数值输入的能力，并通过精心设计的建模策略，在探索与帕累托前沿利用之间取得良好平衡，同时能够有效应对多个（相互冲突的）目标。本文通过将LLMs作为代理模型和候选解采样器，嵌入到一种结构化的分层搜索策略中，弥补了这一差距。我们通过自适应地将输入空间划分为互不重叠的超矩形区域，并利用综合评分函数对这些区域进行排序，从而将LLM的生成过程限制在特定的、高潜力的子空间内。这使得问题求解更加高效——因为LLM无需关注全局问题结构，只需专注于局部推理即可。在标准正则性假设下，我们证明了所提出的算法生成的候选解在豪斯多夫距离意义下收敛于真实的帕累托集。实验结果表明，该方法在合成数据和真实世界基准上均持续优于基于全局LLM的多目标优化器，且性能与传统的进化算法和贝叶斯优化算法相当。"
  },
  {
    "date": "2026-01-20",
    "title": "HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation",
    "authors": "Qirui Chen, Jingxian Shuai, Shuangwu Chen, Shenghao Ye, Zijian Wen, Xufei Su, Jie Jin, Jiangming Li, Jun Chen, Xiaobin Tan, Jian Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13864v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon.",
    "title_zh": "HardSecBench：面向硬件代码生成的大型语言模型安全意识基准测试",
    "abstract_zh": "大型语言模型（LLMs）正越来越多地被集成到实际的硬件与固件开发流程中，用于代码生成。现有研究主要关注LLM生成代码的功能正确性，而对其中潜在的安全问题关注不足。然而，看似功能正确的LLM生成代码可能隐藏安全漏洞，一旦部署便可能引发灾难性后果。这一关键的研究空白促使我们设计一个基准测试，以评估在真实规格条件下的安全意识。本文提出HardSecBench，这是一个包含924个任务的基准，覆盖Verilog寄存器传输级（RTL）和固件级C语言代码，涵盖76项与硬件相关的通用弱点枚举（CWE）条目。每个任务均包含结构化需求说明、安全参考实现以及可执行测试用例。为实现自动化产物生成，我们提出一种多智能体流水线，将代码生成与验证解耦，并基于执行证据进行评估，从而确保评估的可靠性。利用HardSecBench，我们对多种LLM在硬件与固件代码生成方面的表现进行了评估，发现尽管多数模型能够满足功能需求，但仍存在显著的安全风险。此外，我们还发现安全表现受提示方式影响明显。这些发现揭示了当前面临的紧迫挑战，并为未来LLM辅助硬件设计的发展提供了切实可行的洞见。我们的数据与代码将很快公开发布。"
  },
  {
    "date": "2026-01-20",
    "title": "Partial Reductions for Kleene Algebra with Linear Hypotheses",
    "authors": "Liam Chung, Tobias Kappé",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14114v1",
    "source": "arXiv",
    "abstract": "Kleene algebra (KA) is an important tool for reasoning about general program equivalences, with a decidable and complete equational theory. However, KA cannot always prove equivalences between specific programs. For this purpose, one adds hypotheses to KA that encode program-specific knowledge. Traditionally, a map on regular expressions called a reduction then lets us lift decidability and completeness to these more expressive systems. Explicitly constructing such a reduction requires significant labour. Moreover, due to regularity constraints, a reduction may not exist for all combinations of expression and hypothesis. We describe an automaton-based construction to mechanically derive reductions for a wide class of hypotheses. These reductions can be partial, in which case they yield partial completeness: completeness for expressions in their domain. This allows us to automatically establish the provability of more equivalences than what is covered in existing work.",
    "title_zh": "带线性假设的克莱尼代数的部分约化",
    "abstract_zh": "克林代数（Kleene Algebra, KA）是一种用于推理一般程序等价性的有力工具，其具有可判定且完备的等式理论。然而，KA 并不总能证明特定程序之间的等价性。为此，人们通常在 KA 中添加编码了程序特异性知识的假设。传统上，通过一个作用于正则表达式的映射（称为“约化”），可以将可判定性和完备性提升到这些更丰富的系统中。然而，显式构造这样的约化需要大量工作。此外，由于正则性限制，对于某些表达式与假设的组合，可能根本不存在对应的约化。本文描述了一种基于自动机的构造方法，能够机械地为一大类假设推导出约化。这些约化可以是部分的，此时它们提供的是部分完备性：即仅对定义域内的表达式保持完备性。这一方法使我们能够自动证明比现有研究覆盖范围更广的更多程序等价性。"
  },
  {
    "date": "2026-01-20",
    "title": "Principled Latent Diffusion for Graphs via Laplacian Autoencoders",
    "authors": "Antoine Siraudin, Christopher Morris",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13780v1",
    "source": "arXiv",
    "abstract": "Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\\times$ speed-up.",
    "title_zh": "基于拉普拉斯自编码器的图结构原则性潜在扩散",
    "abstract_zh": "图扩散模型在图生成任务中取得了最先进的性能，但其复杂度随节点数量呈二次增长，且在稀疏图中大量计算资源被浪费在建模边的缺失上。受其他模态（如图像、文本）中潜在扩散思想的启发，一个自然的想法是将图压缩到低维潜在空间中进行扩散过程。然而，与图像或文本不同，图生成要求近乎无损的重建，因为邻接矩阵解码中的任何单一错误都可能导致整个样本无效。这一挑战长期以来未得到充分解决。\n\n我们提出了LG-Flow，一种直接克服上述难题的潜在图扩散框架。该框架采用一个置换等变的自编码器，将每个节点映射为固定维度的嵌入表示，从而可严格保证完整邻接关系的恢复，实现了对无向图和有向无环图（DAG）的近无损重建。该潜在表示的维度与节点数呈线性关系，彻底消除了二次复杂度瓶颈，使得训练更大、更强大的模型成为可能。在该潜在空间中，我们使用基于流匹配的扩散Transformer进行训练，实现了高效且富有表现力的图生成。\n\n我们的方法在与现有最先进图扩散模型的对比中表现出色，同时实现了高达1000倍的速度提升。"
  },
  {
    "date": "2026-01-20",
    "title": "Towards Token-Level Text Anomaly Detection",
    "authors": "Yang Cao, Bicheng Yu, Sikun Yang, Ming Liu, Yujiu Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13644v1",
    "source": "arXiv",
    "abstract": "Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.",
    "title_zh": "面向标记级文本异常检测",
    "abstract_zh": "尽管在网页应用的文本异常检测（如垃圾信息过滤和虚假新闻识别）方面取得了显著进展，现有方法仍从根本上局限于文档级别的分析，无法识别文本中哪些具体部分存在异常。为此，我们提出了**词元级异常检测**这一新范式，实现了对文本中异常内容的细粒度定位。我们正式定义了文本异常在文档级与词元级两个层面的表现，并提出一个能够在多层级上统一运作的检测框架。为推动该方向的研究，我们收集并标注了三个基准数据集，涵盖垃圾信息、评论和语法错误，并提供了词元级别的标注标签。实验结果表明，我们的框架在性能上优于其他6种基线方法，为文本中异常内容的精准定位开辟了新的可能性。所有代码与数据均已公开，可访问 https://github.com/charles-cao/TokenCore 获取。"
  },
  {
    "date": "2026-01-20",
    "title": "A model of errors in transformers",
    "authors": "Suvrat Raju, Praneeth Netrapalli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14175v1",
    "source": "arXiv",
    "abstract": "We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.",
    "title_zh": "变压器中的误差模型",
    "abstract_zh": "我们研究了大型语言模型（LLMs）在需要确定性输出以及重复处理来自有限选项集的标记的任务（如算术运算）中的错误率。我们认为，错误预测的产生源于注意力机制中微小误差的累积，当这些误差超过某个阈值时，就会导致错误结果。基于这一洞察，我们推导出一个定量的、包含两个参数的关系式，描述准确率与任务复杂度之间的关联。这两个参数随提示（prompt）和模型的不同而变化，可被解释为基本噪声率以及可能被错误预测的合理标记数量。我们的分析受到“有效场论”视角的启发：大型语言模型的大量原始参数可以重新组织为仅两个决定错误率的关键参数。我们通过使用 Gemini 2.5 Flash、Gemini 2.5 Pro 和 DeepSeek R1 进行了广泛的实证测试，发现对于多种任务，预测准确率与实际观察到的准确率之间具有极佳的一致性，尽管在某些情况下也发现了偏差。我们的模型为理解 LLM 在长序列重复任务中出现的错误提供了一种替代解释，不再将其归因于“推理能力的崩溃”或无法表达“组合性”函数。最后，我们展示了如何设计提示（prompts）以降低错误率。"
  },
  {
    "date": "2026-01-20",
    "title": "A flexible language model-assisted electronic design automation framework",
    "authors": "Cristian Sestito, Panagiota Kontou, Pratibha Verma, Atish Dixit, Alexandros D. Keros, Michael O'Boyle, Christos-Savvas Bouganis, Themis Prodromakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14098v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are transforming electronic design automation (EDA) by enhancing design stages such as schematic design, simulation, netlist synthesis, and place-and-route. Existing methods primarily focus these optimisations within isolated open-source EDA tools and often lack the flexibility to handle multiple domains, such as analogue, digital, and radio-frequency design. In contrast, modern systems require to interface with commercial EDA environments, adhere to tool-specific operation rules, and incorporate feedback from design outcomes while supporting diverse design flows. We propose a versatile framework that uses LLMs to generate files compatible with commercial EDA tools and optimise designs using power-performance-area reports. This is accomplished by guiding the LLMs with tool constraints and feedback from design outputs to meet tool requirements and user specifications. Case studies on operational transconductance amplifiers, microstrip patch antennas, and FPGA circuits show that the framework is effective as an EDA-aware assistant, handling diverse design challenges reliably.",
    "title_zh": "一种基于灵活语言模型的电子设计自动化框架",
    "abstract_zh": "大型语言模型（LLMs）正在通过提升原理图设计、仿真、网表综合以及布局布线等设计环节，推动电子设计自动化（EDA）的变革。现有方法主要聚焦于在孤立的开源EDA工具内进行优化，往往缺乏处理模拟、数字和射频设计等多种领域的能力，灵活性不足。相比之下，现代设计系统需要能够与商业EDA环境对接，遵循特定工具的操作规范，并结合设计结果的反馈，同时支持多样化的设计流程。我们提出了一种通用性框架，利用LLMs生成兼容商业EDA工具的文件，并基于功耗-性能-面积（PPA）报告优化设计。该框架通过引入工具约束条件以及来自设计输出的反馈信息，引导LLMs满足工具要求和用户规格。针对运算跨导放大器、微带贴片天线及FPGA电路的案例研究显示，该框架作为具备EDA感知能力的智能助手，能够可靠地应对多种设计挑战。"
  },
  {
    "date": "2026-01-20",
    "title": "RepoGenesis: Benchmarking End-to-End Microservice Generation from Readme to Repository",
    "authors": "Zhiyuan Peng, Xin Yin, Pu Zhao, Fangkai Yang, Lu Wang, Ran Jia, Xu Chen, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13943v1",
    "source": "arXiv",
    "abstract": "Large language models and agents have achieved remarkable progress in code generation. However, existing benchmarks focus on isolated function/class-level generation (e.g., ClassEval) or modifications to existing codebases (e.g., SWE-Bench), neglecting complete microservice repository generation that reflects real-world 0-to-1 development workflows. To bridge this gap, we introduce RepoGenesis, the first multilingual benchmark for repository-level end-to-end web microservice generation, comprising 106 repositories (60 Python, 46 Java) across 18 domains and 11 frameworks, with 1,258 API endpoints and 2,335 test cases verified through a \"review-rebuttal\" quality assurance process. We evaluate open-source agents (e.g., DeepCode) and commercial IDEs (e.g., Cursor) using Pass@1, API Coverage (AC), and Deployment Success Rate (DSR). Results reveal that despite high AC (up to 73.91%) and DSR (up to 100%), the best-performing system achieves only 23.67% Pass@1 on Python and 21.45% on Java, exposing deficiencies in architectural coherence, dependency management, and cross-file consistency. Notably, GenesisAgent-8B, fine-tuned on RepoGenesis (train), achieves performance comparable to GPT-5 mini, demonstrating the quality of RepoGenesis for advancing microservice generation. We release our benchmark at https://github.com/pzy2000/RepoGenesis.",
    "title_zh": "RepoGenesis：从Readme到仓库的端到端微服务生成基准测试",
    "abstract_zh": "大型语言模型和智能体在代码生成方面取得了显著进展。然而，现有的评估基准主要关注孤立的函数或类级别的生成（如 ClassEval），或对现有代码库的修改（如 SWE-Bench），忽视了反映真实世界从零到一开发流程的完整微服务仓库生成任务。为填补这一空白，我们提出了 RepoGenesis——首个面向多语言、端到端 Web 微服务仓库生成的基准测试。该基准包含 106 个仓库（60 个 Python，46 个 Java），覆盖 18 个领域和 11 种框架，共包含 1,258 个 API 接口和 2,335 个经过“评审-反驳”质量保证流程验证的测试用例。我们采用 Pass@1、API 覆盖率（AC）和部署成功率（DSR）对开源智能体（如 DeepCode）和商业 IDE（如 Cursor）进行了评估。结果表明，尽管部分系统在 AC（最高达 73.91%）和 DSR（最高达 100%）上表现良好，但表现最佳的系统在 Python 上仅达到 23.67% 的 Pass@1，在 Java 上为 21.45%，暴露出在架构一致性、依赖管理以及跨文件一致性方面的明显不足。值得注意的是，基于 RepoGenesis（训练集）微调的 GenesisAgent-8B 在性能上已接近 GPT-5 mini 水平，充分证明了 RepoGenesis 在推动微服务生成技术发展方面的高质量与实用性。我们已将该基准公开发布于 https://github.com/pzy2000/RepoGenesis。"
  },
  {
    "date": "2026-01-20",
    "title": "Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems",
    "authors": "Hong Su",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13887v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.",
    "title_zh": "人类模拟计算：一种类人自适应人工智能系统的框架",
    "abstract_zh": "大型语言模型（LLMs）在基于文本数据的知识表示与推理方面展现了强大的能力。然而，其仅依赖语言材料的局限性，限制了其在开放动态的真实世界环境中进行适应、验证推理结果以及有效运作的能力。本文提出了一种受人类启发的计算框架——人类模拟计算（Human Simulation Computation, HSC），将智能建模为一个持续的闭环过程，包含思考、行动、学习、反思以及活动调度等环节，统称为内部推理过程。HSC强调在内部推理过程及与环境交互中主动参与，其中行动不仅用于达成目标，还能自动地、无需外部干预地对内部推理机制进行优化与改进。此外，HSC在内部推理过程的各个阶段均融入了常见的类人思维策略，例如以核心特征为导向的推理、通过行动拓展认知范围，以及基于环境反馈的即时学习。通过理论分析，我们论证了仅从语言材料中无法完全习得人类模拟策略，而类人推理过程与基于行动的推理方法对于实现稳健的适应性和与真实世界环境的有效互动至关重要。"
  },
  {
    "date": "2026-01-20",
    "title": "From RTL to Prompt Coding: Empowering the Next Generation of Chip Designers through LLMs",
    "authors": "Lukas Krupp, Matthew Venn, Norbert Wehn",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.13815v1",
    "source": "arXiv",
    "abstract": "This paper presents an LLM-based learning platform for chip design education, aiming to make chip design accessible to beginners without overwhelming them with technical complexity. It represents the first educational platform that assists learners holistically across both frontend and backend design. The proposed approach integrates an LLM-based chat agent into a browser-based workflow built upon the Tiny Tapeout ecosystem. The workflow guides users from an initial design idea through RTL code generation to a tapeout-ready chip. To evaluate the concept, a case study was conducted with 18 high-school students. Within a 90-minute session they developed eight functional VGA chip designs in a 130 nm technology. Despite having no prior experience in chip design, all groups successfully implemented tapeout-ready projects. The results demonstrate the feasibility and educational impact of LLM-assisted chip design, highlighting its potential to attract and inspire early learners and significantly broaden the target audience for the field.",
    "title_zh": "从RTL到提示编码：通过大语言模型赋能下一代芯片设计师",
    "abstract_zh": "本文提出了一种基于大语言模型（LLM）的芯片设计教育平台，旨在让初学者在不被复杂技术细节压倒的情况下，轻松入门芯片设计。这是首个能够从前端到后端设计全流程协助学习者的教育平台。该方法将基于LLM的聊天代理集成到基于Tiny Tapeout生态系统的浏览器工作流中，引导用户从最初的设计构想，经过RTL代码生成，最终完成可流片的芯片设计。为验证该理念的可行性，研究团队对18名高中生进行了案例研究。在90分钟的课程中，这些学生成功开发出八个功能完整的VGA芯片设计，采用130纳米工艺技术。尽管他们此前没有任何芯片设计经验，但所有小组均顺利完成了可流片的项目。实验结果证明了LLM辅助芯片设计的可行性及其显著的教育价值，凸显了该技术吸引并激发早期学习者兴趣的巨大潜力，有望大幅拓展芯片设计领域的受众群体。"
  }
]