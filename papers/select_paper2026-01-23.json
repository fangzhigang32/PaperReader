[
  {
    "date": "2026-1-23",
    "title": "Operationalizing Semantics from Domain Diagrams",
    "authors": "Aakash Mor, Mrunal Gangrade",
    "publish": "2025 International Conference on Responsible, Generative and Explainable AI (ResGenXAI)",
    "url": "https://doi.org/10.1109/resgenxai64788.2025.11344013",
    "source": "IEEE",
    "abstract": "This paper introduces AMIDOL, a framework for machine-assisted extraction of formal computational semantics from domain-specific visual diagrams. Our approach tackles significant challenges in Explainable AI by converting intuitive graphical representations into rigorously defined executable models. Through domain-specific ontological languages and a unified intermediate representation, AMIDOL facilitates automated generation of actionable insights and analytical queries. This empowers domain specialists with precise comprehension of complex system behaviors and enables evidence-based decision-making across various application domains.",
    "title_zh": "从领域图中实现语义",
    "abstract_zh": "本文介绍了AMIDOL，这是一个用于机器辅助从特定领域视觉图示中提取形式化计算语义的框架。我们的方法通过将直观的图形表示转换为严格定义的可执行模型，解决了可解释人工智能中的重大挑战。借助特定领域的本体语言和统一的中间表示，AMIDOL实现了行动洞察与分析查询的自动化生成。这使领域专家能够精确理解复杂系统的行为，并在多个应用领域实现基于证据的决策。"
  },
  {
    "date": "2026-1-23",
    "title": "Bridging Formal Methods and Software Engineering Through a Tagless-Final Embedded DSL for Program Semantics",
    "authors": "Rohit Sanjay Puranik",
    "publish": "2025 IEEE 2nd International Conference on Information Technology, Electronics and Intelligent Communication Systems (ICITEICS)",
    "url": "https://doi.org/10.1109/iciteics64870.2025.11341094",
    "source": "IEEE",
    "abstract": "This paper introduces a pedagogical and practical approach to bridging formal methods and mainstream software engineering through a tagless-final Embedded Domain-Specific Language (eDSL) for executable program semantics, implemented in Scala 3. We detail the construction of a richly-typed eDSL that supports user-defined data structures, pre/post-conditions, and recursion, facilitating denotational semantics that are directly executable and type-safe. Our architecture includes two distinct Abstract Syntax Trees (ASTs)-a GADT for semantic reflection and an ADT optimized for code generation-enabling both interpretation and artifact synthesis (e.g., Scala source code). We also present a type reconstruction mechanism aligned with Scala's compiler logic, enhancing semantic fidelity. By minimizing reliance on macros and exotic metaprogramming, our design democratizes access to formal specification techniques for everyday developers. The approach demonstrates scalability via a blockchain ledger use case but is generalizable across domains, offering a roadmap for future extensions in theorem proving, testing, and code synthesis.",
    "title_zh": "通过无标签终态嵌入式领域特定语言实现形式化方法与软件工程的融合：程序语义的表达",
    "abstract_zh": "本文提出了一种教学与实践相结合的方法，通过在 Scala 3 中实现的无标签终态嵌入式领域特定语言（eDSL），弥合形式化方法与主流软件工程之间的鸿沟。我们详细阐述了一个类型丰富、功能完备的 eDSL 的构建过程，该 eDSL 支持用户自定义数据结构、前置/后置条件以及递归，从而实现可直接执行且类型安全的语义描述。我们的架构包含两种不同的抽象语法树（AST）——一种使用 GADT 实现语义反射，另一种采用 ADT 优化代码生成，从而同时支持程序解释与产物合成（如生成 Scala 源码）。此外，我们还提出了一种与 Scala 编译器逻辑一致的类型重建机制，显著提升了语义保真度。通过尽量减少对宏和复杂元编程技术的依赖，本设计使形式化规范技术更易于被日常开发者所掌握。该方法在区块链账本的应用场景中展示了良好的可扩展性，但其适用范围具有普遍性，为未来在定理证明、测试生成和代码合成等方向的拓展提供了清晰的路线图。"
  },
  {
    "date": "2026-1-23",
    "title": "A Fire Emergency Light System-on-Chip Design Methodology",
    "authors": "Yong Pan, Jing Xu, Ruifen Li",
    "publish": "2025 IEEE 3rd International Conference on Control, Electronics and Computer Technology (ICCECT)",
    "url": "https://doi.org/10.1109/iccect64621.2025.11339747",
    "source": "IEEE",
    "abstract": "To address the issues of low integration and poor reliability in fire emergency lights designed using discrete components or simple control chips, this paper proposes a design methodology for high-performance, high-reliability, and highly integrated fire emergency lights based on the System-on-Chip (SoC) concept. By combining C language programming with a co-design approach of digital circuits, the design achieves functions such as main circuit monitoring, battery charge/discharge protection, and fault alarm indication. The main working characteristics of the fire emergency light were simulated using software, and the test results showed that the design functions were consistent with the software simulation results, verifying the correctness of the SoC design methodology for fire emergency lights.",
    "title_zh": "一种消防应急照明系统级芯片设计方法",
    "abstract_zh": "为解决采用分立元件或简单控制芯片设计的消防应急灯集成度低、可靠性差等问题，本文提出了一种基于系统级芯片（SoC）理念的高性能、高可靠性、高度集成的消防应急灯设计方法。通过将C语言编程与数字电路协同设计相结合，实现了主电路监测、电池充放电保护及故障报警指示等功能。利用软件对消防应急灯的主要工作特性进行了仿真，测试结果表明，实际功能表现与软件仿真结果一致，验证了该SoC设计方法在消防应急灯设计中的正确性。"
  },
  {
    "date": "2026-1-23",
    "title": "AI-Enhanced Vulnerability Assessment in Cloud Environments for Salesforce CRM",
    "authors": "Arokia Suresh Kumar Joseph, K. Vivekrabinson, P. Deepalakshmi",
    "publish": "2025 International Conference on Responsible, Generative and Explainable AI (ResGenXAI)",
    "url": "https://doi.org/10.1109/resgenxai64788.2025.11344055",
    "source": "IEEE",
    "abstract": "With the increasing complexity, scope, and diversity of modern cyber threats, vulnerability assessment enabled by AI is increasingly essential for cloud-based platforms such as Salesforce CRM. The existing system is dominated by rule-based scanning and human audits, but it lacks flexibility and scalability, resulting in a significant number of false positives, especially in dynamic, multi-tenant setups. The strategy relies on artificial intelligence. To solve these problems, the paper suggests using an AI-based method that combines machine learning models like Isolation Forest for spotting unusual activities, Random Forest for identifying threats, and LSTM for analyzing behavior to find configuration errors, new threats, and suspicious user actions in real time. Contextual risk prioritization and visual reporting give insights into remedial stages for automated remediation. The performance evaluations show that these outperform with the greatest detection accuracy of 95.2%, the highest true positive rate of 91.2%, the fewest false positives of 8.8%, and the shortest detection delay of 7.6 seconds. These enhancements demonstrate that the outlined system is a very efficient, effective, and scalable method for safeguarding Salesforce CRM instances.",
    "title_zh": "基于AI的云环境中Salesforce CRM漏洞评估",
    "abstract_zh": "随着现代网络威胁的复杂性、范围和多样性不断增加，基于人工智能的漏洞评估对于Salesforce CRM等云平台而言变得日益重要。当前系统主要依赖基于规则的扫描和人工审计，缺乏灵活性与可扩展性，尤其在动态、多租户环境中，导致大量误报。本文提出一种基于人工智能的解决方案，以应对上述挑战。该策略结合了多种机器学习模型：使用孤立森林（Isolation Forest）检测异常行为，利用随机森林（Random Forest）识别潜在威胁，通过长短期记忆网络（LSTM）分析用户行为，实现实时发现配置错误、新型威胁以及可疑用户操作。结合上下文的风险优先级排序与可视化报告，为自动化修复提供清晰的整改指引。性能评估结果显示，该方法在各项指标上均表现优异：检测准确率达到95.2%，真正例率最高达91.2%，误报率最低仅为8.8%，检测延迟最短仅7.6秒。这些改进表明，所提出的系统是一种高效、有效且可扩展的方案，能够切实保障Salesforce CRM实例的安全。"
  },
  {
    "date": "2026-1-23",
    "title": "Enhancing Embedded Systems in Autonomous Vehicles and Robotics through the Integration of VLSI Design and Deep Learning",
    "authors": "S.D. Jayavathi, Baskar Gopal, Abdul Subhani Shaik, Chitravalavan, K. Thamaraiselvi, S Sankar",
    "publish": "2025 10th International Conference on Smart Structures and Systems (ICSSS)",
    "url": "https://doi.org/10.1109/icsss66939.2025.11346233",
    "source": "IEEE",
    "abstract": "The deep neural network quantization in the embedded intelligent system domain are becoming totally reliant on deep learning-based approach for the real time tasks like object detection, sensor fusion, and path planning, the hardware designing becomes more and more important. The unique and high computational processing demands in the power and space constraint embedded system make the traditional general-purpose processors (CPUs, GPUs) often not sufficient. Incorporating VLSI-based architectures, such as ASICs and FPGAs, into embedded systems allows for increased computational efficiency, decreased latency, and improved power management. This study investigates the combination of VLSI design samples with deep learning models, focusing on the advantages of accelerating hardware technology in mobile autonomous devices. Some key areas include low-power design techniques, memory optimization, and real-time deep learning inference using reconfigurable hardware. Dynamic voltage and frequency scaling (DVFS), power gating, and customized dataflow architectures are considered as the potential approaches with the potential to optimize energy consumption and performance. These advancements in energy efficiency and performance will continue to shape the landscape of embedded systems and will directly impact future advancements in autonomous robots and vehicles alike.",
    "title_zh": "通过集成VLSI设计与深度学习提升自动驾驶汽车和机器人中的嵌入式系统",
    "abstract_zh": "在嵌入式智能系统领域，深度神经网络的量化正越来越依赖于基于深度学习的方法，以实现诸如目标检测、传感器融合和路径规划等实时任务。因此，硬件设计的重要性日益凸显。嵌入式系统在功耗和空间受限的条件下，具有独特且高计算需求的特点，使得传统的通用处理器（如CPU、GPU）往往难以满足要求。将基于VLSI的架构（如ASIC和FPGA）引入嵌入式系统，能够显著提升计算效率，降低延迟，并改善功耗管理。本研究探讨了VLSI设计实例与深度学习模型的结合，重点分析了加速硬件技术在移动自主设备中的优势。关键研究方向包括低功耗设计技术、内存优化以及利用可重构硬件实现的实时深度学习推理。动态电压与频率调节（DVFS）、电源门控以及定制化数据流架构被视为优化能耗与性能的潜在方法。这些能效与性能方面的进步将持续塑造嵌入式系统的发展格局，并对自动驾驶机器人及车辆的未来发展产生直接影响。"
  },
  {
    "date": "2026-1-23",
    "title": "Lumen: Developer Agency Through Transparent Context Control in AI-Assisted Programming",
    "authors": "Nakul Goel, Glaucia Melo",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00024",
    "source": "IEEE",
    "abstract": "The landscape of software engineering has undergone rapid transformation with the emergence of Artificial Intelligence (AI) coding assistants, which are being increasingly integrated into development workflows to boost productivity and automate routine tasks. Although modern AI coding assistants, such as Claude Code, Cursor, Codex, and many others, can automatically access entire repositories, they operate as black boxes: developers cannot see or control what context drives AI decisions. This automatic operation creates uncertainty about whether critical dependencies, security configurations, or test files are considered. We present Lumen, an open-source tool that takes a fundamentally different approach: preserving developer control through transparent context assembly. Using a double-copy interaction paradigm that leverages natural clipboard behavior, Lumen instantly shows developers the dependency graph and AI-generated summaries of files connected to their copied code. This allows developers to create AI-generated code where the model uses the same context that the developer is focusing on. This design philosophy, which incorporates human-in-the-loop capabilities with full visibility, lays the foundation for future agentic capabilities, ensuring that developers understand and control what the AI sees and does. We demonstrate through Cognitive Walkthrough Analysis how Lumen reduces context assembly overhead while maintaining the transparency necessary for production code. Our open-source implementation provides a foundation for the community to build upon, developing AI tools that enhance rather than replace human judgment.",
    "title_zh": "Lumen：通过透明的上下文控制实现AI辅助编程的开发者机构",
    "abstract_zh": "软件工程领域的 landscape 随着人工智能（AI）编程助手的出现而经历了快速变革。这些工具正被越来越多地集成到开发工作流中，以提升生产力并自动化常规任务。尽管现代AI编程助手（如 Claude Code、Cursor、Codex 等）能够自动访问整个代码库，但它们本质上仍像“黑箱”：开发者无法查看或控制驱动AI决策的上下文内容。这种自动运行机制带来了不确定性——关键依赖项、安全配置或测试文件是否被考虑，难以判断。\n\n我们提出了 Lumen，一款开源工具，采用根本不同的方法：通过透明的上下文构建来保持开发者的控制权。Lumen 采用双复制交互范式，利用自然的剪贴板行为，即时向开发者展示与其复制代码相关的文件依赖图谱以及AI生成的文件摘要。这使得开发者能够生成由AI生成的代码，且模型所使用的上下文正是开发者当前关注的内容。这一设计理念将人机协同能力与完全可见性相结合，为未来的智能体（agentic）功能奠定了基础，确保开发者清楚了解AI所见与所作，并能有效掌控。\n\n通过认知走查分析（Cognitive Walkthrough Analysis），我们展示了 Lumen 如何在降低上下文组装开销的同时，维持生产代码所需的透明度。我们的开源实现为社区提供了坚实的基础，推动构建那些增强而非取代人类判断的AI工具。"
  },
  {
    "date": "2026-1-23",
    "title": "Design of Burst Mode Enabled SRAM Controller Using FSM",
    "authors": "Paramasivam. C, Gunnala Meghana Sri",
    "publish": "2025 IEEE 2nd International Conference on Information Technology, Electronics and Intelligent Communication Systems (ICITEICS)",
    "url": "https://doi.org/10.1109/iciteics64870.2025.11341477",
    "source": "IEEE",
    "abstract": "Static Random Access Memory (SRAM) is crucial for high-speed digital systems, but because it operates asynchronously, interfacing with synchronous logic can be difficult. This paper brings up the gradual development of two SRAM controllers(controller five and controller six) depending on Finite State Machines (FSMs), which solved particular concerns resulting in a bus write-contention, smaller write-enable (WE) pulse width, and unconfirmed tristate control. The last architecture, Controller 6 brings a new burst-mode operation, full cycle WE compatibility, dedicated precharge stage, tristate safety to provide timing integrity and data asynchronous at high frequency range (50MHz and 100MHz). Simulation of the controller is implemented on xilinx Vivado, and post synthesis analysis done on Cadence Genus. Controller 6 exhibits better slack, lesser setup time and non-contention than earlier designs. It is also well-suited as an embedded system designed on FPGA using fast and reliable communication in SRAM because it is integration of friendly and has strong behavior.",
    "title_zh": "使用有限状态机实现支持突发模式的SRAM控制器设计",
    "abstract_zh": "静态随机存取存储器（SRAM）对于高速数字系统至关重要，但由于其异步工作特性，与同步逻辑接口时存在困难。本文提出基于有限状态机（FSM）的两种SRAM控制器（控制器五和控制器六）的渐进式开发，解决了特定问题，包括总线写冲突、写使能（WE）脉冲宽度过窄以及三态控制未确认等问题。其中，最新架构——控制器六引入了新的突发模式操作、完整的周期WE兼容性、专用预充电阶段以及三态安全机制，从而在高频范围（50MHz和100MHz）内实现了时序完整性与数据异步性。控制器的仿真在Xilinx Vivado平台上完成，综合后的分析则使用Cadence Genus工具进行。结果显示，控制器六相比早期设计具有更优的时序余量、更短的建立时间，并且无总线竞争现象。此外，由于其良好的集成性与稳健的行为表现，该控制器特别适用于基于FPGA实现的嵌入式系统，能够支持SRAM中快速可靠的通信。"
  },
  {
    "date": "2026-1-23",
    "title": "LLM-Powered Code Quality Bot: Automating Refactoring in CI/CD",
    "authors": "Akram Adem, Glaucia Melo",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00101",
    "source": "IEEE",
    "abstract": "Code quality issues, such as code smells and minor bugs, consume valuable developer time and can slow down software delivery pipelines. This poster presents SonaRefactor, an AI-assisted CI/CD pipeline that merges SonarCloud static analysis with Gemini LLM to automatically summarize flagged issues and propose safe, minimal code fixes. When a pull request is opened, the bot automatically detects issues, explains them in context, and generates a minimal safe autofix that is committed back as a new pull request. This work demonstrates how large language models can act as hands-on teammates in software development pipelines, offloading repetitive refactoring tasks so developers can focus on more complex and creative aspects of software engineering. Our tool minimizes developer interruption by enforcing conservative, auditable changes that reduce friction in the review process, without compromising safety or autonomy.",
    "title_zh": "基于大语言模型的代码质量机器人：在CI/CD中实现自动化重构",
    "abstract_zh": "代码质量问题，如代码异味和小缺陷，会消耗宝贵的开发人员时间，并可能拖慢软件交付流程。本海报介绍了 SonaRefactor——一种AI辅助的CI/CD流水线，该系统将 SonarCloud 静态分析与 Gemini 大语言模型相结合，能够自动总结被标记的问题，并提出安全、简洁的代码修复建议。当打开一个拉取请求时，机器人会自动检测问题，在上下文中解释其原因，并生成最小且安全的自动修复方案，随后以新的拉取请求形式提交回代码库。这项工作展示了大型语言模型如何在软件开发流程中扮演“实战搭档”的角色，帮助开发者卸下重复性的重构任务，使其能够专注于更复杂、更具创造性的软件工程工作。我们的工具通过实施保守且可审计的变更策略，最大限度减少对开发者的干扰，既降低了评审过程中的摩擦，又不牺牲安全性或开发自主性。"
  },
  {
    "date": "2026-1-23",
    "title": "Evolutionary-Based Circuit Optimization for Distributed Quantum Computing",
    "authors": "Leo Sünkel, Jonas Stein, Gerhard Stenzel, Michael Kölle, Thomas Gabor, Claudia Linnhoff-Popien",
    "publish": "2025 IEEE International Conference on Quantum Artificial Intelligence (QAI)",
    "url": "https://doi.org/10.1109/qai63978.2025.00048",
    "source": "IEEE",
    "abstract": "In this work, we evaluate an evolutionary algorithm (EA) to optimize a given circuit in such a way that it reduces the required communication when executed in the Distributed Quantum Computing (DQC) paradigm. We evaluate our approach for a state preparation task using Grover circuits and show that it is able to reduce the required global gates by more than 89 % while still achieving high fidelity as well as the ability to extract the correct solution to the given problem. We also apply the approach to reduce circuit depth and number of CX gates. Additionally, we run experiments in which a circuit is optimized for a given network topology after each qubit has been assigned to specific nodes in the network. In these experiments, the algorithm is able to reduce the communication cost (i.e., number of hops between QPUs) by up to 19 %.",
    "title_zh": "基于进化算法的分布式量子计算电路优化",
    "abstract_zh": "在本研究中，我们评估了一种进化算法（EA），用于优化给定电路，使其在分布式量子计算（DQC）范式下执行时减少所需的通信开销。我们以Grover电路实现状态制备任务为例，验证了该方法的有效性，结果表明，该方法能够在保持高保真度并准确提取问题解的同时，将所需全局门的数量减少超过89%。此外，我们将该方法应用于降低电路深度和CX门数量。同时，我们还进行了实验，在每个量子比特被分配到网络中特定节点后，针对给定的网络拓扑结构对电路进行优化。在这些实验中，该算法能够将通信成本（即量子处理单元（QPUs）之间的跳数）最多降低19%。"
  },
  {
    "date": "2026-1-23",
    "title": "Leveraging Large Language Models for Efficient Vulnerability Detection in IoT Firmware",
    "authors": "Jie Liu, Shan Sun",
    "publish": "2025 IEEE 3rd International Conference on Control, Electronics and Computer Technology (ICCECT)",
    "url": "https://doi.org/10.1109/iccect64621.2025.11339749",
    "source": "IEEE",
    "abstract": "The integration of Internet of Things (IoT) technologies across various domains has significantly enhanced operational efficiency. However, it has also introduced serious cybersecurity threats. For instance, buffer overflow vulnerabilities can lead to device crashes, often arising from inadequate validation of data format and length in back-end processing of front-end transmitted data, which may subsequently be misused by unsafe functions. Static taint analysis is an effective approach for detecting such vulnerabilities, but existing methods often suffer from high computational overhead and excessive false positives due to the identification of too many irrelevant sources. To address these challenges, this paper proposes LLMIOT, a large language model-assisted vulnerability detection method that improves efficiency and reduces false positives through keyword filtering in embedded firmware. We leverage shared front-end and back-end keywords to identify relevant function call paths in the program's function call graph (CG). Large language models (LLMs) are then used to filter out irrelevant keywords before performing taint analysis to detect vulnerabilities. We evaluated LLMIOT on two datasets and compared it against state-of-the-art methods, SaTC and HermeScan. Experimental results show that LLMIOT efficiently eliminates more irrelevant keywords, reducing their count by 66% compared to SaTC and 83% compared to HermeScan. Furthermore, LLMIOT improves processing speed, achieving an average speed up of 1.9x over SaTC and 1.83x over HermeScan.",
    "title_zh": "利用大语言模型实现物联网固件中高效漏洞检测",
    "abstract_zh": "物联网（IoT）技术在各个领域的融合显著提升了运营效率，但同时也带来了严重的网络安全威胁。例如，缓冲区溢出漏洞可能导致设备崩溃，这通常源于前端传输数据在后端处理过程中对数据格式和长度的验证不足，进而被不安全函数滥用。静态污点分析是一种有效检测此类漏洞的方法，但现有方法常因识别出过多无关源而面临计算开销大和误报率高的问题。为应对这些挑战，本文提出了一种基于大语言模型的漏洞检测方法——LLMIOT，该方法通过嵌入式固件中的关键词过滤机制，提高了检测效率并降低了误报率。我们利用前端与后端共享的关键词，在程序的调用图（CG）中识别相关的函数调用路径；随后，借助大语言模型（LLMs）对关键词进行筛选，剔除无关项后再执行污点分析以检测漏洞。我们在两个数据集上对LLMIOT进行了评估，并与当前最先进的方法SaTC和HermeScan进行了对比。实验结果表明，LLMIOT能够更高效地消除无关关键词，其数量较SaTC减少66%，较HermeScan减少83%。此外，LLMIOT还显著提升了处理速度，平均比SaTC快1.9倍，比HermeScan快1.83倍。"
  },
  {
    "date": "2026-1-23",
    "title": "Evaluation of ChatGPT and Gemini Large Language Models for Generating Pharmacokinetic Models with SimBiology",
    "authors": "Libera Lucia Del Giudice, Agnese Piersanti, Alessandro Morelli, Christian Göbl, Laura Burattini, Andrea Tura, Micaela Morettini",
    "publish": "2025 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)",
    "url": "https://doi.org/10.1109/metroxraine66377.2025.11340416",
    "source": "IEEE",
    "abstract": "Generative Artificial Intelligence (AI) chatbots like ChatGPT or Gemini rely on Large Language Models (LLMs), which are deep-learning algorithms capable of recognizing, generating, summarizing, translating, and predicting content using large data sets. They are yielding a strong boost to technological innovation in all fields, including drug discovery and development, in which in-silico models are often used to describe the behavior of biological systems and study their pharmacokinetic/pharmacodynamic (PK/PD) properties. This study aimed to evaluate how Generative AI tools, such as ChatGPT and Gemini, among the widely accessible LLMs, can support the PK/PD modeling process. It evaluated the potential of these LLMs in generating instructions within SimBiology, a MATLAB tool dedicated to modeling, simulation and analysis of biological systems. Four case studies were considered, the first two aimed at teaching SimBiology fundamentals and at providing basic model examples, and the second two directly related to the creation of a PK/PD model. Each output was evaluated based on the instructions provided, the differences between the two LLMs' answers, the errors made, and the ability of the tool to correct them. The results showed that ChatGPT offered greater accuracy and flexibility in code generation than Gemini, since it is able to better correct its errors, although both presented structural and syntactic errors, limiting the fully automated modeling tasks. In conclusion, ChatGPT and Gemini are promising tools for building in-silico models, especially in the early stages of model development, but at present, they require human supervision and expertise to correct errors and improve reliability.",
    "title_zh": "使用SimBiology生成药代动力学模型的ChatGPT与Gemini大型语言模型评估",
    "abstract_zh": "生成式人工智能（AI）聊天机器人，如ChatGPT或Gemini，依赖于大型语言模型（LLMs），这些模型是深度学习算法，能够利用大规模数据集识别、生成、总结、翻译和预测内容。它们正在各个领域推动技术革新，包括药物发现与开发，其中常使用计算机模拟（in-silico）模型来描述生物系统的行为，并研究其药代动力学/药效动力学（PK/PD）特性。本研究旨在评估生成式AI工具（如ChatGPT和Gemini）在支持PK/PD建模过程中的作用。研究重点考察了这些LLM在SimBiology（MATLAB中专用于生物系统建模、仿真与分析的工具）中生成操作指令的潜力。研究共设计了四个案例：前两个案例旨在教授SimBiology的基础知识并提供基本模型示例；后两个案例则直接涉及PK/PD模型的构建。每个输出结果均根据所提供的指令、两种LLM回答之间的差异、所犯错误以及工具自我纠错能力进行评估。结果显示，尽管两者均存在结构和语法错误，限制了完全自动化建模任务的实现，但ChatGPT在代码生成方面表现出更高的准确性和灵活性，尤其在错误修正方面优于Gemini。综上所述，ChatGPT和Gemini作为构建计算机模拟模型的工具具有广阔前景，尤其是在模型开发的早期阶段，但目前仍需人工监督与专业知识来纠正错误，以提升模型的可靠性。"
  },
  {
    "date": "2026-1-23",
    "title": "Beyond Functional Correctness: Exploring Hallucinations in LLM-Generated Code",
    "authors": "Fang Liu, Yang Liu, Lin Shi, Zhen Yang, Li Zhang, Xiaoli Lian, Zhongqi Li, Yuchi Ma",
    "publish": "IEEE Transactions on Software Engineering",
    "url": "https://doi.org/10.1109/tse.2026.3657432",
    "source": "IEEE",
    "abstract": "The rise of Large Language Models (LLMs) has significantly advanced various applications on software engineering tasks, particularly in code generation. Despite the promising performance, LLMs are prone to generate hallucinations, which means LLMs might produce outputs that deviate from users’ intent, exhibit internal inconsistencies, or misaligned with the real world knowledge, making the deployment of LLMs potentially risky in a wide range of applications. Existing work mainly focuses on investigating the hallucination in the domain of Natural Language Generation (NLG), leaving a gap in comprehensively understanding the types, causes, and impacts of hallucinations in the context of code generation. To bridge the gap, we conducted a thematic analysis of the LLM-generated code to summarize and categorize the hallucinations, as well as their causes and impacts. Our study established a comprehensive taxonomy of code hallucinations, encompassing 3 primary categories and 12 specific categories. Furthermore, we systematically analyzed the distribution of hallucinations, exploring variations among different LLMs and benchmarks. Moreover, we perform an indepth analysis on the causes and impacts of various hallucinations, aiming to provide valuable insights into hallucination mitigation. Finally, to enhance the correctness and reliability of LLM-generated code in a lightweight manner, we explore a training-free hallucination mitigation approach by prompt enhancing techniques. We believe our findings will shed light on future research about hallucination evaluation and mitigation, ultimately paving the way for building more effective and reliable code LLMs in the future. The replication package is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/Lorien1128/code hallucination</uri>.",
    "title_zh": "超越功能正确性：探索大语言模型生成代码中的幻觉问题",
    "abstract_zh": "大型语言模型（LLMs）的兴起显著推动了软件工程任务中各类应用的发展，尤其是在代码生成方面。尽管表现前景可观，但LLMs容易产生“幻觉”——即生成的内容可能偏离用户意图、存在内部不一致，或与现实世界知识不符，这使得LLMs在广泛应用场景中的部署面临潜在风险。现有研究主要聚焦于自然语言生成（NLG）领域中的幻觉问题，而在代码生成场景下，对幻觉类型、成因及影响的系统性理解仍存在明显空白。为填补这一空白，我们对LLM生成的代码进行了主题分析，总结并分类了幻觉现象及其成因与影响。本研究构建了一个全面的代码幻觉分类体系，涵盖3个主类别和12个具体类别。此外，我们系统地分析了幻觉在不同LLMs和基准测试之间的分布特征，揭示其差异性。同时，我们深入探讨了各类幻觉的成因与实际影响，旨在为幻觉缓解提供有价值的洞见。最后，为以轻量级方式提升LLM生成代码的正确性与可靠性，我们探索了一种无需训练的幻觉缓解方法，通过提示增强技术实现。我们认为，本研究的发现将为未来幻觉评估与缓解相关研究提供重要参考，最终助力构建更高效、更可靠的代码生成类大模型。复现代码包可访问：https://github.com/Lorien1128/code-hallucination。"
  },
  {
    "date": "2026-1-23",
    "title": "Power Consumption Minimization in FSM with Optimal State Encoding Using Whale Optimization Algorithm",
    "authors": "Nataraj Urs H.D., Manju K S, Kuberachari S.H",
    "publish": "2025 Second International Conference on Networks and Soft Computing (ICNSoC)",
    "url": "https://doi.org/10.1109/icnsoc66817.2025.00023",
    "source": "IEEE",
    "abstract": "The power consumption performance of a Finite State Machine (FSM) is significantly influenced by state encoding. Optimal state encoding can greatly reduce dynamic power consumption by minimizing switching activities. This work employs the Whale Optimization Algorithm (WOA) to determine the optimal state encoding and reduce power consumption. A cost model aimed at minimizing power consumption has been developed based on Minimum Weighted Hamming Distance. The proposed approach utilizes state probabilities and a total transition model to form a weighted graph for the FSM. Additionally, other meta-heuristic approaches, such as Particle Swarm Optimization (PSO) in both static and adaptive versions, were also examined, and their performances were evaluated. Ultimately, the WOA achieved the lowest power consumption and demonstrated excellent consistency.",
    "title_zh": "基于鲸鱼优化算法的最优状态编码在有限状态机中的功耗最小化",
    "abstract_zh": "有限状态机（FSM）的功耗性能在很大程度上受到状态编码的影响。采用最优的状态编码可显著降低动态功耗，从而减少开关活动。本文采用鲸鱼优化算法（WOA）来确定最优状态编码，以实现功耗的降低。基于最小加权汉明距离构建了一个旨在最小化功耗的成本模型。所提出的方法利用状态概率和总体转移模型，为FSM构建了一个加权图。此外，还研究了其他几种元启发式算法，包括静态和自适应版本的粒子群优化（PSO），并对其性能进行了评估。最终，WOA在降低功耗方面表现最佳，并展现出优异的一致性。"
  },
  {
    "date": "2026-1-23",
    "title": "Quantum Software: From Engineering to Interaction",
    "authors": "Mina Alipour",
    "publish": "2025 IEEE Conference on Cloud and Big Data Computing (CBDCom)",
    "url": "https://doi.org/10.1109/cbdcom68404.2025.00030",
    "source": "IEEE",
    "abstract": "Recent progress in quantum computing has under-scored the need for specialized software to effectively address the unique challenges posed by quantum systems. While early research emphasized hardware and algorithmic breakthroughs, recent progress underscores the necessity of Quantum Soft-ware Engineering (QSE), an emerging discipline that combines software lifecycle processes, tooling, hybrid orchestration, and human-centered design. This paper integrates insights from QSE and quantum software architecture (QSA) to propose a hybrid execution architecture explicitly shaped by Quantum HCI principles, emphasizing developer experience, trust, and the quality of interaction with quantum systems. While quantum software represents a new genre of software-intensive systems, existing processes and notations can be adapted to derive architecting activities and develop modeling languages for quantum software. Additionally, tool chains can incorporate reusable knowledge and roles to automate and customize the architectural process. By analyzing current research and iden-tifying existing gaps, this paper aims to guide the systematic development of robust and scalable quantum software systems. Central to this vision is meaningful human interaction, ensuring that developers can interpret, act on, and trust system outputs from design to post-execution analysis.",
    "title_zh": "量子软件：从工程到交互",
    "abstract_zh": "近期量子计算领域的进展凸显了开发专用软件以有效应对量子系统独特挑战的迫切需求。尽管早期研究侧重于硬件和算法突破，但近期进展强调了量子软件工程（Quantum Software Engineering, QSE）的必要性——这一新兴学科融合了软件生命周期流程、工具链、混合编排以及以人为本的设计理念。本文结合QSE与量子软件架构（Quantum Software Architecture, QSA）的洞见，提出一种由量子人机交互（Quantum HCI）原则明确塑造的混合执行架构，特别关注开发者的使用体验、对系统的信任度，以及与量子系统交互的质量。虽然量子软件代表了一类新型的软件密集型系统，但现有的流程与表示方法可被适配，用于推导架构活动并构建量子软件的建模语言。此外，工具链可整合可复用的知识与角色，以实现架构过程的自动化与定制化。通过分析当前研究并识别现有空白，本文旨在指导稳健且可扩展的量子软件系统之系统性开发。这一愿景的核心在于有意义的人机交互，确保开发者能够从设计到后执行分析的全过程中，理解、响应并信任系统输出。"
  },
  {
    "date": "2026-1-23",
    "title": "Anew Paradigm of AI Development Driven by Low-Code",
    "authors": "Wenxuan Song",
    "publish": "2025 IEEE 3rd International Conference on Control, Electronics and Computer Technology (ICCECT)",
    "url": "https://doi.org/10.1109/iccect64621.2025.11339730",
    "source": "IEEE",
    "abstract": "In the big data era, to solve algorithm engineers' problems of complex data analysis and low development efficiency, “low-code” platforms emerged. The Intelligent Simplification and Innovation AI Platform in this paper is a low-code-based AI algorithm platform. It builds applications via graphical interfaces. Technologically, it uses low-code to free developers, applies machine and deep learning, offers one-stop services, helps build custom models, and promotes data science-IT O&M collaboration. Functionally, it integrates multiple functions, eases communication, supports the whole development process, and meets diverse needs. It's also easy-to-use, fast-developing, zero-co de-friendly, and has pre-built modules. It suits various AI learning scenarios, supports automated modeling and drag-and-drop task flows, benefits both pros and beginners, has great enterprise application advantages, and follows the low-code development trend.",
    "title_zh": "由低代码驱动的AI发展新范式",
    "abstract_zh": "在大数据时代，为解决算法工程师面临的复杂数据分析与开发效率低下的问题，“低代码”平台应运而生。本文所介绍的智能简化与创新AI平台即是一个基于低代码的AI算法平台。该平台通过图形化界面构建应用，技术上采用低代码技术解放开发者，融合机器学习与深度学习技术，提供一站式服务，助力用户构建定制化模型，并推动数据科学与IT运维的协同合作。功能上，平台集成多项功能，简化沟通流程，支持完整的开发周期，满足多样化需求。其易用性高、开发速度快、零代码友好，且内置丰富的预置模块。该平台适用于各类AI学习场景，支持自动化建模与拖拽式任务流设计，既适合专业人员也惠及初学者，具备显著的企业应用优势，顺应了低代码开发的发展趋势。"
  },
  {
    "date": "2026-1-23",
    "title": "LLM-Driven Automated Penetration Testing: Architectures, Benchmarks, and Safety Considerations",
    "authors": "Akshitha Segireddy",
    "publish": "2025 10th International Conference on Smart Structures and Systems (ICSSS)",
    "url": "https://doi.org/10.1109/icsss66939.2025.11346427",
    "source": "IEEE",
    "abstract": "In recent years, there has been a growing trend toward using large language models (LLMs) to automate penetration testing tasks, including reconnaissance, vulnerability discovery, exploit identification, and reporting. Previous works, including PentestGPT, Curriculum PT, RapidPen, White Rabbit Neo- PentestGPT, and HackSynth, have shown that LLM guided workflows can be superior to naive prompting and traditional scripting-based approaches on both capture the flag (CTF) challenges and realistic lab environments, and have attracted significant community interest and public benchmarking. Nevertheless, the complete automation of penetration testing remains an unsolved problem: current tools continue to fail to address issues related to managing context, orchestrating tools, handling environmental variations, and enforcing safety constraints. In this paper, we introduce a unified LLM-driven automated Penetration Testing Framework that divides the workflow of penetration testing into formally defined tasks, states, and actions, utilizing LLM-based agents to develop, execute, and modify multi-step attack chains across multiple layers of networks, web, cloud, and application environments. We detail how to integrate external tools (scanners, exploit frameworks, and knowledge bases) into the framework, design a memory and reasoning layer to prevent the loss of context, and define safety and governance controls to limit the misuse of the system. We conduct experiments using synthetic labs, standardized CTFstyle benchmarks, and real-world-inspired scenarios, and compare our results against those obtained from human testers, scripted pipelines, and previous LLM-based systems. Our results indicate significant improvements in task completion, coverage, and time-to-compromise, while also identifying failure modes and informing future research directions. The purpose of this paper is to provide a reference architecture and experimental guide for next-generation, LLM-driven penetration testing.",
    "title_zh": "基于大语言模型的自动化渗透测试：架构、基准测试与安全考量",
    "abstract_zh": "近年来，利用大型语言模型（LLMs）自动化渗透测试任务的趋势日益增长，涵盖侦察、漏洞发现、漏洞利用识别以及报告生成等环节。此前的研究工作，包括PentestGPT、Curriculum PT、RapidPen、White Rabbit Neo-PentestGPT以及HackSynth等，已表明基于LLM引导的工作流在CTF挑战和真实实验室环境中，相较于简单的提示工程和传统的脚本化方法具有显著优势，并引发了社区的广泛关注与公开基准测试。然而，渗透测试的完全自动化仍是一个未解决的问题：当前工具在管理上下文、协调工具使用、应对环境差异以及实施安全约束等方面仍存在明显不足。本文提出了一种统一的、由LLM驱动的自动化渗透测试框架，将渗透测试流程分解为形式化定义的任务、状态与动作，通过基于LLM的智能体在多层网络、Web、云及应用环境中构建、执行并动态调整多步骤攻击链。我们详细阐述了如何将外部工具（如扫描器、漏洞利用框架和知识库）集成到该框架中，设计了记忆与推理层以防止上下文丢失，并建立了安全与治理控制机制以防范系统滥用。通过合成实验环境、标准化的CTF风格基准测试以及现实场景启发的模拟案例进行实验，我们将本框架的表现与人工测试者、脚本化流水线以及先前的LLM-based系统进行了对比。实验结果表明，本方法在任务完成率、覆盖范围和攻陷时间方面均有显著提升，同时揭示了系统的失效模式，并为未来研究指明了方向。本文旨在为下一代LLM驱动的渗透测试提供参考架构与实验指南。"
  },
  {
    "date": "2026-1-23",
    "title": "Securing LLM-Generated Embedded Firmware Through AI Agent-Driven Validation and Patching",
    "authors": "Seyed Moein Abtahi, Akramul Azim",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00044",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) show promise in generating firmware for embedded systems but often introduce security flaws and fail to meet real-time performance constraints. This paper proposes a three-phase methodology that combines LLM-based firmware generation with automated security validation and iterative refinement in a virtualized environment. Using structured prompts, models like GPT-4 generate firmware for networking and control tasks, deployed on FreeRTOS via QEMU. These implementations are tested using fuzzing, static analysis, and runtime monitoring to detect vulnerabilities such as buffer overflows (CWE-120), race conditions (CWE-362), and denial-of-service threats (CWE-400). Specialized AI agents for Threat Detection, Performance Optimization, and Compliance Verification collaborate to improve detection and remediation. Identified issues are categorized using CWE, then used to prompt targeted LLM-generated patches in an iterative loop. Experiments show a 92.4% Vulnerability Remediation Rate (37.3% improvement), <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\text{95.8 \\%}$</tex> Threat Model Compliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6 ms worst-case execution time and <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$195 \\mu$</tex> jitter. This process enhances firmware security and performance while contributing an open-source dataset for future research.",
    "title_zh": "通过AI代理驱动的验证与修补实现LLM生成嵌入式固件的安全保障",
    "abstract_zh": "大型语言模型（LLMs）在生成嵌入式系统固件方面展现出巨大潜力，但往往引入安全漏洞，并难以满足实时性能要求。本文提出了一种三阶段方法论，将基于LLM的固件生成与自动化安全验证及虚拟化环境中的迭代优化相结合。通过结构化提示，GPT-4等模型可生成用于网络通信和控制任务的固件，并在FreeRTOS上通过QEMU进行部署。这些实现通过模糊测试、静态分析和运行时监控进行测试，以检测缓冲区溢出（CWE-120）、竞争条件（CWE-362）以及拒绝服务攻击威胁（CWE-400）等漏洞。专门设计的AI代理——威胁检测、性能优化与合规性验证代理——协同工作，提升漏洞检测与修复效率。识别出的问题依据CWE标准分类后，用于触发针对性的LLM生成补丁，形成持续迭代的闭环流程。实验结果表明，漏洞修复率达到92.4%（较基准提升37.3%），威胁模型符合率达95.8%，安全覆盖指数为0.87。实时性能指标包括最差执行时间为8.6毫秒，抖动小于195微秒。该方法显著提升了固件的安全性与实时性能，同时为未来研究贡献了一个开源数据集。"
  },
  {
    "date": "2026-1-23",
    "title": "Streamlining Epidemiological Model Generation Using Large Language Models",
    "authors": "Aaditya Karamchandani, Fatemeh Seyeddabbaghi, Marios Fokaefs",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00096",
    "source": "IEEE",
    "abstract": "Epidemiological modeling is a critical step in understanding and studying diseases. While conventional modeling techniques, like compartmental or agentic models, exist, supporting tools are not necessarily standardized. Consequently, learning a new tool may incur significant effort. In this work, we explore the use of Large Language Models (LLMs) as a means to quickly transition from requirements, in the form of graphical model representations and initial parameters to a software-aided modeling platform with simulation and verification capabilities. Our methodology employs a metamodel-based language specification for prompt engineering, combined with multimodal inputs comprising textual descriptions and epidemiological diagrams. We evaluate LLM performance across three epidemiological models of varying complexity: a simple SIR compartmental model, a COVID-19 pandemic model, and an HIV transmission model. Initial results demonstrate the potential of LLMs to significantly reduce manual modeling effort while maintaining accuracy in structural representation and parameter extraction. The study provides insights into optimal input configurations and identifies key challenges in automated epidemiological model generation.",
    "title_zh": "利用大型语言模型简化流行病学模型的生成",
    "abstract_zh": "流行病学建模是理解与研究疾病的关键步骤。尽管传统的建模方法（如分 compartment 模型或代理模型）已存在，但支持工具并未实现标准化，因此学习使用新工具往往需要付出巨大努力。在本研究中，我们探索利用大型语言模型（LLMs）作为快速将需求（以图形化模型表示和初始参数形式）转换为具备仿真与验证功能的软件建模平台的手段。我们的方法采用基于元模型的语言规范进行提示工程，并结合文本描述与流行病学图示等多模态输入。我们在三种不同复杂度的流行病学模型上评估了LLM的表现：一个简单的SIR分 compartment 模型、一个新冠大流行模型以及一个HIV传播模型。初步结果表明，LLMs 有望显著减少人工建模的工作量，同时保持结构表示和参数提取的准确性。本研究为最优输入配置提供了洞见，并识别出自动化流行病学模型生成中的关键挑战。"
  },
  {
    "date": "2026-1-23",
    "title": "A Preliminary Systematic Review on LLM-Based System Assurance: Is Generative AI All You Need?",
    "authors": "Alvine Boaye Belle, Gerhard Yu",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00098",
    "source": "IEEE",
    "abstract": "Assurance cases allow verifying that the nonfunctional requirements (e.g., safety, security, reliability) of mission-critical systems are correctly implemented. This helps avoid system malfunction, which could have catastrophic consequences (e.g., deaths, environmental damage, financial losses). However, assurance cases are usually very large documents spanning several hundred pages. Their creation and maintenance may therefore be time-consuming and tedious. Relying on (semi)automated techniques such as those supported by generative AI through LLMs could alleviate the task of assurance case developers by facilitating the execution of all activities related to the assurance case lifecycle. In this paper, we report a critical analysis of the peer-reviewed literature on LLM-based system assurance to inform future research on this topic.",
    "title_zh": "基于大语言模型的系统保障初步系统性综述：生成式AI是否已足够？",
    "abstract_zh": "保证案例有助于验证关键任务系统中非功能性需求（如安全、保密、可靠性）是否得到正确实现。这有助于避免系统故障，从而防止可能造成灾难性后果的情况（如人员伤亡、环境破坏、财务损失）。然而，保证案例通常是非常庞大的文档，动辄数百页，其创建和维护过程因此可能耗时且繁琐。借助生成式人工智能通过大语言模型（LLMs）支持的（半）自动化技术，有望减轻保证案例开发人员的工作负担，从而促进整个保证案例生命周期相关活动的高效执行。本文报告了对基于大语言模型的系统保证领域同行评审文献的批判性分析，旨在为该领域的未来研究提供参考。"
  },
  {
    "date": "2026-1-23",
    "title": "Supervised Semantic Similarity-Based Conflict Detection Algorithm: S3CDA",
    "authors": "Garima Malik, Mucahit Cevik, Ayşe Başar, Devang Parikh",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00079",
    "source": "IEEE",
    "abstract": "Identifying conflicting requirements is a key challenge in software requirement engineering, often overlooked in automated solutions. Most existing approaches rely on handcrafted rules or struggle to generalize across different domains. In this paper, we introduce S3CDA, a two-phase algorithm designed to automatically detect conflicts in software requirements. Our method first identifies potentially conflicting requirement pairs using semantic similarity, and then validates them by analyzing overlapping domain-specific entities. We evaluate S3CDA on five diverse real-world datasets and compare it against popular large language models like GPT-4o, Llama-3, Sonnet-3.5 and Gemini-1.5. While LLMs show promise, especially on general datasets, S3CDA consistently performs better in domain-specific settings with higher performance. Our findings suggest that combining Natural Language Processing (NLP) techniques with domainaware insights offers a practical and effective alternative for conflict detection in requirements.",
    "title_zh": "基于监督语义相似性的冲突检测算法：S3CDA",
    "abstract_zh": "识别冲突需求是软件需求工程中的一个关键挑战，但在自动化解决方案中常常被忽视。现有的大多数方法依赖于手工编写的规则，或难以在不同领域间实现泛化。本文提出了一种两阶段算法S3CDA，旨在自动检测软件需求中的冲突。该方法首先利用语义相似性识别可能存在冲突的需求对，然后通过分析重叠的特定领域实体来验证这些冲突。我们在五个不同的真实世界数据集上评估了S3CDA，并与GPT-4o、Llama-3、Sonnet-3.5和Gemini-1.5等主流大语言模型进行了对比。尽管大语言模型在通用数据集上表现出一定潜力，但S3CDA在特定领域设置下始终表现更优，且性能更高。研究结果表明，将自然语言处理（NLP）技术与领域知识相结合，为需求冲突检测提供了一种实用而有效的替代方案。"
  },
  {
    "date": "2026-1-23",
    "title": "Optimised Coding Technique for Low Power Network on Chip Applications",
    "authors": "Surya V.N. S. V. Chakka, Ravirala Sooraj, Peneji Vishnu Sai Revanth, M. Vinodhini",
    "publish": "2025 IEEE 2nd International Conference on Information Technology, Electronics and Intelligent Communication Systems (ICITEICS)",
    "url": "https://doi.org/10.1109/iciteics64870.2025.11341569",
    "source": "IEEE",
    "abstract": "Current computing systems require ever-increasing reliability, particularly as memory technology needs to cater for data-intensive and mission-critical applications. As the sizes of transistors are reducing and the densities of memory are increasing, the probability of memory cells being affected by transient faults, soft errors, and bit flips has dramatically increased. Even an error that is left uncorrected can cause catastrophic failures in the systems used in aerospace, automotive, medical devices, and cloud infrastructure. Error-Correcting Codes (ECCs) have become a key mechanism for protecting data integrity as well as system stability in hostile operating environments. In this work, we precisely focus on self-transition-induced errors, which are a growing class of faults related to internal instability in highly scaled memory cells. To overcome these challenges, we propose a Row-Wise Hamming scheme that significantly reduces redundancy through efficient row-level encoding and decoding. The design attains 100 % correction efficiency of burst errors up to the maximum of 5 bits, alleviating the localized and self-transition faults. Synthesis results show an impressive 82.35 % area reduction and 98.99% power saving, making our solution an efficient and scalable alternative to traditional ECC architectures of future memories. The whole design was carried out in Verilog HDL and used in the ModelSim environment. In addition, synthesis was performed using the Cadence Genus tool.",
    "title_zh": "低功耗网络芯片应用的优化编码技术",
    "abstract_zh": "当前计算系统对可靠性的要求日益提高，尤其是在内存技术需满足数据密集型和关键任务应用需求的背景下。随着晶体管尺寸不断缩小、内存密度持续增加，存储单元受瞬态故障、软错误及位翻转影响的概率显著上升。即使是一个未被纠正的错误，也可能在航空航天、汽车、医疗设备以及云基础设施等系统中引发灾难性故障。因此，纠错码（ECC）已成为在恶劣工作环境下保障数据完整性和系统稳定性的关键技术。本文重点研究由自转变引起的错误，这类故障是高度缩放存储单元内部不稳定性所导致的一类日益增长的故障类型。为应对这些挑战，我们提出了一种基于行的汉明码方案，通过高效的行级编码与解码机制大幅降低冗余开销。该设计能够实现高达5位的突发错误100%纠正效率，有效缓解局部化及自转变故障问题。综合结果表明，本方案实现了惊人的82.35%面积缩减和98.99%功耗降低，使其成为未来内存中传统ECC架构的一种高效且可扩展的替代方案。整个设计采用Verilog HDL完成，并在ModelSim环境中进行仿真验证；同时，使用Cadence Genus工具进行了综合。"
  },
  {
    "date": "2026-1-23",
    "title": "From Requirements to Models: A Case Study of Large Language Models on Epidemiological Modeling",
    "authors": "Aaditya Karamchandani, Fatemeh Seyeddabbaghi, Marios Fokaefs",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00082",
    "source": "IEEE",
    "abstract": "Epidemiological modeling is a critical step in understanding and studying diseases. Although conventional modeling techniques exist, such as compartmental or agentic models, supporting tools are not necessarily standardized. Consequently, learning a new tool may take a significant amount of effort. In this work, we explore the use of Large Language Models (LLMs) as a means to quickly transition from requirements, in the form of graphical model representations and initial parameters, to a software-aided modeling platform with simulation and verification capabilities. Our methodology employs a metamodelbased language specification for prompt engineering, combined with multimodal inputs comprising textual descriptions and epidemiological diagrams. We evaluated LLM performance in three epidemiological models of varying complexity: a simple SIR compartmental model, a COVID-19 pandemic model, and an HIV transmission model. Initial results demonstrate the potential of LLMs to significantly reduce manual modeling effort while maintaining accuracy in structural representation and parameter extraction. The study provides insights into optimal input configurations and identifies key challenges in automated epidemiological model generation.",
    "title_zh": "从需求到模型：大型语言模型在流行病学建模中的案例研究",
    "abstract_zh": "流行病学建模是理解与研究疾病的关键步骤。尽管已存在一些传统的建模方法，如分 compartment（分室）模型或代理模型，但支持这些方法的工具并不一定标准化，因此学习使用新工具往往需要耗费大量精力。在本研究中，我们探索了利用大语言模型（LLMs）作为快速从需求（以图形化模型表示和初始参数形式）过渡到具备仿真与验证能力的软件化建模平台的可行性。我们的方法采用基于元模型的语言规范进行提示工程，并结合包含文本描述和流行病学图示的多模态输入。我们在三种不同复杂度的流行病学模型上评估了LLM的表现：一个简单的SIR分室模型、一个COVID-19大流行模型以及一个HIV传播模型。初步结果表明，LLMs能够在保持结构表示和参数提取准确性的同时，显著减少人工建模的工作量。本研究为最优输入配置提供了见解，并识别出自动化流行病学模型生成中的关键挑战。"
  },
  {
    "date": "2026-1-23",
    "title": "Woodpecker: A Locally Deployed Large Language Model for Protecting Sensitive Information via RAG and Semantic Recognition",
    "authors": "Yiwei Liu, Duo Li, Hu Wang, Pengpeng Zhou, Yuying Xie, Peng Yin",
    "publish": "2025 IEEE 19th International Conference on Big Data Science and Engineering (BigDataSE)",
    "url": "https://doi.org/10.1109/bigdatase66491.2025.00018",
    "source": "IEEE",
    "abstract": "In recent years, large language models (LLMs) have demonstrated remarkable performance in natural language processing tasks. Owing to their strong capabilities in language understanding and generation, they have been widely applied and increasingly deployed locally in domains such as education, healthcare, law, and classified information processing. Retrieval-Augmented Generation (RAG) models enable the integration of local knowledge bases with general knowledge bases, thereby producing richer, more accurate, and contextually relevant outputs. However, in scenarios involving classified or sensitive data, local knowledge bases often contain highly confidential information, raising the critical challenge of ensuring usability while preventing leakage. To address this issue, we propose the Woodpecker Model, a large language model designed for sensitive information protection. Built on the RAG framework, the model combines BERT and rule-based regular expression matching to achieve sensitive information recognition, balancing effective content generation with robust security mechanisms. For evaluation, we constructed a test set consisting of 400 general texts and 200 sensitive texts. Experimental results show that the hybrid approach of BERT and regular expression matching achieves higher recall and F1 scores than either method used independently. Moreover, in expert-based evaluations on 50 queries related to a local knowledge base, the Woodpecker Model achieved an average score of 3.7, significantly outperforming baseline methods in generating useful information. These results confirm the effectiveness and practical value of the proposed model in sensitive information scenarios.",
    "title_zh": "啄木鸟：基于RAG与语义识别的本地化部署大语言模型，用于保护敏感信息",
    "abstract_zh": "近年来，大型语言模型（LLMs）在自然语言处理任务中展现出卓越的性能。凭借其强大的语言理解与生成能力，这些模型已广泛应用于教育、医疗、法律以及机密信息处理等领域，并逐步实现本地化部署。检索增强生成（RAG）模型能够将本地知识库与通用知识库相结合，从而生成内容更丰富、准确性更高且上下文关联性更强的输出。然而，在涉及机密或敏感数据的场景中，本地知识库通常包含高度敏感的信息，如何在保障可用性的同时防止信息泄露，成为一项关键挑战。为应对这一问题，我们提出了“啄木鸟模型”（Woodpecker Model），一种专为敏感信息保护设计的大规模语言模型。该模型基于RAG框架，结合BERT与基于规则的正则表达式匹配技术，实现对敏感信息的精准识别，在保证有效内容生成的同时，构建了强有力的安全部署机制。为评估模型性能，我们构建了一个包含400条普通文本和200条敏感文本的测试集。实验结果表明，BERT与正则表达式匹配相结合的混合方法，在召回率和F1分数上均优于单独使用任一方法。此外，在针对本地知识库的50个查询进行专家评估中，啄木鸟模型平均得分达3.7，显著优于基线方法，展现出生成有用信息的优越能力。这些结果充分验证了所提模型在敏感信息场景下的有效性与实际应用价值。"
  },
  {
    "date": "2026-1-23",
    "title": "A Fully Automated Agent for End-to-End Code Translation and Validation",
    "authors": "Eray Erer, Aysun Bozanta, Turgay Aytac, Ayse Basar",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00128",
    "source": "IEEE",
    "abstract": "Migration of software across programming languages is a critical yet labor-intensive task, often requiring deep code understanding and manual intervention. In this study, we develop a fully automated agent for end-to-end code translation and validation. First, we generate code comments from Java source code using various large language models (LLMs) to enhance code comprehension and facilitate cross-language translation. Second, leveraging these AI-generated comments, we automatically generate equivalent C# code, demonstrating the potential of AI in software migration and interoperability. Third, we complete both Java and generated C# code and prepare them to execute. Fourth, we apply automated unit testing to assess functional correctness and ensure the reliability of AI-generated code. Our results show that a fully automated LLM agent may be effective in bridging programming languages with human-in-the-loop. This approach opens new possibilities for scalable, AIdriven software modernization and cross-platform development. We recommend that such an LLM agent should be used in tandem with human experts during the generation of a reliable and correct code.",
    "title_zh": "一个完全自动化的代理，用于端到端的代码翻译与验证",
    "abstract_zh": "将软件从一种编程语言迁移至另一种，是一项至关重要但又耗时费力的任务，通常需要深入理解代码并进行大量人工干预。在本研究中，我们开发了一个完全自动化的智能体，实现端到端的代码翻译与验证。首先，我们利用多种大型语言模型（LLMs）从Java源代码生成代码注释，以增强代码理解能力，从而促进跨语言的代码转换。其次，基于这些由AI生成的注释，我们自动生成等效的C#代码，展示了人工智能在软件迁移与互操作性方面的巨大潜力。第三，我们对原始Java代码和生成的C#代码进行完整化处理，并准备执行环境。第四，我们应用自动化单元测试来评估功能正确性，确保AI生成代码的可靠性。实验结果表明，一个完全自动化的LLM智能体在人类参与的协同模式下，能够有效实现编程语言间的桥梁作用。该方法为可扩展、以AI驱动的软件现代化及跨平台开发开辟了新路径。我们建议，在生成可靠且正确的代码过程中，应将此类LLM智能体与人类专家协同使用，以保障最终成果的质量。"
  },
  {
    "date": "2026-1-23",
    "title": "AI-Driven DevOps in Modern Software Engineering—A Review of Machine LearningBased Intelligent Automation for Deployment and Maintenance",
    "authors": "Sai Raghavendra Varanasi",
    "publish": "2025 IEEE 2nd International Conference on Information Technology, Electronics and Intelligent Communication Systems (ICITEICS)",
    "url": "https://doi.org/10.1109/iciteics64870.2025.11340882",
    "source": "IEEE",
    "abstract": "The accelerated evolution of software engineering at the background has necessitated the inclusion of Artificial Intelligence (AI) in DevOps, which consequently introduces to the existence of AI-based DevOps, or, AIOps. Artificial Intelligence (AI) disrupts DevOps by adding automation, making deployments more effective, and optimizing software maintenance. This paper investigates how intelligent automation technological process driven by machine learning (ML) is revolutionizing software deployment and maintenance through speed, reliability and adaptability. It looks at how AI can help address historical issues of DevOps, including disjointed toolchains, lack of automation and delayed feedback cycles. An examination is conducted on major AI techniques and their functions in areas such as incident management, selfhealing systems, deep learning, reinforcement learning, supervised learning, and anomaly detection in predictive analytics. This study summaries the state-of-the-art applications, limits, and gaps in the present literature, which has also been thoroughly examined. Researchers and practitioners interested in improving software lifecycle management via intelligent automation may learn a lot from these findings, which highlight the need for a robust and extensible framework to fully use AI in existing DevOps pipelines.",
    "title_zh": "基于机器学习的智能自动化在部署与维护中的应用——现代软件工程中人工智能驱动的DevOps综述",
    "abstract_zh": "软件工程的加速演进背景促使人工智能（AI）被纳入DevOps，从而催生了基于人工智能的DevOps，即AIOps。人工智能通过引入自动化，显著提升了部署效率并优化了软件维护流程，对DevOps产生了深远影响。本文探讨了由机器学习（ML）驱动的智能自动化技术如何通过提升速度、可靠性和适应性，彻底变革软件的部署与维护过程。研究还分析了AI在解决传统DevOps长期存在的问题方面所发挥的作用，如工具链割裂、自动化不足以及反馈周期延迟等。文章深入考察了主要的人工智能技术及其在故障管理、自愈系统、深度学习、强化学习、监督学习以及预测分析中的异常检测等方面的应用。本研究总结了当前文献中关于AIOps的前沿应用、局限性与研究空白，并进行了全面评述。对于希望借助智能自动化提升软件生命周期管理的研究人员和实践者而言，这些发现具有重要参考价值，强调了构建一个强大且可扩展的框架以充分整合AI到现有DevOps流程中的必要性。"
  },
  {
    "date": "2026-1-23",
    "title": "MFU-Powered RISC-V: Efficient Matrix Processing in a Pipelined Core",
    "authors": "Anusree C S, Paramasivam C",
    "publish": "2025 IEEE 2nd International Conference on Information Technology, Electronics and Intelligent Communication Systems (ICITEICS)",
    "url": "https://doi.org/10.1109/iciteics64870.2025.11341546",
    "source": "IEEE",
    "abstract": "Modern applications, include machine learning and computer vision, more and more count on efficient matrix processors have a hard time keeping up with the requirements for latest technologies. For this reason, we made a 5-stage pipelined RISC-V processor, by employing a MFU and a Matrix Register. An MRF file designed to support fast operations with matrices. 32 registers are included in the MRF, all holding four 5-bit signed as a result, two sharing nodes can be represented in a simple 2×2 matrix. It supports adding elements of matrices, as well as doing numerical multiplications, inversion, transposition and error handling for times when a matrix can't be inverted or the transaction is invalid. Also involves detecting hazards. By using forwarding, aim to prevent stalls within the pipeline and maintain reliable performance. A detailed testbench confirms that the design works properly Among the basic tasks, problems with overflow conditions and issues caused by data hazards. Implemented the processor built with Verilog. Static timing analysis is the process to Arranging both these factors, arranging closure and choosing the proper clock frequency. The design benefits from effective matrix processing, as shown by the results. efficient and reliant processes for jobs that heavily use matrices. Enhancements to the model could improve how inverse calculations are performed. and makes memory operations faster which improves performance in practical situations",
    "title_zh": "基于MFU的RISC-V：流水线核心中的高效矩阵处理",
    "abstract_zh": "现代应用，如机器学习和计算机视觉，越来越依赖高效的矩阵处理器，但现有的处理器在应对最新技术需求时显得力不从心。为此，我们设计并实现了一款五级流水线化的RISC-V处理器，通过引入矩阵功能单元（MFU）和矩阵寄存器（Matrix Register），并配套设计了MRF文件，以支持矩阵的快速运算。该MRF包含32个寄存器，每个寄存器可存储四个5位有符号数，因此能够以简单的2×2矩阵形式表示两个共享节点。该设计支持矩阵元素的加法、数值乘法、矩阵求逆、转置操作，以及在矩阵无法求逆或操作无效时的错误处理机制。同时，还具备数据冒险检测功能。通过采用前递（forwarding）技术，有效避免流水线中的停顿，确保系统性能的稳定可靠。通过详细的测试平台验证，该设计在基本任务中表现良好，成功解决了溢出条件及由数据冒险引发的问题。处理器使用Verilog语言实现，并通过静态时序分析（Static Timing Analysis）完成时序收敛，合理选择时钟频率。实验结果表明，该设计在矩阵密集型任务中展现出高效且可靠的处理能力，显著提升了对矩阵运算高度依赖的应用场景下的性能表现。未来可通过优化逆矩阵计算算法，进一步提升计算效率，并加快内存操作速度，从而在实际应用中获得更优的整体性能。"
  },
  {
    "date": "2026-1-23",
    "title": "FileWizz: A Generative AI Based Multi-Format File Convsersion and Management GUI Tool for Enhanced User Productivity",
    "authors": "S Venkatraman, D Pushgara Rani, TJ Jeyaprabha, Sumneet Kaur Bamrah",
    "publish": "2025 International Conference on Responsible, Generative and Explainable AI (ResGenXAI)",
    "url": "https://doi.org/10.1109/resgenxai64788.2025.11344000",
    "source": "IEEE",
    "abstract": "FileWizz is a multi-functional desktop application designed to simplify essential file operations such as format conversion, PDF manipulation, image processing, and compression with a specific focus on serving the academic community. This tool was developed entirely through prompt engineering using ChatGPT 4o mini, a generative AI model based on advanced natural language processing. The core motivation of this work is to explore the practical viability of using large language models (LLMs) to construct real-world utility software, without manual programming from scratch. While FileWizz does not implement machine learning internally, the software serves as a case study in AI-assisted software synthesis, highlighting the evolving role of generative models in rapid prototyping and zero-cost educational tooling. The outcomes indicate the feasibility of using generative AI agents not just for content generation, but also for scaffolded application development through iterative natural language interactions.",
    "title_zh": "FileWizz：基于生成式人工智能的多格式文件转换与管理图形化工具，助力用户提升工作效率",
    "abstract_zh": "FileWizz 是一款多功能桌面应用程序，旨在简化格式转换、PDF 处理、图像编辑和文件压缩等核心文件操作，特别面向学术群体提供服务。该工具完全通过提示工程（prompt engineering）使用基于先进自然语言处理技术的生成式人工智能模型 ChatGPT 4o mini 开发而成。本项目的核心动机在于探索大型语言模型（LLMs）在构建真实世界实用软件方面的实际可行性，而无需从零开始进行手动编程。尽管 FileWizz 内部并未集成机器学习功能，但该软件作为一项典型案例，展示了生成式模型在辅助软件合成中的潜力，凸显了生成式 AI 在快速原型开发与零成本教育工具创建中的日益重要角色。研究结果表明，生成式 AI 代理不仅可用于内容生成，还可通过迭代化的自然语言交互，实现有结构的应用程序开发。"
  },
  {
    "date": "2026-1-23",
    "title": "Detecting and Fixing API Misuses of Data Science Libraries Using Large Language Models",
    "authors": "Akalanka Galappaththi, Francisco Ribeiro, Sarah Nadi",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00083",
    "source": "IEEE",
    "abstract": "Data science libraries, such as scikit-learn and pandas, specialize in processing and manipulating data. The data-centric nature of these libraries makes the detection of API misuse in them more challenging. This paper introduces DSCHECKER, an LLM-based approach designed for detecting and fixing API misuses of data science libraries. We identify two key pieces of information, API directives and data information, that may be beneficial for API misuse detection and fixing. Using three LLMs and misuses from five data science libraries, we experiment with various prompts. We find that incorporating API directives and data-specific details enhances DSCHECKER's ability to detect and fix API misuses, with the best-performing model achieving a detection <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$F_{1}$</tex>-score of 61.18% and fixing 51.28% of the misuses. Building on these results, we implement DSCHECKER <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">${ }_{\\text {agent }}$</tex> which includes an adaptive function calling mechanism to access information on demand, simulating a realworld setting where information about the misuse is unknown in advance. We find that DSCHECKER <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">${ }_{\\text {agent }}$</tex> achieves 48.65% detection <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$F_{1}$</tex>-score and fixes 39.47% of the misuses, demonstrating the promise of LLM-based API misuse detection and fixing in real-world scenarios.",
    "title_zh": "使用大型语言模型检测并修复数据科学库的API误用",
    "abstract_zh": "数据科学库（如 scikit-learn 和 pandas）专注于数据的处理与操作。由于这些库具有高度数据导向的特性，因此在它们中检测 API 使用错误更加困难。本文提出 DSCHECKER，一种基于大语言模型（LLM）的方法，用于检测并修复数据科学库中的 API 使用错误。我们识别出两个关键信息：API 指令和数据信息，这两者可能对 API 错误的检测与修复有所帮助。通过使用三种 LLM 并结合来自五个数据科学库的错误案例，我们测试了多种提示（prompt）策略。结果表明，引入 API 指令和具体数据特征能够显著提升 DSCHECKER 检测和修复 API 错误的能力，其中表现最佳的模型达到了 61.18% 的 F₁ 分数，并修复了 51.28% 的错误。\n\n基于上述成果，我们进一步实现了 DSCHECKER<sub>agent</sub>，该系统包含一种自适应函数调用机制，可根据需要动态获取相关信息，从而模拟真实场景中在事前无法预知错误详情的情况。实验发现，DSCHECKER<sub>agent</sub> 在检测方面取得了 48.65% 的 F₁ 分数，成功修复了 39.47% 的错误，充分展示了基于大语言模型的 API 错误检测与修复方法在真实应用环境中的巨大潜力。"
  },
  {
    "date": "2026-1-23",
    "title": "Adaptive Fine-Tuning for Multiclass Classification Over Software Requirement Data",
    "authors": "Savas Yildirim, Mucahit Cevik, Ayse Basar",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00039",
    "source": "IEEE",
    "abstract": "The analysis of software requirement specifications (SRS) using Natural Language Processing (NLP) methods has been an important study area in the software engineering field in recent years. Especially thanks to the advances brought by deep learning and transfer learning approaches in NLP, SRS data can be utilized for various learning tasks more easily. In this study, we employ a three-stage domain-adaptive fine-tuning approach for three prediction tasks regarding software requirements, which improve the model robustness on a real distribution shift. The multi-class classification tasks involve predicting the type, priority and severity of the requirement texts specified by the users. We compare our results with strong classification baselines such as word embedding pooling and Sentence BERT, and show that the adaptive fine-tuning leads to performance improvements across the tasks. We find that an adaptively fine-tuned model can be specialized to a particular data distribution, which is able to generate accurate results and learns from abundantly available textual data in software engineering task management systems.",
    "title_zh": "面向软件需求数据的多分类自适应微调",
    "abstract_zh": "近年来，利用自然语言处理（NLP）方法对软件需求规格说明书（SRS）进行分析已成为软件工程领域的重要研究方向。特别是得益于深度学习和迁移学习在NLP领域的进展，SRS数据能够更便捷地应用于多种学习任务。在本研究中，我们采用一种三阶段领域自适应微调方法，针对软件需求的三项预测任务，提升了模型在真实分布偏移情况下的鲁棒性。这些多分类任务包括预测用户指定的需求文本的类型、优先级和严重程度。我们将实验结果与强基准方法（如词嵌入池化和Sentence BERT）进行对比，结果表明，自适应微调在各项任务中均带来了性能提升。研究发现，经过自适应微调的模型能够针对特定的数据分布进行优化，从而生成准确的结果，并有效利用软件工程任务管理系统中大量存在的文本数据进行学习。"
  },
  {
    "date": "2026-1-23",
    "title": "NeuroStack: A Agentic AI Platform for Enterprise",
    "authors": "Kanav Kahol, Navid Kalantari, Mir Ali",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00094",
    "source": "IEEE",
    "abstract": "NeuroStack is a general-purpose agentic AI platform designed to enable enterprise-scale multi-agent systems with advanced reasoning, memory, and orchestration capabilities. It addresses limitations of monolithic large language model (LLM) agents by introducing a modular eight-layer architecture that spans from cloud infrastructure up to operations and governance. Each layer encapsulates a key concern (from networking and communication protocols to tooling, cognitive reasoning, longterm memory, user interaction, and oversight), providing a structured foundation for building autonomous AI “agent societies.” The need for such an architecture is motivated by current LLM wrappers' shortcomings in memory, tool-use, and governance. An illustrative use case in code conversion demonstrates how multiple specialized agents can collaborate using NeuroStack to perform complex tasks (e.g. code translation and verification) that single agents handle poorly.",
    "title_zh": "NeuroStack：面向企业的智能代理AI平台",
    "abstract_zh": "NeuroStack 是一个通用的智能体式人工智能平台，旨在支持企业级大规模多智能体系统的构建，具备先进的推理、记忆和编排能力。它克服了传统单体式大语言模型（LLM）智能体的局限性，引入了一种模块化的八层架构，从云基础设施延伸至运营与治理层面。每一层都封装了关键功能领域（包括网络与通信协议、工具集成、认知推理、长期记忆、用户交互以及监管控制），为构建自主运行的“智能体社会”提供了结构化基础。这一架构的必要性源于当前 LLM 封装方案在记忆管理、工具使用和治理方面的不足。一个典型的代码转换应用场景展示了多个专业化智能体如何通过 NeuroStack 协同工作，完成复杂任务（如代码翻译与验证），而这些任务单个智能体往往难以高效处理。"
  },
  {
    "date": "2026-1-23",
    "title": "An Approach for Cross-Project Defect Prediction Using Composite Distribution Alignment and Domain-Adversarial Neural Networks",
    "authors": "Dipender Singh, Sandeep Kumar",
    "publish": "IEEE Transactions on Reliability",
    "url": "https://doi.org/10.1109/tr.2026.3657526",
    "source": "IEEE",
    "abstract": "Cross-project defect prediction (CPDP) is an important task in software engineering, where data from external projects is used to identify defect-prone modules in a target project that lacks sufficient historical information. However, CPDP remains challenging due to substantial distributional disparities between source and target projects. Many existing methods fail to select appropriate source data for a given target project, which hinders knowledge transfer and degrades predictive performance. To address this challenge, we propose CDA-DANN, a novel framework that combines compatible source project selection with domain-adversarial learning. It introduces a composite similarity metric that jointly captures structural relationships, measured by the Frobenius norm of feature correlation matrices, and distributional divergence, quantified using the Kolmogorov-Smirnov test. This composite similarity metric guides the selection of the source project that is most compatible with the target. The selected data is subsequently used to train a domain-adversarial neural network (DANN) augmented with a gradient reversal layer, which facilitates the learning of domain-invariant features to improve generalization across projects. We conduct comprehensive experiments on 22 widely used software projects. The results show that CDA-DANN consistently outperforms state-of-the-art CPDP methods, achieving improvements in AUC ranging from 5.48% to 11.59%, and in MCC from 20% to 57.89%. These findings highlight the effectiveness of combining source selection with adversarial feature alignment in achieving reliable and transferable cross-project defect prediction.",
    "title_zh": "一种基于复合分布对齐与领域对抗神经网络的跨项目缺陷预测方法",
    "abstract_zh": "跨项目缺陷预测（CPDP）是软件工程中的一个重要任务，其核心思想是利用外部项目的数据来识别目标项目中可能存在缺陷的模块，尤其适用于缺乏足够历史信息的目标项目。然而，由于源项目与目标项目之间存在显著的分布差异，CPDP仍然面临巨大挑战。许多现有方法无法为特定目标项目选择合适的源项目数据，从而阻碍了知识迁移并降低了预测性能。为应对这一挑战，我们提出了一种名为CDA-DANN的新框架，该框架将兼容性源项目选择与领域对抗学习相结合。该方法引入了一种复合相似性度量，同时捕捉结构关系（通过特征相关矩阵的Frobenius范数衡量）和分布差异（采用Kolmogorov-Smirnov检验量化），以此指导选择与目标项目最匹配的源项目。随后，所选数据被用于训练一个带有梯度反转层的领域对抗神经网络（DANN），以促进学习领域不变特征，从而提升模型在不同项目间的泛化能力。我们在22个广泛使用的软件项目上进行了全面实验。结果表明，CDA-DANN始终优于现有的先进CPDP方法，在AUC指标上提升幅度达5.48%至11.59%，在MCC指标上提升幅度为20%至57.89%。这些发现充分证明，将源项目选择与对抗特征对齐相结合，能够有效实现可靠且可迁移的跨项目缺陷预测。"
  },
  {
    "date": "2026-1-23",
    "title": "Network Traffic Reduction Through AI-Assisted Local Data Optimization of Synthetic Data",
    "authors": "Matthias Rüb, Jens Grüber, Hans D. Schotten",
    "publish": "2025 8th International Conference on Information and Communications Technology (ICOIACT)",
    "url": "https://doi.org/10.1109/icoiact67584.2025.11344995",
    "source": "IEEE",
    "abstract": "In future wireless networks, AI instances are expected to take on autonomous tasks increasingly. In this context, the availability of high-quality synthetic data is becoming more important, as AI-agents in different domains, such as healthcare and natural language processing (NLP) will be expected to run safety and stability tests without the need for real data. Synthetic data is also useful for clinical practitioners to address imbalances in datasets or to augment existing data. However, this increased demand for datasets places an additional burden on the communication infrastructure, adding to the existing traffic. T his n ot o nly impacts t he performance o f t he network but also negatively affects sustainability. In this work addresses these issues by introducing a new paradigm, which shifts away from transmitting entire datasets and focuses on local data generation and optimization instead. While this approach has been desirable for a long time, recent developments in artificial intelligence (AI), particularly in NLP, have made it now feasible by empowering end-users without technical expertise to perform data optimization. As an exemplary use case, this work demonstrates a large language model (LLM) curated data optimization using synthetic smart insole gait data. Several low-weight LLMs are tasked to assist the curation. It is shown that local light-weight models, which can be deployed even with low-cost clinical IT infrastructure, can support non-experts with the local optimization process of otherwise insufficient synthetic data.",
    "title_zh": "通过人工智能辅助的本地数据优化实现合成数据的网络流量减少",
    "abstract_zh": "在未来的无线网络中，人工智能（AI）实例预计将承担越来越多的自主任务。在此背景下，高质量合成数据的可用性变得日益重要，因为不同领域的AI代理（如医疗健康和自然语言处理，NLP）将需要在无需真实数据的情况下运行安全性和稳定性测试。合成数据对于临床从业者也十分有用，可用于解决数据集不平衡问题或扩充现有数据。然而，这种对数据集日益增长的需求给通信基础设施带来了额外负担，加剧了现有的网络流量压力。这不仅影响网络性能，还对可持续性造成了负面影响。\n\n本文提出了一种新范式，旨在解决上述问题：不再传输完整的数据集，而是转向本地生成与优化数据。尽管这一理念长期以来备受期待，但近年来人工智能（尤其是自然语言处理领域）的快速发展，使得该方案如今已具备可行性——它赋予了不具备技术背景的终端用户能力，使其能够自主完成数据优化工作。\n\n作为典型应用案例，本文展示了利用大型语言模型（LLM）对合成智能鞋垫步态数据进行优化的过程。多个轻量级LLM被指派协助数据整理工作。研究结果表明，即使在低成本的临床IT基础设施条件下，也可部署这些轻量级本地模型，从而帮助非专业人士有效优化原本不足的合成数据，实现高效、可靠的本地化数据处理。"
  },
  {
    "date": "2026-1-23",
    "title": "RevMine: An LLM-Assisted Tool for Code Review Mining and Analysis Across Git Platforms",
    "authors": "Samah Kansab, Francis Bordeleau, Ali Tizghadam",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00092",
    "source": "IEEE",
    "abstract": "Empirical research on code review processes is increasingly central to understanding software quality and collaboration. However, collecting and analyzing review data remains a time-consuming and technically intensive task. Most researchers follow similar workflows-writing ad hoc scripts to extract, filter, and analyze review data from platforms like GitHub and GitLab. This paper introduces RevMine, a conceptual tool that streamlines the entire code review mining pipeline using large language models (LLMs). RevMine guides users through authentication, endpoint discovery, and natural language-driven data collection, significantly reducing the need for manual scripting. After retrieving review data, it supports both quantitative and qualitative analysis based on user-defined filters or LLM-inferred patterns. This poster outlines the tool's architecture, use cases, and research potential. By lowering the barrier to entry, RevMine aims to democratize code review mining and enable a broader range of empirical software engineering studies.",
    "title_zh": "RevMine：一种用于跨Git平台代码审查挖掘与分析的LLM辅助工具",
    "abstract_zh": "关于代码审查流程的实证研究正日益成为理解软件质量和协作的关键。然而，收集和分析审查数据仍然是一项耗时且技术要求较高的任务。目前，大多数研究人员采用相似的工作流程——编写临时脚本，从GitHub、GitLab等平台提取、过滤并分析审查数据。本文介绍了一款名为RevMine的概念性工具，该工具利用大语言模型（LLMs）简化整个代码审查数据挖掘流程。RevMine通过引导用户完成身份验证、接口发现以及基于自然语言的数据采集，大幅减少了手动编写脚本的需求。在获取审查数据后，它支持基于用户自定义筛选条件或LLM推断模式的定量与定性分析。本海报概述了该工具的架构设计、应用场景及研究潜力。通过降低入门门槛，RevMine旨在推动代码审查数据挖掘的普及化，助力更广泛的实证软件工程研究。"
  },
  {
    "date": "2026-1-23",
    "title": "Efficient Pointer Analysis via Def-Use Graph Pruning",
    "authors": "Jiaqi He, Karim Ali",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00063",
    "source": "IEEE",
    "abstract": "Precise pointer information is essential for dataflow analysis. While flow-sensitive pointer analysis yields highly precise results, it introduces more computations. To provide a better trade-off between precision and performance, prior work has developed LEVPA, a pointer analysis that processes pointers according to their pointer level, generally accelerating the analysis. However, LevPA still performs redundant computations for intermediate variables that are generated during Static Single Assignment (SSA) transformation. For real-world programs, we have observed that those variables may constitute up to 87 % of all analyzed variables. These unnecessary computations cause LEVPA to timeout for large programs. To address these limitations, we present Level-based Intermediate variable Skipping Pointer Analysis (LisPA), an enhancement of LevPA that operates on a def-use graph without computing points-to set of intermediate variables introduced during SSA transformation. The key insight behind LISPA is that intermediate variables do not introduce new pointers into the analysis, because they always alias with variables in the original program. Therefore, there is no need to compute their points-to set in a fixed-point computation. Across 27 real-world C/C++ programs, we show that LISPA is on average <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$2.14 \\times$</tex> faster than LevPA, while using <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$2.38 \\times$</tex> less memory.",
    "title_zh": "通过使用-定义图剪枝实现高效的指针分析",
    "abstract_zh": "精确的指针信息对于数据流分析至关重要。虽然流敏感的指针分析能够产生高度精确的结果，但其计算开销较大。为了在精度与性能之间取得更好的平衡，先前的研究提出了LEVPA，一种根据指针层级处理指针的指针分析方法，通常能加速分析过程。然而，LEVPA在静态单赋值（SSA）转换过程中生成的中间变量上仍存在冗余计算。针对真实世界程序的观察表明，这些中间变量可能占所有分析变量的高达87%。这些不必要的计算导致LEVPA在处理大型程序时出现超时问题。\n\n为解决上述局限性，我们提出了一种名为基于层级的中间变量跳过指针分析（LisPA）的新方法，它是LEVPA的改进版本。LisPA在不计算SSA转换中引入的中间变量点集的前提下，直接在定义-使用图（def-use graph）上进行分析。LisPA的核心思想在于：中间变量不会向分析中引入新的指针，因为它们始终与原始程序中的变量别名相同。因此，在固定点计算中无需为其计算点集。\n\n在27个真实世界的C/C++程序上进行的实验表明，LisPA相比LEVPA平均快2.14倍，同时内存使用量减少至原来的2.38倍。"
  },
  {
    "date": "2026-1-23",
    "title": "AI-Driven Circuit Debugging: Leveraging Large Language Models for Automated Fault Detection and Diagnosis",
    "authors": "Sowmya MN",
    "publish": "2025 Second International Conference on Networks and Soft Computing (ICNSoC)",
    "url": "https://doi.org/10.1109/icnsoc66817.2025.00123",
    "source": "IEEE",
    "abstract": "Traditional circuit debugging methods are often inefficient, time-consuming, and prone to human error, making them unsuitable for handling complex electronic systems. This research introduces an AI-driven debugging tool that leverages Large Language Models (LLMs), machine learning, and object detection technologies to enhance circuit analysis, fault detection, and solution recommendations. The proposed system features a web-based interface that enables users to upload circuit images for automated diagnostics and allows interactive troubleshooting through natural language queries. By ensuring data privacy, system reliability, and high-quality responses, this tool aims to improve usability across various circuit complexities. The integration of AI in circuit debugging is expected to reduce downtime, enhance productivity, and support engineers in maintaining intricate electronic systems. Experimental validation shows reliable fault detection and debugging performance.",
    "title_zh": "基于人工智能的电路调试：利用大语言模型实现故障的自动检测与诊断",
    "abstract_zh": "传统的电路调试方法通常效率低下、耗时且容易出错，难以应对复杂的电子系统。本研究提出了一种基于人工智能的调试工具，融合大型语言模型（LLMs）、机器学习和目标检测技术，以提升电路分析、故障检测及解决方案推荐的能力。该系统采用基于Web的界面，用户可上传电路图进行自动化诊断，并通过自然语言交互实现互动式故障排查。通过保障数据隐私、系统可靠性以及高质量的响应，该工具旨在提升在各种复杂电路场景下的易用性。人工智能在电路调试中的应用有望减少停机时间，提高工作效率，并帮助工程师更好地维护复杂的电子系统。实验验证表明，该工具具备可靠的故障检测与调试性能。"
  },
  {
    "date": "2026-1-23",
    "title": "SynRAG: A Large Language Model Framework for Executable Query Generation in Heterogeneous SIEM Systems",
    "authors": "Md Hasan Saju, Austin Page, Akramul Azim, Jeff Gardiner, Farzaneh Abazari, Frank Eargle",
    "publish": "2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON)",
    "url": "https://doi.org/10.1109/cascon66301.2025.00046",
    "source": "IEEE",
    "abstract": "Security Information and Event Management (SIEM) systems are essential for large enterprises to monitor their IT infrastructure by ingesting and analyzing millions of logs and events daily. Security Operations Center (SOC) analysts are tasked with monitoring and analyzing this vast data to identify potential threats and take preventive actions to protect enterprise assets. However, the diversity among SIEM platforms, such as Palo Alto Networks Qradar, Google SecOps, Splunk, Microsoft Sentinel and the Elastic Stack, poses significant challenges. As these systems differ in attributes, architecture, and query languages, making it difficult for analysts to effectively monitor multiple platforms without undergoing extensive training or forcing enterprises to expand their workforce. To address this issue, we introduce SynRAG, a unified framework that automatically generates threat detection or incident investigation queries for multiple SIEM platforms from a platform-agnostic specification. SynRAG can generate platformspecific queries from a single high-level specification written by analysts. Without SynRAG, analysts would need to manually write separate queries for each SIEM platform, since query languages vary significantly across systems. This framework enables seamless threat detection and incident investigation across heterogeneous SIEM environments, reducing the need for specialized training and manual query translation. We evaluate SynRAG against state-of-the-art language models, including GPT, Llama, DeepSeek, Gemma, and Claude, using Qradar and SecOps as representative SIEM systems. Our results demonstrate that SynRAG generates significantly better queries for crossSIEM threat detection and incident investigation compared to the state-of-the-art base models.",
    "title_zh": "SynRAG：一种用于异构SIEM系统中可执行查询生成的大语言模型框架",
    "abstract_zh": "安全信息与事件管理（SIEM）系统对于大型企业监控其IT基础设施至关重要，能够每日接收并分析数百万条日志和事件。安全运营中心（SOC）分析师负责监控和分析这些海量数据，以识别潜在威胁，并采取预防措施保护企业资产。然而，不同SIEM平台之间的差异——如Palo Alto Networks Qradar、Google SecOps、Splunk、Microsoft Sentinel以及Elastic Stack——带来了显著挑战。由于这些系统在属性、架构和查询语言方面存在差异，分析师若要有效监控多个平台，往往需要接受大量培训，或迫使企业扩大人员规模。为解决这一问题，我们提出了SynRAG——一种统一框架，可从平台无关的规范中自动生成适用于多个SIEM平台的威胁检测或事件调查查询。SynRAG能够根据分析师编写的一条高层次规范，自动生成针对不同平台的具体查询语句。若无SynRAG，分析师必须手动为每个SIEM平台分别编写查询，因为各系统的查询语言差异显著。该框架实现了异构SIEM环境下的无缝威胁检测与事件调查，减少了对专业培训的需求以及手动查询转换的工作量。我们在代表性SIEM系统Qradar和SecOps上，对SynRAG与当前最先进的语言模型（包括GPT、Llama、DeepSeek、Gemma和Claude）进行了对比评估。结果表明，SynRAG在跨SIEM威胁检测与事件调查方面生成的查询质量显著优于现有主流基础模型。"
  },
  {
    "date": "2026-1-23",
    "title": "An Empirical Study on the Characteristics of Reusable Code Clones",
    "authors": "Chunli Yu, Shayan Noei, Haoxiang Zhang, Ying Zou",
    "publish": "ACM Transactions on Software Engineering and Methodology",
    "url": "https://doi.org/10.1145/3793251",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "可重用代码克隆特征的实证研究",
    "abstract_zh": "None"
  }
]